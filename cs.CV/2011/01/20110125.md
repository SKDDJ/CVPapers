# Arxiv Papers in cs.CV on 2011-01-25
### Online Adaptive Decision Fusion Framework Based on Entropic Projections onto Convex Sets with Application to Wildfire Detection in Video
- **Arxiv ID**: http://arxiv.org/abs/1101.4749v1
- **DOI**: 10.1117/1.3595426
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1101.4749v1)
- **Published**: 2011-01-25 09:11:49+00:00
- **Updated**: 2011-01-25 09:11:49+00:00
- **Authors**: Osman Gunay, Behcet Ugur Toreyin, Kivanc Kose, A. Enis Cetin
- **Comment**: 10 pages, 7 figures
- **Journal**: None
- **Summary**: In this paper, an Entropy functional based online Adaptive Decision Fusion (EADF) framework is developed for image analysis and computer vision applications. In this framework, it is assumed that the compound algorithm consists of several sub-algorithms each of which yielding its own decision as a real number centered around zero, representing the confidence level of that particular sub-algorithm. Decision values are linearly combined with weights which are updated online according to an active fusion method based on performing entropic projections onto convex sets describing sub-algorithms. It is assumed that there is an oracle, who is usually a human operator, providing feedback to the decision fusion method. A video based wildfire detection system is developed to evaluate the performance of the algorithm in handling the problems where data arrives sequentially. In this case, the oracle is the security guard of the forest lookout tower verifying the decision of the combined algorithm. Simulation results are presented. The EADF framework is also tested with a standard dataset.



### Using Feature Weights to Improve Performance of Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1101.4918v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1101.4918v1)
- **Published**: 2011-01-25 20:24:25+00:00
- **Updated**: 2011-01-25 20:24:25+00:00
- **Authors**: Ridwan Al Iqbal
- **Comment**: 2 tables, 4 figures
- **Journal**: None
- **Summary**: Different features have different relevance to a particular learning problem. Some features are less relevant; while some very important. Instead of selecting the most relevant features using feature selection, an algorithm can be given this knowledge of feature importance based on expert opinion or prior learning. Learning can be faster and more accurate if learners take feature importance into account. Correlation aided Neural Networks (CANN) is presented which is such an algorithm. CANN treats feature importance as the correlation coefficient between the target attribute and the features. CANN modifies normal feed-forward Neural Network to fit both correlation values and training data. Empirical evaluation shows that CANN is faster and more accurate than applying the two step approach of feature selection and then using normal learning algorithms.



### A Generalized Method for Integrating Rule-based Knowledge into Inductive Methods Through Virtual Sample Creation
- **Arxiv ID**: http://arxiv.org/abs/1101.4924v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1101.4924v1)
- **Published**: 2011-01-25 20:42:01+00:00
- **Updated**: 2011-01-25 20:42:01+00:00
- **Authors**: Ridwan Al Iqbal
- **Comment**: None
- **Journal**: None
- **Summary**: Hybrid learning methods use theoretical knowledge of a domain and a set of classified examples to develop a method for classification. Methods that use domain knowledge have been shown to perform better than inductive learners. However, there is no general method to include domain knowledge into all inductive learning algorithms as all hybrid methods are highly specialized for a particular algorithm. We present an algorithm that will take domain knowledge in the form of propositional rules, generate artificial examples from the rules and also remove instances likely to be flawed. This enriched dataset then can be used by any learning algorithm. Experimental results of different scenarios are shown that demonstrate this method to be more effective than simple inductive learning.



