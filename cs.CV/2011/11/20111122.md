# Arxiv Papers in cs.CV on 2011-11-22
### A Theory for Optical flow-based Transport on Image Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1111.5108v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1111.5108v1)
- **Published**: 2011-11-22 05:55:25+00:00
- **Updated**: 2011-11-22 05:55:25+00:00
- **Authors**: Sriram Nagaraj, Aswin C. Sankaranarayanan, Richard G. Baraniuk
- **Comment**: None
- **Journal**: None
- **Summary**: An image articulation manifold (IAM) is the collection of images formed when an object is articulated in front of a camera. IAMs arise in a variety of image processing and computer vision applications, where they provide a natural low-dimensional embedding of the collection of high-dimensional images. To date IAMs have been studied as embedded submanifolds of Euclidean spaces. Unfortunately, their promise has not been realized in practice, because real world imagery typically contains sharp edges that render an IAM non-differentiable and hence non-isometric to the low-dimensional parameter space under the Euclidean metric. As a result, the standard tools from differential geometry, in particular using linear tangent spaces to transport along the IAM, have limited utility. In this paper, we explore a nonlinear transport operator for IAMs based on the optical flow between images and develop new analytical tools reminiscent of those from differential geometry using the idea of optical flow manifolds (OFMs). We define a new metric for IAMs that satisfies certain local isometry conditions, and we show how to use this metric to develop a new tools such as flow fields on IAMs, parallel flow fields, parallel transport, as well as a intuitive notion of curvature. The space of optical flow fields along a path of constant curvature has a natural multi-scale structure via a monoid structure on the space of all flow fields along a path. We also develop lower bounds on approximation errors while approximating non-parallel flow fields by parallel flow fields.



### A New IRIS Normalization Process For Recognition System With Cryptographic Techniques
- **Arxiv ID**: http://arxiv.org/abs/1111.5135v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1111.5135v1)
- **Published**: 2011-11-22 09:38:39+00:00
- **Updated**: 2011-11-22 09:38:39+00:00
- **Authors**: S. Nithyanandam, K. S. Gayathri, P. L. K. Priyadarshini
- **Comment**: 7 Pages,16 Figures; ISSN (Online): 1694-0814
- **Journal**: IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 4, No 1, 2011, 342-348
- **Summary**: Biometric technologies are the foundation of personal identification systems. It provides an identification based on a unique feature possessed by the individual. This paper provides a walkthrough for image acquisition, segmentation, normalization, feature extraction and matching based on the Human Iris imaging. A Canny Edge Detection scheme and a Circular Hough Transform, is used to detect the iris boundaries in the eye's digital image. The extracted IRIS region was normalized by using Image Registration technique. A phase correlation base method is used for this iris image registration purpose. The features of the iris region is encoded by convolving the normalized iris region with 2D Gabor filter. Hamming distance measurement is used to compare the quantized vectors and authenticate the users. To improve the security, Reed-Solomon technique is employed directly to encrypt and decrypt the data. Experimental results show that our system is quite effective and provides encouraging performance. Keywords: Biometric, Iris Recognition, Phase correlation, cryptography, Reed-Solomon



### Contextually Guided Semantic Labeling and Search for 3D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/1111.5358v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1111.5358v3)
- **Published**: 2011-11-22 22:39:31+00:00
- **Updated**: 2012-09-05 15:16:01+00:00
- **Authors**: Abhishek Anand, Hema Swetha Koppula, Thorsten Joachims, Ashutosh Saxena
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1106.5551
- **Journal**: None
- **Summary**: RGB-D cameras, which give an RGB image to- gether with depths, are becoming increasingly popular for robotic perception. In this paper, we address the task of detecting commonly found objects in the 3D point cloud of indoor scenes obtained from such cameras. Our method uses a graphical model that captures various features and contextual relations, including the local visual appearance and shape cues, object co-occurence relationships and geometric relationships. With a large number of object classes and relations, the model's parsimony becomes important and we address that by using multiple types of edge potentials. We train the model using a maximum-margin learning approach. In our experiments over a total of 52 3D scenes of homes and offices (composed from about 550 views), we get a performance of 84.06% and 73.38% in labeling office and home scenes respectively for 17 object classes each. We also present a method for a robot to search for an object using the learned model and the contextual information available from the current labelings of the scene. We applied this algorithm successfully on a mobile robot for the task of finding 12 object classes in 10 different offices and achieved a precision of 97.56% with 78.43% recall.



