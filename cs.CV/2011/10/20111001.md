# Arxiv Papers in cs.CV on 2011-10-01
### Learning image transformations without training examples
- **Arxiv ID**: http://arxiv.org/abs/1110.0061v1
- **DOI**: 10.1007/978-3-642-24031-7_17
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1110.0061v1)
- **Published**: 2011-10-01 01:07:03+00:00
- **Updated**: 2011-10-01 01:07:03+00:00
- **Authors**: Sergey Pankov
- **Comment**: 15 pages, 1 figure, ISVC11
- **Journal**: Proc. 7th International Symposium on Visual Computing, part II, pp
  168-179, 2011
- **Summary**: The use of image transformations is essential for efficient modeling and learning of visual data. But the class of relevant transformations is large: affine transformations, projective transformations, elastic deformations, ... the list goes on. Therefore, learning these transformations, rather than hand coding them, is of great conceptual interest. To the best of our knowledge, all the related work so far has been concerned with either supervised or weakly supervised learning (from correlated sequences, video streams, or image-transform pairs). In this paper, on the contrary, we present a simple method for learning affine and elastic transformations when no examples of these transformations are explicitly given, and no prior knowledge of space (such as ordering of pixels) is included either. The system has only access to a moderately large database of natural images arranged in no particular order.



### Learning to relate images: Mapping units, complex cells and simultaneous eigenspaces
- **Arxiv ID**: http://arxiv.org/abs/1110.0107v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, nlin.AO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1110.0107v2)
- **Published**: 2011-10-01 15:14:16+00:00
- **Updated**: 2012-04-05 21:55:29+00:00
- **Authors**: Roland Memisevic
- **Comment**: Revised argument in sections 4 and 3.3. Added illustration of
  subspaces (Figure 13). Added inference Equation (Eq. 17)
- **Journal**: None
- **Summary**: A fundamental operation in many vision tasks, including motion understanding, stereopsis, visual odometry, or invariant recognition, is establishing correspondences between images or between images and data from other modalities. We present an analysis of the role that multiplicative interactions play in learning such correspondences, and we show how learning and inferring relationships between images can be viewed as detecting rotations in the eigenspaces shared among a set of orthogonal matrices. We review a variety of recent multiplicative sparse coding methods in light of this observation. We also review how the squaring operation performed by energy models and by models of complex cells can be thought of as a way to implement multiplicative interactions. This suggests that the main utility of including complex cells in computational models of vision may be that they can encode relations not invariances.



