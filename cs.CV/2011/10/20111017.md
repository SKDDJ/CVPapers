# Arxiv Papers in cs.CV on 2011-10-17
### Algorithms to automatically quantify the geometric similarity of anatomical surfaces
- **Arxiv ID**: http://arxiv.org/abs/1110.3649v3
- **DOI**: 10.1073/pnas.1112822108
- **Categories**: **math.NA**, cs.CV, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1110.3649v3)
- **Published**: 2011-10-17 12:23:30+00:00
- **Updated**: 2012-03-15 13:36:16+00:00
- **Authors**: D. Boyer, Y. Lipman, E. St. Clair, J. Puente, T. Funkhouser, B. Patel, J. Jernvall, I. Daubechies
- **Comment**: Changes with respect to v1, v2: an Erratum was added, correcting the
  references for one of the three datasets. Note that the datasets and code for
  this paper can be obtained from the Data Conservancy (see Download column on
  v1, v2)
- **Journal**: PNAS 2011 108 (45) 18221-18226
- **Summary**: We describe new approaches for distances between pairs of 2-dimensional surfaces (embedded in 3-dimensional space) that use local structures and global information contained in inter-structure geometric relationships. We present algorithms to automatically determine these distances as well as geometric correspondences. This is motivated by the aspiration of students of natural science to understand the continuity of form that unites the diversity of life. At present, scientists using physical traits to study evolutionary relationships among living and extinct animals analyze data extracted from carefully defined anatomical correspondence points (landmarks). Identifying and recording these landmarks is time consuming and can be done accurately only by trained morphologists. This renders these studies inaccessible to non-morphologists, and causes phenomics to lag behind genomics in elucidating evolutionary patterns. Unlike other algorithms presented for morphological correspondences our approach does not require any preliminary marking of special features or landmarks by the user. It also differs from other seminal work in computational geometry in that our algorithms are polynomial in nature and thus faster, making pairwise comparisons feasible for significantly larger numbers of digitized surfaces. We illustrate our approach using three datasets representing teeth and different bones of primates and humans, and show that it leads to highly accurate results.



### Multi-criteria Anomaly Detection using Pareto Depth Analysis
- **Arxiv ID**: http://arxiv.org/abs/1110.3741v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.DB, stat.ML, I.5; G.3; H.2.8
- **Links**: [PDF](http://arxiv.org/pdf/1110.3741v3)
- **Published**: 2011-10-17 17:48:22+00:00
- **Updated**: 2013-01-07 17:18:42+00:00
- **Authors**: Ko-Jen Hsiao, Kevin S. Xu, Jeff Calder, Alfred O. Hero III
- **Comment**: Removed an unnecessary line from Algorithm 1
- **Journal**: Advances in Neural Information Processing Systems 25 (2012)
  854-862
- **Summary**: We consider the problem of identifying patterns in a data set that exhibit anomalous behavior, often referred to as anomaly detection. In most anomaly detection algorithms, the dissimilarity between data samples is calculated by a single criterion, such as Euclidean distance. However, in many cases there may not exist a single dissimilarity measure that captures all possible anomalous patterns. In such a case, multiple criteria can be defined, and one can test for anomalies by scalarizing the multiple criteria using a linear combination of them. If the importance of the different criteria are not known in advance, the algorithm may need to be executed multiple times with different choices of weights in the linear combination. In this paper, we introduce a novel non-parametric multi-criteria anomaly detection method using Pareto depth analysis (PDA). PDA uses the concept of Pareto optimality to detect anomalies under multiple criteria without having to run an algorithm multiple times with different choices of weights. The proposed PDA approach scales linearly in the number of criteria and is provably better than linear combinations of the criteria.



### Anti-sparse coding for approximate nearest neighbor search
- **Arxiv ID**: http://arxiv.org/abs/1110.3767v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.DB, cs.IR, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1110.3767v2)
- **Published**: 2011-10-17 19:16:16+00:00
- **Updated**: 2011-10-25 06:13:45+00:00
- **Authors**: Hervé Jégou, Teddy Furon, Jean-Jacques Fuchs
- **Comment**: submitted to ICASSP'2012; RR-7771 (2011)
- **Journal**: None
- **Summary**: This paper proposes a binarization scheme for vectors of high dimension based on the recent concept of anti-sparse coding, and shows its excellent performance for approximate nearest neighbor search. Unlike other binarization schemes, this framework allows, up to a scaling factor, the explicit reconstruction from the binary representation of the original vector. The paper also shows that random projections which are used in Locality Sensitive Hashing algorithms, are significantly outperformed by regular frames for both synthetic and real data if the number of bits exceeds the vector dimensionality, i.e., when high precision is required.



