# Arxiv Papers in cs.CV on 2011-10-14
### Robust Image Analysis by L1-Norm Semi-supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1110.3109v2
- **DOI**: 10.1109/TIP.2014.2375641
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1110.3109v2)
- **Published**: 2011-10-14 02:05:14+00:00
- **Updated**: 2013-01-10 23:22:48+00:00
- **Authors**: Zhiwu Lu, Yuxin Peng
- **Comment**: This is an extension of our long paper in ACM MM 2012
- **Journal**: IEEE Trans. Image Processing 24(1): 176-188 (2015)
- **Summary**: This paper presents a novel L1-norm semi-supervised learning algorithm for robust image analysis by giving new L1-norm formulation of Laplacian regularization which is the key step of graph-based semi-supervised learning. Since our L1-norm Laplacian regularization is defined directly over the eigenvectors of the normalized Laplacian matrix, we successfully formulate semi-supervised learning as an L1-norm linear reconstruction problem which can be effectively solved with sparse coding. By working with only a small subset of eigenvectors, we further develop a fast sparse coding algorithm for our L1-norm semi-supervised learning. Due to the sparsity induced by sparse coding, the proposed algorithm can deal with the noise in the data to some extent and thus has important applications to robust image analysis, such as noise-robust image classification and noise reduction for visual and textual bag-of-words (BOW) models. In particular, this paper is the first attempt to obtain robust image representation by sparse co-refinement of visual and textual BOW models. The experimental results have shown the promising performance of the proposed algorithm.



### Controlled Total Variation regularization for inverse problems
- **Arxiv ID**: http://arxiv.org/abs/1110.3194v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1110.3194v1)
- **Published**: 2011-10-14 13:02:36+00:00
- **Updated**: 2011-10-14 13:02:36+00:00
- **Authors**: Qiyu Jin, Ion Grama, Quansheng Liu
- **Comment**: 10 pages, 10 figures and 2 tables
- **Journal**: None
- **Summary**: This paper provides a new algorithm for solving inverse problems, based on the minimization of the $L^2$ norm and on the control of the Total Variation. It consists in relaxing the role of the Total Variation in the classical Total Variation minimization approach, which permits us to get better approximation to the inverse problems. The numerical results on the deconvolution problem show that our method outperforms some previous ones.



