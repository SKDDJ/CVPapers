# Arxiv Papers in cs.CV on 2011-10-10
### Steps Towards a Theory of Visual Information: Active Perception, Signal-to-Symbol Conversion and the Interplay Between Sensing and Control
- **Arxiv ID**: http://arxiv.org/abs/1110.2053v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1110.2053v4)
- **Published**: 2011-10-10 14:28:41+00:00
- **Updated**: 2017-12-27 07:04:07+00:00
- **Authors**: Stefano Soatto
- **Comment**: 151 pages; preliminary version TR UCLA-CSD100028 of September 13,
  20010
- **Journal**: None
- **Summary**: This manuscript describes the elements of a theory of information tailored to control and decision tasks and specifically to visual data. The concept of Actionable Information is described, that relates to a notion of information championed by J. Gibson, and a notion of "complete information" that relates to the minimal sufficient statistics of a complete representation. It is shown that the "actionable information gap" between the two can be reduced by exercising control on the sensing process. Thus, senging, control and information are inextricably tied. This has consequences in the so-called "signal-to-symbol barrier" problem, as well as in the analysis and design of active sensing systems. It has ramifications in vision-based control, navigation, 3-D reconstruction and rendering, as well as detection, localization, recognition and categorization of objects and scenes in live video.   This manuscript has been developed from a set of lecture notes for a summer course at the First International Computer Vision Summer School (ICVSS) in Scicli, Italy, in July of 2008. They were later expanded and amended for subsequent lectures in the same School in July 2009. Starting on November 1, 2009, they were further expanded for a special topics course, CS269, taught at UCLA in the Spring term of 2010.



### Closed-Loop Learning of Visual Control Policies
- **Arxiv ID**: http://arxiv.org/abs/1110.2210v1
- **DOI**: 10.1613/jair.2110
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1110.2210v1)
- **Published**: 2011-10-10 21:56:36+00:00
- **Updated**: 2011-10-10 21:56:36+00:00
- **Authors**: S. R. Jodogne, J. H. Piater
- **Comment**: None
- **Journal**: Journal Of Artificial Intelligence Research, Volume 28, pages
  349-391, 2007
- **Summary**: In this paper we present a general, flexible framework for learning mappings from images to actions by interacting with the environment. The basic idea is to introduce a feature-based image classifier in front of a reinforcement learning algorithm. The classifier partitions the visual space according to the presence or absence of few highly informative local descriptors that are incrementally selected in a sequence of attempts to remove perceptual aliasing. We also address the problem of fighting overfitting in such a greedy algorithm. Finally, we show how high-level visual features can be generated when the power of local descriptors is insufficient for completely disambiguating the aliased states. This is done by building a hierarchy of composite features that consist of recursive spatial combinations of visual features. We demonstrate the efficacy of our algorithms by solving three visual navigation tasks and a visual version of the classical Car on the Hill control problem.



