# Arxiv Papers in cs.CV on 2011-07-25
### Efficient and Accurate Gaussian Image Filtering Using Running Sums
- **Arxiv ID**: http://arxiv.org/abs/1107.4958v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1107.4958v1)
- **Published**: 2011-07-25 14:20:34+00:00
- **Updated**: 2011-07-25 14:20:34+00:00
- **Authors**: Elhanan Elboher, Michael Werman
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a simple and efficient method to convolve an image with a Gaussian kernel. The computation is performed in a constant number of operations per pixel using running sums along the image rows and columns. We investigate the error function used for kernel approximation and its relation to the properties of the input signal. Based on natural image statistics we propose a quadratic form kernel error function so that the output image l2 error is minimized. We apply the proposed approach to approximate the Gaussian kernel by linear combination of constant functions. This results in very efficient Gaussian filtering method. Our experiments show that the proposed technique is faster than state of the art methods while preserving a similar accuracy.



### Variational Gaussian Process Dynamical Systems
- **Arxiv ID**: http://arxiv.org/abs/1107.4985v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, math.PR, 60G15 (Primary), 62-09, 58E30, G.3; G.1.2; I.2.6; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1107.4985v1)
- **Published**: 2011-07-25 15:54:05+00:00
- **Updated**: 2011-07-25 15:54:05+00:00
- **Authors**: Andreas C. Damianou, Michalis K. Titsias, Neil D. Lawrence
- **Comment**: 16 pages, 19 figures
- **Journal**: None
- **Summary**: High dimensional time series are endemic in applications of machine learning such as robotics (sensor data), computational biology (gene expression data), vision (video sequences) and graphics (motion capture data). Practical nonlinear probabilistic approaches to this data are required. In this paper we introduce the variational Gaussian process dynamical system. Our work builds on recent variational approximations for Gaussian process latent variable models to allow for nonlinear dimensionality reduction simultaneously with learning a dynamical prior in the latent space. The approach also allows for the appropriate dimensionality of the latent space to be automatically determined. We demonstrate the model on a human motion capture data set and a series of high resolution video sequences.



### An iterative feature selection method for GRNs inference by exploring topological properties
- **Arxiv ID**: http://arxiv.org/abs/1107.5000v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.IT, math.IT, q-bio.MN
- **Links**: [PDF](http://arxiv.org/pdf/1107.5000v1)
- **Published**: 2011-07-25 17:04:33+00:00
- **Updated**: 2011-07-25 17:04:33+00:00
- **Authors**: Fabr√≠cio Martins Lopes, David C. Martins-Jr, Junior Barrera, Roberto M. Cesar-Jr
- **Comment**: 10 pages, 5 figures, SFFS search method based on scale-free network
  topology
- **Journal**: None
- **Summary**: An important problem in bioinformatics is the inference of gene regulatory networks (GRN) from temporal expression profiles. In general, the main limitations faced by GRN inference methods is the small number of samples with huge dimensionalities and the noisy nature of the expression measurements. In face of these limitations, alternatives are needed to get better accuracy on the GRNs inference problem. This work addresses this problem by presenting an alternative feature selection method that applies prior knowledge on its search strategy, called SFFS-BA. The proposed search strategy is based on the Sequential Floating Forward Selection (SFFS) algorithm, with the inclusion of a scale-free (Barab\'asi-Albert) topology information in order to guide the search process to improve inference. The proposed algorithm explores the scale-free property by pruning the search space and using a power law as a weight for reducing it. In this way, the search space traversed by the SFFS-BA method combines a breadth-first search when the number of combinations is small (<k> <= 2) with a depth-first search when the number of combinations becomes explosive (<k> >= 3), being guided by the scale-free prior information. Experimental results show that the SFFS-BA provides a better inference similarities than SFS and SFFS, keeping the robustness of the SFS and SFFS methods, thus presenting very good results.



