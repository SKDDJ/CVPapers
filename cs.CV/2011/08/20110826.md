# Arxiv Papers in cs.CV on 2011-08-26
### Solving Principal Component Pursuit in Linear Time via $l_1$ Filtering
- **Arxiv ID**: http://arxiv.org/abs/1108.5359v4
- **DOI**: None
- **Categories**: **cs.NA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1108.5359v4)
- **Published**: 2011-08-26 17:40:30+00:00
- **Updated**: 2012-05-06 06:16:32+00:00
- **Authors**: Risheng Liu, Zhouchen Lin, Siming Wei, Zhixun Su
- **Comment**: None
- **Journal**: None
- **Summary**: In the past decades, exactly recovering the intrinsic data structure from corrupted observations, which is known as robust principal component analysis (RPCA), has attracted tremendous interests and found many applications in computer vision. Recently, this problem has been formulated as recovering a low-rank component and a sparse component from the observed data matrix. It is proved that under some suitable conditions, this problem can be exactly solved by principal component pursuit (PCP), i.e., minimizing a combination of nuclear norm and $l_1$ norm. Most of the existing methods for solving PCP require singular value decompositions (SVD) of the data matrix, resulting in a high computational complexity, hence preventing the applications of RPCA to very large scale computer vision problems. In this paper, we propose a novel algorithm, called $l_1$ filtering, for \emph{exactly} solving PCP with an $O(r^2(m+n))$ complexity, where $m\times n$ is the size of data matrix and $r$ is the rank of the matrix to recover, which is supposed to be much smaller than $m$ and $n$. Moreover, $l_1$ filtering is \emph{highly parallelizable}. It is the first algorithm that can \emph{exactly} solve a nuclear norm minimization problem in \emph{linear time} (with respect to the data size). Experiments on both synthetic data and real applications testify to the great advantage of $l_1$ filtering in speed over state-of-the-art algorithms.



### Noise Covariance Properties in Dual-Tree Wavelet Decompositions
- **Arxiv ID**: http://arxiv.org/abs/1108.5395v1
- **DOI**: 10.1109/TIT.2007.909104
- **Categories**: **math.ST**, cs.CV, stat.TH
- **Links**: [PDF](http://arxiv.org/pdf/1108.5395v1)
- **Published**: 2011-08-26 21:06:56+00:00
- **Updated**: 2011-08-26 21:06:56+00:00
- **Authors**: Caroline Chaux, Jean-Christophe Pesquet, Laurent Duval
- **Comment**: None
- **Journal**: IEEE Transactions on Information Theory, December 2007, Volume 53,
  Issue 12, p. 2397 - 2412
- **Summary**: Dual-tree wavelet decompositions have recently gained much popularity, mainly due to their ability to provide an accurate directional analysis of images combined with a reduced redundancy. When the decomposition of a random process is performed -- which occurs in particular when an additive noise is corrupting the signal to be analyzed -- it is useful to characterize the statistical properties of the dual-tree wavelet coefficients of this process. As dual-tree decompositions constitute overcomplete frame expansions, correlation structures are introduced among the coefficients, even when a white noise is analyzed. In this paper, we show that it is possible to provide an accurate description of the covariance properties of the dual-tree coefficients of a wide-sense stationary process. The expressions of the (cross-)covariance sequences of the coefficients are derived in the one and two-dimensional cases. Asymptotic results are also provided, allowing to predict the behaviour of the second-order moments for large lag values or at coarse resolution. In addition, the cross-correlations between the primal and dual wavelets, which play a primary role in our theoretical analysis, are calculated for a number of classical wavelet families. Simulation results are finally provided to validate these results.



