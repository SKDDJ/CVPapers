# Arxiv Papers in cs.CV on 2011-02-04
### Natural images from the birthplace of the human eye
- **Arxiv ID**: http://arxiv.org/abs/1102.0817v1
- **DOI**: 10.1371/journal.pone.0020409
- **Categories**: **q-bio.NC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1102.0817v1)
- **Published**: 2011-02-04 00:27:48+00:00
- **Updated**: 2011-02-04 00:27:48+00:00
- **Authors**: Gašper Tkačik, Patrick Garrigan, Charles Ratliff, Grega Milčinski, Jennifer M Klein, Lucia H Seyfarth, Peter Sterling, David Brainard, Vijay Balasubramanian
- **Comment**: Submitted to PLoS ONE
- **Journal**: PLoS ONE 6: e20409 (2011)
- **Summary**: Here we introduce a database of calibrated natural images publicly available through an easy-to-use web interface. Using a Nikon D70 digital SLR camera, we acquired about 5000 six-megapixel images of Okavango Delta of Botswana, a tropical savanna habitat similar to where the human eye is thought to have evolved. Some sequences of images were captured unsystematically while following a baboon troop, while others were designed to vary a single parameter such as aperture, object distance, time of day or position on the horizon. Images are available in the raw RGB format and in grayscale. Images are also available in units relevant to the physiology of human cone photoreceptors, where pixel values represent the expected number of photoisomerizations per second for cones sensitive to long (L), medium (M) and short (S) wavelengths. This database is distributed under a Creative Commons Attribution-Noncommercial Unported license to facilitate research in computer vision, psychophysics of perception, and visual neuroscience.



### Evidence Feed Forward Hidden Markov Model: A New Type of Hidden Markov Model
- **Arxiv ID**: http://arxiv.org/abs/1102.0899v1
- **DOI**: 10.5121/ijaia.2011.2101
- **Categories**: **cs.AI**, cs.CV, cs.LG, math.NA, math.PR, 60J20, 61E40, 65C50, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1102.0899v1)
- **Published**: 2011-02-04 13:00:06+00:00
- **Updated**: 2011-02-04 13:00:06+00:00
- **Authors**: Michael DelRose, Christian Wagner, Philip Frederick
- **Comment**: 19 pages, International Journal of Artificial Intelligence and
  Applications
- **Journal**: International Journal of Artificial Intelligence and Applications
  (IJAIA), Vol. 2, No. 1, Jan 2011
- **Summary**: The ability to predict the intentions of people based solely on their visual actions is a skill only performed by humans and animals. The intelligence of current computer algorithms has not reached this level of complexity, but there are several research efforts that are working towards it. With the number of classification algorithms available, it is hard to determine which algorithm works best for a particular situation. In classification of visual human intent data, Hidden Markov Models (HMM), and their variants, are leading candidates.   The inability of HMMs to provide a probability in the observation to observation linkages is a big downfall in this classification technique. If a person is visually identifying an action of another person, they monitor patterns in the observations. By estimating the next observation, people have the ability to summarize the actions, and thus determine, with pretty good accuracy, the intention of the person performing the action. These visual cues and linkages are important in creating intelligent algorithms for determining human actions based on visual observations.   The Evidence Feed Forward Hidden Markov Model is a newly developed algorithm which provides observation to observation linkages. The following research addresses the theory behind Evidence Feed Forward HMMs, provides mathematical proofs of their learning of these parameters to optimize the likelihood of observations with a Evidence Feed Forwards HMM, which is important in all computational intelligence algorithm, and gives comparative examples with standard HMMs in classification of both visual action data and measurement data; thus providing a strong base for Evidence Feed Forward HMMs in classification of many types of problems.



