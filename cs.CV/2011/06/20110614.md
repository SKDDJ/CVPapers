# Arxiv Papers in cs.CV on 2011-06-14
### Robust Mobile Object Tracking Based on Multiple Feature Similarity and Trajectory Filtering
- **Arxiv ID**: http://arxiv.org/abs/1106.2695v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1106.2695v1)
- **Published**: 2011-06-14 12:45:05+00:00
- **Updated**: 2011-06-14 12:45:05+00:00
- **Authors**: Duc Phu Chau, François Bremond, Monique Thonnat, Etienne Corvee
- **Comment**: None
- **Journal**: The International Conference on Computer Vision Theory and
  Applications (VISAPP) (2011)
- **Summary**: This paper presents a new algorithm to track mobile objects in different scene conditions. The main idea of the proposed tracker includes estimation, multi-features similarity measures and trajectory filtering. A feature set (distance, area, shape ratio, color histogram) is defined for each tracked object to search for the best matching object. Its best matching object and its state estimated by the Kalman filter are combined to update position and size of the tracked object. However, the mobile object trajectories are usually fragmented because of occlusions and misdetections. Therefore, we also propose a trajectory filtering, named global tracker, aims at removing the noisy trajectories and fusing the fragmented trajectories belonging to a same mobile object. The method has been tested with five videos of different scene conditions. Three of them are provided by the ETISEO benchmarking project (http://www-sop.inria.fr/orion/ETISEO) in which the proposed tracker performance has been compared with other seven tracking algorithms. The advantages of our approach over the existing state of the art ones are: (i) no prior knowledge information is required (e.g. no calibration and no contextual models are needed), (ii) the tracker is more reliable by combining multiple feature similarities, (iii) the tracker can perform in different scene conditions: single/several mobile objects, weak/strong illumination, indoor/outdoor scenes, (iv) a trajectory filtering is defined and applied to improve the tracker performance, (v) the tracker performance outperforms many algorithms of the state of the art.



### Who clicks there!: Anonymizing the photographer in a camera saturated society
- **Arxiv ID**: http://arxiv.org/abs/1106.2696v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1106.2696v1)
- **Published**: 2011-06-14 12:49:48+00:00
- **Updated**: 2011-06-14 12:49:48+00:00
- **Authors**: Peter Schaffer, Djamila Aouada, Shishir Nagaraja
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, social media has played an increasingly important role in reporting world events. The publication of crowd-sourced photographs and videos in near real-time is one of the reasons behind the high impact. However, the use of a camera can draw the photographer into a situation of conflict. Examples include the use of cameras by regulators collecting evidence of Mafia operations; citizens collecting evidence of corruption at a public service outlet; and political dissidents protesting at public rallies. In all these cases, the published images contain fairly unambiguous clues about the location of the photographer (scene viewpoint information). In the presence of adversary operated cameras, it can be easy to identify the photographer by also combining leaked information from the photographs themselves. We call this the camera location detection attack. We propose and review defense techniques against such attacks. Defenses such as image obfuscation techniques do not protect camera-location information; current anonymous publication technologies do not help either. However, the use of view synthesis algorithms could be a promising step in the direction of providing probabilistic privacy guarantees.



### Nested Graph Words for Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1106.2729v2
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1106.2729v2)
- **Published**: 2011-06-14 14:43:02+00:00
- **Updated**: 2014-04-23 08:34:24+00:00
- **Authors**: Svebor Karaman, Jenny Benois-Pineau, Rémi Mégret
- **Comment**: Preliminary version of accepted paper "Multi-Layer Local Graph Words
  for Object Recognition". Leaving only final version to avoid confusion
- **Journal**: None
- **Summary**: In this paper, we propose a new, scalable approach for the task of object based image search or object recognition. Despite the very large literature existing on the scalability issues in CBIR in the sense of retrieval approaches, the scalability of media and scalability of features remain an issue. In our work we tackle the problem of scalability and structural organization of features. The proposed features are nested local graphs built upon sets of SURF feature points with Delaunay triangulation. A Bag-of-Visual-Words (BoVW) framework is applied on these graphs, giving birth to a Bag-of-Graph-Words representation. The nested nature of the descriptors consists in scaling from trivial Delaunay graphs - isolated feature points - by increasing the number of nodes layer by layer up to graphs with maximal number of nodes. For each layer of graphs its proper visual dictionary is built. The experiments conducted on the SIVAL data set reveal that the graph features at different layers exhibit complementary performances on the same content. The nested approach, the combination of all existing layers, yields significant improvement of the object recognition performance compared to single level approaches.



