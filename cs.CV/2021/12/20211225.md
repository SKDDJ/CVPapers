# Arxiv Papers in cs.CV on 2021-12-25
### Semantic Clustering based Deduction Learning for Image Recognition and Classification
- **Arxiv ID**: http://arxiv.org/abs/2112.13165v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2112.13165v1)
- **Published**: 2021-12-25 01:31:21+00:00
- **Updated**: 2021-12-25 01:31:21+00:00
- **Authors**: Wenchi Ma, Xuemin Tu, Bo Luo, Guanghui Wang
- **Comment**: None
- **Journal**: Pattern Recognition 2021
- **Summary**: The paper proposes a semantic clustering based deduction learning by mimicking the learning and thinking process of human brains. Human beings can make judgments based on experience and cognition, and as a result, no one would recognize an unknown animal as a car. Inspired by this observation, we propose to train deep learning models using the clustering prior that can guide the models to learn with the ability of semantic deducing and summarizing from classification attributes, such as a cat belonging to animals while a car pertaining to vehicles. %Specifically, if an image is labeled as a cat, then the model is trained to learn that "this image is totally not any random class that is the outlier of animal". The proposed approach realizes the high-level clustering in the semantic space, enabling the model to deduce the relations among various classes during the learning process. In addition, the paper introduces a semantic prior based random search for the opposite labels to ensure the smooth distribution of the clustering and the robustness of the classifiers. The proposed approach is supported theoretically and empirically through extensive experiments. We compare the performance across state-of-the-art classifiers on popular benchmarks, and the generalization ability is verified by adding noisy labeling to the datasets. Experimental results demonstrate the superiority of the proposed approach.



### DSRGAN: Detail Prior-Assisted Perceptual Single Image Super-Resolution via Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2112.13191v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2112.13191v1)
- **Published**: 2021-12-25 06:23:52+00:00
- **Updated**: 2021-12-25 06:23:52+00:00
- **Authors**: Ziyang Liu, Zhengguo Li, Xingming Wu, Zhong Liu, Weihai Chen
- **Comment**: None
- **Journal**: None
- **Summary**: The generative adversarial network (GAN) is successfully applied to study the perceptual single image superresolution (SISR). However, the GAN often tends to generate images with high frequency details being inconsistent with the real ones. Inspired by conventional detail enhancement algorithms, we propose a novel prior knowledge, the detail prior, to assist the GAN in alleviating this problem and restoring more realistic details. The proposed method, named DSRGAN, includes a well designed detail extraction algorithm to capture the most important high frequency information from images. Then, two discriminators are utilized for supervision on image-domain and detail-domain restorations, respectively. The DSRGAN merges the restored detail into the final output via a detail enhancement manner. The special design of DSRGAN takes advantages from both the model-based conventional algorithm and the data-driven deep learning network. Experimental results demonstrate that the DSRGAN outperforms the state-of-the-art SISR methods on perceptual metrics and achieves comparable results in terms of fidelity metrics simultaneously. Following the DSRGAN, it is feasible to incorporate other conventional image processing algorithms into a deep learning network to form a model-based deep SISR.



### Network-Aware 5G Edge Computing for Object Detection: Augmenting Wearables to "See" More, Farther and Faster
- **Arxiv ID**: http://arxiv.org/abs/2112.13194v2
- **DOI**: 10.1109/ACCESS.2022.3157876
- **Categories**: **eess.IV**, cs.CV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2112.13194v2)
- **Published**: 2021-12-25 07:09:00+00:00
- **Updated**: 2022-04-15 04:05:22+00:00
- **Authors**: Zhongzheng Yuan, Tommy Azzino, Yu Hao, Yixuan Lyu, Haoyang Pei, Alain Boldini, Marco Mezzavilla, Mahya Beheshti, Maurizio Porfiri, Todd Hudson, William Seiple, Yi Fang, Sundeep Rangan, Yao Wang, J. R. Rizzo
- **Comment**: Published in: IEEE Access ( Volume: 10)
- **Journal**: None
- **Summary**: Advanced wearable devices are increasingly incorporating high-resolution multi-camera systems. As state-of-the-art neural networks for processing the resulting image data are computationally demanding, there has been growing interest in leveraging fifth generation (5G) wireless connectivity and mobile edge computing for offloading this processing to the cloud. To assess this possibility, this paper presents a detailed simulation and evaluation of 5G wireless offloading for object detection within a powerful, new smart wearable called VIS4ION, for the Blind-and-Visually Impaired (BVI). The current VIS4ION system is an instrumented book-bag with high-resolution cameras, vision processing and haptic and audio feedback. The paper considers uploading the camera data to a mobile edge cloud to perform real-time object detection and transmitting the detection results back to the wearable. To determine the video requirements, the paper evaluates the impact of video bit rate and resolution on object detection accuracy and range. A new street scene dataset with labeled objects relevant to BVI navigation is leveraged for analysis. The vision evaluation is combined with a detailed full-stack wireless network simulation to determine the distribution of throughputs and delays with real navigation paths and ray-tracing from new high-resolution 3D models in an urban environment. For comparison, the wireless simulation considers both a standard 4G-Long Term Evolution (LTE) carrier and high-rate 5G millimeter-wave (mmWave) carrier. The work thus provides a thorough and realistic assessment of edge computing with mmWave connectivity in an application with both high bandwidth and low latency requirements.



### Pseudocylindrical Convolutions for Learned Omnidirectional Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2112.13227v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2112.13227v1)
- **Published**: 2021-12-25 12:18:32+00:00
- **Updated**: 2021-12-25 12:18:32+00:00
- **Authors**: Mu Li, Kede Ma, Jinxing Li, David Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Although equirectangular projection (ERP) is a convenient form to store omnidirectional images (also known as 360-degree images), it is neither equal-area nor conformal, thus not friendly to subsequent visual communication. In the context of image compression, ERP will over-sample and deform things and stuff near the poles, making it difficult for perceptually optimal bit allocation. In conventional 360-degree image compression, techniques such as region-wise packing and tiled representation are introduced to alleviate the over-sampling problem, achieving limited success. In this paper, we make one of the first attempts to learn deep neural networks for omnidirectional image compression. We first describe parametric pseudocylindrical representation as a generalization of common pseudocylindrical map projections. A computationally tractable greedy method is presented to determine the (sub)-optimal configuration of the pseudocylindrical representation in terms of a novel proxy objective for rate-distortion performance. We then propose pseudocylindrical convolutions for 360-degree image compression. Under reasonable constraints on the parametric representation, the pseudocylindrical convolution can be efficiently implemented by standard convolution with the so-called pseudocylindrical padding. To demonstrate the feasibility of our idea, we implement an end-to-end 360-degree image compression system, consisting of the learned pseudocylindrical representation, an analysis transform, a non-uniform quantizer, a synthesis transform, and an entropy model. Experimental results on $19,790$ omnidirectional images show that our method achieves consistently better rate-distortion performance than the competing methods. Moreover, the visual quality by our method is significantly improved for all images at all bitrates.



### Evolutionary Generation of Visual Motion Illusions
- **Arxiv ID**: http://arxiv.org/abs/2112.13243v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2112.13243v1)
- **Published**: 2021-12-25 14:53:50+00:00
- **Updated**: 2021-12-25 14:53:50+00:00
- **Authors**: Lana Sinapayen, Eiji Watanabe
- **Comment**: None
- **Journal**: None
- **Summary**: Why do we sometimes perceive static images as if they were moving? Visual motion illusions enjoy a sustained popularity, yet there is no definitive answer to the question of why they work. We present a generative model, the Evolutionary Illusion GENerator (EIGen), that creates new visual motion illusions. The structure of EIGen supports the hypothesis that illusory motion might be the result of perceiving the brain's own predictions rather than perceiving raw visual input from the eyes. The scientific motivation of this paper is to demonstrate that the perception of illusory motion could be a side effect of the predictive abilities of the brain. The philosophical motivation of this paper is to call attention to the untapped potential of "motivated failures", ways for artificial systems to fail as biological systems fail, as a worthy outlet for Artificial Intelligence and Artificial Life research.



### Artifact Reduction in Fundus Imaging using Cycle Consistent Adversarial Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2112.13264v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2112.13264v1)
- **Published**: 2021-12-25 18:05:48+00:00
- **Updated**: 2021-12-25 18:05:48+00:00
- **Authors**: Sai Koushik S S, K. G. Srinivasa
- **Comment**: 12 pages, 13 figures, draft paper
- **Journal**: None
- **Summary**: Fundus images are very useful in identifying various ophthalmic disorders. However, due to the presence of artifacts, the visibility of the retina is severely affected. This may result in misdiagnosis of the disorder which may lead to more complicated problems. Since deep learning is a powerful tool to extract patterns from data without much human intervention, they can be applied to image-to-image translation problems. An attempt has been made in this paper to automatically rectify such artifacts present in the images of the fundus. We use a CycleGAN based model which consists of residual blocks to reduce the artifacts in the images. Significant improvements are seen when compared to the existing techniques.



