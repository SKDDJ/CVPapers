# Arxiv Papers in cs.CV on 2021-12-26
### Unsupervised Clustering Active Learning for Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/2112.13308v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2112.13308v1)
- **Published**: 2021-12-26 02:54:35+00:00
- **Updated**: 2021-12-26 02:54:35+00:00
- **Authors**: Wenjing Gao, Minxian Li
- **Comment**: This work was submitted to BMVC2021
- **Journal**: None
- **Summary**: Supervised person re-identification (re-id) approaches require a large amount of pairwise manual labeled data, which is not applicable in most real-world scenarios for re-id deployment. On the other hand, unsupervised re-id methods rely on unlabeled data to train models but performs poorly compared with supervised re-id methods. In this work, we aim to combine unsupervised re-id learning with a small number of human annotations to achieve a competitive performance. Towards this goal, we present a Unsupervised Clustering Active Learning (UCAL) re-id deep learning approach. It is capable of incrementally discovering the representative centroid-pairs and requiring human annotate them. These few labeled representative pairwise data can improve the unsupervised representation learning model with other large amounts of unlabeled data. More importantly, because the representative centroid-pairs are selected for annotation, UCAL can work with very low-cost human effort. Extensive experiments demonstrate the superiority of the proposed model over state-of-the-art active learning methods on three re-id benchmark datasets.



### Learning Cross-Scale Weighted Prediction for Efficient Neural Video Compression
- **Arxiv ID**: http://arxiv.org/abs/2112.13309v2
- **DOI**: 10.1109/TIP.2023.3287495
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2112.13309v2)
- **Published**: 2021-12-26 03:12:17+00:00
- **Updated**: 2023-03-15 15:48:47+00:00
- **Authors**: Zongyu Guo, Runsen Feng, Zhizheng Zhang, Xin Jin, Zhibo Chen
- **Comment**: Preprint. Revised after peer-reviewimg
- **Journal**: None
- **Summary**: Neural video codecs have demonstrated great potential in video transmission and storage applications. Existing neural hybrid video coding approaches rely on optical flow or Gaussian-scale flow for prediction, which cannot support fine-grained adaptation to diverse motion content. Towards more content-adaptive prediction, we propose a novel cross-scale prediction module that achieves more effective motion compensation. Specifically, on the one hand, we produce a reference feature pyramid as prediction sources and then transmit cross-scale flows that leverage the feature scale to control the precision of prediction. On the other hand, for the first time, a weighted prediction mechanism is introduced even if only a single reference frame is available, which can help synthesize a fine prediction result by transmitting cross-scale weight maps. In addition to the cross-scale prediction module, we further propose a multi-stage quantization strategy, which improves the rate-distortion performance with no extra computational penalty during inference. We show the encouraging performance of our efficient neural video codec (ENVC) on several benchmark datasets. In particular, the proposed ENVC can compete with the latest coding standard H.266/VVC in terms of sRGB PSNR on UVG dataset for the low-latency mode. We also analyze in detail the effectiveness of the cross-scale prediction module in handling various video content, and provide a comprehensive ablation study to analyze those important components. Test code is available at https://github.com/USTC-IMCL/ENVC .



### Miti-DETR: Object Detection based on Transformers with Mitigatory Self-Attention Convergence
- **Arxiv ID**: http://arxiv.org/abs/2112.13310v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2112.13310v1)
- **Published**: 2021-12-26 03:23:59+00:00
- **Updated**: 2021-12-26 03:23:59+00:00
- **Authors**: Wenchi Ma, Tianxiao Zhang, Guanghui Wang
- **Comment**: None
- **Journal**: AAAI 2022 workshop
- **Summary**: Object Detection with Transformers (DETR) and related works reach or even surpass the highly-optimized Faster-RCNN baseline with self-attention network architectures. Inspired by the evidence that pure self-attention possesses a strong inductive bias that leads to the transformer losing the expressive power with respect to network depth, we propose a transformer architecture with a mitigatory self-attention mechanism by applying possible direct mapping connections in the transformer architecture to mitigate the rank collapse so as to counteract feature expression loss and enhance the model performance. We apply this proposal in object detection tasks and develop a model named Miti-DETR. Miti-DETR reserves the inputs of each single attention layer to the outputs of that layer so that the "non-attention" information has participated in any attention propagation. The formed residual self-attention network addresses two critical issues: (1) stop the self-attention networks from degenerating to rank-1 to the maximized degree; and (2) further diversify the path distribution of parameter update so that easier attention learning is expected. Miti-DETR significantly enhances the average detection precision and convergence speed towards existing DETR-based models on the challenging COCO object detection dataset. Moreover, the proposed transformer with the residual self-attention network can be easily generalized or plugged in other related task models without specific customization.



### Continuous Offline Handwriting Recognition using Deep Learning Models
- **Arxiv ID**: http://arxiv.org/abs/2112.13328v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T45, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2112.13328v1)
- **Published**: 2021-12-26 07:31:03+00:00
- **Updated**: 2021-12-26 07:31:03+00:00
- **Authors**: Jorge Sueiras
- **Comment**: 186 pages, 83 figures, thesis
- **Journal**: None
- **Summary**: Handwritten text recognition is an open problem of great interest in the area of automatic document image analysis. The transcription of handwritten content present in digitized documents is significant in analyzing historical archives or digitizing information from handwritten documents, forms, and communications. In the last years, great advances have been made in this area due to applying deep learning techniques to its resolution. This Thesis addresses the offline continuous handwritten text recognition (HTR) problem, consisting of developing algorithms and models capable of transcribing the text present in an image without the need for the text to be segmented into characters. For this purpose, we have proposed a new recognition model based on integrating two types of deep learning architectures: convolutional neural networks (CNN) and sequence-to-sequence (seq2seq) models, respectively. The convolutional component of the model is oriented to identify relevant features present in characters, and the seq2seq component builds the transcription of the text by modeling the sequential nature of the text. For the design of this new model, an extensive analysis of the capabilities of different convolutional architectures in the simplified problem of isolated character recognition has been carried out in order to identify the most suitable ones to be integrated into the continuous model. Additionally, extensive experimentation of the proposed model for the continuous problem has been carried out to determine its robustness to changes in parameterization. The generalization capacity of the model has also been validated by evaluating it on three handwritten text databases using different languages: IAM in English, RIMES in French, and Osborne in Spanish, respectively. The new proposed model provides competitive results with those obtained with other well-established methodologies.



### Quasi-Taylor Samplers for Diffusion Generative Models based on Ideal Derivatives
- **Arxiv ID**: http://arxiv.org/abs/2112.13339v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.SD, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2112.13339v2)
- **Published**: 2021-12-26 09:38:11+00:00
- **Updated**: 2022-10-11 08:28:48+00:00
- **Authors**: Hideyuki Tachibana, Mocho Go, Muneyoshi Inahara, Yotaro Katayama, Yotaro Watanabe
- **Comment**: Major update from 2112.13339v1. 47 pages, 24 figures
- **Journal**: None
- **Summary**: Diffusion generative models have emerged as a new challenger to popular deep neural generative models such as GANs, but have the drawback that they often require a huge number of neural function evaluations (NFEs) during synthesis unless some sophisticated sampling strategies are employed. This paper proposes new efficient samplers based on the numerical schemes derived by the familiar Taylor expansion, which directly solves the ODE/SDE of interest. In general, it is not easy to compute the derivatives that are required in higher-order Taylor schemes, but in the case of diffusion models, this difficulty is alleviated by the trick that the authors call ``ideal derivative substitution,'' in which the higher-order derivatives are replaced by tractable ones. To derive ideal derivatives, the authors argue the ``single point approximation,'' in which the true score function is approximated by a conditional one, holds in many cases, and considered the derivatives of this approximation. Applying thus obtained new quasi-Taylor samplers to image generation tasks, the authors experimentally confirmed that the proposed samplers could synthesize plausible images in small number of NFEs, and that the performance was better or at the same level as DDIM and Runge-Kutta methods. The paper also argues the relevance of the proposed samplers to the existing ones mentioned above.



### AlertTrap: A study on object detection in remote insects trap monitoring system using on-the-edge deep learning platform
- **Arxiv ID**: http://arxiv.org/abs/2112.13341v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2112.13341v2)
- **Published**: 2021-12-26 09:44:48+00:00
- **Updated**: 2022-03-04 14:18:34+00:00
- **Authors**: An D. Le, Duy A. Pham, Dong T. Pham, Hien B. Vo
- **Comment**: None
- **Journal**: None
- **Summary**: Fruit flies are one of the most harmful insect species to fruit yields. In AlertTrap, implementation of SSD architecture with different state-of-the-art backbone feature extractors such as MobileNetV1 and MobileNetV2 appear to be potential solutions for the real-time detection problem. SSD-MobileNetV1 and SSD-MobileNetV2 perform well and result in AP@0.5 of 0.957 and 1.0 respectively. YOLOv4-tiny outperforms the SSD family with 1.0 in AP@0.5; however, its throughput velocity is slightly slower.



### Delivery Issues Identification from Customer Feedback Data
- **Arxiv ID**: http://arxiv.org/abs/2112.13372v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV, I.2.1; I.2.7; I.4.9
- **Links**: [PDF](http://arxiv.org/pdf/2112.13372v1)
- **Published**: 2021-12-26 12:41:10+00:00
- **Updated**: 2021-12-26 12:41:10+00:00
- **Authors**: Ankush Chopra, Mahima Arora, Shubham Pandey
- **Comment**: Accepted to be part of MLDS 2022, and will be Published in Lattice
  journal
- **Journal**: None
- **Summary**: Millions of packages are delivered successfully by online and local retail stores across the world every day. The proper delivery of packages is needed to ensure high customer satisfaction and repeat purchases. These deliveries suffer various problems despite the best efforts from the stores. These issues happen not only due to the large volume and high demand for low turnaround time but also due to mechanical operations and natural factors. These issues range from receiving wrong items in the package to delayed shipment to damaged packages because of mishandling during transportation. Finding solutions to various delivery issues faced by both sending and receiving parties plays a vital role in increasing the efficiency of the entire process. This paper shows how to find these issues using customer feedback from the text comments and uploaded images. We used transfer learning for both Text and Image models to minimize the demand for thousands of labeled examples. The results show that the model can find different issues. Furthermore, it can also be used for tasks like bottleneck identification, process improvement, automating refunds, etc. Compared with the existing process, the ensemble of text and image models proposed in this paper ensures the identification of several types of delivery issues, which is more suitable for the real-life scenarios of delivery of items in retail businesses. This method can supply a new idea of issue detection for the delivery of packages in similar industries.



### Sinogram upsampling using Primal-Dual UNet for undersampled CT and radial MRI reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2112.13443v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2112.13443v2)
- **Published**: 2021-12-26 19:31:34+00:00
- **Updated**: 2023-03-01 21:02:26+00:00
- **Authors**: Philipp Ernst, Soumick Chatterjee, Georg Rose, Oliver Speck, Andreas Nürnberger
- **Comment**: None
- **Journal**: None
- **Summary**: Computed tomography and magnetic resonance imaging are two widely used clinical imaging modalities for non-invasive diagnosis. However, both of these modalities come with certain problems. CT uses harmful ionising radiation, and MRI suffers from slow acquisition speed. Both problems can be tackled by undersampling, such as sparse sampling. However, such undersampled data leads to lower resolution and introduces artefacts. Several techniques, including deep learning based methods, have been proposed to reconstruct such data. However, the undersampled reconstruction problem for these two modalities was always considered as two different problems and tackled separately by different research works. This paper proposes a unified solution for both sparse CT and undersampled radial MRI reconstruction, achieved by applying Fourier transform-based pre-processing on the radial MRI and then finally reconstructing both modalities using sinogram upsampling combined with filtered back-projection. The Primal-Dual network is a deep learning based method for reconstructing sparsely-sampled CT data. This paper introduces Primal-Dual UNet, which improves the Primal-Dual network in terms of accuracy and reconstruction speed. The proposed method resulted in an average SSIM of 0.932\textpm0.021 while performing sparse CT reconstruction for fan-beam geometry with a sparsity level of 16, achieving a statistically significant improvement over the previous model, which resulted in 0.919\textpm0.016. Furthermore, the proposed model resulted in 0.903\textpm0.019 and 0.957\textpm0.023 average SSIM while reconstructing undersampled brain and abdominal MRI data with an acceleration factor of 16, respectively - statistically significant improvements over the original model, which resulted in 0.867\textpm0.025 and 0.949\textpm0.025.



### PreDisM: Pre-Disaster Modelling With CNN Ensembles for At-Risk Communities
- **Arxiv ID**: http://arxiv.org/abs/2112.13465v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/2112.13465v1)
- **Published**: 2021-12-26 23:48:23+00:00
- **Updated**: 2021-12-26 23:48:23+00:00
- **Authors**: Vishal Anand, Yuki Miura
- **Comment**: None
- **Journal**: NeurIPS 2021 Workshop on Tackling Climate Change with Machine
  Learning
- **Summary**: The machine learning community has recently had increased interest in the climate and disaster damage domain due to a marked increased occurrences of natural hazards (e.g., hurricanes, forest fires, floods, earthquakes). However, not enough attention has been devoted to mitigating probable destruction from impending natural hazards. We explore this crucial space by predicting building-level damages on a before-the-fact basis that would allow state actors and non-governmental organizations to be best equipped with resource distribution to minimize or preempt losses. We introduce PreDisM that employs an ensemble of ResNets and fully connected layers over decision trees to capture image-level and meta-level information to accurately estimate weakness of man-made structures to disaster-occurrences. Our model performs well and is responsive to tuning across types of disasters and highlights the space of preemptive hazard damage modelling.



