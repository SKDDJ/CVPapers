# Arxiv Papers in cs.CV on 2021-11-27
### Benchmarking Shadow Removal for Facial Landmark Detection and Beyond
- **Arxiv ID**: http://arxiv.org/abs/2111.13790v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13790v1)
- **Published**: 2021-11-27 01:34:40+00:00
- **Updated**: 2021-11-27 01:34:40+00:00
- **Authors**: Lan Fu, Qing Guo, Felix Juefei-Xu, Hongkai Yu, Wei Feng, Yang Liu, Song Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Facial landmark detection is a very fundamental and significant vision task with many important applications. In practice, facial landmark detection can be affected by a lot of natural degradations. One of the most common and important degradations is the shadow caused by light source blocking. While many advanced shadow removal methods have been proposed to recover the image quality in recent years, their effects to facial landmark detection are not well studied. For example, it remains unclear whether shadow removal could enhance the robustness of facial landmark detection to diverse shadow patterns or not. In this work, for the first attempt, we construct a novel benchmark to link two independent but related tasks (i.e., shadow removal and facial landmark detection). In particular, the proposed benchmark covers diverse face shadows with different intensities, sizes, shapes, and locations. Moreover, to mine hard shadow patterns against facial landmark detection, we propose a novel method (i.e., adversarial shadow attack), which allows us to construct a challenging subset of the benchmark for a comprehensive analysis. With the constructed benchmark, we conduct extensive analysis on three state-of-the-art shadow removal methods and three landmark detectors. The observation of this work motivates us to design a novel detection-aware shadow removal framework, which empowers shadow removal to achieve higher restoration quality and enhance the shadow robustness of deployed facial landmark detectors.



### LAFITE: Towards Language-Free Training for Text-to-Image Generation
- **Arxiv ID**: http://arxiv.org/abs/2111.13792v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2111.13792v3)
- **Published**: 2021-11-27 01:54:45+00:00
- **Updated**: 2022-03-24 04:14:56+00:00
- **Authors**: Yufan Zhou, Ruiyi Zhang, Changyou Chen, Chunyuan Li, Chris Tensmeyer, Tong Yu, Jiuxiang Gu, Jinhui Xu, Tong Sun
- **Comment**: Accepted by CVPR 2022, https://github.com/drboog/Lafite
- **Journal**: None
- **Summary**: One of the major challenges in training text-to-image generation models is the need of a large number of high-quality image-text pairs. While image samples are often easily accessible, the associated text descriptions typically require careful human captioning, which is particularly time- and cost-consuming. In this paper, we propose the first work to train text-to-image generation models without any text data. Our method leverages the well-aligned multi-modal semantic space of the powerful pre-trained CLIP model: the requirement of text-conditioning is seamlessly alleviated via generating text features from image features. Extensive experiments are conducted to illustrate the effectiveness of the proposed method. We obtain state-of-the-art results in the standard text-to-image generation tasks. Importantly, the proposed language-free model outperforms most existing models trained with full image-text pairs. Furthermore, our method can be applied in fine-tuning pre-trained models, which saves both training time and cost in training text-to-image generation models. Our pre-trained model obtains competitive results in zero-shot text-to-image generation on the MS-COCO dataset, yet with around only 1% of the model size and training data size relative to the recently proposed large DALL-E model.



### Learning to Transfer for Traffic Forecasting via Multi-task Learning
- **Arxiv ID**: http://arxiv.org/abs/2111.15542v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2111.15542v1)
- **Published**: 2021-11-27 03:16:40+00:00
- **Updated**: 2021-11-27 03:16:40+00:00
- **Authors**: Yichao Lu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have demonstrated superior performance in short-term traffic forecasting. However, most existing traffic forecasting systems assume that the training and testing data are drawn from the same underlying distribution, which limits their practical applicability. The NeurIPS 2021 Traffic4cast challenge is the first of its kind dedicated to benchmarking the robustness of traffic forecasting models towards domain shifts in space and time. This technical report describes our solution to this challenge. In particular, we present a multi-task learning framework for temporal and spatio-temporal domain adaptation of traffic forecasting models. Experimental results demonstrate that our multi-task learning approach achieves strong empirical performance, outperforming a number of baseline domain adaptation methods, while remaining highly efficient. The source code for this technical report is available at https://github.com/YichaoLu/Traffic4cast2021.



### Document Layout Analysis with Aesthetic-Guided Image Augmentation
- **Arxiv ID**: http://arxiv.org/abs/2111.13809v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13809v1)
- **Published**: 2021-11-27 04:04:58+00:00
- **Updated**: 2021-11-27 04:04:58+00:00
- **Authors**: Tianlong Ma, Xingjiao Wu, Xin Li, Xiangcheng Du, Zhao Zhou, Liang Xue, Cheng Jin
- **Comment**: None
- **Journal**: None
- **Summary**: Document layout analysis (DLA) plays an important role in information extraction and document understanding. At present, document layout analysis has reached a milestone achievement, however, document layout analysis of non-Manhattan is still a challenge. In this paper, we propose an image layer modeling method to tackle this challenge. To measure the proposed image layer modeling method, we propose a manually-labeled non-Manhattan layout fine-grained segmentation dataset named FPD. As far as we know, FPD is the first manually-labeled non-Manhattan layout fine-grained segmentation dataset. To effectively extract fine-grained features of documents, we propose an edge embedding network named L-E^3Net. Experimental results prove that our proposed image layer modeling method can better deal with the fine-grained segmented document of the non-Manhattan layout.



### Video Content Classification using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2111.13813v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2111.13813v1)
- **Published**: 2021-11-27 04:36:17+00:00
- **Updated**: 2021-11-27 04:36:17+00:00
- **Authors**: Pradyumn Patil, Vishwajeet Pawar, Yashraj Pawar, Shruti Pisal
- **Comment**: for assosiated Dataset check :-
  https://github.com/coin-dataset/annotations
- **Journal**: None
- **Summary**: Video content classification is an important research content in computer vision, which is widely used in many fields, such as image and video retrieval, computer vision. This paper presents a model that is a combination of Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) which develops, trains, and optimizes a deep learning network that can identify the type of video content and classify them into categories such as "Animation, Gaming, natural content, flat content, etc". To enhance the performance of the model novel keyframe extraction method is included to classify only the keyframes, thereby reducing the overall processing time without sacrificing any significant performance.



### Video Frame Interpolation Transformer
- **Arxiv ID**: http://arxiv.org/abs/2111.13817v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13817v3)
- **Published**: 2021-11-27 05:35:10+00:00
- **Updated**: 2022-03-28 17:46:04+00:00
- **Authors**: Zhihao Shi, Xiangyu Xu, Xiaohong Liu, Jun Chen, Ming-Hsuan Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Existing methods for video interpolation heavily rely on deep convolution neural networks, and thus suffer from their intrinsic limitations, such as content-agnostic kernel weights and restricted receptive field. To address these issues, we propose a Transformer-based video interpolation framework that allows content-aware aggregation weights and considers long-range dependencies with the self-attention operations. To avoid the high computational cost of global self-attention, we introduce the concept of local attention into video interpolation and extend it to the spatial-temporal domain. Furthermore, we propose a space-time separation strategy to save memory usage, which also improves performance. In addition, we develop a multi-scale frame synthesis scheme to fully realize the potential of Transformers. Extensive experiments demonstrate the proposed model performs favorably against the state-of-the-art methods both quantitatively and qualitatively on a variety of benchmark datasets.



### Recognition and Co-Analysis of Pedestrian Activities in Different Parts of Road using Traffic Camera Video
- **Arxiv ID**: http://arxiv.org/abs/2111.13818v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13818v1)
- **Published**: 2021-11-27 05:46:41+00:00
- **Updated**: 2021-11-27 05:46:41+00:00
- **Authors**: Weijia Xu, Heidi Ross, Joel Meyer, Kelly Pierce, Natalia Ruiz Juri, Jennifer Duthie
- **Comment**: None
- **Journal**: None
- **Summary**: Pedestrian safety is a priority for transportation system managers and operators, and a main focus of the Vision Zero strategy employed by the City of Austin, Texas. While there are a number of treatments and technologies to effectively improve pedestrian safety, identifying the location where these treatments are most needed remains a challenge. Current practice requires manual observation of candidate locations for limited time periods, leading to an identification process that is time consuming, lags behind traffic pattern changes over time, and lacks scalability. Mid-block locations, where safety countermeasures are often needed the most, are especially hard to identify and monitor. The goal for this research is to understand the correlation between bus stop locations and mid-block crossings, so as to assist traffic engineers in implementing Vision Zero strategies to improve pedestrian safety. In a prior work, we have developed a tool to detect pedestrian crossing events with traffic camera video using a deep neural network model to identify crossing events. In this paper, we extend the methods to identify bus stop usage with traffic camera video from off-the-shelf CCTV pan-tilt-zoom (PTZ) traffic monitoring cameras installed at nearby intersections. We correlate the video detection results for mid-block crossings near a bus stop, with pedestrian activity at the bus stops in each side of the mid-block crossing. We also implement a web portal to facilitate manual review of pedestrian activity detections by automating creation of video clips that show only crossing events, thereby vastly improving the efficiency of the human review process.



### Recovery of Continuous 3D Refractive Index Maps from Discrete Intensity-Only Measurements using Neural Fields
- **Arxiv ID**: http://arxiv.org/abs/2112.00002v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2112.00002v2)
- **Published**: 2021-11-27 06:05:47+00:00
- **Updated**: 2022-08-15 02:12:21+00:00
- **Authors**: Renhao Liu, Yu Sun, Jiabei Zhu, Lei Tian, Ulugbek Kamilov
- **Comment**: None
- **Journal**: None
- **Summary**: Intensity diffraction tomography (IDT) refers to a class of optical microscopy techniques for imaging the 3D refractive index (RI) distribution of a sample from a set of 2D intensity-only measurements. The reconstruction of artifact-free RI maps is a fundamental challenge in IDT due to the loss of phase information and the missing cone problem. Neural fields (NF) has recently emerged as a new deep learning (DL) approach for learning continuous representations of physical fields. NF uses a coordinate-based neural network to represent the field by mapping the spatial coordinates to the corresponding physical quantities, in our case the complex-valued refractive index values. We present DeCAF as the first NF-based IDT method that can learn a high-quality continuous representation of a RI volume from its intensity-only and limited-angle measurements. The representation in DeCAF is learned directly from the measurements of the test sample by using the IDT forward model, without any ground-truth RI maps. We qualitatively and quantitatively evaluate DeCAF on the simulated and experimental biological samples. Our results show that DeCAF can generate high-contrast and artifact-free RI maps and lead to up to 2.1 times reduction in MSE over existing methods.



### FQ-ViT: Post-Training Quantization for Fully Quantized Vision Transformer
- **Arxiv ID**: http://arxiv.org/abs/2111.13824v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13824v4)
- **Published**: 2021-11-27 06:20:53+00:00
- **Updated**: 2023-02-17 13:17:52+00:00
- **Authors**: Yang Lin, Tianyu Zhang, Peiqin Sun, Zheng Li, Shuchang Zhou
- **Comment**: Accepted by IJCAI 2022
- **Journal**: None
- **Summary**: Network quantization significantly reduces model inference complexity and has been widely used in real-world deployments. However, most existing quantization methods have been developed mainly on Convolutional Neural Networks (CNNs), and suffer severe degradation when applied to fully quantized vision transformers. In this work, we demonstrate that many of these difficulties arise because of serious inter-channel variation in LayerNorm inputs, and present, Power-of-Two Factor (PTF), a systematic method to reduce the performance degradation and inference complexity of fully quantized vision transformers. In addition, observing an extreme non-uniform distribution in attention maps, we propose Log-Int-Softmax (LIS) to sustain that and simplify inference by using 4-bit quantization and the BitShift operator. Comprehensive experiments on various transformer-based architectures and benchmarks show that our Fully Quantized Vision Transformer (FQ-ViT) outperforms previous works while even using lower bit-width on attention maps. For instance, we reach 84.89% top-1 accuracy with ViT-L on ImageNet and 50.8 mAP with Cascade Mask R-CNN (Swin-S) on COCO. To our knowledge, we are the first to achieve lossless accuracy degradation (~1%) on fully quantized vision transformers. The code is available at https://github.com/megvii-research/FQ-ViT.



### Average Outward Flux Skeletons for Environment Mapping and Topology Matching
- **Arxiv ID**: http://arxiv.org/abs/2111.13826v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2111.13826v1)
- **Published**: 2021-11-27 06:29:57+00:00
- **Updated**: 2021-11-27 06:29:57+00:00
- **Authors**: Morteza Rezanejad, Babak Samari, Elham Karimi, Ioannis Rekleitis, Gregory Dudek, Kaleem Siddiqi
- **Comment**: None
- **Journal**: None
- **Summary**: We consider how to directly extract a road map (also known as a topological representation) of an initially-unknown 2-dimensional environment via an online procedure that robustly computes a retraction of its boundaries. In this article, we first present the online construction of a topological map and the implementation of a control law for guiding the robot to the nearest unexplored area, first presented in [1]. The proposed method operates by allowing the robot to localize itself on a partially constructed map, calculate a path to unexplored parts of the environment (frontiers), compute a robust terminating condition when the robot has fully explored the environment, and achieve loop closure detection. The proposed algorithm results in smooth safe paths for the robot's navigation needs. The presented approach is any time algorithm that has the advantage that it allows for the active creation of topological maps from laser scan data, as it is being acquired. We also propose a navigation strategy based on a heuristic where the robot is directed towards nodes in the topological map that open to empty space. We then extend the work in [1] by presenting a topology matching algorithm that leverages the strengths of a particular spectral correspondence method [2], to match the mapped environments generated from our topology-making algorithm. Here, we concentrated on implementing a system that could be used to match the topologies of the mapped environment by using AOF Skeletons. In topology matching between two given maps and their AOF skeletons, we first find correspondences between points on the AOF skeletons of two different environments. We then align the (2D) points of the environments themselves. We also compute a distance measure between two given environments, based on their extracted AOF skeletons and their topology, as the sum of the matching errors between corresponding points.



### DSC: Deep Scan Context Descriptor for Large-Scale Place Recognition
- **Arxiv ID**: http://arxiv.org/abs/2111.13838v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2111.13838v1)
- **Published**: 2021-11-27 07:31:32+00:00
- **Updated**: 2021-11-27 07:31:32+00:00
- **Authors**: Jiafeng Cui, Tengfei Huang, Yingfeng Cai, Junqiao Zhao, Lu Xiong, Zhuoping Yu
- **Comment**: None
- **Journal**: None
- **Summary**: LiDAR-based place recognition is an essential and challenging task both in loop closure detection and global relocalization. We propose Deep Scan Context (DSC), a general and discriminative global descriptor that captures the relationship among segments of a point cloud. Unlike previous methods that utilize either semantics or a sequence of adjacent point clouds for better place recognition, we only use raw point clouds to get competitive results. Concretely, we first segment the point cloud egocentrically to acquire centroids and eigenvalues of the segments. Then, we introduce a graph neural network to aggregate these features into an embedding representation. Extensive experiments conducted on the KITTI dataset show that DSC is robust to scene variants and outperforms existing methods.



### Towards Principled Disentanglement for Domain Generalization
- **Arxiv ID**: http://arxiv.org/abs/2111.13839v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2111.13839v4)
- **Published**: 2021-11-27 07:36:32+00:00
- **Updated**: 2022-10-19 04:26:12+00:00
- **Authors**: Hanlin Zhang, Yi-Fan Zhang, Weiyang Liu, Adrian Weller, Bernhard Schölkopf, Eric P. Xing
- **Comment**: CVPR 2022 Oral
- **Journal**: None
- **Summary**: A fundamental challenge for machine learning models is generalizing to out-of-distribution (OOD) data, in part due to spurious correlations. To tackle this challenge, we first formalize the OOD generalization problem as constrained optimization, called Disentanglement-constrained Domain Generalization (DDG). We relax this non-trivial constrained optimization problem to a tractable form with finite-dimensional parameterization and empirical approximation. Then a theoretical analysis of the extent to which the above transformations deviates from the original problem is provided. Based on the transformation, we propose a primal-dual algorithm for joint representation disentanglement and domain generalization. In contrast to traditional approaches based on domain adversarial training and domain labels, DDG jointly learns semantic and variation encoders for disentanglement, enabling flexible manipulation and augmentation on training data. DDG aims to learn intrinsic representations of semantic concepts that are invariant to nuisance factors and generalizable across domains. Comprehensive experiments on popular benchmarks show that DDG can achieve competitive OOD performance and uncover interpretable salient structures within data.



### Adaptive Perturbation for Adversarial Attack
- **Arxiv ID**: http://arxiv.org/abs/2111.13841v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13841v2)
- **Published**: 2021-11-27 07:57:41+00:00
- **Updated**: 2023-01-02 13:04:00+00:00
- **Authors**: Zheng Yuan, Jie Zhang, Zhaoyan Jiang, Liangliang Li, Shiguang Shan
- **Comment**: 13 pages, 5 figures, 9 tables
- **Journal**: None
- **Summary**: In recent years, the security of deep learning models achieves more and more attentions with the rapid development of neural networks, which are vulnerable to adversarial examples. Almost all existing gradient-based attack methods use the sign function in the generation to meet the requirement of perturbation budget on $L_\infty$ norm. However, we find that the sign function may be improper for generating adversarial examples since it modifies the exact gradient direction. Instead of using the sign function, we propose to directly utilize the exact gradient direction with a scaling factor for generating adversarial perturbations, which improves the attack success rates of adversarial examples even with fewer perturbations. At the same time, we also theoretically prove that this method can achieve better black-box transferability. Moreover, considering that the best scaling factor varies across different images, we propose an adaptive scaling factor generator to seek an appropriate scaling factor for each image, which avoids the computational cost for manually searching the scaling factor. Our method can be integrated with almost all existing gradient-based attack methods to further improve their attack success rates. Extensive experiments on the CIFAR10 and ImageNet datasets show that our method exhibits higher transferability and outperforms the state-of-the-art methods.



### Adaptive Image Transformations for Transfer-based Adversarial Attack
- **Arxiv ID**: http://arxiv.org/abs/2111.13844v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13844v4)
- **Published**: 2021-11-27 08:15:44+00:00
- **Updated**: 2022-09-28 08:09:20+00:00
- **Authors**: Zheng Yuan, Jie Zhang, Shiguang Shan
- **Comment**: 34 pages, 7 figures, 11 tables. Accepted by ECCV2022
- **Journal**: None
- **Summary**: Adversarial attacks provide a good way to study the robustness of deep learning models. One category of methods in transfer-based black-box attack utilizes several image transformation operations to improve the transferability of adversarial examples, which is effective, but fails to take the specific characteristic of the input image into consideration. In this work, we propose a novel architecture, called Adaptive Image Transformation Learner (AITL), which incorporates different image transformation operations into a unified framework to further improve the transferability of adversarial examples. Unlike the fixed combinational transformations used in existing works, our elaborately designed transformation learner adaptively selects the most effective combination of image transformations specific to the input image. Extensive experiments on ImageNet demonstrate that our method significantly improves the attack success rates on both normally trained models and defense models under various settings.



### Temporal Context Mining for Learned Video Compression
- **Arxiv ID**: http://arxiv.org/abs/2111.13850v2
- **DOI**: 10.1109/TMM.2022.3220421
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2111.13850v2)
- **Published**: 2021-11-27 08:55:16+00:00
- **Updated**: 2023-01-30 08:28:09+00:00
- **Authors**: Xihua Sheng, Jiahao Li, Bin Li, Li Li, Dong Liu, Yan Lu
- **Comment**: None
- **Journal**: None
- **Summary**: We address end-to-end learned video compression with a special focus on better learning and utilizing temporal contexts. For temporal context mining, we propose to store not only the previously reconstructed frames, but also the propagated features into the generalized decoded picture buffer. From the stored propagated features, we propose to learn multi-scale temporal contexts, and re-fill the learned temporal contexts into the modules of our compression scheme, including the contextual encoder-decoder, the frame generator, and the temporal context encoder. Our scheme discards the parallelization-unfriendly auto-regressive entropy model to pursue a more practical decoding time. We compare our scheme with x264 and x265 (representing industrial software for H.264 and H.265, respectively) as well as the official reference software for H.264, H.265, and H.266 (JM, HM, and VTM, respectively). When intra period is 32 and oriented to PSNR, our scheme outperforms H.265--HM by 14.4% bit rate saving; when oriented to MS-SSIM, our scheme outperforms H.266--VTM by 21.1% bit rate saving.



### Learning Discriminative Shrinkage Deep Networks for Image Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/2111.13876v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13876v3)
- **Published**: 2021-11-27 12:12:57+00:00
- **Updated**: 2022-07-20 06:40:27+00:00
- **Authors**: Pin-Hung Kuo, Jinshan Pan, Shao-Yi Chien, Ming-Hsuan Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Most existing methods usually formulate the non-blind deconvolution problem into a maximum-a-posteriori framework and address it by manually designing kinds of regularization terms and data terms of the latent clear images. However, explicitly designing these two terms is quite challenging and usually leads to complex optimization problems which are difficult to solve. In this paper, we propose an effective non-blind deconvolution approach by learning discriminative shrinkage functions to implicitly model these terms. In contrast to most existing methods that use deep convolutional neural networks (CNNs) or radial basis functions to simply learn the regularization term, we formulate both the data term and regularization term and split the deconvolution model into data-related and regularization-related sub-problems according to the alternating direction method of multipliers. We explore the properties of the Maxout function and develop a deep CNN model with a Maxout layer to learn discriminative shrinkage functions to directly approximate the solutions of these two sub-problems. Moreover, given the fast-Fourier-transform-based image restoration usually leads to ringing artifacts while conjugate-gradient-based approach is time-consuming, we develop the Conjugate Gradient Network to restore the latent clear images effectively and efficiently. Experimental results show that the proposed method performs favorably against the state-of-the-art ones in terms of efficiency and accuracy.



### Head and Body: Unified Detector and Graph Network for Person Search in Media
- **Arxiv ID**: http://arxiv.org/abs/2111.13888v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13888v1)
- **Published**: 2021-11-27 13:09:18+00:00
- **Updated**: 2021-11-27 13:09:18+00:00
- **Authors**: Xiujun Shu, Yusheng Tao, Ruizhi Qiao, Bo Ke, Wei Wen, Bo Ren
- **Comment**: None
- **Journal**: None
- **Summary**: Person search in media has seen increasing potential in Internet applications, such as video clipping and character collection. This task is common but overlooked by previous person search works which focus on surveillance scenes. The media scenarios have some different challenges from surveillance scenes. For example, a person may change his clothes frequently. To alleviate this issue, this paper proposes a Unified Detector and Graph Network (UDGNet) for person search in media. UDGNet is the first person search framework to detect and re-identify the human body and head simultaneously. Specifically, it first builds two branches based on a unified network to detect the human body and head, then the detected body and head are used for re-identification. This dual-task approach can significantly enhance discriminative learning. To tackle the cloth-changing issue, UDGNet builds two graphs to explore reliable links among cloth-changing samples and utilizes a graph network to learn better embeddings. This design effectively enhances the robustness of person search to cloth-changing challenges. Besides, we demonstrate that UDGNet can be implemented with both anchor-based and anchor-free person search frameworks and further achieve performance improvement. This paper also contributes a large-scale dataset for Person Search in Media (PSM), which provides both body and head annotations. It is by far the largest dataset for person search in media. Experiments show that UDGNet improves the anchor-free model AlignPS by 12.1% in mAP. Meanwhile, it shows good generalization across surveillance and longterm scenarios. The dataset and code will be available at: https://github.com/shuxjweb/PSM.git.



### ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior
- **Arxiv ID**: http://arxiv.org/abs/2111.15362v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.15362v2)
- **Published**: 2021-11-27 13:53:25+00:00
- **Updated**: 2022-03-30 08:45:23+00:00
- **Authors**: Metin Ersin Arican, Ozgur Kara, Gustav Bredell, Ender Konukoglu
- **Comment**: None
- **Journal**: None
- **Summary**: Recent works show that convolutional neural network (CNN) architectures have a spectral bias towards lower frequencies, which has been leveraged for various image restoration tasks in the Deep Image Prior (DIP) framework. The benefit of the inductive bias the network imposes in the DIP framework depends on the architecture. Therefore, researchers have studied how to automate the search to determine the best-performing model. However, common neural architecture search (NAS) techniques are resource and time-intensive. Moreover, best-performing models are determined for a whole dataset of images instead of for each image independently, which would be prohibitively expensive. In this work, we first show that optimal neural architectures in the DIP framework are image-dependent. Leveraging this insight, we then propose an image-specific NAS strategy for the DIP framework that requires substantially less training than typical NAS approaches, effectively enabling image-specific NAS. We justify the proposed strategy's effectiveness by (1) demonstrating its performance on a NAS Dataset for DIP that includes 522 models from a particular search space (2) conducting extensive experiments on image denoising, inpainting, and super-resolution tasks. Our experiments show that image-specific metrics can reduce the search space to a small cohort of models, of which the best model outperforms current NAS approaches for image restoration. Codes and datasets are available at https://github.com/ozgurkara99/ISNAS-DIP.



### AdaDM: Enabling Normalization for Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2111.13905v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2111.13905v1)
- **Published**: 2021-11-27 14:16:11+00:00
- **Updated**: 2021-11-27 14:16:11+00:00
- **Authors**: Jie Liu, Jie Tang, Gangshan Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Normalization like Batch Normalization (BN) is a milestone technique to normalize the distributions of intermediate layers in deep learning, enabling faster training and better generalization accuracy. However, in fidelity image Super-Resolution (SR), it is believed that normalization layers get rid of range flexibility by normalizing the features and they are simply removed from modern SR networks. In this paper, we study this phenomenon quantitatively and qualitatively. We found that the standard deviation of the residual feature shrinks a lot after normalization layers, which causes the performance degradation in SR networks. Standard deviation reflects the amount of variation of pixel values. When the variation becomes smaller, the edges will become less discriminative for the network to resolve. To address this problem, we propose an Adaptive Deviation Modulator (AdaDM), in which a modulation factor is adaptively predicted to amplify the pixel deviation. For better generalization performance, we apply BN in state-of-the-art SR networks with the proposed AdaDM. Meanwhile, the deviation amplification strategy in AdaDM makes the edge information in the feature more distinguishable. As a consequence, SR networks with BN and our AdaDM can get substantial performance improvements on benchmark datasets. Extensive experiments have been conducted to show the effectiveness of our method.



### Pose Representations for Deep Skeletal Animation
- **Arxiv ID**: http://arxiv.org/abs/2111.13907v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, I.3.7; I.3
- **Links**: [PDF](http://arxiv.org/pdf/2111.13907v2)
- **Published**: 2021-11-27 14:33:24+00:00
- **Updated**: 2022-07-27 10:36:32+00:00
- **Authors**: Nefeli Andreou, Andreas Aristidou, Yiorgos Chrysanthou
- **Comment**: Presented at the ACM SIGGRAPH/Eurographics Symposium on Computer
  Animation, SCA'22
- **Journal**: Computer Graphics Forum, Volume 41, Issue 8, 2022
- **Summary**: Data-driven character animation techniques rely on the existence of a properly established model of motion, capable of describing its rich context. However, commonly used motion representations often fail to accurately encode the full articulation of motion, or present artifacts. In this work, we address the fundamental problem of finding a robust pose representation for motion modeling, suitable for deep character animation, one that can better constrain poses and faithfully capture nuances correlated with skeletal characteristics. Our representation is based on dual quaternions, the mathematical abstractions with well-defined operations, which simultaneously encode rotational and positional orientation, enabling a hierarchy-aware encoding, centered around the root. We demonstrate that our representation overcomes common motion artifacts, and assess its performance compared to other popular representations. We conduct an ablation study to evaluate the impact of various losses that can be incorporated during learning. Leveraging the fact that our representation implicitly encodes skeletal motion attributes, we train a network on a dataset comprising of skeletons with different proportions, without the need to retarget them first to a universal skeleton, which causes subtle motion elements to be missed. We show that smooth and natural poses can be achieved, paving the way for fascinating applications.



### Sparse Subspace Clustering Friendly Deep Dictionary Learning for Hyperspectral Image Classification
- **Arxiv ID**: http://arxiv.org/abs/2111.13920v1
- **DOI**: 10.1109/LGRS.2021.3112603
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2111.13920v1)
- **Published**: 2021-11-27 15:23:58+00:00
- **Updated**: 2021-11-27 15:23:58+00:00
- **Authors**: Anurag Goel, Angshul Majumdar
- **Comment**: IEEE Geoscience And Remote Sensing Letters
- **Journal**: None
- **Summary**: Subspace clustering techniques have shown promise in hyperspectral image segmentation. The fundamental assumption in subspace clustering is that the samples belonging to different clusters/segments lie in separable subspaces. What if this condition does not hold? We surmise that even if the condition does not hold in the original space, the data may be nonlinearly transformed to a space where it will be separable into subspaces. In this work, we propose a transformation based on the tenets of deep dictionary learning (DDL). In particular, we incorporate the sparse subspace clustering (SSC) loss in the DDL formulation. Here DDL nonlinearly transforms the data such that the transformed representation (of the data) is separable into subspaces. We show that the proposed formulation improves over the state-of-the-art deep learning techniques in hyperspectral image clustering.



### Learning A 3D-CNN and Transformer Prior for Hyperspectral Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2111.13923v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2111.13923v1)
- **Published**: 2021-11-27 15:38:57+00:00
- **Updated**: 2021-11-27 15:38:57+00:00
- **Authors**: Qing Ma, Junjun Jiang, Xianming Liu, Jiayi Ma
- **Comment**: 10 pages, 5 figures
- **Journal**: None
- **Summary**: To solve the ill-posed problem of hyperspectral image super-resolution (HSISR), an usually method is to use the prior information of the hyperspectral images (HSIs) as a regularization term to constrain the objective function. Model-based methods using hand-crafted priors cannot fully characterize the properties of HSIs. Learning-based methods usually use a convolutional neural network (CNN) to learn the implicit priors of HSIs. However, the learning ability of CNN is limited, it only considers the spatial characteristics of the HSIs and ignores the spectral characteristics, and convolution is not effective for long-range dependency modeling. There is still a lot of room for improvement. In this paper, we propose a novel HSISR method that uses Transformer instead of CNN to learn the prior of HSIs. Specifically, we first use the proximal gradient algorithm to solve the HSISR model, and then use an unfolding network to simulate the iterative solution processes. The self-attention layer of Transformer makes it have the ability of spatial global interaction. In addition, we add 3D-CNN behind the Transformer layers to better explore the spatio-spectral correlation of HSIs. Both quantitative and visual results on two widely used HSI datasets and the real-world dataset demonstrate that the proposed method achieves a considerable gain compared to all the mainstream algorithms including the most competitive conventional methods and the recently proposed deep learning-based methods.



### Investigating the usefulness of Quantum Blur
- **Arxiv ID**: http://arxiv.org/abs/2112.01646v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.ET, quant-ph
- **Links**: [PDF](http://arxiv.org/pdf/2112.01646v2)
- **Published**: 2021-11-27 15:40:31+00:00
- **Updated**: 2022-05-25 13:44:32+00:00
- **Authors**: James R. Wootton, Marcel Pfaffhauser
- **Comment**: None
- **Journal**: None
- **Summary**: Though some years remain before quantum computation can outperform conventional computation, it already provides resources that can be used for exploratory purposes in various fields. This includes certain tasks for procedural generation in computer games, music and art. The so-called `Quantum Blur' method represents the first step on this journey, providing a simple proof-of-principle example of how quantum software can be useful in these areas today. Here we analyse the `Quantum Blur' method and compare it to conventional blur effects. This investigation was guided by discussions with the most prominent user of the method, to determine which features were found most useful. In particular we determine how these features depend on the quantum phenomena of superposition and entanglement.



### A Practical Contrastive Learning Framework for Single-Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2111.13924v2
- **DOI**: 10.1109/TNNLS.2023.3290038
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13924v2)
- **Published**: 2021-11-27 15:42:12+00:00
- **Updated**: 2023-07-16 16:00:40+00:00
- **Authors**: Gang Wu, Junjun Jiang, Xianming Liu
- **Comment**: Accepted by IEEE Transactions on Neural Networks and Learning Systems
- **Journal**: None
- **Summary**: Contrastive learning has achieved remarkable success on various high-level tasks, but there are fewer contrastive learning-based methods proposed for low-level tasks. It is challenging to adopt vanilla contrastive learning technologies proposed for high-level visual tasks to low-level image restoration problems straightly. Because the acquired high-level global visual representations are insufficient for low-level tasks requiring rich texture and context information. In this paper, we investigate the contrastive learning-based single image super-resolution from two perspectives: positive and negative sample construction and feature embedding. The existing methods take naive sample construction approaches (e.g., considering the low-quality input as a negative sample and the ground truth as a positive sample) and adopt a prior model (e.g., pre-trained VGG model) to obtain the feature embedding. To this end, we propose a practical contrastive learning framework for SISR, named PCL-SR. We involve the generation of many informative positive and hard negative samples in frequency space. Instead of utilizing an additional pre-trained network, we design a simple but effective embedding network inherited from the discriminator network which is more task-friendly. Compared with existing benchmark methods, we re-train them by our proposed PCL-SR framework and achieve superior performance. Extensive experiments have been conducted to show the effectiveness and technical contributions of our proposed PCL-SR thorough ablation studies. The code and pre-trained models can be found at https://github.com/Aitical/PCL-SISR.



### Calibrated Feature Decomposition for Generalizable Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2111.13945v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2111.13945v1)
- **Published**: 2021-11-27 17:12:43+00:00
- **Updated**: 2021-11-27 17:12:43+00:00
- **Authors**: Kecheng Zheng, Jiawei Liu, Wei Wu, Liang Li, Zheng-jun Zha
- **Comment**: Technical report, Code: https://github.com/zkcys001/CFD
- **Journal**: None
- **Summary**: Existing disentangled-based methods for generalizable person re-identification aim at directly disentangling person representations into domain-relevant interference and identity-relevant feature. However, they ignore that some crucial characteristics are stubbornly entwined in both the domain-relevant interference and identity-relevant feature, which are intractable to decompose in an unsupervised manner. In this paper, we propose a simple yet effective Calibrated Feature Decomposition (CFD) module that focuses on improving the generalization capacity for person re-identification through a more judicious feature decomposition and reinforcement strategy. Specifically, a calibrated-and-standardized Batch normalization (CSBN) is designed to learn calibrated person representation by jointly exploring intra-domain calibration and inter-domain standardization of multi-source domain features. CSBN restricts instance-level inconsistency of feature distribution for each domain and captures intrinsic domain-level specific statistics. The calibrated person representation is subtly decomposed into the identity-relevant feature, domain feature, and the remaining entangled one. For enhancing the generalization ability and ensuring high discrimination of the identity-relevant feature, a calibrated instance normalization (CIN) is introduced to enforce discriminative id-relevant information, and filter out id-irrelevant information, and meanwhile the rich complementary clues from the remaining entangled feature are further employed to strengthen it. Extensive experiments demonstrate the strong generalization capability of our framework. Our models empowered by CFD modules significantly outperform the state-of-the-art domain generalization approaches on multiple widely-used benchmarks. Code will be made public: https://github.com/zkcys001/CFD.



### Safe Screening for Sparse Conditional Random Fields
- **Arxiv ID**: http://arxiv.org/abs/2111.13958v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2111.13958v1)
- **Published**: 2021-11-27 18:38:57+00:00
- **Updated**: 2021-11-27 18:38:57+00:00
- **Authors**: Weizhong Zhang, Shuang Qiu
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse Conditional Random Field (CRF) is a powerful technique in computer vision and natural language processing for structured prediction. However, solving sparse CRFs in large-scale applications remains challenging. In this paper, we propose a novel safe dynamic screening method that exploits an accurate dual optimum estimation to identify and remove the irrelevant features during the training process. Thus, the problem size can be reduced continuously, leading to great savings in the computational cost without sacrificing any accuracy on the finally learned model. To the best of our knowledge, this is the first screening method which introduces the dual optimum estimation technique -- by carefully exploring and exploiting the strong convexity and the complex structure of the dual problem -- in static screening methods to dynamic screening. In this way, we can absorb the advantages of both the static and dynamic screening methods and avoid their drawbacks. Our estimation would be much more accurate than those developed based on the duality gap, which contributes to a much stronger screening rule. Moreover, our method is also the first screening method in sparse CRFs and even structure prediction models. Experimental results on both synthetic and real-world datasets demonstrate that the speedup gained by our method is significant.



### Label Assistant: A Workflow for Assisted Data Annotation in Image Segmentation Tasks
- **Arxiv ID**: http://arxiv.org/abs/2111.13970v1
- **DOI**: 10.5445/KSP/1000138532
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2111.13970v1)
- **Published**: 2021-11-27 19:08:25+00:00
- **Updated**: 2021-11-27 19:08:25+00:00
- **Authors**: Marcel P. Schilling, Luca Rettenberger, Friedrich Münke, Haijun Cui, Anna A. Popova, Pavel A. Levkin, Ralf Mikut, Markus Reischl
- **Comment**: None
- **Journal**: Proceedings - 31. Workshop Computational Intelligence, 2021
- **Summary**: Recent research in the field of computer vision strongly focuses on deep learning architectures to tackle image processing problems. Deep neural networks are often considered in complex image processing scenarios since traditional computer vision approaches are expensive to develop or reach their limits due to complex relations. However, a common criticism is the need for large annotated datasets to determine robust parameters. Annotating images by human experts is time-consuming, burdensome, and expensive. Thus, support is needed to simplify annotation, increase user efficiency, and annotation quality. In this paper, we propose a generic workflow to assist the annotation process and discuss methods on an abstract level. Thereby, we review the possibilities of focusing on promising samples, image pre-processing, pre-labeling, label inspection, or post-processing of annotations. In addition, we present an implementation of the proposal by means of a developed flexible and extendable software prototype nested in hybrid touchscreen/laptop device.



### NCVX: A User-Friendly and Scalable Package for Nonconvex Optimization in Machine Learning
- **Arxiv ID**: http://arxiv.org/abs/2111.13984v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.MS, eess.SP, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/2111.13984v2)
- **Published**: 2021-11-27 21:02:20+00:00
- **Updated**: 2022-01-01 18:32:07+00:00
- **Authors**: Buyun Liang, Tim Mitchell, Ju Sun
- **Comment**: NCVX is available at https://ncvx.org
- **Journal**: None
- **Summary**: Optimizing nonconvex (NCVX) problems, especially nonsmooth and constrained ones, is an essential part of machine learning. However, it can be hard to reliably solve such problems without optimization expertise. Existing general-purpose NCVX optimization packages are powerful but typically cannot handle nonsmoothness. GRANSO is among the first optimization solvers targeting general nonsmooth NCVX problems with nonsmooth constraints, but, as it is implemented in MATLAB and requires the user to provide analytical gradients, GRANSO is often not a convenient choice in machine learning (especially deep learning) applications. To greatly lower the technical barrier, we introduce a new software package called NCVX, whose initial release contains the solver PyGRANSO, a PyTorch-enabled port of GRANSO incorporating auto-differentiation, GPU acceleration, tensor input, and support for new QP solvers. NCVX is built on freely available and widely used open-source frameworks, and as a highlight, can solve general constrained deep learning problems, the first of its kind. NCVX is available at https://ncvx.org, with detailed documentation and numerous examples from machine learning and other fields.



### Learning Continuous Environment Fields via Implicit Functions
- **Arxiv ID**: http://arxiv.org/abs/2111.13997v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13997v1)
- **Published**: 2021-11-27 22:36:58+00:00
- **Updated**: 2021-11-27 22:36:58+00:00
- **Authors**: Xueting Li, Shalini De Mello, Xiaolong Wang, Ming-Hsuan Yang, Jan Kautz, Sifei Liu
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel scene representation that encodes reaching distance -- the distance between any position in the scene to a goal along a feasible trajectory. We demonstrate that this environment field representation can directly guide the dynamic behaviors of agents in 2D mazes or 3D indoor scenes. Our environment field is a continuous representation and learned via a neural implicit function using discretely sampled training data. We showcase its application for agent navigation in 2D mazes, and human trajectory prediction in 3D indoor environments. To produce physically plausible and natural trajectories for humans, we additionally learn a generative model that predicts regions where humans commonly appear, and enforce the environment field to be defined within such regions. Extensive experiments demonstrate that the proposed method can generate both feasible and plausible trajectories efficiently and accurately.



### Targeted Supervised Contrastive Learning for Long-Tailed Recognition
- **Arxiv ID**: http://arxiv.org/abs/2111.13998v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2111.13998v2)
- **Published**: 2021-11-27 22:40:10+00:00
- **Updated**: 2022-05-02 04:38:30+00:00
- **Authors**: Tianhong Li, Peng Cao, Yuan Yuan, Lijie Fan, Yuzhe Yang, Rogerio Feris, Piotr Indyk, Dina Katabi
- **Comment**: The first two authors contributed equally to this paper
- **Journal**: None
- **Summary**: Real-world data often exhibits long tail distributions with heavy class imbalance, where the majority classes can dominate the training process and alter the decision boundaries of the minority classes. Recently, researchers have investigated the potential of supervised contrastive learning for long-tailed recognition, and demonstrated that it provides a strong performance gain. In this paper, we show that while supervised contrastive learning can help improve performance, past baselines suffer from poor uniformity brought in by imbalanced data distribution. This poor uniformity manifests in samples from the minority class having poor separability in the feature space. To address this problem, we propose targeted supervised contrastive learning (TSC), which improves the uniformity of the feature distribution on the hypersphere. TSC first generates a set of targets uniformly distributed on a hypersphere. It then makes the features of different classes converge to these distinct and uniformly distributed targets during training. This forces all classes, including minority classes, to maintain a uniform distribution in the feature space, improves class boundaries, and provides better generalization even in the presence of long-tail data. Experiments on multiple datasets show that TSC achieves state-of-the-art performance on long-tailed recognition tasks.



