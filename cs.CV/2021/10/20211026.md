# Arxiv Papers in cs.CV on 2021-10-26
### Robust Ellipsoid-specific Fitting via Expectation Maximization
- **Arxiv ID**: http://arxiv.org/abs/2110.13337v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13337v1)
- **Published**: 2021-10-26 00:43:02+00:00
- **Updated**: 2021-10-26 00:43:02+00:00
- **Authors**: Zhao Mingyang, Jia Xiaohong, Ma Lei, Qiu Xinlin, Jiang Xin, Yan Dong-Ming
- **Comment**: None
- **Journal**: None
- **Summary**: Ellipsoid fitting is of general interest in machine vision, such as object detection and shape approximation. Most existing approaches rely on the least-squares fitting of quadrics, minimizing the algebraic or geometric distances, with additional constraints to enforce the quadric as an ellipsoid. However, they are susceptible to outliers and non-ellipsoid or biased results when the axis ratio exceeds certain thresholds. To address these problems, we propose a novel and robust method for ellipsoid fitting in a noisy, outlier-contaminated 3D environment. We explicitly model the ellipsoid by kernel density estimation (KDE) of the input data. The ellipsoid fitting is cast as a maximum likelihood estimation (MLE) problem without extra constraints, where a weighting term is added to depress outliers, and then effectively solved via the Expectation-Maximization (EM) framework. Furthermore, we introduce the vector {\epsilon} technique to accelerate the convergence of the original EM. The proposed method is compared with representative state-of-the-art approaches by extensive experiments, and results show that our method is ellipsoid-specific, parameter free, and more robust against noise, outliers, and the large axis ratio. Our implementation is available at https://zikai1.github.io/.



### RGB Camera-based Physiological Sensing: Challenges and Future Directions
- **Arxiv ID**: http://arxiv.org/abs/2110.13362v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2110.13362v2)
- **Published**: 2021-10-26 02:30:18+00:00
- **Updated**: 2022-02-22 02:53:58+00:00
- **Authors**: Xin Liu, Shwetak Patel, Daniel McDuff
- **Comment**: None
- **Journal**: None
- **Summary**: Numerous real-world applications have been driven by the recent algorithmic advancement of artificial intelligence (AI). Healthcare is no exception and AI technologies have great potential to revolutionize the industry. Non-contact camera-based physiological sensing, including remote photoplethysmography (rPPG), is a set of imaging methods that leverages ordinary RGB cameras (e.g., webcam or smartphone camera) to capture subtle changes in electromagnetic radiation (e.g., light) reflected by the body caused by physiological processes. RGB camera-based systems not only have the ability to measure the signals without contact with the body but also have the opportunity to capture multimodal information (e.g., facial expressions, activities and other context) from the same sensor. However, developing accessible, equitable and useful camera-based physiological sensing systems comes with various challenges. In this article, we identify four research challenges for the field of RGB camera-based physiological sensing and broader AI driven healthcare communities and suggest future directions to tackle these. We believe solving these challenges will help deliver accurate, equitable and generalizable AI systems for healthcare that are practical in real-world and clinical contexts.



### An Automatic Detection Method Of Cerebral Aneurysms In Time-Of-Flight Magnetic Resonance Angiography Images Based On Attention 3D U-Net
- **Arxiv ID**: http://arxiv.org/abs/2110.13367v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13367v1)
- **Published**: 2021-10-26 02:45:15+00:00
- **Updated**: 2021-10-26 02:45:15+00:00
- **Authors**: Chen Geng, Meng Chen, Ruoyu Di, Dongdong Wang, Liqin Yang, Wei Xia, Yuxin Li, Daoying Geng
- **Comment**: None
- **Journal**: None
- **Summary**: Background:Subarachnoid hemorrhage caused by ruptured cerebral aneurysm often leads to fatal consequences.However,if the aneurysm can be found and treated during asymptomatic periods,the probability of rupture can be greatly reduced.At present,time-of-flight magnetic resonance angiography is one of the most commonly used non-invasive screening techniques for cerebral aneurysm,and the application of deep learning technology in aneurysm detection can effectively improve the screening effect of aneurysm.Existing studies have found that three-dimensional features play an important role in aneurysm detection,but they require a large amount of training data and have problems such as a high false positive rate. Methods:This paper proposed a novel method for aneurysm detection.First,a fully automatic cerebral artery segmentation algorithm without training data was used to extract the volume of interest,and then the 3D U-Net was improved by the 3D SENet module to establish an aneurysm detection model.Eventually a set of fully automated,end-to-end aneurysm detection methods have been formed. Results:A total of 231 magnetic resonance angiography image data were used in this study,among which 132 were training sets,34 were internal test sets and 65 were external test sets.The presented method obtained 97.89% sensitivity in the five-fold cross-validation and obtained 91.0% sensitivity with 2.48 false positives/case in the detection of the external test sets. Conclusions:Compared with the results of our previous studies and other studies,the method in this paper achieves a very competitive sensitivity with less training data and maintains a low false positive rate.As the only method currently using 3D U-Net for aneurysm detection,it proves the feasibility and superior performance of this network in aneurysm detection,and also explores the potential of the channel attention mechanism in this task.



### Instant Response Few-shot Object Detection with Meta Strategy and Explicit Localization Inference
- **Arxiv ID**: http://arxiv.org/abs/2110.13377v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13377v2)
- **Published**: 2021-10-26 03:09:57+00:00
- **Updated**: 2022-05-12 08:19:29+00:00
- **Authors**: Junying Huang, Fan Chen, Sibo Huang, Dongyu Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Aiming at recognizing and localizing the object of novel categories by a few reference samples, few-shot object detection (FSOD) is a quite challenging task. Previous works often depend on the fine-tuning process to transfer their model to the novel category and rarely consider the defect of fine-tuning, resulting in many application drawbacks. For example, these methods are far from satisfying in the episode-changeable scenarios due to excessive fine-tuning times, and their performance on low-quality (e.g., low-shot and class-incomplete) support sets degrades severely. To this end, this paper proposes an instant response few-shot object detector (IR-FSOD) that can accurately and directly detect the objects of novel categories without the fine-tuning process. To accomplish the objective, we carefully analyze the defects of individual modules in the Faster R-CNN framework under the FSOD setting and then extend it to IR-FSOD by improving these defects. Specifically, we first propose two simple but effective meta-strategies for the box classifier and RPN module to enable the object detection of novel categories with instant response. Then, we introduce two explicit inferences into the localization module to alleviate its over-fitting to the base categories, including explicit localization score and semi-explicit box regression. Extensive experiments show that the IR-FSOD framework not only achieves few-shot object detection with the instant response but also reaches state-of-the-art performance in precision and recall under various FSOD settings.



### ViDA-MAN: Visual Dialog with Digital Humans
- **Arxiv ID**: http://arxiv.org/abs/2110.13384v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13384v1)
- **Published**: 2021-10-26 03:23:51+00:00
- **Updated**: 2021-10-26 03:23:51+00:00
- **Authors**: Tong Shen, Jiawei Zuo, Fan Shi, Jin Zhang, Liqin Jiang, Meng Chen, Zhengchen Zhang, Wei Zhang, Xiaodong He, Tao Mei
- **Comment**: None
- **Journal**: None
- **Summary**: We demonstrate ViDA-MAN, a digital-human agent for multi-modal interaction, which offers realtime audio-visual responses to instant speech inquiries. Compared to traditional text or voice-based system, ViDA-MAN offers human-like interactions (e.g, vivid voice, natural facial expression and body gestures). Given a speech request, the demonstration is able to response with high quality videos in sub-second latency. To deliver immersive user experience, ViDA-MAN seamlessly integrates multi-modal techniques including Acoustic Speech Recognition (ASR), multi-turn dialog, Text To Speech (TTS), talking heads video generation. Backed with large knowledge base, ViDA-MAN is able to chat with users on a number of topics including chit-chat, weather, device control, News recommendations, booking hotels, as well as answering questions via structured knowledge.



### IIP-Transformer: Intra-Inter-Part Transformer for Skeleton-Based Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/2110.13385v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13385v1)
- **Published**: 2021-10-26 03:24:22+00:00
- **Updated**: 2021-10-26 03:24:22+00:00
- **Authors**: Qingtian Wang, Jianlin Peng, Shuze Shi, Tingxi Liu, Jiabin He, Renliang Weng
- **Comment**: 10 pages, 7 figures
- **Journal**: None
- **Summary**: Recently, Transformer-based networks have shown great promise on skeleton-based action recognition tasks. The ability to capture global and local dependencies is the key to success while it also brings quadratic computation and memory cost. Another problem is that previous studies mainly focus on the relationships among individual joints, which often suffers from the noisy skeleton joints introduced by the noisy inputs of sensors or inaccurate estimations. To address the above issues, we propose a novel Transformer-based network (IIP-Transformer). Instead of exploiting interactions among individual joints, our IIP-Transformer incorporates body joints and parts interactions simultaneously and thus can capture both joint-level (intra-part) and part-level (inter-part) dependencies efficiently and effectively. From the data aspect, we introduce a part-level skeleton data encoding that significantly reduces the computational complexity and is more robust to joint-level skeleton noise. Besides, a new part-level data augmentation is proposed to improve the performance of the model. On two large-scale datasets, NTU-RGB+D 60 and NTU RGB+D 120, the proposed IIP-Transformer achieves the-state-of-art performance with more than 8x less computational complexity than DSTA-Net, which is the SOTA Transformer-based method.



### Self-Denoising Neural Networks for Few Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.13386v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.13386v1)
- **Published**: 2021-10-26 03:28:36+00:00
- **Updated**: 2021-10-26 03:28:36+00:00
- **Authors**: Steven Schwarcz, Sai Saketh Rambhatla, Rama Chellappa
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a new architecture for few shot learning, the task of teaching a neural network from as few as one or five labeled examples. Inspired by the theoretical results of Alaine et al that Denoising Autoencoders refine features to lie closer to the true data manifold, we present a new training scheme that adds noise at multiple stages of an existing neural architecture while simultaneously learning to be robust to this added noise. This architecture, which we call a Self-Denoising Neural Network (SDNN), can be applied easily to most modern convolutional neural architectures, and can be used as a supplement to many existing few-shot learning techniques. We empirically show that SDNNs out-perform previous state-of-the-art methods for few shot image recognition using the Wide-ResNet architecture on the \textit{mini}ImageNet, tiered-ImageNet, and CIFAR-FS few shot learning datasets. We also perform a series of ablation experiments to empirically justify the construction of the SDNN architecture. Finally, we show that SDNNs even improve few shot performance on the task of human action detection in video using experiments on the ActEV SDL Surprise Activities challenge.



### A Normalized Gaussian Wasserstein Distance for Tiny Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.13389v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13389v2)
- **Published**: 2021-10-26 03:43:17+00:00
- **Updated**: 2022-06-14 12:58:44+00:00
- **Authors**: Jinwang Wang, Chang Xu, Wen Yang, Lei Yu
- **Comment**: Codes are available at: https://github.com/jwwangchn/NWD. Its
  expanded work is accepted by the ISPRS J P & RS
  (https://www.sciencedirect.com/science/article/pii/S0924271622001599?dgcid=author)
- **Journal**: None
- **Summary**: Detecting tiny objects is a very challenging problem since a tiny object only contains a few pixels in size. We demonstrate that state-of-the-art detectors do not produce satisfactory results on tiny objects due to the lack of appearance information. Our key observation is that Intersection over Union (IoU) based metrics such as IoU itself and its extensions are very sensitive to the location deviation of the tiny objects, and drastically deteriorate the detection performance when used in anchor-based detectors. To alleviate this, we propose a new evaluation metric using Wasserstein distance for tiny object detection. Specifically, we first model the bounding boxes as 2D Gaussian distributions and then propose a new metric dubbed Normalized Wasserstein Distance (NWD) to compute the similarity between them by their corresponding Gaussian distributions. The proposed NWD metric can be easily embedded into the assignment, non-maximum suppression, and loss function of any anchor-based detector to replace the commonly used IoU metric. We evaluate our metric on a new dataset for tiny object detection (AI-TOD) in which the average object size is much smaller than existing object detection datasets. Extensive experiments show that, when equipped with NWD metric, our approach yields performance that is 6.7 AP points higher than a standard fine-tuning baseline, and 6.0 AP points higher than state-of-the-art competitors. Codes are available at: https://github.com/jwwangchn/NWD.



### Transferring Domain-Agnostic Knowledge in Video Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2110.13395v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.13395v1)
- **Published**: 2021-10-26 03:58:31+00:00
- **Updated**: 2021-10-26 03:58:31+00:00
- **Authors**: Tianran Wu, Noa Garcia, Mayu Otani, Chenhui Chu, Yuta Nakashima, Haruo Takemura
- **Comment**: None
- **Journal**: None
- **Summary**: Video question answering (VideoQA) is designed to answer a given question based on a relevant video clip. The current available large-scale datasets have made it possible to formulate VideoQA as the joint understanding of visual and language information. However, this training procedure is costly and still less competent with human performance. In this paper, we investigate a transfer learning method by the introduction of domain-agnostic knowledge and domain-specific knowledge. First, we develop a novel transfer learning framework, which finetunes the pre-trained model by applying domain-agnostic knowledge as the medium. Second, we construct a new VideoQA dataset with 21,412 human-generated question-answer samples for comparable transfer of knowledge. Our experiments show that: (i) domain-agnostic knowledge is transferable and (ii) our proposed transfer learning framework can boost VideoQA performance effectively.



### Learning Rich Features for Gait Recognition by Integrating Skeletons and Silhouettes
- **Arxiv ID**: http://arxiv.org/abs/2110.13408v2
- **DOI**: None
- **Categories**: **cs.CV**, I.2; I.4; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2110.13408v2)
- **Published**: 2021-10-26 04:42:24+00:00
- **Updated**: 2022-05-05 07:35:07+00:00
- **Authors**: Yunjie Peng, Kang Ma, Yang Zhang, Zhiqiang He
- **Comment**: The paper is under consideration at Multimedia Tools and Applications
- **Journal**: None
- **Summary**: Gait recognition captures gait patterns from the walking sequence of an individual for identification. Most existing gait recognition methods learn features from silhouettes or skeletons for the robustness to clothing, carrying, and other exterior factors. The combination of the two data modalities, however, is not fully exploited. Previous multimodal gait recognition methods mainly employ the skeleton to assist the local feature extraction where the intrinsic discrimination of the skeleton data is ignored. This paper proposes a simple yet effective Bimodal Fusion (BiFusion) network which mines discriminative gait patterns in skeletons and integrates with silhouette representations to learn rich features for identification. Particularly, the inherent hierarchical semantics of body joints in a skeleton is leveraged to design a novel Multi-Scale Gait Graph (MSGG) network for the feature extraction of skeletons. Extensive experiments on CASIA-B and OUMVLP demonstrate both the superiority of the proposed MSGG network in modeling skeletons and the effectiveness of the bimodal fusion for gait recognition. Under the most challenging condition of walking in different clothes on CASIA-B, our method achieves the rank-1 accuracy of 92.1%.



### TriBERT: Full-body Human-centric Audio-visual Representation Learning for Visual Sound Separation
- **Arxiv ID**: http://arxiv.org/abs/2110.13412v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13412v1)
- **Published**: 2021-10-26 04:50:42+00:00
- **Updated**: 2021-10-26 04:50:42+00:00
- **Authors**: Tanzila Rahman, Mengyu Yang, Leonid Sigal
- **Comment**: 10 pages, 5 Figures, Neurips 2021
- **Journal**: https://nips.cc/Conferences/2021
- **Summary**: The recent success of transformer models in language, such as BERT, has motivated the use of such architectures for multi-modal feature learning and tasks. However, most multi-modal variants (e.g., ViLBERT) have limited themselves to visual-linguistic data. Relatively few have explored its use in audio-visual modalities, and none, to our knowledge, illustrate them in the context of granular audio-visual detection or segmentation tasks such as sound source separation and localization. In this work, we introduce TriBERT -- a transformer-based architecture, inspired by ViLBERT, which enables contextual feature learning across three modalities: vision, pose, and audio, with the use of flexible co-attention. The use of pose keypoints is inspired by recent works that illustrate that such representations can significantly boost performance in many audio-visual scenarios where often one or more persons are responsible for the sound explicitly (e.g., talking) or implicitly (e.g., sound produced as a function of human manipulating an object). From a technical perspective, as part of the TriBERT architecture, we introduce a learned visual tokenization scheme based on spatial attention and leverage weak-supervision to allow granular cross-modal interactions for visual and pose modalities. Further, we supplement learning with sound-source separation loss formulated across all three streams. We pre-train our model on the large MUSIC21 dataset and demonstrate improved performance in audio-visual sound source separation on that dataset as well as other datasets through fine-tuning. In addition, we show that the learned TriBERT representations are generic and significantly improve performance on other audio-visual tasks such as cross-modal audio-visual-pose retrieval by as much as 66.7% in top-1 accuracy.



### Semantic Host-free Trojan Attack
- **Arxiv ID**: http://arxiv.org/abs/2110.13414v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2110.13414v1)
- **Published**: 2021-10-26 05:01:22+00:00
- **Updated**: 2021-10-26 05:01:22+00:00
- **Authors**: Haripriya Harikumar, Kien Do, Santu Rana, Sunil Gupta, Svetha Venkatesh
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel host-free Trojan attack with triggers that are fixed in the semantic space but not necessarily in the pixel space. In contrast to existing Trojan attacks which use clean input images as hosts to carry small, meaningless trigger patterns, our attack considers triggers as full-sized images belonging to a semantically meaningful object class. Since in our attack, the backdoored classifier is encouraged to memorize the abstract semantics of the trigger images than any specific fixed pattern, it can be later triggered by semantically similar but different looking images. This makes our attack more practical to be applied in the real-world and harder to defend against. Extensive experimental results demonstrate that with only a small number of Trojan patterns for training, our attack can generalize well to new patterns of the same Trojan class and can bypass state-of-the-art defense methods.



### Image Magnification Network for Vessel Segmentation in OCTA Images
- **Arxiv ID**: http://arxiv.org/abs/2110.13428v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13428v2)
- **Published**: 2021-10-26 06:18:38+00:00
- **Updated**: 2022-05-07 13:00:36+00:00
- **Authors**: Mingchao Li, Yerui Chen, Weiwei Zhang, Qiang Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Optical coherence tomography angiography (OCTA) is a novel non-invasive imaging modality that allows micron-level resolution to visualize the retinal microvasculature. The retinal vessel segmentation in OCTA images is still an open problem, and especially the thin and dense structure of the capillary plexus is an important challenge of this problem. In this work, we propose a novel image magnification network (IMN) for vessel segmentation in OCTA images. Contrary to the U-Net structure with a down-sampling encoder and up-sampling decoder, the proposed IMN adopts the design of up-sampling encoding and then down-sampling decoding. This design is to capture more low-level image details to reduce the omission of small structures. The experimental results on three open OCTA datasets show that the proposed IMN with an average dice score of 90.2% achieves the best performance in vessel segmentation of OCTA images. Besides, we also demonstrate the superior performance of IMN in cross-field image vessel segmentation and vessel skeleton extraction.



### Contextual Similarity Aggregation with Self-attention for Visual Re-ranking
- **Arxiv ID**: http://arxiv.org/abs/2110.13430v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13430v1)
- **Published**: 2021-10-26 06:20:31+00:00
- **Updated**: 2021-10-26 06:20:31+00:00
- **Authors**: Jianbo Ouyang, Hui Wu, Min Wang, Wengang Zhou, Houqiang Li
- **Comment**: Accepted to NeurIPS, 2021
- **Journal**: None
- **Summary**: In content-based image retrieval, the first-round retrieval result by simple visual feature comparison may be unsatisfactory, which can be refined by visual re-ranking techniques. In image retrieval, it is observed that the contextual similarity among the top-ranked images is an important clue to distinguish the semantic relevance. Inspired by this observation, in this paper, we propose a visual re-ranking method by contextual similarity aggregation with self-attention. In our approach, for each image in the top-K ranking list, we represent it into an affinity feature vector by comparing it with a set of anchor images. Then, the affinity features of the top-K images are refined by aggregating the contextual information with a transformer encoder. Finally, the affinity features are used to recalculate the similarity scores between the query and the top-K images for re-ranking of the latter. To further improve the robustness of our re-ranking model and enhance the performance of our method, a new data augmentation scheme is designed. Since our re-ranking model is not directly involved with the visual feature used in the initial retrieval, it is ready to be applied to retrieval result lists obtained from various retrieval algorithms. We conduct comprehensive experiments on four benchmark datasets to demonstrate the generality and effectiveness of our proposed visual re-ranking method.



### Deep Learning-based Segmentation of Cerebral Aneurysms in 3D TOF-MRA using Coarse-to-Fine Framework
- **Arxiv ID**: http://arxiv.org/abs/2110.13432v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13432v1)
- **Published**: 2021-10-26 06:25:43+00:00
- **Updated**: 2021-10-26 06:25:43+00:00
- **Authors**: Meng Chen, Chen Geng, Dongdong Wang, Jiajun Zhang, Ruoyu Di, Fengmei Li, Zhiyong Zhou, Sirong Piao, Yuxin Li, Yaikang Dai
- **Comment**: None
- **Journal**: None
- **Summary**: BACKGROUND AND PURPOSE: Cerebral aneurysm is one of the most common cerebrovascular diseases, and SAH caused by its rupture has a very high mortality and disability rate. Existing automatic segmentation methods based on DLMs with TOF-MRA modality could not segment edge voxels very well, so that our goal is to realize more accurate segmentation of cerebral aneurysms in 3D TOF-MRA with the help of DLMs. MATERIALS AND METHODS: In this research, we proposed an automatic segmentation framework of cerebral aneurysm in 3D TOF-MRA. The framework was composed of two segmentation networks ranging from coarse to fine. The coarse segmentation network, namely DeepMedic, completed the coarse segmentation of cerebral aneurysms, and the processed results were fed into the fine segmentation network, namely dual-channel SE_3D U-Net trained with weighted loss function, for fine segmentation. Images from ADAM2020 (n=113) were used for training and validation and images from another center (n=45) were used for testing. The segmentation metrics we used include DSC, HD, and VS. RESULTS: The trained cerebral aneurysm segmentation model achieved DSC of 0.75, HD of 1.52, and VS of 0.91 on validation cohort. On the totally independent test cohort, our method achieved the highest DSC of 0.12, the lowest HD of 11.61, and the highest VS of 0.16 in comparison with state-of-the-art segmentation networks. CONCLUSIONS: The coarse-to-fine framework, which composed of DeepMedic and dual-channel SE_3D U-Net can segment cerebral aneurysms in 3D TOF-MRA with a superior accuracy.



### Understanding the Role of Self-Supervised Learning in Out-of-Distribution Detection Task
- **Arxiv ID**: http://arxiv.org/abs/2110.13435v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13435v1)
- **Published**: 2021-10-26 06:29:18+00:00
- **Updated**: 2021-10-26 06:29:18+00:00
- **Authors**: Jiuhai Chen, Chen Zhu, Bin Dai
- **Comment**: None
- **Journal**: None
- **Summary**: Self-supervised learning (SSL) has achieved great success in a variety of computer vision tasks. However, the mechanism of how SSL works in these tasks remains a mystery. In this paper, we study how SSL can enhance the performance of the out-of-distribution (OOD) detection task. We first point out two general properties that a good OOD detector should have: 1) the overall feature space should be large and 2) the inlier feature space should be small. Then we demonstrate that SSL can indeed increase the intrinsic dimension of the overall feature space. In the meantime, SSL even has the potential to shrink the inlier feature space. As a result, there will be more space spared for the outliers, making OOD detection much easier. The conditions when SSL can shrink the inlier feature space is also discussed and validated. By understanding the role of SSL in the OOD detection task, our study can provide a guideline for designing better OOD detection algorithms. Moreover, this work can also shed light to other tasks where SSL can improve the performance.



### A time-weighted metric for sets of trajectories to assess multi-object tracking algorithms
- **Arxiv ID**: http://arxiv.org/abs/2110.13444v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/2110.13444v1)
- **Published**: 2021-10-26 07:15:52+00:00
- **Updated**: 2021-10-26 07:15:52+00:00
- **Authors**: Ángel F. García-Fernández, Abu Sajana Rahmathullah, Lennart Svensson
- **Comment**: Matlab code available at https://github.com/Agarciafernandez/MTT
  (Trajectory metric folder)
- **Journal**: in Proceedings of the 24th International Conference on Information
  Fusion, 2021
- **Summary**: This paper proposes a metric for sets of trajectories to evaluate multi-object tracking algorithms that includes time-weighted costs for localisation errors of properly detected targets, for false targets, missed targets and track switches. The proposed metric extends the metric in [1] by including weights to the costs associated to different time steps. The time-weighted costs increase the flexibility of the metric [1] to fit more applications and user preferences. We first introduce a metric based on multi-dimensional assignments, and then its linear programming relaxation, which is computable in polynomial time and is also a metric. The metrics can also be extended to metrics on random finite sets of trajectories to evaluate and rank algorithms across different scenarios, each with a ground truth set of trajectories.



### Subject Adaptive EEG-based Visual Recognition
- **Arxiv ID**: http://arxiv.org/abs/2110.13470v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.13470v1)
- **Published**: 2021-10-26 08:06:55+00:00
- **Updated**: 2021-10-26 08:06:55+00:00
- **Authors**: Pilhyeon Lee, Sunhee Hwang, Seogkyu Jeon, Hyeran Byun
- **Comment**: Accepted by ACPR 2021. Code is available at
  https://github.com/DeepBCI/Deep-BCI
- **Journal**: None
- **Summary**: This paper focuses on EEG-based visual recognition, aiming to predict the visual object class observed by a subject based on his/her EEG signals. One of the main challenges is the large variation between signals from different subjects. It limits recognition systems to work only for the subjects involved in model training, which is undesirable for real-world scenarios where new subjects are frequently added. This limitation can be alleviated by collecting a large amount of data for each new user, yet it is costly and sometimes infeasible. To make the task more practical, we introduce a novel problem setting, namely subject adaptive EEG-based visual recognition. In this setting, a bunch of pre-recorded data of existing users (source) is available, while only a little training data from a new user (target) are provided. At inference time, the model is evaluated solely on the signals from the target user. This setting is challenging, especially because training samples from source subjects may not be helpful when evaluating the model on the data from the target subject. To tackle the new problem, we design a simple yet effective baseline that minimizes the discrepancy between feature distributions from different subjects, which allows the model to extract subject-independent features. Consequently, our model can learn the common knowledge shared among subjects, thereby significantly improving the recognition performance for the target subject. In the experiments, we demonstrate the effectiveness of our method under various settings. Our code is available at https://github.com/DeepBCI/Deep-BCI/tree/master/1_Intelligent_BCI/Subject_Adaptive_EEG_based_Visual_Recognition.



### Response-based Distillation for Incremental Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.13471v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13471v1)
- **Published**: 2021-10-26 08:07:55+00:00
- **Updated**: 2021-10-26 08:07:55+00:00
- **Authors**: Tao Feng, Mang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Traditional object detection are ill-equipped for incremental learning. However, fine-tuning directly on a well-trained detection model with only new data will leads to catastrophic forgetting. Knowledge distillation is a straightforward way to mitigate catastrophic forgetting. In Incremental Object Detection (IOD), previous work mainly focuses on feature-level knowledge distillation, but the different response of detector has not been fully explored yet. In this paper, we propose a fully response-based incremental distillation method focusing on learning response from detection bounding boxes and classification predictions. Firstly, our method transferring category knowledge while equipping student model with the ability to retain localization knowledge during incremental learning. In addition, we further evaluate the qualities of all locations and provides valuable response by adaptive pseudo-label selection (APS) strategies. Finally, we elucidate that knowledge from different responses should be assigned with different importance during incremental distillation. Extensive experiments conducted on MS COCO demonstrate significant advantages of our method, which substantially narrow the performance gap towards full training.



### CTRN: Class-Temporal Relational Network for Action Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.13473v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.13473v2)
- **Published**: 2021-10-26 08:15:47+00:00
- **Updated**: 2022-07-11 12:55:51+00:00
- **Authors**: Rui Dai, Srijan Das, Francois Bremond
- **Comment**: None
- **Journal**: None
- **Summary**: Action detection is an essential and challenging task, especially for densely labelled datasets of untrimmed videos. There are many real-world challenges in those datasets, such as composite action, co-occurring action, and high temporal variation of instance duration. For handling these challenges, we propose to explore both the class and temporal relations of detected actions. In this work, we introduce an end-to-end network: Class-Temporal Relational Network (CTRN). It contains three key components: (1) The Representation Transform Module filters the class-specific features from the mixed representations to build graph-structured data. (2) The Class-Temporal Module models the class and temporal relations in a sequential manner. (3) G-classifier leverages the privileged knowledge of the snippet-wise co-occurring action pairs to further improve the co-occurring action detection. We evaluate CTRN on three challenging densely labelled datasets and achieve state-of-the-art performance, reflecting the effectiveness and robustness of our method.



### Zero-Shot Action Recognition from Diverse Object-Scene Compositions
- **Arxiv ID**: http://arxiv.org/abs/2110.13479v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13479v1)
- **Published**: 2021-10-26 08:23:14+00:00
- **Updated**: 2021-10-26 08:23:14+00:00
- **Authors**: Carlo Bretti, Pascal Mettes
- **Comment**: BMVC 2021
- **Journal**: None
- **Summary**: This paper investigates the problem of zero-shot action recognition, in the setting where no training videos with seen actions are available. For this challenging scenario, the current leading approach is to transfer knowledge from the image domain by recognizing objects in videos using pre-trained networks, followed by a semantic matching between objects and actions. Where objects provide a local view on the content in videos, in this work we also seek to include a global view of the scene in which actions occur. We find that scenes on their own are also capable of recognizing unseen actions, albeit more marginally than objects, and a direct combination of object-based and scene-based scores degrades the action recognition performance. To get the best out of objects and scenes, we propose to construct them as a Cartesian product of all possible compositions. We outline how to determine the likelihood of object-scene compositions in videos, as well as a semantic matching from object-scene compositions to actions that enforces diversity among the most relevant compositions for each action. While simple, our composition-based approach outperforms object-based approaches and even state-of-the-art zero-shot approaches that rely on large-scale video datasets with hundreds of seen actions for training and knowledge transfer.



### Meta-Learning for Multi-Label Few-Shot Classification
- **Arxiv ID**: http://arxiv.org/abs/2110.13494v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13494v1)
- **Published**: 2021-10-26 08:47:48+00:00
- **Updated**: 2021-10-26 08:47:48+00:00
- **Authors**: Christian Simon, Piotr Koniusz, Mehrtash Harandi
- **Comment**: Accepted to WACV 2022
- **Journal**: None
- **Summary**: Even with the luxury of having abundant data, multi-label classification is widely known to be a challenging task to address. This work targets the problem of multi-label meta-learning, where a model learns to predict multiple labels within a query (e.g., an image) by just observing a few supporting examples. In doing so, we first propose a benchmark for Few-Shot Learning (FSL) with multiple labels per sample. Next, we discuss and extend several solutions specifically designed to address the conventional and single-label FSL, to work in the multi-label regime. Lastly, we introduce a neural module to estimate the label count of a given sample by exploiting the relational inference. We will show empirically the benefit of the label count module, the label propagation algorithm, and the extensions of conventional FSL methods on three challenging datasets, namely MS-COCO, iMaterialist, and Open MIC. Overall, our thorough experiments suggest that the proposed label-propagation algorithm in conjunction with the neural label count module (NLC) shall be considered as the method of choice.



### Single Morphing Attack Detection using Feature Selection and Visualisation based on Mutual Information
- **Arxiv ID**: http://arxiv.org/abs/2110.13552v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13552v1)
- **Published**: 2021-10-26 10:27:06+00:00
- **Updated**: 2021-10-26 10:27:06+00:00
- **Authors**: Juan Tapia, Christoph Busch
- **Comment**: None
- **Journal**: None
- **Summary**: Face morphing attack detection is a challenging task. Automatic classification methods and manual inspection are realised in automatic border control gates to detect morphing attacks. Understanding how a machine learning system can detect morphed faces and the most relevant facial areas is crucial. Those relevant areas contain texture signals that allow us to separate the bona fide and the morph images. Also, it helps in the manual examination to detect a passport generated with morphed images. This paper explores features extracted from intensity, shape, texture, and proposes a feature selection stage based on the Mutual Information filter to select the most relevant and less redundant features. This selection allows us to reduce the workload and know the exact localisation of such areas to understand the morphing impact and create a robust classifier. The best results were obtained for the method based on Conditional Mutual Information and Shape features using only 500 features for FERET images and 800 features for FRGCv2 images from 1,048 features available. The eyes and nose are identified as the most critical areas to be analysed.



### Directional Self-supervised Learning for Heavy Image Augmentations
- **Arxiv ID**: http://arxiv.org/abs/2110.13555v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13555v2)
- **Published**: 2021-10-26 10:33:25+00:00
- **Updated**: 2021-11-29 03:38:19+00:00
- **Authors**: Yalong Bai, Yifan Yang, Wei Zhang, Tao Mei
- **Comment**: None
- **Journal**: None
- **Summary**: Despite the large augmentation family, only a few cherry-picked robust augmentation policies are beneficial to self-supervised image representation learning. In this paper, we propose a directional self-supervised learning paradigm (DSSL), which is compatible with significantly more augmentations. Specifically, we adapt heavy augmentation policies after the views lightly augmented by standard augmentations, to generate harder view (HV). HV usually has a higher deviation from the original image than the lightly augmented standard view (SV). Unlike previous methods equally pairing all augmented views to symmetrically maximize their similarities, DSSL treats augmented views of the same instance as a partially ordered set (with directions as SV$\leftrightarrow $SV, SV$\leftarrow$HV), and then equips a directional objective function respecting to the derived relationships among views. DSSL can be easily implemented with a few lines of codes and is highly flexible to popular self-supervised learning frameworks, including SimCLR, SimSiam, BYOL. Extensive experimental results on CIFAR and ImageNet demonstrated that DSSL can stably improve various baselines with compatibility to a wider range of augmentations.



### Cross-Region Building Counting in Satellite Imagery using Counting Consistency
- **Arxiv ID**: http://arxiv.org/abs/2110.13558v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13558v2)
- **Published**: 2021-10-26 10:36:56+00:00
- **Updated**: 2023-08-13 07:16:43+00:00
- **Authors**: Muaaz Zakria, Hamza Rawal, Waqas Sultani, Mohsen Ali
- **Comment**: None
- **Journal**: None
- **Summary**: Estimating the number of buildings in any geographical region is a vital component of urban analysis, disaster management, and public policy decision. Deep learning methods for building localization and counting in satellite imagery, can serve as a viable and cheap alternative. However, these algorithms suffer performance degradation when applied to the regions on which they have not been trained. Current large datasets mostly cover the developed regions and collecting such datasets for every region is a costly, time-consuming, and difficult endeavor. In this paper, we propose an unsupervised domain adaptation method for counting buildings where we use a labeled source domain (developed regions) and adapt the trained model on an unlabeled target domain (developing regions). We initially align distribution maps across domains by aligning the output space distribution through adversarial loss. We then exploit counting consistency constraints, within-image count consistency, and across-image count consistency, to decrease the domain shift. Within-image consistency enforces that building count in the whole image should be greater than or equal to count in any of its sub-image. Across-image consistency constraint enforces that if an image contains considerably more buildings than the other image, then their sub-images shall also have the same order. These two constraints encourage the behavior to be consistent across and within the images, regardless of the scale. To evaluate the performance of our proposed approach, we collected and annotated a large-scale dataset consisting of challenging South Asian regions having higher building densities and irregular structures as compared to existing datasets. We perform extensive experiments to verify the efficacy of our approach and report improvements of approximately 7% to 20% over the competitive baseline methods.



### Learning Graph Representation of Person-specific Cognitive Processes from Audio-visual Behaviours for Automatic Personality Recognition
- **Arxiv ID**: http://arxiv.org/abs/2110.13570v2
- **DOI**: None
- **Categories**: **cs.CV**, 68T40, I.2.1
- **Links**: [PDF](http://arxiv.org/pdf/2110.13570v2)
- **Published**: 2021-10-26 11:04:23+00:00
- **Updated**: 2021-10-27 10:14:58+00:00
- **Authors**: Siyang Song, Zilong Shao, Shashank Jaiswal, Linlin Shen, Michel Valstar, Hatice Gunes
- **Comment**: Submitted to IJCV
- **Journal**: None
- **Summary**: This approach builds on two following findings in cognitive science: (i) human cognition partially determines expressed behaviour and is directly linked to true personality traits; and (ii) in dyadic interactions individuals' nonverbal behaviours are influenced by their conversational partner behaviours. In this context, we hypothesise that during a dyadic interaction, a target subject's facial reactions are driven by two main factors, i.e. their internal (person-specific) cognitive process, and the externalised nonverbal behaviours of their conversational partner. Consequently, we propose to represent the target subjects (defined as the listener) person-specific cognition in the form of a person-specific CNN architecture that has unique architectural parameters and depth, which takes audio-visual non-verbal cues displayed by the conversational partner (defined as the speaker) as input, and is able to reproduce the target subject's facial reactions. Each person-specific CNN is explored by the Neural Architecture Search (NAS) and a novel adaptive loss function, which is then represented as a graph representation for recognising the target subject's true personality. Experimental results not only show that the produced graph representations are well associated with target subjects' personality traits in both human-human and human-machine interaction scenarios, and outperform the existing approaches with significant advantages, but also demonstrate that the proposed novel strategies such as adaptive loss, and the end-to-end vertices/edges feature learning, help the proposed approach in learning more reliable personality representations.



### Emotion recognition in talking-face videos using persistent entropy and neural networks
- **Arxiv ID**: http://arxiv.org/abs/2110.13571v1
- **DOI**: None
- **Categories**: **cs.CV**, math.AT
- **Links**: [PDF](http://arxiv.org/pdf/2110.13571v1)
- **Published**: 2021-10-26 11:08:56+00:00
- **Updated**: 2021-10-26 11:08:56+00:00
- **Authors**: Eduardo Paluzo-Hidalgo, Guillermo Aguirre-Carrazana, Rocio Gonzalez-Diaz
- **Comment**: None
- **Journal**: None
- **Summary**: The automatic recognition of a person's emotional state has become a very active research field that involves scientists specialized in different areas such as artificial intelligence, computer vision or psychology, among others. Our main objective in this work is to develop a novel approach, using persistent entropy and neural networks as main tools, to recognise and classify emotions from talking-face videos. Specifically, we combine audio-signal and image-sequence information to compute a topology signature(a 9-dimensional vector) for each video. We prove that small changes in the video produce small changes in the signature. These topological signatures are used to feed a neural network to distinguish between the following emotions: neutral, calm, happy, sad, angry, fearful, disgust, and surprised. The results reached are promising and competitive, beating the performance reached in other state-of-the-art works found in the literature.



### Adversarial Robustness in Multi-Task Learning: Promises and Illusions
- **Arxiv ID**: http://arxiv.org/abs/2110.15053v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.15053v1)
- **Published**: 2021-10-26 11:29:03+00:00
- **Updated**: 2021-10-26 11:29:03+00:00
- **Authors**: Salah Ghamizi, Maxime Cordy, Mike Papadakis, Yves Le Traon
- **Comment**: None
- **Journal**: None
- **Summary**: Vulnerability to adversarial attacks is a well-known weakness of Deep Neural networks. While most of the studies focus on single-task neural networks with computer vision datasets, very little research has considered complex multi-task models that are common in real applications. In this paper, we evaluate the design choices that impact the robustness of multi-task deep learning networks. We provide evidence that blindly adding auxiliary tasks, or weighing the tasks provides a false sense of robustness. Thereby, we tone down the claim made by previous research and study the different factors which may affect robustness. In particular, we show that the choice of the task to incorporate in the loss function are important factors that can be leveraged to yield more robust models.



### Incremental Learning for Animal Pose Estimation using RBF k-DPP
- **Arxiv ID**: http://arxiv.org/abs/2110.13598v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13598v1)
- **Published**: 2021-10-26 11:55:20+00:00
- **Updated**: 2021-10-26 11:55:20+00:00
- **Authors**: Gaurav Kumar Nayak, Het Shah, Anirban Chakraborty
- **Comment**: Accepted in BMVC 2021
- **Journal**: None
- **Summary**: Pose estimation is the task of locating keypoints for an object of interest in an image. Animal Pose estimation is more challenging than estimating human pose due to high inter and intra class variability in animals. Existing works solve this problem for a fixed set of predefined animal categories. Models trained on such sets usually do not work well with new animal categories. Retraining the model on new categories makes the model overfit and leads to catastrophic forgetting. Thus, in this work, we propose a novel problem of "Incremental Learning for Animal Pose Estimation". Our method uses an exemplar memory, sampled using Determinantal Point Processes (DPP) to continually adapt to new animal categories without forgetting the old ones. We further propose a new variant of k-DPP that uses RBF kernel (termed as "RBF k-DPP") which gives more gain in performance over traditional k-DPP. Due to memory constraints, the limited number of exemplars along with new class data can lead to class imbalance. We mitigate it by performing image warping as an augmentation technique. This helps in crafting diverse poses, which reduces overfitting and yields further improvement in performance. The efficacy of our proposed approach is demonstrated via extensive experiments and ablations where we obtain significant improvements over state-of-the-art baseline methods.



### A Precision Diagnostic Framework of Renal Cell Carcinoma on Whole-Slide Images using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.13652v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13652v1)
- **Published**: 2021-10-26 12:53:25+00:00
- **Updated**: 2021-10-26 12:53:25+00:00
- **Authors**: Jialun Wu, Haichuan Zhang, Zeyu Gao, Xinrui Bao, Tieliang Gong, Chunbao Wang, Chen Li
- **Comment**: BIBM 2021 accepted, 9 pages including reference, 3 figures and 1
  table
- **Journal**: None
- **Summary**: Diagnostic pathology, which is the basis and gold standard of cancer diagnosis, provides essential information on the prognosis of the disease and vital evidence for clinical treatment. Tumor region detection, subtype and grade classification are the fundamental diagnostic indicators for renal cell carcinoma (RCC) in whole-slide images (WSIs). However, pathological diagnosis is subjective, differences in observation and diagnosis between pathologists is common in hospitals with inadequate diagnostic capacity. The main challenge for developing deep learning based RCC diagnostic system is the lack of large-scale datasets with precise annotations. In this work, we proposed a deep learning-based framework for analyzing histopathological images of patients with renal cell carcinoma, which has the potential to achieve pathologist-level accuracy in diagnosis. A deep convolutional neural network (InceptionV3) was trained on the high-quality annotated dataset of The Cancer Genome Atlas (TCGA) whole-slide histopathological image for accurate tumor area detection, classification of RCC subtypes, and ISUP grades classification of clear cell carcinoma subtypes. These results suggest that our framework can help pathologists in the detection of cancer region and classification of subtypes and grades, which could be applied to any cancer type, providing auxiliary diagnosis and promoting clinical consensus.



### W-Net: A Two-Stage Convolutional Network for Nucleus Detection in Histopathology Image
- **Arxiv ID**: http://arxiv.org/abs/2110.13670v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13670v1)
- **Published**: 2021-10-26 13:00:16+00:00
- **Updated**: 2021-10-26 13:00:16+00:00
- **Authors**: Anyu Mao, Jialun Wu, Xinrui Bao, Zeyu Gao, Tieliang Gong, Chen Li
- **Comment**: BIBM 2021 accepted,including 8 pages, 3 figures
- **Journal**: None
- **Summary**: Pathological diagnosis is the gold standard for cancer diagnosis, but it is labor-intensive, in which tasks such as cell detection, classification, and counting are particularly prominent. A common solution for automating these tasks is using nucleus segmentation technology. However, it is hard to train a robust nucleus segmentation model, due to several challenging problems, the nucleus adhesion, stacking, and excessive fusion with the background. Recently, some researchers proposed a series of automatic nucleus segmentation methods based on point annotation, which can significant improve the model performance. Nevertheless, the point annotation needs to be marked by experienced pathologists. In order to take advantage of segmentation methods based on point annotation, further alleviate the manual workload, and make cancer diagnosis more efficient and accurate, it is necessary to develop an automatic nucleus detection algorithm, which can automatically and efficiently locate the position of the nucleus in the pathological image and extract valuable information for pathologists. In this paper, we propose a W-shaped network for automatic nucleus detection. Different from the traditional U-Net based method, mapping the original pathology image to the target mask directly, our proposed method split the detection task into two sub-tasks. The first sub-task maps the original pathology image to the binary mask, then the binary mask is mapped to the density mask in the second sub-task. After the task is split, the task's difficulty is significantly reduced, and the network's overall performance is improved.



### Alpha-IoU: A Family of Power Intersection over Union Losses for Bounding Box Regression
- **Arxiv ID**: http://arxiv.org/abs/2110.13675v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13675v2)
- **Published**: 2021-10-26 13:09:20+00:00
- **Updated**: 2022-01-22 15:58:13+00:00
- **Authors**: Jiabo He, Sarah Erfani, Xingjun Ma, James Bailey, Ying Chi, Xian-Sheng Hua
- **Comment**: None
- **Journal**: None
- **Summary**: Bounding box (bbox) regression is a fundamental task in computer vision. So far, the most commonly used loss functions for bbox regression are the Intersection over Union (IoU) loss and its variants. In this paper, we generalize existing IoU-based losses to a new family of power IoU losses that have a power IoU term and an additional power regularization term with a single power parameter $\alpha$. We call this new family of losses the $\alpha$-IoU losses and analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that $\alpha$-IoU losses, 1) can surpass existing IoU-based losses by a noticeable performance margin; 2) offer detectors more flexibility in achieving different levels of bbox regression accuracy by modulating $\alpha$; and 3) are more robust to small datasets and noisy bboxes.



### A Personalized Diagnostic Generation Framework Based on Multi-source Heterogeneous Data
- **Arxiv ID**: http://arxiv.org/abs/2110.13677v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.13677v1)
- **Published**: 2021-10-26 13:12:52+00:00
- **Updated**: 2021-10-26 13:12:52+00:00
- **Authors**: Jialun Wu, Zeyu Gao, Haichuan Zhang, Ruonan Zhang, Tieliang Gong, Chunbao Wang, Chen Li
- **Comment**: BIBM 2021 accepted, including 9 pages, 3 figures
- **Journal**: None
- **Summary**: Personalized diagnoses have not been possible due to sear amount of data pathologists have to bear during the day-to-day routine. This lead to the current generalized standards that are being continuously updated as new findings are reported. It is noticeable that these effective standards are developed based on a multi-source heterogeneous data, including whole-slide images and pathology and clinical reports. In this study, we propose a framework that combines pathological images and medical reports to generate a personalized diagnosis result for individual patient. We use nuclei-level image feature similarity and content-based deep learning method to search for a personalized group of population with similar pathological characteristics, extract structured prognostic information from descriptive pathology reports of the similar patient population, and assign importance of different prognostic factors to generate a personalized pathological diagnosis result. We use multi-source heterogeneous data from TCGA (The Cancer Genome Atlas) database. The result demonstrate that our framework matches the performance of pathologists in the diagnosis of renal cell carcinoma. This framework is designed to be generic, thus could be applied for other types of cancer. The weights could provide insights to the known prognostic factors and further guide more precise clinical treatment protocols.



### BioIE: Biomedical Information Extraction with Multi-head Attention Enhanced Graph Convolutional Network
- **Arxiv ID**: http://arxiv.org/abs/2110.13683v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/2110.13683v1)
- **Published**: 2021-10-26 13:19:28+00:00
- **Updated**: 2021-10-26 13:19:28+00:00
- **Authors**: Jialun Wu, Yang Liu, Zeyu Gao, Tieliang Gong, Chunbao Wang, Chen Li
- **Comment**: BIBM 2021 accepted, including 9 pages, 1 figure
- **Journal**: None
- **Summary**: Constructing large-scaled medical knowledge graphs can significantly boost healthcare applications for medical surveillance, bring much attention from recent research. An essential step in constructing large-scale MKG is extracting information from medical reports. Recently, information extraction techniques have been proposed and show promising performance in biomedical information extraction. However, these methods only consider limited types of entity and relation due to the noisy biomedical text data with complex entity correlations. Thus, they fail to provide enough information for constructing MKGs and restrict the downstream applications. To address this issue, we propose Biomedical Information Extraction, a hybrid neural network to extract relations from biomedical text and unstructured medical reports. Our model utilizes a multi-head attention enhanced graph convolutional network to capture the complex relations and context information while resisting the noise from the data. We evaluate our model on two major biomedical relationship extraction tasks, chemical-disease relation and chemical-protein interaction, and a cross-hospital pan-cancer pathology report corpus. The results show that our method achieves superior performance than baselines. Furthermore, we evaluate the applicability of our method under a transfer learning setting and show that BioIE achieves promising performance in processing medical text from different formats and writing styles.



### A Closer Look at Reference Learning for Fourier Phase Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2110.13688v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13688v1)
- **Published**: 2021-10-26 13:25:36+00:00
- **Updated**: 2021-10-26 13:25:36+00:00
- **Authors**: Tobias Uelwer, Nick Rucks, Stefan Harmeling
- **Comment**: Accepted at the NeurIPS 2021 Workshop on Deep Learning and Inverse
  Problems
- **Journal**: None
- **Summary**: Reconstructing images from their Fourier magnitude measurements is a problem that often arises in different research areas. This process is also referred to as phase retrieval. In this work, we consider a modified version of the phase retrieval problem, which allows for a reference image to be added onto the image before the Fourier magnitudes are measured. We analyze an unrolled Gerchberg-Saxton (GS) algorithm that can be used to learn a good reference image from a dataset. Furthermore, we take a closer look at the learned reference images and propose a simple and efficient heuristic to construct reference images that, in some cases, yields reconstructions of comparable quality as approaches that learn references. Our code is available at https://github.com/tuelwer/reference-learning.



### A vectorized sea horizon edge filter for maritime video processing tasks
- **Arxiv ID**: http://arxiv.org/abs/2110.13694v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13694v3)
- **Published**: 2021-10-26 13:31:50+00:00
- **Updated**: 2022-04-30 16:51:47+00:00
- **Authors**: Yassir Zardoua, Boulaala Mohammed, Astito Abdelali
- **Comment**: None
- **Journal**: None
- **Summary**: The horizon line is a fundamental semantic feature in several maritime video processing tasks, such as digital video stabilization, camera calibration, target tracking, and target distance estimation. Visible range Electro-Optical (EO) sensors capture richer information in the daytime, which often comes with challenging clutter. The best methods rely on tailored filters to keep, ideally, only horizon edge pixels. These methods work well but often fail in the case of edge-degraded horizons. Our first aim is to solve this problem while taking the real-time constraint into account; we propose a tailored edge filter that relies on growing line segments with a low edge threshold and filters them based on their slope, length, and relative position. Next, we build the filtered edge map by computing Cartesian coordinates of pixels across line segments that survived the filter. We infer the horizon from the filtered edge map using line fitting techniques and simple temporal information. We consider the real-time constraint by vectorizing the computations and proposing a better way to leverage image downsizing. Extensive experiments on 26,125 visible range frames show that the proposed method achieves significant robustness while satisfying the real-time constraint.



### Addressing out-of-distribution label noise in webly-labelled data
- **Arxiv ID**: http://arxiv.org/abs/2110.13699v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13699v1)
- **Published**: 2021-10-26 13:38:50+00:00
- **Updated**: 2021-10-26 13:38:50+00:00
- **Authors**: Paul Albert, Diego Ortego, Eric Arazo, Noel O'Connor, Kevin McGuinness
- **Comment**: Accepted at WACV 2022
- **Journal**: None
- **Summary**: A recurring focus of the deep learning community is towards reducing the labeling effort. Data gathering and annotation using a search engine is a simple alternative to generating a fully human-annotated and human-gathered dataset. Although web crawling is very time efficient, some of the retrieved images are unavoidably noisy, i.e. incorrectly labeled. Designing robust algorithms for training on noisy data gathered from the web is an important research perspective that would render the building of datasets easier. In this paper we conduct a study to understand the type of label noise to expect when building a dataset using a search engine. We review the current limitations of state-of-the-art methods for dealing with noisy labels for image classification tasks in the case of web noise distribution. We propose a simple solution to bridge the gap with a fully clean dataset using Dynamic Softening of Out-of-distribution Samples (DSOS), which we design on corrupted versions of the CIFAR-100 dataset, and compare against state-of-the-art algorithms on the web noise perturbated MiniImageNet and Stanford datasets and on real label noise datasets: WebVision 1.0 and Clothing1M. Our work is fully reproducible https://git.io/JKGcj



### TNTC: two-stream network with transformer-based complementarity for gait-based emotion recognition
- **Arxiv ID**: http://arxiv.org/abs/2110.13708v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13708v1)
- **Published**: 2021-10-26 13:55:31+00:00
- **Updated**: 2021-10-26 13:55:31+00:00
- **Authors**: Chuanfei Hu, Weijie Sheng, Bo Dong, Xinde Li
- **Comment**: None
- **Journal**: None
- **Summary**: Recognizing the human emotion automatically from visual characteristics plays a vital role in many intelligent applications. Recently, gait-based emotion recognition, especially gait skeletons-based characteristic, has attracted much attention, while many available methods have been proposed gradually. The popular pipeline is to first extract affective features from joint skeletons, and then aggregate the skeleton joint and affective features as the feature vector for classifying the emotion. However, the aggregation procedure of these emerged methods might be rigid, resulting in insufficiently exploiting the complementary relationship between skeleton joint and affective features. Meanwhile, the long range dependencies in both spatial and temporal domains of the gait sequence are scarcely considered. To address these issues, we propose a novel two-stream network with transformer-based complementarity, termed as TNTC. Skeleton joint and affective features are encoded into two individual images as the inputs of two streams, respectively. A new transformer-based complementarity module (TCM) is proposed to bridge the complementarity between two streams hierarchically via capturing long range dependencies. Experimental results demonstrate TNTC outperforms state-of-the-art methods on the latest dataset in terms of accuracy.



### YOLO-ReT: Towards High Accuracy Real-time Object Detection on Edge GPUs
- **Arxiv ID**: http://arxiv.org/abs/2110.13713v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13713v1)
- **Published**: 2021-10-26 14:02:59+00:00
- **Updated**: 2021-10-26 14:02:59+00:00
- **Authors**: Prakhar Ganesh, Yao Chen, Yin Yang, Deming Chen, Marianne Winslett
- **Comment**: To appear in WACV 2022
- **Journal**: None
- **Summary**: Performance of object detection models has been growing rapidly on two major fronts, model accuracy and efficiency. However, in order to map deep neural network (DNN) based object detection models to edge devices, one typically needs to compress such models significantly, thus compromising the model accuracy. In this paper, we propose a novel edge GPU friendly module for multi-scale feature interaction by exploiting missing combinatorial connections between various feature scales in existing state-of-the-art methods. Additionally, we propose a novel transfer learning backbone adoption inspired by the changing translational information flow across various tasks, designed to complement our feature interaction module and together improve both accuracy as well as execution speed on various edge GPU devices available in the market. For instance, YOLO-ReT with MobileNetV2x0.75 backbone runs real-time on Jetson Nano, and achieves 68.75 mAP on Pascal VOC and 34.91 mAP on COCO, beating its peers by 3.05 mAP and 0.91 mAP respectively, while executing faster by 3.05 FPS. Furthermore, introducing our multi-scale feature interaction module in YOLOv4-tiny and YOLOv4-tiny (3l) improves their performance to 41.5 and 48.1 mAP respectively on COCO, outperforming the original versions by 1.3 and 0.9 mAP.



### Semi-supervised dry herbage mass estimation using automatic data and synthetic images
- **Arxiv ID**: http://arxiv.org/abs/2110.13719v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13719v1)
- **Published**: 2021-10-26 14:10:39+00:00
- **Updated**: 2021-10-26 14:10:39+00:00
- **Authors**: Paul Albert, Mohamed Saadeldin, Badri Narayanan, Brian Mac Namee, Deirdre Hennessy, Aisling O'Connor, Noel O'Connor, Kevin McGuinness
- **Comment**: Published at CVPPA 2021, ICCVW 2021
- **Journal**: None
- **Summary**: Monitoring species-specific dry herbage biomass is an important aspect of pasture-based milk production systems. Being aware of the herbage biomass in the field enables farmers to manage surpluses and deficits in herbage supply, as well as using targeted nitrogen fertilization when necessary. Deep learning for computer vision is a powerful tool in this context as it can accurately estimate the dry biomass of a herbage parcel using images of the grass canopy taken using a portable device. However, the performance of deep learning comes at the cost of an extensive, and in this case destructive, data gathering process. Since accurate species-specific biomass estimation is labor intensive and destructive for the herbage parcel, we propose in this paper to study low supervision approaches to dry biomass estimation using computer vision. Our contributions include: a synthetic data generation algorithm to generate data for a herbage height aware semantic segmentation task, an automatic process to label data using semantic segmentation maps, and a robust regression network trained to predict dry biomass using approximate biomass labels and a small trusted dataset with gold standard labels. We design our approach on a herbage mass estimation dataset collected in Ireland and also report state-of-the-art results on the publicly released Grass-Clover biomass estimation dataset from Denmark. Our code is available at https://git.io/J0L2a



### Deep DIC: Deep Learning-Based Digital Image Correlation for End-to-End Displacement and Strain Measurement
- **Arxiv ID**: http://arxiv.org/abs/2110.13720v2
- **DOI**: 10.1016/j.jmatprotec.2021.117474
- **Categories**: **eess.IV**, cond-mat.mtrl-sci, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13720v2)
- **Published**: 2021-10-26 14:13:57+00:00
- **Updated**: 2022-01-06 20:23:24+00:00
- **Authors**: Ru Yang, Yang Li, Danielle Zeng, Ping Guo
- **Comment**: 39 pages, 19 figures
- **Journal**: Journal of Materials Processing Technology (2021): 117474
- **Summary**: Digital image correlation (DIC) has become an industry standard to retrieve accurate displacement and strain measurement in tensile testing and other material characterization. Though traditional DIC offers a high precision estimation of deformation for general tensile testing cases, the prediction becomes unstable at large deformation or when the speckle patterns start to tear. In addition, traditional DIC requires a long computation time and often produces a low spatial resolution output affected by filtering and speckle pattern quality. To address these challenges, we propose a new deep learning-based DIC approach--Deep DIC, in which two convolutional neural networks, DisplacementNet and StrainNet, are designed to work together for end-to-end prediction of displacements and strains. DisplacementNet predicts the displacement field and adaptively tracks a region of interest. StrainNet predicts the strain field directly from the image input without relying on the displacement prediction, which significantly improves the strain prediction accuracy. A new dataset generation method is developed to synthesize a realistic and comprehensive dataset, including the generation of speckle patterns and the deformation of the speckle image with synthetic displacement fields. Though trained on synthetic datasets only, Deep DIC gives highly consistent and comparable predictions of displacement and strain with those obtained from commercial DIC software for real experiments, while it outperforms commercial software with very robust strain prediction even at large and localized deformation and varied pattern qualities. In addition, Deep DIC is capable of real-time prediction of deformation with a calculation time down to milliseconds.



### DP-SSL: Towards Robust Semi-supervised Learning with A Few Labeled Samples
- **Arxiv ID**: http://arxiv.org/abs/2110.13740v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13740v1)
- **Published**: 2021-10-26 14:43:12+00:00
- **Updated**: 2021-10-26 14:43:12+00:00
- **Authors**: Yi Xu, Jiandong Ding, Lu Zhang, Shuigeng Zhou
- **Comment**: Accepted by NeurIPS 2021; 16 pages with appendix
- **Journal**: None
- **Summary**: The scarcity of labeled data is a critical obstacle to deep learning. Semi-supervised learning (SSL) provides a promising way to leverage unlabeled data by pseudo labels. However, when the size of labeled data is very small (say a few labeled samples per class), SSL performs poorly and unstably, possibly due to the low quality of learned pseudo labels. In this paper, we propose a new SSL method called DP-SSL that adopts an innovative data programming (DP) scheme to generate probabilistic labels for unlabeled data. Different from existing DP methods that rely on human experts to provide initial labeling functions (LFs), we develop a multiple-choice learning~(MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, we design a label model to resolve the conflict and overlap among the noisy labels, and finally infer probabilistic labels for unlabeled samples. Extensive experiments on four standard SSL benchmarks show that DP-SSL can provide reliable labels for unlabeled data and achieve better classification performance on test sets than existing SSL methods, especially when only a small number of labeled samples are available. Concretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82% annotation accuracy on unlabeled data and 93.46% classification accuracy on test data, which are higher than the SOTA results.



### Robust Multi-view Registration of Point Sets with Laplacian Mixture Model
- **Arxiv ID**: http://arxiv.org/abs/2110.13744v1
- **DOI**: 10.1007/978-3-031-02444-3_41
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13744v1)
- **Published**: 2021-10-26 14:49:09+00:00
- **Updated**: 2021-10-26 14:49:09+00:00
- **Authors**: Jin Zhang, Mingyang Zhao, Xin Jiang, Dong-Ming Yan
- **Comment**: None
- **Journal**: None
- **Summary**: Point set registration is an essential step in many computer vision applications, such as 3D reconstruction and SLAM. Although there exist many registration algorithms for different purposes, however, this topic is still challenging due to the increasing complexity of various real-world scenarios, such as heavy noise and outlier contamination. In this paper, we propose a novel probabilistic generative method to simultaneously align multiple point sets based on the heavy-tailed Laplacian distribution. The proposed method assumes each data point is generated by a Laplacian Mixture Model (LMM), where its centers are determined by the corresponding points in other point sets. Different from the previous Gaussian Mixture Model (GMM) based method, which minimizes the quadratic distance between points and centers of Gaussian probability density, LMM minimizes the sparsity-induced L1 distance, thereby it is more robust against noise and outliers. We adopt Expectation-Maximization (EM) framework to solve LMM parameters and rigid transformations. We approximate the L1 optimization as a linear programming problem by exponential mapping in Lie algebra, which can be effectively solved through the interior point method. To improve efficiency, we also solve the L1 optimization by Alternating Direction Multiplier Method (ADMM). We demonstrate the advantages of our method by comparing it with representative state-of-the-art approaches on benchmark challenging data sets, in terms of robustness and accuracy.



### H-NeRF: Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion
- **Arxiv ID**: http://arxiv.org/abs/2110.13746v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13746v2)
- **Published**: 2021-10-26 14:51:36+00:00
- **Updated**: 2021-11-02 15:42:09+00:00
- **Authors**: Hongyi Xu, Thiemo Alldieck, Cristian Sminchisescu
- **Comment**: None
- **Journal**: None
- **Summary**: We present neural radiance fields for rendering and temporal (4D) reconstruction of humans in motion (H-NeRF), as captured by a sparse set of cameras or even from a monocular video. Our approach combines ideas from neural scene representation, novel-view synthesis, and implicit statistical geometric human representations, coupled using novel loss functions. Instead of learning a radiance field with a uniform occupancy prior, we constrain it by a structured implicit human body model, represented using signed distance functions. This allows us to robustly fuse information from sparse views and generalize well beyond the poses or views observed in training. Moreover, we apply geometric constraints to co-learn the structure of the observed subject -- including both body and clothing -- and to regularize the radiance field to geometrically plausible solutions. Extensive experiments on multiple datasets demonstrate the robustness and the accuracy of our approach, its generalization capabilities significantly outside a small training set of poses and views, and statistical extrapolation beyond the observed shape.



### DPCOVID: Privacy-Preserving Federated Covid-19 Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.13760v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13760v1)
- **Published**: 2021-10-26 15:09:00+00:00
- **Updated**: 2021-10-26 15:09:00+00:00
- **Authors**: Trang-Thi Ho, Yennun-Huang
- **Comment**: 7 pages, 8 Figures, 4 Tables
- **Journal**: None
- **Summary**: Coronavirus (COVID-19) has shown an unprecedented global crisis by the detrimental effect on the global economy and health. The number of COVID-19 cases has been rapidly increasing, and there is no sign of stopping. It leads to a severe shortage of test kits and accurate detection models. A recent study demonstrated that the chest X-ray radiography outperformed laboratory testing in COVID-19 detection. Therefore, using chest X-ray radiography analysis can help to screen suspected COVID-19 cases at an early stage. Moreover, the patient data is sensitive, and it must be protected to avoid revealing through model updates and reconstruction from the malicious attacker. In this paper, we present a privacy-preserving Federated Learning system for COVID-19 detection based on chest X-ray images. First, a Federated Learning system is constructed from chest X-ray images. The main idea is to build a decentralized model across multiple hospitals without sharing data among hospitals. Second, we first show that the accuracy of Federated Learning for COVID-19 identification reduces significantly for Non-IID data. We then propose a strategy to improve model's accuracy on Non-IID COVID-19 data by increasing the total number of clients, parallelism (client fraction), and computation per client. Finally, we apply a Differential Privacy Stochastic Gradient Descent (DP-SGD) to enhance the preserving of patient data privacy for our Federated Learning model. A strategy is also proposed to keep the robustness of Federated Learning to ensure the security and accuracy of the model.



### AugMax: Adversarial Composition of Random Augmentations for Robust Training
- **Arxiv ID**: http://arxiv.org/abs/2110.13771v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13771v3)
- **Published**: 2021-10-26 15:23:56+00:00
- **Updated**: 2022-01-01 20:38:35+00:00
- **Authors**: Haotao Wang, Chaowei Xiao, Jean Kossaifi, Zhiding Yu, Anima Anandkumar, Zhangyang Wang
- **Comment**: NeurIPS, 2021
- **Journal**: None
- **Summary**: Data augmentation is a simple yet effective way to improve the robustness of deep neural networks (DNNs). Diversity and hardness are two complementary dimensions of data augmentation to achieve robustness. For example, AugMix explores random compositions of a diverse set of augmentations to enhance broader coverage, while adversarial training generates adversarially hard samples to spot the weakness. Motivated by this, we propose a data augmentation framework, termed AugMax, to unify the two aspects of diversity and hardness. AugMax first randomly samples multiple augmentation operators and then learns an adversarial mixture of the selected operators. Being a stronger form of data augmentation, AugMax leads to a significantly augmented input distribution which makes model training more challenging. To solve this problem, we further design a disentangled normalization module, termed DuBIN (Dual-Batch-and-Instance Normalization), that disentangles the instance-wise feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN leads to significantly improved out-of-distribution robustness, outperforming prior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny ImageNet-C and ImageNet-C. Codes and pretrained models are available: https://github.com/VITA-Group/AugMax.



### Pyramidal Blur Aware X-Corner Chessboard Detector
- **Arxiv ID**: http://arxiv.org/abs/2110.13793v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13793v1)
- **Published**: 2021-10-26 15:46:49+00:00
- **Updated**: 2021-10-26 15:46:49+00:00
- **Authors**: Peter Abeles
- **Comment**: 7 pages
- **Journal**: None
- **Summary**: With camera resolution ever increasing and the need to rapidly recalibrate robotic platforms in less than ideal environments, there is a need for faster and more robust chessboard fiducial marker detectors. A new chessboard detector is proposed that is specifically designed for: high resolution images, focus/motion blur, harsh lighting conditions, and background clutter. This is accomplished using a new x-corner detector, where for the first time blur is estimated and used in a novel way to enhance corner localization, edge validation, and connectivity. Performance is measured and compared against other libraries using a diverse set of images created by combining multiple third party datasets and including new specially crafted scenarios designed to stress the state-of-the-art. The proposed detector has the best F1- Score of 0.97, runs 1.9x faster than next fastest, and is a top performer for corner accuracy, while being the only detector to have consistent good performance in all scenarios.



### CloudFindr: A Deep Learning Cloud Artifact Masker for Satellite DEM Data
- **Arxiv ID**: http://arxiv.org/abs/2110.13819v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13819v1)
- **Published**: 2021-10-26 16:15:17+00:00
- **Updated**: 2021-10-26 16:15:17+00:00
- **Authors**: Kalina Borkiewicz, Viraj Shah, J. P. Naiman, Chuanyue Shen, Stuart Levy, Jeff Carpenter
- **Comment**: None
- **Journal**: None
- **Summary**: Artifact removal is an integral component of cinematic scientific visualization, and is especially challenging with big datasets in which artifacts are difficult to define. In this paper, we describe a method for creating cloud artifact masks which can be used to remove artifacts from satellite imagery using a combination of traditional image processing together with deep learning based on U-Net. Compared to previous methods, our approach does not require multi-channel spectral imagery but performs successfully on single-channel Digital Elevation Models (DEMs). DEMs are a representation of the topography of the Earth and have a variety applications including planetary science, geology, flood modeling, and city planning.



### Real-time division-of-focal-plane polarization imaging system with progressive networks
- **Arxiv ID**: http://arxiv.org/abs/2110.13823v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13823v1)
- **Published**: 2021-10-26 16:19:17+00:00
- **Updated**: 2021-10-26 16:19:17+00:00
- **Authors**: Rongyuan Wu, Yongqiang Zhao, Ning Li, Seong G. Kong
- **Comment**: Submit to IEEE Sensors Journal
- **Journal**: None
- **Summary**: Division-of-focal-plane (DoFP) polarization imaging technical recently has been applied in many fields. However, the images captured by such sensors cannot be used directly because they suffer from instantaneous field-of-view errors and low resolution problem. This paper builds a fast DoFP demosaicing system with proposed progressive polarization demosaicing convolutional neural network (PPDN), which is specifically designed for edge-side GPU devices like Navidia Jetson TX2. The proposed network consists of two parts: reconstruction stage and refining stage. The former recovers four polarization channels from a single DoFP image. The latter fine-tune the four channels to obtain more accurate polarization information. PPDN can be implemented in another version: PPDN-L (large), for the platforms of high computing resources. Experiments show that PPDN can compete with the best existing methods with fewer parameters and faster inference speed and meet the real-time demands of imaging system.



### A Light-weight Interpretable Compositional Model for Nuclei Detection and Weakly-Supervised Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2110.13846v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13846v2)
- **Published**: 2021-10-26 16:44:08+00:00
- **Updated**: 2022-08-10 00:57:51+00:00
- **Authors**: Yixiao Zhang, Adam Kortylewski, Qing Liu, Seyoun Park, Benjamin Green, Elizabeth Engle, Guillermo Almodovar, Ryan Walk, Sigfredo Soto-Diaz, Janis Taube, Alex Szalay, Alan Yuille
- **Comment**: None
- **Journal**: None
- **Summary**: The field of computational pathology has witnessed great advancements since deep neural networks have been widely applied. These networks usually require large numbers of annotated data to train vast parameters. However, it takes significant effort to annotate a large histopathology dataset. We introduce a light-weight and interpretable model for nuclei detection and weakly-supervised segmentation. It only requires annotations on isolated nucleus, rather than on all nuclei in the dataset. Besides, it is a generative compositional model that first locates parts of nucleus, then learns the spatial correlation of the parts to further locate the nucleus. This process brings interpretability in its prediction. Empirical results on an in-house dataset show that in detection, the proposed method achieved comparable or better performance than its deep network counterparts, especially when the annotated data is limited. It also outperforms popular weakly-supervised segmentation methods. The proposed method could be an alternative solution for the data-hungry problem of deep learning methods.



### Defensive Tensorization
- **Arxiv ID**: http://arxiv.org/abs/2110.13859v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13859v1)
- **Published**: 2021-10-26 17:00:16+00:00
- **Updated**: 2021-10-26 17:00:16+00:00
- **Authors**: Adrian Bulat, Jean Kossaifi, Sourav Bhattacharya, Yannis Panagakis, Timothy Hospedales, Georgios Tzimiropoulos, Nicholas D Lane, Maja Pantic
- **Comment**: To be presented at BMVC 2021
- **Journal**: None
- **Summary**: We propose defensive tensorization, an adversarial defence technique that leverages a latent high-order factorization of the network. The layers of a network are first expressed as factorized tensor layers. Tensor dropout is then applied in the latent subspace, therefore resulting in dense reconstructed weights, without the sparsity or perturbations typically induced by the randomization.Our approach can be readily integrated with any arbitrary neural architecture and combined with techniques like adversarial training. We empirically demonstrate the effectiveness of our approach on standard image classification benchmarks. We validate the versatility of our approach across domains and low-precision architectures by considering an audio classification task and binary networks. In all cases, we demonstrate improved performance compared to prior works.



### FL-WBC: Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective
- **Arxiv ID**: http://arxiv.org/abs/2110.13864v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/2110.13864v1)
- **Published**: 2021-10-26 17:13:35+00:00
- **Updated**: 2021-10-26 17:13:35+00:00
- **Authors**: Jingwei Sun, Ang Li, Louis DiValentin, Amin Hassanzadeh, Yiran Chen, Hai Li
- **Comment**: To be appeared in NeurIPS 2021 conference
- **Journal**: None
- **Summary**: Federated learning (FL) is a popular distributed learning framework that trains a global model through iterative communications between a central server and edge devices. Recent works have demonstrated that FL is vulnerable to model poisoning attacks. Several server-based defense approaches (e.g. robust aggregation), have been proposed to mitigate such attacks. However, we empirically show that under extremely strong attacks, these defensive methods fail to guarantee the robustness of FL. More importantly, we observe that as long as the global model is polluted, the impact of attacks on the global model will remain in subsequent rounds even if there are no subsequent attacks. In this work, we propose a client-based defense, named White Blood Cell for Federated Learning (FL-WBC), which can mitigate model poisoning attacks that have already polluted the global model. The key idea of FL-WBC is to identify the parameter space where long-lasting attack effect on parameters resides and perturb that space during local training. Furthermore, we derive a certified robustness guarantee against model poisoning attacks and a convergence guarantee to FedAvg after applying our FL-WBC. We conduct experiments on FasionMNIST and CIFAR10 to evaluate the defense against state-of-the-art model poisoning attacks. The results demonstrate that our method can effectively mitigate model poisoning attack impact on the global model within 5 communication rounds with nearly no accuracy drop under both IID and Non-IID settings. Our defense is also complementary to existing server-based robust aggregation approaches and can further improve the robustness of FL under extremely strong attacks.



### HR-RCNN: Hierarchical Relational Reasoning for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.13892v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13892v2)
- **Published**: 2021-10-26 17:47:01+00:00
- **Updated**: 2021-12-14 22:26:28+00:00
- **Authors**: Hao Chen, Abhinav Shrivastava
- **Comment**: To appear at BMVC 2021
- **Journal**: None
- **Summary**: Incorporating relational reasoning in neural networks for object recognition remains an open problem. Although many attempts have been made for relational reasoning, they generally only consider a single type of relationship. For example, pixel relations through self-attention (e.g., non-local networks), scale relations through feature fusion (e.g., feature pyramid networks), or object relations through graph convolutions (e.g., reasoning-RCNN). Little attention has been given to more generalized frameworks that can reason across these relationships. In this paper, we propose a hierarchical relational reasoning framework (HR-RCNN) for object detection, which utilizes a novel graph attention module (GAM). This GAM is a concise module that enables reasoning across heterogeneous nodes by operating on the graph edges directly. Leveraging heterogeneous relationships, our HR-RCNN shows great improvement on COCO dataset, for both object detection and instance segmentation.



### NeRV: Neural Representations for Videos
- **Arxiv ID**: http://arxiv.org/abs/2110.13903v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2110.13903v1)
- **Published**: 2021-10-26 17:56:23+00:00
- **Updated**: 2021-10-26 17:56:23+00:00
- **Authors**: Hao Chen, Bo He, Hanyu Wang, Yixuan Ren, Ser-Nam Lim, Abhinav Shrivastava
- **Comment**: To appear at NeurIPS 2021
- **Journal**: None
- **Summary**: We propose a novel neural representation for videos (NeRV) which encodes videos in neural networks. Unlike conventional representations that treat videos as frame sequences, we represent videos as neural networks taking frame index as input. Given a frame index, NeRV outputs the corresponding RGB image. Video encoding in NeRV is simply fitting a neural network to video frames and decoding process is a simple feedforward operation. As an image-wise implicit representation, NeRV output the whole image and shows great efficiency compared to pixel-wise implicit representation, improving the encoding speed by 25x to 70x, the decoding speed by 38x to 132x, while achieving better video quality. With such a representation, we can treat videos as neural networks, simplifying several video-related tasks. For example, conventional video compression methods are restricted by a long and complex pipeline, specifically designed for the task. In contrast, with NeRV, we can use any neural network compression method as a proxy for video compression, and achieve comparable performance to traditional frame-based video compression approaches (H.264, HEVC \etc). Besides compression, we demonstrate the generalization of NeRV for video denoising. The source code and pre-trained model can be found at https://github.com/haochen-rye/NeRV.git.



### Frequency Centric Defense Mechanisms against Adversarial Examples
- **Arxiv ID**: http://arxiv.org/abs/2110.13935v1
- **DOI**: 10.1145/3475724.3483610
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13935v1)
- **Published**: 2021-10-26 18:03:38+00:00
- **Updated**: 2021-10-26 18:03:38+00:00
- **Authors**: Sanket B. Shah, Param Raval, Harin Khakhi, Mehul S. Raval
- **Comment**: AdvM '21: Proceedings of the 1st International Workshop on
  Adversarial Learning for Multimedia, at ACM Multimedia '21
- **Journal**: None
- **Summary**: Adversarial example (AE) aims at fooling a Convolution Neural Network by introducing small perturbations in the input image.The proposed work uses the magnitude and phase of the Fourier Spectrum and the entropy of the image to defend against AE. We demonstrate the defense in two ways: by training an adversarial detector and denoising the adversarial effect. Experiments were conducted on the low-resolution CIFAR-10 and high-resolution ImageNet datasets. The adversarial detector has 99% accuracy for FGSM and PGD attacks on the CIFAR-10 dataset. However, the detection accuracy falls to 50% for sophisticated DeepFool and Carlini & Wagner attacks on ImageNet. We overcome the limitation by using autoencoder and show that 70% of AEs are correctly classified after denoising.



### CausalAF: Causal Autoregressive Flow for Safety-Critical Driving Scenario Generation
- **Arxiv ID**: http://arxiv.org/abs/2110.13939v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13939v3)
- **Published**: 2021-10-26 18:07:48+00:00
- **Updated**: 2023-08-19 19:34:30+00:00
- **Authors**: Wenhao Ding, Haohong Lin, Bo Li, Ding Zhao
- **Comment**: Acceptted to CoRL 2022
- **Journal**: None
- **Summary**: Generating safety-critical scenarios, which are crucial yet difficult to collect, provides an effective way to evaluate the robustness of autonomous driving systems. However, the diversity of scenarios and efficiency of generation methods are heavily restricted by the rareness and structure of safety-critical scenarios. Therefore, existing generative models that only estimate distributions from observational data are not satisfying to solve this problem. In this paper, we integrate causality as a prior into the scenario generation and propose a flow-based generative framework, Causal Autoregressive Flow (CausalAF). CausalAF encourages the generative model to uncover and follow the causal relationship among generated objects via novel causal masking operations instead of searching the sample only from observational data. By learning the cause-and-effect mechanism of how the generated scenario causes risk situations rather than just learning correlations from data, CausalAF significantly improves learning efficiency. Extensive experiments on three heterogeneous traffic scenarios illustrate that CausalAF requires much fewer optimization resources to effectively generate safety-critical scenarios. We also show that using generated scenarios as additional training samples empirically improves the robustness of autonomous driving algorithms.



### Collaborative Uncertainty in Multi-Agent Trajectory Forecasting
- **Arxiv ID**: http://arxiv.org/abs/2110.13947v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13947v1)
- **Published**: 2021-10-26 18:27:22+00:00
- **Updated**: 2021-10-26 18:27:22+00:00
- **Authors**: Bohan Tang, Yiqi Zhong, Ulrich Neumann, Gang Wang, Ya Zhang, Siheng Chen
- **Comment**: This paper has been accepted by NeurIPS 2021
- **Journal**: None
- **Summary**: Uncertainty modeling is critical in trajectory forecasting systems for both interpretation and safety reasons. To better predict the future trajectories of multiple agents, recent works have introduced interaction modules to capture interactions among agents. This approach leads to correlations among the predicted trajectories. However, the uncertainty brought by such correlations is neglected. To fill this gap, we propose a novel concept, collaborative uncertainty(CU), which models the uncertainty resulting from the interaction module. We build a general CU-based framework to make a prediction model to learn the future trajectory and the corresponding uncertainty. The CU-based framework is integrated as a plugin module to current state-of-the-art (SOTA) systems and deployed in two special cases based on multivariate Gaussian and Laplace distributions. In each case, we conduct extensive experiments on two synthetic datasets and two public, large-scale benchmarks of trajectory forecasting. The results are promising: 1) The results of synthetic datasets show that CU-based framework allows the model to appropriately approximate the ground-truth distribution. 2) The results of trajectory forecasting benchmarks demonstrate that the CU-based framework steadily helps SOTA systems improve their performances. Especially, the proposed CU-based framework helps VectorNet improve by 57cm regarding Final Displacement Error on nuScenes dataset. 3) The visualization results of CU illustrate that the value of CU is highly related to the amount of the interactive information among agents.



### Can't Fool Me: Adversarially Robust Transformer for Video Understanding
- **Arxiv ID**: http://arxiv.org/abs/2110.13950v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2110.13950v1)
- **Published**: 2021-10-26 18:30:21+00:00
- **Updated**: 2021-10-26 18:30:21+00:00
- **Authors**: Divya Choudhary, Palash Goyal, Saurabh Sahu
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2103.10043
- **Journal**: None
- **Summary**: Deep neural networks have been shown to perform poorly on adversarial examples. To address this, several techniques have been proposed to increase robustness of a model for image classification tasks. However, in video understanding tasks, developing adversarially robust models is still unexplored. In this paper, we aim to bridge this gap. We first show that simple extensions of image based adversarially robust models slightly improve the worst-case performance. Further, we propose a temporal attention regularization scheme in Transformer to improve the robustness of attention modules to adversarial examples. We illustrate using a large-scale video data set YouTube-8M that the final model (A-ART) achieves close to non-adversarial performance on its adversarial example set. We achieve 91% GAP on adversarial examples, whereas baseline Transformer and simple adversarial extensions achieve 72.9% and 82% respectively, showing significant improvement in robustness over the state-of-the-art.



### A Frequency Perspective of Adversarial Robustness
- **Arxiv ID**: http://arxiv.org/abs/2111.00861v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2111.00861v1)
- **Published**: 2021-10-26 19:12:34+00:00
- **Updated**: 2021-10-26 19:12:34+00:00
- **Authors**: Shishira R Maiya, Max Ehrlich, Vatsal Agarwal, Ser-Nam Lim, Tom Goldstein, Abhinav Shrivastava
- **Comment**: None
- **Journal**: None
- **Summary**: Adversarial examples pose a unique challenge for deep learning systems. Despite recent advances in both attacks and defenses, there is still a lack of clarity and consensus in the community about the true nature and underlying properties of adversarial examples. A deep understanding of these examples can provide new insights towards the development of more effective attacks and defenses. Driven by the common misconception that adversarial examples are high-frequency noise, we present a frequency-based understanding of adversarial examples, supported by theoretical and empirical findings. Our analysis shows that adversarial examples are neither in high-frequency nor in low-frequency components, but are simply dataset dependent. Particularly, we highlight the glaring disparities between models trained on CIFAR-10 and ImageNet-derived datasets. Utilizing this framework, we analyze many intriguing properties of training robust models with frequency constraints, and propose a frequency-based explanation for the commonly observed accuracy vs. robustness trade-off.



### Video-based fully automatic assessment of open surgery suturing skills
- **Arxiv ID**: http://arxiv.org/abs/2110.13972v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13972v2)
- **Published**: 2021-10-26 19:21:40+00:00
- **Updated**: 2022-01-08 07:51:05+00:00
- **Authors**: Adam Goldbraikh, Anne-Lise D'Angelo, Carla M. Pugh, Shlomi Laufer
- **Comment**: 12 pages, 5 figures, Accepted at IJCARS
- **Journal**: None
- **Summary**: The goal of this study was to develop new reliable open surgery suturing simulation system for training medical students in situation where resources are limited or in the domestic setup. Namely, we developed an algorithm for tools and hands localization as well as identifying the interactions between them based on simple webcam video data, calculating motion metrics for assessment of surgical skill. Twenty-five participants performed multiple suturing tasks using our simulator. The YOLO network has been modified to a multi-task network, for the purpose of tool localization and tool-hand interaction detection. This was accomplished by splitting the YOLO detection heads so that they supported both tasks with minimal addition to computer run-time. Furthermore, based on the outcome of the system, motion metrics were calculated. These metrics included traditional metrics such as time and path length as well as new metrics assessing the technique participants use for holding the tools. The dual-task network performance was similar to that of two networks, while computational load was only slightly bigger than one network. In addition, the motion metrics showed significant differences between experts and novices. While video capture is an essential part of minimally invasive surgery, it is not an integral component of open surgery. Thus, new algorithms, focusing on the unique challenges open surgery videos present, are required. In this study, a dual-task network was developed to solve both a localization task and a hand-tool interaction task. The dual network may be easily expanded to a multi-task network, which may be useful for images with multiple layers and for evaluating the interaction between these different layers.



### CHIP: CHannel Independence-based Pruning for Compact Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2110.13981v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13981v3)
- **Published**: 2021-10-26 19:35:56+00:00
- **Updated**: 2022-04-03 08:11:33+00:00
- **Authors**: Yang Sui, Miao Yin, Yi Xie, Huy Phan, Saman Zonouz, Bo Yuan
- **Comment**: Accepted by NeurIPS 2021. Model Compression, Channel Pruning, Filter
  Pruning, Deep Learning
- **Journal**: None
- **Summary**: Filter pruning has been widely used for neural network compression because of its enabled practical acceleration. To date, most of the existing filter pruning works explore the importance of filters via using intra-channel information. In this paper, starting from an inter-channel perspective, we propose to perform efficient filter pruning using Channel Independence, a metric that measures the correlations among different feature maps. The less independent feature map is interpreted as containing less useful information$/$knowledge, and hence its corresponding filter can be pruned without affecting model capacity. We systematically investigate the quantification metric, measuring scheme and sensitiveness$/$reliability of channel independence in the context of filter pruning. Our evaluation results for different models on various datasets show the superior performance of our approach. Notably, on CIFAR-10 dataset our solution can bring $0.90\%$ and $0.94\%$ accuracy increase over baseline ResNet-56 and ResNet-110 models, respectively, and meanwhile the model size and FLOPs are reduced by $42.8\%$ and $47.4\%$ (for ResNet-56) and $48.3\%$ and $52.1\%$ (for ResNet-110), respectively. On ImageNet dataset, our approach can achieve $40.8\%$ and $44.8\%$ storage and computation reductions, respectively, with $0.15\%$ accuracy increase over the baseline ResNet-50 model. The code is available at https://github.com/Eclipsess/CHIP_NeurIPS2021.



### Revisiting Batch Norm Initialization
- **Arxiv ID**: http://arxiv.org/abs/2110.13989v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.13989v2)
- **Published**: 2021-10-26 19:48:19+00:00
- **Updated**: 2022-07-14 21:35:24+00:00
- **Authors**: Jim Davis, Logan Frank
- **Comment**: European Conference on Computer Vision, October 2022
- **Journal**: None
- **Summary**: Batch normalization (BN) is comprised of a normalization component followed by an affine transformation and has become essential for training deep neural networks. Standard initialization of each BN in a network sets the affine transformation scale and shift to 1 and 0, respectively. However, after training we have observed that these parameters do not alter much from their initialization. Furthermore, we have noticed that the normalization process can still yield overly large values, which is undesirable for training. We revisit the BN formulation and present a new initialization method and update approach for BN to address the aforementioned issues. Experiments are designed to emphasize and demonstrate the positive influence of proper BN scale initialization on performance, and use rigorous statistical significance tests for evaluation. The approach can be used with existing implementations at no additional computational cost. Source code is available at https://github.com/osu-cvl/revisiting-bn-init.



### Leveraging Local Temporal Information for Multimodal Scene Classification
- **Arxiv ID**: http://arxiv.org/abs/2110.13992v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13992v1)
- **Published**: 2021-10-26 19:58:32+00:00
- **Updated**: 2021-10-26 19:58:32+00:00
- **Authors**: Saurabh Sahu, Palash Goyal
- **Comment**: None
- **Journal**: None
- **Summary**: Robust video scene classification models should capture the spatial (pixel-wise) and temporal (frame-wise) characteristics of a video effectively. Transformer models with self-attention which are designed to get contextualized representations for individual tokens given a sequence of tokens, are becoming increasingly popular in many computer vision tasks. However, the use of Transformer based models for video understanding is still relatively unexplored. Moreover, these models fail to exploit the strong temporal relationships between the neighboring video frames to get potent frame-level representations. In this paper, we propose a novel self-attention block that leverages both local and global temporal relationships between the video frames to obtain better contextualized representations for the individual frames. This enables the model to understand the video at various granularities. We illustrate the performance of our models on the large scale YoutTube-8M data set on the task of video categorization and further analyze the results to showcase improvement.



### Controllable Data Augmentation Through Deep Relighting
- **Arxiv ID**: http://arxiv.org/abs/2110.13996v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.13996v1)
- **Published**: 2021-10-26 20:02:51+00:00
- **Updated**: 2021-10-26 20:02:51+00:00
- **Authors**: George Chogovadze, Rémi Pautrat, Marc Pollefeys
- **Comment**: None
- **Journal**: None
- **Summary**: At the heart of the success of deep learning is the quality of the data. Through data augmentation, one can train models with better generalization capabilities and thus achieve greater results in their field of interest. In this work, we explore how to augment a varied set of image datasets through relighting so as to improve the ability of existing models to be invariant to illumination changes, namely for learned descriptors. We develop a tool, based on an encoder-decoder network, that is able to quickly generate multiple variations of the illumination of various input scenes whilst also allowing the user to define parameters such as the angle of incidence and intensity. We demonstrate that by training models on datasets that have been augmented with our pipeline, it is possible to achieve higher performance on localization benchmarks.



### MisConv: Convolutional Neural Networks for Missing Data
- **Arxiv ID**: http://arxiv.org/abs/2110.14010v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.14010v2)
- **Published**: 2021-10-26 20:39:36+00:00
- **Updated**: 2021-10-29 10:09:46+00:00
- **Authors**: Marcin Przewięźlikowski, Marek Śmieja, Łukasz Struski, Jacek Tabor
- **Comment**: Accepted for publication at WACV 2022 Conference
- **Journal**: None
- **Summary**: Processing of missing data by modern neural networks, such as CNNs, remains a fundamental, yet unsolved challenge, which naturally arises in many practical applications, like image inpainting or autonomous vehicles and robots. While imputation-based techniques are still one of the most popular solutions, they frequently introduce unreliable information to the data and do not take into account the uncertainty of estimation, which may be destructive for a machine learning model. In this paper, we present MisConv, a general mechanism, for adapting various CNN architectures to process incomplete images. By modeling the distribution of missing values by the Mixture of Factor Analyzers, we cover the spectrum of possible replacements and find an analytical formula for the expected value of convolution operator applied to the incomplete image. The whole framework is realized by matrix operations, which makes MisConv extremely efficient in practice. Experiments performed on various image processing tasks demonstrate that MisConv achieves superior or comparable performance to the state-of-the-art methods.



### Deep Integrated Pipeline of Segmentation Guided Classification of Breast Cancer from Ultrasound Images
- **Arxiv ID**: http://arxiv.org/abs/2110.14013v2
- **DOI**: 10.1016/j.bspc.2022.103553
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.14013v2)
- **Published**: 2021-10-26 20:42:39+00:00
- **Updated**: 2022-02-14 06:53:35+00:00
- **Authors**: Muhammad Sakib Khan Inan, Fahim Irfan Alam, Rizwan Hasan
- **Comment**: Accepted for publication as a Research Paper (Journal Article) in
  Biomedical Signal Processing and Control, Elsevier
- **Journal**: None
- **Summary**: Breast cancer has become a symbol of tremendous concern in the modern world, as it is one of the major causes of cancer mortality worldwide. In this regard, breast ultrasonography images are frequently utilized by doctors to diagnose breast cancer at an early stage. However, the complex artifacts and heavily noised breast ultrasonography images make diagnosis a great challenge. Furthermore, the ever-increasing number of patients being screened for breast cancer necessitates the use of automated end-to-end technology for highly accurate diagnosis at a low cost and in a short time. In this concern, to develop an end-to-end integrated pipeline for breast ultrasonography image classification, we conducted an exhaustive analysis of image preprocessing methods such as K Means++ and SLIC, as well as four transfer learning models such as VGG16, VGG19, DenseNet121, and ResNet50. With a Dice-coefficient score of 63.4 in the segmentation stage and accuracy and an F1-Score (Benign) of 73.72 percent and 78.92 percent in the classification stage, the combination of SLIC, UNET, and VGG16 outperformed all other integrated combinations. Finally, we have proposed an end to end integrated automated pipelining framework which includes preprocessing with SLIC to capture super-pixel features from the complex artifact of ultrasonography images, complementing semantic segmentation with modified U-Net, leading to breast tumor classification using a transfer learning approach with a pre-trained VGG16 and a densely connected neural network. The proposed automated pipeline can be effectively implemented to assist medical practitioners in making more accurate and timely diagnoses of breast cancer.



### Improving Local Effectiveness for Global robust training
- **Arxiv ID**: http://arxiv.org/abs/2110.14030v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.14030v1)
- **Published**: 2021-10-26 21:12:28+00:00
- **Updated**: 2021-10-26 21:12:28+00:00
- **Authors**: Jingyue Lu, M. Pawan Kumar
- **Comment**: None
- **Journal**: None
- **Summary**: Despite its popularity, deep neural networks are easily fooled. To alleviate this deficiency, researchers are actively developing new training strategies, which encourage models that are robust to small input perturbations. Several successful robust training methods have been proposed. However, many of them rely on strong adversaries, which can be prohibitively expensive to generate when the input dimension is high and the model structure is complicated. We adopt a new perspective on robustness and propose a novel training algorithm that allows a more effective use of adversaries. Our method improves the model robustness at each local ball centered around an adversary and then, by combining these local balls through a global term, achieves overall robustness. We demonstrate that, by maximizing the use of adversaries via focusing on local balls, we achieve high robust accuracy with weak adversaries. Specifically, our method reaches a similar robust accuracy level to the state of the art approaches trained on strong adversaries on MNIST, CIFAR-10 and CIFAR-100. As a result, the overall training time is reduced. Furthermore, when trained with strong adversaries, our method matches with the current state of the art on MNIST and outperforms them on CIFAR-10 and CIFAR-100.



### MEST: Accurate and Fast Memory-Economic Sparse Training Framework on the Edge
- **Arxiv ID**: http://arxiv.org/abs/2110.14032v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2110.14032v1)
- **Published**: 2021-10-26 21:15:17+00:00
- **Updated**: 2021-10-26 21:15:17+00:00
- **Authors**: Geng Yuan, Xiaolong Ma, Wei Niu, Zhengang Li, Zhenglun Kong, Ning Liu, Yifan Gong, Zheng Zhan, Chaoyang He, Qing Jin, Siyue Wang, Minghai Qin, Bin Ren, Yanzhi Wang, Sijia Liu, Xue Lin
- **Comment**: NeurIPS 2021 Spotlight Paper
- **Journal**: None
- **Summary**: Recently, a new trend of exploring sparsity for accelerating neural network training has emerged, embracing the paradigm of training on the edge. This paper proposes a novel Memory-Economic Sparse Training (MEST) framework targeting for accurate and fast execution on edge devices. The proposed MEST framework consists of enhancements by Elastic Mutation (EM) and Soft Memory Bound (&S) that ensure superior accuracy at high sparsity ratios. Different from the existing works for sparse training, this current work reveals the importance of sparsity schemes on the performance of sparse training in terms of accuracy as well as training speed on real edge devices. On top of that, the paper proposes to employ data efficiency for further acceleration of sparse training. Our results suggest that unforgettable examples can be identified in-situ even during the dynamic exploration of sparsity masks in the sparse training process, and therefore can be removed for further training speedup on edge devices. Comparing with state-of-the-art (SOTA) works on accuracy, our MEST increases Top-1 accuracy significantly on ImageNet when using the same unstructured sparsity scheme. Systematical evaluation on accuracy, training speed, and memory footprint are conducted, where the proposed MEST framework consistently outperforms representative SOTA works. A reviewer strongly against our work based on his false assumptions and misunderstandings. On top of the previous submission, we employ data efficiency for further acceleration of sparse training. And we explore the impact of model sparsity, sparsity schemes, and sparse training algorithms on the number of removable training examples. Our codes are publicly available at: https://github.com/boone891214/MEST.



### A Unified Survey on Anomaly, Novelty, Open-Set, and Out-of-Distribution Detection: Solutions and Future Challenges
- **Arxiv ID**: http://arxiv.org/abs/2110.14051v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.14051v5)
- **Published**: 2021-10-26 22:05:31+00:00
- **Updated**: 2022-12-03 15:10:18+00:00
- **Authors**: Mohammadreza Salehi, Hossein Mirzaei, Dan Hendrycks, Yixuan Li, Mohammad Hossein Rohban, Mohammad Sabokrou
- **Comment**: Published in Transaction on Machine Learning (TMLR)
- **Journal**: None
- **Summary**: Machine learning models often encounter samples that are diverged from the training distribution. Failure to recognize an out-of-distribution (OOD) sample, and consequently assign that sample to an in-class label significantly compromises the reliability of a model. The problem has gained significant attention due to its importance for safety deploying models in open-world settings. Detecting OOD samples is challenging due to the intractability of modeling all possible unknown distributions. To date, several research domains tackle the problem of detecting unfamiliar samples, including anomaly detection, novelty detection, one-class learning, open set recognition, and out-of-distribution detection. Despite having similar and shared concepts, out-of-distribution, open-set, and anomaly detection have been investigated independently. Accordingly, these research avenues have not cross-pollinated, creating research barriers. While some surveys intend to provide an overview of these approaches, they seem to only focus on a specific domain without examining the relationship between different domains. This survey aims to provide a cross-domain and comprehensive review of numerous eminent works in respective areas while identifying their commonalities. Researchers can benefit from the overview of research advances in different fields and develop future methodology synergistically. Furthermore, to the best of our knowledge, while there are surveys in anomaly detection or one-class learning, there is no comprehensive or up-to-date survey on out-of-distribution detection, which our survey covers extensively. Finally, having a unified cross-domain perspective, we discuss and shed light on future lines of research, intending to bring these fields closer together.



### Increasing Liquid State Machine Performance with Edge-of-Chaos Dynamics Organized by Astrocyte-modulated Plasticity
- **Arxiv ID**: http://arxiv.org/abs/2111.01760v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2111.01760v1)
- **Published**: 2021-10-26 23:04:40+00:00
- **Updated**: 2021-10-26 23:04:40+00:00
- **Authors**: Vladimir A. Ivanov, Konstantinos P. Michmizos
- **Comment**: 23 pages, 9 figures, NeurIPS 2021
- **Journal**: 35th Conference on Neural Information Processing Systems (NeurIPS
  2021)
- **Summary**: The liquid state machine (LSM) combines low training complexity and biological plausibility, which has made it an attractive machine learning framework for edge and neuromorphic computing paradigms. Originally proposed as a model of brain computation, the LSM tunes its internal weights without backpropagation of gradients, which results in lower performance compared to multi-layer neural networks. Recent findings in neuroscience suggest that astrocytes, a long-neglected non-neuronal brain cell, modulate synaptic plasticity and brain dynamics, tuning brain networks to the vicinity of the computationally optimal critical phase transition between order and chaos. Inspired by this disruptive understanding of how brain networks self-tune, we propose the neuron-astrocyte liquid state machine (NALSM) that addresses under-performance through self-organized near-critical dynamics. Similar to its biological counterpart, the astrocyte model integrates neuronal activity and provides global feedback to spike-timing-dependent plasticity (STDP), which self-organizes NALSM dynamics around a critical branching factor that is associated with the edge-of-chaos. We demonstrate that NALSM achieves state-of-the-art accuracy versus comparable LSM methods, without the need for data-specific hand-tuning. With a top accuracy of 97.61% on MNIST, 97.51% on N-MNIST, and 85.84% on Fashion-MNIST, NALSM achieved comparable performance to current fully-connected multi-layer spiking neural networks trained via backpropagation. Our findings suggest that the further development of brain-inspired machine learning methods has the potential to reach the performance of deep learning, with the added benefits of supporting robust and energy-efficient neuromorphic computing on the edge.



### CoFiNet: Reliable Coarse-to-fine Correspondences for Robust Point Cloud Registration
- **Arxiv ID**: http://arxiv.org/abs/2110.14076v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.14076v1)
- **Published**: 2021-10-26 23:05:00+00:00
- **Updated**: 2021-10-26 23:05:00+00:00
- **Authors**: Hao Yu, Fu Li, Mahdi Saleh, Benjamin Busam, Slobodan Ilic
- **Comment**: Accepted to NeurIPS 2021
- **Journal**: None
- **Summary**: We study the problem of extracting correspondences between a pair of point clouds for registration. For correspondence retrieval, existing works benefit from matching sparse keypoints detected from dense points but usually struggle to guarantee their repeatability. To address this issue, we present CoFiNet - Coarse-to-Fine Network which extracts hierarchical correspondences from coarse to fine without keypoint detection. On a coarse scale and guided by a weighting scheme, our model firstly learns to match down-sampled nodes whose vicinity points share more overlap, which significantly shrinks the search space of a consecutive stage. On a finer scale, node proposals are consecutively expanded to patches that consist of groups of points together with associated descriptors. Point correspondences are then refined from the overlap areas of corresponding patches, by a density-adaptive matching module capable to deal with varying point density. Extensive evaluation of CoFiNet on both indoor and outdoor standard benchmarks shows our superiority over existing methods. Especially on 3DLoMatch where point clouds share less overlap, CoFiNet significantly outperforms state-of-the-art approaches by at least 5% on Registration Recall, with at most two-third of their parameters.



