# Arxiv Papers in cs.CV on 2021-10-18
### Uncertainty-Aware Semi-Supervised Few Shot Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2110.08954v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.08954v1)
- **Published**: 2021-10-18 00:37:46+00:00
- **Updated**: 2021-10-18 00:37:46+00:00
- **Authors**: Soopil Kim, Philip Chikontwe, Sang Hyun Park
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Few shot segmentation (FSS) aims to learn pixel-level classification of a target object in a query image using only a few annotated support samples. This is challenging as it requires modeling appearance variations of target objects and the diverse visual cues between query and support images with limited information. To address this problem, we propose a semi-supervised FSS strategy that leverages additional prototypes from unlabeled images with uncertainty guided pseudo label refinement. To obtain reliable prototypes from unlabeled images, we meta-train a neural network to jointly predict segmentation and estimate the uncertainty of predictions. We employ the uncertainty estimates to exclude predictions with high degrees of uncertainty for pseudo label construction to obtain additional prototypes based on the refined pseudo labels. During inference, query segmentation is predicted using prototypes from both support and unlabeled images including low-level features of the query images. Our approach is end-to-end and can easily supplement existing approaches without the requirement of additional training to employ unlabeled samples. Extensive experiments on PASCAL-$5^i$ and COCO-$20^i$ demonstrate that our model can effectively remove unreliable predictions to refine pseudo labels and significantly improve upon state-of-the-art performances.



### Predicting Rebar Endpoints using Sin Exponential Regression Model
- **Arxiv ID**: http://arxiv.org/abs/2110.08955v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.08955v1)
- **Published**: 2021-10-18 00:38:00+00:00
- **Updated**: 2021-10-18 00:38:00+00:00
- **Authors**: Jong-Chan Park, Hye-Youn Lim, Dae-Seong Kang
- **Comment**: None
- **Journal**: None
- **Summary**: Currently, unmanned automation studies are underway to minimize the loss rate of rebar production and the time and accuracy of calibration when producing defective products in the cutting process of processing rebar factories. In this paper, we propose a method to detect and track rebar endpoint images entering the machine vision camera based on YOLO (You Only Look Once)v3, and to predict rebar endpoint in advance with sin exponential regression of acquired coordinates. The proposed method solves the problem of large prediction error rates for frame locations where rebar endpoints are far away in OPPDet (Object Position Prediction Detect) models, which prepredict rebar endpoints with improved results showing 0.23 to 0.52% less error rates at sin exponential regression prediction points.



### Accurate and Robust Object-oriented SLAM with 3D Quadric Landmark Construction in Outdoor Environment
- **Arxiv ID**: http://arxiv.org/abs/2110.08977v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.08977v1)
- **Published**: 2021-10-18 02:03:51+00:00
- **Updated**: 2021-10-18 02:03:51+00:00
- **Authors**: Rui Tian, Yunzhou Zhang, Yonghui Feng, Linghao Yang, Zhenzhong Cao, Sonya Coleman, Dermot Kerr
- **Comment**: Submitting to RA-L
- **Journal**: None
- **Summary**: Object-oriented SLAM is a popular technology in autonomous driving and robotics. In this paper, we propose a stereo visual SLAM with a robust quadric landmark representation method. The system consists of four components, including deep learning detection, object-oriented data association, dual quadric landmark initialization and object-based pose optimization. State-of-the-art quadric-based SLAM algorithms always face observation related problems and are sensitive to observation noise, which limits their application in outdoor scenes. To solve this problem, we propose a quadric initialization method based on the decoupling of the quadric parameters method, which improves the robustness to observation noise. The sufficient object data association algorithm and object-oriented optimization with multiple cues enables a highly accurate object pose estimation that is robust to local observations. Experimental results show that the proposed system is more robust to observation noise and significantly outperforms current state-of-the-art methods in outdoor environments. In addition, the proposed system demonstrates real-time performance.



### StyleNeRF: A Style-based 3D-Aware Generator for High-resolution Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2110.08985v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.08985v1)
- **Published**: 2021-10-18 02:37:01+00:00
- **Updated**: 2021-10-18 02:37:01+00:00
- **Authors**: Jiatao Gu, Lingjie Liu, Peng Wang, Christian Theobalt
- **Comment**: 24 pages, 19 figures. Project page: http://jiataogu.me/style_nerf/
- **Journal**: None
- **Summary**: We propose StyleNeRF, a 3D-aware generative model for photo-realistic high-resolution image synthesis with high multi-view consistency, which can be trained on unstructured 2D images. Existing approaches either cannot synthesize high-resolution images with fine details or yield noticeable 3D-inconsistent artifacts. In addition, many of them lack control over style attributes and explicit 3D camera poses. StyleNeRF integrates the neural radiance field (NeRF) into a style-based generator to tackle the aforementioned challenges, i.e., improving rendering efficiency and 3D consistency for high-resolution image generation. We perform volume rendering only to produce a low-resolution feature map and progressively apply upsampling in 2D to address the first issue. To mitigate the inconsistencies caused by 2D upsampling, we propose multiple designs, including a better upsampler and a new regularization loss. With these designs, StyleNeRF can synthesize high-resolution images at interactive rates while preserving 3D consistency at high quality. StyleNeRF also enables control of camera poses and different levels of styles, which can generalize to unseen views. It also supports challenging tasks, including zoom-in and-out, style mixing, inversion, and semantic editing.



### FEANet: Feature-Enhanced Attention Network for RGB-Thermal Real-time Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2110.08988v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.08988v1)
- **Published**: 2021-10-18 02:43:41+00:00
- **Updated**: 2021-10-18 02:43:41+00:00
- **Authors**: Fuqin Deng, Hua Feng, Mingjian Liang, Hongmin Wang, Yong Yang, Yuan Gao, Junfeng Chen, Junjie Hu, Xiyue Guo, Tin Lun Lam
- **Comment**: 7 pages, 5 figures
- **Journal**: None
- **Summary**: The RGB-Thermal (RGB-T) information for semantic segmentation has been extensively explored in recent years. However, most existing RGB-T semantic segmentation usually compromises spatial resolution to achieve real-time inference speed, which leads to poor performance. To better extract detail spatial information, we propose a two-stage Feature-Enhanced Attention Network (FEANet) for the RGB-T semantic segmentation task. Specifically, we introduce a Feature-Enhanced Attention Module (FEAM) to excavate and enhance multi-level features from both the channel and spatial views. Benefited from the proposed FEAM module, our FEANet can preserve the spatial information and shift more attention to high-resolution features from the fused RGB-T images. Extensive experiments on the urban scene dataset demonstrate that our FEANet outperforms other state-of-the-art (SOTA) RGB-T methods in terms of objective metrics and subjective visual comparison (+2.6% in global mAcc and +0.8% in global mIoU). For the 480 x 640 RGB-T test images, our FEANet can run with a real-time speed on an NVIDIA GeForce RTX 2080 Ti card.



### CMTR: Cross-modality Transformer for Visible-infrared Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/2110.08994v1
- **DOI**: 10.1109/TMM.2023.3237155
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.08994v1)
- **Published**: 2021-10-18 03:12:59+00:00
- **Updated**: 2021-10-18 03:12:59+00:00
- **Authors**: Tengfei Liang, Yi Jin, Yajun Gao, Wu Liu, Songhe Feng, Tao Wang, Yidong Li
- **Comment**: 11 pages, 7 figures, 7 tables
- **Journal**: 2023 IEEE Transactions on Multimedia (TMM)
- **Summary**: Visible-infrared cross-modality person re-identification is a challenging ReID task, which aims to retrieve and match the same identity's images between the heterogeneous visible and infrared modalities. Thus, the core of this task is to bridge the huge gap between these two modalities. The existing convolutional neural network-based methods mainly face the problem of insufficient perception of modalities' information, and can not learn good discriminative modality-invariant embeddings for identities, which limits their performance. To solve these problems, we propose a cross-modality transformer-based method (CMTR) for the visible-infrared person re-identification task, which can explicitly mine the information of each modality and generate better discriminative features based on it. Specifically, to capture modalities' characteristics, we design the novel modality embeddings, which are fused with token embeddings to encode modalities' information. Furthermore, to enhance representation of modality embeddings and adjust matching embeddings' distribution, we propose a modality-aware enhancement loss based on the learned modalities' information, reducing intra-class distance and enlarging inter-class distance. To our knowledge, this is the first work of applying transformer network to the cross-modality re-identification task. We implement extensive experiments on the public SYSU-MM01 and RegDB datasets, and our proposed CMTR model's performance significantly surpasses existing outstanding CNN-based methods.



### NYU-VPR: Long-Term Visual Place Recognition Benchmark with View Direction and Data Anonymization Influences
- **Arxiv ID**: http://arxiv.org/abs/2110.09004v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09004v2)
- **Published**: 2021-10-18 03:56:33+00:00
- **Updated**: 2022-07-25 05:43:04+00:00
- **Authors**: Diwei Sheng, Yuxiang Chai, Xinru Li, Chen Feng, Jianzhe Lin, Claudio Silva, John-Ross Rizzo
- **Comment**: 8 pages, 10 figures, published in 2021 IEEE/RSJ International
  Conference on Intelligent Robots and Systems (IROS 2021)
- **Journal**: None
- **Summary**: Visual place recognition (VPR) is critical in not only localization and mapping for autonomous driving vehicles, but also in assistive navigation for the visually impaired population. To enable a long-term VPR system on a large scale, several challenges need to be addressed. First, different applications could require different image view directions, such as front views for self-driving cars while side views for the low vision people. Second, VPR in metropolitan scenes can often cause privacy concerns due to the imaging of pedestrian and vehicle identity information, calling for the need for data anonymization before VPR queries and database construction. Both factors could lead to VPR performance variations that are not well understood yet. To study their influences, we present the NYU-VPR dataset that contains more than 200,000 images over a 2km by 2km area near the New York University campus, taken within the whole year of 2016. We present benchmark results on several popular VPR algorithms showing that side views are significantly more challenging for current VPR methods while the influence of data anonymization is almost negligible, together with our hypothetical explanations and in-depth analysis.



### Natural Image Reconstruction from fMRI using Deep Learning: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2110.09006v2
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.09006v2)
- **Published**: 2021-10-18 04:05:29+00:00
- **Updated**: 2021-11-25 04:46:45+00:00
- **Authors**: Zarina Rakhimberdina, Quentin Jodelet, Xin Liu, Tsuyoshi Murata
- **Comment**: Accepted for publication in Frontiers in Neuroscience
- **Journal**: https://www.frontiersin.org/articles/10.3389/fnins.2021.795488/abstract
- **Summary**: With the advent of brain imaging techniques and machine learning tools, much effort has been devoted to building computational models to capture the encoding of visual information in the human brain. One of the most challenging brain decoding tasks is the accurate reconstruction of the perceived natural images from brain activities measured by functional magnetic resonance imaging (fMRI). In this work, we survey the most recent deep learning methods for natural image reconstruction from fMRI. We examine these methods in terms of architectural design, benchmark datasets, and evaluation metrics and present a fair performance evaluation across standardized evaluation metrics. Finally, we discuss the strengths and limitations of existing studies and present potential future directions.



### Mitigating Memorization of Noisy Labels via Regularization between Representations
- **Arxiv ID**: http://arxiv.org/abs/2110.09022v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09022v3)
- **Published**: 2021-10-18 05:41:57+00:00
- **Updated**: 2022-05-26 09:58:47+00:00
- **Authors**: Hao Cheng, Zhaowei Zhu, Xing Sun, Yang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Designing robust loss functions is popular in learning with noisy labels while existing designs did not explicitly consider the overfitting property of deep neural networks (DNNs). As a result, applying these losses may still suffer from overfitting/memorizing noisy labels as training proceeds. In this paper, we first theoretically analyze the memorization effect and show that a lower-capacity model may perform better on noisy datasets. However, it is non-trivial to design a neural network with the best capacity given an arbitrary task. To circumvent this dilemma, instead of changing the model architecture, we decouple DNNs into an encoder followed by a linear classifier and propose to restrict the function space of a DNN by a representation regularizer. Particularly, we require the distance between two self-supervised features to be positively related to the distance between the corresponding two supervised model outputs. Our proposed framework is easily extendable and can incorporate many other robust loss functions to further improve performance. Extensive experiments and theoretical analyses support our claims. Code is available at github.com/UCSC-REAL/SelfSup_NoisyLabel.



### Utilizing Active Machine Learning for Quality Assurance: A Case Study of Virtual Car Renderings in the Automotive Industry
- **Arxiv ID**: http://arxiv.org/abs/2110.09023v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09023v1)
- **Published**: 2021-10-18 05:43:06+00:00
- **Updated**: 2021-10-18 05:43:06+00:00
- **Authors**: Patrick Hemmer, Niklas Kühl, Jakob Schöffer
- **Comment**: Hawaii International Conference on System Sciences 2022 (HICSS-55)
- **Journal**: None
- **Summary**: Computer-generated imagery of car models has become an indispensable part of car manufacturers' advertisement concepts. They are for instance used in car configurators to offer customers the possibility to configure their car online according to their personal preferences. However, human-led quality assurance faces the challenge to keep up with high-volume visual inspections due to the car models' increasing complexity. Even though the application of machine learning to many visual inspection tasks has demonstrated great success, its need for large labeled data sets remains a central barrier to using such systems in practice. In this paper, we propose an active machine learning-based quality assurance system that requires significantly fewer labeled instances to identify defective virtual car renderings without compromising performance. By employing our system at a German automotive manufacturer, start-up difficulties can be overcome, the inspection process efficiency can be increased, and thus economic advantages can be realized.



### Fast tree skeleton extraction using voxel thinning based on tree point cloud
- **Arxiv ID**: http://arxiv.org/abs/2110.09028v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09028v1)
- **Published**: 2021-10-18 05:57:00+00:00
- **Updated**: 2021-10-18 05:57:00+00:00
- **Authors**: Jingqian Sun, Pei Wang, Ronghao Li, Mei Zhou
- **Comment**: None
- **Journal**: None
- **Summary**: Tree skeleton plays an important role in tree structure analysis, forest inventory and ecosystem monitoring. However, it is a challenge to extract a skeleton from a tree point cloud with complex branches. In this paper, an automatic and fast tree skeleton extraction method (FTSEM) based on voxel thinning is proposed. In this method, a wood-leaf classification algorithm was introduced to filter leaf points for the reduction of the leaf interference on tree skeleton generation, tree voxel thinning was adopted to extract raw tree skeleton quickly, and a breakpoint connection algorithm was used to improve the skeleton connectivity and completeness. Experiments were carried out in Haidian Park, Beijing, in which 24 trees were scanned and processed to obtain tree skeletons. The graph search algorithm (GSA) is used to extract tree skeletons based on the same datasets. Compared with GSA method, the FTSEM method obtained more complete tree skeletons. And the time cost of the FTSEM method is evaluated using the runtime and time per million points (TPMP). The runtime of FTSEM is from 1.0 s to 13.0 s, and the runtime of GSA is from 6.4 s to 309.3 s. The average value of TPMP is 1.8 s for FTSEM, and 22.3 s for GSA respectively. The experimental results demonstrate that the proposed method is feasible, robust, and fast with a good potential on tree skeleton extraction.



### Abnormal Occupancy Grid Map Recognition using Attention Network
- **Arxiv ID**: http://arxiv.org/abs/2110.09047v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09047v1)
- **Published**: 2021-10-18 06:37:21+00:00
- **Updated**: 2021-10-18 06:37:21+00:00
- **Authors**: Fuqin Deng, Hua Feng, Mingjian Liang, Qi Feng, Ningbo Yi, Yong Yang, Yuan Gao, Junfeng Chen, Tin Lun Lam
- **Comment**: None
- **Journal**: None
- **Summary**: The occupancy grid map is a critical component of autonomous positioning and navigation in the mobile robotic system, as many other systems' performance depends heavily on it. To guarantee the quality of the occupancy grid maps, researchers previously had to perform tedious manual recognition for a long time. This work focuses on automatic abnormal occupancy grid map recognition using the residual neural networks and a novel attention mechanism module. We propose an effective channel and spatial Residual SE(csRSE) attention module, which contains a residual block for producing hierarchical features, followed by both channel SE (cSE) block and spatial SE (sSE) block for the sufficient information extraction along the channel and spatial pathways. To further summarize the occupancy grid map characteristics and experiment with our csRSE attention modules, we constructed a dataset called occupancy grid map dataset (OGMD) for our experiments. On this OGMD test dataset, we tested few variants of our proposed structure and compared them with other attention mechanisms. Our experimental results show that the proposed attention network can infer the abnormal map with state-of-the-art (SOTA) accuracy of 96.23% for abnormal occupancy grid map recognition.



### Discovery-and-Selection: Towards Optimal Multiple Instance Learning for Weakly Supervised Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.09060v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09060v2)
- **Published**: 2021-10-18 07:06:57+00:00
- **Updated**: 2022-05-05 13:36:39+00:00
- **Authors**: Shiwei Zhang, Wei Ke, Lin Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Weakly supervised object detection (WSOD) is a challenging task that requires simultaneously learn object classifiers and estimate object locations under the supervision of image category labels. A major line of WSOD methods roots in multiple instance learning which regards images as bags of instances and selects positive instances from each bag to learn the detector. However, a grand challenge emerges when the detector inclines to converge to discriminative parts of objects rather than the whole objects. In this paper, under the hypothesis that optimal solutions are included in local minima, we propose a discovery-and-selection approach fused with multiple instance learning (DS-MIL), which finds rich local minima and select optimal solution from multiple local minima. To implement DS-MIL, an attention module is proposed so that more context information can be captured by feature maps and more valuable proposals can be collected during training. With proposal candidates, a selection module is proposed to select informative instances for object detector. Experimental results on commonly used benchmarks show that our proposed DS-MIL approach can consistently improve the baselines, reporting state-of-the-art performance.



### Unsupervised Shot Boundary Detection for Temporal Segmentation of Long Capsule Endoscopy Videos
- **Arxiv ID**: http://arxiv.org/abs/2110.09067v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09067v1)
- **Published**: 2021-10-18 07:22:46+00:00
- **Updated**: 2021-10-18 07:22:46+00:00
- **Authors**: Sodiq Adewole, Philip Fernandes, James Jablonski, Andrew Copland, Michael Porter, Sana Syed, Donald Brown
- **Comment**: None
- **Journal**: None
- **Summary**: Physicians use Capsule Endoscopy (CE) as a non-invasive and non-surgical procedure to examine the entire gastrointestinal (GI) tract for diseases and abnormalities. A single CE examination could last between 8 to 11 hours generating up to 80,000 frames which is compiled as a video. Physicians have to review and analyze the entire video to identify abnormalities or diseases before making diagnosis. This review task can be very tedious, time consuming and prone to error. While only as little as a single frame may capture useful content that is relevant to the physicians' final diagnosis, frames covering the small bowel region alone could be as much as 50,000. To minimize physicians' review time and effort, this paper proposes a novel unsupervised and computationally efficient temporal segmentation method to automatically partition long CE videos into a homogeneous and identifiable video segments. However, the search for temporal boundaries in a long video using high dimensional frame-feature matrix is computationally prohibitive and impracticable for real clinical application. Therefore, leveraging both spatial and temporal information in the video, we first extracted high level frame features using a pretrained CNN model and then projected the high-dimensional frame-feature matrix to lower 1-dimensional embedding. Using this 1-dimensional sequence embedding, we applied the Pruned Exact Linear Time (PELT) algorithm to searched for temporal boundaries that indicates the transition points from normal to abnormal frames and vice-versa. We experimented with multiple real patients' CE videos and our model achieved an AUC of 66\% on multiple test videos against expert provided labels.



### Boosting the Transferability of Video Adversarial Examples via Temporal Translation
- **Arxiv ID**: http://arxiv.org/abs/2110.09075v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09075v2)
- **Published**: 2021-10-18 07:52:17+00:00
- **Updated**: 2021-12-28 08:30:50+00:00
- **Authors**: Zhipeng Wei, Jingjing Chen, Zuxuan Wu, Yu-Gang Jiang
- **Comment**: None
- **Journal**: None
- **Summary**: Although deep-learning based video recognition models have achieved remarkable success, they are vulnerable to adversarial examples that are generated by adding human-imperceptible perturbations on clean video samples. As indicated in recent studies, adversarial examples are transferable, which makes it feasible for black-box attacks in real-world applications. Nevertheless, most existing adversarial attack methods have poor transferability when attacking other video models and transfer-based attacks on video models are still unexplored. To this end, we propose to boost the transferability of video adversarial examples for black-box attacks on video recognition models. Through extensive analysis, we discover that different video recognition models rely on different discriminative temporal patterns, leading to the poor transferability of video adversarial examples. This motivates us to introduce a temporal translation attack method, which optimizes the adversarial perturbations over a set of temporal translated video clips. By generating adversarial examples over translated videos, the resulting adversarial examples are less sensitive to temporal patterns existed in the white-box model being attacked and thus can be better transferred. Extensive experiments on the Kinetics-400 dataset and the UCF-101 dataset demonstrate that our method can significantly boost the transferability of video adversarial examples. For transfer-based attack against video recognition models, it achieves a 61.56% average attack success rate on the Kinetics-400 and 48.60% on the UCF-101. Code is available at https://github.com/zhipeng-wei/TT.



### SCENIC: A JAX Library for Computer Vision Research and Beyond
- **Arxiv ID**: http://arxiv.org/abs/2110.11403v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.11403v1)
- **Published**: 2021-10-18 08:41:17+00:00
- **Updated**: 2021-10-18 08:41:17+00:00
- **Authors**: Mostafa Dehghani, Alexey Gritsenko, Anurag Arnab, Matthias Minderer, Yi Tay
- **Comment**: None
- **Journal**: None
- **Summary**: Scenic is an open-source JAX library with a focus on Transformer-based models for computer vision research and beyond. The goal of this toolkit is to facilitate rapid experimentation, prototyping, and research of new vision architectures and models. Scenic supports a diverse range of vision tasks (e.g., classification, segmentation, detection)and facilitates working on multi-modal problems, along with GPU/TPU support for multi-host, multi-device large-scale training. Scenic also offers optimized implementations of state-of-the-art research models spanning a wide range of modalities. Scenic has been successfully used for numerous projects and published papers and continues serving as the library of choice for quick prototyping and publication of new research ideas.



### Differentiable Rendering with Perturbed Optimizers
- **Arxiv ID**: http://arxiv.org/abs/2110.09107v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09107v1)
- **Published**: 2021-10-18 08:56:23+00:00
- **Updated**: 2021-10-18 08:56:23+00:00
- **Authors**: Quentin Le Lidec, Ivan Laptev, Cordelia Schmid, Justin Carpentier
- **Comment**: None
- **Journal**: None
- **Summary**: Reasoning about 3D scenes from their 2D image projections is one of the core problems in computer vision. Solutions to this inverse and ill-posed problem typically involve a search for models that best explain observed image data. Notably, images depend both on the properties of observed scenes and on the process of image formation. Hence, if optimization techniques should be used to explain images, it is crucial to design differentiable functions for the projection of 3D scenes into images, also known as differentiable rendering. Previous approaches to differentiable rendering typically replace non-differentiable operations by smooth approximations, impacting the subsequent 3D estimation. In this paper, we take a more general approach and study differentiable renderers through the prism of randomized optimization and the related notion of perturbed optimizers. In particular, our work highlights the link between some well-known differentiable renderer formulations and randomly smoothed optimizers, and introduces differentiable perturbed renderers. We also propose a variance reduction mechanism to alleviate the computational burden inherent to perturbed optimizers and introduce an adaptive scheme to automatically adjust the smoothing parameters of the rendering process. We apply our method to 3D scene reconstruction and demonstrate its advantages on the tasks of 6D pose estimation and 3D mesh reconstruction. By providing informative gradients that can be used as a strong supervisory signal, we demonstrate the benefits of perturbed renderers to obtain more accurate solutions when compared to the state-of-the-art alternatives using smooth gradient approximations.



### Asymmetric Modality Translation For Face Presentation Attack Detection
- **Arxiv ID**: http://arxiv.org/abs/2110.09108v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09108v2)
- **Published**: 2021-10-18 08:59:09+00:00
- **Updated**: 2021-10-20 11:50:16+00:00
- **Authors**: Zhi Li, Haoliang Li, Xin Luo, Yongjian Hu, Kwok-Yan Lam, Alex C. Kot
- **Comment**: None
- **Journal**: None
- **Summary**: Face presentation attack detection (PAD) is an essential measure to protect face recognition systems from being spoofed by malicious users and has attracted great attention from both academia and industry. Although most of the existing methods can achieve desired performance to some extent, the generalization issue of face presentation attack detection under cross-domain settings (e.g., the setting of unseen attacks and varying illumination) remains to be solved. In this paper, we propose a novel framework based on asymmetric modality translation for face presentation attack detection in bi-modality scenarios. Under the framework, we establish connections between two modality images of genuine faces. Specifically, a novel modality fusion scheme is presented that the image of one modality is translated to the other one through an asymmetric modality translator, then fused with its corresponding paired image. The fusion result is fed as the input to a discriminator for inference. The training of the translator is supervised by an asymmetric modality translation loss. Besides, an illumination normalization module based on Pattern of Local Gravitational Force (PLGF) representation is used to reduce the impact of illumination variation. We conduct extensive experiments on three public datasets, which validate that our method is effective in detecting various types of attacks and achieves state-of-the-art performance under different evaluation protocols.



### Patch-Based Deep Autoencoder for Point Cloud Geometry Compression
- **Arxiv ID**: http://arxiv.org/abs/2110.09109v1
- **DOI**: 10.1145/3469877.3490611
- **Categories**: **cs.CV**, cs.MM, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09109v1)
- **Published**: 2021-10-18 08:59:57+00:00
- **Updated**: 2021-10-18 08:59:57+00:00
- **Authors**: Kang You, Pan Gao
- **Comment**: Accepted to ACM Multimedia Asia (MMAsia '21)
- **Journal**: None
- **Summary**: The ever-increasing 3D application makes the point cloud compression unprecedentedly important and needed. In this paper, we propose a patch-based compression process using deep learning, focusing on the lossy point cloud geometry compression. Unlike existing point cloud compression networks, which apply feature extraction and reconstruction on the entire point cloud, we divide the point cloud into patches and compress each patch independently. In the decoding process, we finally assemble the decompressed patches into a complete point cloud. In addition, we train our network by a patch-to-patch criterion, i.e., use the local reconstruction loss for optimization, to approximate the global reconstruction optimality. Our method outperforms the state-of-the-art in terms of rate-distortion performance, especially at low bitrates. Moreover, the compression process we proposed can guarantee to generate the same number of points as the input. The network model of this method can be easily applied to other point cloud reconstruction problems, such as upsampling.



### Graph Convolution Neural Network For Weakly Supervised Abnormality Localization In Long Capsule Endoscopy Videos
- **Arxiv ID**: http://arxiv.org/abs/2110.09110v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2110.09110v1)
- **Published**: 2021-10-18 09:00:24+00:00
- **Updated**: 2021-10-18 09:00:24+00:00
- **Authors**: Sodiq Adewole, Philip Fernandes, James Jablonski, Andrew Copland, Michael Porter, Sana Syed, Donald Brown
- **Comment**: None
- **Journal**: None
- **Summary**: Temporal activity localization in long videos is an important problem. The cost of obtaining frame level label for long Wireless Capsule Endoscopy (WCE) videos is prohibitive. In this paper, we propose an end-to-end temporal abnormality localization for long WCE videos using only weak video level labels. Physicians use Capsule Endoscopy (CE) as a non-surgical and non-invasive method to examine the entire digestive tract in order to diagnose diseases or abnormalities. While CE has revolutionized traditional endoscopy procedures, a single CE examination could last up to 8 hours generating as much as 100,000 frames. Physicians must review the entire video, frame-by-frame, in order to identify the frames capturing relevant abnormality. This, sometimes could be as few as just a single frame. Given this very high level of redundancy, analyzing long CE videos can be very tedious, time consuming and also error prone. This paper presents a novel multi-step method for an end-to-end localization of target frames capturing abnormalities of interest in the long video using only weak video labels. First we developed an automatic temporal segmentation using change point detection technique to temporally segment the video into uniform, homogeneous and identifiable segments. Then we employed Graph Convolutional Neural Network (GCNN) to learn a representation of each video segment. Using weak video segment labels, we trained our GCNN model to recognize each video segment as abnormal if it contains at least a single abnormal frame. Finally, leveraging the parameters of the trained GCNN model, we replaced the final layer of the network with a temporal pool layer to localize the relevant abnormal frames within each abnormal video segment. Our method achieved an accuracy of 89.9\% on the graph classification task and a specificity of 97.5\% on the abnormal frames localization task.



### Salt and pepper noise removal method based on stationary Framelet transform with non-convex sparsity regularization
- **Arxiv ID**: http://arxiv.org/abs/2110.09113v9
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09113v9)
- **Published**: 2021-10-18 09:07:31+00:00
- **Updated**: 2023-02-08 00:35:22+00:00
- **Authors**: Yingpin Chen, Yuming Huang, Lingzhi Wang, Huiying Huang, Jianhua Song, Chaoqun Yu, Yanping Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Salt and pepper noise removal is a common inverse problem in image processing. Traditional denoising methods have two limitations. First, noise characteristics are often not described accurately. For example, the noise location information is often ignored and the sparsity of the salt and pepper noise is often described by L1 norm, which cannot illustrate the sparse variables clearly. Second, conventional methods separate the contaminated image into a recovered image and a noise part, thus resulting in recovering an image with unsatisfied smooth parts and detail parts. In this study, we introduce a noise detection strategy to determine the position of the noise, and a non-convex sparsity regularization depicted by Lp quasi-norm is employed to describe the sparsity of the noise, thereby addressing the first limitation. The morphological component analysis framework with stationary Framelet transform is adopted to decompose the processed image into cartoon, texture, and noise parts to resolve the second limitation. Then, the alternating direction method of multipliers (ADMM) is employed to solve the proposed model. Finally, experiments are conducted to verify the proposed method and compare it with some current state-of-the-art denoising methods. The experimental results show that the proposed method can remove salt and pepper noise while preserving the details of the processed image.



### Deep Models with Fusion Strategies for MVP Point Cloud Registration
- **Arxiv ID**: http://arxiv.org/abs/2110.09129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09129v1)
- **Published**: 2021-10-18 09:32:49+00:00
- **Updated**: 2021-10-18 09:32:49+00:00
- **Authors**: Lifa Zhu, Changwei Lin, Dongrui Liu, Xin Li, Francisco Gómez-Fernández
- **Comment**: Point cloud registration competition, ICCV21 workshop. Substantial
  text overlap with arXiv:2107.02583
- **Journal**: None
- **Summary**: The main goal of point cloud registration in Multi-View Partial (MVP) Challenge 2021 is to estimate a rigid transformation to align a point cloud pair. The pairs in this competition have the characteristics of low overlap, non-uniform density, unrestricted rotations and ambiguity, which pose a huge challenge to the registration task. In this report, we introduce our solution to the registration task, which fuses two deep learning models: ROPNet and PREDATOR, with customized ensemble strategies. Finally, we achieved the second place in the registration track with 2.96546, 0.02632 and 0.07808 under the the metrics of Rot\_Error, Trans\_Error and MSE, respectively.



### GAN-based disentanglement learning for chest X-ray rib suppression
- **Arxiv ID**: http://arxiv.org/abs/2110.09134v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09134v1)
- **Published**: 2021-10-18 09:39:53+00:00
- **Updated**: 2021-10-18 09:39:53+00:00
- **Authors**: Luyi Han, Yuanyuan Lyu, Cheng Peng, S. Kevin Zhou
- **Comment**: None
- **Journal**: None
- **Summary**: Clinical evidence has shown that rib-suppressed chest X-rays (CXRs) can improve the reliability of pulmonary disease diagnosis. However, previous approaches on generating rib-suppressed CXR face challenges in preserving details and eliminating rib residues. We hereby propose a GAN-based disentanglement learning framework called Rib Suppression GAN, or RSGAN, to perform rib suppression by utilizing the anatomical knowledge embedded in unpaired computed tomography (CT) images. In this approach, we employ a residual map to characterize the intensity difference between CXR and the corresponding rib-suppressed result. To predict the residual map in CXR domain, we disentangle the image into structure- and contrast-specific features and transfer the rib structural priors from digitally reconstructed radiographs (DRRs) computed by CT. Furthermore, we employ additional adaptive loss to suppress rib residue and preserve more details. We conduct extensive experiments based on 1,673 CT volumes, and four benchmarking CXR datasets, totaling over 120K images, to demonstrate that (i) our proposed RSGAN achieves superior image quality compared to the state-of-the-art rib suppression methods; (ii) combining CXR with our rib-suppressed result leads to better performance in lung disease classification and tuberculosis area detection.



### SynCoLFinGer: Synthetic Contactless Fingerprint Generator
- **Arxiv ID**: http://arxiv.org/abs/2110.09144v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09144v2)
- **Published**: 2021-10-18 09:56:07+00:00
- **Updated**: 2022-04-04 14:42:51+00:00
- **Authors**: Jannis Priesnitz, Christian Rathgeb, Nicolas Buchmann, Christoph Busch
- **Comment**: None
- **Journal**: None
- **Summary**: We present the first method for synthetic generation of contactless fingerprint images, referred to as SynCoLFinGer. To this end, the constituent components of contactless fingerprint images regarding capturing, subject characteristics, and environmental influences are modeled and applied to a synthetically generated ridge pattern using the SFinGe algorithm. The proposed method is able to generate different synthetic samples corresponding to a single finger and it can be parameterized to generate contactless fingerprint images of various quality levels. The resemblance of the synthetically generated contactless fingerprints to real fingerprints is confirmed by evaluating biometric sample quality using an adapted NFIQ 2.0 algorithm and biometric utility using a state-of-the-art contactless fingerprint recognition system.



### Body Part Regression for CT Images
- **Arxiv ID**: http://arxiv.org/abs/2110.09148v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09148v1)
- **Published**: 2021-10-18 10:03:42+00:00
- **Updated**: 2021-10-18 10:03:42+00:00
- **Authors**: Sarah Schuhegger
- **Comment**: None
- **Journal**: None
- **Summary**: One of the greatest challenges in the medical imaging domain is to successfully transfer deep learning models into clinical practice. Since models are often trained on a specific body region, a robust transfer into the clinic necessitates the selection of images with body regions that fit the algorithm to avoid false-positive predictions in unknown regions. Due to the insufficient and inaccurate nature of manually-defined imaging meta-data, automated body part recognition is a key ingredient towards the broad and reliable adoption of medical deep learning models. While some approaches to this task have been presented in the past, building and evaluating robust algorithms for fine-grained body part recognition remains challenging. So far, no easy-to-use method exists to determine the scanned body range of medical Computed Tomography (CT) volumes. In this thesis, a self-supervised body part regression model for CT volumes is developed and trained on a heterogeneous collection of CT studies. Furthermore, it is demonstrated how the algorithm can contribute to the robust and reliable transfer of medical models into the clinic. Finally, easy application of the developed method is ensured by integrating it into the medical platform toolkit Kaapana and providing it as a python package at https://github.com/MIC-DKFZ/BodyPartRegression .



### Disentangled Representation with Dual-stage Feature Learning for Face Anti-spoofing
- **Arxiv ID**: http://arxiv.org/abs/2110.09157v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09157v1)
- **Published**: 2021-10-18 10:22:52+00:00
- **Updated**: 2021-10-18 10:22:52+00:00
- **Authors**: Yu-Chun Wang, Chien-Yi Wang, Shang-Hong Lai
- **Comment**: WACV 2022
- **Journal**: None
- **Summary**: As face recognition is widely used in diverse security-critical applications, the study of face anti-spoofing (FAS) has attracted more and more attention. Several FAS methods have achieved promising performances if the attack types in the testing data are the same as training data, while the performance significantly degrades for unseen attack types. It is essential to learn more generalized and discriminative features to prevent overfitting to pre-defined spoof attack types. This paper proposes a novel dual-stage disentangled representation learning method that can efficiently untangle spoof-related features from irrelevant ones. Unlike previous FAS disentanglement works with one-stage architecture, we found that the dual-stage training design can improve the training stability and effectively encode the features to detect unseen attack types. Our experiments show that the proposed method provides superior accuracy than the state-of-the-art methods on several cross-type FAS benchmarks.



### Domain Generalisation for Apparent Emotional Facial Expression Recognition across Age-Groups
- **Arxiv ID**: http://arxiv.org/abs/2110.09168v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09168v1)
- **Published**: 2021-10-18 10:35:40+00:00
- **Updated**: 2021-10-18 10:35:40+00:00
- **Authors**: Rafael Poyiadzi, Jie Shen, Stavros Petridis, Yujiang Wang, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: Apparent emotional facial expression recognition has attracted a lot of research attention recently. However, the majority of approaches ignore age differences and train a generic model for all ages. In this work, we study the effect of using different age-groups for training apparent emotional facial expression recognition models. To this end, we study Domain Generalisation in the context of apparent emotional facial expression recognition from facial imagery across different age groups. We first compare several domain generalisation algorithms on the basis of out-of-domain-generalisation, and observe that the Class-Conditional Domain-Adversarial Neural Networks (CDANN) algorithm has the best performance. We then study the effect of variety and number of age-groups used during training on generalisation to unseen age-groups and observe that an increase in the number of training age-groups tends to increase the apparent emotional facial expression recognition performance on unseen age-groups. We also show that exclusion of an age-group during training tends to affect more the performance of the neighbouring age groups.



### Continuation of Famous Art with AI: A Conditional Adversarial Network Inpainting Approach
- **Arxiv ID**: http://arxiv.org/abs/2110.09170v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2110.09170v3)
- **Published**: 2021-10-18 10:39:32+00:00
- **Updated**: 2022-02-01 14:13:18+00:00
- **Authors**: Jordan J. Bird
- **Comment**: None
- **Journal**: None
- **Summary**: Much of the state-of-the-art in image synthesis inspired by real artwork are either entirely generative by filtered random noise or inspired by the transfer of style. This work explores the application of image inpainting to continue famous artworks and produce generative art with a Conditional GAN. During the training stage of the process, the borders of images are cropped, leaving only the centre. An inpainting GAN is then tasked with learning to reconstruct the original image from the centre crop by way of minimising both adversarial and absolute difference losses, which are analysed by both their Fr\'echet Inception Distances and manual observations which are presented. Once the network is trained, images are then resized rather than cropped and presented as input to the generator. Following the learning process, the generator then creates new images by continuing from the edges of the original piece. Three experiments are performed with datasets of 4766 landscape paintings (impressionism and romanticism), 1167 Ukiyo-e works from the Japanese Edo period, and 4968 abstract artworks. Results show that geometry and texture (including canvas and paint) as well as scenery such as sky, clouds, water, land (including hills and mountains), grass, and flowers are implemented by the generator when extending real artworks. In the Ukiyo-e experiments, it was observed that features such as written text were generated even in cases where the original image did not have any, due to the presence of an unpainted border within the input image.



### Learning Optimal Conformal Classifiers
- **Arxiv ID**: http://arxiv.org/abs/2110.09192v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ME, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.09192v3)
- **Published**: 2021-10-18 11:25:33+00:00
- **Updated**: 2022-05-06 14:45:56+00:00
- **Authors**: David Stutz, Krishnamurthy, Dvijotham, Ali Taylan Cemgil, Arnaud Doucet
- **Comment**: ICLR 2022
- **Journal**: None
- **Summary**: Modern deep learning based classifiers show very high accuracy on test data but this does not provide sufficient guarantees for safe deployment, especially in high-stake AI applications such as medical diagnosis. Usually, predictions are obtained without a reliable uncertainty estimate or a formal guarantee. Conformal prediction (CP) addresses these issues by using the classifier's predictions, e.g., its probability estimates, to predict confidence sets containing the true class with a user-specified probability. However, using CP as a separate processing step after training prevents the underlying model from adapting to the prediction of confidence sets. Thus, this paper explores strategies to differentiate through CP during training with the goal of training model with the conformal wrapper end-to-end. In our approach, conformal training (ConfTr), we specifically "simulate" conformalization on mini-batches during training. Compared to standard training, ConfTr reduces the average confidence set size (inefficiency) of state-of-the-art CP methods applied after training. Moreover, it allows to "shape" the confidence sets predicted at test time, which is difficult for standard CP. On experiments with several datasets, we show ConfTr can influence how inefficiency is distributed across classes, or guide the composition of confidence sets in terms of the included classes, while retaining the guarantees offered by CP.



### Sub-bit Neural Networks: Learning to Compress and Accelerate Binary Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2110.09195v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09195v1)
- **Published**: 2021-10-18 11:30:29+00:00
- **Updated**: 2021-10-18 11:30:29+00:00
- **Authors**: Yikai Wang, Yi Yang, Fuchun Sun, Anbang Yao
- **Comment**: ICCV 2021. Code and models: https://github.com/yikaiw/SNN
- **Journal**: None
- **Summary**: In the low-bit quantization field, training Binary Neural Networks (BNNs) is the extreme solution to ease the deployment of deep models on resource-constrained devices, having the lowest storage cost and significantly cheaper bit-wise operations compared to 32-bit floating-point counterparts. In this paper, we introduce Sub-bit Neural Networks (SNNs), a new type of binary quantization design tailored to compress and accelerate BNNs. SNNs are inspired by an empirical observation, showing that binary kernels learnt at convolutional layers of a BNN model are likely to be distributed over kernel subsets. As a result, unlike existing methods that binarize weights one by one, SNNs are trained with a kernel-aware optimization framework, which exploits binary quantization in the fine-grained convolutional kernel space. Specifically, our method includes a random sampling step generating layer-specific subsets of the kernel space, and a refinement step learning to adjust these subsets of binary kernels via optimization. Experiments on visual recognition benchmarks and the hardware deployment on FPGA validate the great potentials of SNNs. For instance, on ImageNet, SNNs of ResNet-18/ResNet-34 with 0.56-bit weights achieve 3.13/3.33 times runtime speed-up and 1.8 times compression over conventional BNNs with moderate drops in recognition accuracy. Promising results are also obtained when applying SNNs to binarize both weights and activations. Our code is available at https://github.com/yikaiw/SNN.



### Finding Strong Gravitational Lenses Through Self-Attention
- **Arxiv ID**: http://arxiv.org/abs/2110.09202v4
- **DOI**: 10.1051/0004-6361/202142463
- **Categories**: **cs.CV**, astro-ph.GA, astro-ph.IM
- **Links**: [PDF](http://arxiv.org/pdf/2110.09202v4)
- **Published**: 2021-10-18 11:40:48+00:00
- **Updated**: 2022-12-25 16:26:53+00:00
- **Authors**: Hareesh Thuruthipilly, Adam Zadrozny, Agnieszka Pollo, Marek Biesiada
- **Comment**: 18 Pages, 4 tables and 19 Figures
- **Journal**: A&A 664, A4 (2022)
- **Summary**: The upcoming large scale surveys like LSST are expected to find approximately $10^5$ strong gravitational lenses by analysing data of many orders of magnitude larger than those in contemporary astronomical surveys. In this case, non-automated techniques will be highly challenging and time-consuming, even if they are possible at all. We propose a new automated architecture based on the principle of self-attention to find strong gravitational lenses. The advantages of self-attention-based encoder models over convolution neural networks are investigated, and ways to optimise the outcome of encoder models are analysed. We constructed and trained 21 self-attention based encoder models and five convolution neural networks to identify gravitational lenses from the Bologna Lens Challenge. Each model was trained separately using 18,000 simulated images, cross-validated using 2,000 images, and then applied to a test set with 100,000 images. We used four different metrics for evaluation: classification accuracy, area under the receiver operating characteristic curve (AUROC), the TPR$_0$ score and the TPR$_{10}$ score. The performances of self-attention-based encoder models and CNNs participating in the challenge are compared. They were able to surpass the CNN models that participated in the Bologna Lens Challenge by a high margin for the TPR$_0$ and TPR_${10}$. Self-Attention based models have clear advantages compared to simpler CNNs. They have highly competing performance in comparison to the currently used residual neural networks. Compared to CNNs, self-attention based models can identify highly confident lensing candidates and will be able to filter out potential candidates from real data. Moreover, introducing the encoder layers can also tackle the over-fitting problem present in the CNNs by acting as effective filters.



### Color Image Segmentation Using Multi-Objective Swarm Optimizer and Multi-level Histogram Thresholding
- **Arxiv ID**: http://arxiv.org/abs/2110.09217v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2110.09217v1)
- **Published**: 2021-10-18 12:15:03+00:00
- **Updated**: 2021-10-18 12:15:03+00:00
- **Authors**: Mohammadreza Naderi Boldaji, Samaneh Hosseini Semnani
- **Comment**: 11 pages, 6 figures
- **Journal**: None
- **Summary**: Rapid developments in swarm intelligence optimizers and computer processing abilities make opportunities to design more accurate, stable, and comprehensive methods for color image segmentation. This paper presents a new way for unsupervised image segmentation by combining histogram thresholding methods (Kapur's entropy and Otsu's method) and different multi-objective swarm intelligence algorithms (MOPSO, MOGWO, MSSA, and MOALO) to thresholding 3D histogram of a color image. More precisely, this method first combines the objective function of traditional thresholding algorithms to design comprehensive objective functions then uses multi-objective optimizers to find the best thresholds during the optimization of designed objective functions. Also, our method uses a vector objective function in 3D space that could simultaneously handle the segmentation of entire image color channels with the same thresholds. To optimize this vector objective function, we employ multiobjective swarm optimizers that can optimize multiple objective functions at the same time. Therefore, our method considers dependencies between channels to find the thresholds that satisfy objective functions of color channels (which we name as vector objective function) simultaneously. Segmenting entire color channels with the same thresholds also benefits from the fact that our proposed method needs fewer thresholds to segment the image than other thresholding algorithms; thus, it requires less memory space to save thresholds. It helps a lot when we want to segment many images to many regions. The subjective and objective results show the superiority of this method to traditional thresholding methods that separately threshold histograms of a color image.



### Video Coding for Machine: Compact Visual Representation Compression for Intelligent Collaborative Analytics
- **Arxiv ID**: http://arxiv.org/abs/2110.09241v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09241v1)
- **Published**: 2021-10-18 12:42:13+00:00
- **Updated**: 2021-10-18 12:42:13+00:00
- **Authors**: Wenhan Yang, Haofeng Huang, Yueyu Hu, Ling-Yu Duan, Jiaying Liu
- **Comment**: The first three authors had equal contribution. arXiv admin note:
  text overlap with arXiv:2106.08512
- **Journal**: None
- **Summary**: Video Coding for Machines (VCM) is committed to bridging to an extent separate research tracks of video/image compression and feature compression, and attempts to optimize compactness and efficiency jointly from a unified perspective of high accuracy machine vision and full fidelity human vision. In this paper, we summarize VCM methodology and philosophy based on existing academia and industrial efforts. The development of VCM follows a general rate-distortion optimization, and the categorization of key modules or techniques is established. From previous works, it is demonstrated that, although existing works attempt to reveal the nature of scalable representation in bits when dealing with machine and human vision tasks, there remains a rare study in the generality of low bit rate representation, and accordingly how to support a variety of visual analytic tasks. Therefore, we investigate a novel visual information compression for the analytics taxonomy problem to strengthen the capability of compact visual representations extracted from multiple tasks for visual analytics. A new perspective of task relationships versus compression is revisited. By keeping in mind the transferability among different machine vision tasks (e.g. high-level semantic and mid-level geometry-related), we aim to support multiple tasks jointly at low bit rates. In particular, to narrow the dimensionality gap between neural network generated features extracted from pixels and a variety of machine vision features/labels (e.g. scene class, segmentation labels), a codebook hyperprior is designed to compress the neural network-generated features. As demonstrated in our experiments, this new hyperprior model is expected to improve feature compression efficiency by estimating the signal entropy more accurately, which enables further investigation of the granularity of abstracting compact features among different tasks.



### Leveraging MoCap Data for Human Mesh Recovery
- **Arxiv ID**: http://arxiv.org/abs/2110.09243v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09243v1)
- **Published**: 2021-10-18 12:43:00+00:00
- **Updated**: 2021-10-18 12:43:00+00:00
- **Authors**: Fabien Baradel, Thibault Groueix, Philippe Weinzaepfel, Romain Brégier, Yannis Kalantidis, Grégory Rogez
- **Comment**: 3DV 2021
- **Journal**: None
- **Summary**: Training state-of-the-art models for human body pose and shape recovery from images or videos requires datasets with corresponding annotations that are really hard and expensive to obtain. Our goal in this paper is to study whether poses from 3D Motion Capture (MoCap) data can be used to improve image-based and video-based human mesh recovery methods. We find that fine-tune image-based models with synthetic renderings from MoCap data can increase their performance, by providing them with a wider variety of poses, textures and backgrounds. In fact, we show that simply fine-tuning the batch normalization layers of the model is enough to achieve large gains. We further study the use of MoCap data for video, and introduce PoseBERT, a transformer module that directly regresses the pose parameters and is trained via masked modeling. It is simple, generic and can be plugged on top of any state-of-the-art image-based model in order to transform it in a video-based model leveraging temporal information. Our experimental results show that the proposed approaches reach state-of-the-art performance on various datasets including 3DPW, MPI-INF-3DHP, MuPoTS-3D, MCB and AIST. Test code and models will be available soon.



### Self-supervised denoising for massive noisy images
- **Arxiv ID**: http://arxiv.org/abs/2110.11911v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, physics.comp-ph
- **Links**: [PDF](http://arxiv.org/pdf/2110.11911v2)
- **Published**: 2021-10-18 12:54:21+00:00
- **Updated**: 2021-10-25 18:29:03+00:00
- **Authors**: Feng Wang, Trond R. Henninen, Debora Keller, Rolf Erni
- **Comment**: None
- **Journal**: None
- **Summary**: We propose an effective deep learning model for signal reconstruction, which requires no signal prior, no noise model calibration, and no clean samples. This model only assumes that the noise is independent of the measurement and that the true signals share the same structured information. We demonstrate its performance on a variety of real-world applications, from sub-\r{A}ngstr\"{o}m resolution atomic images to sub-arcsecond resolution astronomy images.



### A Unified Framework for Generalized Low-Shot Medical Image Segmentation with Scarce Data
- **Arxiv ID**: http://arxiv.org/abs/2110.09260v1
- **DOI**: 10.1109/TMI.2020.3045775
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09260v1)
- **Published**: 2021-10-18 13:01:06+00:00
- **Updated**: 2021-10-18 13:01:06+00:00
- **Authors**: Hengji Cui, Dong Wei, Kai Ma, Shi Gu, Yefeng Zheng
- **Comment**: Published in IEEE TRANSACTIONS ON MEDICAL IMAGING
- **Journal**: None
- **Summary**: Medical image segmentation has achieved remarkable advancements using deep neural networks (DNNs). However, DNNs often need big amounts of data and annotations for training, both of which can be difficult and costly to obtain. In this work, we propose a unified framework for generalized low-shot (one- and few-shot) medical image segmentation based on distance metric learning (DML). Unlike most existing methods which only deal with the lack of annotations while assuming abundance of data, our framework works with extreme scarcity of both, which is ideal for rare diseases. Via DML, the framework learns a multimodal mixture representation for each category, and performs dense predictions based on cosine distances between the pixels' deep embeddings and the category representations. The multimodal representations effectively utilize the inter-subject similarities and intraclass variations to overcome overfitting due to extremely limited data. In addition, we propose adaptive mixing coefficients for the multimodal mixture distributions to adaptively emphasize the modes better suited to the current input. The representations are implicitly embedded as weights of the fc layer, such that the cosine distances can be computed efficiently via forward propagation. In our experiments on brain MRI and abdominal CT datasets, the proposed framework achieves superior performances for low-shot segmentation towards standard DNN-based (3D U-Net) and classical registration-based (ANTs) methods, e.g., achieving mean Dice coefficients of 81%/69% for brain tissue/abdominal multiorgan segmentation using a single training sample, as compared to 52%/31% and 72%/35% by the U-Net and ANTs, respectively.



### Boosting Image Outpainting with Semantic Layout Prediction
- **Arxiv ID**: http://arxiv.org/abs/2110.09267v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09267v1)
- **Published**: 2021-10-18 13:09:31+00:00
- **Updated**: 2021-10-18 13:09:31+00:00
- **Authors**: Ye Ma, Jin Ma, Min Zhou, Quan Chen, Tiezheng Ge, Yuning Jiang, Tong Lin
- **Comment**: None
- **Journal**: None
- **Summary**: The objective of image outpainting is to extend image current border and generate new regions based on known ones. Previous methods adopt generative adversarial networks (GANs) to synthesize realistic images. However, the lack of explicit semantic representation leads to blurry and abnormal image pixels when the outpainting areas are complex and with various objects. In this work, we decompose the outpainting task into two stages. Firstly, we train a GAN to extend regions in semantic segmentation domain instead of image domain. Secondly, another GAN model is trained to synthesize real images based on the extended semantic layouts. The first model focuses on low frequent context such as sizes, classes and other semantic cues while the second model focuses on high frequent context like color and texture. By this design, our approach can handle semantic clues more easily and hence works better in complex scenarios. We evaluate our framework on various datasets and make quantitative and qualitative analysis. Experiments demonstrate that our method generates reasonable extended semantic layouts and images, outperforming state-of-the-art models.



### A Lightweight and Accurate Recognition Framework for Signs of X-ray Weld Images
- **Arxiv ID**: http://arxiv.org/abs/2110.09278v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09278v1)
- **Published**: 2021-10-18 13:21:28+00:00
- **Updated**: 2021-10-18 13:21:28+00:00
- **Authors**: Moyun Liu, Jingming Xie, Jing Hao, Yang Zhang, Xuzhan Chen, Youping Chen
- **Comment**: None
- **Journal**: None
- **Summary**: X-ray images are commonly used to ensure the security of devices in quality inspection industry. The recognition of signs printed on X-ray weld images plays an essential role in digital traceability system of manufacturing industry. However, the scales of objects vary different greatly in weld images, and it hinders us to achieve satisfactory recognition. In this paper, we propose a signs recognition framework based on convolutional neural networks (CNNs) for weld images. The proposed framework firstly contains a shallow classification network for correcting the pose of images. Moreover, we present a novel spatial and channel enhancement (SCE) module to address the above scale problem. This module can integrate multi-scale features and adaptively assign weights for each feature source. Based on SCE module, a narrow network is designed for final weld information recognition. To enhance the practicability of our framework, we carefully design the architecture of framework with a few parameters and computations. Experimental results show that our framework achieves 99.7% accuracy with 1.1 giga floating-point of operations (GFLOPs) on classification stage, and 90.0 mean average precision (mAP) with 176.1 frames per second (FPS) on recognition stage.



### "Sparse + Low-Rank'' Tensor Completion Approach for Recovering Images and Videos
- **Arxiv ID**: http://arxiv.org/abs/2110.09298v2
- **DOI**: None
- **Categories**: **cs.CV**, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/2110.09298v2)
- **Published**: 2021-10-18 13:41:27+00:00
- **Updated**: 2022-08-19 04:37:25+00:00
- **Authors**: Chenjian Pan, Chen Ling, Hongjin He, Liqun Qi, Yanwei Xu
- **Comment**: 15 pages, 2 tables and 11 figures
- **Journal**: None
- **Summary**: Recovering color images and videos from highly undersampled data is a fundamental and challenging task in face recognition and computer vision. By the multi-dimensional nature of color images and videos, in this paper, we propose a novel tensor completion approach, which is able to efficiently explore the sparsity of tensor data under the discrete cosine transform (DCT). Specifically, we introduce two ``sparse + low-rank'' tensor completion models as well as two implementable algorithms for finding their solutions. The first one is a DCT-based sparse plus weighted nuclear norm induced low-rank minimization model. The second one is a DCT-based sparse plus $p$-shrinking mapping induced low-rank optimization model. Moreover, we accordingly propose two implementable augmented Lagrangian-based algorithms for solving the underlying optimization models. A series of numerical experiments including color image inpainting and video data recovery demonstrate that our proposed approach performs better than many existing state-of-the-art tensor completion methods, especially for the case when the ratio of missing data is high.



### Incremental Cross-Domain Adaptation for Robust Retinopathy Screening via Bayesian Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.09319v2
- **DOI**: 10.1109/TIM.2021.3122172
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09319v2)
- **Published**: 2021-10-18 13:45:21+00:00
- **Updated**: 2021-11-04 07:45:51+00:00
- **Authors**: Taimur Hassan, Bilal Hassan, Muhammad Usman Akram, Shahrukh Hashmi, Abdel Hakim Taguri, Naoufel Werghi
- **Comment**: Accepted in IEEE Transactions on Instrumentation and Measurement.
  Source code is available at
  https://github.com/taimurhassan/continual_learning/
- **Journal**: IEEE Transactions on Instrumentation and Measurement, 2021
- **Summary**: Retinopathy represents a group of retinal diseases that, if not treated timely, can cause severe visual impairments or even blindness. Many researchers have developed autonomous systems to recognize retinopathy via fundus and optical coherence tomography (OCT) imagery. However, most of these frameworks employ conventional transfer learning and fine-tuning approaches, requiring a decent amount of well-annotated training data to produce accurate diagnostic performance. This paper presents a novel incremental cross-domain adaptation instrument that allows any deep classification model to progressively learn abnormal retinal pathologies in OCT and fundus imagery via few-shot training. Furthermore, unlike its competitors, the proposed instrument is driven via a Bayesian multi-objective function that not only enforces the candidate classification network to retain its prior learned knowledge during incremental training but also ensures that the network understands the structural and semantic relationships between previously learned pathologies and newly added disease categories to effectively recognize them at the inference stage. The proposed framework, evaluated on six public datasets acquired with three different scanners to screen thirteen retinal pathologies, outperforms the state-of-the-art competitors by achieving an overall accuracy and F1 score of 0.9826 and 0.9846, respectively.



### Self-Supervised Representation Learning: Introduction, Advances and Challenges
- **Arxiv ID**: http://arxiv.org/abs/2110.09327v1
- **DOI**: 10.1109/MSP.2021.3134634
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.09327v1)
- **Published**: 2021-10-18 13:51:22+00:00
- **Updated**: 2021-10-18 13:51:22+00:00
- **Authors**: Linus Ericsson, Henry Gouk, Chen Change Loy, Timothy M. Hospedales
- **Comment**: None
- **Journal**: None
- **Summary**: Self-supervised representation learning methods aim to provide powerful deep feature learning without the requirement of large annotated datasets, thus alleviating the annotation bottleneck that is one of the main barriers to practical deployment of deep learning today. These methods have advanced rapidly in recent years, with their efficacy approaching and sometimes surpassing fully supervised pre-training alternatives across a variety of data modalities including image, video, sound, text and graphs. This article introduces this vibrant area including key concepts, the four main families of approach and associated state of the art, and how self-supervised methods are applied to diverse modalities of data. We further discuss practical considerations including workflows, representation transferability, and compute cost. Finally, we survey the major open challenges in the field that provide fertile ground for future work.



### Understanding Dimensional Collapse in Contrastive Self-supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.09348v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09348v3)
- **Published**: 2021-10-18 14:22:19+00:00
- **Updated**: 2022-04-23 16:44:20+00:00
- **Authors**: Li Jing, Pascal Vincent, Yann LeCun, Yuandong Tian
- **Comment**: In Proceedings of the 10th International Conference on Learning
  Representations (ICLR) 2022
- **Journal**: ICLR 2022
- **Summary**: Self-supervised visual representation learning aims to learn useful representations without relying on human annotations. Joint embedding approach bases on maximizing the agreement between embedding vectors from different views of the same image. Various methods have been proposed to solve the collapsing problem where all embedding vectors collapse to a trivial constant solution. Among these methods, contrastive learning prevents collapse via negative sample pairs. It has been shown that non-contrastive methods suffer from a lesser collapse problem of a different nature: dimensional collapse, whereby the embedding vectors end up spanning a lower-dimensional subspace instead of the entire available embedding space. Here, we show that dimensional collapse also happens in contrastive learning. In this paper, we shed light on the dynamics at play in contrastive learning that leads to dimensional collapse. Inspired by our theory, we propose a novel contrastive learning method, called DirectCLR, which directly optimizes the representation space without relying on an explicit trainable projector. Experiments show that DirectCLR outperforms SimCLR with a trainable linear projector on ImageNet.



### An Analysis and Implementation of the HDR+ Burst Denoising Method
- **Arxiv ID**: http://arxiv.org/abs/2110.09354v1
- **DOI**: 10.5201/ipol.2021.336
- **Categories**: **eess.IV**, cs.CV, I.4; F.2.1
- **Links**: [PDF](http://arxiv.org/pdf/2110.09354v1)
- **Published**: 2021-10-18 14:29:07+00:00
- **Updated**: 2021-10-18 14:29:07+00:00
- **Authors**: Antoine Monod, Julie Delon, Thomas Veit
- **Comment**: 28 pages, 15 figures, published at
  https://doi.org/10.5201/ipol.2021.336, code on
  https://github.com/amonod/hdrplus-python
- **Journal**: Image Processing On Line, 11 (2021), pp. 142-169
- **Summary**: HDR+ is an image processing pipeline presented by Google in 2016. At its core lies a denoising algorithm that uses a burst of raw images to produce a single higher quality image. Since it is designed as a versatile solution for smartphone cameras, it does not necessarily aim for the maximization of standard denoising metrics, but rather for the production of natural, visually pleasing images. In this article, we specifically discuss and analyze the HDR+ burst denoising algorithm architecture and the impact of its various parameters. With this publication, we provide an open source Python implementation of the algorithm, along with an interactive demo.



### FAST3D: Flow-Aware Self-Training for 3D Object Detectors
- **Arxiv ID**: http://arxiv.org/abs/2110.09355v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2110.09355v1)
- **Published**: 2021-10-18 14:32:05+00:00
- **Updated**: 2021-10-18 14:32:05+00:00
- **Authors**: Christian Fruhwirth-Reisinger, Michael Opitz, Horst Possegger, Horst Bischof
- **Comment**: Accepted to BMVC 2021
- **Journal**: None
- **Summary**: In the field of autonomous driving, self-training is widely applied to mitigate distribution shifts in LiDAR-based 3D object detectors. This eliminates the need for expensive, high-quality labels whenever the environment changes (e.g., geographic location, sensor setup, weather condition). State-of-the-art self-training approaches, however, mostly ignore the temporal nature of autonomous driving data. To address this issue, we propose a flow-aware self-training method that enables unsupervised domain adaptation for 3D object detectors on continuous LiDAR point clouds. In order to get reliable pseudo-labels, we leverage scene flow to propagate detections through time. In particular, we introduce a flow-based multi-target tracker, that exploits flow consistency to filter and refine resulting tracks. The emerged precise pseudo-labels then serve as a basis for model re-training. Starting with a pre-trained KITTI model, we conduct experiments on the challenging Waymo Open Dataset to demonstrate the effectiveness of our approach. Without any prior target domain knowledge, our results show a significant improvement over the state-of-the-art.



### Dendritic Self-Organizing Maps for Continual Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.13611v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2110.13611v1)
- **Published**: 2021-10-18 14:47:19+00:00
- **Updated**: 2021-10-18 14:47:19+00:00
- **Authors**: Kosmas Pinitas, Spyridon Chavlis, Panayiota Poirazi
- **Comment**: 12 pages, 13 figures, 7 tables
- **Journal**: None
- **Summary**: Current deep learning architectures show remarkable performance when trained in large-scale, controlled datasets. However, the predictive ability of these architectures significantly decreases when learning new classes incrementally. This is due to their inclination to forget the knowledge acquired from previously seen data, a phenomenon termed catastrophic-forgetting. On the other hand, Self-Organizing Maps (SOMs) can model the input space utilizing constrained k-means and thus maintain past knowledge. Here, we propose a novel algorithm inspired by biological neurons, termed Dendritic-Self-Organizing Map (DendSOM). DendSOM consists of a single layer of SOMs, which extract patterns from specific regions of the input space accompanied by a set of hit matrices, one per SOM, which estimate the association between units and labels. The best-matching unit of an input pattern is selected using the maximum cosine similarity rule, while the point-wise mutual information is employed for class inference. DendSOM performs unsupervised feature extraction as it does not use labels for targeted updating of the weights. It outperforms classical SOMs and several state-of-the-art continual learning algorithms on benchmark datasets, such as the Split-MNIST and Split-CIFAR-10. We propose that the incorporation of neuronal properties in SOMs may help remedy catastrophic forgetting.



### Ortho-Shot: Low Displacement Rank Regularization with Data Augmentation for Few-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2110.09374v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09374v1)
- **Published**: 2021-10-18 14:58:36+00:00
- **Updated**: 2021-10-18 14:58:36+00:00
- **Authors**: Uche Osahor, Nasser M. Nasrabadi
- **Comment**: None
- **Journal**: None
- **Summary**: In few-shot classification, the primary goal is to learn representations from a few samples that generalize well for novel classes. In this paper, we propose an efficient low displacement rank (LDR) regularization strategy termed Ortho-Shot; a technique that imposes orthogonal regularization on the convolutional layers of a few-shot classifier, which is based on the doubly-block toeplitz (DBT) matrix structure. The regularized convolutional layers of the few-shot classifier enhances model generalization and intra-class feature embeddings that are crucial for few-shot learning. Overfitting is a typical issue for few-shot models, the lack of data diversity inhibits proper model inference which weakens the classification accuracy of few-shot learners to novel classes. In this regard, we broke down the pipeline of the few-shot classifier and established that the support, query and task data augmentation collectively alleviates overfitting in networks. With compelling results, we demonstrated that combining a DBT-based low-rank orthogonal regularizer with data augmentation strategies, significantly boosts the performance of a few-shot classifier. We perform our experiments on the miniImagenet, CIFAR-FS and Stanford datasets with performance values of about 5\% when compared to state-of-the-art



### Learning multiplane images from single views with self-supervision
- **Arxiv ID**: http://arxiv.org/abs/2110.09380v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09380v2)
- **Published**: 2021-10-18 15:03:08+00:00
- **Updated**: 2021-10-19 07:42:28+00:00
- **Authors**: Gustavo Sutter P. Carvalho, Diogo C. Luvizon, Antonio Joia Neto, Andre G. C. Pacheco, Otavio A. B. Penatti
- **Comment**: To appear on BMVC 2021
- **Journal**: None
- **Summary**: Generating static novel views from an already captured image is a hard task in computer vision and graphics, in particular when the single input image has dynamic parts such as persons or moving objects. In this paper, we tackle this problem by proposing a new framework, called CycleMPI, that is capable of learning a multiplane image representation from single images through a cyclic training strategy for self-supervision. Our framework does not require stereo data for training, therefore it can be trained with massive visual data from the Internet, resulting in a better generalization capability even for very challenging cases. Although our method does not require stereo data for supervision, it reaches results on stereo datasets comparable to the state of the art in a zero-shot scenario. We evaluated our method on RealEstate10K and Mannequin Challenge datasets for view synthesis and presented qualitative results on Places II dataset.



### Neuro-Symbolic Forward Reasoning
- **Arxiv ID**: http://arxiv.org/abs/2110.09383v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09383v1)
- **Published**: 2021-10-18 15:14:58+00:00
- **Updated**: 2021-10-18 15:14:58+00:00
- **Authors**: Hikaru Shindo, Devendra Singh Dhami, Kristian Kersting
- **Comment**: Preprint
- **Journal**: None
- **Summary**: Reasoning is an essential part of human intelligence and thus has been a long-standing goal in artificial intelligence research. With the recent success of deep learning, incorporating reasoning with deep learning systems, i.e., neuro-symbolic AI has become a major field of interest. We propose the Neuro-Symbolic Forward Reasoner (NSFR), a new approach for reasoning tasks taking advantage of differentiable forward-chaining using first-order logic. The key idea is to combine differentiable forward-chaining reasoning with object-centric (deep) learning. Differentiable forward-chaining reasoning computes logical entailments smoothly, i.e., it deduces new facts from given facts and rules in a differentiable manner. The object-centric learning approach factorizes raw inputs into representations in terms of objects. Thus, it allows us to provide a consistent framework to perform the forward-chaining inference from raw inputs. NSFR factorizes the raw inputs into the object-centric representations, converts them into probabilistic ground atoms, and finally performs differentiable forward-chaining inference using weighted rules for inference. Our comprehensive experimental evaluations on object-centric reasoning data sets, 2D Kandinsky patterns and 3D CLEVR-Hans, and a variety of tasks show the effectiveness and advantage of our approach.



### Conditional De-Identification of 3D Magnetic Resonance Images
- **Arxiv ID**: http://arxiv.org/abs/2110.09927v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CR, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09927v1)
- **Published**: 2021-10-18 15:19:35+00:00
- **Updated**: 2021-10-18 15:19:35+00:00
- **Authors**: Lennart Alexander Van der Goten, Tobias Hepp, Zeynep Akata, Kevin Smith
- **Comment**: None
- **Journal**: None
- **Summary**: Privacy protection of medical image data is challenging. Even if metadata is removed, brain scans are vulnerable to attacks that match renderings of the face to facial image databases. Solutions have been developed to de-identify diagnostic scans by obfuscating or removing parts of the face. However, these solutions either fail to reliably hide the patient's identity or are so aggressive that they impair further analyses. We propose a new class of de-identification techniques that, instead of removing facial features, remodels them. Our solution relies on a conditional multi-scale GAN architecture. It takes a patient's MRI scan as input and generates a 3D volume conditioned on the patient's brain, which is preserved exactly, but where the face has been de-identified through remodeling. We demonstrate that our approach preserves privacy far better than existing techniques, without compromising downstream medical analyses. Analyses were run on the OASIS-3 and ADNI corpora.



### Mesh Convolutional Autoencoder for Semi-Regular Meshes of Different Sizes
- **Arxiv ID**: http://arxiv.org/abs/2110.09401v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09401v2)
- **Published**: 2021-10-18 15:30:40+00:00
- **Updated**: 2021-10-20 15:29:04+00:00
- **Authors**: Sara Hahner, Jochen Garcke
- **Comment**: Accepted at 2022 IEEE Winter Conference on Applications of Computer
  Vision (WACV)
- **Journal**: None
- **Summary**: The analysis of deforming 3D surface meshes is accelerated by autoencoders since the low-dimensional embeddings can be used to visualize underlying dynamics. But, state-of-the-art mesh convolutional autoencoders require a fixed connectivity of all input meshes handled by the autoencoder. This is due to either the use of spectral convolutional layers or mesh dependent pooling operations. Therefore, the types of datasets that one can study are limited and the learned knowledge cannot be transferred to other datasets that exhibit similar behavior. To address this, we transform the discretization of the surfaces to semi-regular meshes that have a locally regular connectivity and whose meshing is hierarchical. This allows us to apply the same spatial convolutional filters to the local neighborhoods and to define a pooling operator that can be applied to every semi-regular mesh. We apply the same mesh autoencoder to different datasets and our reconstruction error is more than 50% lower than the error from state-of-the-art models, which have to be trained for every mesh separately. Additionally, we visualize the underlying dynamics of unseen mesh sequences with an autoencoder trained on different classes of meshes.



### HRFormer: High-Resolution Transformer for Dense Prediction
- **Arxiv ID**: http://arxiv.org/abs/2110.09408v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09408v3)
- **Published**: 2021-10-18 15:37:58+00:00
- **Updated**: 2021-11-07 14:39:41+00:00
- **Authors**: Yuhui Yuan, Rao Fu, Lang Huang, Weihong Lin, Chao Zhang, Xilin Chen, Jingdong Wang
- **Comment**: Accepted at NeurIPS 2021
- **Journal**: None
- **Summary**: We present a High-Resolution Transformer (HRFormer) that learns high-resolution representations for dense prediction tasks, in contrast to the original Vision Transformer that produces low-resolution representations and has high memory and computational cost. We take advantage of the multi-resolution parallel design introduced in high-resolution convolutional networks (HRNet), along with local-window self-attention that performs self-attention over small non-overlapping image windows, for improving the memory and computation efficiency. In addition, we introduce a convolution into the FFN to exchange information across the disconnected image windows. We demonstrate the effectiveness of the High-Resolution Transformer on both human pose estimation and semantic segmentation tasks, e.g., HRFormer outperforms Swin transformer by $1.3$ AP on COCO pose estimation with $50\%$ fewer parameters and $30\%$ fewer FLOPs. Code is available at: https://github.com/HRNet/HRFormer.



### NeuralBlox: Real-Time Neural Representation Fusion for Robust Volumetric Mapping
- **Arxiv ID**: http://arxiv.org/abs/2110.09415v1
- **DOI**: 10.1109/3DV53792.2021.00135
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2110.09415v1)
- **Published**: 2021-10-18 15:45:05+00:00
- **Updated**: 2021-10-18 15:45:05+00:00
- **Authors**: Stefan Lionar, Lukas Schmid, Cesar Cadena, Roland Siegwart, Andrei Cramariuc
- **Comment**: 3DV 2021. Equal contribution between the first two authors. Code:
  https://github.com/ethz-asl/neuralblox
- **Journal**: International Conference on 3D Vision (3DV), 2021, pp. 1279-1289
- **Summary**: We present a novel 3D mapping method leveraging the recent progress in neural implicit representation for 3D reconstruction. Most existing state-of-the-art neural implicit representation methods are limited to object-level reconstructions and can not incrementally perform updates given new data. In this work, we propose a fusion strategy and training pipeline to incrementally build and update neural implicit representations that enable the reconstruction of large scenes from sequential partial observations. By representing an arbitrarily sized scene as a grid of latent codes and performing updates directly in latent space, we show that incrementally built occupancy maps can be obtained in real-time even on a CPU. Compared to traditional approaches such as Truncated Signed Distance Fields (TSDFs), our map representation is significantly more robust in yielding a better scene completeness given noisy inputs. We demonstrate the performance of our approach in thorough experimental validation on real-world datasets with varying degrees of added pose noise.



### Don't Judge Me by My Face : An Indirect Adversarial Approach to Remove Sensitive Information From Multimodal Neural Representation in Asynchronous Job Video Interviews
- **Arxiv ID**: http://arxiv.org/abs/2110.09424v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.HC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09424v1)
- **Published**: 2021-10-18 15:53:15+00:00
- **Updated**: 2021-10-18 15:53:15+00:00
- **Authors**: Léo Hemamou, Arthur Guillon, Jean-Claude Martin, Chloé Clavel
- **Comment**: published in ACII 2021
- **Journal**: None
- **Summary**: se of machine learning for automatic analysis of job interview videos has recently seen increased interest. Despite claims of fair output regarding sensitive information such as gender or ethnicity of the candidates, the current approaches rarely provide proof of unbiased decision-making, or that sensitive information is not used. Recently, adversarial methods have been proved to effectively remove sensitive information from the latent representation of neural networks. However, these methods rely on the use of explicitly labeled protected variables (e.g. gender), which cannot be collected in the context of recruiting in some countries (e.g. France). In this article, we propose a new adversarial approach to remove sensitive information from the latent representation of neural networks without the need to collect any sensitive variable. Using only a few frames of the interview, we train our model to not be able to find the face of the candidate related to the job interview in the inner layers of the model. This, in turn, allows us to remove relevant private information from these layers. Comparing our approach to a standard baseline on a public dataset with gender and ethnicity annotations, we show that it effectively removes sensitive information from the main network. Moreover, to the best of our knowledge, this is the first application of adversarial techniques for obtaining a multimodal fair representation in the context of video job interviews. In summary, our contributions aim at improving fairness of the upcoming automatic systems processing videos of job interviews for equality in job selection.



### FacialGAN: Style Transfer and Attribute Manipulation on Synthetic Faces
- **Arxiv ID**: http://arxiv.org/abs/2110.09425v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09425v1)
- **Published**: 2021-10-18 15:53:38+00:00
- **Updated**: 2021-10-18 15:53:38+00:00
- **Authors**: Ricard Durall, Jireh Jam, Dominik Strassel, Moi Hoon Yap, Janis Keuper
- **Comment**: None
- **Journal**: None
- **Summary**: Facial image manipulation is a generation task where the output face is shifted towards an intended target direction in terms of facial attribute and styles. Recent works have achieved great success in various editing techniques such as style transfer and attribute translation. However, current approaches are either focusing on pure style transfer, or on the translation of predefined sets of attributes with restricted interactivity. To address this issue, we propose FacialGAN, a novel framework enabling simultaneous rich style transfers and interactive facial attributes manipulation. While preserving the identity of a source image, we transfer the diverse styles of a target image to the source image. We then incorporate the geometry information of a segmentation mask to provide a fine-grained manipulation of facial attributes. Finally, a multi-objective learning strategy is introduced to optimize the loss of each specific tasks. Experiments on the CelebA-HQ dataset, with CelebAMask-HQ as semantic mask labels, show our model's capacity in producing visually compelling results in style transfer, attribute manipulation, diversity and face verification. For reproducibility, we provide an interactive open-source tool to perform facial manipulations, and the Pytorch implementation of the model.



### Distinguishing Natural and Computer-Generated Images using Multi-Colorspace fused EfficientNet
- **Arxiv ID**: http://arxiv.org/abs/2110.09428v2
- **DOI**: 10.1016/j.jisa.2022.103261
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09428v2)
- **Published**: 2021-10-18 15:55:45+00:00
- **Updated**: 2022-01-10 08:50:55+00:00
- **Authors**: Manjary P Gangan, Anoop K, Lajish V L
- **Comment**: 13 pages
- **Journal**: Journal of Information Security and Applications, Volume 68,
  August 2022, 103261
- **Summary**: The problem of distinguishing natural images from photo-realistic computer-generated ones either addresses natural images versus computer graphics or natural images versus GAN images, at a time. But in a real-world image forensic scenario, it is highly essential to consider all categories of image generation, since in most cases image generation is unknown. We, for the first time, to our best knowledge, approach the problem of distinguishing natural images from photo-realistic computer-generated images as a three-class classification task classifying natural, computer graphics, and GAN images. For the task, we propose a Multi-Colorspace fused EfficientNet model by parallelly fusing three EfficientNet networks that follow transfer learning methodology where each network operates in different colorspaces, RGB, LCH, and HSV, chosen after analyzing the efficacy of various colorspace transformations in this image forensics problem. Our model outperforms the baselines in terms of accuracy, robustness towards post-processing, and generalizability towards other datasets. We conduct psychophysics experiments to understand how accurately humans can distinguish natural, computer graphics, and GAN images where we could observe that humans find difficulty in classifying these images, particularly the computer-generated images, indicating the necessity of computational algorithms for the task. We also analyze the behavior of our model through visual explanations to understand salient regions that contribute to the model's decision making and compare with manual explanations provided by human participants in the form of region markings, where we could observe similarities in both the explanations indicating the powerful nature of our model to take the decisions meaningfully.



### Comparing Deep Neural Nets with UMAP Tour
- **Arxiv ID**: http://arxiv.org/abs/2110.09431v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09431v1)
- **Published**: 2021-10-18 15:59:13+00:00
- **Updated**: 2021-10-18 15:59:13+00:00
- **Authors**: Mingwei Li, Carlos Scheidegger
- **Comment**: None
- **Journal**: None
- **Summary**: Neural networks should be interpretable to humans. In particular, there is a growing interest in concepts learned in a layer and similarity between layers. In this work, a tool, UMAP Tour, is built to visually inspect and compare internal behavior of real-world neural network models using well-aligned, instance-level representations. The method used in the visualization also implies a new similarity measure between neural network layers. Using the visual tool and the similarity measure, we find concepts learned in state-of-the-art models and dissimilarities between them, such as GoogLeNet and ResNet.



### TLDR: Twin Learning for Dimensionality Reduction
- **Arxiv ID**: http://arxiv.org/abs/2110.09455v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09455v2)
- **Published**: 2021-10-18 16:46:12+00:00
- **Updated**: 2022-06-15 09:30:20+00:00
- **Authors**: Yannis Kalantidis, Carlos Lassance, Jon Almazan, Diane Larlus
- **Comment**: Accepted at Transactions on Machine Learning Research (TMLR). Code
  available at: https://github.com/naver/tldr
- **Journal**: None
- **Summary**: Dimensionality reduction methods are unsupervised approaches which learn low-dimensional spaces where some properties of the initial space, typically the notion of "neighborhood", are preserved. Such methods usually require propagation on large k-NN graphs or complicated optimization solvers. On the other hand, self-supervised learning approaches, typically used to learn representations from scratch, rely on simple and more scalable frameworks for learning. In this paper, we propose TLDR, a dimensionality reduction method for generic input spaces that is porting the recent self-supervised learning framework of Zbontar et al. (2021) to the specific task of dimensionality reduction, over arbitrary representations. We propose to use nearest neighbors to build pairs from a training set and a redundancy reduction loss to learn an encoder that produces representations invariant across such pairs. TLDR is a method that is simple, easy to train, and of broad applicability; it consists of an offline nearest neighbor computation step that can be highly approximated, and a straightforward learning process. Aiming for scalability, we focus on improving linear dimensionality reduction, and show consistent gains on image and document retrieval tasks, e.g. gaining +4% mAP over PCA on ROxford for GeM- AP, improving the performance of DINO on ImageNet or retaining it with a 10x compression.



### Improving Robustness using Generated Data
- **Arxiv ID**: http://arxiv.org/abs/2110.09468v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.09468v2)
- **Published**: 2021-10-18 17:00:26+00:00
- **Updated**: 2021-12-14 10:07:09+00:00
- **Authors**: Sven Gowal, Sylvestre-Alvise Rebuffi, Olivia Wiles, Florian Stimberg, Dan Andrei Calian, Timothy Mann
- **Comment**: Accepted at NeurIPS 2021; Added ImageNet results
- **Journal**: None
- **Summary**: Recent work argues that robust training requires substantially larger datasets than those required for standard classification. On CIFAR-10 and CIFAR-100, this translates into a sizable robust-accuracy gap between models trained solely on data from the original training set and those trained with additional data extracted from the "80 Million Tiny Images" dataset (TI-80M). In this paper, we explore how generative models trained solely on the original training set can be leveraged to artificially increase the size of the original training set and improve adversarial robustness to $\ell_p$ norm-bounded perturbations. We identify the sufficient conditions under which incorporating additional generated data can improve robustness, and demonstrate that it is possible to significantly reduce the robust-accuracy gap to models trained with additional real data. Surprisingly, we even show that even the addition of non-realistic random data (generated by Gaussian sampling) can improve robustness. We evaluate our approach on CIFAR-10, CIFAR-100, SVHN and TinyImageNet against $\ell_\infty$ and $\ell_2$ norm-bounded perturbations of size $\epsilon = 8/255$ and $\epsilon = 128/255$, respectively. We show large absolute improvements in robust accuracy compared to previous state-of-the-art methods. Against $\ell_\infty$ norm-bounded perturbations of size $\epsilon = 8/255$, our models achieve 66.10% and 33.49% robust accuracy on CIFAR-10 and CIFAR-100, respectively (improving upon the state-of-the-art by +8.96% and +3.29%). Against $\ell_2$ norm-bounded perturbations of size $\epsilon = 128/255$, our model achieves 78.31% on CIFAR-10 (+3.81%). These results beat most prior works that use external data.



### No RL, No Simulation: Learning to Navigate without Navigating
- **Arxiv ID**: http://arxiv.org/abs/2110.09470v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09470v2)
- **Published**: 2021-10-18 17:04:06+00:00
- **Updated**: 2021-10-22 15:35:03+00:00
- **Authors**: Meera Hahn, Devendra Chaplot, Shubham Tulsiani, Mustafa Mukadam, James M. Rehg, Abhinav Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: Most prior methods for learning navigation policies require access to simulation environments, as they need online policy interaction and rely on ground-truth maps for rewards. However, building simulators is expensive (requires manual effort for each and every scene) and creates challenges in transferring learned policies to robotic platforms in the real-world, due to the sim-to-real domain gap. In this paper, we pose a simple question: Do we really need active interaction, ground-truth maps or even reinforcement-learning (RL) in order to solve the image-goal navigation task? We propose a self-supervised approach to learn to navigate from only passive videos of roaming. Our approach, No RL, No Simulator (NRNS), is simple and scalable, yet highly effective. NRNS outperforms RL-based formulations by a significant margin. We present NRNS as a strong baseline for any future image-based navigation tasks that use RL or Simulation.



### DBSegment: Fast and robust segmentation of deep brain structures -- Evaluation of transportability across acquisition domains
- **Arxiv ID**: http://arxiv.org/abs/2110.09473v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2110.09473v3)
- **Published**: 2021-10-18 17:15:39+00:00
- **Updated**: 2022-05-19 11:49:13+00:00
- **Authors**: Mehri Baniasadi, Mikkel V. Petersen, Jorge Goncalves, Andreas Horn, Vanja Vlasov, Frank Hertel, Andreas Husch
- **Comment**: The data used have mistakes. No one has time to correct the data and
  add a new version, that is why we would like to retract it. Once we have the
  correct version we will resubmit to arxiv
- **Journal**: None
- **Summary**: Segmenting deep brain structures from magnetic resonance images is important for patient diagnosis, surgical planning, and research. Most current state-of-the-art solutions follow a segmentation-by-registration approach, where subject MRIs are mapped to a template with well-defined segmentations. However, registration-based pipelines are time-consuming, thus, limiting their clinical use. This paper uses deep learning to provide a robust and efficient deep brain segmentation solution. The method consists of a pre-processing step to conform all MRI images to the same orientation, followed by a convolutional neural network using the nnU-Net framework. We use a total of 14 datasets from both research and clinical collections. Of these, seven were used for training and validation and seven were retained for independent testing. We trained the network to segment 30 deep brain structures, as well as a brain mask, using labels generated from a registration-based approach. We evaluated the generalizability of the network by performing a leave-one-dataset-out cross-validation, and extensive testing on external datasets. Furthermore, we assessed cross-domain transportability by evaluating the results separately on different domains. We achieved an average DSC of 0.89 $\pm$ 0.04 on the independent testing datasets when compared to the registration-based gold standard. On our test system, the computation time decreased from 42 minutes for a reference registration-based pipeline to 1 minute. Our proposed method is fast, robust, and generalizes with high reliability. It can be extended to the segmentation of other brain structures. The method is publicly available on GitHub, as well as a pip package for convenient usage.



### MTP: Multi-Hypothesis Tracking and Prediction for Reduced Error Propagation
- **Arxiv ID**: http://arxiv.org/abs/2110.09481v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MA, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2110.09481v1)
- **Published**: 2021-10-18 17:30:59+00:00
- **Updated**: 2021-10-18 17:30:59+00:00
- **Authors**: Xinshuo Weng, Boris Ivanovic, Marco Pavone
- **Comment**: Project page: https://www.xinshuoweng.com/projects/MTP
- **Journal**: None
- **Summary**: Recently, there has been tremendous progress in developing each individual module of the standard perception-planning robot autonomy pipeline, including detection, tracking, prediction of other agents' trajectories, and ego-agent trajectory planning. Nevertheless, there has been less attention given to the principled integration of these components, particularly in terms of the characterization and mitigation of cascading errors. This paper addresses the problem of cascading errors by focusing on the coupling between the tracking and prediction modules. First, by using state-of-the-art tracking and prediction tools, we conduct a comprehensive experimental evaluation of how severely errors stemming from tracking can impact prediction performance. On the KITTI and nuScenes datasets, we find that predictions consuming tracked trajectories as inputs (the typical case in practice) can experience a significant (even order of magnitude) drop in performance in comparison to the idealized setting where ground truth past trajectories are used as inputs. To address this issue, we propose a multi-hypothesis tracking and prediction framework. Rather than relying on a single set of tracking results for prediction, our framework simultaneously reasons about multiple sets of tracking results, thereby increasing the likelihood of including accurate tracking results as inputs to prediction. We show that this framework improves overall prediction performance over the standard single-hypothesis tracking-prediction pipeline by up to 34.2% on the nuScenes dataset, with even more significant improvements (up to ~70%) when restricting the evaluation to challenging scenarios involving identity switches and fragments -- all with an acceptable computation overhead.



### Self-Supervised Monocular Depth Estimation with Internal Feature Fusion
- **Arxiv ID**: http://arxiv.org/abs/2110.09482v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09482v3)
- **Published**: 2021-10-18 17:31:11+00:00
- **Updated**: 2021-11-19 11:29:51+00:00
- **Authors**: Hang Zhou, David Greenwood, Sarah Taylor
- **Comment**: Accepted at BMVC2021
- **Journal**: None
- **Summary**: Self-supervised learning for depth estimation uses geometry in image sequences for supervision and shows promising results. Like many computer vision tasks, depth network performance is determined by the capability to learn accurate spatial and semantic representations from images. Therefore, it is natural to exploit semantic segmentation networks for depth estimation. In this work, based on a well-developed semantic segmentation network HRNet, we propose a novel depth estimation network DIFFNet, which can make use of semantic information in down and upsampling procedures. By applying feature fusion and an attention mechanism, our proposed method outperforms the state-of-the-art monocular depth estimation methods on the KITTI benchmark. Our method also demonstrates greater potential on higher resolution training data. We propose an additional extended evaluation strategy by establishing a test set of challenging cases, empirically derived from the standard benchmark.



### Learning in High Dimension Always Amounts to Extrapolation
- **Arxiv ID**: http://arxiv.org/abs/2110.09485v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09485v2)
- **Published**: 2021-10-18 17:32:25+00:00
- **Updated**: 2021-10-29 20:48:06+00:00
- **Authors**: Randall Balestriero, Jerome Pesenti, Yann LeCun
- **Comment**: None
- **Journal**: None
- **Summary**: The notion of interpolation and extrapolation is fundamental in various fields from deep learning to function approximation. Interpolation occurs for a sample $x$ whenever this sample falls inside or on the boundary of the given dataset's convex hull. Extrapolation occurs when $x$ falls outside of that convex hull. One fundamental (mis)conception is that state-of-the-art algorithms work so well because of their ability to correctly interpolate training data. A second (mis)conception is that interpolation happens throughout tasks and datasets, in fact, many intuitions and theories rely on that assumption. We empirically and theoretically argue against those two points and demonstrate that on any high-dimensional ($>$100) dataset, interpolation almost surely never happens. Those results challenge the validity of our current interpolation/extrapolation definition as an indicator of generalization performances.



### Unsupervised Image Fusion Using Deep Image Priors
- **Arxiv ID**: http://arxiv.org/abs/2110.09490v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09490v3)
- **Published**: 2021-10-18 17:38:35+00:00
- **Updated**: 2022-02-22 16:52:27+00:00
- **Authors**: Xudong Ma, Paul Hill, Nantheera Anantrasirichai, Alin Achim
- **Comment**: None
- **Journal**: None
- **Summary**: A significant number of researchers have applied deep learning methods to image fusion. However, most works require a large amount of training data or depend on pre-trained models or frameworks to capture features from source images. This is inevitably hampered by a shortage of training data or a mismatch between the framework and the actual problem. Deep Image Prior (DIP) has been introduced to exploit convolutional neural networks' ability to synthesize the 'prior' in the input image. However, the original design of DIP is hard to be generalized to multi-image processing problems, particularly for image fusion. Therefore, we propose a new image fusion technique that extends DIP to fusion tasks formulated as inverse problems. Additionally, we apply a multi-channel approach to enhance DIP's effect further. The evaluation is conducted with several commonly used image fusion assessment metrics. The results are compared with state-of-the-art image fusion methods. Our method outperforms these techniques for a range of metrics. In particular, it is shown to provide the best objective results for most metrics when applied to medical images.



### MEMO: Test Time Robustness via Adaptation and Augmentation
- **Arxiv ID**: http://arxiv.org/abs/2110.09506v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.09506v3)
- **Published**: 2021-10-18 17:55:11+00:00
- **Updated**: 2022-10-10 20:03:06+00:00
- **Authors**: Marvin Zhang, Sergey Levine, Chelsea Finn
- **Comment**: NeurIPS '22 camera ready. Code: https://github.com/zhangmarvin/memo
- **Journal**: None
- **Summary**: While deep neural networks can attain good accuracy on in-distribution test points, many applications require robustness even in the face of unexpected perturbations in the input, changes in the domain, or other sources of distribution shift. We study the problem of test time robustification, i.e., using the test input to improve model robustness. Recent prior works have proposed methods for test time adaptation, however, they each introduce additional assumptions, such as access to multiple test points, that prevent widespread adoption. In this work, we aim to study and devise methods that make no assumptions about the model training process and are broadly applicable at test time. We propose a simple approach that can be used in any test setting where the model is probabilistic and adaptable: when presented with a test example, perform different data augmentations on the data point, and then adapt (all of) the model parameters by minimizing the entropy of the model's average, or marginal, output distribution across the augmentations. Intuitively, this objective encourages the model to make the same prediction across different augmentations, thus enforcing the invariances encoded in these augmentations, while also maintaining confidence in its predictions. In our experiments, we evaluate two baseline ResNet models, two robust ResNet-50 models, and a robust vision transformer model, and we demonstrate that this approach achieves accuracy gains of 1-8\% over standard model evaluation and also generally outperforms prior augmentation and adaptation strategies. For the setting in which only one test point is available, we achieve state-of-the-art results on the ImageNet-C, ImageNet-R, and, among ResNet-50 models, ImageNet-A distribution shift benchmarks.



### Deep CNNs for Peripheral Blood Cell Classification
- **Arxiv ID**: http://arxiv.org/abs/2110.09508v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09508v1)
- **Published**: 2021-10-18 17:56:07+00:00
- **Updated**: 2021-10-18 17:56:07+00:00
- **Authors**: Ekta Gavas, Kaustubh Olpadkar
- **Comment**: 20 pages, 14 figures, Submitted at MIDL 2021
- **Journal**: None
- **Summary**: The application of machine learning techniques to the medical domain is especially challenging due to the required level of precision and the incurrence of huge risks of minute errors. Employing these techniques to a more complex subdomain of hematological diagnosis seems quite promising, with automatic identification of blood cell types, which can help in detection of hematologic disorders. In this paper, we benchmark 27 popular deep convolutional neural network architectures on the microscopic peripheral blood cell images dataset. The dataset is publicly available, with large number of normal peripheral blood cells acquired using the CellaVision DM96 analyzer and identified by expert pathologists into eight different cell types. We fine-tune the state-of-the-art image classification models pre-trained on the ImageNet dataset for blood cell classification. We exploit data augmentation techniques during training to avoid overfitting and achieve generalization. An ensemble of the top performing models obtains significant improvements over past published works, achieving the state-of-the-art results with a classification accuracy of 99.51%. Our work provides empirical baselines and benchmarks on standard deep-learning architectures for microscopic peripheral blood cell recognition task.



### Unsupervised Finetuning
- **Arxiv ID**: http://arxiv.org/abs/2110.09510v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2110.09510v1)
- **Published**: 2021-10-18 17:57:05+00:00
- **Updated**: 2021-10-18 17:57:05+00:00
- **Authors**: Suichan Li, Dongdong Chen, Yinpeng Chen, Lu Yuan, Lei Zhang, Qi Chu, Bin Liu, Nenghai Yu
- **Comment**: None
- **Journal**: None
- **Summary**: This paper studies "unsupervised finetuning", the symmetrical problem of the well-known "supervised finetuning". Given a pretrained model and small-scale unlabeled target data, unsupervised finetuning is to adapt the representation pretrained from the source domain to the target domain so that better transfer performance can be obtained. This problem is more challenging than the supervised counterpart, as the low data density in the small-scale target data is not friendly for unsupervised learning, leading to the damage of the pretrained representation and poor representation in the target domain. In this paper, we find the source data is crucial when shifting the finetuning paradigm from supervise to unsupervise, and propose two simple and effective strategies to combine source and target data into unsupervised finetuning: "sparse source data replaying", and "data mixing". The motivation of the former strategy is to add a small portion of source data back to occupy their pretrained representation space and help push the target data to reside in a smaller compact space; and the motivation of the latter strategy is to increase the data density and help learn more compact representation. To demonstrate the effectiveness of our proposed ``unsupervised finetuning'' strategy, we conduct extensive experiments on multiple different target datasets, which show better transfer performance than the naive strategy.



### Discovering and Achieving Goals via World Models
- **Arxiv ID**: http://arxiv.org/abs/2110.09514v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2110.09514v1)
- **Published**: 2021-10-18 17:59:58+00:00
- **Updated**: 2021-10-18 17:59:58+00:00
- **Authors**: Russell Mendonca, Oleh Rybkin, Kostas Daniilidis, Danijar Hafner, Deepak Pathak
- **Comment**: NeurIPS 2021. First two authors contributed equally. Website at
  https://orybkin.github.io/lexa/
- **Journal**: None
- **Summary**: How can artificial agents learn to solve many diverse tasks in complex visual environments in the absence of any supervision? We decompose this question into two problems: discovering new goals and learning to reliably achieve them. We introduce Latent Explorer Achiever (LEXA), a unified solution to these that learns a world model from image inputs and uses it to train an explorer and an achiever policy from imagined rollouts. Unlike prior methods that explore by reaching previously visited states, the explorer plans to discover unseen surprising states through foresight, which are then used as diverse targets for the achiever to practice. After the unsupervised phase, LEXA solves tasks specified as goal images zero-shot without any additional learning. LEXA substantially outperforms previous approaches to unsupervised goal-reaching, both on prior benchmarks and on a new challenging benchmark with a total of 40 test tasks spanning across four standard robotic manipulation and locomotion domains. LEXA further achieves goals that require interacting with multiple objects in sequence. Finally, to demonstrate the scalability and generality of LEXA, we train a single general agent across four distinct environments. Code and videos at https://orybkin.github.io/lexa/



### TransFusion: Cross-view Fusion with Transformer for 3D Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/2110.09554v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09554v3)
- **Published**: 2021-10-18 18:08:18+00:00
- **Updated**: 2021-12-09 05:01:53+00:00
- **Authors**: Haoyu Ma, Liangjian Chen, Deying Kong, Zhe Wang, Xingwei Liu, Hao Tang, Xiangyi Yan, Yusheng Xie, Shih-Yao Lin, Xiaohui Xie
- **Comment**: BMVC 2021. Code is available at:
  https://github.com/HowieMa/TransFusion-Pose
- **Journal**: None
- **Summary**: Estimating the 2D human poses in each view is typically the first step in calibrated multi-view 3D pose estimation. But the performance of 2D pose detectors suffers from challenging situations such as occlusions and oblique viewing angles. To address these challenges, previous works derive point-to-point correspondences between different views from epipolar geometry and utilize the correspondences to merge prediction heatmaps or feature representations. Instead of post-prediction merge/calibration, here we introduce a transformer framework for multi-view 3D pose estimation, aiming at directly improving individual 2D predictors by integrating information from different views. Inspired by previous multi-modal transformers, we design a unified transformer architecture, named TransFusion, to fuse cues from both current views and neighboring views. Moreover, we propose the concept of epipolar field to encode 3D positional information into the transformer model. The 3D position encoding guided by the epipolar field provides an efficient way of encoding correspondences between pixels of different views. Experiments on Human 3.6M and Ski-Pose show that our method is more efficient and has consistent improvements compared to other fusion methods. Specifically, we achieve 25.8 mm MPJPE on Human 3.6M with only 5M parameters on 256 x 256 resolution.



### BGaitR-Net: Occluded Gait Sequence reconstructionwith temporally constrained model for gait recognition
- **Arxiv ID**: http://arxiv.org/abs/2110.09564v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T10
- **Links**: [PDF](http://arxiv.org/pdf/2110.09564v1)
- **Published**: 2021-10-18 18:28:18+00:00
- **Updated**: 2021-10-18 18:28:18+00:00
- **Authors**: Somnath Sendhil Kumara, Pratik Chattopadhyaya, Lipo Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Recent advancements in computational resources and Deep Learning methodologies has significantly benefited development of intelligent vision-based surveillance applications. Gait recognition in the presence of occlusion is one of the challenging research topics in this area, and the solutions proposed by researchers to date lack in robustness and also dependent of several unrealistic constraints, which limits their practical applicability. We improve the state-of-the-art by developing novel deep learning-based algorithms to identify the occluded frames in an input sequence and next reconstruct these occluded frames by exploiting the spatio-temporal information present in the gait sequence. The multi-stage pipeline adopted in this work consists of key pose mapping, occlusion detection and reconstruction, and finally gait recognition. While the key pose mapping and occlusion detection phases are done %using Constrained KMeans Clustering and via a graph sorting algorithm, reconstruction of occluded frames is done by fusing the key pose-specific information derived in the previous step along with the spatio-temporal information contained in a gait sequence using a Bi-Directional Long Short Time Memory. This occlusion reconstruction model has been trained using synthetically occluded CASIA-B and OU-ISIR data, and the trained model is termed as Bidirectional Gait Reconstruction Network BGait-R-Net. Our LSTM-based model reconstructs occlusion and generates frames that are temporally consistent with the periodic pattern of a gait cycle, while simultaneously preserving the body structure.



### Hands Off: A Handshake Interaction Detection and Localization Model for COVID-19 Threat Control
- **Arxiv ID**: http://arxiv.org/abs/2110.09571v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09571v1)
- **Published**: 2021-10-18 18:49:28+00:00
- **Updated**: 2021-10-18 18:49:28+00:00
- **Authors**: A. S. Jameel Hassan, Suren Sritharan, Gihan Jayatilaka, Roshan I. Godaliyadda, Parakrama B. Ekanayake, Vijitha Herath, Janaka B. Ekanayake
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: The COVID-19 outbreak has affected millions of people across the globe and is continuing to spread at a drastic scale. Out of the numerous steps taken to control the spread of the virus, social distancing has been a crucial and effective practice. However, recent reports of social distancing violations suggest the need for non-intrusive detection techniques to ensure safety in public spaces. In this paper, a real-time detection model is proposed to identify handshake interactions in a range of realistic scenarios with multiple people in the scene and also detect multiple interactions in a single frame. This is the first work that performs dyadic interaction localization in a multi-person setting. The efficacy of the proposed model was evaluated across two different datasets on more than 3200 frames, thus enabling a robust localization model in different environments. The proposed model is the first dyadic interaction localizer in a multi-person setting, which enables it to be used in public spaces to identify handshake interactions and thereby identify and mitigate COVID-19 transmission.



### Dynamic Feature Alignment for Semi-supervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2110.09641v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2110.09641v1)
- **Published**: 2021-10-18 22:26:27+00:00
- **Updated**: 2021-10-18 22:26:27+00:00
- **Authors**: Yu Zhang, Gongbo Liang, Nathan Jacobs
- **Comment**: BMVC 2021
- **Journal**: None
- **Summary**: Most research on domain adaptation has focused on the purely unsupervised setting, where no labeled examples in the target domain are available. However, in many real-world scenarios, a small amount of labeled target data is available and can be used to improve adaptation. We address this semi-supervised setting and propose to use dynamic feature alignment to address both inter- and intra-domain discrepancy. Unlike previous approaches, which attempt to align source and target features within a mini-batch, we propose to align the target features to a set of dynamically updated class prototypes, which we use both for minimizing divergence and pseudo-labeling. By updating based on class prototypes, we avoid problems that arise in previous approaches due to class imbalances. Our approach, which doesn't require extensive tuning or adversarial training, significantly improves the state of the art for semi-supervised domain adaptation. We provide a quantitative evaluation on two standard datasets, DomainNet and Office-Home, and performance analysis.



### Channel redundancy and overlap in convolutional neural networks with channel-wise NNK graphs
- **Arxiv ID**: http://arxiv.org/abs/2110.11400v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2110.11400v1)
- **Published**: 2021-10-18 22:50:07+00:00
- **Updated**: 2021-10-18 22:50:07+00:00
- **Authors**: David Bonet, Antonio Ortega, Javier Ruiz-Hidalgo, Sarath Shekkizhar
- **Comment**: Under review at ICASSP
- **Journal**: None
- **Summary**: Feature spaces in the deep layers of convolutional neural networks (CNNs) are often very high-dimensional and difficult to interpret. However, convolutional layers consist of multiple channels that are activated by different types of inputs, which suggests that more insights may be gained by studying the channels and how they relate to each other. In this paper, we first analyze theoretically channel-wise non-negative kernel (CW-NNK) regression graphs, which allow us to quantify the overlap between channels and, indirectly, the intrinsic dimension of the data representation manifold. We find that redundancy between channels is significant and varies with the layer depth and the level of regularization during training. Additionally, we observe that there is a correlation between channel overlap in the last convolutional layer and generalization performance. Our experimental results demonstrate that these techniques can lead to a better understanding of deep representations.



