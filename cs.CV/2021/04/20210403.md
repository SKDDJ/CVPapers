# Arxiv Papers in cs.CV on 2021-04-03
### Instance Level Affinity-Based Transfer for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2104.01286v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01286v1)
- **Published**: 2021-04-03 01:33:14+00:00
- **Updated**: 2021-04-03 01:33:14+00:00
- **Authors**: Astuti Sharma, Tarun Kalluri, Manmohan Chandraker
- **Comment**: CVPR 2021 (Conference on Computer Vision and Pattern Recognition)
- **Journal**: None
- **Summary**: Domain adaptation deals with training models using large scale labeled data from a specific source domain and then adapting the knowledge to certain target domains that have few or no labels. Many prior works learn domain agnostic feature representations for this purpose using a global distribution alignment objective which does not take into account the finer class specific structure in the source and target domains. We address this issue in our work and propose an instance affinity based criterion for source to target transfer during adaptation, called ILA-DA. We first propose a reliable and efficient method to extract similar and dissimilar samples across source and target, and utilize a multi-sample contrastive loss to drive the domain alignment process. ILA-DA simultaneously accounts for intra-class clustering as well as inter-class separation among the categories, resulting in less noisy classifier boundaries, improved transferability and increased accuracy. We verify the effectiveness of ILA-DA by observing consistent improvements in accuracy over popular domain adaptation approaches on a variety of benchmark datasets and provide insights into the proposed alignment approach. Code will be made publicly available at https://github.com/astuti/ILA-DA.



### Fingerspelling Detection in American Sign Language
- **Arxiv ID**: http://arxiv.org/abs/2104.01291v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/2104.01291v1)
- **Published**: 2021-04-03 02:11:09+00:00
- **Updated**: 2021-04-03 02:11:09+00:00
- **Authors**: Bowen Shi, Diane Brentari, Greg Shakhnarovich, Karen Livescu
- **Comment**: CVPR 2021
- **Journal**: None
- **Summary**: Fingerspelling, in which words are signed letter by letter, is an important component of American Sign Language. Most previous work on automatic fingerspelling recognition has assumed that the boundaries of fingerspelling regions in signing videos are known beforehand. In this paper, we consider the task of fingerspelling detection in raw, untrimmed sign language videos. This is an important step towards building real-world fingerspelling recognition systems. We propose a benchmark and a suite of evaluation metrics, some of which reflect the effect of detection on the downstream fingerspelling recognition task. In addition, we propose a new model that learns to detect fingerspelling via multi-task training, incorporating pose estimation and fingerspelling recognition (transcription) along with detection, and compare this model to several alternatives. The model outperforms all alternative approaches across all metrics, establishing a state of the art on the benchmark.



### Multimedia Technology Applications and Algorithms: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2104.01301v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.01301v1)
- **Published**: 2021-04-03 03:23:06+00:00
- **Updated**: 2021-04-03 03:23:06+00:00
- **Authors**: Palak Tiwary, Sanjida Ahmed
- **Comment**: None
- **Journal**: None
- **Summary**: Multimedia related research and development has evolved rapidly in the last few years with advancements in hardware, software and network infrastructures. As a result, multimedia has been integrated into domains like Healthcare and Medicine, Human facial feature extraction and tracking, pose recognition, disparity estimation, etc. This survey gives an overview of the various multimedia technologies and algorithms developed in the domains mentioned.



### Efficient DETR: Improving End-to-End Object Detector with Dense Prior
- **Arxiv ID**: http://arxiv.org/abs/2104.01318v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01318v1)
- **Published**: 2021-04-03 06:14:24+00:00
- **Updated**: 2021-04-03 06:14:24+00:00
- **Authors**: Zhuyu Yao, Jiangbo Ai, Boxun Li, Chi Zhang
- **Comment**: 10 pages, 5 figures, 10 tables
- **Journal**: None
- **Summary**: The recently proposed end-to-end transformer detectors, such as DETR and Deformable DETR, have a cascade structure of stacking 6 decoder layers to update object queries iteratively, without which their performance degrades seriously. In this paper, we investigate that the random initialization of object containers, which include object queries and reference points, is mainly responsible for the requirement of multiple iterations. Based on our findings, we propose Efficient DETR, a simple and efficient pipeline for end-to-end object detection. By taking advantage of both dense detection and sparse set detection, Efficient DETR leverages dense prior to initialize the object containers and brings the gap of the 1-decoder structure and 6-decoder structure. Experiments conducted on MS COCO show that our method, with only 3 encoder layers and 1 decoder layer, achieves competitive performance with state-of-the-art object detection methods. Efficient DETR is also robust in crowded scenes. It outperforms modern detectors on CrowdHuman dataset by a large margin.



### DARCNN: Domain Adaptive Region-based Convolutional Neural Network for Unsupervised Instance Segmentation in Biomedical Images
- **Arxiv ID**: http://arxiv.org/abs/2104.01325v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.10
- **Links**: [PDF](http://arxiv.org/pdf/2104.01325v1)
- **Published**: 2021-04-03 06:54:33+00:00
- **Updated**: 2021-04-03 06:54:33+00:00
- **Authors**: Joy Hsu, Wah Chiu, Serena Yeung
- **Comment**: To appear at CVPR 2021
- **Journal**: None
- **Summary**: In the biomedical domain, there is an abundance of dense, complex data where objects of interest may be challenging to detect or constrained by limits of human knowledge. Labelled domain specific datasets for supervised tasks are often expensive to obtain, and furthermore discovery of novel distinct objects may be desirable for unbiased scientific discovery. Therefore, we propose leveraging the wealth of annotations in benchmark computer vision datasets to conduct unsupervised instance segmentation for diverse biomedical datasets. The key obstacle is thus overcoming the large domain shift from common to biomedical images. We propose a Domain Adaptive Region-based Convolutional Neural Network (DARCNN), that adapts knowledge of object definition from COCO, a large labelled vision dataset, to multiple biomedical datasets. We introduce a domain separation module, a self-supervised representation consistency loss, and an augmented pseudo-labelling stage within DARCNN to effectively perform domain adaptation across such large domain shifts. We showcase DARCNN's performance for unsupervised instance segmentation on numerous biomedical datasets.



### Cross-Modal learning for Audio-Visual Video Parsing
- **Arxiv ID**: http://arxiv.org/abs/2104.04598v2
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, cs.LG, eess.AS, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2104.04598v2)
- **Published**: 2021-04-03 07:07:21+00:00
- **Updated**: 2021-06-21 10:56:29+00:00
- **Authors**: Jatin Lamba, Abhishek, Jayaprakash Akula, Rishabh Dabral, Preethi Jyothi, Ganesh Ramakrishnan
- **Comment**: Work accepted at Interspeech 2021
- **Journal**: None
- **Summary**: In this paper, we present a novel approach to the audio-visual video parsing (AVVP) task that demarcates events from a video separately for audio and visual modalities. The proposed parsing approach simultaneously detects the temporal boundaries in terms of start and end times of such events. We show how AVVP can benefit from the following techniques geared towards effective cross-modal learning: (i) adversarial training and skip connections (ii) global context aware attention and, (iii) self-supervised pretraining using an audio-video grounding objective to obtain cross-modal audio-video representations. We present extensive experimental evaluations on the Look, Listen, and Parse (LLP) dataset and show that we outperform the state-of-the-art Hybrid Attention Network (HAN) on all five metrics proposed for AVVP. We also present several ablations to validate the effect of pretraining, global attention and adversarial training.



### Uncertainty for Identifying Open-Set Errors in Visual Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2104.01328v2
- **DOI**: 10.1109/LRA.2021.3123374
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2104.01328v2)
- **Published**: 2021-04-03 07:12:31+00:00
- **Updated**: 2021-11-12 04:18:05+00:00
- **Authors**: Dimity Miller, Niko SÃ¼nderhauf, Michael Milford, Feras Dayoub
- **Comment**: None
- **Journal**: IEEE Robotics and Automation Letters (January 2022), Volume 7,
  Issue 1, pages 215-222, ISSN 2377-3766
- **Summary**: Deployed into an open world, object detectors are prone to open-set errors, false positive detections of object classes not present in the training dataset. We propose GMM-Det, a real-time method for extracting epistemic uncertainty from object detectors to identify and reject open-set errors. GMM-Det trains the detector to produce a structured logit space that is modelled with class-specific Gaussian Mixture Models. At test time, open-set errors are identified by their low log-probability under all Gaussian Mixture Models. We test two common detector architectures, Faster R-CNN and RetinaNet, across three varied datasets spanning robotics and computer vision. Our results show that GMM-Det consistently outperforms existing uncertainty techniques for identifying and rejecting open-set detections, especially at the low-error-rate operating point required for safety-critical applications. GMM-Det maintains object detection performance, and introduces only minimal computational overhead. We also introduce a methodology for converting existing object detection datasets into specific open-set datasets to evaluate open-set performance in object detection.



### Recursively Refined R-CNN: Instance Segmentation with Self-RoI Rebalancing
- **Arxiv ID**: http://arxiv.org/abs/2104.01329v2
- **DOI**: 10.1007/978-3-030-89128-2_46
- **Categories**: **cs.CV**, I.4.6; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/2104.01329v2)
- **Published**: 2021-04-03 07:25:33+00:00
- **Updated**: 2021-08-02 09:36:09+00:00
- **Authors**: Leonardo Rossi, Akbar Karimi, Andrea Prati
- **Comment**: None
- **Journal**: International Conference on Computer Analysis of Images and
  Patterns. Springer, Cham, 2021
- **Summary**: Within the field of instance segmentation, most of the state-of-the-art deep learning networks rely nowadays on cascade architectures, where multiple object detectors are trained sequentially, re-sampling the ground truth at each step. This offers a solution to the problem of exponentially vanishing positive samples. However, it also translates into an increase in network complexity in terms of the number of parameters. To address this issue, we propose Recursively Refined R-CNN (R^3-CNN) which avoids duplicates by introducing a loop mechanism instead. At the same time, it achieves a quality boost using a recursive re-sampling technique, where a specific IoU quality is utilized in each recursion to eventually equally cover the positive spectrum. Our experiments highlight the specific encoding of the loop mechanism in the weights, requiring its usage at inference time. The R^3-CNN architecture is able to surpass the recently proposed HTC model, while reducing the number of parameters significantly. Experiments on COCO minival 2017 dataset show performance boost independently from the utilized baseline model. The code is available online at https://github.com/IMPLabUniPr/mmdetection/tree/r3_cnn.



### Generation of Gradient-Preserving Images allowing HOG Feature Extraction
- **Arxiv ID**: http://arxiv.org/abs/2104.01350v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01350v2)
- **Published**: 2021-04-03 09:06:58+00:00
- **Updated**: 2021-05-22 06:46:37+00:00
- **Authors**: Masaki Kitayama, Hitoshi Kiya
- **Comment**: Accepted for publication in IEEE International Conference on Consumer
  Electronics - Taiwan, 2021(ICCE-TW 2021)
- **Journal**: None
- **Summary**: In this paper, we propose a method for generating visually protected images, referred to as gradient-preserving images. The protected images allow us to directly extract Histogram-of-Oriented-Gradients (HOG) features for privacy-preserving machine learning. In an experiment, HOG features extracted from gradient-preserving images are applied to a face recognition algorithm to demonstrate the effectiveness of the proposed method.



### Deepfake Detection Scheme Based on Vision Transformer and Distillation
- **Arxiv ID**: http://arxiv.org/abs/2104.01353v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2104.01353v1)
- **Published**: 2021-04-03 09:13:05+00:00
- **Updated**: 2021-04-03 09:13:05+00:00
- **Authors**: Young-Jin Heo, Young-Ju Choi, Young-Woon Lee, Byung-Gyu Kim
- **Comment**: 7 pages, 5 figures
- **Journal**: None
- **Summary**: Deepfake is the manipulated video made with a generative deep learning technique such as Generative Adversarial Networks (GANs) or Auto Encoder that anyone can utilize. Recently, with the increase of Deepfake videos, some classifiers consisting of the convolutional neural network that can distinguish fake videos as well as deepfake datasets have been actively created. However, the previous studies based on the CNN structure have the problem of not only overfitting, but also considerable misjudging fake video as real ones. In this paper, we propose a Vision Transformer model with distillation methodology for detecting fake videos. We design that a CNN features and patch-based positioning model learns to interact with all positions to find the artifact region for solving false negative problem. Through comparative analysis on Deepfake Detection (DFDC) Dataset, we verify that the proposed scheme with patch embedding as input outperforms the state-of-the-art using the combined CNN features. Without ensemble technique, our model obtains 0.978 of AUC and 91.9 of f1 score, while previous SOTA model yields 0.972 of AUC and 90.6 of f1 score on the same condition.



### Mutual Graph Learning for Camouflaged Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2104.02613v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.02613v1)
- **Published**: 2021-04-03 10:14:39+00:00
- **Updated**: 2021-04-03 10:14:39+00:00
- **Authors**: Qiang Zhai, Xin Li, Fan Yang, Chenglizhao Chen, Hong Cheng, Deng-Ping Fan
- **Comment**: None
- **Journal**: None
- **Summary**: Automatically detecting/segmenting object(s) that blend in with their surroundings is difficult for current models. A major challenge is that the intrinsic similarities between such foreground objects and background surroundings make the features extracted by deep model indistinguishable. To overcome this challenge, an ideal model should be able to seek valuable, extra clues from the given scene and incorporate them into a joint learning framework for representation co-enhancement. With this inspiration, we design a novel Mutual Graph Learning (MGL) model, which generalizes the idea of conventional mutual learning from regular grids to the graph domain. Specifically, MGL decouples an image into two task-specific feature maps -- one for roughly locating the target and the other for accurately capturing its boundary details -- and fully exploits the mutual benefits by recurrently reasoning their high-order relations through graphs. Importantly, in contrast to most mutual learning approaches that use a shared function to model all between-task interactions, MGL is equipped with typed functions for handling different complementary relations to maximize information interactions. Experiments on challenging datasets, including CHAMELEON, CAMO and COD10K, demonstrate the effectiveness of our MGL with superior performance to existing state-of-the-art methods.



### Interpretable Unsupervised Diversity Denoising and Artefact Removal
- **Arxiv ID**: http://arxiv.org/abs/2104.01374v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2104.01374v2)
- **Published**: 2021-04-03 11:00:21+00:00
- **Updated**: 2022-02-24 18:27:09+00:00
- **Authors**: Mangal Prakash, Mauricio Delbracio, Peyman Milanfar, Florian Jug
- **Comment**: None
- **Journal**: None
- **Summary**: Image denoising and artefact removal are complex inverse problems admitting multiple valid solutions. Unsupervised diversity restoration, that is, obtaining a diverse set of possible restorations given a corrupted image, is important for ambiguity removal in many applications such as microscopy where paired data for supervised training are often unobtainable. In real world applications, imaging noise and artefacts are typically hard to model, leading to unsatisfactory performance of existing unsupervised approaches. This work presents an interpretable approach for unsupervised and diverse image restoration. To this end, we introduce a capable architecture called Hierarchical DivNoising (HDN) based on hierarchical Variational Autoencoder. We show that HDN learns an interpretable multi-scale representation of artefacts and we leverage this interpretability to remove imaging artefacts commonly occurring in microscopy data. Our method achieves state-of-the-art results on twelve benchmark image denoising datasets while providing access to a whole distribution of sensibly restored solutions. Additionally, we demonstrate on three real microscopy datasets that HDN removes artefacts without supervision, being the first method capable of doing so while generating multiple plausible restorations all consistent with the given corrupted image.



### Evaluating explainable artificial intelligence methods for multi-label deep learning classification tasks in remote sensing
- **Arxiv ID**: http://arxiv.org/abs/2104.01375v2
- **DOI**: 10.1016/j.jag.2021.102520
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.01375v2)
- **Published**: 2021-04-03 11:13:14+00:00
- **Updated**: 2021-09-20 11:04:15+00:00
- **Authors**: Ioannis Kakogeorgiou, Konstantinos Karantzalos
- **Comment**: None
- **Journal**: International Journal of Applied Earth Observation and
  Geoinformation 103 (2021) 102520
- **Summary**: Although deep neural networks hold the state-of-the-art in several remote sensing tasks, their black-box operation hinders the understanding of their decisions, concealing any bias and other shortcomings in datasets and model performance. To this end, we have applied explainable artificial intelligence (XAI) methods in remote sensing multi-label classification tasks towards producing human-interpretable explanations and improve transparency. In particular, we utilized and trained deep learning models with state-of-the-art performance in the benchmark BigEarthNet and SEN12MS datasets. Ten XAI methods were employed towards understanding and interpreting models' predictions, along with quantitative metrics to assess and compare their performance. Numerous experiments were performed to assess the overall performance of XAI methods for straightforward prediction cases, competing multiple labels, as well as misclassification cases. According to our findings, Occlusion, Grad-CAM and Lime were the most interpretable and reliable XAI methods. However, none delivers high-resolution outputs, while apart from Grad-CAM, both Lime and Occlusion are computationally expensive. We also highlight different aspects of XAI performance and elaborate with insights on black-box decisions in order to improve transparency, understand their behavior and reveal, as well, datasets' particularities.



### Learning Mobile CNN Feature Extraction Toward Fast Computation of Visual Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/2104.01381v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, 68T10, 68T05, 68T07
- **Links**: [PDF](http://arxiv.org/pdf/2104.01381v1)
- **Published**: 2021-04-03 11:49:54+00:00
- **Updated**: 2021-04-03 11:49:54+00:00
- **Authors**: Tsubasa Murate, Takashi Watanabe, Masaki Yamada
- **Comment**: 9 pages, 17 figures
- **Journal**: None
- **Summary**: In this paper, we construct a lightweight, high-precision and high-speed object tracking using a trained CNN. Conventional methods with trained CNNs use VGG16 network which requires powerful computational resources. Therefore, there is a problem that it is difficult to apply in low computation resources environments. To solve this problem, we use MobileNetV3, which is a CNN for mobile terminals.Based on Feature Map Selection Tracking, we propose a new architecture that extracts effective features of MobileNet for object tracking. The architecture requires no online learning but only offline learning. In addition, by using features of objects other than tracking target, the features of tracking target are extracted more efficiently. We measure the tracking accuracy with Visual Tracker Benchmark and confirm that the proposed method can perform high-precision and high-speed calculation even in low computation resource environments.



### MMBERT: Multimodal BERT Pretraining for Improved Medical VQA
- **Arxiv ID**: http://arxiv.org/abs/2104.01394v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2104.01394v1)
- **Published**: 2021-04-03 13:01:19+00:00
- **Updated**: 2021-04-03 13:01:19+00:00
- **Authors**: Yash Khare, Viraj Bagal, Minesh Mathew, Adithi Devi, U Deva Priyakumar, CV Jawahar
- **Comment**: None
- **Journal**: None
- **Summary**: Images in the medical domain are fundamentally different from the general domain images. Consequently, it is infeasible to directly employ general domain Visual Question Answering (VQA) models for the medical domain. Additionally, medical images annotation is a costly and time-consuming process. To overcome these limitations, we propose a solution inspired by self-supervised pretraining of Transformer-style architectures for NLP, Vision and Language tasks. Our method involves learning richer medical image and text semantic representations using Masked Language Modeling (MLM) with image features as the pretext task on a large medical image+caption dataset. The proposed solution achieves new state-of-the-art performance on two VQA datasets for radiology images -- VQA-Med 2019 and VQA-RAD, outperforming even the ensemble models of previous best solutions. Moreover, our solution provides attention maps which help in model interpretability. The code is available at https://github.com/VirajBagal/MMBERT



### IDOL-Net: An Interactive Dual-Domain Parallel Network for CT Metal Artifact Reduction
- **Arxiv ID**: http://arxiv.org/abs/2104.01405v1
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.01405v1)
- **Published**: 2021-04-03 13:50:34+00:00
- **Updated**: 2021-04-03 13:50:34+00:00
- **Authors**: Tao Wang, Wenjun Xia, Zexin Lu, Huaiqiang Sun, Yan Liu, Hu Chen, Jiliu Zhou, Yi Zhang
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: Due to the presence of metallic implants, the imaging quality of computed tomography (CT) would be heavily degraded. With the rapid development of deep learning, several network models have been proposed for metal artifact reduction (MAR). Since the dual-domain MAR methods can leverage the hybrid information from both sinogram and image domains, they have significantly improved the performance compared to single-domain methods. However,current dual-domain methods usually operate on both domains in a specific order, which implicitly imposes a certain priority prior into MAR and may ignore the latent information interaction between both domains. To address this problem, in this paper, we propose a novel interactive dualdomain parallel network for CT MAR, dubbed as IDOLNet. Different from existing dual-domain methods, the proposed IDOL-Net is composed of two modules. The disentanglement module is utilized to generate high-quality prior sinogram and image as the complementary inputs. The follow-up refinement module consists of two parallel and interactive branches that simultaneously operate on image and sinogram domain, fully exploiting the latent information interaction between both domains. The simulated and clinical results demonstrate that the proposed IDOL-Net outperforms several state-of-the-art models in both qualitative and quantitative aspects.



### Graph Contrastive Clustering
- **Arxiv ID**: http://arxiv.org/abs/2104.01429v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01429v1)
- **Published**: 2021-04-03 15:32:49+00:00
- **Updated**: 2021-04-03 15:32:49+00:00
- **Authors**: Huasong Zhong, Jianlong Wu, Chong Chen, Jianqiang Huang, Minghua Deng, Liqiang Nie, Zhouchen Lin, Xian-Sheng Hua
- **Comment**: 10
- **Journal**: None
- **Summary**: Recently, some contrastive learning methods have been proposed to simultaneously learn representations and clustering assignments, achieving significant improvements. However, these methods do not take the category information and clustering objective into consideration, thus the learned representations are not optimal for clustering and the performance might be limited. Towards this issue, we first propose a novel graph contrastive learning framework, which is then applied to the clustering task and we come up with the Graph Constrastive Clustering~(GCC) method. Different from basic contrastive clustering that only assumes an image and its augmentation should share similar representation and clustering assignments, we lift the instance-level consistency to the cluster-level consistency with the assumption that samples in one cluster and their augmentations should all be similar. Specifically, on the one hand, the graph Laplacian based contrastive loss is proposed to learn more discriminative and clustering-friendly features. On the other hand, a novel graph-based contrastive learning strategy is proposed to learn more compact clustering assignments. Both of them incorporate the latent category information to reduce the intra-cluster variance while increasing the inter-cluster variance. Experiments on six commonly used datasets demonstrate the superiority of our proposed approach over the state-of-the-art methods.



### Aggregated Contextual Transformations for High-Resolution Image Inpainting
- **Arxiv ID**: http://arxiv.org/abs/2104.01431v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01431v1)
- **Published**: 2021-04-03 15:50:17+00:00
- **Updated**: 2021-04-03 15:50:17+00:00
- **Authors**: Yanhong Zeng, Jianlong Fu, Hongyang Chao, Baining Guo
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
- **Journal**: None
- **Summary**: State-of-the-art image inpainting approaches can suffer from generating distorted structures and blurry textures in high-resolution images (e.g., 512x512). The challenges mainly drive from (1) image content reasoning from distant contexts, and (2) fine-grained texture synthesis for a large missing region. To overcome these two challenges, we propose an enhanced GAN-based model, named Aggregated COntextual-Transformation GAN (AOT-GAN), for high-resolution image inpainting. Specifically, to enhance context reasoning, we construct the generator of AOT-GAN by stacking multiple layers of a proposed AOT block. The AOT blocks aggregate contextual transformations from various receptive fields, allowing to capture both informative distant image contexts and rich patterns of interest for context reasoning. For improving texture synthesis, we enhance the discriminator of AOT-GAN by training it with a tailored mask-prediction task. Such a training objective forces the discriminator to distinguish the detailed appearances of real and synthesized patches, and in turn, facilitates the generator to synthesize clear textures. Extensive comparisons on Places2, the most challenging benchmark with 1.8 million high-resolution images of 365 complex scenes, show that our model outperforms the state-of-the-art by a significant margin in terms of FID with 38.60% relative improvement. A user study including more than 30 subjects further validates the superiority of AOT-GAN. We further evaluate the proposed AOT-GAN in practical applications, e.g., logo removal, face editing, and object removal. Results show that our model achieves promising completions in the real world. We release code and models in https://github.com/researchmm/AOT-GAN-for-Inpainting.



### MR-Contrast-Aware Image-to-Image Translations with Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2104.01449v1
- **DOI**: 10.1007/s11548-021-02433-x
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.01449v1)
- **Published**: 2021-04-03 17:05:13+00:00
- **Updated**: 2021-04-03 17:05:13+00:00
- **Authors**: Jonas Denck, Jens Guehring, Andreas Maier, Eva Rothgang
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose   A Magnetic Resonance Imaging (MRI) exam typically consists of several sequences that yield different image contrasts. Each sequence is parameterized through multiple acquisition parameters that influence image contrast, signal-to-noise ratio, acquisition time, and/or resolution. Depending on the clinical indication, different contrasts are required by the radiologist to make a diagnosis. As MR sequence acquisition is time consuming and acquired images may be corrupted due to motion, a method to synthesize MR images with adjustable contrast properties is required.   Methods   Therefore, we trained an image-to-image generative adversarial network conditioned on the MR acquisition parameters repetition time and echo time. Our approach is motivated by style transfer networks, whereas the "style" for an image is explicitly given in our case, as it is determined by the MR acquisition parameters our network is conditioned on.   Results   This enables us to synthesize MR images with adjustable image contrast. We evaluated our approach on the fastMRI dataset, a large set of publicly available MR knee images, and show that our method outperforms a benchmark pix2pix approach in the translation of non-fat-saturated MR images to fat-saturated images. Our approach yields a peak signal-to-noise ratio and structural similarity of 24.48 and 0.66, surpassing the pix2pix benchmark model significantly.   Conclusion   Our model is the first that enables fine-tuned contrast synthesis, which can be used to synthesize missing MR contrasts or as a data augmentation technique for AI training in MRI.



### "Forget" the Forget Gate: Estimating Anomalies in Videos using Self-contained Long Short-Term Memory Networks
- **Arxiv ID**: http://arxiv.org/abs/2104.01478v1
- **DOI**: 10.1007/978-3-030-61864-3_15
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.01478v1)
- **Published**: 2021-04-03 20:43:49+00:00
- **Updated**: 2021-04-03 20:43:49+00:00
- **Authors**: Habtamu Fanta, Zhiwen Shao, Lizhuang Ma
- **Comment**: 16 pages, 7 figures, Computer Graphics International (CGI) 2020
- **Journal**: None
- **Summary**: Abnormal event detection is a challenging task that requires effectively handling intricate features of appearance and motion. In this paper, we present an approach of detecting anomalies in videos by learning a novel LSTM based self-contained network on normal dense optical flow. Due to their sigmoid implementations, standard LSTM's forget gate is susceptible to overlooking and dismissing relevant content in long sequence tasks like abnormality detection. The forget gate mitigates participation of previous hidden state for computation of cell state prioritizing current input. In addition, the hyperbolic tangent activation of standard LSTMs sacrifices performance when a network gets deeper. To tackle these two limitations, we introduce a bi-gated, light LSTM cell by discarding the forget gate and introducing sigmoid activation. Specifically, the LSTM architecture we come up with fully sustains content from previous hidden state thereby enabling the trained model to be robust and make context-independent decision during evaluation. Removing the forget gate results in a simplified and undemanding LSTM cell with improved performance effectiveness and computational efficiency. Empirical evaluations show that the proposed bi-gated LSTM based network outperforms various LSTM based models verifying its effectiveness for abnormality detection and generalization tasks on CUHK Avenue and UCSD datasets.



### Training Deep Normalizing Flow Models in Highly Incomplete Data Scenarios with Prior Regularization
- **Arxiv ID**: http://arxiv.org/abs/2104.01482v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.01482v1)
- **Published**: 2021-04-03 20:57:57+00:00
- **Updated**: 2021-04-03 20:57:57+00:00
- **Authors**: Edgar A. Bernal
- **Comment**: None
- **Journal**: None
- **Summary**: Deep generative frameworks including GANs and normalizing flow models have proven successful at filling in missing values in partially observed data samples by effectively learning -- either explicitly or implicitly -- complex, high-dimensional statistical distributions. In tasks where the data available for learning is only partially observed, however, their performance decays monotonically as a function of the data missingness rate. In high missing data rate regimes (e.g., 60% and above), it has been observed that state-of-the-art models tend to break down and produce unrealistic and/or semantically inaccurate data. We propose a novel framework to facilitate the learning of data distributions in high paucity scenarios that is inspired by traditional formulations of solutions to ill-posed problems. The proposed framework naturally stems from posing the process of learning from incomplete data as a joint optimization task of the parameters of the model being learned and the missing data values. The method involves enforcing a prior regularization term that seamlessly integrates with objectives used to train explicit and tractable deep generative frameworks such as deep normalizing flow models. We demonstrate via extensive experimental validation that the proposed framework outperforms competing techniques, particularly as the rate of data paucity approaches unity.



### Towards Self-Adaptive Metric Learning On the Fly
- **Arxiv ID**: http://arxiv.org/abs/2104.01495v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/2104.01495v1)
- **Published**: 2021-04-03 23:11:52+00:00
- **Updated**: 2021-04-03 23:11:52+00:00
- **Authors**: Yang Gao, Yi-Fan Li, Swarup Chandra, Latifur Khan, Bhavani Thuraisingham
- **Comment**: Accepted by WWW 2019 (Long Paper, Oral)
- **Journal**: None
- **Summary**: Good quality similarity metrics can significantly facilitate the performance of many large-scale, real-world applications. Existing studies have proposed various solutions to learn a Mahalanobis or bilinear metric in an online fashion by either restricting distances between similar (dissimilar) pairs to be smaller (larger) than a given lower (upper) bound or requiring similar instances to be separated from dissimilar instances with a given margin. However, these linear metrics learned by leveraging fixed bounds or margins may not perform well in real-world applications, especially when data distributions are complex. We aim to address the open challenge of "Online Adaptive Metric Learning" (OAML) for learning adaptive metric functions on the fly. Unlike traditional online metric learning methods, OAML is significantly more challenging since the learned metric could be non-linear and the model has to be self-adaptive as more instances are observed. In this paper, we present a new online metric learning framework that attempts to tackle the challenge by learning an ANN-based metric with adaptive model complexity from a stream of constraints. In particular, we propose a novel Adaptive-Bound Triplet Loss (ABTL) to effectively utilize the input constraints and present a novel Adaptive Hedge Update (AHU) method for online updating the model parameters. We empirically validate the effectiveness and efficacy of our framework on various applications such as real-world image classification, facial verification, and image retrieval.



