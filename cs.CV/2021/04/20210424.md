# Arxiv Papers in cs.CV on 2021-04-24
### Do All MobileNets Quantize Poorly? Gaining Insights into the Effect of Quantization on Depthwise Separable Convolutional Networks Through the Eyes of Multi-scale Distributional Dynamics
- **Arxiv ID**: http://arxiv.org/abs/2104.11849v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2104.11849v1)
- **Published**: 2021-04-24 01:28:29+00:00
- **Updated**: 2021-04-24 01:28:29+00:00
- **Authors**: Stone Yun, Alexander Wong
- **Comment**: Accepted for publication in Mobile AI (MAI) Workshop 2021 at CVPR
- **Journal**: None
- **Summary**: As the "Mobile AI" revolution continues to grow, so does the need to understand the behaviour of edge-deployed deep neural networks. In particular, MobileNets are the go-to family of deep convolutional neural networks (CNN) for mobile. However, they often have significant accuracy degradation under post-training quantization. While studies have introduced quantization-aware training and other methods to tackle this challenge, there is limited understanding into why MobileNets (and potentially depthwise-separable CNNs (DWSCNN) in general) quantize so poorly compared to other CNN architectures. Motivated to gain deeper insights into this phenomenon, we take a different strategy and study the multi-scale distributional dynamics of MobileNet-V1, a set of smaller DWSCNNs, and regular CNNs. Specifically, we investigate the impact of quantization on the weight and activation distributional dynamics as information propagates from layer to layer, as well as overall changes in distributional dynamics at the network level. This fine-grained analysis revealed significant dynamic range fluctuations and a "distributional mismatch" between channelwise and layerwise distributions in DWSCNNs that lead to increasing quantized degradation and distributional shift during information propagation. Furthermore, analysis of the activation quantization errors show that there is greater quantization error accumulation in DWSCNN compared to regular CNNs. The hope is that such insights can lead to innovative strategies for reducing such distributional dynamics changes and improve post-training quantization for mobile.



### Oriented Bounding Boxes for Small and Freely Rotated Objects
- **Arxiv ID**: http://arxiv.org/abs/2104.11854v1
- **DOI**: 10.1109/TGRS.2021.3076050
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11854v1)
- **Published**: 2021-04-24 02:04:49+00:00
- **Updated**: 2021-04-24 02:04:49+00:00
- **Authors**: Mohsen Zand, Ali Etemad, Michael Greenspan
- **Comment**: IEEE Transactions on Geoscience and Remote Sensing, 2021
- **Journal**: None
- **Summary**: A novel object detection method is presented that handles freely rotated objects of arbitrary sizes, including tiny objects as small as $2\times 2$ pixels. Such tiny objects appear frequently in remotely sensed images, and present a challenge to recent object detection algorithms. More importantly, current object detection methods have been designed originally to accommodate axis-aligned bounding box detection, and therefore fail to accurately localize oriented boxes that best describe freely rotated objects. In contrast, the proposed CNN-based approach uses potential pixel information at multiple scale levels without the need for any external resources, such as anchor boxes.The method encodes the precise location and orientation of features of the target objects at grid cell locations. Unlike existing methods which regress the bounding box location and dimension,the proposed method learns all the required information by classification, which has the added benefit of enabling oriented bounding box detection without any extra computation. It thus infers the bounding boxes only at inference time by finding the minimum surrounding box for every set of the same predicted class labels. Moreover, a rotation-invariant feature representation is applied to each scale, which imposes a regularization constraint to enforce covering the 360 degree range of in-plane rotation of the training samples to share similar features. Evaluations on the xView and DOTA datasets show that the proposed method uniformly improves performance over existing state-of-the-art methods.



### Class-Incremental Experience Replay for Continual Learning under Concept Drift
- **Arxiv ID**: http://arxiv.org/abs/2104.11861v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, I.4.0; I.5.0
- **Links**: [PDF](http://arxiv.org/pdf/2104.11861v1)
- **Published**: 2021-04-24 02:36:38+00:00
- **Updated**: 2021-04-24 02:36:38+00:00
- **Authors**: ≈Åukasz Korycki, Bartosz Krawczyk
- **Comment**: IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
  Workshops, 2021
- **Journal**: None
- **Summary**: Modern machine learning systems need to be able to cope with constantly arriving and changing data. Two main areas of research dealing with such scenarios are continual learning and data stream mining. Continual learning focuses on accumulating knowledge and avoiding forgetting, assuming information once learned should be stored. Data stream mining focuses on adaptation to concept drift and discarding outdated information, assuming that only the most recent data is relevant. While these two areas are mainly being developed in separation, they offer complementary views on the problem of learning from dynamic data. There is a need for unifying them, by offering architectures capable of both learning and storing new information, as well as revisiting and adapting to changes in previously seen concepts. We propose a novel continual learning approach that can handle both tasks. Our experience replay method is fueled by a centroid-driven memory storing diverse instances of incrementally arriving classes. This is enhanced with a reactive subspace buffer that tracks concept drift occurrences in previously seen classes and adapts clusters accordingly. The proposed architecture is thus capable of both remembering valid and forgetting outdated information, offering a holistic framework for continual learning under concept drift.



### Carrying out CNN Channel Pruning in a White Box
- **Arxiv ID**: http://arxiv.org/abs/2104.11883v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11883v4)
- **Published**: 2021-04-24 04:59:03+00:00
- **Updated**: 2022-01-28 08:59:09+00:00
- **Authors**: Yuxin Zhang, Mingbao Lin, Chia-Wen Lin, Jie Chen, Feiyue Huang, Yongjian Wu, Yonghong Tian, Rongrong Ji
- **Comment**: Accepted by IEEE Transactions on Neural Networks and Learning Systems
  (IEEE TNNLS)
- **Journal**: None
- **Summary**: Channel Pruning has been long studied to compress CNNs, which significantly reduces the overall computation. Prior works implement channel pruning in an unexplainable manner, which tends to reduce the final classification errors while failing to consider the internal influence of each channel. In this paper, we conduct channel pruning in a white box. Through deep visualization of feature maps activated by different channels, we observe that different channels have a varying contribution to different categories in image classification. Inspired by this, we choose to preserve channels contributing to most categories. Specifically, to model the contribution of each channel to differentiating categories, we develop a class-wise mask for each channel, implemented in a dynamic training manner w.r.t. the input image's category. On the basis of the learned class-wise mask, we perform a global voting mechanism to remove channels with less category discrimination. Lastly, a fine-tuning process is conducted to recover the performance of the pruned model. To our best knowledge, it is the first time that CNN interpretability theory is considered to guide channel pruning. Extensive experiments on representative image classification tasks demonstrate the superiority of our White-Box over many state-of-the-arts. For instance, on CIFAR-10, it reduces 65.23% FLOPs with even 0.62% accuracy improvement for ResNet-110. On ILSVRC-2012, White-Box achieves a 45.6% FLOPs reduction with only a small loss of 0.83% in the top-1 accuracy for ResNet-50.



### A Survey of Modern Deep Learning based Object Detection Models
- **Arxiv ID**: http://arxiv.org/abs/2104.11892v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2104.11892v2)
- **Published**: 2021-04-24 06:33:54+00:00
- **Updated**: 2021-05-12 16:45:20+00:00
- **Authors**: Syed Sahil Abbas Zaidi, Mohammad Samar Ansari, Asra Aslam, Nadia Kanwal, Mamoona Asghar, Brian Lee
- **Comment**: Preprint submitted to IET Computer Vision
- **Journal**: None
- **Summary**: Object Detection is the task of classification and localization of objects in an image or video. It has gained prominence in recent years due to its widespread applications. This article surveys recent developments in deep learning based object detectors. Concise overview of benchmark datasets and evaluation metrics used in detection is also provided along with some of the prominent backbone architectures used in recognition tasks. It also covers contemporary lightweight classification models used on edge devices. Lastly, we compare the performances of these architectures on multiple metrics.



### M3DeTR: Multi-representation, Multi-scale, Mutual-relation 3D Object Detection with Transformers
- **Arxiv ID**: http://arxiv.org/abs/2104.11896v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11896v3)
- **Published**: 2021-04-24 06:48:23+00:00
- **Updated**: 2021-10-22 19:02:01+00:00
- **Authors**: Tianrui Guan, Jun Wang, Shiyi Lan, Rohan Chandra, Zuxuan Wu, Larry Davis, Dinesh Manocha
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel architecture for 3D object detection, M3DeTR, which combines different point cloud representations (raw, voxels, bird-eye view) with different feature scales based on multi-scale feature pyramids. M3DeTR is the first approach that unifies multiple point cloud representations, feature scales, as well as models mutual relationships between point clouds simultaneously using transformers. We perform extensive ablation experiments that highlight the benefits of fusing representation and scale, and modeling the relationships. Our method achieves state-of-the-art performance on the KITTI 3D object detection dataset and Waymo Open Dataset. Results show that M3DeTR improves the baseline significantly by 1.48% mAP for all classes on Waymo Open Dataset. In particular, our approach ranks 1st on the well-known KITTI 3D Detection Benchmark for both car and cyclist classes, and ranks 1st on Waymo Open Dataset with single frame point cloud input. Our code is available at: https://github.com/rayguan97/M3DETR.



### Spatial-Spectral Clustering with Anchor Graph for Hyperspectral Image
- **Arxiv ID**: http://arxiv.org/abs/2104.11904v1
- **DOI**: 10.1109/TGRS.2022.3217597
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11904v1)
- **Published**: 2021-04-24 08:09:27+00:00
- **Updated**: 2021-04-24 08:09:27+00:00
- **Authors**: Qi Wang, Yanling Miao, Mulin Chen, Xuelong Li
- **Comment**: None
- **Journal**: None
- **Summary**: Hyperspectral image (HSI) clustering, which aims at dividing hyperspectral pixels into clusters, has drawn significant attention in practical applications. Recently, many graph-based clustering methods, which construct an adjacent graph to model the data relationship, have shown dominant performance. However, the high dimensionality of HSI data makes it hard to construct the pairwise adjacent graph. Besides, abundant spatial structures are often overlooked during the clustering procedure. In order to better handle the high dimensionality problem and preserve the spatial structures, this paper proposes a novel unsupervised approach called spatial-spectral clustering with anchor graph (SSCAG) for HSI data clustering. The SSCAG has the following contributions: 1) the anchor graph-based strategy is used to construct a tractable large graph for HSI data, which effectively exploits all data points and reduces the computational complexity; 2) a new similarity metric is presented to embed the spatial-spectral information into the combined adjacent graph, which can mine the intrinsic property structure of HSI data; 3) an effective neighbors assignment strategy is adopted in the optimization, which performs the singular value decomposition (SVD) on the adjacent graph to get solutions efficiently. Extensive experiments on three public HSI datasets show that the proposed SSCAG is competitive against the state-of-the-art approaches.



### EXplainable Neural-Symbolic Learning (X-NeSyL) methodology to fuse deep learning representations with expert knowledge graphs: the MonuMAI cultural heritage use case
- **Arxiv ID**: http://arxiv.org/abs/2104.11914v2
- **DOI**: 10.1016/j.inffus.2021.09.022
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.SC
- **Links**: [PDF](http://arxiv.org/pdf/2104.11914v2)
- **Published**: 2021-04-24 09:06:08+00:00
- **Updated**: 2021-10-13 06:17:12+00:00
- **Authors**: Natalia D√≠az-Rodr√≠guez, Alberto Lamas, Jules Sanchez, Gianni Franchi, Ivan Donadello, Siham Tabik, David Filliat, Policarpo Cruz, Rosana Montes, Francisco Herrera
- **Comment**: None
- **Journal**: None
- **Summary**: The latest Deep Learning (DL) models for detection and classification have achieved an unprecedented performance over classical machine learning algorithms. However, DL models are black-box methods hard to debug, interpret, and certify. DL alone cannot provide explanations that can be validated by a non technical audience. In contrast, symbolic AI systems that convert concepts into rules or symbols -- such as knowledge graphs -- are easier to explain. However, they present lower generalisation and scaling capabilities. A very important challenge is to fuse DL representations with expert knowledge. One way to address this challenge, as well as the performance-explainability trade-off is by leveraging the best of both streams without obviating domain expert knowledge. We tackle such problem by considering the symbolic knowledge is expressed in form of a domain expert knowledge graph. We present the eXplainable Neural-symbolic learning (X-NeSyL) methodology, designed to learn both symbolic and deep representations, together with an explainability metric to assess the level of alignment of machine and human expert explanations. The ultimate objective is to fuse DL representations with expert domain knowledge during the learning process to serve as a sound basis for explainability. X-NeSyL methodology involves the concrete use of two notions of explanation at inference and training time respectively: 1) EXPLANet: Expert-aligned eXplainable Part-based cLAssifier NETwork Architecture, a compositional CNN that makes use of symbolic representations, and 2) SHAP-Backprop, an explainable AI-informed training procedure that guides the DL process to align with such symbolic representations in form of knowledge graphs. We showcase X-NeSyL methodology using MonuMAI dataset for monument facade image classification, and demonstrate that our approach improves explainability and performance.



### Anomaly Detection for Solder Joints Using $Œ≤$-VAE
- **Arxiv ID**: http://arxiv.org/abs/2104.11927v2
- **DOI**: 10.1109/TCPMT.2021.3121265
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2104.11927v2)
- **Published**: 2021-04-24 11:19:27+00:00
- **Updated**: 2021-12-16 15:09:49+00:00
- **Authors**: Furkan Ulger, Seniha Esen Yuksel, Atila Yilmaz
- **Comment**: Published in IEEE Transactions on Components, Packaging and
  Manufacturing Technology
- **Journal**: in IEEE Transactions on Components, Packaging and Manufacturing
  Technology, vol. 11, no. 12, pp. 2214-2221, Dec. 2021
- **Summary**: In the assembly process of printed circuit boards (PCB), most of the errors are caused by solder joints in Surface Mount Devices (SMD). In the literature, traditional feature extraction based methods require designing hand-crafted features and rely on the tiered RGB illumination to detect solder joint errors, whereas the supervised Convolutional Neural Network (CNN) based approaches require a lot of labelled abnormal samples (defective solder joints) to achieve high accuracy. To solve the optical inspection problem in unrestricted environments with no special lighting and without the existence of error-free reference boards, we propose a new beta-Variational Autoencoders (beta-VAE) architecture for anomaly detection that can work on both IC and non-IC components. We show that the proposed model learns disentangled representation of data, leading to more independent features and improved latent space representations. We compare the activation and gradient-based representations that are used to characterize anomalies; and observe the effect of different beta parameters on accuracy and on untwining the feature representations in beta-VAE. Finally, we show that anomalies on solder joints can be detected with high accuracy via a model trained on directly normal samples without designated hardware or feature engineering.



### Adaptive Appearance Rendering
- **Arxiv ID**: http://arxiv.org/abs/2104.11931v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11931v1)
- **Published**: 2021-04-24 11:53:09+00:00
- **Updated**: 2021-04-24 11:53:09+00:00
- **Authors**: Mengyao Zhai, Ruizhi Deng, Jiacheng Chen, Lei Chen, Zhiwei Deng, Greg Mori
- **Comment**: Accepted to BMVC 2018. arXiv admin note: substantial text overlap
  with arXiv:1712.01955
- **Journal**: None
- **Summary**: We propose an approach to generate images of people given a desired appearance and pose. Disentangled representations of pose and appearance are necessary to handle the compound variability in the resulting generated images. Hence, we develop an approach based on intermediate representations of poses and appearance: our pose-guided appearance rendering network firstly encodes the targets' poses using an encoder-decoder neural network. Then the targets' appearances are encoded by learning adaptive appearance filters using a fully convolutional network. Finally, these filters are placed in the encoder-decoder neural networks to complete the rendering. We demonstrate that our model can generate images and videos that are superior to state-of-the-art methods, and can handle pose guided appearance rendering in both image and video generation.



### RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition
- **Arxiv ID**: http://arxiv.org/abs/2104.11934v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2104.11934v2)
- **Published**: 2021-04-24 12:04:04+00:00
- **Updated**: 2022-03-29 14:47:44+00:00
- **Authors**: Jun Chen, Aniket Agarwal, Sherif Abdelkarim, Deyao Zhu, Mohamed Elhoseiny
- **Comment**: None
- **Journal**: None
- **Summary**: The visual relationship recognition (VRR) task aims at understanding the pairwise visual relationships between interacting objects in an image. These relationships typically have a long-tail distribution due to their compositional nature. This problem gets more severe when the vocabulary becomes large, rendering this task very challenging. This paper shows that modeling an effective message-passing flow through an attention mechanism can be critical to tackling the compositionality and long-tail challenges in VRR. The method, called RelTransformer, represents each image as a fully-connected scene graph and restructures the whole scene into the relation-triplet and global-scene contexts. It directly passes the message from each element in the relation-triplet and global-scene contexts to the target relation via self-attention. We also design a learnable memory to augment the long-tail relation representation learning. Through extensive experiments, we find that our model generalizes well on many VRR benchmarks. Our model outperforms the best-performing models on two large-scale long-tail VRR benchmarks, VG8K-LT (+2.0% overall acc) and GQA-LT (+26.0% overall acc), both having a highly skewed distribution towards the tail. It also achieves strong results on the VG200 relation detection task. Our code is available at https://github.com/Vision-CAIR/RelTransformer.



### Piggyback GAN: Efficient Lifelong Learning for Image Conditioned Generation
- **Arxiv ID**: http://arxiv.org/abs/2104.11939v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.11939v1)
- **Published**: 2021-04-24 12:09:52+00:00
- **Updated**: 2021-04-24 12:09:52+00:00
- **Authors**: Mengyao Zhai, Lei Chen, Jiawei He, Megha Nawhal, Frederick Tung, Greg Mori
- **Comment**: Accepted to ECCV 2020
- **Journal**: None
- **Summary**: Humans accumulate knowledge in a lifelong fashion. Modern deep neural networks, on the other hand, are susceptible to catastrophic forgetting: when adapted to perform new tasks, they often fail to preserve their performance on previously learned tasks. Given a sequence of tasks, a naive approach addressing catastrophic forgetting is to train a separate standalone model for each task, which scales the total number of parameters drastically without efficiently utilizing previous models. In contrast, we propose a parameter efficient framework, Piggyback GAN, which learns the current task by building a set of convolutional and deconvolutional filters that are factorized into filters of the models trained on previous tasks. For the current task, our model achieves high generation quality on par with a standalone model at a lower number of parameters. For previous tasks, our model can also preserve generation quality since the filters for previous tasks are not altered. We validate Piggyback GAN on various image-conditioned generation tasks across different domains, and provide qualitative and quantitative results to show that the proposed approach can address catastrophic forgetting effectively and efficiently.



### Automatic Diagnosis of COVID-19 from CT Images using CycleGAN and Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2104.11949v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2104.11949v1)
- **Published**: 2021-04-24 13:12:20+00:00
- **Updated**: 2021-04-24 13:12:20+00:00
- **Authors**: Navid Ghassemi, Afshin Shoeibi, Marjane Khodatars, Jonathan Heras, Alireza Rahimi, Assef Zare, Ram Bilas Pachori, J. Manuel Gorriz
- **Comment**: None
- **Journal**: None
- **Summary**: The outbreak of the corona virus disease (COVID-19) has changed the lives of most people on Earth. Given the high prevalence of this disease, its correct diagnosis in order to quarantine patients is of the utmost importance in steps of fighting this pandemic. Among the various modalities used for diagnosis, medical imaging, especially computed tomography (CT) imaging, has been the focus of many previous studies due to its accuracy and availability. In addition, automation of diagnostic methods can be of great help to physicians. In this paper, a method based on pre-trained deep neural networks is presented, which, by taking advantage of a cyclic generative adversarial net (CycleGAN) model for data augmentation, has reached state-of-the-art performance for the task at hand, i.e., 99.60% accuracy. Also, in order to evaluate the method, a dataset containing 3163 images from 189 patients has been collected and labeled by physicians. Unlike prior datasets, normal data have been collected from people suspected of having COVID-19 disease and not from data from other diseases, and this database is made available publicly.



### On the stability of deep convolutional neural networks under irregular or random deformations
- **Arxiv ID**: http://arxiv.org/abs/2104.11977v1
- **DOI**: None
- **Categories**: **math.FA**, cs.CV, cs.LG, 68T07, 68T05, 94A12, 42B35, 42C15
- **Links**: [PDF](http://arxiv.org/pdf/2104.11977v1)
- **Published**: 2021-04-24 16:16:30+00:00
- **Updated**: 2021-04-24 16:16:30+00:00
- **Authors**: Fabio Nicola, S. Ivan Trapasso
- **Comment**: 36 pages, 6 figures, 2 tables
- **Journal**: None
- **Summary**: The problem of robustness under location deformations for deep convolutional neural networks (DCNNs) is of great theoretical and practical interest. This issue has been studied in pioneering works, especially for scattering-type architectures, for deformation vector fields $\tau(x)$ with some regularity - at least $C^1$. Here we address this issue for any field $\tau\in L^\infty(\mathbb{R}^d;\mathbb{R}^d)$, without any additional regularity assumption, hence including the case of wild irregular deformations such as a noise on the pixel location of an image. We prove that for signals in multiresolution approximation spaces $U_s$ at scale $s$, whenever the network is Lipschitz continuous (regardless of its architecture), stability in $L^2$ holds in the regime $\|\tau\|_{L^\infty}/s\ll 1$, essentially as a consequence of the uncertainty principle. When $\|\tau\|_{L^\infty}/s\gg 1$ instability can occur even for well-structured DCNNs such as the wavelet scattering networks, and we provide a sharp upper bound for the asymptotic growth rate. The stability results are then extended to signals in the Besov space $B^{d/2}_{2,1}$ tailored to the given multiresolution approximation. We also consider the case of more general time-frequency deformations. Finally, we provide stochastic versions of the aforementioned results, namely we study the issue of stability in mean when $\tau(x)$ is modeled as a random field (not bounded, in general) with with identically distributed variables $|\tau(x)|$, $x\in\mathbb{R}^d$.



### Width Transfer: On the (In)variance of Width Optimization
- **Arxiv ID**: http://arxiv.org/abs/2104.13255v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2104.13255v1)
- **Published**: 2021-04-24 19:51:53+00:00
- **Updated**: 2021-04-24 19:51:53+00:00
- **Authors**: Ting-Wu Chin, Diana Marculescu, Ari S. Morcos
- **Comment**: Full paper accepted at CVPR Workshops 2021; a 4-page abridged version
  is accepted at ICLR 2021 NAS Workshop
- **Journal**: None
- **Summary**: Optimizing the channel counts for different layers of a CNN has shown great promise in improving the efficiency of CNNs at test-time. However, these methods often introduce large computational overhead (e.g., an additional 2x FLOPs of standard training). Minimizing this overhead could therefore significantly speed up training. In this work, we propose width transfer, a technique that harnesses the assumptions that the optimized widths (or channel counts) are regular across sizes and depths. We show that width transfer works well across various width optimization algorithms and networks. Specifically, we can achieve up to 320x reduction in width optimization overhead without compromising the top-1 accuracy on ImageNet, making the additional cost of width optimization negligible relative to initial training. Our findings not only suggest an efficient way to conduct width optimization but also highlight that the widths that lead to better accuracy are invariant to various aspects of network architectures and training data.



### Calibrating LiDAR and Camera using Semantic Mutual information
- **Arxiv ID**: http://arxiv.org/abs/2104.12023v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2104.12023v1)
- **Published**: 2021-04-24 21:04:33+00:00
- **Updated**: 2021-04-24 21:04:33+00:00
- **Authors**: Peng Jiang, Philip Osteen, Srikanth Saripalli
- **Comment**: 5 pages, 6 figures, submitted to ICRA 2021 workshop
- **Journal**: None
- **Summary**: We propose an algorithm for automatic, targetless, extrinsic calibration of a LiDAR and camera system using semantic information. We achieve this goal by maximizing mutual information (MI) of semantic information between sensors, leveraging a neural network to estimate semantic mutual information, and matrix exponential for calibration computation. Using kernel-based sampling to sample data from camera measurement based on LiDAR projected points, we formulate the problem as a novel differentiable objective function which supports the use of gradient-based optimization methods. We also introduce an initial calibration method using 2D MI-based image registration. Finally, we demonstrate the robustness of our method and quantitatively analyze the accuracy on a synthetic dataset and also evaluate our algorithm qualitatively on KITTI360 and RELLIS-3D benchmark datasets, showing improvement over recent comparable approaches.



### Deep Convolutional Neural Network for Non-rigid Image Registration
- **Arxiv ID**: http://arxiv.org/abs/2104.12034v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2104.12034v1)
- **Published**: 2021-04-24 23:24:29+00:00
- **Updated**: 2021-04-24 23:24:29+00:00
- **Authors**: Eduard F. Durech
- **Comment**: 10 pages, 11 figures
- **Journal**: None
- **Summary**: Images taken at different times or positions undergo transformations such as rotation, scaling, skewing, and more. The process of aligning different images which have undergone transformations can be done via registration. Registration is desirable when analyzing time-series data for tracking, averaging, or differential diagnoses of diseases. Efficient registration methods exist for rigid (including linear or affine) transformations; however, for non-rigid (also known as non-affine) transformations, current methods are computationally expensive and time-consuming. In this report, I will explore the ability of a deep neural network (DNN) and, more specifically, a deep convolutional neural network (CNN) to efficiently perform non-rigid image registration. The experimental results show that a CNN can be used for efficient non-rigid image registration and in significantly less computational time than a conventional Diffeomorphic Demons or Pyramiding approach.



