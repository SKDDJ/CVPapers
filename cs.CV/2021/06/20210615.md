# Arxiv Papers in cs.CV on 2021-06-15
### Efficient Facial Expression Analysis For Dimensional Affect Recognition Using Geometric Features
- **Arxiv ID**: http://arxiv.org/abs/2106.07817v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2106.07817v1)
- **Published**: 2021-06-15 00:28:16+00:00
- **Updated**: 2021-06-15 00:28:16+00:00
- **Authors**: Vassilios Vonikakis, Stefan Winkler
- **Comment**: None
- **Journal**: None
- **Summary**: Despite their continued popularity, categorical approaches to affect recognition have limitations, especially in real-life situations. Dimensional models of affect offer important advantages for the recognition of subtle expressions and more fine-grained analysis. We introduce a simple but effective facial expression analysis (FEA) system for dimensional affect, solely based on geometric features and Partial Least Squares (PLS) regression. The system jointly learns to estimate Arousal and Valence ratings from a set of facial images. The proposed approach is robust, efficient, and exhibits comparable performance to contemporary deep learning models, while requiring a fraction of the computational resources.



### Canonical Face Embeddings
- **Arxiv ID**: http://arxiv.org/abs/2106.07822v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2106.07822v3)
- **Published**: 2021-06-15 00:52:05+00:00
- **Updated**: 2021-10-27 22:46:14+00:00
- **Authors**: David McNeely-White, Ben Sattelberg, Nathaniel Blanchard, Ross Beveridge
- **Comment**: 13 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: We present evidence that many common convolutional neural networks (CNNs) trained for face verification learn functions that are nearly equivalent under rotation. More specifically, we demonstrate that one face verification model's embeddings (i.e. last-layer activations) can be compared directly to another model's embeddings after only a rotation or linear transformation, with little performance penalty. This finding is demonstrated using IJB-C 1:1 verification across the combinations of ten modern off-the-shelf CNN-based face verification models which vary in training dataset, CNN architecture, method of angular loss calculation, or some combination of the 3. These networks achieve a mean true accept rate of 0.96 at a false accept rate of 0.01. When instead evaluating embeddings generated from two CNNs, where one CNN's embeddings are mapped with a linear transformation, the mean true accept rate drops to 0.95 using the same verification paradigm. Restricting these linear maps to only perform rotation produces a mean true accept rate of 0.91. These mappings' existence suggests that a common representation is learned by models despite variation in training or structure. We discuss the broad implications a result like this has, including an example regarding face template security.



### Temporal Consistency Checks to Detect LiDAR Spoofing Attacks on Autonomous Vehicle Perception
- **Arxiv ID**: http://arxiv.org/abs/2106.07833v1
- **DOI**: 10.1145/3469261.3469406
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07833v1)
- **Published**: 2021-06-15 01:36:40+00:00
- **Updated**: 2021-06-15 01:36:40+00:00
- **Authors**: Chengzeng You, Zhongyuan Hau, Soteris Demetriou
- **Comment**: Accepted in 1st Workshop on Security and Privacy for Mobile AI (MAISP
  2021)
- **Journal**: None
- **Summary**: LiDAR sensors are used widely in Autonomous Vehicles for better perceiving the environment which enables safer driving decisions. Recent work has demonstrated serious LiDAR spoofing attacks with alarming consequences. In particular, model-level LiDAR spoofing attacks aim to inject fake depth measurements to elicit ghost objects that are erroneously detected by 3D Object Detectors, resulting in hazardous driving decisions. In this work, we explore the use of motion as a physical invariant of genuine objects for detecting such attacks. Based on this, we propose a general methodology, 3D Temporal Consistency Check (3D-TC2), which leverages spatio-temporal information from motion prediction to verify objects detected by 3D Object Detectors. Our preliminary design and implementation of a 3D-TC2 prototype demonstrates very promising performance, providing more than 98% attack detection rate with a recall of 91% for detecting spoofed Vehicle (Car) objects, and is able to achieve real-time detection at 41Hz



### Cluster-guided Asymmetric Contrastive Learning for Unsupervised Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2106.07846v2
- **DOI**: 10.1109/TIP.2022.3173163
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07846v2)
- **Published**: 2021-06-15 02:40:22+00:00
- **Updated**: 2022-05-09 11:43:43+00:00
- **Authors**: Mingkun Li, Chun-Guang Li, Jun Guo
- **Comment**: None
- **Journal**: None
- **Summary**: Unsupervised person re-identification (Re-ID) aims to match pedestrian images from different camera views in unsupervised setting. Existing methods for unsupervised person Re-ID are usually built upon the pseudo labels from clustering. However, the quality of clustering depends heavily on the quality of the learned features, which are overwhelmingly dominated by the colors in images especially in the unsupervised setting. In this paper, we propose a Cluster-guided Asymmetric Contrastive Learning (CACL) approach for unsupervised person Re-ID, in which cluster structure is leveraged to guide the feature learning in a properly designed asymmetric contrastive learning framework. To be specific, we propose a novel cluster-level contrastive loss to help the siamese network effectively mine the invariance in feature learning with respect to the cluster structure within and between different data augmentation views, respectively. Extensive experiments conducted on three benchmark datasets demonstrate superior performance of our proposal.



### Learning Stable Classifiers by Transferring Unstable Features
- **Arxiv ID**: http://arxiv.org/abs/2106.07847v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CL, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2106.07847v4)
- **Published**: 2021-06-15 02:41:12+00:00
- **Updated**: 2022-06-27 02:34:56+00:00
- **Authors**: Yujia Bao, Shiyu Chang, Regina Barzilay
- **Comment**: ICML 2022
- **Journal**: None
- **Summary**: While unbiased machine learning models are essential for many applications, bias is a human-defined concept that can vary across tasks. Given only input-label pairs, algorithms may lack sufficient information to distinguish stable (causal) features from unstable (spurious) features. However, related tasks often share similar biases -- an observation we may leverage to develop stable classifiers in the transfer setting. In this work, we explicitly inform the target classifier about unstable features in the source tasks. Specifically, we derive a representation that encodes the unstable features by contrasting different data environments in the source task. We achieve robustness by clustering data of the target task according to this representation and minimizing the worst-case risk across these clusters. We evaluate our method on both text and image classifications. Empirical results demonstrate that our algorithm is able to maintain robustness on the target task for both synthetically generated environments and real-world environments. Our code is available at https://github.com/YujiaBao/Tofu.



### Simon Says: Evaluating and Mitigating Bias in Pruned Neural Networks with Knowledge Distillation
- **Arxiv ID**: http://arxiv.org/abs/2106.07849v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07849v1)
- **Published**: 2021-06-15 02:59:32+00:00
- **Updated**: 2021-06-15 02:59:32+00:00
- **Authors**: Cody Blakeney, Nathaniel Huish, Yan Yan, Ziliang Zong
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years the ubiquitous deployment of AI has posed great concerns in regards to algorithmic bias, discrimination, and fairness. Compared to traditional forms of bias or discrimination caused by humans, algorithmic bias generated by AI is more abstract and unintuitive therefore more difficult to explain and mitigate. A clear gap exists in the current literature on evaluating and mitigating bias in pruned neural networks. In this work, we strive to tackle the challenging issues of evaluating, mitigating, and explaining induced bias in pruned neural networks. Our paper makes three contributions. First, we propose two simple yet effective metrics, Combined Error Variance (CEV) and Symmetric Distance Error (SDE), to quantitatively evaluate the induced bias prevention quality of pruned models. Second, we demonstrate that knowledge distillation can mitigate induced bias in pruned neural networks, even with unbalanced datasets. Third, we reveal that model similarity has strong correlations with pruning induced bias, which provides a powerful method to explain why bias occurs in pruned neural networks. Our code is available at https://github.com/codestar12/pruning-distilation-bias



### Learning to Aggregate and Personalize 3D Face from In-the-Wild Photo Collection
- **Arxiv ID**: http://arxiv.org/abs/2106.07852v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2106.07852v1)
- **Published**: 2021-06-15 03:10:17+00:00
- **Updated**: 2021-06-15 03:10:17+00:00
- **Authors**: Zhenyu Zhang, Yanhao Ge, Renwang Chen, Ying Tai, Yan Yan, Jian Yang, Chengjie Wang, Jilin Li, Feiyue Huang
- **Comment**: CVPR 2021 Oral, 11 pages, 9 figures
- **Journal**: None
- **Summary**: Non-parametric face modeling aims to reconstruct 3D face only from images without shape assumptions. While plausible facial details are predicted, the models tend to over-depend on local color appearance and suffer from ambiguous noise. To address such problem, this paper presents a novel Learning to Aggregate and Personalize (LAP) framework for unsupervised robust 3D face modeling. Instead of using controlled environment, the proposed method implicitly disentangles ID-consistent and scene-specific face from unconstrained photo set. Specifically, to learn ID-consistent face, LAP adaptively aggregates intrinsic face factors of an identity based on a novel curriculum learning approach with relaxed consistency loss. To adapt the face for a personalized scene, we propose a novel attribute-refining network to modify ID-consistent face with target attribute and details. Based on the proposed method, we make unsupervised 3D face modeling benefit from meaningful image facial structure and possibly higher resolutions. Extensive experiments on benchmarks show LAP recovers superior or competitive face shape and texture, compared with state-of-the-art (SOTA) methods with or without prior and supervision.



### G2DA: Geometry-Guided Dual-Alignment Learning for RGB-Infrared Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2106.07853v2
- **DOI**: None
- **Categories**: **cs.CV**, 68T07 (Primary), I.4.9
- **Links**: [PDF](http://arxiv.org/pdf/2106.07853v2)
- **Published**: 2021-06-15 03:14:31+00:00
- **Updated**: 2021-07-25 02:19:17+00:00
- **Authors**: Lin Wan, Zongyuan Sun, Qianyan Jing, Yehansen Chen, Lijing Lu, Zhihang Li
- **Comment**: 14 pages, 7 figures
- **Journal**: None
- **Summary**: RGB-Infrared (IR) person re-identification aims to retrieve person-of-interest from heterogeneous cameras, easily suffering from large image modality discrepancy caused by different sensing wavelength ranges. Existing work usually minimizes such discrepancy by aligning domain distribution of global features, while neglecting the intra-modality structural relations between semantic parts. This could result in the network overly focusing on local cues, without considering long-range body part dependencies, leading to meaningless region representations. In this paper, we propose a graph-enabled distribution matching solution, dubbed Geometry-Guided Dual-Alignment (G2DA) learning, for RGB-IR ReID. It can jointly encourage the cross-modal consistency between part semantics and structural relations for fine-grained modality alignment by solving a graph matching task within a multi-scale skeleton graph that embeds human topology information. Specifically, we propose to build a semantic-aligned complete graph into which all cross-modality images can be mapped via a pose-adaptive graph construction mechanism. This graph represents extracted whole-part features by nodes and expresses the node-wise similarities with associated edges. To achieve the graph-based dual-alignment learning, an Optimal Transport (OT) based structured metric is further introduced to simultaneously measure point-wise relations and group-wise structural similarities across modalities. By minimizing the cost of an inter-modality transport plan, G2DA can learn a consistent and discriminative feature subspace for cross-modality image retrieval. Furthermore, we advance a Message Fusion Attention (MFA) mechanism to adaptively reweight the information flow of semantic propagation, effectively strengthening the discriminability of extracted semantic features.



### A Hybrid mmWave and Camera System for Long-Range Depth Imaging
- **Arxiv ID**: http://arxiv.org/abs/2106.07856v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.NI, cs.RO, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2106.07856v3)
- **Published**: 2021-06-15 03:19:35+00:00
- **Updated**: 2022-02-24 16:08:52+00:00
- **Authors**: Akarsh Prabhakara, Diana Zhang, Chao Li, Sirajum Munir, Aswin Sankanaryanan, Anthony Rowe, Swarun Kumar
- **Comment**: None
- **Journal**: None
- **Summary**: mmWave radars offer excellent depth resolution even at very long ranges owing to their high bandwidth. But their angular resolution is at least an order-of-magnitude worse than camera and lidar systems. Hence, mmWave radar is not a capable 3-D imaging solution in isolation. We propose Metamoran, a system that combines the complimentary strengths of radar and camera to obtain accurate, high resolution depth images over long ranges even in high clutter environments, all from a single fixed vantage point. Metamoran enables rich long-range depth imaging with applications in security and surveillance, roadside safety infrastructure and wide-area mapping. Our approach leverages the high angular resolution from cameras using computer vision techniques, including image segmentation and monocular depth estimation, to obtain object shape. Our core contribution is a method to convert this object shape into an RF I/Q equivalent, which we use in a novel radar processing pipeline to help declutter the scene and capture extremely weak reflections from objects at long distances. We perform a detailed evaluation of Metamoran's depth imaging capabilities in 400 diverse scenes. Our evaluation shows that Metamoran estimates the depth of static objects up to 90 m and moving objects up to 305 m and with a median error of 28 cm, an improvement of 13$\times$ compared to a naive radar+camera baseline and 23$\times$ compared to monocular depth estimation.



### Keep CALM and Improve Visual Feature Attribution
- **Arxiv ID**: http://arxiv.org/abs/2106.07861v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07861v3)
- **Published**: 2021-06-15 03:33:25+00:00
- **Updated**: 2021-08-12 11:46:37+00:00
- **Authors**: Jae Myung Kim, Junsuk Choe, Zeynep Akata, Seong Joon Oh
- **Comment**: ICCV 2021 camera-ready. First two authors contributed equally
- **Journal**: None
- **Summary**: The class activation mapping, or CAM, has been the cornerstone of feature attribution methods for multiple vision tasks. Its simplicity and effectiveness have led to wide applications in the explanation of visual predictions and weakly-supervised localization tasks. However, CAM has its own shortcomings. The computation of attribution maps relies on ad-hoc calibration steps that are not part of the training computational graph, making it difficult for us to understand the real meaning of the attribution values. In this paper, we improve CAM by explicitly incorporating a latent variable encoding the location of the cue for recognition in the formulation, thereby subsuming the attribution map into the training computational graph. The resulting model, class activation latent mapping, or CALM, is trained with the expectation-maximization algorithm. Our experiments show that CALM identifies discriminative attributes for image classifiers more accurately than CAM and other visual attribution baselines. CALM also shows performance improvements over prior arts on the weakly-supervised object localization benchmarks. Our code is available at https://github.com/naver-ai/calm.



### Domain Adaptive SiamRPN++ for Object Tracking in the Wild
- **Arxiv ID**: http://arxiv.org/abs/2106.07862v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07862v1)
- **Published**: 2021-06-15 03:40:53+00:00
- **Updated**: 2021-06-15 03:40:53+00:00
- **Authors**: Zhongzhou Zhang, Lei Zhang
- **Comment**: 10 pages,7 figures
- **Journal**: None
- **Summary**: Benefit from large-scale training data, recent advances in Siamese-based object tracking have achieved compelling results on the normal sequences. Whilst Siamese-based trackers assume training and test data follow an identical distribution. Suppose there is a set of foggy or rainy test sequences, it cannot be guaranteed that the trackers trained on the normal images perform well on the data belonging to other domains. The problem of domain shift among training and test data has already been discussed in object detection and semantic segmentation areas, which, however, has not been investigated for visual tracking. To this end, based on SiamRPN++, we introduce a Domain Adaptive SiamRPN++, namely DASiamRPN++, to improve the cross-domain transferability and robustness of a tracker. Inspired by A-distance theory, we present two domain adaptive modules, Pixel Domain Adaptation (PDA) and Semantic Domain Adaptation (SDA). The PDA module aligns the feature maps of template and search region images to eliminate the pixel-level domain shift caused by weather, illumination, etc. The SDA module aligns the feature representations of the tracking target's appearance to eliminate the semantic-level domain shift. PDA and SDA modules reduce the domain disparity by learning domain classifiers in an adversarial training manner. The domain classifiers enforce the network to learn domain-invariant feature representations. Extensive experiments are performed on the standard datasets of two different domains, including synthetic foggy and TIR sequences, which demonstrate the transferability and domain adaptability of the proposed tracker.



### Defending Touch-based Continuous Authentication Systems from Active Adversaries Using Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2106.07867v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.HC, K.6.5
- **Links**: [PDF](http://arxiv.org/pdf/2106.07867v1)
- **Published**: 2021-06-15 04:04:58+00:00
- **Updated**: 2021-06-15 04:04:58+00:00
- **Authors**: Mohit Agrawal, Pragyan Mehrotra, Rajesh Kumar, Rajiv Ratn Shah
- **Comment**: 2021 IEEE International Joint Conference on Biometrics (IJCB), 8
  pages
- **Journal**: None
- **Summary**: Previous studies have demonstrated that commonly studied (vanilla) touch-based continuous authentication systems (V-TCAS) are susceptible to population attack. This paper proposes a novel Generative Adversarial Network assisted TCAS (G-TCAS) framework, which showed more resilience to the population attack. G-TCAS framework was tested on a dataset of 117 users who interacted with a smartphone and tablet pair. On average, the increase in the false accept rates (FARs) for V-TCAS was much higher (22%) than G-TCAS (13%) for the smartphone. Likewise, the increase in the FARs for V-TCAS was 25% compared to G-TCAS (6%) for the tablet.



### Reverse Engineering of Generative Models: Inferring Model Hyperparameters from Generated Images
- **Arxiv ID**: http://arxiv.org/abs/2106.07873v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.07873v3)
- **Published**: 2021-06-15 04:19:26+00:00
- **Updated**: 2023-07-30 00:48:21+00:00
- **Authors**: Vishal Asnani, Xi Yin, Tal Hassner, Xiaoming Liu
- **Comment**: Accepted at Transactions on Pattern Analysis and Machine Intelligence
- **Journal**: None
- **Summary**: State-of-the-art (SOTA) Generative Models (GMs) can synthesize photo-realistic images that are hard for humans to distinguish from genuine photos. Identifying and understanding manipulated media are crucial to mitigate the social concerns on the potential misuse of GMs. We propose to perform reverse engineering of GMs to infer model hyperparameters from the images generated by these models. We define a novel problem, ``model parsing", as estimating GM network architectures and training loss functions by examining their generated images -- a task seemingly impossible for human beings. To tackle this problem, we propose a framework with two components: a Fingerprint Estimation Network (FEN), which estimates a GM fingerprint from a generated image by training with four constraints to encourage the fingerprint to have desired properties, and a Parsing Network (PN), which predicts network architecture and loss functions from the estimated fingerprints. To evaluate our approach, we collect a fake image dataset with $100$K images generated by $116$ different GMs. Extensive experiments show encouraging results in parsing the hyperparameters of the unseen models. Finally, our fingerprint estimation can be leveraged for deepfake detection and image attribution, as we show by reporting SOTA results on both the deepfake detection (Celeb-DF) and image attribution benchmarks.



### Vision-Language Navigation with Random Environmental Mixup
- **Arxiv ID**: http://arxiv.org/abs/2106.07876v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07876v3)
- **Published**: 2021-06-15 04:34:26+00:00
- **Updated**: 2021-11-01 16:39:17+00:00
- **Authors**: Chong Liu, Fengda Zhu, Xiaojun Chang, Xiaodan Liang, Zongyuan Ge, Yi-Dong Shen
- **Comment**: ICCV 2021
- **Journal**: None
- **Summary**: Vision-language Navigation (VLN) tasks require an agent to navigate step-by-step while perceiving the visual observations and comprehending a natural language instruction. Large data bias, which is caused by the disparity ratio between the small data scale and large navigation space, makes the VLN task challenging. Previous works have proposed various data augmentation methods to reduce data bias. However, these works do not explicitly reduce the data bias across different house scenes. Therefore, the agent would overfit to the seen scenes and achieve poor navigation performance in the unseen scenes. To tackle this problem, we propose the Random Environmental Mixup (REM) method, which generates cross-connected house scenes as augmented data via mixuping environment. Specifically, we first select key viewpoints according to the room connection graph for each scene. Then, we cross-connect the key views of different scenes to construct augmented scenes. Finally, we generate augmented instruction-path pairs in the cross-connected scenes. The experimental results on benchmark datasets demonstrate that our augmentation data via REM help the agent reduce its performance gap between the seen and unseen environment and improve the overall performance, making our model the best existing approach on the standard VLN benchmark. The code have released: https://github.com/LCFractal/VLNREM.



### A Lightweight ReLU-Based Feature Fusion for Aerial Scene Classification
- **Arxiv ID**: http://arxiv.org/abs/2106.07879v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07879v1)
- **Published**: 2021-06-15 04:43:41+00:00
- **Updated**: 2021-06-15 04:43:41+00:00
- **Authors**: Md Adnan Arefeen, Sumaiya Tabassum Nimi, Md Yusuf Sarwar Uddin, Zhu Li
- **Comment**: To be presented in IEEE ICIP'21
- **Journal**: None
- **Summary**: In this paper, we propose a transfer-learning based model construction technique for the aerial scene classification problem. The core of our technique is a layer selection strategy, named ReLU-Based Feature Fusion (RBFF), that extracts feature maps from a pretrained CNN-based single-object image classification model, namely MobileNetV2, and constructs a model for the aerial scene classification task. RBFF stacks features extracted from the batch normalization layer of a few selected blocks of MobileNetV2, where the candidate blocks are selected based on the characteristics of the ReLU activation layers present in those blocks. The feature vector is then compressed into a low-dimensional feature space using dimension reduction algorithms on which we train a low-cost SVM classifier for the classification of the aerial images. We validate our choice of selected features based on the significance of the extracted features with respect to our classification pipeline. RBFF remarkably does not involve any training of the base CNN model except for a few parameters for the classifier, which makes the technique very cost-effective for practical deployments. The constructed model despite being lightweight outperforms several recently proposed models in terms of accuracy for a number of aerial scene datasets.



### Scaling Neural Tangent Kernels via Sketching and Random Features
- **Arxiv ID**: http://arxiv.org/abs/2106.07880v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.DS
- **Links**: [PDF](http://arxiv.org/pdf/2106.07880v2)
- **Published**: 2021-06-15 04:44:52+00:00
- **Updated**: 2021-12-08 13:00:58+00:00
- **Authors**: Amir Zandieh, Insu Han, Haim Avron, Neta Shoham, Chaewon Kim, Jinwoo Shin
- **Comment**: This is a merger of arXiv:2104.01351, arXiv:2104.00415
- **Journal**: None
- **Summary**: The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely-wide neural networks trained under least squares loss by gradient descent. Recent works also report that NTK regression can outperform finitely-wide neural networks trained on small-scale datasets. However, the computational complexity of kernel methods has limited its use in large-scale learning tasks. To accelerate learning with NTK, we design a near input-sparsity time approximation algorithm for NTK, by sketching the polynomial expansions of arc-cosine kernels: our sketch for the convolutional counterpart of NTK (CNTK) can transform any image using a linear runtime in the number of pixels. Furthermore, we prove a spectral approximation guarantee for the NTK matrix, by combining random features (based on leverage score sampling) of the arc-cosine kernels with a sketching algorithm. We benchmark our methods on various large-scale regression and classification tasks and show that a linear regressor trained on our CNTK features matches the accuracy of exact CNTK on CIFAR-10 dataset while achieving 150x speedup.



### Mixed Model OCR Training on Historical Latin Script for Out-of-the-Box Recognition and Finetuning
- **Arxiv ID**: http://arxiv.org/abs/2106.07881v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07881v1)
- **Published**: 2021-06-15 04:51:54+00:00
- **Updated**: 2021-06-15 04:51:54+00:00
- **Authors**: Christian Reul, Christoph Wick, Maximilian Nöth, Andreas Büttner, Maximilian Wehner, Uwe Springmann
- **Comment**: submitted to HIP'21
- **Journal**: None
- **Summary**: In order to apply Optical Character Recognition (OCR) to historical printings of Latin script fully automatically, we report on our efforts to construct a widely-applicable polyfont recognition model yielding text with a Character Error Rate (CER) around 2% when applied out-of-the-box. Moreover, we show how this model can be further finetuned to specific classes of printings with little manual and computational effort. The mixed or polyfont model is trained on a wide variety of materials, in terms of age (from the 15th to the 19th century), typography (various types of Fraktur and Antiqua), and languages (among others, German, Latin, and French). To optimize the results we combined established techniques of OCR training like pretraining, data augmentation, and voting. In addition, we used various preprocessing methods to enrich the training data and obtain more robust models. We also implemented a two-stage approach which first trains on all available, considerably unbalanced data and then refines the output by training on a selected more balanced subset. Evaluations on 29 previously unseen books resulted in a CER of 1.73%, outperforming a widely used standard model with a CER of 2.84% by almost 40%. Training a more specialized model for some unseen Early Modern Latin books starting from our mixed model led to a CER of 1.47%, an improvement of up to 50% compared to training from scratch and up to 30% compared to training from the aforementioned standard model. Our new mixed model is made openly available to the community.



### Robust Out-of-Distribution Detection on Deep Probabilistic Generative Models
- **Arxiv ID**: http://arxiv.org/abs/2106.07903v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07903v1)
- **Published**: 2021-06-15 06:36:10+00:00
- **Updated**: 2021-06-15 06:36:10+00:00
- **Authors**: Jaemoo Choi, Changyeon Yoon, Jeongwoo Bae, Myungjoo Kang
- **Comment**: 23 pages, 11 figures
- **Journal**: None
- **Summary**: Out-of-distribution (OOD) detection is an important task in machine learning systems for ensuring their reliability and safety. Deep probabilistic generative models facilitate OOD detection by estimating the likelihood of a data sample. However, such models frequently assign a suspiciously high likelihood to a specific outlier. Several recent works have addressed this issue by training a neural network with auxiliary outliers, which are generated by perturbing the input data. In this paper, we discover that these approaches fail for certain OOD datasets. Thus, we suggest a new detection metric that operates without outlier exposure. We observe that our metric is robust to diverse variations of an image compared to the previous outlier-exposing methods. Furthermore, our proposed score requires neither auxiliary models nor additional training. Instead, this paper utilizes the likelihood ratio statistic in a new perspective to extract genuine properties from the given single deep probabilistic generative model. We also apply a novel numerical approximation to enable fast implementation. Finally, we demonstrate comprehensive experiments on various probabilistic generative models and show that our method achieves state-of-the-art performance.



### Non-Gradient Manifold Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2106.07905v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07905v1)
- **Published**: 2021-06-15 06:39:13+00:00
- **Updated**: 2021-06-15 06:39:13+00:00
- **Authors**: Rui Zhang, Ziheng Jiao, Hongyuan Zhang, Xuelong Li
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural network (DNN) generally takes thousands of iterations to optimize via gradient descent and thus has a slow convergence. In addition, softmax, as a decision layer, may ignore the distribution information of the data during classification. Aiming to tackle the referred problems, we propose a novel manifold neural network based on non-gradient optimization, i.e., the closed-form solutions. Considering that the activation function is generally invertible, we reconstruct the network via forward ridge regression and low rank backward approximation, which achieve the rapid convergence. Moreover, by unifying the flexible Stiefel manifold and adaptive support vector machine, we devise the novel decision layer which efficiently fits the manifold structure of the data and label information. Consequently, a jointly non-gradient optimization method is designed to generate the network with closed-form results. Eventually, extensive experiments validate the superior performance of the model.



### Wavelength-based Attributed Deep Neural Network for Underwater Image Restoration
- **Arxiv ID**: http://arxiv.org/abs/2106.07910v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07910v3)
- **Published**: 2021-06-15 06:47:51+00:00
- **Updated**: 2022-01-19 10:44:37+00:00
- **Authors**: Prasen Kumar Sharma, Ira Bisht, Arijit Sur
- **Comment**: Accepted by ACM Transactions on Multimedia Computing, Communications,
  and Applications (ACM TOMM)
- **Journal**: None
- **Summary**: Background: Underwater images, in general, suffer from low contrast and high color distortions due to the non-uniform attenuation of the light as it propagates through the water. In addition, the degree of attenuation varies with the wavelength resulting in the asymmetric traversing of colors. Despite the prolific works for underwater image restoration (UIR) using deep learning, the above asymmetricity has not been addressed in the respective network engineering.   Contributions: As the first novelty, this paper shows that attributing the right receptive field size (context) based on the traversing range of the color channel may lead to a substantial performance gain for the task of UIR. Further, it is important to suppress the irrelevant multi-contextual features and increase the representational power of the model. Therefore, as a second novelty, we have incorporated an attentive skip mechanism to adaptively refine the learned multi-contextual features. The proposed framework, called Deep WaveNet, is optimized using the traditional pixel-wise and feature-based cost functions. An extensive set of experiments have been carried out to show the efficacy of the proposed scheme over existing best-published literature on benchmark datasets. More importantly, we have demonstrated a comprehensive validation of enhanced images across various high-level vision tasks, e.g., underwater image semantic segmentation, and diver's 2D pose estimation. A sample video to exhibit our real-world performance is available at \url{https://tinyurl.com/yzcrup9n}. Also, we have open-sourced our framework at \url{https://github.com/pksvision/Deep-WaveNet-UnderwaterImage-Restoration}.



### Encouraging Intra-Class Diversity Through a Reverse Contrastive Loss for Better Single-Source Domain Generalization
- **Arxiv ID**: http://arxiv.org/abs/2106.07916v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.07916v2)
- **Published**: 2021-06-15 07:04:39+00:00
- **Updated**: 2023-02-02 09:40:29+00:00
- **Authors**: Thomas Duboudin, Emmanuel Dellandréa, Corentin Abgrall, Gilles Hénaff, Liming Chen
- **Comment**: None
- **Journal**: ICCV - Workshop on Adversarial Robustness In the Real World, 2021,
  Virtual, France
- **Summary**: Traditional deep learning algorithms often fail to generalize when they are tested outside of the domain of the training data. The issue can be mitigated by using unlabeled data from the target domain at training time, but because data distributions can change dynamically in real-life applications once a learned model is deployed, it is critical to create networks robust to unknown and unforeseen domain shifts. In this paper we focus on one of the reasons behind the inability of neural networks to be so: deep networks focus only on the most obvious, potentially spurious, clues to make their predictions and are blind to useful but slightly less efficient or more complex patterns. This behaviour has been identified and several methods partially addressed the issue. To investigate their effectiveness and limits, we first design a publicly available MNIST-based benchmark to precisely measure the ability of an algorithm to find the ''hidden'' patterns. Then, we evaluate state-of-the-art algorithms through our benchmark and show that the issue is largely unsolved. Finally, we propose a partially reversed contrastive loss to encourage intra-class diversity and find less strongly correlated patterns, whose efficiency is demonstrated by our experiments.



### CT Image Synthesis Using Weakly Supervised Segmentation and Geometric Inter-Label Relations For COVID Image Analysis
- **Arxiv ID**: http://arxiv.org/abs/2106.10230v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.10230v1)
- **Published**: 2021-06-15 07:21:24+00:00
- **Updated**: 2021-06-15 07:21:24+00:00
- **Authors**: Dwarikanath Mahapatra, Ankur Singh
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2003.14119;
  text overlap with arXiv:1908.10555, arXiv:2004.14133 by other authors
- **Journal**: None
- **Summary**: While medical image segmentation is an important task for computer aided diagnosis, the high expertise requirement for pixelwise manual annotations makes it a challenging and time consuming task. Since conventional data augmentations do not fully represent the underlying distribution of the training set, the trained models have varying performance when tested on images captured from different sources. Most prior work on image synthesis for data augmentation ignore the interleaved geometric relationship between different anatomical labels. We propose improvements over previous GAN-based medical image synthesis methods by learning the relationship between different anatomical labels. We use a weakly supervised segmentation method to obtain pixel level semantic label map of images which is used learn the intrinsic relationship of geometry and shape across semantic labels. Latent space variable sampling results in diverse generated images from a base image and improves robustness. We use the synthetic images from our method to train networks for segmenting COVID-19 infected areas from lung CT images. The proposed method outperforms state-of-the-art segmentation methods on a public dataset. Ablation studies also demonstrate benefits of integrating geometry and diversity.



### ReS2tAC -- UAV-Borne Real-Time SGM Stereo Optimized for Embedded ARM and CUDA Devices
- **Arxiv ID**: http://arxiv.org/abs/2106.07927v1
- **DOI**: 10.3390/s21113938
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07927v1)
- **Published**: 2021-06-15 07:29:25+00:00
- **Updated**: 2021-06-15 07:29:25+00:00
- **Authors**: Boitumelo Ruf, Jonas Mohrs, Martin Weinmann, Stefan Hinz, Jürgen Beyerer
- **Comment**: None
- **Journal**: Sensors 2021, 21, 3938
- **Summary**: With the emergence of low-cost robotic systems, such as unmanned aerial vehicle, the importance of embedded high-performance image processing has increased. For a long time, FPGAs were the only processing hardware that were capable of high-performance computing, while at the same time preserving a low power consumption, essential for embedded systems. However, the recently increasing availability of embedded GPU-based systems, such as the NVIDIA Jetson series, comprised of an ARM CPU and a NVIDIA Tegra GPU, allows for massively parallel embedded computing on graphics hardware. With this in mind, we propose an approach for real-time embedded stereo processing on ARM and CUDA-enabled devices, which is based on the popular and widely used Semi-Global Matching algorithm. In this, we propose an optimization of the algorithm for embedded CUDA GPUs, by using massively parallel computing, as well as using the NEON intrinsics to optimize the algorithm for vectorized SIMD processing on embedded ARM CPUs. We have evaluated our approach with different configurations on two public stereo benchmark datasets to demonstrate that they can reach an error rate as low as 3.3%. Furthermore, our experiments show that the fastest configuration of our approach reaches up to 46 FPS on VGA image resolution. Finally, in a use-case specific qualitative evaluation, we have evaluated the power consumption of our approach and deployed it on the DJI Manifold 2-G attached to a DJI Matrix 210v2 RTK unmanned aerial vehicle (UAV), demonstrating its suitability for real-time stereo processing onboard a UAV.



### Image Feature Information Extraction for Interest Point Detection: A Review
- **Arxiv ID**: http://arxiv.org/abs/2106.07929v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07929v5)
- **Published**: 2021-06-15 07:31:31+00:00
- **Updated**: 2022-09-08 02:16:43+00:00
- **Authors**: Junfeng Jing, Tian Gao, Weichuan Zhang, Yongsheng Gao, Changming Sun
- **Comment**: None
- **Journal**: None
- **Summary**: Interest point detection is one of the most fundamental and critical problems in computer vision and image processing. In this paper, we carry out a comprehensive review on image feature information (IFI) extraction techniques for interest point detection. To systematically introduce how the existing interest point detection methods extract IFI from an input image, we propose a taxonomy of the IFI extraction techniques for interest point detection. According to this taxonomy, we discuss different types of IFI extraction techniques for interest point detection. Furthermore, we identify the main unresolved issues related to the existing IFI extraction techniques for interest point detection and any interest point detection methods that have not been discussed before. The existing popular datasets and evaluation standards are provided and the performances for eighteen state-of-the-art approaches are evaluated and discussed. Moreover, future research directions on IFI extraction techniques for interest point detection are elaborated.



### Direction-aware Feature-level Frequency Decomposition for Single Image Deraining
- **Arxiv ID**: http://arxiv.org/abs/2106.07941v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.07941v1)
- **Published**: 2021-06-15 07:51:19+00:00
- **Updated**: 2021-06-15 07:51:19+00:00
- **Authors**: Sen Deng, Yidan Feng, Mingqiang Wei, Haoran Xie, Yiping Chen, Jonathan Li, Xiao-Ping Zhang, Jing Qin
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel direction-aware feature-level frequency decomposition network for single image deraining. Compared with existing solutions, the proposed network has three compelling characteristics. First, unlike previous algorithms, we propose to perform frequency decomposition at feature-level instead of image-level, allowing both low-frequency maps containing structures and high-frequency maps containing details to be continuously refined during the training procedure. Second, we further establish communication channels between low-frequency maps and high-frequency maps to interactively capture structures from high-frequency maps and add them back to low-frequency maps and, simultaneously, extract details from low-frequency maps and send them back to high-frequency maps, thereby removing rain streaks while preserving more delicate features in the input image. Third, different from existing algorithms using convolutional filters consistent in all directions, we propose a direction-aware filter to capture the direction of rain streaks in order to more effectively and thoroughly purge the input images of rain streaks. We extensively evaluate the proposed approach in three representative datasets and experimental results corroborate our approach consistently outperforms state-of-the-art deraining algorithms.



### Cascading Convolutional Temporal Colour Constancy
- **Arxiv ID**: http://arxiv.org/abs/2106.07955v1
- **DOI**: 10.1117/1.JEI.32.1.013049
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.07955v1)
- **Published**: 2021-06-15 08:17:30+00:00
- **Updated**: 2021-06-15 08:17:30+00:00
- **Authors**: Matteo Rizzo, Cristina Conati, Daesik Jang, Hui Hu
- **Comment**: None
- **Journal**: None
- **Summary**: Computational Colour Constancy (CCC) consists of estimating the colour of one or more illuminants in a scene and using them to remove unwanted chromatic distortions. Much research has focused on illuminant estimation for CCC on single images, with few attempts of leveraging the temporal information intrinsic in sequences of correlated images (e.g., the frames in a video), a task known as Temporal Colour Constancy (TCC). The state-of-the-art for TCC is TCCNet, a deep-learning architecture that uses a ConvLSTM for aggregating the encodings produced by CNN submodules for each image in a sequence. We extend this architecture with different models obtained by (i) substituting the TCCNet submodules with C4, the state-of-the-art method for CCC targeting images; (ii) adding a cascading strategy to perform an iterative improvement of the estimate of the illuminant. We tested our models on the recently released TCC benchmark and achieved results that surpass the state-of-the-art. Analyzing the impact of the number of frames involved in illuminant estimation on performance, we show that it is possible to reduce inference time by training the models on few selected frames from the sequences while retaining comparable accuracy.



### Zero-sample surface defect detection and classification based on semantic feedback neural network
- **Arxiv ID**: http://arxiv.org/abs/2106.07959v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2106.07959v1)
- **Published**: 2021-06-15 08:26:36+00:00
- **Updated**: 2021-06-15 08:26:36+00:00
- **Authors**: Yibo Guo, Yiming Fan, Zhiyang Xiang, Haidi Wang, Wenhua Meng, Mingliang Xu
- **Comment**: 28 pages 10 figures
- **Journal**: None
- **Summary**: Defect detection and classification technology has changed from traditional artificial visual inspection to current intelligent automated inspection, but most of the current defect detection methods are training related detection models based on a data-driven approach, taking into account the difficulty of collecting some sample data in the industrial field. We apply zero-shot learning technology to the industrial field. Aiming at the problem of the existing "Latent Feature Guide Attribute Attention" (LFGAA) zero-shot image classification network, the output latent attributes and artificially defined attributes are different in the semantic space, which leads to the problem of model performance degradation, proposed an LGFAA network based on semantic feedback, and improved model performance by constructing semantic embedded modules and feedback mechanisms. At the same time, for the common domain shift problem in zero-shot learning, based on the idea of co-training algorithm using the difference information between different views of data to learn from each other, we propose an Ensemble Co-training algorithm, which adaptively reduces the prediction error in image tag embedding from multiple angles. Various experiments conducted on the zero-shot dataset and the cylinder liner dataset in the industrial field provide competitive results.



### A Value-Function-based Interior-point Method for Non-convex Bi-level Optimization
- **Arxiv ID**: http://arxiv.org/abs/2106.07991v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.07991v1)
- **Published**: 2021-06-15 09:10:40+00:00
- **Updated**: 2021-06-15 09:10:40+00:00
- **Authors**: Risheng Liu, Xuan Liu, Xiaoming Yuan, Shangzhi Zeng, Jin Zhang
- **Comment**: Accepted at ICML 2021
- **Journal**: None
- **Summary**: Bi-level optimization model is able to capture a wide range of complex learning tasks with practical interest. Due to the witnessed efficiency in solving bi-level programs, gradient-based methods have gained popularity in the machine learning community. In this work, we propose a new gradient-based solution scheme, namely, the Bi-level Value-Function-based Interior-point Method (BVFIM). Following the main idea of the log-barrier interior-point scheme, we penalize the regularized value function of the lower level problem into the upper level objective. By further solving a sequence of differentiable unconstrained approximation problems, we consequently derive a sequential programming scheme. The numerical advantage of our scheme relies on the fact that, when gradient methods are applied to solve the approximation problem, we successfully avoid computing any expensive Hessian-vector or Jacobian-vector product. We prove the convergence without requiring any convexity assumption on either the upper level or the lower level objective. Experiments demonstrate the efficiency of the proposed BVFIM on non-convex bi-level problems.



### Learning of feature points without additional supervision improves reinforcement learning from images
- **Arxiv ID**: http://arxiv.org/abs/2106.07995v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2106.07995v3)
- **Published**: 2021-06-15 09:17:06+00:00
- **Updated**: 2022-06-04 07:41:09+00:00
- **Authors**: Rinu Boney, Alexander Ilin, Juho Kannala
- **Comment**: None
- **Journal**: None
- **Summary**: In many control problems that include vision, optimal controls can be inferred from the location of the objects in the scene. This information can be represented using feature points, which is a list of spatial locations in learned feature maps of an input image. Previous works show that feature points learned using unsupervised pre-training or human supervision can provide good features for control tasks. In this paper, we show that it is possible to learn efficient feature point representations end-to-end, without the need for unsupervised pre-training, decoders, or additional losses. Our proposed architecture consists of a differentiable feature point extractor that feeds the coordinates of the estimated feature points directly to a soft actor-critic agent. The proposed algorithm yields performance competitive to the state-of-the art on DeepMind Control Suite tasks.



### Revisiting the Calibration of Modern Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2106.07998v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.07998v2)
- **Published**: 2021-06-15 09:24:43+00:00
- **Updated**: 2021-10-26 12:08:13+00:00
- **Authors**: Matthias Minderer, Josip Djolonga, Rob Romijnders, Frances Hubis, Xiaohua Zhai, Neil Houlsby, Dustin Tran, Mario Lucic
- **Comment**: 35th Conference on Neural Information Processing Systems (NeurIPS
  2021)
- **Journal**: None
- **Summary**: Accurate estimation of predictive uncertainty (model calibration) is essential for the safe application of neural networks. Many instances of miscalibration in modern neural networks have been reported, suggesting a trend that newer, more accurate models produce poorly calibrated predictions. Here, we revisit this question for recent state-of-the-art image classification models. We systematically relate model calibration and accuracy, and find that the most recent models, notably those not using convolutions, are among the best calibrated. Trends observed in prior model generations, such as decay of calibration with distribution shift or model size, are less pronounced in recent architectures. We also show that model size and amount of pretraining do not fully explain these differences, suggesting that architecture is a major determinant of calibration properties.



### SAR Image Classification Based on Spiking Neural Network through Spike-Time Dependent Plasticity and Gradient Descent
- **Arxiv ID**: http://arxiv.org/abs/2106.08005v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08005v1)
- **Published**: 2021-06-15 09:36:04+00:00
- **Updated**: 2021-06-15 09:36:04+00:00
- **Authors**: Jiankun Chen, Xiaolan Qiu, Chibiao Ding, Yirong Wu
- **Comment**: None
- **Journal**: None
- **Summary**: At present, the Synthetic Aperture Radar (SAR) image classification method based on convolution neural network (CNN) has faced some problems such as poor noise resistance and generalization ability. Spiking neural network (SNN) is one of the core components of brain-like intelligence and has good application prospects. This article constructs a complete SAR image classifier based on unsupervised and supervised learning of SNN by using spike sequences with complex spatio-temporal information. We firstly expound the spiking neuron model, the receptive field of SNN, and the construction of spike sequence. Then we put forward an unsupervised learning algorithm based on STDP and a supervised learning algorithm based on gradient descent. The average classification accuracy of single layer and bilayer unsupervised learning SNN in three categories images on MSTAR dataset is 80.8\% and 85.1\%, respectively. Furthermore, the convergent output spike sequences of unsupervised learning can be used as teaching signals. Based on the TensorFlow framework, a single layer supervised learning SNN is built from the bottom, and the classification accuracy reaches 90.05\%. By comparing noise resistance and model parameters between SNNs and CNNs, the effectiveness and outstanding advantages of SNN are verified. Code to reproduce our experiments is available at \url{https://github.com/Jiankun-chen/Supervised-SNN-with-GD}.



### Compositional Sketch Search
- **Arxiv ID**: http://arxiv.org/abs/2106.08009v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08009v1)
- **Published**: 2021-06-15 09:38:09+00:00
- **Updated**: 2021-06-15 09:38:09+00:00
- **Authors**: Alexander Black, Tu Bui, Long Mai, Hailin Jin, John Collomosse
- **Comment**: ICIP 2021 camera-ready version
- **Journal**: None
- **Summary**: We present an algorithm for searching image collections using free-hand sketches that describe the appearance and relative positions of multiple objects. Sketch based image retrieval (SBIR) methods predominantly match queries containing a single, dominant object invariant to its position within an image. Our work exploits drawings as a concise and intuitive representation for specifying entire scene compositions. We train a convolutional neural network (CNN) to encode masked visual features from sketched objects, pooling these into a spatial descriptor encoding the spatial relationships and appearances of objects in the composition. Training the CNN backbone as a Siamese network under triplet loss yields a metric search embedding for measuring compositional similarity which may be efficiently leveraged for visual search by applying product quantization.



### Color2Embed: Fast Exemplar-Based Image Colorization using Color Embeddings
- **Arxiv ID**: http://arxiv.org/abs/2106.08017v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2106.08017v3)
- **Published**: 2021-06-15 10:05:58+00:00
- **Updated**: 2021-08-24 12:21:52+00:00
- **Authors**: Hengyuan Zhao, Wenhao Wu, Yihao Liu, Dongliang He
- **Comment**: 10 pages, 10 figures
- **Journal**: None
- **Summary**: In this paper, we present a fast exemplar-based image colorization approach using color embeddings named Color2Embed. Generally, due to the difficulty of obtaining input and ground truth image pairs, it is hard to train a exemplar-based colorization model with unsupervised and unpaired training manner. Current algorithms usually strive to achieve two procedures: i) retrieving a large number of reference images with high similarity for preparing training dataset, which is inevitably time-consuming and tedious; ii) designing complicated modules to transfer the colors of the reference image to the target image, by calculating and leveraging the deep semantic correspondence between them (e.g., non-local operation), which is computationally expensive during testing. Contrary to the previous methods, we adopt a self-augmented self-reference learning scheme, where the reference image is generated by graphical transformations from the original colorful one whereby the training can be formulated in a paired manner. Second, in order to reduce the process time, our method explicitly extracts the color embeddings and exploits a progressive style feature Transformation network, which injects the color embeddings into the reconstruction of the final image. Such design is much more lightweight and intelligible, achieving appealing performance with fast processing speed.



### A Clinically Inspired Approach for Melanoma classification
- **Arxiv ID**: http://arxiv.org/abs/2106.08021v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08021v1)
- **Published**: 2021-06-15 10:12:24+00:00
- **Updated**: 2021-06-15 10:12:24+00:00
- **Authors**: Prathyusha Akundi, Soumyasis Gun, Jayanthi Sivaswamy
- **Comment**: 5 pages, 3 figures, 1 table
- **Journal**: None
- **Summary**: Melanoma is a leading cause of deaths due to skin cancer deaths and hence, early and effective diagnosis of melanoma is of interest. Current approaches for automated diagnosis of melanoma either use pattern recognition or analytical recognition like ABCDE (asymmetry, border, color, diameter and evolving) criterion. In practice however, a differential approach wherein outliers (ugly duckling) are detected and used to evaluate nevi/lesions. Incorporation of differential recognition in Computer Aided Diagnosis (CAD) systems has not been explored but can be beneficial as it can provide a clinical justification for the derived decision. We present a method for identifying and quantifying ugly ducklings by performing Intra-Patient Comparative Analysis (IPCA) of neighboring nevi. This is then incorporated in a CAD system design for melanoma detection. This design ensures flexibility to handle cases where IPCA is not possible. Our experiments on a public dataset show that the outlier information helps boost the sensitivity of detection by at least 4.1 % and specificity by 4.0 % to 8.9 %, depending on the use of a strong (EfficientNet) or moderately strong (VGG or ResNet) classifier.



### Mean Embeddings with Test-Time Data Augmentation for Ensembling of Representations
- **Arxiv ID**: http://arxiv.org/abs/2106.08038v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08038v2)
- **Published**: 2021-06-15 10:49:46+00:00
- **Updated**: 2021-07-14 16:22:21+00:00
- **Authors**: Arsenii Ashukha, Andrei Atanov, Dmitry Vetrov
- **Comment**: None
- **Journal**: None
- **Summary**: Averaging predictions over a set of models -- an ensemble -- is widely used to improve predictive performance and uncertainty estimation of deep learning models. At the same time, many machine learning systems, such as search, matching, and recommendation systems, heavily rely on embeddings. Unfortunately, due to misalignment of features of independently trained models, embeddings, cannot be improved with a naive deep ensemble like approach. In this work, we look at the ensembling of representations and propose mean embeddings with test-time augmentation (MeTTA) simple yet well-performing recipe for ensembling representations. Empirically we demonstrate that MeTTA significantly boosts the quality of linear evaluation on ImageNet for both supervised and self-supervised models. Even more exciting, we draw connections between MeTTA, image retrieval, and transformation invariant models. We believe that spreading the success of ensembles to inference higher-quality representations is the important step that will open many new applications of ensembling.



### Hotel Recognition via Latent Image Embedding
- **Arxiv ID**: http://arxiv.org/abs/2106.08042v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08042v1)
- **Published**: 2021-06-15 10:52:07+00:00
- **Updated**: 2021-06-15 10:52:07+00:00
- **Authors**: Boris Tseytlin, Ilya Makarov
- **Comment**: IWANN 2021
- **Journal**: None
- **Summary**: We approach the problem of hotel recognition with deep metric learning. We overview the existing approaches and propose a modification to Contrastive loss called Contrastive-Triplet loss. We construct a robust pipeline for benchmarking metric learning models and perform experiments on Hotels-50K and CUB200 datasets. Contrastive-Triplet loss is shown to achieve better retrieval on Hotels-50k. We open-source our code.



### Object detection and Autoencoder-based 6D pose estimation for highly cluttered Bin Picking
- **Arxiv ID**: http://arxiv.org/abs/2106.08045v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08045v1)
- **Published**: 2021-06-15 11:01:07+00:00
- **Updated**: 2021-06-15 11:01:07+00:00
- **Authors**: Timon Höfer, Faranak Shamsafar, Nuri Benbarka, Andreas Zell
- **Comment**: 5 pages, 1 page references. Accepted to ICIP 2021
- **Journal**: None
- **Summary**: Bin picking is a core problem in industrial environments and robotics, with its main module as 6D pose estimation. However, industrial depth sensors have a lack of accuracy when it comes to small objects. Therefore, we propose a framework for pose estimation in highly cluttered scenes with small objects, which mainly relies on RGB data and makes use of depth information only for pose refinement. In this work, we compare synthetic data generation approaches for object detection and pose estimation and introduce a pose filtering algorithm that determines the most accurate estimated poses. We will make our



### Demographic Fairness in Face Identification: The Watchlist Imbalance Effect
- **Arxiv ID**: http://arxiv.org/abs/2106.08049v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/2106.08049v3)
- **Published**: 2021-06-15 11:09:06+00:00
- **Updated**: 2021-06-30 07:20:20+00:00
- **Authors**: Pawel Drozdowski, Christian Rathgeb, Christoph Busch
- **Comment**: dispute over contents of section 2
- **Journal**: None
- **Summary**: Recently, different researchers have found that the gallery composition of a face database can induce performance differentials to facial identification systems in which a probe image is compared against up to all stored reference images to reach a biometric decision. This negative effect is referred to as "watchlist imbalance effect". In this work, we present a method to theoretically estimate said effect for a biometric identification system given its verification performance across demographic groups and the composition of the used gallery. Further, we report results for identification experiments on differently composed demographic subsets, i.e. females and males, of the public academic MORPH database using the open-source ArcFace face recognition system. It is shown that the database composition has a huge impact on performance differentials in biometric identification systems, even if performance differentials are less pronounced in the verification scenario. This study represents the first detailed analysis of the watchlist imbalance effect which is expected to be of high interest for future research in the field of facial recognition.



### Real-time Pose and Shape Reconstruction of Two Interacting Hands With a Single Depth Camera
- **Arxiv ID**: http://arxiv.org/abs/2106.08059v1
- **DOI**: 10.1145/3306346.3322958
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08059v1)
- **Published**: 2021-06-15 11:39:49+00:00
- **Updated**: 2021-06-15 11:39:49+00:00
- **Authors**: Franziska Mueller, Micah Davis, Florian Bernard, Oleksandr Sotnychenko, Mickeal Verschoor, Miguel A. Otaduy, Dan Casas, Christian Theobalt
- **Comment**: ACM Transactions on Graphics (Proceedings SIGGRAPH 2019)
- **Journal**: None
- **Summary**: We present a novel method for real-time pose and shape reconstruction of two strongly interacting hands. Our approach is the first two-hand tracking solution that combines an extensive list of favorable properties, namely it is marker-less, uses a single consumer-level depth camera, runs in real time, handles inter- and intra-hand collisions, and automatically adjusts to the user's hand shape. In order to achieve this, we embed a recent parametric hand pose and shape model and a dense correspondence predictor based on a deep neural network into a suitable energy minimization framework. For training the correspondence prediction network, we synthesize a two-hand dataset based on physical simulations that includes both hand pose and shape annotations while at the same time avoiding inter-hand penetrations. To achieve real-time rates, we phrase the model fitting in terms of a nonlinear least-squares problem so that the energy can be optimized based on a highly efficient GPU-based Gauss-Newton optimizer. We show state-of-the-art results in scenes that exceed the complexity level demonstrated by previous work, including tight two-hand grasps, significant inter-hand occlusions, and gesture interaction.



### Relation Modeling in Spatio-Temporal Action Localization
- **Arxiv ID**: http://arxiv.org/abs/2106.08061v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08061v2)
- **Published**: 2021-06-15 11:40:18+00:00
- **Updated**: 2021-06-16 07:00:12+00:00
- **Authors**: Yutong Feng, Jianwen Jiang, Ziyuan Huang, Zhiwu Qing, Xiang Wang, Shiwei Zhang, Mingqian Tang, Yue Gao
- **Comment**: CVPR 2021 ActivityNet Workshop Report
- **Journal**: None
- **Summary**: This paper presents our solution to the AVA-Kinetics Crossover Challenge of ActivityNet workshop at CVPR 2021. Our solution utilizes multiple types of relation modeling methods for spatio-temporal action detection and adopts a training strategy to integrate multiple relation modeling in end-to-end training over the two large-scale video datasets. Learning with memory bank and finetuning for long-tailed distribution are also investigated to further improve the performance. In this paper, we detail the implementations of our solution and provide experiments results and corresponding discussions. We finally achieve 40.67 mAP on the test set of AVA-Kinetics.



### Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label
- **Arxiv ID**: http://arxiv.org/abs/2106.08073v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2106.08073v1)
- **Published**: 2021-06-15 12:04:22+00:00
- **Updated**: 2021-06-15 12:04:22+00:00
- **Authors**: Guangze Zheng, Changhong Fu, Junjie Ye, Fuling Lin, Fangqiang Ding
- **Comment**: Accepted by ICRA 2021, Github:
  https://github.com/vision4robotics/MSCF-tracker
- **Journal**: None
- **Summary**: Unmanned aerial vehicle (UAV) based visual tracking has been confronted with numerous challenges, e.g., object motion and occlusion. These challenges generally introduce unexpected mutations of target appearance and result in tracking failure. However, prevalent discriminative correlation filter (DCF) based trackers are insensitive to target mutations due to a predefined label, which concentrates on merely the centre of the training region. Meanwhile, appearance mutations caused by occlusion or similar objects usually lead to the inevitable learning of wrong information. To cope with appearance mutations, this paper proposes a novel DCF-based method to enhance the sensitivity and resistance to mutations with an adaptive hybrid label, i.e., MSCF. The ideal label is optimized jointly with the correlation filter and remains temporal consistency. Besides, a novel measurement of mutations called mutation threat factor (MTF) is applied to correct the label dynamically. Considerable experiments are conducted on widely used UAV benchmarks. The results indicate that the performance of MSCF tracker surpasses other 26 state-of-the-art DCF-based and deep-based trackers. With a real-time speed of _38 frames/s, the proposed approach is sufficient for UAV tracking commissions.



### Computer-aided Interpretable Features for Leaf Image Classification
- **Arxiv ID**: http://arxiv.org/abs/2106.08077v3
- **DOI**: None
- **Categories**: **cs.CV**, stat.AP, E.4; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2106.08077v3)
- **Published**: 2021-06-15 12:11:10+00:00
- **Updated**: 2021-08-24 07:14:47+00:00
- **Authors**: Jayani P. G. Lakshika, Thiyanga S. Talagala
- **Comment**: 31 pages
- **Journal**: None
- **Summary**: Plant species identification is time consuming, costly, and requires lots of efforts, and expertise knowledge. In recent, many researchers use deep learning methods to classify plants directly using plant images. While deep learning models have achieved a great success, the lack of interpretability limit their widespread application. To overcome this, we explore the use of interpretable, measurable and computer-aided features extracted from plant leaf images. Image processing is one of the most challenging, and crucial steps in feature-extraction. The purpose of image processing is to improve the leaf image by removing undesired distortion. The main image processing steps of our algorithm involves: i) Convert original image to RGB (Red-Green-Blue) image, ii) Gray scaling, iii) Gaussian smoothing, iv) Binary thresholding, v) Remove stalk, vi) Closing holes, and vii) Resize image. The next step after image processing is to extract features from plant leaf images. We introduced 52 computationally efficient features to classify plant species. These features are mainly classified into four groups as: i) shape-based features, ii) color-based features, iii) texture-based features, and iv) scagnostic features. Length, width, area, texture correlation, monotonicity and scagnostics are to name few of them. We explore the ability of features to discriminate the classes of interest under supervised learning and unsupervised learning settings. For that, supervised dimensionality reduction technique, Linear Discriminant Analysis (LDA), and unsupervised dimensionality reduction technique, Principal Component Analysis (PCA) are used to convert and visualize the images from digital-image space to feature space. The results show that the features are sufficient to discriminate the classes of interest under both supervised and unsupervised learning settings.



### Generating Thermal Human Faces for Physiological Assessment Using Thermal Sensor Auxiliary Labels
- **Arxiv ID**: http://arxiv.org/abs/2106.08091v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08091v1)
- **Published**: 2021-06-15 12:32:52+00:00
- **Updated**: 2021-06-15 12:32:52+00:00
- **Authors**: Catherine Ordun, Edward Raff, Sanjay Purushotham
- **Comment**: None
- **Journal**: 2021 IEEE International Conference on Image Processing (ICIP)
- **Summary**: Thermal images reveal medically important physiological information about human stress, signs of inflammation, and emotional mood that cannot be seen on visible images. Providing a method to generate thermal faces from visible images would be highly valuable for the telemedicine community in order to show this medical information. To the best of our knowledge, there are limited works on visible-to-thermal (VT) face translation, and many current works go the opposite direction to generate visible faces from thermal surveillance images (TV) for law enforcement applications. As a result, we introduce favtGAN, a VT GAN which uses the pix2pix image translation model with an auxiliary sensor label prediction network for generating thermal faces from visible images. Since most TV methods are trained on only one data source drawn from one thermal sensor, we combine datasets from faces and cityscapes. These combined data are captured from similar sensors in order to bootstrap the training and transfer learning task, especially valuable because visible-thermal face datasets are limited. Experiments on these combined datasets show that favtGAN demonstrates an increase in SSIM and PSNR scores of generated thermal faces, compared to training on a single face dataset alone.



### Cine-MRI detection of abdominal adhesions with spatio-temporal deep learning
- **Arxiv ID**: http://arxiv.org/abs/2106.08094v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08094v1)
- **Published**: 2021-06-15 12:33:54+00:00
- **Updated**: 2021-06-15 12:33:54+00:00
- **Authors**: Bram de Wilde, Richard P. G. ten Broek, Henkjan Huisman
- **Comment**: Accepted at MIDL 2021 as short paper
- **Journal**: None
- **Summary**: Adhesions are an important cause of chronic pain following abdominal surgery. Recent developments in abdominal cine-MRI have enabled the non-invasive diagnosis of adhesions. Adhesions are identified on cine-MRI by the absence of sliding motion during movement. Diagnosis and mapping of adhesions improves the management of patients with pain. Detection of abdominal adhesions on cine-MRI is challenging from both a radiological and deep learning perspective. We focus on classifying presence or absence of adhesions in sagittal abdominal cine-MRI series. We experimented with spatio-temporal deep learning architectures centered around a ConvGRU architecture. A hybrid architecture comprising a ResNet followed by a ConvGRU model allows to classify a whole time-series. Compared to a stand-alone ResNet with a two time-point (inspiration/expiration) input, we show an increase in classification performance (AUROC) from 0.74 to 0.83 ($p<0.05$). Our full temporal classification approach adds only a small amount (5%) of parameters to the entire architecture, which may be useful for other medical imaging problems with a temporal dimension.



### ResDepth: A Deep Residual Prior For 3D Reconstruction From High-resolution Satellite Images
- **Arxiv ID**: http://arxiv.org/abs/2106.08107v2
- **DOI**: 10.1016/j.isprsjprs.2021.11.009
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08107v2)
- **Published**: 2021-06-15 12:51:28+00:00
- **Updated**: 2021-11-11 18:58:06+00:00
- **Authors**: Corinne Stucker, Konrad Schindler
- **Comment**: Accepted for publication in the ISPRS Journal of Photogrammetry and
  Remote Sensing
- **Journal**: ISPRS Journal of Photogrammetry and Remote Sensing, 2022, Vol.
  183, pp. 560-580
- **Summary**: Modern optical satellite sensors enable high-resolution stereo reconstruction from space. But the challenging imaging conditions when observing the Earth from space push stereo matching to its limits. In practice, the resulting digital surface models (DSMs) are fairly noisy and often do not attain the accuracy needed for high-resolution applications such as 3D city modeling. Arguably, stereo correspondence based on low-level image similarity is insufficient and should be complemented with a-priori knowledge about the expected surface geometry beyond basic local smoothness. To that end, we introduce ResDepth, a convolutional neural network that learns such an expressive geometric prior from example data. ResDepth refines an initial, raw stereo DSM while conditioning the refinement on the images. I.e., it acts as a smart, learned post-processing filter and can seamlessly complement any stereo matching pipeline. In a series of experiments, we find that the proposed method consistently improves stereo DSMs both quantitatively and qualitatively. We show that the prior encoded in the network weights captures meaningful geometric characteristics of urban design, which also generalize across different districts and even from one city to another. Moreover, we demonstrate that, by training on a variety of stereo pairs, ResDepth can acquire a sufficient degree of invariance against variations in imaging conditions and acquisition geometry.



### Contextualizing Multiple Tasks via Learning to Decompose
- **Arxiv ID**: http://arxiv.org/abs/2106.08112v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08112v1)
- **Published**: 2021-06-15 13:10:56+00:00
- **Updated**: 2021-06-15 13:10:56+00:00
- **Authors**: Han-Jia Ye, Da-Wei Zhou, Lanqing Hong, Zhenguo Li, Xiu-Shen Wei, De-Chuan Zhan
- **Comment**: None
- **Journal**: None
- **Summary**: One single instance could possess multiple portraits and reveal diverse relationships with others according to different contexts. Those ambiguities increase the difficulty of learning a generalizable model when there exists one concept or mixed concepts in a task. We propose a general approach Learning to Decompose Network (LeadNet) for both two cases, which contextualizes a model through meta-learning multiple maps for concepts discovery -- the representations of instances are decomposed and adapted conditioned on the contexts. Through taking a holistic view over multiple latent components over instances in a sampled pseudo task, LeadNet learns to automatically select the right concept via incorporating those rich semantics inside and between objects. LeadNet demonstrates its superiority in various applications, including exploring multiple views of confusing tasks, out-of-distribution recognition, and few-shot image classification.



### Perceptually-inspired super-resolution of compressed videos
- **Arxiv ID**: http://arxiv.org/abs/2106.08147v1
- **DOI**: 10.1117/12.2530688
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08147v1)
- **Published**: 2021-06-15 13:50:24+00:00
- **Updated**: 2021-06-15 13:50:24+00:00
- **Authors**: Di Ma, Mariana Afonso, Fan Zhang, David R. Bull
- **Comment**: None
- **Journal**: None
- **Summary**: Spatial resolution adaptation is a technique which has often been employed in video compression to enhance coding efficiency. This approach encodes a lower resolution version of the input video and reconstructs the original resolution during decoding. Instead of using conventional up-sampling filters, recent work has employed advanced super-resolution methods based on convolutional neural networks (CNNs) to further improve reconstruction quality. These approaches are usually trained to minimise pixel-based losses such as Mean-Squared Error (MSE), despite the fact that this type of loss metric does not correlate well with subjective opinions. In this paper, a perceptually-inspired super-resolution approach (M-SRGAN) is proposed for spatial up-sampling of compressed video using a modified CNN model, which has been trained using a generative adversarial network (GAN) on compressed content with perceptual loss functions. The proposed method was integrated with HEVC HM 16.20, and has been evaluated on the JVET Common Test Conditions (UHD test sequences) using the Random Access configuration. The results show evident perceptual quality improvement over the original HM 16.20, with an average bitrate saving of 35.6% (Bj{\o}ntegaard Delta measurement) based on a perceptual quality metric, VMAF.



### How Modular Should Neural Module Networks Be for Systematic Generalization?
- **Arxiv ID**: http://arxiv.org/abs/2106.08170v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08170v2)
- **Published**: 2021-06-15 14:13:47+00:00
- **Updated**: 2022-01-15 22:59:24+00:00
- **Authors**: Vanessa D'Amario, Tomotake Sasaki, Xavier Boix
- **Comment**: None
- **Journal**: 35th Conference on Neural Information Processing Systems (NeurIPS
  2021), Sydney, Australia
- **Summary**: Neural Module Networks (NMNs) aim at Visual Question Answering (VQA) via composition of modules that tackle a sub-task. NMNs are a promising strategy to achieve systematic generalization, i.e., overcoming biasing factors in the training distribution. However, the aspects of NMNs that facilitate systematic generalization are not fully understood. In this paper, we demonstrate that the degree of modularity of the NMN have large influence on systematic generalization. In a series of experiments on three VQA datasets (VQA-MNIST, SQOOP, and CLEVR-CoGenT), our results reveal that tuning the degree of modularity, especially at the image encoder stage, reaches substantially higher systematic generalization. These findings lead to new NMN architectures that outperform previous ones in terms of systematic generalization.



### Automatic linear measurements of the fetal brain on MRI with deep neural networks
- **Arxiv ID**: http://arxiv.org/abs/2106.08174v1
- **DOI**: 10.1007/s11548-021-02436-8
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08174v1)
- **Published**: 2021-06-15 14:20:11+00:00
- **Updated**: 2021-06-15 14:20:11+00:00
- **Authors**: Netanell Avisdris, Bossmat Yehuda, Ori Ben-Zvi, Daphna Link-Sourani, Liat Ben-Sira, Elka Miller, Elena Zharkov, Dafna Ben Bashat, Leo Joskowicz
- **Comment**: 15 pages, 8 figures, presented in CARS 2020, submitted to IJCARS
- **Journal**: None
- **Summary**: Timely, accurate and reliable assessment of fetal brain development is essential to reduce short and long-term risks to fetus and mother. Fetal MRI is increasingly used for fetal brain assessment. Three key biometric linear measurements important for fetal brain evaluation are Cerebral Biparietal Diameter (CBD), Bone Biparietal Diameter (BBD), and Trans-Cerebellum Diameter (TCD), obtained manually by expert radiologists on reference slices, which is time consuming and prone to human error. The aim of this study was to develop a fully automatic method computing the CBD, BBD and TCD measurements from fetal brain MRI. The input is fetal brain MRI volumes which may include the fetal body and the mother's abdomen. The outputs are the measurement values and reference slices on which the measurements were computed. The method, which follows the manual measurements principle, consists of five stages: 1) computation of a Region Of Interest that includes the fetal brain with an anisotropic 3D U-Net classifier; 2) reference slice selection with a Convolutional Neural Network; 3) slice-wise fetal brain structures segmentation with a multiclass U-Net classifier; 4) computation of the fetal brain midsagittal line and fetal brain orientation, and; 5) computation of the measurements. Experimental results on 214 volumes for CBD, BBD and TCD measurements yielded a mean $L_1$ difference of 1.55mm, 1.45mm and 1.23mm respectively, and a Bland-Altman 95% confidence interval ($CI_{95}$) of 3.92mm, 3.98mm and 2.25mm respectively. These results are similar to the manual inter-observer variability. The proposed automatic method for computing biometric linear measurements of the fetal brain from MR imaging achieves human level performance. It has the potential of being a useful method for the assessment of fetal brain biometry in normal and pathological cases, and of improving routine clinical practice.



### Automated triaging of head MRI examinations using convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/2106.08176v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08176v2)
- **Published**: 2021-06-15 14:21:27+00:00
- **Updated**: 2022-06-28 08:06:34+00:00
- **Authors**: David A. Wood, Sina Kafiabadi, Ayisha Al Busaidi, Emily Guilhem, Antanas Montvila, Siddharth Agarwal, Jeremy Lynch, Matthew Townend, Gareth Barker, Sebastien Ourselin, James H. Cole, Thomas C. Booth
- **Comment**: Accepted as an oral presentation at Medical Imaging with Deep
  Learning (MIDL) 2021
- **Journal**: None
- **Summary**: The growing demand for head magnetic resonance imaging (MRI) examinations, along with a global shortage of radiologists, has led to an increase in the time taken to report head MRI scans around the world. For many neurological conditions, this delay can result in increased morbidity and mortality. An automated triaging tool could reduce reporting times for abnormal examinations by identifying abnormalities at the time of imaging and prioritizing the reporting of these scans. In this work, we present a convolutional neural network for detecting clinically-relevant abnormalities in $\text{T}_2$-weighted head MRI scans. Using a validated neuroradiology report classifier, we generated a labelled dataset of 43,754 scans from two large UK hospitals for model training, and demonstrate accurate classification (area under the receiver operating curve (AUC) = 0.943) on a test set of 800 scans labelled by a team of neuroradiologists. Importantly, when trained on scans from only a single hospital the model generalized to scans from the other hospital ($\Delta$AUC $\leq$ 0.02). A simulation study demonstrated that our model would reduce the mean reporting time for abnormal examinations from 28 days to 14 days and from 9 days to 5 days at the two hospitals, demonstrating feasibility for use in a clinical triage environment.



### A Spacecraft Dataset for Detection, Segmentation and Parts Recognition
- **Arxiv ID**: http://arxiv.org/abs/2106.08186v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08186v1)
- **Published**: 2021-06-15 14:36:56+00:00
- **Updated**: 2021-06-15 14:36:56+00:00
- **Authors**: Dung Anh Hoang, Bo Chen, Tat-Jun Chin
- **Comment**: None
- **Journal**: None
- **Summary**: Virtually all aspects of modern life depend on space technology. Thanks to the great advancement of computer vision in general and deep learning-based techniques in particular, over the decades, the world witnessed the growing use of deep learning in solving problems for space applications, such as self-driving robot, tracers, insect-like robot on cosmos and health monitoring of spacecraft. These are just some prominent examples that has advanced space industry with the help of deep learning. However, the success of deep learning models requires a lot of training data in order to have decent performance, while on the other hand, there are very limited amount of publicly available space datasets for the training of deep learning models. Currently, there is no public datasets for space-based object detection or instance segmentation, partly because manually annotating object segmentation masks is very time consuming as they require pixel-level labelling, not to mention the challenge of obtaining images from space. In this paper, we aim to fill this gap by releasing a dataset for spacecraft detection, instance segmentation and part recognition. The main contribution of this work is the development of the dataset using images of space stations and satellites, with rich annotations including bounding boxes of spacecrafts and masks to the level of object parts, which are obtained with a mixture of automatic processes and manual efforts. We also provide evaluations with state-of-the-art methods in object detection and instance segmentation as a benchmark for the dataset. The link for downloading the proposed dataset can be found on https://github.com/Yurushia1998/SatelliteDataset.



### Optimal Latent Vector Alignment for Unsupervised Domain Adaptation in Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2106.08188v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08188v1)
- **Published**: 2021-06-15 14:41:09+00:00
- **Updated**: 2021-06-15 14:41:09+00:00
- **Authors**: Dawood Al Chanti, Diana Mateus
- **Comment**: 10 pages, 3 figures, conference MICCAI
- **Journal**: None
- **Summary**: This paper addresses the domain shift problem for segmentation. As a solution, we propose OLVA, a novel and lightweight unsupervised domain adaptation method based on a Variational Auto-Encoder (VAE) and Optimal Transport (OT) theory. Thanks to the VAE, our model learns a shared cross-domain latent space that follows a normal distribution, which reduces the domain shift. To guarantee valid segmentations, our shared latent space is designed to model the shape rather than the intensity variations. We further rely on an OT loss to match and align the remaining discrepancy between the two domains in the latent space. We demonstrate OLVA's effectiveness for the segmentation of multiple cardiac structures on the public Multi-Modality Whole Heart Segmentation (MM-WHS) dataset, where the source domain consists of annotated 3D MR images and the unlabelled target domain of 3D CTs. Our results show remarkable improvements with an additional margin of 12.5\% dice score over concurrent generative training approaches.



### SUPER-ADAM: Faster and Universal Framework of Adaptive Gradients
- **Arxiv ID**: http://arxiv.org/abs/2106.08208v10
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08208v10)
- **Published**: 2021-06-15 15:16:28+00:00
- **Updated**: 2022-05-11 20:26:24+00:00
- **Authors**: Feihu Huang, Junyi Li, Heng Huang
- **Comment**: Published in NeurIPS 2021. We fixed a small error in the theoretical
  results
- **Journal**: None
- **Summary**: Adaptive gradient methods have shown excellent performances for solving many machine learning problems. Although multiple adaptive gradient methods were recently studied, they mainly focus on either empirical or theoretical aspects and also only work for specific problems by using some specific adaptive learning rates. Thus, it is desired to design a universal framework for practical algorithms of adaptive gradients with theoretical guarantee to solve general problems. To fill this gap, we propose a faster and universal framework of adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive matrix that includes most existing adaptive gradient forms. Moreover, our framework can flexibly integrate the momentum and variance reduced techniques. In particular, our novel framework provides the convergence analysis support for adaptive gradient methods under the nonconvex setting. In theoretical analysis, we prove that our SUPER-ADAM algorithm can achieve the best known gradient (i.e., stochastic first-order oracle (SFO)) complexity of $\tilde{O}(\epsilon^{-3})$ for finding an $\epsilon$-stationary point of nonconvex optimization, which matches the lower bound for stochastic smooth nonconvex optimization. In numerical experiments, we employ various deep learning tasks to validate that our algorithm consistently outperforms the existing adaptive algorithms. Code is available at https://github.com/LIJUNYI95/SuperAdam



### Classification of Documents Extracted from Images with Optical Character Recognition Methods
- **Arxiv ID**: http://arxiv.org/abs/2106.11125v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2106.11125v1)
- **Published**: 2021-06-15 15:56:00+00:00
- **Updated**: 2021-06-15 15:56:00+00:00
- **Authors**: Omer Aydin
- **Comment**: None
- **Journal**: Computer Science , 6 (2) , 46-55 (2021). Retrieved from
  https://dergipark.org.tr/tr/pub/bbd/issue/62530/864863
- **Summary**: Over the past decade, machine learning methods have given us driverless cars, voice recognition, effective web search, and a much better understanding of the human genome. Machine learning is so common today that it is used dozens of times a day, possibly unknowingly. Trying to teach a machine some processes or some situations can make them predict some results that are difficult to predict by the human brain. These methods also help us do some operations that are often impossible or difficult to do with human activities in a short time. For these reasons, machine learning is so important today. In this study, two different machine learning methods were combined. In order to solve a real-world problem, the manuscript documents were first transferred to the computer and then classified. We used three basic methods to realize the whole process. Handwriting or printed documents have been digitalized by a scanner or digital camera. These documents have been processed with two different Optical Character Recognition (OCR) operation. After that generated texts are classified by using Naive Bayes algorithm. All project was programmed in Microsoft Visual Studio 12 platform on Windows operating system. C# programming language was used for all parts of the study. Also, some prepared codes and DLLs were used.



### BEiT: BERT Pre-Training of Image Transformers
- **Arxiv ID**: http://arxiv.org/abs/2106.08254v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08254v2)
- **Published**: 2021-06-15 16:02:37+00:00
- **Updated**: 2022-09-03 14:11:33+00:00
- **Authors**: Hangbo Bao, Li Dong, Songhao Piao, Furu Wei
- **Comment**: A Path to the BERT Moment of CV
- **Journal**: None
- **Summary**: We introduce a self-supervised vision representation model BEiT, which stands for Bidirectional Encoder representation from Image Transformers. Following BERT developed in the natural language processing area, we propose a masked image modeling task to pretrain vision Transformers. Specifically, each image has two views in our pre-training, i.e, image patches (such as 16x16 pixels), and visual tokens (i.e., discrete tokens). We first "tokenize" the original image into visual tokens. Then we randomly mask some image patches and fed them into the backbone Transformer. The pre-training objective is to recover the original visual tokens based on the corrupted image patches. After pre-training BEiT, we directly fine-tune the model parameters on downstream tasks by appending task layers upon the pretrained encoder. Experimental results on image classification and semantic segmentation show that our model achieves competitive results with previous pre-training methods. For example, base-size BEiT achieves 83.2% top-1 accuracy on ImageNet-1K, significantly outperforming from-scratch DeiT training (81.8%) with the same setup. Moreover, large-size BEiT obtains 86.3% only using ImageNet-1K, even outperforming ViT-L with supervised pre-training on ImageNet-22K (85.2%). The code and pretrained models are available at https://aka.ms/beit.



### Physion: Evaluating Physical Prediction from Vision in Humans and Machines
- **Arxiv ID**: http://arxiv.org/abs/2106.08261v3
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, I.2.10; I.4.8; I.5
- **Links**: [PDF](http://arxiv.org/pdf/2106.08261v3)
- **Published**: 2021-06-15 16:13:39+00:00
- **Updated**: 2022-06-20 14:27:21+00:00
- **Authors**: Daniel M. Bear, Elias Wang, Damian Mrowca, Felix J. Binder, Hsiao-Yu Fish Tung, R. T. Pramod, Cameron Holdaway, Sirui Tao, Kevin Smith, Fan-Yun Sun, Li Fei-Fei, Nancy Kanwisher, Joshua B. Tenenbaum, Daniel L. K. Yamins, Judith E. Fan
- **Comment**: 28 pages
- **Journal**: None
- **Summary**: While current vision algorithms excel at many challenging tasks, it is unclear how well they understand the physical dynamics of real-world environments. Here we introduce Physion, a dataset and benchmark for rigorously evaluating the ability to predict how physical scenarios will evolve over time. Our dataset features realistic simulations of a wide range of physical phenomena, including rigid and soft-body collisions, stable multi-object configurations, rolling, sliding, and projectile motion, thus providing a more comprehensive challenge than previous benchmarks. We used Physion to benchmark a suite of models varying in their architecture, learning objective, input-output structure, and training data. In parallel, we obtained precise measurements of human prediction behavior on the same set of scenarios, allowing us to directly evaluate how well any model could approximate human behavior. We found that vision algorithms that learn object-centric representations generally outperform those that do not, yet still fall far short of human performance. On the other hand, graph neural networks with direct access to physical state information both perform substantially better and make predictions that are more similar to those made by humans. These results suggest that extracting physical representations of scenes is the main bottleneck to achieving human-level and human-like physical understanding in vision algorithms. We have publicly released all data and code to facilitate the use of Physion to benchmark additional models in a fully reproducible manner, enabling systematic evaluation of progress towards vision algorithms that understand physical environments as robustly as people do.



### Towards Total Recall in Industrial Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/2106.08265v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08265v2)
- **Published**: 2021-06-15 16:27:02+00:00
- **Updated**: 2022-05-05 23:01:53+00:00
- **Authors**: Karsten Roth, Latha Pemula, Joaquin Zepeda, Bernhard Schölkopf, Thomas Brox, Peter Gehler
- **Comment**: Accepted to CVPR 2022
- **Journal**: None
- **Summary**: Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best performing approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose \textbf{PatchCore}, which uses a maximally representative memory bank of nominal patch-features. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to $99.6\%$, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime.\freefootnote{$^*$ Work done during a research internship at Amazon AWS.} Code: github.com/amazon-research/patchcore-inspection.



### Multi-script Handwritten Digit Recognition Using Multi-task Learning
- **Arxiv ID**: http://arxiv.org/abs/2106.08267v1
- **DOI**: 10.3233/JIFS-212233
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08267v1)
- **Published**: 2021-06-15 16:30:37+00:00
- **Updated**: 2021-06-15 16:30:37+00:00
- **Authors**: Mesay Samuel Gondere, Lars Schmidt-Thieme, Durga Prasad Sharma, Randolf Scholz
- **Comment**: None
- **Journal**: None
- **Summary**: Handwritten digit recognition is one of the extensively studied area in machine learning. Apart from the wider research on handwritten digit recognition on MNIST dataset, there are many other research works on various script recognition. However, it is not very common for multi-script digit recognition which encourage the development of robust and multipurpose systems. Additionally working on multi-script digit recognition enables multi-task learning, considering the script classification as a related task for instance. It is evident that multi-task learning improves model performance through inductive transfer using the information contained in related tasks. Therefore, in this study multi-script handwritten digit recognition using multi-task learning will be investigated. As a specific case of demonstrating the solution to the problem, Amharic handwritten character recognition will also be experimented. The handwritten digits of three scripts including Latin, Arabic and Kannada are studied to show that multi-task models with reformulation of the individual tasks have shown promising results. In this study a novel way of using the individual tasks predictions was proposed to help classification performance and regularize the different loss for the purpose of the main task. This finding has outperformed the baseline and the conventional multi-task learning models. More importantly, it avoided the need for weighting the different losses of the tasks, which is one of the challenges in multi-task learning.



### Generating Data Augmentation samples for Semantic Segmentation of Salt Bodies in a Synthetic Seismic Image Dataset
- **Arxiv ID**: http://arxiv.org/abs/2106.08269v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08269v2)
- **Published**: 2021-06-15 16:32:32+00:00
- **Updated**: 2021-06-17 17:06:52+00:00
- **Authors**: Luis Felipe Henriques, Sérgio Colcher, Ruy Luiz Milidiú, André Bulcão, Pablo Barros
- **Comment**: None
- **Journal**: None
- **Summary**: Nowadays, subsurface salt body localization and delineation, also called semantic segmentation of salt bodies, are among the most challenging geophysicist tasks. Thus, identifying large salt bodies is notoriously tricky and is crucial for identifying hydrocarbon reservoirs and drill path planning. This work proposes a Data Augmentation method based on training two generative models to augment the number of samples in a seismic image dataset for the semantic segmentation of salt bodies. Our method uses deep learning models to generate pairs of seismic image patches and their respective salt masks for the Data Augmentation. The first model is a Variational Autoencoder and is responsible for generating patches of salt body masks. The second is a Conditional Normalizing Flow model, which receives the generated masks as inputs and generates the associated seismic image patches. We evaluate the proposed method by comparing the performance of ten distinct state-of-the-art models for semantic segmentation, trained with and without the generated augmentations, in a dataset from two synthetic seismic images. The proposed methodology yields an average improvement of 8.57% in the IoU metric across all compared models. The best result is achieved by a DeeplabV3+ model variant, which presents an IoU score of 95.17% when trained with our augmentations. Additionally, our proposal outperformed six selected data augmentation methods, and the most significant improvement in the comparison, of 9.77%, is achieved by composing our DA with augmentations from an elastic transformation. At last, we show that the proposed method is adaptable for a larger context size by achieving results comparable to the obtained on the smaller context size.



### Multi-StyleGAN: Towards Image-Based Simulation of Time-Lapse Live-Cell Microscopy
- **Arxiv ID**: http://arxiv.org/abs/2106.08285v3
- **DOI**: 10.1007/978-3-030-87237-3_46
- **Categories**: **cs.CV**, cs.LG, eess.IV, q-bio.QM, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2106.08285v3)
- **Published**: 2021-06-15 16:51:16+00:00
- **Updated**: 2021-09-24 13:09:49+00:00
- **Authors**: Christoph Reich, Tim Prangemeier, Christian Wildner, Heinz Koeppl
- **Comment**: revised -- accepted to MICCAI 2021
  (doi.org/10.1007/978-3-030-87237-3_46) (Tim Prangemeier and Christoph Reich
  --- both authors contributed equally)
- **Journal**: None
- **Summary**: Time-lapse fluorescent microscopy (TLFM) combined with predictive mathematical modelling is a powerful tool to study the inherently dynamic processes of life on the single-cell level. Such experiments are costly, complex and labour intensive. A complimentary approach and a step towards in silico experimentation, is to synthesise the imagery itself. Here, we propose Multi-StyleGAN as a descriptive approach to simulate time-lapse fluorescence microscopy imagery of living cells, based on a past experiment. This novel generative adversarial network synthesises a multi-domain sequence of consecutive timesteps. We showcase Multi-StyleGAN on imagery of multiple live yeast cells in microstructured environments and train on a dataset recorded in our laboratory. The simulation captures underlying biophysical factors and time dependencies, such as cell morphology, growth, physical interactions, as well as the intensity of a fluorescent reporter protein. An immediate application is to generate additional training and validation data for feature extraction algorithms or to aid and expedite development of advanced experimental techniques such as online monitoring or control of cells.   Code and dataset is available at https://git.rwth-aachen.de/bcs/projects/tp/multi-stylegan.



### A White Paper on Neural Network Quantization
- **Arxiv ID**: http://arxiv.org/abs/2106.08295v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08295v1)
- **Published**: 2021-06-15 17:12:42+00:00
- **Updated**: 2021-06-15 17:12:42+00:00
- **Authors**: Markus Nagel, Marios Fournarakis, Rana Ali Amjad, Yelysei Bondarenko, Mart van Baalen, Tijmen Blankevoort
- **Comment**: None
- **Journal**: None
- **Summary**: While neural networks have advanced the frontiers in many applications, they often come at a high computational cost. Reducing the power and latency of neural network inference is key if we want to integrate modern networks into edge devices with strict power and compute requirements. Neural network quantization is one of the most effective ways of achieving these savings but the additional noise it induces can lead to accuracy degradation. In this white paper, we introduce state-of-the-art algorithms for mitigating the impact of quantization noise on the network's performance while maintaining low-bit weights and activations. We start with a hardware motivated introduction to quantization and then consider two main classes of algorithms: Post-Training Quantization (PTQ) and Quantization-Aware-Training (QAT). PTQ requires no re-training or labelled data and is thus a lightweight push-button approach to quantization. In most cases, PTQ is sufficient for achieving 8-bit quantization with close to floating-point accuracy. QAT requires fine-tuning and access to labeled training data but enables lower bit quantization with competitive results. For both solutions, we provide tested pipelines based on existing literature and extensive experimentation that lead to state-of-the-art performance for common deep learning models and tasks.



### Efficient Micro-Structured Weight Unification and Pruning for Neural Network Compression
- **Arxiv ID**: http://arxiv.org/abs/2106.08301v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08301v2)
- **Published**: 2021-06-15 17:22:59+00:00
- **Updated**: 2021-06-16 16:43:08+00:00
- **Authors**: Sheng Lin, Wei Jiang, Wei Wang, Kaidi Xu, Yanzhi Wang, Shan Liu, Songnan Li
- **Comment**: 10 pages, 3 figures and 5 tables
- **Journal**: None
- **Summary**: Compressing Deep Neural Network (DNN) models to alleviate the storage and computation requirements is essential for practical applications, especially for resource limited devices. Although capable of reducing a reasonable amount of model parameters, previous unstructured or structured weight pruning methods can hardly truly accelerate inference, either due to the poor hardware compatibility of the unstructured sparsity or due to the low sparse rate of the structurally pruned network. Aiming at reducing both storage and computation, as well as preserving the original task performance, we propose a generalized weight unification framework at a hardware compatible micro-structured level to achieve high amount of compression and acceleration. Weight coefficients of a selected micro-structured block are unified to reduce the storage and computation of the block without changing the neuron connections, which turns to a micro-structured pruning special case when all unified coefficients are set to zero, where neuron connections (hence storage and computation) are completely removed. In addition, we developed an effective training framework based on the alternating direction method of multipliers (ADMM), which converts our complex constrained optimization into separately solvable subproblems. Through iteratively optimizing the subproblems, the desired micro-structure can be ensured with high compression ratio and low performance degradation. We extensively evaluated our method using a variety of benchmark models and datasets for different applications. Experimental results demonstrate state-of-the-art performance.



### Gradient Forward-Propagation for Large-Scale Temporal Video Modelling
- **Arxiv ID**: http://arxiv.org/abs/2106.08318v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08318v2)
- **Published**: 2021-06-15 17:50:22+00:00
- **Updated**: 2021-07-12 12:52:29+00:00
- **Authors**: Mateusz Malinowski, Dimitrios Vytiniotis, Grzegorz Swirszcz, Viorica Patraucean, Joao Carreira
- **Comment**: Accepted to CVPR 2021. arXiv admin note: text overlap with
  arXiv:2001.06232
- **Journal**: None
- **Summary**: How can neural networks be trained on large-volume temporal data efficiently? To compute the gradients required to update parameters, backpropagation blocks computations until the forward and backward passes are completed. For temporal signals, this introduces high latency and hinders real-time learning. It also creates a coupling between consecutive layers, which limits model parallelism and increases memory consumption. In this paper, we build upon Sideways, which avoids blocking by propagating approximate gradients forward in time, and we propose mechanisms for temporal integration of information based on different variants of skip connections. We also show how to decouple computation and delegate individual neural modules to different devices, allowing distributed and parallel training. The proposed Skip-Sideways achieves low latency training, model parallelism, and, importantly, is capable of extracting temporal features, leading to more stable training and improved performance on real-world action recognition video datasets such as HMDB51, UCF101, and the large-scale Kinetics-600. Finally, we also show that models trained with Skip-Sideways generate better future frames than Sideways models, and hence they can better utilize motion cues.



### Self-Supervised Learning with Kernel Dependence Maximization
- **Arxiv ID**: http://arxiv.org/abs/2106.08320v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08320v2)
- **Published**: 2021-06-15 17:51:16+00:00
- **Updated**: 2021-12-02 21:30:47+00:00
- **Authors**: Yazhe Li, Roman Pogodin, Danica J. Sutherland, Arthur Gretton
- **Comment**: None
- **Journal**: None
- **Summary**: We approach self-supervised learning of image representations from a statistical dependence perspective, proposing Self-Supervised Learning with the Hilbert-Schmidt Independence Criterion (SSL-HSIC). SSL-HSIC maximizes dependence between representations of transformations of an image and the image identity, while minimizing the kernelized variance of those representations. This framework yields a new understanding of InfoNCE, a variational lower bound on the mutual information (MI) between different transformations. While the MI itself is known to have pathologies which can result in learning meaningless representations, its bound is much better behaved: we show that it implicitly approximates SSL-HSIC (with a slightly different regularizer). Our approach also gives us insight into BYOL, a negative-free SSL method, since SSL-HSIC similarly learns local neighborhoods of samples. SSL-HSIC allows us to directly optimize statistical dependence in time linear in the batch size, without restrictive data assumptions or indirect mutual information estimators. Trained with or without a target network, SSL-HSIC matches the current state-of-the-art for standard linear evaluation on ImageNet, semi-supervised learning and transfer to other classification and vision tasks such as semantic segmentation, depth estimation and object recognition. Code is available at https://github.com/deepmind/ssl_hsic .



### Dynamic Head: Unifying Object Detection Heads with Attentions
- **Arxiv ID**: http://arxiv.org/abs/2106.08322v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08322v1)
- **Published**: 2021-06-15 17:55:22+00:00
- **Updated**: 2021-06-15 17:55:22+00:00
- **Authors**: Xiyang Dai, Yinpeng Chen, Bin Xiao, Dongdong Chen, Mengchen Liu, Lu Yuan, Lei Zhang
- **Comment**: CVPR 2021 camera ready with extensions
- **Journal**: None
- **Summary**: The complex nature of combining localization and classification in object detection has resulted in the flourished development of methods. Previous works tried to improve the performance in various object detection heads but failed to present a unified view. In this paper, we present a novel dynamic head framework to unify object detection heads with attentions. By coherently combining multiple self-attention mechanisms between feature levels for scale-awareness, among spatial locations for spatial-awareness, and within output channels for task-awareness, the proposed approach significantly improves the representation ability of object detection heads without any computational overhead. Further experiments demonstrate that the effectiveness and efficiency of the proposed dynamic head on the COCO benchmark. With a standard ResNeXt-101-DCN backbone, we largely improve the performance over popular object detectors and achieve a new state-of-the-art at 54.0 AP. Furthermore, with latest transformer backbone and extra data, we can push current best COCO result to a new record at 60.6 AP. The code will be released at https://github.com/microsoft/DynamicHead.



### VidHarm: A Clip Based Dataset for Harmful Content Detection
- **Arxiv ID**: http://arxiv.org/abs/2106.08323v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08323v4)
- **Published**: 2021-06-15 17:57:12+00:00
- **Updated**: 2022-09-02 15:16:09+00:00
- **Authors**: Johan Edstedt, Amanda Berg, Michael Felsberg, Johan Karlsson, Francisca Benavente, Anette Novak, Gustav Grund Pihlgren
- **Comment**: None
- **Journal**: None
- **Summary**: Automatically identifying harmful content in video is an important task with a wide range of applications. However, there is a lack of professionally labeled open datasets available. In this work VidHarm, an open dataset of 3589 video clips from film trailers annotated by professionals, is presented. An analysis of the dataset is performed, revealing among other things the relation between clip and trailer level annotations. Audiovisual models are trained on the dataset and an in-depth study of modeling choices conducted. The results show that performance is greatly improved by combining the visual and audio modality, pre-training on large-scale video recognition datasets, and class balanced sampling. Lastly, biases of the trained models are investigated using discrimination probing.   VidHarm is openly available, and further details are available at: https://vidharm.github.io



### Explaining decision of model from its prediction
- **Arxiv ID**: http://arxiv.org/abs/2106.08366v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08366v1)
- **Published**: 2021-06-15 18:36:54+00:00
- **Updated**: 2021-06-15 18:36:54+00:00
- **Authors**: Dipesh Tamboli
- **Comment**: Literature review
- **Journal**: None
- **Summary**: This document summarizes different visual explanations methods such as CAM, Grad-CAM, Localization using Multiple Instance Learning - Saliency-based methods, Saliency-driven Class-Impressions, Muting pixels in input image - Adversarial methods and Activation visualization, Convolution filter visualization - Feature-based methods. We have also shown the results produced by different methods and a comparison between CAM, GradCAM, and Guided Backpropagation.



### A Multi-Layered Approach for Measuring the Simulation-to-Reality Gap of Radar Perception for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/2106.08372v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2106.08372v2)
- **Published**: 2021-06-15 18:51:39+00:00
- **Updated**: 2021-06-20 08:13:14+00:00
- **Authors**: Anthony Ngo, Max Paul Bauer, Michael Resch
- **Comment**: Accepted at the 24th IEEE International Conference on Intelligent
  Transportation Systems (ITSC 2021)
- **Journal**: None
- **Summary**: With the increasing safety validation requirements for the release of a self-driving car, alternative approaches, such as simulation-based testing, are emerging in addition to conventional real-world testing. In order to rely on virtual tests the employed sensor models have to be validated. For this reason, it is necessary to quantify the discrepancy between simulation and reality in order to determine whether a certain fidelity is sufficient for a desired intended use. There exists no sound method to measure this simulation-to-reality gap of radar perception for autonomous driving. We address this problem by introducing a multi-layered evaluation approach, which consists of a combination of an explicit and an implicit sensor model evaluation. The former directly evaluates the realism of the synthetically generated sensor data, while the latter refers to an evaluation of a downstream target application. In order to demonstrate the method, we evaluated the fidelity of three typical radar model types (ideal, data-driven, ray tracing-based) and their applicability for virtually testing radar-based multi-object tracking. We have shown the effectiveness of the proposed approach in terms of providing an in-depth sensor model assessment that renders existing disparities visible and enables a realistic estimation of the overall model fidelity across different scenarios.



### TextStyleBrush: Transfer of Text Aesthetics from a Single Example
- **Arxiv ID**: http://arxiv.org/abs/2106.08385v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.08385v1)
- **Published**: 2021-06-15 19:28:49+00:00
- **Updated**: 2021-06-15 19:28:49+00:00
- **Authors**: Praveen Krishnan, Rama Kovvuri, Guan Pang, Boris Vassilev, Tal Hassner
- **Comment**: 18 pages, 13 figures
- **Journal**: None
- **Summary**: We present a novel approach for disentangling the content of a text image from all aspects of its appearance. The appearance representation we derive can then be applied to new content, for one-shot transfer of the source style to new content. We learn this disentanglement in a self-supervised manner. Our method processes entire word boxes, without requiring segmentation of text from background, per-character processing, or making assumptions on string lengths. We show results in different text domains which were previously handled by specialized methods, e.g., scene text, handwritten text. To these ends, we make a number of technical contributions: (1) We disentangle the style and content of a textual image into a non-parametric, fixed-dimensional vector. (2) We propose a novel approach inspired by StyleGAN but conditioned over the example style at different resolution and content. (3) We present novel self-supervised training criteria which preserve both source style and target content using a pre-trained font classifier and text recognizer. Finally, (4) we also introduce Imgur5K, a new challenging dataset for handwritten word images. We offer numerous qualitative photo-realistic results of our method. We further show that our method surpasses previous work in quantitative tests on scene text and handwriting datasets, as well as in a user study.



### Seeing Through Clouds in Satellite Images
- **Arxiv ID**: http://arxiv.org/abs/2106.08408v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08408v1)
- **Published**: 2021-06-15 20:01:27+00:00
- **Updated**: 2021-06-15 20:01:27+00:00
- **Authors**: Mingmin Zhao, Peder A. Olsen, Ranveer Chandra
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a neural-network-based solution to recover pixels occluded by clouds in satellite images. We leverage radio frequency (RF) signals in the ultra/super-high frequency band that penetrate clouds to help reconstruct the occluded regions in multispectral images. We introduce the first multi-modal multi-temporal cloud removal model. Our model uses publicly available satellite observations and produces daily cloud-free images. Experimental results show that our system significantly outperforms baselines by 8dB in PSNR. We also demonstrate use cases of our system in digital agriculture, flood monitoring, and wildfire detection. We will release the processed dataset to facilitate future research.



### Scene Transformer: A unified architecture for predicting multiple agent trajectories
- **Arxiv ID**: http://arxiv.org/abs/2106.08417v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2106.08417v3)
- **Published**: 2021-06-15 20:20:44+00:00
- **Updated**: 2022-03-04 20:25:25+00:00
- **Authors**: Jiquan Ngiam, Benjamin Caine, Vijay Vasudevan, Zhengdong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca Roelofs, Alex Bewley, Chenxi Liu, Ashish Venugopal, David Weiss, Ben Sapp, Zhifeng Chen, Jonathon Shlens
- **Comment**: ICLR 2022
- **Journal**: None
- **Summary**: Predicting the motion of multiple agents is necessary for planning in dynamic environments. This task is challenging for autonomous driving since agents (e.g. vehicles and pedestrians) and their associated behaviors may be diverse and influence one another. Most prior work have focused on predicting independent futures for each agent based on all past motion, and planning against these independent predictions. However, planning against independent predictions can make it challenging to represent the future interaction possibilities between different agents, leading to sub-optimal planning. In this work, we formulate a model for predicting the behavior of all agents jointly, producing consistent futures that account for interactions between agents. Inspired by recent language modeling approaches, we use a masking strategy as the query to our model, enabling one to invoke a single model to predict agent behavior in many ways, such as potentially conditioned on the goal or full future trajectory of the autonomous vehicle or the behavior of other agents in the environment. Our model architecture employs attention to combine features across road elements, agent interactions, and time steps. We evaluate our approach on autonomous driving datasets for both marginal and joint motion prediction, and achieve state of the art performance across two popular datasets. Through combining a scene-centric approach, agent permutation equivariant model, and a sequence masking strategy, we show that our model can unify a variety of motion prediction tasks from joint motion predictions to conditioned prediction.



### Machine learning-based analysis of hyperspectral images for automated sepsis diagnosis
- **Arxiv ID**: http://arxiv.org/abs/2106.08445v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, I.2.10; I.4; I.5; J.3
- **Links**: [PDF](http://arxiv.org/pdf/2106.08445v1)
- **Published**: 2021-06-15 21:33:59+00:00
- **Updated**: 2021-06-15 21:33:59+00:00
- **Authors**: Maximilian Dietrich, Silvia Seidlitz, Nicholas Schreck, Manuel Wiesenfarth, Patrick Godau, Minu Tizabi, Jan Sellner, Sebastian Marx, Samuel Knödler, Michael M. Allers, Leonardo Ayala, Karsten Schmidt, Thorsten Brenner, Alexander Studier-Fischer, Felix Nickel, Beat P. Müller-Stich, Annette Kopp-Schneider, Markus A. Weigand, Lena Maier-Hein
- **Comment**: Maximilian Dietrich and Silvia Seidlitz contributed equally. Markus
  A. Weigand and Lena Maier-Hein contributed equally
- **Journal**: None
- **Summary**: Sepsis is a leading cause of mortality and critical illness worldwide. While robust biomarkers for early diagnosis are still missing, recent work indicates that hyperspectral imaging (HSI) has the potential to overcome this bottleneck by monitoring microcirculatory alterations. Automated machine learning-based diagnosis of sepsis based on HSI data, however, has not been explored to date. Given this gap in the literature, we leveraged an existing data set to (1) investigate whether HSI-based automated diagnosis of sepsis is possible and (2) put forth a list of possible confounders relevant for HSI-based tissue classification. While we were able to classify sepsis with an accuracy of over $98\,\%$ using the existing data, our research also revealed several subject-, therapy- and imaging-related confounders that may lead to an overestimation of algorithm performance when not balanced across the patient groups. We conclude that further prospective studies, carefully designed with respect to these confounders, are necessary to confirm the preliminary results obtained in this study.



### Multi-Resolution Continuous Normalizing Flows
- **Arxiv ID**: http://arxiv.org/abs/2106.08462v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2106.08462v5)
- **Published**: 2021-06-15 22:14:56+00:00
- **Updated**: 2021-10-05 05:54:05+00:00
- **Authors**: Vikram Voleti, Chris Finlay, Adam Oberman, Christopher Pal
- **Comment**: 10 pages, 5 figures, 3 tables, 18 equations
- **Journal**: None
- **Summary**: Recent work has shown that Neural Ordinary Differential Equations (ODEs) can serve as generative models of images using the perspective of Continuous Normalizing Flows (CNFs). Such models offer exact likelihood calculation, and invertible generation/density estimation. In this work we introduce a Multi-Resolution variant of such models (MRCNF), by characterizing the conditional distribution over the additional information required to generate a fine image that is consistent with the coarse image. We introduce a transformation between resolutions that allows for no change in the log likelihood. We show that this approach yields comparable likelihood values for various image datasets, with improved performance at higher resolutions, with fewer parameters, using only 1 GPU. Further, we examine the out-of-distribution properties of (Multi-Resolution) Continuous Normalizing Flows, and find that they are similar to those of other likelihood-based generative models.



### Achieving Domain Robustness in Stereo Matching Networks by Removing Shortcut Learning
- **Arxiv ID**: http://arxiv.org/abs/2106.08486v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.08486v1)
- **Published**: 2021-06-15 23:22:54+00:00
- **Updated**: 2021-06-15 23:22:54+00:00
- **Authors**: WeiQin Chuah, Ruwan Tennakoon, Alireza Bab-Hadiashar, David Suter
- **Comment**: 11 pages, 7 figures
- **Journal**: None
- **Summary**: Learning-based stereo matching and depth estimation networks currently excel on public benchmarks with impressive results. However, state-of-the-art networks often fail to generalize from synthetic imagery to more challenging real data domains. This paper is an attempt to uncover hidden secrets of achieving domain robustness and in particular, discovering the important ingredients of generalization success of stereo matching networks by analyzing the effect of synthetic image learning on real data performance. We provide evidence that demonstrates that learning of features in the synthetic domain by a stereo matching network is heavily influenced by two "shortcuts" presented in the synthetic data: (1) identical local statistics (RGB colour features) between matching pixels in the synthetic stereo images and (2) lack of realism in synthetic textures on 3D objects simulated in game engines. We will show that by removing such shortcuts, we can achieve domain robustness in the state-of-the-art stereo matching frameworks and produce a remarkable performance on multiple realistic datasets, despite the fact that the networks were trained on synthetic data, only. Our experimental results point to the fact that eliminating shortcuts from the synthetic data is key to achieve domain-invariant generalization between synthetic and real data domains.



