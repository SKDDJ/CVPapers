# Arxiv Papers in cs.CV on 2021-07-13
### Kit-Net: Self-Supervised Learning to Kit Novel 3D Objects into Novel 3D Cavities
- **Arxiv ID**: http://arxiv.org/abs/2107.05789v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.05789v1)
- **Published**: 2021-07-13 00:21:23+00:00
- **Updated**: 2021-07-13 00:21:23+00:00
- **Authors**: Shivin Devgon, Jeffrey Ichnowski, Michael Danielczuk, Daniel S. Brown, Ashwin Balakrishna, Shirin Joshi, Eduardo M. C. Rocha, Eugen Solowjow, Ken Goldberg
- **Comment**: None
- **Journal**: Conference on Automation Science and Engineering (CASE) 2021
- **Summary**: In industrial part kitting, 3D objects are inserted into cavities for transportation or subsequent assembly. Kitting is a critical step as it can decrease downstream processing and handling times and enable lower storage and shipping costs. We present Kit-Net, a framework for kitting previously unseen 3D objects into cavities given depth images of both the target cavity and an object held by a gripper in an unknown initial orientation. Kit-Net uses self-supervised deep learning and data augmentation to train a convolutional neural network (CNN) to robustly estimate 3D rotations between objects and matching concave or convex cavities using a large training dataset of simulated depth images pairs. Kit-Net then uses the trained CNN to implement a controller to orient and position novel objects for insertion into novel prismatic and conformal 3D cavities. Experiments in simulation suggest that Kit-Net can orient objects to have a 98.9% average intersection volume between the object mesh and that of the target cavity. Physical experiments with industrial objects succeed in 18% of trials using a baseline method and in 63% of trials with Kit-Net. Video, code, and data are available at https://github.com/BerkeleyAutomation/Kit-Net.



### Visual Parser: Representing Part-whole Hierarchies with Transformers
- **Arxiv ID**: http://arxiv.org/abs/2107.05790v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05790v2)
- **Published**: 2021-07-13 00:27:01+00:00
- **Updated**: 2022-01-08 16:59:18+00:00
- **Authors**: Shuyang Sun, Xiaoyu Yue, Song Bai, Philip Torr
- **Comment**: None
- **Journal**: None
- **Summary**: Human vision is able to capture the part-whole hierarchical information from the entire scene. This paper presents the Visual Parser (ViP) that explicitly constructs such a hierarchy with transformers. ViP divides visual representations into two levels, the part level and the whole level. Information of each part represents a combination of several independent vectors within the whole. To model the representations of the two levels, we first encode the information from the whole into part vectors through an attention mechanism, then decode the global information within the part vectors back into the whole representation. By iteratively parsing the two levels with the proposed encoder-decoder interaction, the model can gradually refine the features on both levels. Experimental results demonstrate that ViP can achieve very competitive performance on three major tasks e.g. classification, detection and instance segmentation. In particular, it can surpass the previous state-of-the-art CNN backbones by a large margin on object detection. The tiny model of the ViP family with $7.2\times$ fewer parameters and $10.9\times$ fewer FLOPS can perform comparably with the largest model ResNeXt-101-64$\times$4d of ResNe(X)t family. Visualization results also demonstrate that the learnt parts are highly informative of the predicting class, making ViP more explainable than previous fundamental architectures. Code is available at https://github.com/kevin-ssy/ViP.



### AlterSGD: Finding Flat Minima for Continual Learning by Alternative Training
- **Arxiv ID**: http://arxiv.org/abs/2107.05804v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.05804v1)
- **Published**: 2021-07-13 01:43:51+00:00
- **Updated**: 2021-07-13 01:43:51+00:00
- **Authors**: Zhongzhan Huang, Mingfu Liang, Senwei Liang, Wei He
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks suffer from catastrophic forgetting when learning multiple knowledge sequentially, and a growing number of approaches have been proposed to mitigate this problem. Some of these methods achieved considerable performance by associating the flat local minima with forgetting mitigation in continual learning. However, they inevitably need (1) tedious hyperparameters tuning, and (2) additional computational cost. To alleviate these problems, in this paper, we propose a simple yet effective optimization method, called AlterSGD, to search for a flat minima in the loss landscape. In AlterSGD, we conduct gradient descent and ascent alternatively when the network tends to converge at each session of learning new knowledge. Moreover, we theoretically prove that such a strategy can encourage the optimization to converge to a flat minima. We verify AlterSGD on continual learning benchmark for semantic segmentation and the empirical results show that we can significantly mitigate the forgetting and outperform the state-of-the-art methods with a large margin under challenging continual learning protocols.



### FairyTailor: A Multimodal Generative Framework for Storytelling
- **Arxiv ID**: http://arxiv.org/abs/2108.04324v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2108.04324v1)
- **Published**: 2021-07-13 02:45:08+00:00
- **Updated**: 2021-07-13 02:45:08+00:00
- **Authors**: Eden Bensaid, Mauro Martino, Benjamin Hoover, Hendrik Strobelt
- **Comment**: visit https://fairytailor.org/ and
  https://github.com/EdenBD/MultiModalStory-demo for web demo and source code
- **Journal**: None
- **Summary**: Storytelling is an open-ended task that entails creative thinking and requires a constant flow of ideas. Natural language generation (NLG) for storytelling is especially challenging because it requires the generated text to follow an overall theme while remaining creative and diverse to engage the reader. In this work, we introduce a system and a web-based demo, FairyTailor, for human-in-the-loop visual story co-creation. Users can create a cohesive children's fairytale by weaving generated texts and retrieved images with their input. FairyTailor adds another modality and modifies the text generation process to produce a coherent and creative sequence of text and images. To our knowledge, this is the first dynamic tool for multimodal story generation that allows interactive co-formation of both texts and images. It allows users to give feedback on co-created stories and share their results.



### Multitask Identity-Aware Image Steganography via Minimax Optimization
- **Arxiv ID**: http://arxiv.org/abs/2107.05819v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05819v1)
- **Published**: 2021-07-13 02:53:38+00:00
- **Updated**: 2021-07-13 02:53:38+00:00
- **Authors**: Jiabao Cui, Pengyi Zhang, Songyuan Li, Liangli Zheng, Cuizhu Bao, Jupeng Xia, Xi Li
- **Comment**: Accepted to Transaction of Image Processing
- **Journal**: None
- **Summary**: High-capacity image steganography, aimed at concealing a secret image in a cover image, is a technique to preserve sensitive data, e.g., faces and fingerprints. Previous methods focus on the security during transmission and subsequently run a risk of privacy leakage after the restoration of secret images at the receiving end. To address this issue, we propose a framework, called Multitask Identity-Aware Image Steganography (MIAIS), to achieve direct recognition on container images without restoring secret images. The key issue of the direct recognition is to preserve identity information of secret images into container images and make container images look similar to cover images at the same time. Thus, we introduce a simple content loss to preserve the identity information, and design a minimax optimization to deal with the contradictory aspects. We demonstrate that the robustness results can be transferred across different cover datasets. In order to be flexible for the secret image restoration in some cases, we incorporate an optional restoration network into our method, providing a multitask framework. The experiments under the multitask scenario show the effectiveness of our framework compared with other visual information hiding methods and state-of-the-art high-capacity image steganography methods.



### Detect and Locate: Exposing Face Manipulation by Semantic- and Noise-level Telltales
- **Arxiv ID**: http://arxiv.org/abs/2107.05821v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05821v2)
- **Published**: 2021-07-13 02:59:31+00:00
- **Updated**: 2022-04-06 11:04:24+00:00
- **Authors**: Chenqi Kong, Baoliang Chen, Haoliang Li, Shiqi Wang, Anderson Rocha, Sam Kwong
- **Comment**: 12 pages, 10 figures
- **Journal**: None
- **Summary**: The technological advancements of deep learning have enabled sophisticated face manipulation schemes, raising severe trust issues and security concerns in modern society. Generally speaking, detecting manipulated faces and locating the potentially altered regions are challenging tasks. Herein, we propose a conceptually simple but effective method to efficiently detect forged faces in an image while simultaneously locating the manipulated regions. The proposed scheme relies on a segmentation map that delivers meaningful high-level semantic information clues about the image. Furthermore, a noise map is estimated, playing a complementary role in capturing low-level clues and subsequently empowering decision-making. Finally, the features from these two modules are combined to distinguish fake faces. Extensive experiments show that the proposed model achieves state-of-the-art detection accuracy and remarkable localization performance.



### Dynamic Distribution of Edge Intelligence at the Node Level for Internet of Things
- **Arxiv ID**: http://arxiv.org/abs/2107.05828v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05828v1)
- **Published**: 2021-07-13 03:26:36+00:00
- **Updated**: 2021-07-13 03:26:36+00:00
- **Authors**: Hawzhin Mohammed, Tolulope A. Odetola, Nan Guo, Syed Rafay Hasan
- **Comment**: 5 pages, 4 figures, and 4 tables
- **Journal**: None
- **Summary**: In this paper, dynamic deployment of Convolutional Neural Network (CNN) architecture is proposed utilizing only IoT-level devices. By partitioning and pipelining the CNN, it horizontally distributes the computation load among resource-constrained devices (called horizontal collaboration), which in turn increases the throughput. Through partitioning, we can decrease the computation and energy consumption on individual IoT devices and increase the throughput without sacrificing accuracy. Also, by processing the data at the generation point, data privacy can be achieved. The results show that throughput can be increased by 1.55x to 1.75x for sharing the CNN into two and three resource-constrained devices, respectively.



### ReLLIE: Deep Reinforcement Learning for Customized Low-Light Image Enhancement
- **Arxiv ID**: http://arxiv.org/abs/2107.05830v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05830v1)
- **Published**: 2021-07-13 03:36:30+00:00
- **Updated**: 2021-07-13 03:36:30+00:00
- **Authors**: Rongkai Zhang, Lanqing Guo, Siyu Huang, Bihan Wen
- **Comment**: Accepted by ACM MM 2021
- **Journal**: None
- **Summary**: Low-light image enhancement (LLIE) is a pervasive yet challenging problem, since: 1) low-light measurements may vary due to different imaging conditions in practice; 2) images can be enlightened subjectively according to diverse preferences by each individual. To tackle these two challenges, this paper presents a novel deep reinforcement learning based method, dubbed ReLLIE, for customized low-light enhancement. ReLLIE models LLIE as a markov decision process, i.e., estimating the pixel-wise image-specific curves sequentially and recurrently. Given the reward computed from a set of carefully crafted non-reference loss functions, a lightweight network is proposed to estimate the curves for enlightening of a low-light image input. As ReLLIE learns a policy instead of one-one image translation, it can handle various low-light measurements and provide customized enhanced outputs by flexibly applying the policy different times. Furthermore, ReLLIE can enhance real-world images with hybrid corruptions, e.g., noise, by using a plug-and-play denoiser easily. Extensive experiments on various benchmarks demonstrate the advantages of ReLLIE, comparing to the state-of-the-art methods.



### NucMM Dataset: 3D Neuronal Nuclei Instance Segmentation at Sub-Cubic Millimeter Scale
- **Arxiv ID**: http://arxiv.org/abs/2107.05840v2
- **DOI**: 10.1007/978-3-030-87193-2_16
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05840v2)
- **Published**: 2021-07-13 04:29:58+00:00
- **Updated**: 2021-12-07 20:06:21+00:00
- **Authors**: Zudi Lin, Donglai Wei, Mariela D. Petkova, Yuelong Wu, Zergham Ahmed, Krishna Swaroop K, Silin Zou, Nils Wendt, Jonathan Boulanger-Weill, Xueying Wang, Nagaraju Dhanyasi, Ignacio Arganda-Carreras, Florian Engert, Jeff Lichtman, Hanspeter Pfister
- **Comment**: MICCAI 2021. Fix typos and update citations
- **Journal**: None
- **Summary**: Segmenting 3D cell nuclei from microscopy image volumes is critical for biological and clinical analysis, enabling the study of cellular expression patterns and cell lineages. However, current datasets for neuronal nuclei usually contain volumes smaller than $10^{\text{-}3}\ mm^3$ with fewer than 500 instances per volume, unable to reveal the complexity in large brain regions and restrict the investigation of neuronal structures. In this paper, we have pushed the task forward to the sub-cubic millimeter scale and curated the NucMM dataset with two fully annotated volumes: one $0.1\ mm^3$ electron microscopy (EM) volume containing nearly the entire zebrafish brain with around 170,000 nuclei; and one $0.25\ mm^3$ micro-CT (uCT) volume containing part of a mouse visual cortex with about 7,000 nuclei. With two imaging modalities and significantly increased volume size and instance numbers, we discover a great diversity of neuronal nuclei in appearance and density, introducing new challenges to the field. We also perform a statistical analysis to illustrate those challenges quantitatively. To tackle the challenges, we propose a novel hybrid-representation learning model that combines the merits of foreground mask, contour map, and signed distance transform to produce high-quality 3D masks. The benchmark comparisons on the NucMM dataset show that our proposed method significantly outperforms state-of-the-art nuclei segmentation approaches. Code and data are available at https://connectomics-bazaar.github.io/proj/nucMM/index.html.



### eProduct: A Million-Scale Visual Search Benchmark to Address Product Recognition Challenges
- **Arxiv ID**: http://arxiv.org/abs/2107.05856v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05856v1)
- **Published**: 2021-07-13 05:28:34+00:00
- **Updated**: 2021-07-13 05:28:34+00:00
- **Authors**: Jiangbo Yuan, An-Ti Chiang, Wen Tang, Antonio Haro
- **Comment**: This paper was accepted at FGVC8 CVPR2021 as a competition paper
  (https://sites.google.com/view/fgvc8/papers)
- **Journal**: None
- **Summary**: Large-scale product recognition is one of the major applications of computer vision and machine learning in the e-commerce domain. Since the number of products is typically much larger than the number of categories of products, image-based product recognition is often cast as a visual search rather than a classification problem. It is also one of the instances of super fine-grained recognition, where there are many products with slight or subtle visual differences. It has always been a challenge to create a benchmark dataset for training and evaluation on various visual search solutions in a real-world setting. This motivated creation of eProduct, a dataset consisting of 2.5 million product images towards accelerating development in the areas of self-supervised learning, weakly-supervised learning, and multimodal learning, for fine-grained recognition. We present eProduct as a training set and an evaluation set, where the training set contains 1.3M+ listing images with titles and hierarchical category labels, for model development, and the evaluation set includes 10,000 query and 1.1 million index images for visual search evaluation. We will present eProduct's construction steps, provide analysis about its diversity and cover the performance of baseline models trained on it.



### Applications of knowledge graphs for food science and industry
- **Arxiv ID**: http://arxiv.org/abs/2107.05869v3
- **DOI**: 10.1016/j.patter.2022.100484
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05869v3)
- **Published**: 2021-07-13 06:26:53+00:00
- **Updated**: 2022-05-16 17:26:30+00:00
- **Authors**: Weiqing Min, Chunlin Liu, Leyi Xu, Shuqiang Jiang
- **Comment**: 45 pages, 6 figures
- **Journal**: Patterns Volume 3, Issue 5 (2022) 100484
- **Summary**: The deployment of various networks (e.g., Internet of Things [IoT] and mobile networks), databases (e.g., nutrition tables and food compositional databases), and social media (e.g., Instagram and Twitter) generates huge amounts of food data, which present researchers with an unprecedented opportunity to study various problems and applications in food science and industry via data-driven computational methods. However, these multi-source heterogeneous food data appear as information silos, leading to difficulty in fully exploiting these food data. The knowledge graph provides a unified and standardized conceptual terminology in a structured form, and thus can effectively organize these food data to benefit various applications. In this review, we provide a brief introduction to knowledge graphs and the evolution of food knowledge organization mainly from food ontology to food knowledge graphs. We then summarize seven representative applications of food knowledge graphs, such as new recipe development, diet-disease correlation discovery, and personalized dietary recommendation. We also discuss future directions in this field, such as multimodal food knowledge graph construction and food knowledge graphs for human health.



### Corridor for new mobility Aachen-Düsseldorf: Methods and concepts of the research project ACCorD
- **Arxiv ID**: http://arxiv.org/abs/2107.14048v1
- **DOI**: None
- **Categories**: **cs.CY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.14048v1)
- **Published**: 2021-07-13 07:09:51+00:00
- **Updated**: 2021-07-13 07:09:51+00:00
- **Authors**: Laurent Kloeker, Amarin Kloeker, Fabian Thomsen, Armin Erraji, Lutz Eckstein, Serge Lamberty, Adrian Fazekas, Eszter Kalló, Markus Oeser, Charlotte Fléchon, Jochen Lohmiller, Pascal Pfeiffer, Martin Sommer, Helen Winter
- **Comment**: None
- **Journal**: None
- **Summary**: With the Corridor for New Mobility Aachen - D\"usseldorf, an integrated development environment is created, incorporating existing test capabilities, to systematically test and validate automated vehicles in interaction with connected Intelligent Transport Systems Stations (ITS-Ss). This is achieved through a time- and cost-efficient toolchain and methodology, in which simulation, closed test sites as well as test fields in public transport are linked in the best possible way. By implementing a digital twin, the recorded traffic events can be visualized in real-time and driving functions can be tested in the simulation based on real data. In order to represent diverse traffic scenarios, the corridor contains a highway section, a rural area, and urban areas. First, this paper outlines the project goals before describing the individual project contents in more detail. These include the concepts of traffic detection, driving function development, digital twin development, and public involvement.



### Adversarial Motorial Prototype Framework for Open Set Recognition
- **Arxiv ID**: http://arxiv.org/abs/2108.04225v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2108.04225v1)
- **Published**: 2021-07-13 07:31:34+00:00
- **Updated**: 2021-07-13 07:31:34+00:00
- **Authors**: Ziheng Xia, Penghui Wang, Ganggang Dong, Hongwei Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Open set recognition is designed to identify known classes and to reject unknown classes simultaneously. Specifically, identifying known classes and rejecting unknown classes correspond to reducing the empirical risk and the open space risk, respectively. First, the motorial prototype framework (MPF) is proposed, which classifies known classes according to the prototype classification idea. Moreover, a motorial margin constraint term is added into the loss function of the MPF, which can further improve the clustering compactness of known classes in the feature space to reduce both risks. Second, this paper proposes the adversarial motorial prototype framework (AMPF) based on the MPF. On the one hand, this model can generate adversarial samples and add these samples into the training phase; on the other hand, it can further improve the differential mapping ability of the model to known and unknown classes with the adversarial motion of the margin constraint radius. Finally, this paper proposes an upgraded version of the AMPF, AMPF++, which adds much more generated unknown samples into the training phase. In this paper, a large number of experiments prove that the performance of the proposed models is superior to that of other current works.



### ST-DETR: Spatio-Temporal Object Traces Attention Detection Transformer
- **Arxiv ID**: http://arxiv.org/abs/2107.05887v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05887v2)
- **Published**: 2021-07-13 07:38:08+00:00
- **Updated**: 2021-07-24 19:47:14+00:00
- **Authors**: Eslam Mohamed, Ahmad El-Sallab
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2106.11401
- **Journal**: None
- **Summary**: We propose ST-DETR, a Spatio-Temporal Transformer-based architecture for object detection from a sequence of temporal frames. We treat the temporal frames as sequences in both space and time and employ the full attention mechanisms to take advantage of the features correlations over both dimensions. This treatment enables us to deal with frames sequence as temporal object features traces over every location in the space. We explore two possible approaches; the early spatial features aggregation over the temporal dimension, and the late temporal aggregation of object query spatial features. Moreover, we propose a novel Temporal Positional Embedding technique to encode the time sequence information. To evaluate our approach, we choose the Moving Object Detection (MOD)task, since it is a perfect candidate to showcase the importance of the temporal dimension. Results show a significant 5% mAP improvement on the KITTI MOD dataset over the 1-step spatial baseline.



### PU-Flow: a Point Cloud Upsampling Network with Normalizing Flows
- **Arxiv ID**: http://arxiv.org/abs/2107.05893v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05893v4)
- **Published**: 2021-07-13 07:45:48+00:00
- **Updated**: 2022-06-08 03:24:09+00:00
- **Authors**: Aihua Mao, Zihui Du, Junhui Hou, Yaqi Duan, Yong-jin Liu, Ying He
- **Comment**: None
- **Journal**: None
- **Summary**: Point cloud upsampling aims to generate dense point clouds from given sparse ones, which is a challenging task due to the irregular and unordered nature of point sets. To address this issue, we present a novel deep learning-based model, called PU-Flow, which incorporates normalizing flows and weight prediction techniques to produce dense points uniformly distributed on the underlying surface. Specifically, we exploit the invertible characteristics of normalizing flows to transform points between Euclidean and latent spaces and formulate the upsampling process as ensemble of neighbouring points in a latent space, where the ensemble weights are adaptively learned from local geometric context. Extensive experiments show that our method is competitive and, in most test cases, it outperforms state-of-the-art methods in terms of reconstruction quality, proximity-to-surface accuracy, and computation efficiency. The source code will be publicly available at https://github.com/unknownue/pu-flow.



### Automatic Seizure Detection Using the Pulse Transit Time
- **Arxiv ID**: http://arxiv.org/abs/2107.05894v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05894v1)
- **Published**: 2021-07-13 07:46:47+00:00
- **Updated**: 2021-07-13 07:46:47+00:00
- **Authors**: Eric Fiege, Salima Houta, Pinar Bisgin, Rainer Surges, Falk Howar
- **Comment**: None
- **Journal**: None
- **Summary**: Documentation of epileptic seizures plays an essential role in planning medical therapy. Solutions for automated epileptic seizure detection can help improve the current problem of incomplete and erroneous manual documentation of epileptic seizures. In recent years, a number of wearable sensors have been tested for this purpose. However, detecting seizures with subtle symptoms remains difficult and current solutions tend to have a high false alarm rate. Seizures can also affect the patient's arterial blood pressure, which has not yet been studied for detection with sensors. The pulse transit time (PTT) provides a noninvasive estimate of arterial blood pressure. It can be obtained by using to two sensors, which are measuring the time differences between arrivals of the pulse waves. Due to separated time chips a clock drift emerges, which is strongly influencing the PTT. In this work, we present an algorithm which responds to alterations in the PTT, considering the clock drift and enabling the noninvasive monitoring of blood pressure alterations using separated sensors. Furthermore we investigated whether seizures can be detected using the PTT. Our results indicate that using the algorithm, it is possible to detect seizures with a Random Forest. Using the PTT along with other signals in a multimodal approach, the detection of seizures with subtle symptoms could thereby be improved.



### Region attention and graph embedding network for occlusion objective class-based micro-expression recognition
- **Arxiv ID**: http://arxiv.org/abs/2107.05904v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2107.05904v1)
- **Published**: 2021-07-13 08:04:03+00:00
- **Updated**: 2021-07-13 08:04:03+00:00
- **Authors**: Qirong Mao, Ling Zhou, Wenming Zheng, Xiuyan Shao, Xiaohua Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Micro-expression recognition (\textbf{MER}) has attracted lots of researchers' attention in a decade. However, occlusion will occur for MER in real-world scenarios. This paper deeply investigates an interesting but unexplored challenging issue in MER, \ie, occlusion MER. First, to research MER under real-world occlusion, synthetic occluded micro-expression databases are created by using various mask for the community. Second, to suppress the influence of occlusion, a \underline{R}egion-inspired \underline{R}elation \underline{R}easoning \underline{N}etwork (\textbf{RRRN}) is proposed to model relations between various facial regions. RRRN consists of a backbone network, the Region-Inspired (\textbf{RI}) module and Relation Reasoning (\textbf{RR}) module. More specifically, the backbone network aims at extracting feature representations from different facial regions, RI module computing an adaptive weight from the region itself based on attention mechanism with respect to the unobstructedness and importance for suppressing the influence of occlusion, and RR module exploiting the progressive interactions among these regions by performing graph convolutions. Experiments are conducted on handout-database evaluation and composite database evaluation tasks of MEGC 2018 protocol. Experimental results show that RRRN can significantly explore the importance of facial regions and capture the cooperative complementary relationship of facial regions for MER. The results also demonstrate RRRN outperforms the state-of-the-art approaches, especially on occlusion, and RRRN acts more robust to occlusion.



### Learning from Partially Overlapping Labels: Image Segmentation under Annotation Shift
- **Arxiv ID**: http://arxiv.org/abs/2107.05938v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05938v1)
- **Published**: 2021-07-13 09:22:24+00:00
- **Updated**: 2021-07-13 09:22:24+00:00
- **Authors**: Gregory Filbrandt, Konstantinos Kamnitsas, David Bernstein, Alexandra Taylor, Ben Glocker
- **Comment**: None
- **Journal**: None
- **Summary**: Scarcity of high quality annotated images remains a limiting factor for training accurate image segmentation models. While more and more annotated datasets become publicly available, the number of samples in each individual database is often small. Combining different databases to create larger amounts of training data is appealing yet challenging due to the heterogeneity as a result of differences in data acquisition and annotation processes, often yielding incompatible or even conflicting information. In this paper, we investigate and propose several strategies for learning from partially overlapping labels in the context of abdominal organ segmentation. We find that combining a semi-supervised approach with an adaptive cross entropy loss can successfully exploit heterogeneously annotated data and substantially improve segmentation accuracy compared to baseline and alternative approaches.



### Cats, not CAT scans: a study of dataset similarity in transfer learning for 2D medical image classification
- **Arxiv ID**: http://arxiv.org/abs/2107.05940v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05940v1)
- **Published**: 2021-07-13 09:24:34+00:00
- **Updated**: 2021-07-13 09:24:34+00:00
- **Authors**: Irma van den Brandt, Floris Fok, Bas Mulders, Joaquin Vanschoren, Veronika Cheplygina
- **Comment**: None
- **Journal**: None
- **Summary**: Transfer learning is a commonly used strategy for medical image classification, especially via pretraining on source data and fine-tuning on target data. There is currently no consensus on how to choose appropriate source data, and in the literature we can find both evidence of favoring large natural image datasets such as ImageNet, and evidence of favoring more specialized medical datasets. In this paper we perform a systematic study with nine source datasets with natural or medical images, and three target medical datasets, all with 2D images. We find that ImageNet is the source leading to the highest performances, but also that larger datasets are not necessarily better. We also study different definitions of data similarity. We show that common intuitions about similarity may be inaccurate, and therefore not sufficient to predict an appropriate source a priori. Finally, we discuss several steps needed for further research in this field, especially with regard to other types (for example 3D) medical images. Our experiments and pretrained models are available via \url{https://www.github.com/vcheplygina/cats-scans}



### A Novel Deep Learning Method for Thermal to Annotated Thermal-Optical Fused Images
- **Arxiv ID**: http://arxiv.org/abs/2107.05942v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05942v1)
- **Published**: 2021-07-13 09:29:12+00:00
- **Updated**: 2021-07-13 09:29:12+00:00
- **Authors**: Suranjan Goswami, Satish Kumar Singh, and Bidyut B. Chaudhuri
- **Comment**: None
- **Journal**: None
- **Summary**: Thermal Images profile the passive radiation of objects and capture them in grayscale images. Such images have a very different distribution of data compared to optical colored images. We present here a work that produces a grayscale thermo-optical fused mask given a thermal input. This is a deep learning based pioneering work since to the best of our knowledge, there exists no other work on thermal-optical grayscale fusion. Our method is also unique in the sense that the deep learning method we are proposing here works on the Discrete Wavelet Transform (DWT) domain instead of the gray level domain. As a part of this work, we also present a new and unique database for obtaining the region of interest in thermal images based on an existing thermal visual paired database, containing the Region of Interest on 5 different classes of data. Finally, we are proposing a simple low cost overhead statistical measure for identifying the region of interest in the fused images, which we call as the Region of Fusion (RoF). Experiments on the database show encouraging results in identifying the region of interest in the fused images. We also show that they can be processed better in the mixed form rather than with only thermal images.



### CentripetalText: An Efficient Text Instance Representation for Scene Text Detection
- **Arxiv ID**: http://arxiv.org/abs/2107.05945v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.05945v3)
- **Published**: 2021-07-13 09:34:18+00:00
- **Updated**: 2022-01-15 16:21:51+00:00
- **Authors**: Tao Sheng, Jie Chen, Zhouhui Lian
- **Comment**: Accepted by NeurIPS 2021
- **Journal**: None
- **Summary**: Scene text detection remains a grand challenge due to the variation in text curvatures, orientations, and aspect ratios. One of the hardest problems in this task is how to represent text instances of arbitrary shapes. Although many methods have been proposed to model irregular texts in a flexible manner, most of them lose simplicity and robustness. Their complicated post-processings and the regression under Dirac delta distribution undermine the detection performance and the generalization ability. In this paper, we propose an efficient text instance representation named CentripetalText (CT), which decomposes text instances into the combination of text kernels and centripetal shifts. Specifically, we utilize the centripetal shifts to implement pixel aggregation, guiding the external text pixels to the internal text kernels. The relaxation operation is integrated into the dense regression for centripetal shifts, allowing the correct prediction in a range instead of a specific value. The convenient reconstruction of text contours and the tolerance of prediction errors in our method guarantee the high detection accuracy and the fast inference speed, respectively. Besides, we shrink our text detector into a proposal generation module, namely CentripetalText Proposal Network, replacing Segmentation Proposal Network in Mask TextSpotter v3 and producing more accurate proposals. To validate the effectiveness of our method, we conduct experiments on several commonly used scene text benchmarks, including both curved and multi-oriented text datasets. For the task of scene text detection, our approach achieves superior or competitive performance compared to other existing methods, e.g., F-measure of 86.3% at 40.0 FPS on Total-Text, F-measure of 86.1% at 34.8 FPS on MSRA-TD500, etc. For the task of end-to-end scene text recognition, our method outperforms Mask TextSpotter v3 by 1.1% on Total-Text.



### HAT: Hierarchical Aggregation Transformers for Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/2107.05946v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2107.05946v2)
- **Published**: 2021-07-13 09:34:54+00:00
- **Updated**: 2021-07-14 01:42:35+00:00
- **Authors**: Guowen Zhang, Pingping Zhang, Jinqing Qi, Huchuan Lu
- **Comment**: This work has been accepted by ACM International Conference on
  Multimedia 2021
- **Journal**: None
- **Summary**: Recently, with the advance of deep Convolutional Neural Networks (CNNs), person Re-Identification (Re-ID) has witnessed great success in various applications. However, with limited receptive fields of CNNs, it is still challenging to extract discriminative representations in a global view for persons under non-overlapped cameras. Meanwhile, Transformers demonstrate strong abilities of modeling long-range dependencies for spatial and sequential data. In this work, we take advantages of both CNNs and Transformers, and propose a novel learning framework named Hierarchical Aggregation Transformer (HAT) for image-based person Re-ID with high performance. To achieve this goal, we first propose a Deeply Supervised Aggregation (DSA) to recurrently aggregate hierarchical features from CNN backbones. With multi-granularity supervisions, the DSA can enhance multi-scale features for person retrieval, which is very different from previous methods. Then, we introduce a Transformer-based Feature Calibration (TFC) to integrate low-level detail information as the global prior for high-level semantic information. The proposed TFC is inserted to each level of hierarchical features, resulting in great performance improvements. To our best knowledge, this work is the first to take advantages of both CNNs and Transformers for image-based person Re-ID. Comprehensive experiments on four large-scale Re-ID benchmarks demonstrate that our method shows better results than several state-of-the-art methods. The code is released at https://github.com/AI-Zhpp/HAT.



### Clustering-Based Representation Learning through Output Translation and Its Application to Remote--Sensing Images
- **Arxiv ID**: http://arxiv.org/abs/2107.05948v4
- **DOI**: 10.3390/rs14143361
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.05948v4)
- **Published**: 2021-07-13 09:39:43+00:00
- **Updated**: 2022-09-25 06:38:27+00:00
- **Authors**: Qinglin Li, Bin Li, Jonathan M Garibaldi, Guoping Qiu
- **Comment**: 14 pages
- **Journal**: Remote Sens. 2022, 14, 3361
- **Summary**: In supervised deep learning, learning good representations for remote--sensing images (RSI) relies on manual annotations. However, in the area of remote sensing, it is hard to obtain huge amounts of labeled data. Recently, self--supervised learning shows its outstanding capability to learn representations of images, especially the methods of instance discrimination. Comparing methods of instance discrimination, clustering--based methods not only view the transformations of the same image as ``positive" samples but also similar images. In this paper, we propose a new clustering-based method for representation learning. We first introduce a quantity to measure representations' discriminativeness and from which we show that even distribution requires the most discriminative representations. This provides a theoretical insight into why evenly distributing the images works well. We notice that only the even distributions that preserve representations' neighborhood relations are desirable. Therefore, we develop an algorithm that translates the outputs of a neural network to achieve the goal of evenly distributing the samples while preserving outputs' neighborhood relations. Extensive experiments have demonstrated that our method can learn representations that are as good as or better than the state of the art approaches, and that our method performs computationally efficiently and robustly on various RSI datasets.



### Detecting when pre-trained nnU-Net models fail silently for Covid-19 lung lesion segmentation
- **Arxiv ID**: http://arxiv.org/abs/2107.05975v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.05975v2)
- **Published**: 2021-07-13 10:48:08+00:00
- **Updated**: 2021-07-14 11:45:47+00:00
- **Authors**: Camila Gonzalez, Karol Gotkowski, Andreas Bucher, Ricarda Fischbach, Isabel Kaltenborn, Anirban Mukhopadhyay
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic segmentation of lung lesions in computer tomography has the potential to ease the burden of clinicians during the Covid-19 pandemic. Yet predictive deep learning models are not trusted in the clinical routine due to failing silently in out-of-distribution (OOD) data. We propose a lightweight OOD detection method that exploits the Mahalanobis distance in the feature space. The proposed approach can be seamlessly integrated into state-of-the-art segmentation pipelines without requiring changes in model architecture or training procedure, and can therefore be used to assess the suitability of pre-trained models to new data. We validate our method with a patch-based nnU-Net architecture trained with a multi-institutional dataset and find that it effectively detects samples that the model segments incorrectly.



### Combining 3D Image and Tabular Data via the Dynamic Affine Feature Map Transform
- **Arxiv ID**: http://arxiv.org/abs/2107.05990v1
- **DOI**: 10.1007/978-3-030-87240-3_66
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.05990v1)
- **Published**: 2021-07-13 11:18:22+00:00
- **Updated**: 2021-07-13 11:18:22+00:00
- **Authors**: Sebastian Pölsterl, Tom Nuno Wolf, Christian Wachinger
- **Comment**: Accepted at 2021 International Conference on Medical Image Computing
  and Computer Assisted Intervention (MICCAI)
- **Journal**: None
- **Summary**: Prior work on diagnosing Alzheimer's disease from magnetic resonance images of the brain established that convolutional neural networks (CNNs) can leverage the high-dimensional image information for classifying patients. However, little research focused on how these models can utilize the usually low-dimensional tabular information, such as patient demographics or laboratory measurements. We introduce the Dynamic Affine Feature Map Transform (DAFT), a general-purpose module for CNNs that dynamically rescales and shifts the feature maps of a convolutional layer, conditional on a patient's tabular clinical information. We show that DAFT is highly effective in combining 3D image and tabular information for diagnosis and time-to-dementia prediction, where it outperforms competing CNNs with a mean balanced accuracy of 0.622 and mean c-index of 0.748, respectively. Our extensive ablation study provides valuable insights into the architectural properties of DAFT. Our implementation is available at https://github.com/ai-med/DAFT.



### Scalable, Axiomatic Explanations of Deep Alzheimer's Diagnosis from Heterogeneous Data
- **Arxiv ID**: http://arxiv.org/abs/2107.05997v2
- **DOI**: 10.1007/978-3-030-87199-4_41
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2107.05997v2)
- **Published**: 2021-07-13 11:25:54+00:00
- **Updated**: 2021-09-30 18:00:04+00:00
- **Authors**: Sebastian Pölsterl, Christina Aigner, Christian Wachinger
- **Comment**: Accepted at 2021 International Conference on Medical Image Computing
  and Computer Assisted Intervention (MICCAI)
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) have an enormous potential to learn from complex biomedical data. In particular, DNNs have been used to seamlessly fuse heterogeneous information from neuroanatomy, genetics, biomarkers, and neuropsychological tests for highly accurate Alzheimer's disease diagnosis. On the other hand, their black-box nature is still a barrier for the adoption of such a system in the clinic, where interpretability is absolutely essential. We propose Shapley Value Explanation of Heterogeneous Neural Networks (SVEHNN) for explaining the Alzheimer's diagnosis made by a DNN from the 3D point cloud of the neuroanatomy and tabular biomarkers. Our explanations are based on the Shapley value, which is the unique method that satisfies all fundamental axioms for local explanations previously established in the literature. Thus, SVEHNN has many desirable characteristics that previous work on interpretability for medical decision making is lacking. To avoid the exponential time complexity of the Shapley value, we propose to transform a given DNN into a Lightweight Probabilistic Deep Network without re-training, thus achieving a complexity only quadratic in the number of features. In our experiments on synthetic and real data, we show that we can closely approximate the exact Shapley value with a dramatically reduced runtime and can reveal the hidden knowledge the network has learned from the data.



### Teaching Agents how to Map: Spatial Reasoning for Multi-Object Navigation
- **Arxiv ID**: http://arxiv.org/abs/2107.06011v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2107.06011v4)
- **Published**: 2021-07-13 12:01:05+00:00
- **Updated**: 2023-04-25 08:26:47+00:00
- **Authors**: Pierre Marza, Laetitia Matignon, Olivier Simonin, Christian Wolf
- **Comment**: None
- **Journal**: None
- **Summary**: In the context of visual navigation, the capacity to map a novel environment is necessary for an agent to exploit its observation history in the considered place and efficiently reach known goals. This ability can be associated with spatial reasoning, where an agent is able to perceive spatial relationships and regularities, and discover object characteristics. Recent work introduces learnable policies parametrized by deep neural networks and trained with Reinforcement Learning (RL). In classical RL setups, the capacity to map and reason spatially is learned end-to-end, from reward alone. In this setting, we introduce supplementary supervision in the form of auxiliary tasks designed to favor the emergence of spatial perception capabilities in agents trained for a goal-reaching downstream objective. We show that learning to estimate metrics quantifying the spatial relationships between an agent at a given location and a goal to reach has a high positive impact in Multi-Object Navigation settings. Our method significantly improves the performance of different baseline agents, that either build an explicit or implicit representation of the environment, even matching the performance of incomparable oracle agents taking ground-truth maps as input. A learning-based agent from the literature trained with the proposed auxiliary losses was the winning entry to the Multi-Object Navigation Challenge, part of the CVPR 2021 Embodied AI Workshop.



### This Person (Probably) Exists. Identity Membership Attacks Against GAN Generated Faces
- **Arxiv ID**: http://arxiv.org/abs/2107.06018v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2107.06018v1)
- **Published**: 2021-07-13 12:11:21+00:00
- **Updated**: 2021-07-13 12:11:21+00:00
- **Authors**: Ryan Webster, Julien Rabin, Loic Simon, Frederic Jurie
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, generative adversarial networks (GANs) have achieved stunning realism, fooling even human observers. Indeed, the popular tongue-in-cheek website {\small \url{ http://thispersondoesnotexist.com}}, taunts users with GAN generated images that seem too real to believe. On the other hand, GANs do leak information about their training data, as evidenced by membership attacks recently demonstrated in the literature. In this work, we challenge the assumption that GAN faces really are novel creations, by constructing a successful membership attack of a new kind. Unlike previous works, our attack can accurately discern samples sharing the same identity as training samples without being the same samples. We demonstrate the interest of our attack across several popular face datasets and GAN training procedures. Notably, we show that even in the presence of significant dataset diversity, an over represented person can pose a privacy concern.



### Lifting the Convex Conjugate in Lagrangian Relaxations: A Tractable Approach for Continuous Markov Random Fields
- **Arxiv ID**: http://arxiv.org/abs/2107.06028v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06028v2)
- **Published**: 2021-07-13 12:31:06+00:00
- **Updated**: 2022-05-16 10:41:07+00:00
- **Authors**: Hartmut Bauermeister, Emanuel Laude, Thomas Möllenhoff, Michael Moeller, Daniel Cremers
- **Comment**: None
- **Journal**: None
- **Summary**: Dual decomposition approaches in nonconvex optimization may suffer from a duality gap. This poses a challenge when applying them directly to nonconvex problems such as MAP-inference in a Markov random field (MRF) with continuous state spaces. To eliminate such gaps, this paper considers a reformulation of the original nonconvex task in the space of measures. This infinite-dimensional reformulation is then approximated by a semi-infinite one, which is obtained via a piecewise polynomial discretization in the dual. We provide a geometric intuition behind the primal problem induced by the dual discretization and draw connections to optimization over moment spaces. In contrast to existing discretizations which suffer from a grid bias, we show that a piecewise polynomial discretization better preserves the continuous nature of our problem. Invoking results from optimal transport theory and convex algebraic geometry we reduce the semi-infinite program to a finite one and provide a practical implementation based on semidefinite programming. We show, experimentally and in theory, that the approach successfully reduces the duality gap. To showcase the scalability of our approach, we apply it to the stereo matching problem between two images.



### Force-in-domain GAN inversion
- **Arxiv ID**: http://arxiv.org/abs/2107.06050v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06050v2)
- **Published**: 2021-07-13 13:03:53+00:00
- **Updated**: 2021-07-14 01:42:15+00:00
- **Authors**: Guangjie Leng, Yekun Zhu, Zhi-Qin John Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Empirical works suggest that various semantics emerge in the latent space of Generative Adversarial Networks (GANs) when being trained to generate images. To perform real image editing, it requires an accurate mapping from the real image to the latent space to leveraging these learned semantics, which is important yet difficult. An in-domain GAN inversion approach is recently proposed to constraint the inverted code within the latent space by forcing the reconstructed image obtained from the inverted code within the real image space. Empirically, we find that the inverted code by the in-domain GAN can deviate from the latent space significantly. To solve this problem, we propose a force-in-domain GAN based on the in-domain GAN, which utilizes a discriminator to force the inverted code within the latent space. The force-in-domain GAN can also be interpreted by a cycle-GAN with slight modification. Extensive experiments show that our force-in-domain GAN not only reconstructs the target image at the pixel level, but also align the inverted code with the latent space well for semantic editing.



### MSR-Net: Multi-Scale Relighting Network for One-to-One Relighting
- **Arxiv ID**: http://arxiv.org/abs/2107.06125v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06125v1)
- **Published**: 2021-07-13 14:25:05+00:00
- **Updated**: 2021-07-13 14:25:05+00:00
- **Authors**: Sourya Dipta Das, Nisarg A. Shah, Saikat Dutta
- **Comment**: Workshop on Differentiable Vision, Graphics, and Physics in Machine
  Learning at NeurIPS 2020. arXiv admin note: text overlap with
  arXiv:2102.09242
- **Journal**: None
- **Summary**: Deep image relighting allows photo enhancement by illumination-specific retouching without human effort and so it is getting much interest lately. Most of the existing popular methods available for relighting are run-time intensive and memory inefficient. Keeping these issues in mind, we propose the use of Stacked Deep Multi-Scale Hierarchical Network, which aggregates features from each image at different scales. Our solution is differentiable and robust for translating image illumination setting from input image to target image. Additionally, we have also shown that using a multi-step training approach to this problem with two different loss functions can significantly boost performance and can achieve a high quality reconstruction of a relighted image.



### Bidirectional Regression for Arbitrary-Shaped Text Detection
- **Arxiv ID**: http://arxiv.org/abs/2107.06129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06129v1)
- **Published**: 2021-07-13 14:29:09+00:00
- **Updated**: 2021-07-13 14:29:09+00:00
- **Authors**: Tao Sheng, Zhouhui Lian
- **Comment**: Accepted at ICDAR 2021, 15 pages
- **Journal**: None
- **Summary**: Arbitrary-shaped text detection has recently attracted increasing interests and witnessed rapid development with the popularity of deep learning algorithms. Nevertheless, existing approaches often obtain inaccurate detection results, mainly due to the relatively weak ability to utilize context information and the inappropriate choice of offset references. This paper presents a novel text instance expression which integrates both foreground and background information into the pipeline, and naturally uses the pixels near text boundaries as the offset starts. Besides, a corresponding post-processing algorithm is also designed to sequentially combine the four prediction results and reconstruct the text instance accurately. We evaluate our method on several challenging scene text benchmarks, including both curved and multi-oriented text datasets. Experimental results demonstrate that the proposed approach obtains superior or competitive performance compared to other state-of-the-art methods, e.g., 83.4% F-score for Total-Text, 82.4% F-score for MSRA-TD500, etc.



### Scalable Surface Reconstruction with Delaunay-Graph Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2107.06130v3
- **DOI**: 10.1111/cgf.14364
- **Categories**: **cs.CV**, cs.CG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06130v3)
- **Published**: 2021-07-13 14:30:32+00:00
- **Updated**: 2022-02-02 00:19:03+00:00
- **Authors**: Raphael Sulzer, Loic Landrieu, Renaud Marlet, Bruno Vallet
- **Comment**: The presentation of this work at SGP 2021 is available at
  https://youtu.be/KIrCDGhS10o
- **Journal**: Computer Graphics Forum 2021
- **Summary**: We introduce a novel learning-based, visibility-aware, surface reconstruction method for large-scale, defect-laden point clouds. Our approach can cope with the scale and variety of point cloud defects encountered in real-life Multi-View Stereo (MVS) acquisitions. Our method relies on a 3D Delaunay tetrahedralization whose cells are classified as inside or outside the surface by a graph neural network and an energy model solvable with a graph cut. Our model, making use of both local geometric attributes and line-of-sight visibility information, is able to learn a visibility model from a small amount of synthetic training data and generalizes to real-life acquisitions. Combining the efficiency of deep learning methods and the scalability of energy based models, our approach outperforms both learning and non learning-based reconstruction algorithms on two publicly available reconstruction benchmarks. Our code and data is available at https://github.com/raphaelsulzer/dgnn.



### Deep learning approaches to Earth Observation change detection
- **Arxiv ID**: http://arxiv.org/abs/2107.06132v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2107.06132v1)
- **Published**: 2021-07-13 14:34:59+00:00
- **Updated**: 2021-07-13 14:34:59+00:00
- **Authors**: Antonio Di Pilato, Nicolò Taggio, Alexis Pompili, Michele Iacobellis, Adriano Di Florio, Davide Passarelli, Sergio Samarelli
- **Comment**: None
- **Journal**: None
- **Summary**: The interest for change detection in the field of remote sensing has increased in the last few years. Searching for changes in satellite images has many useful applications, ranging from land cover and land use analysis to anomaly detection. In particular, urban change detection provides an efficient tool to study urban spread and growth through several years of observation. At the same time, change detection is often a computationally challenging and time-consuming task, which requires innovative methods to guarantee optimal results with unquestionable value and within reasonable time. In this paper we present two different approaches to change detection (semantic segmentation and classification) that both exploit convolutional neural networks to achieve good results, which can be further refined and used in a post-processing workflow for a large variety of applications.



### MINERVAS: Massive INterior EnviRonments VirtuAl Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2107.06149v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06149v4)
- **Published**: 2021-07-13 14:53:01+00:00
- **Updated**: 2022-08-30 09:21:25+00:00
- **Authors**: Haocheng Ren, Hao Zhang, Jia Zheng, Jiaxiang Zheng, Rui Tang, Yuchi Huo, Hujun Bao, Rui Wang
- **Comment**: Accepted by Computer Graphics Forum, Pacific Graphics 2022. The two
  first authors contribute equally. Project pape:
  https://coohom.github.io/MINERVAS
- **Journal**: None
- **Summary**: With the rapid development of data-driven techniques, data has played an essential role in various computer vision tasks. Many realistic and synthetic datasets have been proposed to address different problems. However, there are lots of unresolved challenges: (1) the creation of dataset is usually a tedious process with manual annotations, (2) most datasets are only designed for a single specific task, (3) the modification or randomization of the 3D scene is difficult, and (4) the release of commercial 3D data may encounter copyright issue. This paper presents MINERVAS, a Massive INterior EnviRonments VirtuAl Synthesis system, to facilitate the 3D scene modification and the 2D image synthesis for various vision tasks. In particular, we design a programmable pipeline with Domain-Specific Language, allowing users to (1) select scenes from the commercial indoor scene database, (2) synthesize scenes for different tasks with customized rules, and (3) render various imagery data, such as visual color, geometric structures, semantic label. Our system eases the difficulty of customizing massive numbers of scenes for different tasks and relieves users from manipulating fine-grained scene configurations by providing user-controllable randomness using multi-level samplers. Most importantly, it empowers users to access commercial scene databases with millions of indoor scenes and protects the copyright of core data assets, e.g., 3D CAD models. We demonstrate the validity and flexibility of our system by using our synthesized data to improve the performance on different kinds of computer vision tasks.



### Fast Batch Nuclear-norm Maximization and Minimization for Robust Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2107.06154v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06154v4)
- **Published**: 2021-07-13 15:08:32+00:00
- **Updated**: 2021-08-04 14:17:20+00:00
- **Authors**: Shuhao Cui, Shuhui Wang, Junbao Zhuo, Liang Li, Qingming Huang, Qi Tian
- **Comment**: TPAMI under revivew. arXiv admin note: text overlap with
  arXiv:2003.12237
- **Journal**: None
- **Summary**: Due to the domain discrepancy in visual domain adaptation, the performance of source model degrades when bumping into the high data density near decision boundary in target domain. A common solution is to minimize the Shannon Entropy to push the decision boundary away from the high density area. However, entropy minimization also leads to severe reduction of prediction diversity, and unfortunately brings harm to the domain adaptation. In this paper, we investigate the prediction discriminability and diversity by studying the structure of the classification output matrix of a randomly selected data batch. We find by theoretical analysis that the prediction discriminability and diversity could be separately measured by the Frobenius-norm and rank of the batch output matrix. The nuclear-norm is an upperbound of the former, and a convex approximation of the latter. Accordingly, we propose Batch Nuclear-norm Maximization and Minimization, which performs nuclear-norm maximization on the target output matrix to enhance the target prediction ability, and nuclear-norm minimization on the source batch output matrix to increase applicability of the source domain knowledge. We further approximate the nuclear-norm by L_{1,2}-norm, and design multi-batch optimization for stable solution on large number of categories. The fast approximation method achieves O(n^2) computational complexity and better convergence property. Experiments show that our method could boost the adaptation accuracy and robustness under three typical domain adaptation scenarios. The code is available at https://github.com/cuishuhao/BNM.



### 3D Parametric Wireframe Extraction Based on Distance Fields
- **Arxiv ID**: http://arxiv.org/abs/2107.06165v2
- **DOI**: 10.1145/3488933.3488982
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2107.06165v2)
- **Published**: 2021-07-13 15:25:14+00:00
- **Updated**: 2022-04-20 12:11:24+00:00
- **Authors**: Albert Matveev, Alexey Artemov, Denis Zorin, Evgeny Burnaev
- **Comment**: None
- **Journal**: None
- **Summary**: We present a pipeline for parametric wireframe extraction from densely sampled point clouds. Our approach processes a scalar distance field that represents proximity to the nearest sharp feature curve. In intermediate stages, it detects corners, constructs curve segmentation, and builds a topological graph fitted to the wireframe. As an output, we produce parametric spline curves that can be edited and sampled arbitrarily. We evaluate our method on 50 complex 3D shapes and compare it to the novel deep learning-based technique, demonstrating superior quality.



### Deep Ranking with Adaptive Margin Triplet Loss
- **Arxiv ID**: http://arxiv.org/abs/2107.06187v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06187v1)
- **Published**: 2021-07-13 15:37:20+00:00
- **Updated**: 2021-07-13 15:37:20+00:00
- **Authors**: Mai Lan Ha, Volker Blanz
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a simple modification from a fixed margin triplet loss to an adaptive margin triplet loss. While the original triplet loss is used widely in classification problems such as face recognition, face re-identification and fine-grained similarity, our proposed loss is well suited for rating datasets in which the ratings are continuous values. In contrast to original triplet loss where we have to sample data carefully, in out method, we can generate triplets using the whole dataset, and the optimization can still converge without frequently running into a model collapsing issue. The adaptive margins only need to be computed once before the training, which is much less expensive than generating triplets after every epoch as in the fixed margin case. Besides substantially improved training stability (the proposed model never collapsed in our experiments compared to a couple of times that the training collapsed on existing triplet loss), we achieved slightly better performance than the original triplet loss on various rating datasets and network architectures.



### Generative Adversarial Learning via Kernel Density Discrimination
- **Arxiv ID**: http://arxiv.org/abs/2107.06197v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06197v1)
- **Published**: 2021-07-13 15:52:10+00:00
- **Updated**: 2021-07-13 15:52:10+00:00
- **Authors**: Abdelhak Lemkhenter, Adam Bielski, Alp Eren Sari, Paolo Favaro
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce Kernel Density Discrimination GAN (KDD GAN), a novel method for generative adversarial learning. KDD GAN formulates the training as a likelihood ratio optimization problem where the data distributions are written explicitly via (local) Kernel Density Estimates (KDE). This is inspired by the recent progress in contrastive learning and its relation to KDE. We define the KDEs directly in feature space and forgo the requirement of invertibility of the kernel feature mappings. In our approach, features are no longer optimized for linear separability, as in the original GAN formulation, but for the more general discrimination of distributions in the feature space. We analyze the gradient of our loss with respect to the feature representation and show that it is better behaved than that of the original hinge loss. We perform experiments with the proposed KDE-based loss, used either as a training loss or a regularization term, on both CIFAR10 and scaled versions of ImageNet. We use BigGAN/SA-GAN as a backbone and baseline, since our focus is not to design the architecture of the networks. We show a boost in the quality of generated samples with respect to FID from 10% to 40% compared to the baseline. Code will be made available.



### Learning a Discriminant Latent Space with Neural Discriminant Analysis
- **Arxiv ID**: http://arxiv.org/abs/2107.06209v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06209v1)
- **Published**: 2021-07-13 16:06:07+00:00
- **Updated**: 2021-07-13 16:06:07+00:00
- **Authors**: Mai Lan Ha, Gianni Franchi, Emanuel Aldea, Volker Blanz
- **Comment**: None
- **Journal**: None
- **Summary**: Discriminative features play an important role in image and object classification and also in other fields of research such as semi-supervised learning, fine-grained classification, out of distribution detection. Inspired by Linear Discriminant Analysis (LDA), we propose an optimization called Neural Discriminant Analysis (NDA) for Deep Convolutional Neural Networks (DCNNs). NDA transforms deep features to become more discriminative and, therefore, improves the performances in various tasks. Our proposed optimization has two primary goals for inter- and intra-class variances. The first one is to minimize variances within each individual class. The second goal is to maximize pairwise distances between features coming from different classes. We evaluate our NDA optimization in different research fields: general supervised classification, fine-grained classification, semi-supervised learning, and out of distribution detection. We achieve performance improvements in all the fields compared to baseline methods that do not use NDA. Besides, using NDA, we also surpass the state of the art on the four tasks on various testing datasets.



### Attention-Guided Progressive Neural Texture Fusion for High Dynamic Range Image Restoration
- **Arxiv ID**: http://arxiv.org/abs/2107.06211v1
- **DOI**: 10.1109/TIP.2022.3160070
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06211v1)
- **Published**: 2021-07-13 16:07:00+00:00
- **Updated**: 2021-07-13 16:07:00+00:00
- **Authors**: Jie Chen, Zaifeng Yang, Tsz Nam Chan, Hui Li, Junhui Hou, Lap-Pui Chau
- **Comment**: None
- **Journal**: None
- **Summary**: High Dynamic Range (HDR) imaging via multi-exposure fusion is an important task for most modern imaging platforms. In spite of recent developments in both hardware and algorithm innovations, challenges remain over content association ambiguities caused by saturation, motion, and various artifacts introduced during multi-exposure fusion such as ghosting, noise, and blur. In this work, we propose an Attention-guided Progressive Neural Texture Fusion (APNT-Fusion) HDR restoration model which aims to address these issues within one framework. An efficient two-stream structure is proposed which separately focuses on texture feature transfer over saturated regions and multi-exposure tonal and texture feature fusion. A neural feature transfer mechanism is proposed which establishes spatial correspondence between different exposures based on multi-scale VGG features in the masked saturated HDR domain for discriminative contextual clues over the ambiguous image areas. A progressive texture blending module is designed to blend the encoded two-stream features in a multi-scale and progressive manner. In addition, we introduce several novel attention mechanisms, i.e., the motion attention module detects and suppresses the content discrepancies among the reference images; the saturation attention module facilitates differentiating the misalignment caused by saturation from those caused by motion; and the scale attention module ensures texture blending consistency between different coder/decoder scales. We carry out comprehensive qualitative and quantitative evaluations and ablation studies, which validate that these novel modules work coherently under the same framework and outperform state-of-the-art methods.



### 'CADSketchNet' -- An Annotated Sketch dataset for 3D CAD Model Retrieval with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2107.06212v2
- **DOI**: 10.1016/j.cag.2021.07.001
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06212v2)
- **Published**: 2021-07-13 16:10:16+00:00
- **Updated**: 2021-07-20 06:26:54+00:00
- **Authors**: Bharadwaj Manda, Shubham Dhayarkar, Sai Mitheran, V. K. Viekash, Ramanathan Muthuganapathy
- **Comment**: Computers & Graphics Journal, Special Section on 3DOR 2021
- **Journal**: Computers & Graphics, Volume 99, 2021, Pages 100-113, ISSN
  0097-8493
- **Summary**: Ongoing advancements in the fields of 3D modelling and digital archiving have led to an outburst in the amount of data stored digitally. Consequently, several retrieval systems have been developed depending on the type of data stored in these databases. However, unlike text data or images, performing a search for 3D models is non-trivial. Among 3D models, retrieving 3D Engineering/CAD models or mechanical components is even more challenging due to the presence of holes, volumetric features, presence of sharp edges etc., which make CAD a domain unto itself. The research work presented in this paper aims at developing a dataset suitable for building a retrieval system for 3D CAD models based on deep learning. 3D CAD models from the available CAD databases are collected, and a dataset of computer-generated sketch data, termed 'CADSketchNet', has been prepared. Additionally, hand-drawn sketches of the components are also added to CADSketchNet. Using the sketch images from this dataset, the paper also aims at evaluating the performance of various retrieval system or a search engine for 3D CAD models that accepts a sketch image as the input query. Many experimental models are constructed and tested on CADSketchNet. These experiments, along with the model architecture, choice of similarity metrics are reported along with the search results.



### Towards Unsupervised Domain Generalization
- **Arxiv ID**: http://arxiv.org/abs/2107.06219v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2107.06219v2)
- **Published**: 2021-07-13 16:20:50+00:00
- **Updated**: 2022-04-12 03:36:35+00:00
- **Authors**: Xingxuan Zhang, Linjun Zhou, Renzhe Xu, Peng Cui, Zheyan Shen, Haoxin Liu
- **Comment**: Accepted by CVPR2022
- **Journal**: None
- **Summary**: Domain generalization (DG) aims to help models trained on a set of source domains generalize better on unseen target domains. The performances of current DG methods largely rely on sufficient labeled data, which are usually costly or unavailable, however. Since unlabeled data are far more accessible, we seek to explore how unsupervised learning can help deep models generalize across domains. Specifically, we study a novel generalization problem called unsupervised domain generalization (UDG), which aims to learn generalizable models with unlabeled data and analyze the effects of pre-training on DG. In UDG, models are pretrained with unlabeled data from various source domains before being trained on labeled source data and eventually tested on unseen target domains. Then we propose a method named Domain-Aware Representation LearnING (DARLING) to cope with the significant and misleading heterogeneity within unlabeled pretraining data and severe distribution shifts between source and target data. Surprisingly we observe that DARLING can not only counterbalance the scarcity of labeled data but also further strengthen the generalization ability of models when the labeled data are insufficient. As a pretraining approach, DARLING shows superior or comparable performance compared with ImageNet pretraining protocol even when the available data are unlabeled and of a vastly smaller amount compared to ImageNet, which may shed light on improving generalization with large-scale unlabeled data.



### Exploiting Image Translations via Ensemble Self-Supervised Learning for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2107.06235v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06235v1)
- **Published**: 2021-07-13 16:43:02+00:00
- **Updated**: 2021-07-13 16:43:02+00:00
- **Authors**: Fabrizio J. Piva, Gijs Dubbelman
- **Comment**: Manuscript under review at Computer Vision and Image Understanding
  (CVIU) journal
- **Journal**: None
- **Summary**: We introduce an unsupervised domain adaption (UDA) strategy that combines multiple image translations, ensemble learning and self-supervised learning in one coherent approach. We focus on one of the standard tasks of UDA in which a semantic segmentation model is trained on labeled synthetic data together with unlabeled real-world data, aiming to perform well on the latter. To exploit the advantage of using multiple image translations, we propose an ensemble learning approach, where three classifiers calculate their prediction by taking as input features of different image translations, making each classifier learn independently, with the purpose of combining their outputs by sparse Multinomial Logistic Regression. This regression layer known as meta-learner helps to reduce the bias during pseudo label generation when performing self-supervised learning and improves the generalizability of the model by taking into consideration the contribution of each classifier. We evaluate our method on the standard UDA benchmarks, i.e. adapting GTA V and Synthia to Cityscapes, and achieve state-of-the-art results in the mean intersection over union metric. Extensive ablation experiments are reported to highlight the advantageous properties of our proposed UDA strategy.



### Medical Imaging with Deep Learning for COVID- 19 Diagnosis: A Comprehensive Review
- **Arxiv ID**: http://arxiv.org/abs/2107.09602v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.09602v1)
- **Published**: 2021-07-13 16:49:49+00:00
- **Updated**: 2021-07-13 16:49:49+00:00
- **Authors**: Subrato Bharati, Prajoy Podder, M. Rubaiyat Hossain Mondal, V. B. Surya Prasath
- **Comment**: 22 pages, 11 Figures
- **Journal**: International Journal of Computer Information Systems and
  Industrial Management Applications(ISSN 2150-7988), Volume 13, 2021
- **Summary**: The outbreak of novel coronavirus disease (COVID- 19) has claimed millions of lives and has affected all aspects of human life. This paper focuses on the application of deep learning (DL) models to medical imaging and drug discovery for managing COVID-19 disease. In this article, we detail various medical imaging-based studies such as X-rays and computed tomography (CT) images along with DL methods for classifying COVID-19 affected versus pneumonia. The applications of DL techniques to medical images are further described in terms of image localization, segmentation, registration, and classification leading to COVID-19 detection. The reviews of recent papers indicate that the highest classification accuracy of 99.80% is obtained when InstaCovNet-19 DL method is applied to an X-ray dataset of 361 COVID-19 patients, 362 pneumonia patients and 365 normal people. Furthermore, it can be seen that the best classification accuracy of 99.054% can be achieved when EDL_COVID DL method is applied to a CT image dataset of 7500 samples where COVID-19 patients, lung tumor patients and normal people are equal in number. Moreover, we illustrate the potential DL techniques in drug or vaccine discovery in combating the coronavirus. Finally, we address a number of problems, concerns and future research directions relevant to DL applications for COVID-19.



### Everybody Is Unique: Towards Unbiased Human Mesh Recovery
- **Arxiv ID**: http://arxiv.org/abs/2107.06239v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2107.06239v1)
- **Published**: 2021-07-13 16:52:55+00:00
- **Updated**: 2021-07-13 16:52:55+00:00
- **Authors**: Ren Li, Meng Zheng, Srikrishna Karanam, Terrence Chen, Ziyan Wu
- **Comment**: 10 pages, 5 figures, 4 tables
- **Journal**: None
- **Summary**: We consider the problem of obese human mesh recovery, i.e., fitting a parametric human mesh to images of obese people. Despite obese person mesh fitting being an important problem with numerous applications (e.g., healthcare), much recent progress in mesh recovery has been restricted to images of non-obese people. In this work, we identify this crucial gap in the current literature by presenting and discussing limitations of existing algorithms. Next, we present a simple baseline to address this problem that is scalable and can be easily used in conjunction with existing algorithms to improve their performance. Finally, we present a generalized human mesh optimization algorithm that substantially improves the performance of existing methods on both obese person images as well as community-standard benchmark datasets. A key innovation of this technique is that it does not rely on supervision from expensive-to-create mesh parameters. Instead, starting from widely and cheaply available 2D keypoints annotations, our method automatically generates mesh parameters that can in turn be used to re-train and fine-tune any existing mesh estimation algorithm. This way, we show our method acts as a drop-in to improve the performance of a wide variety of contemporary mesh estimation methods. We conduct extensive experiments on multiple datasets comprising both standard and obese person images and demonstrate the efficacy of our proposed techniques.



### Retrieve in Style: Unsupervised Facial Feature Transfer and Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2107.06256v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06256v3)
- **Published**: 2021-07-13 17:31:34+00:00
- **Updated**: 2021-08-24 23:11:57+00:00
- **Authors**: Min Jin Chong, Wen-Sheng Chu, Abhishek Kumar, David Forsyth
- **Comment**: Code is here https://github.com/mchong6/RetrieveInStyle
- **Journal**: None
- **Summary**: We present Retrieve in Style (RIS), an unsupervised framework for facial feature transfer and retrieval on real images. Recent work shows capabilities of transferring local facial features by capitalizing on the disentanglement property of the StyleGAN latent space. RIS improves existing art on the following: 1) Introducing more effective feature disentanglement to allow for challenging transfers (ie, hair, pose) that were not shown possible in SoTA methods. 2) Eliminating the need for per-image hyperparameter tuning, and for computing a catalog over a large batch of images. 3) Enabling fine-grained face retrieval using disentangled facial features (eg, eyes). To our best knowledge, this is the first work to retrieve face images at this fine level. 4) Demonstrating robust, natural editing on real images. Our qualitative and quantitative analyses show RIS achieves both high-fidelity feature transfers and accurate fine-grained retrievals on real images. We also discuss the responsible applications of RIS.



### Object Tracking and Geo-localization from Street Images
- **Arxiv ID**: http://arxiv.org/abs/2107.06257v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2107.06257v1)
- **Published**: 2021-07-13 17:32:04+00:00
- **Updated**: 2021-07-13 17:32:04+00:00
- **Authors**: Daniel Wilson, Thayer Alshaabi, Colin Van Oort, Xiaohan Zhang, Jonathan Nelson, Safwan Wshah
- **Comment**: 28 pages, 7 figures, to be submitted to Elsevier Pattern Recognition
- **Journal**: None
- **Summary**: Geo-localizing static objects from street images is challenging but also very important for road asset mapping and autonomous driving. In this paper we present a two-stage framework that detects and geolocalizes traffic signs from low frame rate street videos. Our proposed system uses a modified version of RetinaNet (GPS-RetinaNet), which predicts a positional offset for each sign relative to the camera, in addition to performing the standard classification and bounding box regression. Candidate sign detections from GPS-RetinaNet are condensed into geolocalized signs by our custom tracker, which consists of a learned metric network and a variant of the Hungarian Algorithm. Our metric network estimates the similarity between pairs of detections, then the Hungarian Algorithm matches detections across images using the similarity scores provided by the metric network. Our models were trained using an updated version of the ARTS dataset, which contains 25,544 images and 47.589 sign annotations ~\cite{arts}. The proposed dataset covers a diverse set of environments gathered from a broad selection of roads. Each annotaiton contains a sign class label, its geospatial location, an assembly label, a side of road indicator, and unique identifiers that aid in the evaluation. This dataset will support future progress in the field, and the proposed system demonstrates how to take advantage of some of the unique characteristics of a realistic geolocalization dataset.



### Scene Text recognition with Full Normalization
- **Arxiv ID**: http://arxiv.org/abs/2109.01034v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2109.01034v1)
- **Published**: 2021-07-13 17:36:30+00:00
- **Updated**: 2021-07-13 17:36:30+00:00
- **Authors**: Nathan Zachary, Gerald Carl, Russell Elijah, Hessi Roma, Robert Leer, James Amelia
- **Comment**: arXiv admin note: text overlap with arXiv:1907.09653 by other authors
- **Journal**: None
- **Summary**: Scene text recognition has made significant progress in recent years and has become an important part of the work-flow. The widespread use of mobile devices opens up wide possibilities for using OCR technologies in everyday life. However, lack of training data for new research in this area remains relevant. In this article, we present a new dataset consisting of real shots on smartphones and demonstrate the effectiveness of profile normalization in this task. In addition, the influence of various augmentations during the training of models for analyzing document images on smartphones is studied in detail. Our dataset is publicly available.



### Learning Aesthetic Layouts via Visual Guidance
- **Arxiv ID**: http://arxiv.org/abs/2107.06262v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2107.06262v1)
- **Published**: 2021-07-13 17:46:42+00:00
- **Updated**: 2021-07-13 17:46:42+00:00
- **Authors**: Qingyuan Zheng, Zhuoru Li, Adam Bargteil
- **Comment**: 17 pages
- **Journal**: None
- **Summary**: We explore computational approaches for visual guidance to aid in creating aesthetically pleasing art and graphic design. Our work complements and builds on previous work that developed models for how humans look at images. Our approach comprises three steps. First, we collected a dataset of art masterpieces and labeled the visual fixations with state-of-art vision models. Second, we clustered the visual guidance templates of the art masterpieces with unsupervised learning. Third, we developed a pipeline using generative adversarial networks to learn the principles of visual guidance and that can produce aesthetically pleasing layouts. We show that the aesthetic visual guidance principles can be learned and integrated into a high-dimensional model and can be queried by the features of graphic elements. We evaluate our approach by generating layouts on various drawings and graphic designs. Moreover, our model considers the color and structure of graphic elements when generating layouts. Consequently, we believe our tool, which generates multiple aesthetic layout options in seconds, can help artists create beautiful art and graphic designs.



### CMT: Convolutional Neural Networks Meet Vision Transformers
- **Arxiv ID**: http://arxiv.org/abs/2107.06263v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06263v3)
- **Published**: 2021-07-13 17:47:19+00:00
- **Updated**: 2022-06-14 14:05:23+00:00
- **Authors**: Jianyuan Guo, Kai Han, Han Wu, Yehui Tang, Xinghao Chen, Yunhe Wang, Chang Xu
- **Comment**: Accepted in CVPR 2022
- **Journal**: None
- **Summary**: Vision transformers have been successfully applied to image recognition tasks due to their ability to capture long-range dependencies within an image. However, there are still gaps in both performance and computational cost between transformers and existing convolutional neural networks (CNNs). In this paper, we aim to address this issue and develop a network that can outperform not only the canonical transformers, but also the high-performance convolutional models. We propose a new transformer based hybrid network by taking advantage of transformers to capture long-range dependencies, and of CNNs to model local features. Furthermore, we scale it to obtain a family of models, called CMTs, obtaining much better accuracy and efficiency than previous convolution and transformer based models. In particular, our CMT-S achieves 83.5% top-1 accuracy on ImageNet, while being 14x and 2x smaller on FLOPs than the existing DeiT and EfficientNet, respectively. The proposed CMT-S also generalizes well on CIFAR10 (99.2%), CIFAR100 (91.7%), Flowers (98.7%), and other challenging vision datasets such as COCO (44.3% mAP), with considerably less computational cost.



### Attention based CNN-LSTM Network for Pulmonary Embolism Prediction on Chest Computed Tomography Pulmonary Angiograms
- **Arxiv ID**: http://arxiv.org/abs/2107.06276v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06276v1)
- **Published**: 2021-07-13 17:58:15+00:00
- **Updated**: 2021-07-13 17:58:15+00:00
- **Authors**: Sudhir Suman, Gagandeep Singh, Nicole Sakla, Rishabh Gattu, Jeremy Green, Tej Phatak, Dimitris Samaras, Prateek Prasanna
- **Comment**: This work will be presented at MICCAI 2021
- **Journal**: None
- **Summary**: With more than 60,000 deaths annually in the United States, Pulmonary Embolism (PE) is among the most fatal cardiovascular diseases. It is caused by an artery blockage in the lung; confirming its presence is time-consuming and is prone to over-diagnosis. The utilization of automated PE detection systems is critical for diagnostic accuracy and efficiency. In this study we propose a two-stage attention-based CNN-LSTM network for predicting PE, its associated type (chronic, acute) and corresponding location (leftsided, rightsided or central) on computed tomography (CT) examinations. We trained our model on the largest available public Computed Tomography Pulmonary Angiogram PE dataset (RSNA-STR Pulmonary Embolism CT (RSPECT) Dataset, N=7279 CT studies) and tested it on an in-house curated dataset of N=106 studies. Our framework mirrors the radiologic diagnostic process via a multi-slice approach so that the accuracy and pathologic sequela of true pulmonary emboli may be meticulously assessed, enabling physicians to better appraise the morbidity of a PE when present. Our proposed method outperformed a baseline CNN classifier and a single-stage CNN-LSTM network, achieving an AUC of 0.95 on the test set for detecting the presence of PE in the study.



### Per-Pixel Classification is Not All You Need for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2107.06278v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06278v2)
- **Published**: 2021-07-13 17:59:50+00:00
- **Updated**: 2021-10-31 17:41:44+00:00
- **Authors**: Bowen Cheng, Alexander G. Schwing, Alexander Kirillov
- **Comment**: NeurIPS 2021, Spotlight. Project page:
  https://bowenc0221.github.io/maskformer
- **Journal**: None
- **Summary**: Modern approaches typically formulate semantic segmentation as a per-pixel classification task, while instance-level segmentation is handled with an alternative mask classification. Our key insight: mask classification is sufficiently general to solve both semantic- and instance-level segmentation tasks in a unified manner using the exact same model, loss, and training procedure. Following this observation, we propose MaskFormer, a simple mask classification model which predicts a set of binary masks, each associated with a single global class label prediction. Overall, the proposed mask classification-based method simplifies the landscape of effective approaches to semantic and panoptic segmentation tasks and shows excellent empirical results. In particular, we observe that MaskFormer outperforms per-pixel classification baselines when the number of classes is large. Our mask classification-based method outperforms both current state-of-the-art semantic (55.6 mIoU on ADE20K) and panoptic segmentation (52.7 PQ on COCO) models.



### Privacy Vulnerability of Split Computing to Data-Free Model Inversion Attacks
- **Arxiv ID**: http://arxiv.org/abs/2107.06304v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06304v2)
- **Published**: 2021-07-13 18:01:43+00:00
- **Updated**: 2022-10-25 00:57:29+00:00
- **Authors**: Xin Dong, Hongxu Yin, Jose M. Alvarez, Jan Kautz, Pavlo Molchanov, H. T. Kung
- **Comment**: A new data-free inversion method to reverse neural networks and get
  input from intermediate feature maps. BMVC'22
- **Journal**: None
- **Summary**: Mobile edge devices see increased demands in deep neural networks (DNNs) inference while suffering from stringent constraints in computing resources. Split computing (SC) emerges as a popular approach to the issue by executing only initial layers on devices and offloading the remaining to the cloud. Prior works usually assume that SC offers privacy benefits as only intermediate features, instead of private data, are shared from devices to the cloud. In this work, we debunk this SC-induced privacy protection by (i) presenting a novel data-free model inversion method and (ii) demonstrating sample inversion where private data from devices can still be leaked with high fidelity from the shared feature even after tens of neural network layers. We propose Divide-and-Conquer Inversion (DCI) which partitions the given deep network into multiple shallow blocks and inverts each block with an inversion method. Additionally, cycle-consistency technique is introduced by re-directing the inverted results back to the model under attack in order to better supervise the training of the inversion modules. In contrast to prior art based on generative priors and computation-intensive optimization in deriving inverted samples, DCI removes the need for real device data and generative priors, and completes inversion with a single quick forward pass over inversion modules. For the first time, we scale data-free and sample-specific inversion to deep architectures and large datasets for both discriminative and generative networks. We perform model inversion attack to ResNet and RepVGG models on ImageNet and SNGAN on CelebA and recover the original input from intermediate features more than 40 layers deep into the network.



### HDMapNet: An Online HD Map Construction and Evaluation Framework
- **Arxiv ID**: http://arxiv.org/abs/2107.06307v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2107.06307v4)
- **Published**: 2021-07-13 18:06:46+00:00
- **Updated**: 2022-03-18 08:15:56+00:00
- **Authors**: Qi Li, Yue Wang, Yilun Wang, Hang Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Constructing HD semantic maps is a central component of autonomous driving. However, traditional pipelines require a vast amount of human efforts and resources in annotating and maintaining the semantics in the map, which limits its scalability. In this paper, we introduce the problem of HD semantic map learning, which dynamically constructs the local semantics based on onboard sensor observations. Meanwhile, we introduce a semantic map learning method, dubbed HDMapNet. HDMapNet encodes image features from surrounding cameras and/or point clouds from LiDAR, and predicts vectorized map elements in the bird's-eye view. We benchmark HDMapNet on nuScenes dataset and show that in all settings, it performs better than baseline methods. Of note, our camera-LiDAR fusion-based HDMapNet outperforms existing methods by more than 50% in all metrics. In addition, we develop semantic-level and instance-level metrics to evaluate the map learning performance. Finally, we showcase our method is capable of predicting a locally consistent map. By introducing the method and metrics, we invite the community to study this novel map learning problem.



### Graphhopper: Multi-Hop Scene Graph Reasoning for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2107.06325v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06325v1)
- **Published**: 2021-07-13 18:33:04+00:00
- **Updated**: 2021-07-13 18:33:04+00:00
- **Authors**: Rajat Koner, Hang Li, Marcel Hildebrandt, Deepan Das, Volker Tresp, Stephan Günnemann
- **Comment**: arXiv admin note: text overlap with arXiv:2007.01072
- **Journal**: None
- **Summary**: Visual Question Answering (VQA) is concerned with answering free-form questions about an image. Since it requires a deep semantic and linguistic understanding of the question and the ability to associate it with various objects that are present in the image, it is an ambitious task and requires multi-modal reasoning from both computer vision and natural language processing. We propose Graphhopper, a novel method that approaches the task by integrating knowledge graph reasoning, computer vision, and natural language processing techniques. Concretely, our method is based on performing context-driven, sequential reasoning based on the scene entities and their semantic and spatial relationships. As a first step, we derive a scene graph that describes the objects in the image, as well as their attributes and their mutual relationships. Subsequently, a reinforcement learning agent is trained to autonomously navigate in a multi-hop manner over the extracted scene graph to generate reasoning paths, which are the basis for deriving answers. We conduct an experimental study on the challenging dataset GQA, based on both manually curated and automatically generated scene graphs. Our results show that we keep up with a human performance on manually curated scene graphs. Moreover, we find that Graphhopper outperforms another state-of-the-art scene graph reasoning model on both manually curated and automatically generated scene graphs by a significant margin.



### BRIMA: low-overhead BRowser-only IMage Annotation tool (Preprint)
- **Arxiv ID**: http://arxiv.org/abs/2107.06351v1
- **DOI**: 10.1109/ICIP42928.2021.9506683
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06351v1)
- **Published**: 2021-07-13 19:23:13+00:00
- **Updated**: 2021-07-13 19:23:13+00:00
- **Authors**: Tuomo Lahtinen, Hannu Turtiainen, Andrei Costin
- **Comment**: None
- **Journal**: None
- **Summary**: Image annotation and large annotated datasets are crucial parts within the Computer Vision and Artificial Intelligence fields.At the same time, it is well-known and acknowledged by the research community that the image annotation process is challenging, time-consuming and hard to scale. Therefore, the researchers and practitioners are always seeking ways to perform the annotations easier, faster, and at higher quality. Even though several widely used tools exist and the tools' landscape evolved considerably, most of the tools still require intricate technical setups and high levels of technical savviness from its operators and crowdsource contributors.   In order to address such challenges, we develop and present BRIMA -- a flexible and open-source browser extension that allows BRowser-only IMage Annotation at considerably lower overheads. Once added to the browser, it instantly allows the user to annotate images easily and efficiently directly from the browser without any installation or setup on the client-side. It also features cross-browser and cross-platform functionality thus presenting itself as a neat tool for researchers within the Computer Vision, Artificial Intelligence, and privacy-related fields.



### Real-Time Pothole Detection Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2107.06356v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.2; I.4
- **Links**: [PDF](http://arxiv.org/pdf/2107.06356v1)
- **Published**: 2021-07-13 19:36:34+00:00
- **Updated**: 2021-07-13 19:36:34+00:00
- **Authors**: Anas Al Shaghouri, Rami Alkhatib, Samir Berjaoui
- **Comment**: 10 pages, 16 figures
- **Journal**: None
- **Summary**: Roads are connecting line between different places, and used daily. Roads' periodic maintenance keeps them safe and functional. Detecting and reporting the existence of potholes to responsible departments can help in eliminating them. This study deployed and tested on different deep learning architecture to detect potholes. The images used for training were collected by cellphone mounted on the windshield of the car, in addition to many images downloaded from the internet to increase the size and variability of the database. Second, various object detection algorithms are employed and compared to detect potholes in real-time like SDD-TensorFlow, YOLOv3Darknet53 and YOLOv4Darknet53. YOLOv4 achieved the best performance with 81% recall, 85% precision and 85.39% mean Average Precision (mAP). The speed of processing was 20 frame per second. The system was able to detect potholes from a range on 100 meters away from the camera. The system can increase the safety of drivers and improve the performance of self-driving cars by detecting pothole time ahead.



### Developmental Stage Classification of Embryos Using Two-Stream Neural Network with Linear-Chain Conditional Random Field
- **Arxiv ID**: http://arxiv.org/abs/2107.06360v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06360v1)
- **Published**: 2021-07-13 19:56:01+00:00
- **Updated**: 2021-07-13 19:56:01+00:00
- **Authors**: Stanislav Lukyanenko, Won-Dong Jang, Donglai Wei, Robbert Struyven, Yoon Kim, Brian Leahy, Helen Yang, Alexander Rush, Dalit Ben-Yosef, Daniel Needleman, Hanspeter Pfister
- **Comment**: 8.5 pages, to appear in MICCAI 2021
- **Journal**: None
- **Summary**: The developmental process of embryos follows a monotonic order. An embryo can progressively cleave from one cell to multiple cells and finally transform to morula and blastocyst. For time-lapse videos of embryos, most existing developmental stage classification methods conduct per-frame predictions using an image frame at each time step. However, classification using only images suffers from overlapping between cells and imbalance between stages. Temporal information can be valuable in addressing this problem by capturing movements between neighboring frames. In this work, we propose a two-stream model for developmental stage classification. Unlike previous methods, our two-stream model accepts both temporal and image information. We develop a linear-chain conditional random field (CRF) on top of neural network features extracted from the temporal and image streams to make use of both modalities. The linear-chain CRF formulation enables tractable training of global sequential models over multiple frames while also making it possible to inject monotonic development order constraints into the learning process explicitly. We demonstrate our algorithm on two time-lapse embryo video datasets: i) mouse and ii) human embryo datasets. Our method achieves 98.1 % and 80.6 % for mouse and human embryo stage classification, respectively. Our approach will enable more profound clinical and biological studies and suggests a new direction for developmental stage classification by utilizing temporal information.



### How Much Can CLIP Benefit Vision-and-Language Tasks?
- **Arxiv ID**: http://arxiv.org/abs/2107.06383v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2107.06383v1)
- **Published**: 2021-07-13 20:48:12+00:00
- **Updated**: 2021-07-13 20:48:12+00:00
- **Authors**: Sheng Shen, Liunian Harold Li, Hao Tan, Mohit Bansal, Anna Rohrbach, Kai-Wei Chang, Zhewei Yao, Kurt Keutzer
- **Comment**: 14 pages
- **Journal**: None
- **Summary**: Most existing Vision-and-Language (V&L) models rely on pre-trained visual encoders, using a relatively small set of manually-annotated data (as compared to web-crawled data), to perceive the visual world. However, it has been observed that large-scale pretraining usually can result in better generalization performance, e.g., CLIP (Contrastive Language-Image Pre-training), trained on a massive amount of image-caption pairs, has shown a strong zero-shot capability on various vision tasks. To further study the advantage brought by CLIP, we propose to use CLIP as the visual encoder in various V&L models in two typical scenarios: 1) plugging CLIP into task-specific fine-tuning; 2) combining CLIP with V&L pre-training and transferring to downstream tasks. We show that CLIP significantly outperforms widely-used visual encoders trained with in-domain annotated data, such as BottomUp-TopDown. We achieve competitive or better results on diverse V&L tasks, while establishing new state-of-the-art results on Visual Question Answering, Visual Entailment, and V&L Navigation tasks. We release our code at https://github.com/clip-vil/CLIP-ViL.



### SurgeonAssist-Net: Towards Context-Aware Head-Mounted Display-Based Augmented Reality for Surgical Guidance
- **Arxiv ID**: http://arxiv.org/abs/2107.06397v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2107.06397v1)
- **Published**: 2021-07-13 21:12:34+00:00
- **Updated**: 2021-07-13 21:12:34+00:00
- **Authors**: Mitchell Doughty, Karan Singh, Nilesh R. Ghugre
- **Comment**: Accepted at MICCAI 2021; 11 pages, 3 figures
- **Journal**: None
- **Summary**: We present SurgeonAssist-Net: a lightweight framework making action-and-workflow-driven virtual assistance, for a set of predefined surgical tasks, accessible to commercially available optical see-through head-mounted displays (OST-HMDs). On a widely used benchmark dataset for laparoscopic surgical workflow, our implementation competes with state-of-the-art approaches in prediction accuracy for automated task recognition, and yet requires 7.4x fewer parameters, 10.2x fewer floating point operations per second (FLOPS), is 7.0x faster for inference on a CPU, and is capable of near real-time performance on the Microsoft HoloLens 2 OST-HMD. To achieve this, we make use of an efficient convolutional neural network (CNN) backbone to extract discriminative features from image data, and a low-parameter recurrent neural network (RNN) architecture to learn long-term temporal dependencies. To demonstrate the feasibility of our approach for inference on the HoloLens 2 we created a sample dataset that included video of several surgical tasks recorded from a user-centric point-of-view. After training, we deployed our model and cataloged its performance in an online simulated surgical scenario for the prediction of the current surgical task. The utility of our approach is explored in the discussion of several relevant clinical use-cases. Our code is publicly available at https://github.com/doughtmw/surgeon-assist-net.



### The Foes of Neural Network's Data Efficiency Among Unnecessary Input Dimensions
- **Arxiv ID**: http://arxiv.org/abs/2107.06409v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2107.06409v1)
- **Published**: 2021-07-13 21:52:02+00:00
- **Updated**: 2021-07-13 21:52:02+00:00
- **Authors**: Vanessa D'Amario, Sanjana Srivastava, Tomotake Sasaki, Xavier Boix
- **Comment**: None
- **Journal**: None
- **Summary**: Datasets often contain input dimensions that are unnecessary to predict the output label, e.g. background in object recognition, which lead to more trainable parameters. Deep Neural Networks (DNNs) are robust to increasing the number of parameters in the hidden layers, but it is unclear whether this holds true for the input layer. In this letter, we investigate the impact of unnecessary input dimensions on a central issue of DNNs: their data efficiency, ie. the amount of examples needed to achieve certain generalization performance. Our results show that unnecessary input dimensions that are task-unrelated substantially degrade data efficiency. This highlights the need for mechanisms that remove {task-unrelated} dimensions to enable data efficiency gains.



