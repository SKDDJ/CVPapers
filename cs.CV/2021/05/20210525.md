# Arxiv Papers in cs.CV on 2021-05-25
### SRH-Net: Stacked Recurrent Hourglass Network for Stereo Matching
- **Arxiv ID**: http://arxiv.org/abs/2105.11587v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2105.11587v1)
- **Published**: 2021-05-25 00:10:56+00:00
- **Updated**: 2021-05-25 00:10:56+00:00
- **Authors**: Hongzhi Du, Yanyan Li, Yanbiao Sun, Jigui Zhu, Federico Tombari
- **Comment**: None
- **Journal**: None
- **Summary**: The cost aggregation strategy shows a crucial role in learning-based stereo matching tasks, where 3D convolutional filters obtain state of the art but require intensive computation resources, while 2D operations need less GPU memory but are sensitive to domain shift. In this paper, we decouple the 4D cubic cost volume used by 3D convolutional filters into sequential cost maps along the direction of disparity instead of dealing with it at once by exploiting a recurrent cost aggregation strategy. Furthermore, a novel recurrent module, Stacked Recurrent Hourglass (SRH), is proposed to process each cost map. Our hourglass network is constructed based on Gated Recurrent Units (GRUs) and down/upsampling layers, which provides GRUs larger receptive fields. Then two hourglass networks are stacked together, while multi-scale information is processed by skip connections to enhance the performance of the pipeline in textureless areas. The proposed architecture is implemented in an end-to-end pipeline and evaluated on public datasets, which reduces GPU memory consumption by up to 56.1\% compared with PSMNet using stacked hourglass 3D CNNs without the degradation of accuracy. Then, we further demonstrate the scalability of the proposed method on several high-resolution pairs, while previously learned approaches often fail due to the memory constraint. The code is released at \url{https://github.com/hongzhidu/SRHNet}.



### VISITRON: Visual Semantics-Aligned Interactively Trained Object-Navigator
- **Arxiv ID**: http://arxiv.org/abs/2105.11589v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG, cs.RO, I.2.9
- **Links**: [PDF](http://arxiv.org/pdf/2105.11589v2)
- **Published**: 2021-05-25 00:21:54+00:00
- **Updated**: 2022-03-16 03:03:00+00:00
- **Authors**: Ayush Shrivastava, Karthik Gopalakrishnan, Yang Liu, Robinson Piramuthu, Gokhan Tür, Devi Parikh, Dilek Hakkani-Tür
- **Comment**: Accepted at Findings of the Annual Meeting of the Association for
  Computational Linguistics (ACL) 2022, previous version accepted at Visually
  Grounded Interaction and Language (ViGIL) Workshop at NAACL 2021
- **Journal**: None
- **Summary**: Interactive robots navigating photo-realistic environments need to be trained to effectively leverage and handle the dynamic nature of dialogue in addition to the challenges underlying vision-and-language navigation (VLN). In this paper, we present VISITRON, a multi-modal Transformer-based navigator better suited to the interactive regime inherent to Cooperative Vision-and-Dialog Navigation (CVDN). VISITRON is trained to: i) identify and associate object-level concepts and semantics between the environment and dialogue history, ii) identify when to interact vs. navigate via imitation learning of a binary classification head. We perform extensive pre-training and fine-tuning ablations with VISITRON to gain empirical insights and improve performance on CVDN. VISITRON's ability to identify when to interact leads to a natural generalization of the game-play mode introduced by Roman et al. (arXiv:2005.00728) for enabling the use of such models in different environments. VISITRON is competitive with models on the static CVDN leaderboard and attains state-of-the-art performance on the Success weighted by Path Length (SPL) metric.



### SiamMOT: Siamese Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/2105.11595v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11595v1)
- **Published**: 2021-05-25 01:09:26+00:00
- **Updated**: 2021-05-25 01:09:26+00:00
- **Authors**: Bing Shuai, Andrew Berneshawi, Xinyu Li, Davide Modolo, Joseph Tighe
- **Comment**: None
- **Journal**: CVPR2021
- **Summary**: In this paper, we focus on improving online multi-object tracking (MOT). In particular, we introduce a region-based Siamese Multi-Object Tracking network, which we name SiamMOT. SiamMOT includes a motion model that estimates the instance's movement between two frames such that detected instances are associated. To explore how the motion modelling affects its tracking capability, we present two variants of Siamese tracker, one that implicitly models motion and one that models it explicitly. We carry out extensive quantitative experiments on three different MOT datasets: MOT17, TAO-person and Caltech Roadside Pedestrians, showing the importance of motion modelling for MOT and the ability of SiamMOT to substantially outperform the state-of-the-art. Finally, SiamMOT also outperforms the winners of ACM MM'20 HiEve Grand Challenge on HiEve dataset. Moreover, SiamMOT is efficient, and it runs at 17 FPS for 720P videos on a single modern GPU. Codes are available in \url{https://github.com/amazon-research/siam-mot}.



### Multi-view 3D Reconstruction of a Texture-less Smooth Surface of Unknown Generic Reflectance
- **Arxiv ID**: http://arxiv.org/abs/2105.11599v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2105.11599v1)
- **Published**: 2021-05-25 01:28:54+00:00
- **Updated**: 2021-05-25 01:28:54+00:00
- **Authors**: Ziang Cheng, Hongdong Li, Yuta Asano, Yinqiang Zheng, Imari Sato
- **Comment**: Accepted to CVPR2021
- **Journal**: None
- **Summary**: Recovering the 3D geometry of a purely texture-less object with generally unknown surface reflectance (e.g. non-Lambertian) is regarded as a challenging task in multi-view reconstruction. The major obstacle revolves around establishing cross-view correspondences where photometric constancy is violated. This paper proposes a simple and practical solution to overcome this challenge based on a co-located camera-light scanner device. Unlike existing solutions, we do not explicitly solve for correspondence. Instead, we argue the problem is generally well-posed by multi-view geometrical and photometric constraints, and can be solved from a small number of input views. We formulate the reconstruction task as a joint energy minimization over the surface geometry and reflectance. Despite this energy is highly non-convex, we develop an optimization algorithm that robustly recovers globally optimal shape and reflectance even from a random initialization. Extensive experiments on both simulated and real data have validated our method, and possible future extensions are discussed.



### TransLoc3D : Point Cloud based Large-scale Place Recognition using Adaptive Receptive Fields
- **Arxiv ID**: http://arxiv.org/abs/2105.11605v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11605v3)
- **Published**: 2021-05-25 01:54:31+00:00
- **Updated**: 2022-10-12 09:22:30+00:00
- **Authors**: Tian-Xing Xu, Yuan-Chen Guo, Zhiqiang Li, Ge Yu, Yu-Kun Lai, Song-Hai Zhang
- **Comment**: Appeared in Computational Visual Media 2022, poster. Communications
  in Information and Systems. Accepted
- **Journal**: None
- **Summary**: Place recognition plays an essential role in the field of autonomous driving and robot navigation. Point cloud based methods mainly focus on extracting global descriptors from local features of point clouds. Despite having achieved promising results, existing solutions neglect the following aspects, which may cause performance degradation: (1) huge size difference between objects in outdoor scenes; (2) moving objects that are unrelated to place recognition; (3) long-range contextual information. We illustrate that the above aspects bring challenges to extracting discriminative global descriptors. To mitigate these problems, we propose a novel method named TransLoc3D, utilizing adaptive receptive fields with a point-wise reweighting scheme to handle objects of different sizes while suppressing noises, and an external transformer to capture long-range feature dependencies. As opposed to existing architectures which adopt fixed and limited receptive fields, our method benefits from size-adaptive receptive fields as well as global contextual information, and outperforms current state-of-the-arts with significant improvements on popular datasets.



### Centimeter-Wave Free-Space Time-of-Flight Imaging
- **Arxiv ID**: http://arxiv.org/abs/2105.11606v1
- **DOI**: None
- **Categories**: **cs.CV**, physics.optics
- **Links**: [PDF](http://arxiv.org/pdf/2105.11606v1)
- **Published**: 2021-05-25 01:57:10+00:00
- **Updated**: 2021-05-25 01:57:10+00:00
- **Authors**: Seung-Hwan Baek, Noah Walsh, Ilya Chugunov, Zheng Shi, Felix Heide
- **Comment**: None
- **Journal**: None
- **Summary**: Depth cameras are emerging as a cornerstone modality with diverse applications that directly or indirectly rely on measured depth, including personal devices, robotics, and self-driving vehicles. Although time-of-flight (ToF) methods have fueled these applications, the precision and robustness of ToF methods is limited by relying on photon time-tagging or modulation after photo-conversion. Successful optical modulation approaches have been restricted fiber-coupled modulation with large coupling losses or interferometric modulation with sub-cm range, and the precision gap between interferometric methods and ToF methods is more than three orders of magnitudes. In this work, we close this gap and propose a computational imaging method for all-optical free-space correlation before photo-conversion that achieves micron-scale depth resolution with robustness to surface reflectance and ambient light with conventional silicon intensity sensors. To this end, we solve two technical challenges: modulating at GHz rates and computational phase unwrapping. We propose an imaging approach with resonant polarization modulators and devise a novel optical dual-pass frequency-doubling which achieves high modulation contrast at more than 10GHz. At the same time, centimeter-wave modulation together with a small modulation bandwidth render existing phase unwrapping methods ineffective. We tackle this problem with a neural phase unwrapping method that exploits that adjacent wraps are often highly correlated. We validate the proposed method in simulation and experimentally, where it achieves micron-scale depth precision. We demonstrate precise depth sensing independently of surface texture and ambient light and compare against existing analog demodulation methods, which we outperform across all tested scenarios.



### Polarimetric Spatio-Temporal Light Transport Probing
- **Arxiv ID**: http://arxiv.org/abs/2105.11609v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11609v2)
- **Published**: 2021-05-25 02:16:07+00:00
- **Updated**: 2021-09-15 13:52:02+00:00
- **Authors**: Seung-Hwan Baek, Felix Heide
- **Comment**: None
- **Journal**: None
- **Summary**: Light emitted from a source into a scene can undergo complex interactions with scene surfaces of different material types before being reflected. During this transport, every surface reflection is encoded in the properties of the photons that reach the detector, including time, direction, intensity, wavelength and polarization. Conventional imaging systems capture intensity by integrating over all other dimensions of the light, hiding this rich scene information. Existing methods are capable of untangling these measurements into their spatial and temporal dimensions, fueling geometric scene understanding tasks. However, examining material properties jointly with geometric properties is an open challenge that could enable unprecedented capabilities beyond geometric scene understanding, allowing for material-dependent scene understanding and imaging through complex transport. In this work, we close this gap, and propose a computational light transport imaging method that captures the spatially- and temporally-resolved complete polarimetric response of a scene. Our method hinges on a 7D tensor theory of light transport. We discover low-rank structure in the polarimetric tensor dimension and propose a data-driven rotating ellipsometry method that learns to exploit redundancy of polarimetric structure. We instantiate our theory with two prototypes: spatio-polarimetric imaging and coaxial temporal-polarimetric imaging. This allows us, for the first time, to decompose scene light transport into temporal, spatial, and complete polarimetric dimensions that unveil scene properties hidden to conventional methods. We validate the applicability of our method on diverse tasks, including shape reconstruction with subsurface scattering, seeing through scattering media, untangling multi-bounce light transport, breaking metamerism, and decomposition of crystals.



### Unsupervised Scale-consistent Depth Learning from Video
- **Arxiv ID**: http://arxiv.org/abs/2105.11610v1
- **DOI**: 10.1007/s11263-021-01484-6
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11610v1)
- **Published**: 2021-05-25 02:17:56+00:00
- **Updated**: 2021-05-25 02:17:56+00:00
- **Authors**: Jia-Wang Bian, Huangying Zhan, Naiyan Wang, Zhichao Li, Le Zhang, Chunhua Shen, Ming-Ming Cheng, Ian Reid
- **Comment**: Accept to IJCV. The source code is available at
  https://github.com/JiawangBian/SC-SfMLearner-Release
- **Journal**: International Journal of Computer Vision, 2021
- **Summary**: We propose a monocular depth estimator SC-Depth, which requires only unlabelled videos for training and enables the scale-consistent prediction at inference time. Our contributions include: (i) we propose a geometry consistency loss, which penalizes the inconsistency of predicted depths between adjacent views; (ii) we propose a self-discovered mask to automatically localize moving objects that violate the underlying static scene assumption and cause noisy signals during training; (iii) we demonstrate the efficacy of each component with a detailed ablation study and show high-quality depth estimation results in both KITTI and NYUv2 datasets. Moreover, thanks to the capability of scale-consistent prediction, we show that our monocular-trained deep networks are readily integrated into the ORB-SLAM2 system for more robust and accurate tracking. The proposed hybrid Pseudo-RGBD SLAM shows compelling results in KITTI, and it generalizes well to the KAIST dataset without additional training. Finally, we provide several demos for qualitative evaluation.



### Boosting-GNN: Boosting Algorithm for Graph Networks on Imbalanced Node Classification
- **Arxiv ID**: http://arxiv.org/abs/2105.11625v2
- **DOI**: 10.3389/fnbot.2021.775688
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11625v2)
- **Published**: 2021-05-25 02:43:31+00:00
- **Updated**: 2022-05-08 01:16:54+00:00
- **Authors**: S. Shi, Kai Qiao, Shuai Yang, L. Wang, J. Chen, Bin Yan
- **Comment**: 19 pages, 6 figures published on Frontiers in Neurorobotics
- **Journal**: Frontiers in Neurorobotics, 15 (2021)
- **Summary**: The Graph Neural Network (GNN) has been widely used for graph data representation. However, the existing researches only consider the ideal balanced dataset, and the imbalanced dataset is rarely considered. Traditional methods such as resampling, reweighting, and synthetic samples that deal with imbalanced datasets are no longer applicable in GNN. This paper proposes an ensemble model called Boosting-GNN, which uses GNNs as the base classifiers during boosting. In Boosting-GNN, higher weights are set for the training samples that are not correctly classified by the previous classifier, thus achieving higher classification accuracy and better reliability. Besides, transfer learning is used to reduce computational cost and increase fitting ability. Experimental results indicate that the proposed Boosting-GNN model achieves better performance than GCN, GraphSAGE, GAT, SGC, N-GCN, and most advanced reweighting and resampling methods on synthetic imbalanced datasets, with an average performance improvement of 4.5%



### TIPCB: A Simple but Effective Part-based Convolutional Baseline for Text-based Person Search
- **Arxiv ID**: http://arxiv.org/abs/2105.11628v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11628v1)
- **Published**: 2021-05-25 03:00:21+00:00
- **Updated**: 2021-05-25 03:00:21+00:00
- **Authors**: Yuhao Chen, Guoqing Zhang, Yujiang Lu, Zhenxing Wang, Yuhui Zheng, Ruili Wang
- **Comment**: 27 pages
- **Journal**: None
- **Summary**: Text-based person search is a sub-task in the field of image retrieval, which aims to retrieve target person images according to a given textual description. The significant feature gap between two modalities makes this task very challenging. Many existing methods attempt to utilize local alignment to address this problem in the fine-grained level. However, most relevant methods introduce additional models or complicated training and evaluation strategies, which are hard to use in realistic scenarios. In order to facilitate the practical application, we propose a simple but effective end-to-end learning framework for text-based person search named TIPCB (i.e., Text-Image Part-based Convolutional Baseline). Firstly, a novel dual-path local alignment network structure is proposed to extract visual and textual local representations, in which images are segmented horizontally and texts are aligned adaptively. Then, we propose a multi-stage cross-modal matching strategy, which eliminates the modality gap from three feature levels, including low level, local level and global level. Extensive experiments are conducted on the widely-used benchmark dataset (CUHK-PEDES) and verify that our method outperforms the state-of-the-art methods by 3.69%, 2.95% and 2.31% in terms of Top-1, Top-5 and Top-10. Our code has been released in https://github.com/OrangeYHChen/TIPCB.



### FILTRA: Rethinking Steerable CNN by Filter Transform
- **Arxiv ID**: http://arxiv.org/abs/2105.11636v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11636v2)
- **Published**: 2021-05-25 03:32:34+00:00
- **Updated**: 2022-02-15 05:02:16+00:00
- **Authors**: Bo Li, Qili Wang, Gim Hee Lee
- **Comment**: ICML 2021
- **Journal**: None
- **Summary**: Steerable CNN imposes the prior knowledge of transformation invariance or equivariance in the network architecture to enhance the the network robustness on geometry transformation of data and reduce overfitting. It has been an intuitive and widely used technique to construct a steerable filter by augmenting a filter with its transformed copies in the past decades, which is named as filter transform in this paper. Recently, the problem of steerable CNN has been studied from aspect of group representation theory, which reveals the function space structure of a steerable kernel function. However, it is not yet clear on how this theory is related to the filter transform technique. In this paper, we show that kernel constructed by filter transform can also be interpreted in the group representation theory. This interpretation help complete the puzzle of steerable CNN theory and provides a novel and simple approach to implement steerable convolution operators. Experiments are executed on multiple datasets to verify the feasibility of the proposed approach.



### Feature Space Targeted Attacks by Statistic Alignment
- **Arxiv ID**: http://arxiv.org/abs/2105.11645v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11645v2)
- **Published**: 2021-05-25 03:46:39+00:00
- **Updated**: 2021-07-10 02:27:55+00:00
- **Authors**: Lianli Gao, Yaya Cheng, Qilong Zhang, Xing Xu, Jingkuan Song
- **Comment**: None
- **Journal**: None
- **Summary**: By adding human-imperceptible perturbations to images, DNNs can be easily fooled. As one of the mainstream methods, feature space targeted attacks perturb images by modulating their intermediate feature maps, for the discrepancy between the intermediate source and target features is minimized. However, the current choice of pixel-wise Euclidean Distance to measure the discrepancy is questionable because it unreasonably imposes a spatial-consistency constraint on the source and target features. Intuitively, an image can be categorized as "cat" no matter the cat is on the left or right of the image. To address this issue, we propose to measure this discrepancy using statistic alignment. Specifically, we design two novel approaches called Pair-wise Alignment Attack and Global-wise Alignment Attack, which attempt to measure similarities between feature maps by high-order statistics with translation invariance. Furthermore, we systematically analyze the layer-wise transferability with varied difficulties to obtain highly reliable attacks. Extensive experiments verify the effectiveness of our proposed method, and it outperforms the state-of-the-art algorithms by a large margin. Our code is publicly available at https://github.com/yaya-cheng/PAA-GAA.



### On Enhancing Ground Surface Detection from Sparse Lidar Point Cloud
- **Arxiv ID**: http://arxiv.org/abs/2105.11649v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11649v1)
- **Published**: 2021-05-25 03:58:18+00:00
- **Updated**: 2021-05-25 03:58:18+00:00
- **Authors**: Bo Li
- **Comment**: IROS 2019
- **Journal**: None
- **Summary**: Ground surface detection in point cloud is widely used as a key module in autonomous driving systems. Different from previous approaches which are mostly developed for lidars with high beam resolution, e.g. Velodyne HDL-64, this paper proposes ground detection techniques applicable to much sparser point cloud captured by lidars with low beam resolution, e.g. Velodyne VLP-16. The approach is based on the RANSAC scheme of plane fitting. Inlier verification for plane hypotheses is enhanced by exploiting the point-wise tangent, which is a local feature available to compute regardless of the density of lidar beams. Ground surface which is not perfectly planar is fitted by multiple (specifically 4 in our implementation) disjoint plane regions. By assuming these plane regions to be rectanglar and exploiting the integral image technique, our approach approximately finds the optimal region partition and plane hypotheses under the RANSAC scheme with real-time computational complexity.



### Fast and Accurate Scene Parsing via Bi-direction Alignment Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.11651v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11651v1)
- **Published**: 2021-05-25 04:04:00+00:00
- **Updated**: 2021-05-25 04:04:00+00:00
- **Authors**: Yanran Wu, Xiangtai Li, Chen Shi, Yunhai Tong, Yang Hua, Tao Song, Ruhui Ma, Haibing Guan
- **Comment**: accepted by ICIP-2021
- **Journal**: None
- **Summary**: In this paper, we propose an effective method for fast and accurate scene parsing called Bidirectional Alignment Network (BiAlignNet). Previously, one representative work BiSeNet~\cite{bisenet} uses two different paths (Context Path and Spatial Path) to achieve balanced learning of semantics and details, respectively. However, the relationship between the two paths is not well explored. We argue that both paths can benefit each other in a complementary way. Motivated by this, we propose a novel network by aligning two-path information into each other through a learned flow field. To avoid the noise and semantic gaps, we introduce a Gated Flow Alignment Module to align both features in a bidirectional way. Moreover, to make the Spatial Path learn more detailed information, we present an edge-guided hard pixel mining loss to supervise the aligned learning process. Our method achieves 80.1\% and 78.5\% mIoU in validation and test set of Cityscapes while running at 30 FPS with full resolution inputs. Code and models will be available at \url{https://github.com/jojacola/BiAlignNet}.



### Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep Spiking Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.11654v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11654v1)
- **Published**: 2021-05-25 04:15:06+00:00
- **Updated**: 2021-05-25 04:15:06+00:00
- **Authors**: Jianhao Ding, Zhaofei Yu, Yonghong Tian, Tiejun Huang
- **Comment**: 9 pages, 7 figures, 2 tables. To appear in the 30th International
  Joint Conference on Artificial Intelligence (IJCAI 2021)
- **Journal**: None
- **Summary**: Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural networks, have attracted great attentions from researchers and industry. The most efficient way to train deep SNNs is through ANN-SNN conversion. However, the conversion usually suffers from accuracy loss and long inference time, which impede the practical application of SNN. In this paper, we theoretically analyze ANN-SNN conversion and derive sufficient conditions of the optimal conversion. To better correlate ANN-SNN and get greater accuracy, we propose Rate Norm Layer to replace the ReLU activation function in source ANN training, enabling direct conversion from a trained ANN to an SNN. Moreover, we propose an optimal fit curve to quantify the fit between the activation value of source ANN and the actual firing rate of target SNN. We show that the inference time can be reduced by optimizing the upper bound of the fit curve in the revised ANN to achieve fast inference. Our theory can explain the existing work on fast reasoning and get better results. The experimental results show that the proposed method achieves near loss less conversion with VGG-16, PreActResNet-18, and deeper structures. Moreover, it can reach 8.6x faster reasoning performance under 0.265x energy consumption of the typical method. The code is available at https://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.



### Dynamic Dual Sampling Module for Fine-Grained Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2105.11657v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11657v1)
- **Published**: 2021-05-25 04:25:47+00:00
- **Updated**: 2021-05-25 04:25:47+00:00
- **Authors**: Chen Shi, Xiangtai Li, Yanran Wu, Yunhai Tong, Yi Xu
- **Comment**: accepted by ICIP-2021
- **Journal**: None
- **Summary**: Representation of semantic context and local details is the essential issue for building modern semantic segmentation models. However, the interrelationship between semantic context and local details is not well explored in previous works. In this paper, we propose a Dynamic Dual Sampling Module (DDSM) to conduct dynamic affinity modeling and propagate semantic context to local details, which yields a more discriminative representation. Specifically, a dynamic sampling strategy is used to sparsely sample representative pixels and channels in the higher layer, forming adaptive compact support for each pixel and channel in the lower layer. The sampled features with high semantics are aggregated according to the affinities and then propagated to detailed lower-layer features, leading to a fine-grained segmentation result with well-preserved boundaries. Experiment results on both Cityscapes and Camvid datasets validate the effectiveness and efficiency of the proposed approach. Code and models will be available at \url{x3https://github.com/Fantasticarl/DDSM}.



### BoundarySqueeze: Image Segmentation as Boundary Squeezing
- **Arxiv ID**: http://arxiv.org/abs/2105.11668v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11668v3)
- **Published**: 2021-05-25 04:58:51+00:00
- **Updated**: 2021-12-14 05:39:02+00:00
- **Authors**: Hao He, Xiangtai Li, Yibo Yang, Guangliang Cheng, Yunhai Tong, Lubin Weng, Zhouchen Lin, Shiming Xiang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a novel method for high-quality image segmentation of both objects and scenes. Inspired by the dilation and erosion operations in morphological image processing techniques, the pixel-level image segmentation problems are treated as squeezing object boundaries. From this perspective, a novel and efficient \textbf{Boundary Squeeze} module is proposed. This module is used to squeeze the object boundary from both inner and outer directions, which contributes to precise mask representation. A bi-directionally flow-based warping process is proposed to generate such squeezed feature representation, and two specific loss signals are designed to supervise the squeezing process. The Boundary Squeeze module can be easily applied to both instance and semantic segmentation tasks as a plug-and-play module by building on top of some existing methods. Moreover, the proposed module is light-weighted, and thus has potential for practical usage. Experiment results show that our simple yet effective design can produce high-quality results on several different datasets. Besides, several other metrics on the boundary are used to prove the effectiveness of our method over previous work. Our approach yields significant improvement on challenging COCO and Cityscapes datasets for both instance and semantic segmentation, and outperforms previous state-of-the-art PointRend in both accuracy and speed under the same setting. Codes and models will be published at \url{https://github.com/lxtGH/BSSeg}.



### ViBERTgrid: A Jointly Trained Multi-Modal 2D Document Representation for Key Information Extraction from Documents
- **Arxiv ID**: http://arxiv.org/abs/2105.11672v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11672v1)
- **Published**: 2021-05-25 05:12:08+00:00
- **Updated**: 2021-05-25 05:12:08+00:00
- **Authors**: Weihong Lin, Qifang Gao, Lei Sun, Zhuoyao Zhong, Kai Hu, Qin Ren, Qiang Huo
- **Comment**: To be published at ICDAR 2021
- **Journal**: None
- **Summary**: Recent grid-based document representations like BERTgrid allow the simultaneous encoding of the textual and layout information of a document in a 2D feature map so that state-of-the-art image segmentation and/or object detection models can be straightforwardly leveraged to extract key information from documents. However, such methods have not achieved comparable performance to state-of-the-art sequence- and graph-based methods such as LayoutLM and PICK yet. In this paper, we propose a new multi-modal backbone network by concatenating a BERTgrid to an intermediate layer of a CNN model, where the input of CNN is a document image and the BERTgrid is a grid of word embeddings, to generate a more powerful grid-based document representation, named ViBERTgrid. Unlike BERTgrid, the parameters of BERT and CNN in our multimodal backbone network are trained jointly. Our experimental results demonstrate that this joint training strategy improves significantly the representation ability of ViBERTgrid. Consequently, our ViBERTgrid-based key information extraction approach has achieved state-of-the-art performance on real-world datasets.



### Towards Compact Single Image Super-Resolution via Contrastive Self-distillation
- **Arxiv ID**: http://arxiv.org/abs/2105.11683v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11683v1)
- **Published**: 2021-05-25 05:44:11+00:00
- **Updated**: 2021-05-25 05:44:11+00:00
- **Authors**: Yanbo Wang, Shaohui Lin, Yanyun Qu, Haiyan Wu, Zhizhong Zhang, Yuan Xie, Angela Yao
- **Comment**: Accepted by IJCAI-21
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) are highly successful for super-resolution (SR) but often require sophisticated architectures with heavy memory cost and computational overhead, significantly restricts their practical deployments on resource-limited devices. In this paper, we proposed a novel contrastive self-distillation (CSD) framework to simultaneously compress and accelerate various off-the-shelf SR models. In particular, a channel-splitting super-resolution network can first be constructed from a target teacher network as a compact student network. Then, we propose a novel contrastive loss to improve the quality of SR images and PSNR/SSIM via explicit knowledge transfer. Extensive experiments demonstrate that the proposed CSD scheme effectively compresses and accelerates several standard SR models such as EDSR, RCAN and CARN. Code is available at https://github.com/Booooooooooo/CSD.



### A Geometry-Informed Deep Learning Framework for Ultra-Sparse 3D Tomographic Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2105.11692v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11692v1)
- **Published**: 2021-05-25 06:20:03+00:00
- **Updated**: 2021-05-25 06:20:03+00:00
- **Authors**: Liyue Shen, Wei Zhao, Dante Capaldi, John Pauly, Lei Xing
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning affords enormous opportunities to augment the armamentarium of biomedical imaging, albeit its design and implementation have potential flaws. Fundamentally, most deep learning models are driven entirely by data without consideration of any prior knowledge, which dramatically increases the complexity of neural networks and limits the application scope and model generalizability. Here we establish a geometry-informed deep learning framework for ultra-sparse 3D tomographic image reconstruction. We introduce a novel mechanism for integrating geometric priors of the imaging system. We demonstrate that the seamless inclusion of known priors is essential to enhance the performance of 3D volumetric computed tomography imaging with ultra-sparse sampling. The study opens new avenues for data-driven biomedical imaging and promises to provide substantially improved imaging tools for various clinical imaging and image-guided interventions.



### FNAS: Uncertainty-Aware Fast Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2105.11694v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11694v3)
- **Published**: 2021-05-25 06:32:52+00:00
- **Updated**: 2021-05-27 07:53:59+00:00
- **Authors**: Jihao Liu, Ming Zhang, Yangting Sun, Boxiao Liu, Guanglu Song, Yu Liu, Hongsheng Li
- **Comment**: None
- **Journal**: None
- **Summary**: Reinforcement learning (RL)-based neural architecture search (NAS) generally guarantees better convergence yet suffers from the requirement of huge computational resources compared with gradient-based approaches, due to the rollout bottleneck -- exhaustive training for each sampled generation on proxy tasks. In this paper, we propose a general pipeline to accelerate the convergence of the rollout process as well as the RL process in NAS. It is motivated by the interesting observation that both the architecture and the parameter knowledge can be transferred between different experiments and even different tasks. We first introduce an uncertainty-aware critic (value function) in Proximal Policy Optimization (PPO) to utilize the architecture knowledge in previous experiments, which stabilizes the training process and reduces the searching time by 4 times. Further, an architecture knowledge pool together with a block similarity function is proposed to utilize parameter knowledge and reduces the searching time by 2 times. It is the first to introduce block-level weight sharing in RLbased NAS. The block similarity function guarantees a 100% hitting ratio with strict fairness. Besides, we show that a simply designed off-policy correction factor used in "replay buffer" in RL optimization can further reduce half of the searching time. Experiments on the Mobile Neural Architecture Search (MNAS) search space show the proposed Fast Neural Architecture Search (FNAS) accelerates standard RL-based NAS process by ~10x (e.g. ~256 2x2 TPUv2 x days / 20,000 GPU x hour -> 2,000 GPU x hour for MNAS), and guarantees better performance on various vision tasks.



### SBEVNet: End-to-End Deep Stereo Layout Estimation
- **Arxiv ID**: http://arxiv.org/abs/2105.11705v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11705v2)
- **Published**: 2021-05-25 07:10:30+00:00
- **Updated**: 2021-10-17 21:12:07+00:00
- **Authors**: Divam Gupta, Wei Pu, Trenton Tabor, Jeff Schneider
- **Comment**: WACV 2022
- **Journal**: None
- **Summary**: Accurate layout estimation is crucial for planning and navigation in robotics applications, such as self-driving. In this paper, we introduce the Stereo Bird's Eye ViewNetwork (SBEVNet), a novel supervised end-to-end framework for estimation of bird's eye view layout from a pair of stereo images. Although our network reuses some of the building blocks from the state-of-the-art deep learning networks for disparity estimation, we show that explicit depth estimation is neither sufficient nor necessary. Instead, the learning of a good internal bird's eye view feature representation is effective for layout estimation. Specifically, we first generate a disparity feature volume using the features of the stereo images and then project it to the bird's eye view coordinates. This gives us coarse-grained information about the scene structure. We also apply inverse perspective mapping (IPM) to map the input images and their features to the bird's eye view. This gives us fine-grained texture information. Concatenating IPM features with the projected feature volume creates a rich bird's eye view representation which is useful for spatial reasoning. We use this representation to estimate the BEV semantic map. Additionally, we show that using the IPM features as a supervisory signal for stereo features can give an improvement in performance. We demonstrate our approach on two datasets:the KITTI dataset and a synthetically generated dataset from the CARLA simulator. For both of these datasets, we establish state-of-the-art performance compared to baseline techniques.



### High-Frequency aware Perceptual Image Enhancement
- **Arxiv ID**: http://arxiv.org/abs/2105.11711v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11711v1)
- **Published**: 2021-05-25 07:33:14+00:00
- **Updated**: 2021-05-25 07:33:14+00:00
- **Authors**: Hyungmin Roh, Myungjoo Kang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a novel deep neural network suitable for multi-scale analysis and propose efficient model-agnostic methods that help the network extract information from high-frequency domains to reconstruct clearer images. Our model can be applied to multi-scale image enhancement problems including denoising, deblurring and single image super-resolution. Experiments on SIDD, Flickr2K, DIV2K, and REDS datasets show that our method achieves state-of-the-art performance on each task. Furthermore, we show that our model can overcome the over-smoothing problem commonly observed in existing PSNR-oriented methods and generate more natural high-resolution images by applying adversarial training.



### Improving Few-shot Learning with Weakly-supervised Object Localization
- **Arxiv ID**: http://arxiv.org/abs/2105.11715v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.10
- **Links**: [PDF](http://arxiv.org/pdf/2105.11715v1)
- **Published**: 2021-05-25 07:39:32+00:00
- **Updated**: 2021-05-25 07:39:32+00:00
- **Authors**: Inyong Koo, Minki Jeong, Changick Kim
- **Comment**: 5 pages, 4 figures
- **Journal**: None
- **Summary**: Few-shot learning often involves metric learning-based classifiers, which predict the image label by comparing the distance between the extracted feature vector and class representations. However, applying global pooling in the backend of the feature extractor may not produce an embedding that correctly focuses on the class object. In this work, we propose a novel framework that generates class representations by extracting features from class-relevant regions of the images. Given only a few exemplary images with image-level labels, our framework first localizes the class objects by spatially decomposing the similarity between the images and their class prototypes. Then, enhanced class representations are achieved from the localization results. We also propose a loss function to enhance distinctions of the refined features. Our method outperforms the baseline few-shot model in miniImageNet and tieredImageNet benchmarks.



### Deep High-Resolution Representation Learning for Cross-Resolution Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/2105.11722v1
- **DOI**: 10.1109/TIP.2021.3120054
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11722v1)
- **Published**: 2021-05-25 07:45:38+00:00
- **Updated**: 2021-05-25 07:45:38+00:00
- **Authors**: Guoqing Zhang, Yu Ge, Zhicheng Dong, Hao Wang, Yuhui Zheng, Shengyong Chen
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: Person re-identification (re-ID) tackles the problem of matching person images with the same identity from different cameras. In practical applications, due to the differences in camera performance and distance between cameras and persons of interest, captured person images usually have various resolutions. We name this problem as Cross-Resolution Person Re-identification which brings a great challenge for matching correctly. In this paper, we propose a Deep High-Resolution Pseudo-Siamese Framework (PS-HRNet) to solve the above problem. Specifically, in order to restore the resolution of low-resolution images and make reasonable use of different channel information of feature maps, we introduce and innovate VDSR module with channel attention (CA) mechanism, named as VDSR-CA. Then we reform the HRNet by designing a novel representation head to extract discriminating features, named as HRNet-ReID. In addition, a pseudo-siamese framework is constructed to reduce the difference of feature distributions between low-resolution images and high-resolution images. The experimental results on five cross-resolution person datasets verify the effectiveness of our proposed approach. Compared with the state-of-the-art methods, our proposed PS-HRNet improves 3.4\%, 6.2\%, 2.5\%,1.1\% and 4.2\% at Rank-1 on MLR-Market-1501, MLR-CUHK03, MLR-VIPeR, MLR-DukeMTMC-reID, and CAVIAR datasets, respectively. Our code is available at \url{https://github.com/zhguoqing}.



### Writing by Memorizing: Hierarchical Retrieval-based Medical Report Generation
- **Arxiv ID**: http://arxiv.org/abs/2106.06471v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/2106.06471v1)
- **Published**: 2021-05-25 07:47:23+00:00
- **Updated**: 2021-05-25 07:47:23+00:00
- **Authors**: Xingyi Yang, Muchao Ye, Quanzeng You, Fenglong Ma
- **Comment**: Accepted by ACL 2021, Camera-ready version
- **Journal**: None
- **Summary**: Medical report generation is one of the most challenging tasks in medical image analysis. Although existing approaches have achieved promising results, they either require a predefined template database in order to retrieve sentences or ignore the hierarchical nature of medical report generation. To address these issues, we propose MedWriter that incorporates a novel hierarchical retrieval mechanism to automatically extract both report and sentence-level templates for clinically accurate report generation. MedWriter first employs the Visual-Language Retrieval~(VLR) module to retrieve the most relevant reports for the given images. To guarantee the logical coherence between sentences, the Language-Language Retrieval~(LLR) module is introduced to retrieve relevant sentences based on the previous generated description. At last, a language decoder fuses image features and features from retrieved reports and sentences to generate meaningful medical reports. We verified the effectiveness of our model by automatic evaluation and human evaluation on two datasets, i.e., Open-I and MIMIC-CXR.



### ST-HOI: A Spatial-Temporal Baseline for Human-Object Interaction Detection in Videos
- **Arxiv ID**: http://arxiv.org/abs/2105.11731v2
- **DOI**: 10.1145/3463944.3469097
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11731v2)
- **Published**: 2021-05-25 07:54:35+00:00
- **Updated**: 2021-06-24 09:10:17+00:00
- **Authors**: Meng-Jiun Chiou, Chun-Yu Liao, Li-Wei Wang, Roger Zimmermann, Jiashi Feng
- **Comment**: Accepted at ACM ICMR'21 Workshop on Intelligent Cross-Data Analysis
  and Retrieval. The dataset and source code are available at
  https://github.com/coldmanck/VidHOI
- **Journal**: None
- **Summary**: Detecting human-object interactions (HOI) is an important step toward a comprehensive visual understanding of machines. While detecting non-temporal HOIs (e.g., sitting on a chair) from static images is feasible, it is unlikely even for humans to guess temporal-related HOIs (e.g., opening/closing a door) from a single video frame, where the neighboring frames play an essential role. However, conventional HOI methods operating on only static images have been used to predict temporal-related interactions, which is essentially guessing without temporal contexts and may lead to sub-optimal performance. In this paper, we bridge this gap by detecting video-based HOIs with explicit temporal information. We first show that a naive temporal-aware variant of a common action detection baseline does not work on video-based HOIs due to a feature-inconsistency issue. We then propose a simple yet effective architecture named Spatial-Temporal HOI Detection (ST-HOI) utilizing temporal information such as human and object trajectories, correctly-localized visual features, and spatial-temporal masking pose features. We construct a new video HOI benchmark dubbed VidHOI where our proposed approach serves as a solid baseline.



### Dense Regression Activation Maps For Lesion Segmentation in CT scans of COVID-19 patients
- **Arxiv ID**: http://arxiv.org/abs/2105.11748v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11748v2)
- **Published**: 2021-05-25 08:29:35+00:00
- **Updated**: 2021-11-18 21:01:13+00:00
- **Authors**: Weiyi Xie, Colin Jacobs, Jean-Paul Charbonnier, Bram van Ginneken
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic lesion segmentation on thoracic CT enables rapid quantitative analysis of lung involvement in COVID-19 infections. However, obtaining a large amount of voxel-level annotations for training segmentation networks is prohibitively expensive. Therefore, we propose a weakly-supervised segmentation method based on dense regression activation maps (dRAMs). Most weakly-supervised segmentation approaches exploit class activation maps (CAMs) to localize objects. However, because CAMs were trained for classification, they do not align precisely with the object segmentations. Instead, we produce high-resolution activation maps using dense features from a segmentation network that was trained to estimate a per-lobe lesion percentage. In this way, the network can exploit knowledge regarding the required lesion volume. In addition, we propose an attention neural network module to refine dRAMs, optimized together with the main regression task. We evaluated our algorithm on 90 subjects. Results show our method achieved 70.2% Dice coefficient, substantially outperforming the CAM-based baseline at 48.6%.



### Deep learning-based bias transfer for overcoming laboratory differences of microscopic images
- **Arxiv ID**: http://arxiv.org/abs/2105.11765v1
- **DOI**: 10.1007/978-3-030-80432-9_25
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11765v1)
- **Published**: 2021-05-25 09:02:30+00:00
- **Updated**: 2021-05-25 09:02:30+00:00
- **Authors**: Ann-Katrin Thebille, Esther Dietrich, Martin Klaus, Lukas Gernhold, Maximilian Lennartz, Christoph Kuppe, Rafael Kramann, Tobias B. Huber, Guido Sauter, Victor G. Puelles, Marina Zimmermann, Stefan Bonn
- **Comment**: Accepted as a regular conference paper at MIUA 2021
- **Journal**: None
- **Summary**: The automated analysis of medical images is currently limited by technical and biological noise and bias. The same source tissue can be represented by vastly different images if the image acquisition or processing protocols vary. For an image analysis pipeline, it is crucial to compensate such biases to avoid misinterpretations. Here, we evaluate, compare, and improve existing generative model architectures to overcome domain shifts for immunofluorescence (IF) and Hematoxylin and Eosin (H&E) stained microscopy images. To determine the performance of the generative models, the original and transformed images were segmented or classified by deep neural networks that were trained only on images of the target bias. In the scope of our analysis, U-Net cycleGANs trained with an additional identity and an MS-SSIM-based loss and Fixed-Point GANs trained with an additional structure loss led to the best results for the IF and H&E stained samples, respectively. Adapting the bias of the samples significantly improved the pixel-level segmentation for human kidney glomeruli and podocytes and improved the classification accuracy for human prostate biopsies by up to 14%.



### GAN for Vision, KG for Relation: a Two-stage Deep Network for Zero-shot Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/2105.11789v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11789v1)
- **Published**: 2021-05-25 09:34:42+00:00
- **Updated**: 2021-05-25 09:34:42+00:00
- **Authors**: Bin Sun, Dehui Kong, Shaofan Wang, Jinghua Li, Baocai Yin, Xiaonan Luo
- **Comment**: 19 pages, 7 figures
- **Journal**: None
- **Summary**: Zero-shot action recognition can recognize samples of unseen classes that are unavailable in training by exploring common latent semantic representation in samples. However, most methods neglected the connotative relation and extensional relation between the action classes, which leads to the poor generalization ability of the zero-shot learning. Furthermore, the learned classifier incline to predict the samples of seen class, which leads to poor classification performance. To solve the above problems, we propose a two-stage deep neural network for zero-shot action recognition, which consists of a feature generation sub-network serving as the sampling stage and a graph attention sub-network serving as the classification stage. In the sampling stage, we utilize a generative adversarial networks (GAN) trained by action features and word vectors of seen classes to synthesize the action features of unseen classes, which can balance the training sample data of seen classes and unseen classes. In the classification stage, we construct a knowledge graph (KG) based on the relationship between word vectors of action classes and related objects, and propose a graph convolution network (GCN) based on attention mechanism, which dynamically updates the relationship between action classes and objects, and enhances the generalization ability of zero-shot learning. In both stages, we all use word vectors as bridges for feature generation and classifier generalization from seen classes to unseen classes. We compare our method with state-of-the-art methods on UCF101 and HMDB51 datasets. Experimental results show that our proposed method improves the classification performance of the trained classifier and achieves higher accuracy.



### Bridging Few-Shot Learning and Adaptation: New Challenges of Support-Query Shift
- **Arxiv ID**: http://arxiv.org/abs/2105.11804v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11804v2)
- **Published**: 2021-05-25 10:10:09+00:00
- **Updated**: 2021-08-05 08:51:54+00:00
- **Authors**: Etienne Bennequin, Victor Bouvier, Myriam Tami, Antoine Toubhans, Céline Hudelot
- **Comment**: ECML-PKDD 2021
- **Journal**: None
- **Summary**: Few-Shot Learning (FSL) algorithms have made substantial progress in learning novel concepts with just a handful of labelled data. To classify query instances from novel classes encountered at test-time, they only require a support set composed of a few labelled samples. FSL benchmarks commonly assume that those queries come from the same distribution as instances in the support set. However, in a realistic set-ting, data distribution is plausibly subject to change, a situation referred to as Distribution Shift (DS). The present work addresses the new and challenging problem of Few-Shot Learning under Support/Query Shift (FSQS) i.e., when support and query instances are sampled from related but different distributions. Our contributions are the following. First, we release a testbed for FSQS, including datasets, relevant baselines and a protocol for a rigorous and reproducible evaluation. Second, we observe that well-established FSL algorithms unsurprisingly suffer from a considerable drop in accuracy when facing FSQS, stressing the significance of our study. Finally, we show that transductive algorithms can limit the inopportune effect of DS. In particular, we study both the role of Batch-Normalization and Optimal Transport (OT) in aligning distributions, bridging Unsupervised Domain Adaptation with FSL. This results in a new method that efficiently combines OT with the celebrated Prototypical Networks. We bring compelling experiments demonstrating the advantage of our method. Our work opens an exciting line of research by providing a testbed and strong baselines. Our code is available at https://github.com/ebennequin/meta-domain-shift.



### PAS-MEF: Multi-exposure image fusion based on principal component analysis, adaptive well-exposedness and saliency map
- **Arxiv ID**: http://arxiv.org/abs/2105.11809v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11809v1)
- **Published**: 2021-05-25 10:22:43+00:00
- **Updated**: 2021-05-25 10:22:43+00:00
- **Authors**: Diclehan Karakaya, Oguzhan Ulucan, Mehmet Turkan
- **Comment**: None
- **Journal**: None
- **Summary**: High dynamic range (HDR) imaging enables to immortalize natural scenes similar to the way that they are perceived by human observers. With regular low dynamic range (LDR) capture/display devices, significant details may not be preserved in images due to the huge dynamic range of natural scenes. To minimize the information loss and produce high quality HDR-like images for LDR screens, this study proposes an efficient multi-exposure fusion (MEF) approach with a simple yet effective weight extraction method relying on principal component analysis, adaptive well-exposedness and saliency maps. These weight maps are later refined through a guided filter and the fusion is carried out by employing a pyramidal decomposition. Experimental comparisons with existing techniques demonstrate that the proposed method produces very strong statistical and visual results.



### Bridging the Gap Between Explainable AI and Uncertainty Quantification to Enhance Trustability
- **Arxiv ID**: http://arxiv.org/abs/2105.11828v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11828v1)
- **Published**: 2021-05-25 10:53:58+00:00
- **Updated**: 2021-05-25 10:53:58+00:00
- **Authors**: Dominik Seuß
- **Comment**: None
- **Journal**: None
- **Summary**: After the tremendous advances of deep learning and other AI methods, more attention is flowing into other properties of modern approaches, such as interpretability, fairness, etc. combined in frameworks like Responsible AI. Two research directions, namely Explainable AI and Uncertainty Quantification are becoming more and more important, but have been so far never combined and jointly explored. In this paper, I show how both research areas provide potential for combination, why more research should be done in this direction and how this would lead to an increase in trustability in AI systems.



### CI-dataset and DetDSCI methodology for detecting too small and too large critical infrastructures in satellite images: Airports and electrical substations as case study
- **Arxiv ID**: http://arxiv.org/abs/2105.11844v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11844v2)
- **Published**: 2021-05-25 11:38:15+00:00
- **Updated**: 2021-09-21 10:20:30+00:00
- **Authors**: Francisco Pérez-Hernández, José Rodríguez-Ortega, Yassir Benhammou, Francisco Herrera, Siham Tabik
- **Comment**: None
- **Journal**: None
- **Summary**: The detection of critical infrastructures in large territories represented by aerial and satellite images is of high importance in several fields such as in security, anomaly detection, land use planning and land use change detection. However, the detection of such infrastructures is complex as they have highly variable shapes and sizes, i.e., some infrastructures, such as electrical substations, are too small while others, such as airports, are too large. Besides, airports can have a surface area either small or too large with completely different shapes, which makes its correct detection challenging. As far as we know, these limitations have not been tackled yet in previous works. This paper presents (1) a smart Critical Infrastructure dataset, named CI-dataset, organised into two scales, small and large scales critical infrastructures and (2) a two-level resolution-independent critical infrastructure detection (DetDSCI) methodology that first determines the spatial resolution of the input image using a classification model, then analyses the image using the appropriate detector for that spatial resolution. The present study targets two representative classes, airports and electrical substations. Our experiments show that DetDSCI methodology achieves up to 37,53% F1 improvement with respect to Faster R-CNN, one of the most influential detection models.



### DTNN: Energy-efficient Inference with Dendrite Tree Inspired Neural Networks for Edge Vision Applications
- **Arxiv ID**: http://arxiv.org/abs/2105.11848v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2105.11848v1)
- **Published**: 2021-05-25 11:44:12+00:00
- **Updated**: 2021-05-25 11:44:12+00:00
- **Authors**: Tao Luo, Wai Teng Tang, Matthew Kay Fei Lee, Chuping Qu, Weng-Fai Wong, Rick Goh
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNN) have achieved remarkable success in computer vision (CV). However, training and inference of DNN models are both memory and computation intensive, incurring significant overhead in terms of energy consumption and silicon area. In particular, inference is much more cost-sensitive than training because training can be done offline with powerful platforms, while inference may have to be done on battery powered devices with constrained form factors, especially for mobile or edge vision applications. In order to accelerate DNN inference, model quantization was proposed. However previous works only focus on the quantization rate without considering the efficiency of operations. In this paper, we propose Dendrite-Tree based Neural Network (DTNN) for energy-efficient inference with table lookup operations enabled by activation quantization. In DTNN both costly weight access and arithmetic computations are eliminated for inference. We conducted experiments on various kinds of DNN models such as LeNet-5, MobileNet, VGG, and ResNet with different datasets, including MNIST, Cifar10/Cifar100, SVHN, and ImageNet. DTNN achieved significant energy saving (19.4X and 64.9X improvement on ResNet-18 and VGG-11 with ImageNet, respectively) with negligible loss of accuracy. To further validate the effectiveness of DTNN and compare with state-of-the-art low energy implementation for edge vision, we design and implement DTNN based MLP image classifiers using off-the-shelf FPGAs. The results show that DTNN on the FPGA, with higher accuracy, could achieve orders of magnitude better energy consumption and latency compared with the state-of-the-art low energy approaches reported that use ASIC chips.



### GCNBoost: Artwork Classification by Label Propagation through a Knowledge Graph
- **Arxiv ID**: http://arxiv.org/abs/2105.11852v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11852v1)
- **Published**: 2021-05-25 11:50:05+00:00
- **Updated**: 2021-05-25 11:50:05+00:00
- **Authors**: Cheikh Brahim El Vaigh, Noa Garcia, Benjamin Renoust, Chenhui Chu, Yuta Nakashima, Hajime Nagahara
- **Comment**: None
- **Journal**: None
- **Summary**: The rise of digitization of cultural documents offers large-scale contents, opening the road for development of AI systems in order to preserve, search, and deliver cultural heritage. To organize such cultural content also means to classify them, a task that is very familiar to modern computer science. Contextual information is often the key to structure such real world data, and we propose to use it in form of a knowledge graph. Such a knowledge graph, combined with content analysis, enhances the notion of proximity between artworks so it improves the performances in classification tasks. In this paper, we propose a novel use of a knowledge graph, that is constructed on annotated data and pseudo-labeled data. With label propagation, we boost artwork classification by training a model using a graph convolutional network, relying on the relationships between entities of the knowledge graph. Following a transductive learning framework, our experiments show that relying on a knowledge graph modeling the relations between labeled data and unlabeled data allows to achieve state-of-the-art results on multiple classification tasks on a dataset of paintings, and on a dataset of Buddha statues. Additionally, we show state-of-the-art results for the difficult case of dealing with unbalanced data, with the limitation of disregarding classes with extremely low degrees in the knowledge graph.



### Estimates of maize plant density from UAV RGB images using Faster-RCNN detection model: impact of the spatial resolution
- **Arxiv ID**: http://arxiv.org/abs/2105.11857v1
- **DOI**: 10.34133/2021/9824843
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11857v1)
- **Published**: 2021-05-25 11:54:51+00:00
- **Updated**: 2021-05-25 11:54:51+00:00
- **Authors**: Kaaviya Velumani, Raul Lopez-Lozano, Simon Madec, Wei Guo, Joss Gillet, Alexis Comar, Frederic Baret
- **Comment**: 16 pages, 10 figures
- **Journal**: None
- **Summary**: Early-stage plant density is an essential trait that determines the fate of a genotype under given environmental conditions and management practices. The use of RGB images taken from UAVs may replace traditional visual counting in fields with improved throughput, accuracy and access to plant localization. However, high-resolution (HR) images are required to detect small plants present at early stages. This study explores the impact of image ground sampling distance (GSD) on the performances of maize plant detection at 3-5 leaves stage using Faster-RCNN. Data collected at HR (GSD=0.3cm) over 6 contrasted sites were used for model training. Two additional sites with images acquired both at high and low (GSD=0.6cm) resolution were used for model evaluation. Results show that Faster-RCNN achieved very good plant detection and counting (rRMSE=0.08) performances when native HR images are used both for training and validation. Similarly, good performances were observed (rRMSE=0.11) when the model is trained over synthetic low-resolution (LR) images obtained by down-sampling the native training HR images, and applied to the synthetic LR validation images. Conversely, poor performances are obtained when the model is trained on a given spatial resolution and applied to another spatial resolution. Training on a mix of HR and LR images allows to get very good performances on the native HR (rRMSE=0.06) and synthetic LR (rRMSE=0.10) images. However, very low performances are still observed over the native LR images (rRMSE=0.48), mainly due to the poor quality of the native LR images. Finally, an advanced super-resolution method based on GAN (generative adversarial network) that introduces additional textural information derived from the native HR images was applied to the native LR validation images. Results show some significant improvement (rRMSE=0.22) compared to bicubic up-sampling approach.



### CoRSAI: A System for Robust Interpretation of CT Scans of COVID-19 Patients Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2105.11863v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11863v1)
- **Published**: 2021-05-25 12:06:55+00:00
- **Updated**: 2021-05-25 12:06:55+00:00
- **Authors**: Manvel Avetisian, Ilya Burenko, Konstantin Egorov, Vladimir Kokh, Aleksandr Nesterov, Aleksandr Nikolaev, Alexander Ponomarchuk, Elena Sokolova, Alex Tuzhilin, Dmitry Umerenkov
- **Comment**: None
- **Journal**: None
- **Summary**: Analysis of chest CT scans can be used in detecting parts of lungs that are affected by infectious diseases such as COVID-19.Determining the volume of lungs affected by lesions is essential for formulating treatment recommendations and prioritizingpatients by severity of the disease. In this paper we adopted an approach based on using an ensemble of deep convolutionalneural networks for segmentation of slices of lung CT scans. Using our models we are able to segment the lesions, evaluatepatients dynamics, estimate relative volume of lungs affected by lesions and evaluate the lung damage stage. Our modelswere trained on data from different medical centers. We compared predictions of our models with those of six experiencedradiologists and our segmentation model outperformed most of them. On the task of classification of disease severity, ourmodel outperformed all the radiologists.



### TransNAS-Bench-101: Improving Transferability and Generalizability of Cross-Task Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2105.11871v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.11871v1)
- **Published**: 2021-05-25 12:15:21+00:00
- **Updated**: 2021-05-25 12:15:21+00:00
- **Authors**: Yawen Duan, Xin Chen, Hang Xu, Zewei Chen, Xiaodan Liang, Tong Zhang, Zhenguo Li
- **Comment**: Published at CVPR 2021. 8 pages main paper, 13 pages in total
- **Journal**: None
- **Summary**: Recent breakthroughs of Neural Architecture Search (NAS) extend the field's research scope towards a broader range of vision tasks and more diversified search spaces. While existing NAS methods mostly design architectures on a single task, algorithms that look beyond single-task search are surging to pursue a more efficient and universal solution across various tasks. Many of them leverage transfer learning and seek to preserve, reuse, and refine network design knowledge to achieve higher efficiency in future tasks. However, the enormous computational cost and experiment complexity of cross-task NAS are imposing barriers for valuable research in this direction. Existing NAS benchmarks all focus on one type of vision task, i.e., classification. In this work, we propose TransNAS-Bench-101, a benchmark dataset containing network performance across seven tasks, covering classification, regression, pixel-level prediction, and self-supervised tasks. This diversity provides opportunities to transfer NAS methods among tasks and allows for more complex transfer schemes to evolve. We explore two fundamentally different types of search space: cell-level search space and macro-level search space. With 7,352 backbones evaluated on seven tasks, 51,464 trained models with detailed training information are provided. With TransNAS-Bench-101, we hope to encourage the advent of exceptional NAS algorithms that raise cross-task search efficiency and generalizability to the next level. Our dataset file will be available at Mindspore, VEGA.



### Few-Shot Learning with Part Discovery and Augmentation from Unlabeled Images
- **Arxiv ID**: http://arxiv.org/abs/2105.11874v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11874v1)
- **Published**: 2021-05-25 12:22:11+00:00
- **Updated**: 2021-05-25 12:22:11+00:00
- **Authors**: Wentao Chen, Chenyang Si, Wei Wang, Liang Wang, Zilei Wang, Tieniu Tan
- **Comment**: Accepted by IJCAI 2021
- **Journal**: None
- **Summary**: Few-shot learning is a challenging task since only few instances are given for recognizing an unseen class. One way to alleviate this problem is to acquire a strong inductive bias via meta-learning on similar tasks. In this paper, we show that such inductive bias can be learned from a flat collection of unlabeled images, and instantiated as transferable representations among seen and unseen classes. Specifically, we propose a novel part-based self-supervised representation learning scheme to learn transferable representations by maximizing the similarity of an image to its discriminative part. To mitigate the overfitting in few-shot classification caused by data scarcity, we further propose a part augmentation strategy by retrieving extra images from a base dataset. We conduct systematic studies on miniImageNet and tieredImageNet benchmarks. Remarkably, our method yields impressive results, outperforming the previous best unsupervised methods by 7.74% and 9.24% under 5-way 1-shot and 5-way 5-shot settings, which are comparable with state-of-the-art supervised methods.



### Flexible Table Recognition and Semantic Interpretation System
- **Arxiv ID**: http://arxiv.org/abs/2105.11879v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11879v2)
- **Published**: 2021-05-25 12:31:02+00:00
- **Updated**: 2021-12-02 17:33:35+00:00
- **Authors**: Marcin Namysl, Alexander M. Esser, Sven Behnke, Joachim Köhler
- **Comment**: Accepted for publication in Proceedings of the 17th International
  Conference on Computer Vision Theory and Applications (VISAPP 2022)
- **Journal**: None
- **Summary**: Table extraction is an important but still unsolved problem. In this paper, we introduce a flexible and modular table extraction system. We develop two rule-based algorithms that perform the complete table recognition process, including table detection and segmentation, and support the most frequent table formats. Moreover, to incorporate the extraction of semantic information, we develop a graph-based table interpretation method. We conduct extensive experiments on the challenging table recognition benchmarks ICDAR 2013 and ICDAR 2019, achieving results competitive with state-of-the-art approaches. Our complete information extraction system exhibited a high F1 score of 0.7380. To support future research on information extraction from documents, we make the resources (ground-truth annotations, evaluation scripts, algorithm parameters) from our table interpretation experiment publicly available.



### Review on Indoor RGB-D Semantic Segmentation with Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.11925v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.11925v1)
- **Published**: 2021-05-25 13:30:19+00:00
- **Updated**: 2021-05-25 13:30:19+00:00
- **Authors**: Sami Barchid, José Mennesson, Chaabane Djéraba
- **Comment**: None
- **Journal**: None
- **Summary**: Many research works focus on leveraging the complementary geometric information of indoor depth sensors in vision tasks performed by deep convolutional neural networks, notably semantic segmentation. These works deal with a specific vision task known as "RGB-D Indoor Semantic Segmentation". The challenges and resulting solutions of this task differ from its standard RGB counterpart. This results in a new active research topic. The objective of this paper is to introduce the field of Deep Convolutional Neural Networks for RGB-D Indoor Semantic Segmentation. This review presents the most popular public datasets, proposes a categorization of the strategies employed by recent contributions, evaluates the performance of the current state-of-the-art, and discusses the remaining challenges and promising directions for future works.



### Hyperspectral Image Denoising with Log-Based Robust PCA
- **Arxiv ID**: http://arxiv.org/abs/2105.11927v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.11927v1)
- **Published**: 2021-05-25 13:32:01+00:00
- **Updated**: 2021-05-25 13:32:01+00:00
- **Authors**: Yang Liu, Qian Zhang, Yongyong Chen, Qiang Cheng, Chong Peng
- **Comment**: None
- **Journal**: None
- **Summary**: It is a challenging task to remove heavy and mixed types of noise from Hyperspectral images (HSIs). In this paper, we propose a novel nonconvex approach to RPCA for HSI denoising, which adopts the log-determinant rank approximation and a novel $\ell_{2,\log}$ norm, to restrict the low-rank or column-wise sparse properties for the component matrices, respectively.For the $\ell_{2,\log}$-regularized shrinkage problem, we develop an efficient, closed-form solution, which is named $\ell_{2,\log}$-shrinkage operator, which can be generally used in other problems. Extensive experiments on both simulated and real HSIs demonstrate the effectiveness of the proposed method in denoising HSIs.



### Understanding Mobile GUI: from Pixel-Words to Screen-Sentences
- **Arxiv ID**: http://arxiv.org/abs/2105.11941v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2105.11941v2)
- **Published**: 2021-05-25 13:45:54+00:00
- **Updated**: 2022-04-14 11:00:58+00:00
- **Authors**: Jingwen Fu, Xiaoyi Zhang, Yuwang Wang, Wenjun Zeng, Sam Yang, Grayson Hilliard
- **Comment**: None
- **Journal**: None
- **Summary**: The ubiquity of mobile phones makes mobile GUI understanding an important task. Most previous works in this domain require human-created metadata of screens (e.g. View Hierarchy) during inference, which unfortunately is often not available or reliable enough for GUI understanding. Inspired by the impressive success of Transformers in NLP tasks, targeting for purely vision-based GUI understanding, we extend the concepts of Words/Sentence to Pixel-Words/Screen-Sentence, and propose a mobile GUI understanding architecture: Pixel-Words to Screen-Sentence (PW2SS). In analogy to the individual Words, we define the Pixel-Words as atomic visual components (text and graphic components), which are visually consistent and semantically clear across screenshots of a large variety of design styles. The Pixel-Words extracted from a screenshot are aggregated into Screen-Sentence with a Screen Transformer proposed to model their relations. Since the Pixel-Words are defined as atomic visual components, the ambiguity between their visual appearance and semantics is dramatically reduced. We are able to make use of metadata available in training data to auto-generate high-quality annotations for Pixel-Words. A dataset, RICO-PW, of screenshots with Pixel-Words annotations is built based on the public RICO dataset, which will be released to help to address the lack of high-quality training data in this area. We train a detector to extract Pixel-Words from screenshots on this dataset and achieve metadata-free GUI understanding during inference. We conduct experiments and show that Pixel-Words can be well extracted on RICO-PW and well generalized to a new dataset, P2S-UI, collected by ourselves. The effectiveness of PW2SS is further verified in the GUI understanding tasks including relation prediction, clickability prediction, screen retrieval, and app type classification.



### Emotion Recognition in Horses with Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.11953v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, q-bio.QM, I.4.7
- **Links**: [PDF](http://arxiv.org/pdf/2105.11953v2)
- **Published**: 2021-05-25 14:04:43+00:00
- **Updated**: 2022-07-17 13:55:40+00:00
- **Authors**: Luis A. Corujo, Peter A. Gloor, Emily Kieson, Timo Schloesser
- **Comment**: 14 pages, 11figures
- **Journal**: None
- **Summary**: Creating intelligent systems capable of recognizing emotions is a difficult task, especially when looking at emotions in animals. This paper describes the process of designing a "proof of concept" system to recognize emotions in horses. This system is formed by two elements, a detector and a model. The detector is a fast region-based convolutional neural network that detects horses in an image. The model is a convolutional neural network that predicts the emotions of those horses. These two elements were trained with multiple images of horses until they achieved high accuracy in their tasks. In total, 400 images of horses were collected and labeled to train both the detector and the model while 40 were used to test the system. Once the two components were validated, they were combined into a testable system that would detect equine emotions based on established behavioral ethograms indicating emotional affect through head, neck, ear, muzzle and eye position. The system showed an accuracy of 80% on the validation set and 65% on the test set, demonstrating that it is possible to predict emotions in animals using autonomous intelligent systems. Such a system has multiple applications including further studies in the growing field of animal emotions as well as in the veterinary field to determine the physical welfare of horses or other livestock.



### Learning Generative Prior with Latent Space Sparsity Constraints
- **Arxiv ID**: http://arxiv.org/abs/2105.11956v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, 60E05, I.4.5; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2105.11956v1)
- **Published**: 2021-05-25 14:12:04+00:00
- **Updated**: 2021-05-25 14:12:04+00:00
- **Authors**: Vinayak Killedar, Praveen Kumar Pokala, Chandra Sekhar Seelamantula
- **Comment**: Submitted to UAI 2021
- **Journal**: None
- **Summary**: We address the problem of compressed sensing using a deep generative prior model and consider both linear and learned nonlinear sensing mechanisms, where the nonlinear one involves either a fully connected neural network or a convolutional neural network. Recently, it has been argued that the distribution of natural images do not lie in a single manifold but rather lie in a union of several submanifolds. We propose a sparsity-driven latent space sampling (SDLSS) framework and develop a proximal meta-learning (PML) algorithm to enforce sparsity in the latent space. SDLSS allows the range-space of the generator to be considered as a union-of-submanifolds. We also derive the sample complexity bounds within the SDLSS framework for the linear measurement model. The results demonstrate that for a higher degree of compression, the SDLSS method is more efficient than the state-of-the-art method. We first consider a comparison between linear and nonlinear sensing mechanisms on Fashion-MNIST dataset and show that the learned nonlinear version is superior to the linear one. Subsequent comparisons with the deep compressive sensing (DCS) framework proposed in the literature are reported. We also consider the effect of the dimension of the latent space and the sparsity factor in validating the SDLSS framework. Performance quantification is carried out by employing three objective metrics: peak signal-to-noise ratio (PSNR), structural similarity index metric (SSIM), and reconstruction error (RE).



### Unpaired Depth Super-Resolution in the Wild
- **Arxiv ID**: http://arxiv.org/abs/2105.12038v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.12038v4)
- **Published**: 2021-05-25 16:19:16+00:00
- **Updated**: 2022-09-23 15:29:08+00:00
- **Authors**: Aleksandr Safin, Maxim Kan, Nikita Drobyshev, Oleg Voynov, Alexey Artemov, Alexander Filippov, Denis Zorin, Evgeny Burnaev
- **Comment**: None
- **Journal**: None
- **Summary**: Depth maps captured with commodity sensors are often of low quality and resolution; these maps need to be enhanced to be used in many applications. State-of-the-art data-driven methods of depth map super-resolution rely on registered pairs of low- and high-resolution depth maps of the same scenes. Acquisition of real-world paired data requires specialized setups. Another alternative, generating low-resolution maps from high-resolution maps by subsampling, adding noise and other artificial degradation methods, does not fully capture the characteristics of real-world low-resolution images. As a consequence, supervised learning methods trained on such artificial paired data may not perform well on real-world low-resolution inputs. We consider an approach to depth super-resolution based on learning from unpaired data. While many techniques for unpaired image-to-image translation have been proposed, most fail to deliver effective hole-filling or reconstruct accurate surfaces using depth maps. We propose an unpaired learning method for depth super-resolution, which is based on a learnable degradation model, enhancement component and surface normal estimates as features to produce more accurate depth maps. We propose a benchmark for unpaired depth SR and demonstrate that our method outperforms existing unpaired methods and performs on par with paired.



### Temporal Action Proposal Generation with Transformers
- **Arxiv ID**: http://arxiv.org/abs/2105.12043v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2105.12043v1)
- **Published**: 2021-05-25 16:22:12+00:00
- **Updated**: 2021-05-25 16:22:12+00:00
- **Authors**: Lining Wang, Haosen Yang, Wenhao Wu, Hongxun Yao, Hujie Huang
- **Comment**: The first three authors contributed equally
- **Journal**: None
- **Summary**: Transformer networks are effective at modeling long-range contextual information and have recently demonstrated exemplary performance in the natural language processing domain. Conventionally, the temporal action proposal generation (TAPG) task is divided into two main sub-tasks: boundary prediction and proposal confidence prediction, which rely on the frame-level dependencies and proposal-level relationships separately. To capture the dependencies at different levels of granularity, this paper intuitively presents a unified temporal action proposal generation framework with original Transformers, called TAPG Transformer, which consists of a Boundary Transformer and a Proposal Transformer. Specifically, the Boundary Transformer captures long-term temporal dependencies to predict precise boundary information and the Proposal Transformer learns the rich inter-proposal relationships for reliable confidence evaluation. Extensive experiments are conducted on two popular benchmarks: ActivityNet-1.3 and THUMOS14, and the results demonstrate that TAPG Transformer outperforms state-of-the-art methods. Equipped with the existing action classifier, our method achieves remarkable performance on the temporal action localization task. Codes and models will be available.



### Real-time Monocular Depth Estimation with Sparse Supervision on Mobile
- **Arxiv ID**: http://arxiv.org/abs/2105.12053v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.12053v1)
- **Published**: 2021-05-25 16:33:28+00:00
- **Updated**: 2021-05-25 16:33:28+00:00
- **Authors**: Mehmet Kerim Yucel, Valia Dimaridou, Anastasios Drosou, Albert Saà-Garriga
- **Comment**: To appear at CVPR 2021 Mobile AI (MAI) Workshop
- **Journal**: None
- **Summary**: Monocular (relative or metric) depth estimation is a critical task for various applications, such as autonomous vehicles, augmented reality and image editing. In recent years, with the increasing availability of mobile devices, accurate and mobile-friendly depth models have gained importance. Increasingly accurate models typically require more computational resources, which inhibits the use of such models on mobile devices. The mobile use case is arguably the most unrestricted one, which requires highly accurate yet mobile-friendly architectures. Therefore, we try to answer the following question: How can we improve a model without adding further complexity (i.e. parameters)? Towards this end, we systematically explore the design space of a relative depth estimation model from various dimensions and we show, with key design choices and ablation studies, even an existing architecture can reach highly competitive performance to the state of the art, with a fraction of the complexity. Our study spans an in-depth backbone model selection process, knowledge distillation, intermediate predictions, model pruning and loss rebalancing. We show that our model, using only DIW as the supervisory dataset, achieves 0.1156 WHDR on DIW with 2.6M parameters and reaches 37 FPS on a mobile GPU, without pruning or hardware-specific optimization. A pruned version of our model achieves 0.1208 WHDR on DIW with 1M parameters and reaches 44 FPS on a mobile GPU.



### Matching Targets Across Domains with RADON, the Re-Identification Across Domain Network
- **Arxiv ID**: http://arxiv.org/abs/2105.12056v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12056v1)
- **Published**: 2021-05-25 16:36:38+00:00
- **Updated**: 2021-05-25 16:36:38+00:00
- **Authors**: Cassandra Burgess, Cordelia Neisinger, Rafael Dinner
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel convolutional neural network that learns to match images of an object taken from different viewpoints or by different optical sensors. Our Re-Identification Across Domain Network (RADON) scores pairs of input images from different domains on similarity. Our approach extends previous work on Siamese networks and modifies them to more challenging use cases, including low- and no-shot learning, in which few images of a specific target are available for training. RADON shows strong performance on cross-view vehicle matching and cross-domain person identification in a no-shot learning environment.



### DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2105.12085v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2105.12085v3)
- **Published**: 2021-05-25 17:09:57+00:00
- **Updated**: 2021-08-17 07:11:18+00:00
- **Authors**: Wenhao Wu, Yuxiang Zhao, Yanwu Xu, Xiao Tan, Dongliang He, Zhikang Zou, Jin Ye, Yingying Li, Mingde Yao, Zichao Dong, Yifeng Shi
- **Comment**: Accepted to ACMMM2021
- **Journal**: None
- **Summary**: Long-range and short-range temporal modeling are two complementary and crucial aspects of video recognition. Most of the state-of-the-arts focus on short-range spatio-temporal modeling and then average multiple snippet-level predictions to yield the final video-level prediction. Thus, their video-level prediction does not consider spatio-temporal features of how video evolves along the temporal dimension. In this paper, we introduce a novel Dynamic Segment Aggregation (DSA) module to capture relationship among snippets. To be more specific, we attempt to generate a dynamic kernel for a convolutional operation to aggregate long-range temporal information among adjacent snippets adaptively. The DSA module is an efficient plug-and-play module and can be combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform powerful long-range modeling with minimal overhead. The final video architecture, coined as DSANet. We conduct extensive experiments on several video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400, Something-Something V1 and ActivityNet) to show its superiority. Our proposed DSA module is shown to benefit various video recognition models significantly. For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is improved from 74.9% to 78.2% on Kinetics-400. Codes are available at https://github.com/whwu95/DSANet.



### Security in Next Generation Mobile Payment Systems: A Comprehensive Survey
- **Arxiv ID**: http://arxiv.org/abs/2105.12097v2
- **DOI**: 10.1109/ACCESS.2021.3105450
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12097v2)
- **Published**: 2021-05-25 17:34:22+00:00
- **Updated**: 2021-07-10 17:43:12+00:00
- **Authors**: Waqas Ahmed, Amir Rasool, Neeraj Kumar, Abdul RehmanJaved, Thippa Reddy Gadekallu, Zunera Jalil, Natalia Kryvinska
- **Comment**: None
- **Journal**: IEEE ACCESS, 2021
- **Summary**: Cash payment is still king in several markets, accounting for more than 90\ of the payments in almost all the developing countries. The usage of mobile phones is pretty ordinary in this present era. Mobile phones have become an inseparable friend for many users, serving much more than just communication tools. Every subsequent person is heavily relying on them due to multifaceted usage and affordability. Every person wants to manage his/her daily transactions and related issues by using his/her mobile phone. With the rise and advancements of mobile-specific security, threats are evolving as well. In this paper, we provide a survey of various security models for mobile phones. We explore multiple proposed models of the mobile payment system (MPS), their technologies and comparisons, payment methods, different security mechanisms involved in MPS, and provide analysis of the encryption technologies, authentication methods, and firewall in MPS. We also present current challenges and future directions of mobile phone security.



### Adversarial Attack Driven Data Augmentation for Accurate And Robust Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2105.12106v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12106v1)
- **Published**: 2021-05-25 17:44:19+00:00
- **Updated**: 2021-05-25 17:44:19+00:00
- **Authors**: Mst. Tasnim Pervin, Linmi Tao, Aminul Huq, Zuoxiang He, Li Huo
- **Comment**: None
- **Journal**: None
- **Summary**: Segmentation is considered to be a very crucial task in medical image analysis. This task has been easier since deep learning models have taken over with its high performing behavior. However, deep learning models dependency on large data proves it to be an obstacle in medical image analysis because of insufficient data samples. Several data augmentation techniques have been used to mitigate this problem. We propose a new augmentation method by introducing adversarial learning attack techniques, specifically Fast Gradient Sign Method (FGSM). Furthermore, We have also introduced the concept of Inverse FGSM (InvFGSM), which works in the opposite manner of FGSM for the data augmentation. This two approaches worked together to improve the segmentation accuracy, as well as helped the model to gain robustness against adversarial attacks. The overall analysis of experiments indicates a novel use of adversarial machine learning along with robustness enhancement.



### Self-Organized Variational Autoencoders (Self-VAE) for Learned Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2105.12107v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12107v3)
- **Published**: 2021-05-25 17:44:20+00:00
- **Updated**: 2021-05-28 15:43:13+00:00
- **Authors**: M. Akın Yılmaz, Onur Keleş, Hilal Güven, A. Murat Tekalp, Junaid Malik, Serkan Kıranyaz
- **Comment**: Accepted for publication in IEEE International Conference on Image
  Processing (ICIP) 2021
- **Journal**: None
- **Summary**: In end-to-end optimized learned image compression, it is standard practice to use a convolutional variational autoencoder with generalized divisive normalization (GDN) to transform images into a latent space. Recently, Operational Neural Networks (ONNs) that learn the best non-linearity from a set of alternatives, and their self-organized variants, Self-ONNs, that approximate any non-linearity via Taylor series have been proposed to address the limitations of convolutional layers and a fixed nonlinear activation. In this paper, we propose to replace the convolutional and GDN layers in the variational autoencoder with self-organized operational layers, and propose a novel self-organized variational autoencoder (Self-VAE) architecture that benefits from stronger non-linearity. The experimental results demonstrate that the proposed Self-VAE yields improvements in both rate-distortion performance and perceptual image quality.



### Calibration and Uncertainty Quantification of Bayesian Convolutional Neural Networks for Geophysical Applications
- **Arxiv ID**: http://arxiv.org/abs/2105.12115v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, physics.geo-ph, 86-08, 68T10, 68T37, I.4.6; I.5.1; J.2
- **Links**: [PDF](http://arxiv.org/pdf/2105.12115v1)
- **Published**: 2021-05-25 17:54:23+00:00
- **Updated**: 2021-05-25 17:54:23+00:00
- **Authors**: Lukas Mosser, Ehsan Zabihi Naeini
- **Comment**: 25 pages, 11 figures
- **Journal**: None
- **Summary**: Deep neural networks offer numerous potential applications across geoscience, for example, one could argue that they are the state-of-the-art method for predicting faults in seismic datasets. In quantitative reservoir characterization workflows, it is common to incorporate the uncertainty of predictions thus such subsurface models should provide calibrated probabilities and the associated uncertainties in their predictions. It has been shown that popular Deep Learning-based models are often miscalibrated, and due to their deterministic nature, provide no means to interpret the uncertainty of their predictions. We compare three different approaches to obtaining probabilistic models based on convolutional neural networks in a Bayesian formalism, namely Deep Ensembles, Concrete Dropout, and Stochastic Weight Averaging-Gaussian (SWAG). These methods are consistently applied to fault detection case studies where Deep Ensembles use independently trained models to provide fault probabilities, Concrete Dropout represents an extension to the popular Dropout technique to approximate Bayesian neural networks, and finally, we apply SWAG, a recent method that is based on the Bayesian inference equivalence of mini-batch Stochastic Gradient Descent. We provide quantitative results in terms of model calibration and uncertainty representation, as well as qualitative results on synthetic and real seismic datasets. Our results show that the approximate Bayesian methods, Concrete Dropout and SWAG, both provide well-calibrated predictions and uncertainty attributes at a lower computational cost when compared to the baseline Deep Ensemble approach. The resulting uncertainties also offer a possibility to further improve the model performance as well as enhancing the interpretability of the models.



### AutoReCon: Neural Architecture Search-based Reconstruction for Data-free Compression
- **Arxiv ID**: http://arxiv.org/abs/2105.12151v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12151v1)
- **Published**: 2021-05-25 18:03:25+00:00
- **Updated**: 2021-05-25 18:03:25+00:00
- **Authors**: Baozhou Zhu, Peter Hofstee, Johan Peltenburg, Jinho Lee, Zaid Alars
- **Comment**: None
- **Journal**: None
- **Summary**: Data-free compression raises a new challenge because the original training dataset for a pre-trained model to be compressed is not available due to privacy or transmission issues. Thus, a common approach is to compute a reconstructed training dataset before compression. The current reconstruction methods compute the reconstructed training dataset with a generator by exploiting information from the pre-trained model. However, current reconstruction methods focus on extracting more information from the pre-trained model but do not leverage network engineering. This work is the first to consider network engineering as an approach to design the reconstruction method. Specifically, we propose the AutoReCon method, which is a neural architecture search-based reconstruction method. In the proposed AutoReCon method, the generator architecture is designed automatically given the pre-trained model for reconstruction. Experimental results show that using generators discovered by the AutoRecon method always improve the performance of data-free compression.



### Occlusion Aware Kernel Correlation Filter Tracker using RGB-D
- **Arxiv ID**: http://arxiv.org/abs/2105.12161v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2105.12161v1)
- **Published**: 2021-05-25 18:37:39+00:00
- **Updated**: 2021-05-25 18:37:39+00:00
- **Authors**: Srishti Yadav
- **Comment**: Thesis, Simon Fraser University
- **Journal**: None
- **Summary**: Unlike deep learning which requires large training datasets, correlation filter-based trackers like Kernelized Correlation Filter (KCF) uses implicit properties of tracked images (circulant matrices) for training in real-time. Despite their practical application in tracking, a need for a better understanding of the fundamentals associated with KCF in terms of theoretically, mathematically, and experimentally exists. This thesis first details the workings prototype of the tracker and investigates its effectiveness in real-time applications and supporting visualizations. We further address some of the drawbacks of the tracker in cases of occlusions, scale changes, object rotation, out-of-view and model drift with our novel RGB-D Kernel Correlation tracker. We also study the use of particle filters to improve trackers' accuracy. Our results are experimentally evaluated using a) standard dataset and b) real-time using the Microsoft Kinect V2 sensor. We believe this work will set the basis for a better understanding of the effectiveness of kernel-based correlation filter trackers and to further define some of its possible advantages in tracking.



### Self-Guided Instance-Aware Network for Depth Completion and Enhancement
- **Arxiv ID**: http://arxiv.org/abs/2105.12186v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2105.12186v2)
- **Published**: 2021-05-25 19:41:38+00:00
- **Updated**: 2021-05-27 19:25:16+00:00
- **Authors**: Zhongzhen Luo, Fengjia Zhang, Guoyi Fu, Jiajie Xu
- **Comment**: Accepted by ICRA 2021
- **Journal**: None
- **Summary**: Depth completion aims at inferring a dense depth image from sparse depth measurement since glossy, transparent or distant surface cannot be scanned properly by the sensor. Most of existing methods directly interpolate the missing depth measurements based on pixel-wise image content and the corresponding neighboring depth values. Consequently, this leads to blurred boundaries or inaccurate structure of object. To address these problems, we propose a novel self-guided instance-aware network (SG-IANet) that: (1) utilize self-guided mechanism to extract instance-level features that is needed for depth restoration, (2) exploit the geometric and context information into network learning to conform to the underlying constraints for edge clarity and structure consistency, (3) regularize the depth estimation and mitigate the impact of noise by instance-aware learning, and (4) train with synthetic data only by domain randomization to bridge the reality gap. Extensive experiments on synthetic and real world dataset demonstrate that our proposed method outperforms previous works. Further ablation studies give more insights into the proposed method and demonstrate the generalization capability of our model.



### The Nonlinearity Coefficient - A Practical Guide to Neural Architecture Design
- **Arxiv ID**: http://arxiv.org/abs/2105.12210v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2105.12210v1)
- **Published**: 2021-05-25 20:47:43+00:00
- **Updated**: 2021-05-25 20:47:43+00:00
- **Authors**: George Philipp
- **Comment**: This work is based on the PhD thesis with the same name, author, year
  and institution. Both works may be cited interchangeably
- **Journal**: None
- **Summary**: In essence, a neural network is an arbitrary differentiable, parametrized function. Choosing a neural network architecture for any task is as complex as searching the space of those functions. For the last few years, 'neural architecture design' has been largely synonymous with 'neural architecture search' (NAS), i.e. brute-force, large-scale search. NAS has yielded significant gains on practical tasks. However, NAS methods end up searching for a local optimum in architecture space in a small neighborhood around architectures that often go back decades, based on CNN or LSTM.   In this work, we present a different and complementary approach to architecture design, which we term 'zero-shot architecture design' (ZSAD). We develop methods that can predict, without any training, whether an architecture will achieve a relatively high test or training error on a task after training. We then go on to explain the error in terms of the architecture definition itself and develop tools for modifying the architecture based on this explanation. This confers an unprecedented level of control on the deep learning practitioner. They can make informed design decisions before the first line of code is written, even for tasks for which no prior art exists.   Our first major contribution is to show that the 'degree of nonlinearity' of a neural architecture is a key causal driver behind its performance, and a primary aspect of the architecture's model complexity. We introduce the 'nonlinearity coefficient' (NLC), a scalar metric for measuring nonlinearity. Via extensive empirical study, we show that the value of the NLC in the architecture's randomly initialized state before training is a powerful predictor of test error after training and that attaining a right-sized NLC is essential for attaining an optimal test error. The NLC is also conceptually simple, well-defined for any feedforward network, easy and cheap to compute, has extensive theoretical, empirical and conceptual grounding, follows instructively from the architecture definition, and can be easily controlled via our 'nonlinearity normalization' algorithm. We argue that the NLC is the most powerful scalar statistic for architecture design specifically and neural network analysis in general. Our analysis is fueled by mean field theory, which we use to uncover the 'meta-distribution' of layers.   Beyond the NLC, we uncover and flesh out a range of metrics and properties that have a significant explanatory influence on test and training error. We go on to explain the majority of the error variation across a wide range of randomly generated architectures with these metrics and properties. We compile our insights into a practical guide for architecture designers, which we argue can significantly shorten the trial-and-error phase of deep learning deployment.   Our results are grounded in an experimental protocol that exceeds that of the vast majority of other deep learning studies in terms of carefulness and rigor. We study the impact of e.g. dataset, learning rate, floating-point precision, loss function, statistical estimation error and batch inter-dependency on performance and other key properties. We promote research practices that we believe can significantly accelerate progress in architecture design research.



### Learning a Model-Driven Variational Network for Deformable Image Registration
- **Arxiv ID**: http://arxiv.org/abs/2105.12227v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.12227v1)
- **Published**: 2021-05-25 21:37:37+00:00
- **Updated**: 2021-05-25 21:37:37+00:00
- **Authors**: Xi Jia, Alexander Thorley, Wei Chen, Huaqi Qiu, Linlin Shen, Iain B Styles, Hyung Jin Chang, Ales Leonardis, Antonio de Marvao, Declan P. O'Regan, Daniel Rueckert, Jinming Duan
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
- **Journal**: None
- **Summary**: Data-driven deep learning approaches to image registration can be less accurate than conventional iterative approaches, especially when training data is limited. To address this whilst retaining the fast inference speed of deep learning, we propose VR-Net, a novel cascaded variational network for unsupervised deformable image registration. Using the variable splitting optimization scheme, we first convert the image registration problem, established in a generic variational framework, into two sub-problems, one with a point-wise, closed-form solution while the other one is a denoising problem. We then propose two neural layers (i.e. warping layer and intensity consistency layer) to model the analytical solution and a residual U-Net to formulate the denoising problem (i.e. generalized denoising layer). Finally, we cascade the warping layer, intensity consistency layer, and generalized denoising layer to form the VR-Net. Extensive experiments on three (two 2D and one 3D) cardiac magnetic resonance imaging datasets show that VR-Net outperforms state-of-the-art deep learning methods on registration accuracy, while maintains the fast inference speed of deep learning and the data-efficiency of variational model.



### AutoMate: A Dataset and Learning Approach for Automatic Mating of CAD Assemblies
- **Arxiv ID**: http://arxiv.org/abs/2105.12238v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, I.3.5; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2105.12238v2)
- **Published**: 2021-05-25 22:07:55+00:00
- **Updated**: 2021-10-04 22:32:46+00:00
- **Authors**: Benjamin Jones, Dalton Hildreth, Duowen Chen, Ilya Baran, Vladimir G. Kim, Adriana Schulz
- **Comment**: 16 pages, 17 figures, 4 tables
- **Journal**: None
- **Summary**: Assembly modeling is a core task of computer aided design (CAD), comprising around one third of the work in a CAD workflow. Optimizing this process therefore represents a huge opportunity in the design of a CAD system, but current research of assembly based modeling is not directly applicable to modern CAD systems because it eschews the dominant data structure of modern CAD: parametric boundary representations (BREPs). CAD assembly modeling defines assemblies as a system of pairwise constraints, called mates, between parts, which are defined relative to BREP topology rather than in world coordinates common to existing work. We propose SB-GCN, a representation learning scheme on BREPs that retains the topological structure of parts, and use these learned representations to predict CAD type mates. To train our system, we compiled the first large scale dataset of BREP CAD assemblies, which we are releasing along with benchmark mate prediction tasks. Finally, we demonstrate the compatibility of our model with an existing commercial CAD system by building a tool that assists users in mate creation by suggesting mate completions, with 72.2% accuracy.



### GraphVICRegHSIC: Towards improved self-supervised representation learning for graphs with a hyrbid loss function
- **Arxiv ID**: http://arxiv.org/abs/2105.12247v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CG, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2105.12247v4)
- **Published**: 2021-05-25 22:34:19+00:00
- **Updated**: 2021-11-26 19:31:09+00:00
- **Authors**: Sayan Nag
- **Comment**: Paper Accepted in the Weakly Supervised Representation Learning
  Workshop, IJCAI 2021 (IJCAI2021-WSRL)
- **Journal**: None
- **Summary**: Self-supervised learning and pre-training strategieshave developed over the last few years especiallyfor Convolutional Neural Networks (CNNs). Re-cently application of such methods can also be no-ticed for Graph Neural Networks (GNNs) . In thispaper, we have used a graph based self-supervisedlearning strategy with different loss functions (Bar-low Twins[Zbontaret al., 2021], HSIC[Tsaiet al.,2021], VICReg[Bardeset al., 2021]) which haveshown promising results when applied with CNNspreviously. We have also proposed a hybrid lossfunction combining the advantages of VICReg andHSIC and called it as VICRegHSIC. The perfor-mance of these aforementioned methods have beencompared when applied to 7 different datasets suchas MUTAG, PROTEINS, IMDB-Binary, etc. Ex-periments showed that our hybrid loss function per-formed better than the remaining ones in 4 out of7 cases. Moreover, the impact of different batchsizes, projector dimensions and data augmentationstrategies have also been explored.



### Style Similarity as Feedback for Product Design
- **Arxiv ID**: http://arxiv.org/abs/2105.12256v1
- **DOI**: 10.1007/978-981-15-7707-9_3
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.12256v1)
- **Published**: 2021-05-25 23:30:29+00:00
- **Updated**: 2021-05-25 23:30:29+00:00
- **Authors**: Mathew Schwartz, Tomer Weiss, Esra Ataer-Cansizoglu, Jae-Woo Choi
- **Comment**: 15 pages, 9 figures, interdisciplinary book chapter on using computer
  vision and style similarity for industrial design
- **Journal**: In: Lee JH. (eds) A New Perspective of Cultural DNA. KAIST
  Research Series. Springer, Singapore (2021)
- **Summary**: Matching and recommending products is beneficial for both customers and companies. With the rapid increase in home goods e-commerce, there is an increasing demand for quantitative methods for providing such recommendations for millions of products. This approach is facilitated largely by online stores such as Amazon and Wayfair, in which the goal is to maximize overall sales. Instead of focusing on overall sales, we take a product design perspective, by employing big-data analysis for determining the design qualities of a highly recommended product. Specifically, we focus on the visual style compatibility of such products. We build off previous work which implemented a style-based similarity metric for thousands of furniture products. Using analysis and visualization, we extract attributes of furniture products that are highly compatible style-wise. We propose a designer in-the-loop workflow that mirrors methods of displaying similar products to consumers browsing e-commerce websites. Our findings are useful when designing new products, since they provide insight regarding what furniture will be strongly compatible across multiple styles, and hence, more likely to be recommended.



