# Arxiv Papers in cs.CV on 2021-05-31
### Human-level COVID-19 Diagnosis from Low-dose CT Scans Using a Two-stage Time-distributed Capsule Network
- **Arxiv ID**: http://arxiv.org/abs/2105.14656v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14656v2)
- **Published**: 2021-05-31 00:49:34+00:00
- **Updated**: 2021-12-01 16:27:33+00:00
- **Authors**: Parnian Afshar, Moezedin Javad Rafiee, Farnoosh Naderkhani, Shahin Heidarian, Nastaran Enshaei, Anastasia Oikonomou, Faranak Babaki Fard, Reut Anconina, Keyvan Farahani, Konstantinos N. Plataniotis, Arash Mohammadi
- **Comment**: None
- **Journal**: None
- **Summary**: Reverse transcription-polymerase chain reaction (RT-PCR) is currently the gold standard in COVID-19 diagnosis. It can, however, take days to provide the diagnosis, and false negative rate is relatively high. Imaging, in particular chest computed tomography (CT), can assist with diagnosis and assessment of this disease. Nevertheless, it is shown that standard dose CT scan gives significant radiation burden to patients, especially those in need of multiple scans. In this study, we consider low-dose and ultra-low-dose (LDCT and ULDCT) scan protocols that reduce the radiation exposure close to that of a single X-Ray, while maintaining an acceptable resolution for diagnosis purposes. Since thoracic radiology expertise may not be widely available during the pandemic, we develop an Artificial Intelligence (AI)-based framework using a collected dataset of LDCT/ULDCT scans, to study the hypothesis that the AI model can provide human-level performance. The AI model uses a two stage capsule network architecture and can rapidly classify COVID-19, community acquired pneumonia (CAP), and normal cases, using LDCT/ULDCT scans. The AI model achieves COVID-19 sensitivity of 89.5% +\- 0.11, CAP sensitivity of 95% +\- 0.11, normal cases sensitivity (specificity) of 85.7% +\- 0.16, and accuracy of 90% +\- 0.06. By incorporating clinical data (demographic and symptoms), the performance further improves to COVID-19 sensitivity of 94.3% +\- pm 0.05, CAP sensitivity of 96.7% +\- 0.07, normal cases sensitivity (specificity) of 91% +\- 0.09 , and accuracy of 94.1% +\- 0.03. The proposed AI model achieves human-level diagnosis based on the LDCT/ULDCT scans with reduced radiation exposure. We believe that the proposed AI model has the potential to assist the radiologists to accurately and promptly diagnose COVID-19 infection and help control the transmission chain during the pandemic.



### Image-to-Video Generation via 3D Facial Dynamics
- **Arxiv ID**: http://arxiv.org/abs/2105.14678v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14678v1)
- **Published**: 2021-05-31 02:30:11+00:00
- **Updated**: 2021-05-31 02:30:11+00:00
- **Authors**: Xiaoguang Tu, Yingtian Zou, Jian Zhao, Wenjie Ai, Jian Dong, Yuan Yao, Zhikang Wang, Guodong Guo, Zhifeng Li, Wei Liu, Jiashi Feng
- **Comment**: None
- **Journal**: None
- **Summary**: We present a versatile model, FaceAnime, for various video generation tasks from still images. Video generation from a single face image is an interesting problem and usually tackled by utilizing Generative Adversarial Networks (GANs) to integrate information from the input face image and a sequence of sparse facial landmarks. However, the generated face images usually suffer from quality loss, image distortion, identity change, and expression mismatching due to the weak representation capacity of the facial landmarks. In this paper, we propose to "imagine" a face video from a single face image according to the reconstructed 3D face dynamics, aiming to generate a realistic and identity-preserving face video, with precisely predicted pose and facial expression. The 3D dynamics reveal changes of the facial expression and motion, and can serve as a strong prior knowledge for guiding highly realistic face video generation. In particular, we explore face video prediction and exploit a well-designed 3D dynamic prediction network to predict a 3D dynamic sequence for a single face image. The 3D dynamics are then further rendered by the sparse texture mapping algorithm to recover structural details and sparse textures for generating face frames. Our model is versatile for various AR/VR and entertainment applications, such as face video retargeting and face video prediction. Superior experimental results have well demonstrated its effectiveness in generating high-fidelity, identity-preserving, and visually pleasant face video clips from a single source face image.



### Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality Collaboration
- **Arxiv ID**: http://arxiv.org/abs/2105.14683v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14683v1)
- **Published**: 2021-05-31 03:16:38+00:00
- **Updated**: 2021-05-31 03:16:38+00:00
- **Authors**: Yuhang He, Wentao Yu, Jie Han, Xing Wei, Xiaopeng Hong, Yihong Gong
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we focus on the multi-object tracking (MOT) problem of automatic driving and robot navigation. Most existing MOT methods track multiple objects using a singular RGB camera, which are prone to camera field-of-view and suffer tracking failures in complex scenarios due to background clutters and poor light conditions. To meet these challenges, we propose a MultiModality PAnoramic multi-object Tracking framework (MMPAT), which takes both 2D panorama images and 3D point clouds as input and then infers target trajectories using the multimodality data. The proposed method contains four major modules, a panorama image detection module, a multimodality data fusion module, a data association module and a trajectory inference model. We evaluate the proposed method on the JRDB dataset, where the MMPAT achieves the top performance in both the detection and tracking tasks and significantly outperforms state-of-the-art methods by a large margin (15.7 and 8.5 improvement in terms of AP and MOTA, respectively).



### DeepChange: A Large Long-Term Person Re-Identification Benchmark with Clothes Change
- **Arxiv ID**: http://arxiv.org/abs/2105.14685v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14685v4)
- **Published**: 2021-05-31 03:35:00+00:00
- **Updated**: 2022-03-02 18:53:03+00:00
- **Authors**: Peng Xu, Xiatian Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Existing person re-identification (re-id) works mostly consider short-term application scenarios without clothes change. In real-world, however, we often dress differently across space and time. To solve this contrast, a few recent attempts have been made on long-term re-id with clothes change. Currently, one of the most significant limitations in this field is the lack of a large realistic benchmark. In this work, we contribute a large, realistic long-term person re-identification benchmark, named as DeepChange. It has several unique characteristics: (1) Realistic and rich personal appearance (e.g., clothes and hair style) and variations: Highly diverse clothes change and styles, with varying reappearing gaps in time from minutes to seasons, different weather conditions (e.g., sunny, cloudy, windy, rainy, snowy, extremely cold) and events (e.g., working, leisure, daily activities). (2) Rich camera setups: Raw videos were recorded by 17 outdoor varying resolution cameras operating in a real-world surveillance system. (3) The currently largest number of (17) cameras, (1, 121) identities, and (178, 407) bounding boxes, over the longest time span (12 months). Further, we investigate multimodal fusion strategies for tackling the clothes change challenge. Extensive experiments show that our fusion models outperform a wide variety of state-of-the-art models on DeepChange. Our dataset and documents are available at https://github.com/PengBoXiangShang/deepchange.



### Training Domain-invariant Object Detector Faster with Feature Replay and Slow Learner
- **Arxiv ID**: http://arxiv.org/abs/2105.14693v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14693v1)
- **Published**: 2021-05-31 04:09:00+00:00
- **Updated**: 2021-05-31 04:09:00+00:00
- **Authors**: Chaehyeon Lee, Junghoon Seo, Heechul Jung
- **Comment**: 2021 CVPR Workshop
- **Journal**: None
- **Summary**: In deep learning-based object detection on remote sensing domain, nuisance factors, which affect observed variables while not affecting predictor variables, often matters because they cause domain changes. Previously, nuisance disentangled feature transformation (NDFT) was proposed to build domain-invariant feature extractor with with knowledge of nuisance factors. However, NDFT requires enormous time in a training phase, so it has been impractical. In this paper, we introduce our proposed method, A-NDFT, which is an improvement to NDFT. A-NDFT utilizes two acceleration techniques, feature replay and slow learner. Consequently, on a large-scale UAVDT benchmark, it is shown that our framework can reduce the training time of NDFT from 31 hours to 3 hours while still maintaining the performance. The code will be made publicly available online.



### CTSpine1K: A Large-Scale Dataset for Spinal Vertebrae Segmentation in Computed Tomography
- **Arxiv ID**: http://arxiv.org/abs/2105.14711v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14711v3)
- **Published**: 2021-05-31 05:34:27+00:00
- **Updated**: 2021-07-05 06:41:49+00:00
- **Authors**: Yang Deng, Ce Wang, Yuan Hui, Qian Li, Jun Li, Shiwei Luo, Mengke Sun, Quan Quan, Shuxin Yang, You Hao, Pengbo Liu, Honghu Xiao, Chunpeng Zhao, Xinbao Wu, S. Kevin Zhou
- **Comment**: None
- **Journal**: None
- **Summary**: Spine-related diseases have high morbidity and cause a huge burden of social cost. Spine imaging is an essential tool for noninvasively visualizing and assessing spinal pathology. Segmenting vertebrae in computed tomography (CT) images is the basis of quantitative medical image analysis for clinical diagnosis and surgery planning of spine diseases. Current publicly available annotated datasets on spinal vertebrae are small in size. Due to the lack of a large-scale annotated spine image dataset, the mainstream deep learning-based segmentation methods, which are data-driven, are heavily restricted. In this paper, we introduce a large-scale spine CT dataset, called CTSpine1K, curated from multiple sources for vertebra segmentation, which contains 1,005 CT volumes with over 11,100 labeled vertebrae belonging to different spinal conditions. Based on this dataset, we conduct several spinal vertebrae segmentation experiments to set the first benchmark. We believe that this large-scale dataset will facilitate further research in many spine-related image analysis tasks, including but not limited to vertebrae segmentation, labeling, 3D spine reconstruction from biplanar radiographs, image super-resolution, and enhancement.



### 1xN Pattern for Pruning Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.14713v6
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2105.14713v6)
- **Published**: 2021-05-31 05:50:33+00:00
- **Updated**: 2022-10-16 01:34:36+00:00
- **Authors**: Mingbao Lin, Yuxin Zhang, Yuchao Li, Bohong Chen, Fei Chao, Mengdi Wang, Shen Li, Yonghong Tian, Rongrong Ji
- **Comment**: Accepted by IEEE TPAMI, 2022
- **Journal**: None
- **Summary**: Though network pruning receives popularity in reducing the complexity of convolutional neural networks (CNNs), it remains an open issue to concurrently maintain model accuracy as well as achieve significant speedups on general CPUs. In this paper, we propose a novel 1xN pruning pattern to break this limitation. In particular, consecutive N output kernels with the same input channel index are grouped into one block, which serves as a basic pruning granularity of our pruning pattern. Our 1xN pattern prunes these blocks considered unimportant. We also provide a workflow of filter rearrangement that first rearranges the weight matrix in the output channel dimension to derive more influential blocks for accuracy improvements and then applies similar rearrangement to the next-layer weights in the input channel dimension to ensure correct convolutional operations. Moreover, the output computation after our 1xN pruning can be realized via a parallelized block-wise vectorized operation, leading to significant speedups on general CPUs. The efficacy of our pruning pattern is proved with experiments on ILSVRC-2012. For example, given the pruning rate of 50% and N=4, our pattern obtains about 3.0% improvements over filter pruning in the top-1 accuracy of MobileNet-V2. Meanwhile, it obtains 56.04ms inference savings on Cortex-A7 CPU over weight pruning. Our project is made available at https://github.com/lmbxmu/1xN.



### Transferable Sparse Adversarial Attack
- **Arxiv ID**: http://arxiv.org/abs/2105.14727v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14727v1)
- **Published**: 2021-05-31 06:44:58+00:00
- **Updated**: 2021-05-31 06:44:58+00:00
- **Authors**: Ziwen He, Wei Wang, Jing Dong, Tieniu Tan
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have shown their vulnerability to adversarial attacks. In this paper, we focus on sparse adversarial attack based on the $\ell_0$ norm constraint, which can succeed by only modifying a few pixels of an image. Despite a high attack success rate, prior sparse attack methods achieve a low transferability under the black-box protocol due to overfitting the target model. Therefore, we introduce a generator architecture to alleviate the overfitting issue and thus efficiently craft transferable sparse adversarial examples. Specifically, the generator decouples the sparse perturbation into amplitude and position components. We carefully design a random quantization operator to optimize these two components jointly in an end-to-end way. The experiment shows that our method has improved the transferability by a large margin under a similar sparsity setting compared with state-of-the-art methods. Moreover, our method achieves superior inference speed, 700$\times$ faster than other optimization-based methods. The code is available at https://github.com/shaguopohuaizhe/TSAA.



### Hierarchical Deep Network with Uncertainty-aware Semi-supervised Learning for Vessel Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2105.14732v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14732v1)
- **Published**: 2021-05-31 06:55:43+00:00
- **Updated**: 2021-05-31 06:55:43+00:00
- **Authors**: Chenxin Li, Wenao Ma, Liyan Sun, Xinghao Ding, Yue Huang, Guisheng Wang, Yizhou Yu
- **Comment**: None
- **Journal**: None
- **Summary**: The analysis of organ vessels is essential for computer-aided diagnosis and surgical planning. But it is not a easy task since the fine-detailed connected regions of organ vessel bring a lot of ambiguity in vessel segmentation and sub-type recognition, especially for the low-contrast capillary regions. Furthermore, recent two-staged approaches would accumulate and even amplify these inaccuracies from the first-stage whole vessel segmentation into the second-stage sub-type vessel pixel-wise classification. Moreover, the scarcity of manual annotation in organ vessels poses another challenge. In this paper, to address the above issues, we propose a hierarchical deep network where an attention mechanism localizes the low-contrast capillary regions guided by the whole vessels, and enhance the spatial activation in those areas for the sub-type vessels. In addition, we propose an uncertainty-aware semi-supervised training framework to alleviate the annotation-hungry limitation of deep models. The proposed method achieves the state-of-the-art performance in the benchmarks of both retinal artery/vein segmentation in fundus images and liver portal/hepatic vessel segmentation in CT images.



### Dual-stream Network for Visual Recognition
- **Arxiv ID**: http://arxiv.org/abs/2105.14734v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14734v4)
- **Published**: 2021-05-31 06:56:29+00:00
- **Updated**: 2021-10-27 14:58:47+00:00
- **Authors**: Mingyuan Mao, Renrui Zhang, Honghui Zheng, Peng Gao, Teli Ma, Yan Peng, Errui Ding, Baochang Zhang, Shumin Han
- **Comment**: Accepted by NeurIPS 2021
- **Journal**: None
- **Summary**: Transformers with remarkable global representation capacities achieve competitive results for visual tasks, but fail to consider high-level local pattern information in input images. In this paper, we present a generic Dual-stream Network (DS-Net) to fully explore the representation capacity of local and global pattern features for image classification. Our DS-Net can simultaneously calculate fine-grained and integrated features and efficiently fuse them. Specifically, we propose an Intra-scale Propagation module to process two different resolutions in each block and an Inter-Scale Alignment module to perform information interaction across features at dual scales. Besides, we also design a Dual-stream FPN (DS-FPN) to further enhance contextual information for downstream dense predictions. Without bells and whistles, the proposed DS-Net outperforms DeiT-Small by 2.4% in terms of top-1 accuracy on ImageNet-1k and achieves state-of-the-art performance over other Vision Transformers and ResNets. For object detection and instance segmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4% and 5.5% in terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art scheme, which significantly demonstrates its potential to be a general backbone in vision tasks. The code will be released soon.



### Semi-orthogonal Embedding for Efficient Unsupervised Anomaly Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2105.14737v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14737v1)
- **Published**: 2021-05-31 07:02:20+00:00
- **Updated**: 2021-05-31 07:02:20+00:00
- **Authors**: Jin-Hwa Kim, Do-Hyeong Kim, Saehoon Yi, Taehoon Lee
- **Comment**: None
- **Journal**: None
- **Summary**: We present the efficiency of semi-orthogonal embedding for unsupervised anomaly segmentation. The multi-scale features from pre-trained CNNs are recently used for the localized Mahalanobis distances with significant performance. However, the increased feature size is problematic to scale up to the bigger CNNs, since it requires the batch-inverse of multi-dimensional covariance tensor. Here, we generalize an ad-hoc method, random feature selection, into semi-orthogonal embedding for robust approximation, cubically reducing the computational cost for the inverse of multi-dimensional covariance tensor. With the scrutiny of ablation studies, the proposed method achieves a new state-of-the-art with significant margins for the MVTec AD, KolektorSDD, KolektorSDD2, and mSTC datasets. The theoretical and empirical analyses offer insights and verification of our straightforward yet cost-effective approach.



### Controllable Person Image Synthesis with Spatially-Adaptive Warped Normalization
- **Arxiv ID**: http://arxiv.org/abs/2105.14739v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2105.14739v3)
- **Published**: 2021-05-31 07:07:44+00:00
- **Updated**: 2023-01-10 02:30:45+00:00
- **Authors**: Jichao Zhang, Aliaksandr Siarohin, Hao Tang, Enver Sangineto, Wei Wang, Humphrey Sh, Nicu Sebe
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: Controllable person image generation aims to produce realistic human images with desirable attributes such as a given pose, cloth textures, or hairstyles. However, the large spatial misalignment between source and target images makes the standard image-to-image translation architectures unsuitable for this task. Most state-of-the-art methods focus on alignment for global pose-transfer tasks. However, they fail to deal with region-specific texture-transfer tasks, especially for person images with complex textures. To solve this problem, we propose a novel Spatially-Adaptive Warped Normalization (SAWN) which integrates a learned flow-field to warp modulation parameters. It allows us to efficiently align person spatially-adaptive styles with pose features. Moreover, we propose a novel Self-Training Part Replacement (STPR) strategy to refine the model for the texture-transfer task, which improves the quality of the generated clothes and the preservation ability of non-target regions. Our experimental results on the widely used DeepFashion dataset demonstrate a significant improvement of the proposed method over the state-of-the-art methods on pose-transfer and texture-transfer tasks. The code is available at https://github.com/zhangqianhui/Sawn.



### A Study On the Effects of Pre-processing On Spatio-temporal Action Recognition Using Spiking Neural Networks Trained with STDP
- **Arxiv ID**: http://arxiv.org/abs/2105.14740v1
- **DOI**: 10.1109/CBMI50038.2021.9461922
- **Categories**: **cs.CV**, I.4.7; I.4.8; I.5.0
- **Links**: [PDF](http://arxiv.org/pdf/2105.14740v1)
- **Published**: 2021-05-31 07:07:48+00:00
- **Updated**: 2021-05-31 07:07:48+00:00
- **Authors**: El-Assal Mireille, Tirilly Pierre, Bilasco Ioan Marius
- **Comment**: None
- **Journal**: None
- **Summary**: There has been an increasing interest in spiking neural networks in recent years. SNNs are seen as hypothetical solutions for the bottlenecks of ANNs in pattern recognition, such as energy efficiency. But current methods such as ANN-to-SNN conversion and back-propagation do not take full advantage of these networks, and unsupervised methods have not yet reached a success comparable to advanced artificial neural networks. It is important to study the behavior of SNNs trained with unsupervised learning methods such as spike-timing dependent plasticity (STDP) on video classification tasks, including mechanisms to model motion information using spikes, as this information is critical for video understanding. This paper presents multiple methods of transposing temporal information into a static format, and then transforming the visual information into spikes using latency coding. These methods are paired with two types of temporal fusion known as early and late fusion, and are used to help the spiking neural network in capturing the spatio-temporal features from videos. In this paper, we rely on the network architecture of a convolutional spiking neural network trained with STDP, and we test the performance of this network when challenged with action recognition tasks. Understanding how a spiking neural network responds to different methods of movement extraction and representation can help reduce the performance gap between SNNs and ANNs. In this paper we show the effect of the similarity in the shape and speed of certain actions on action recognition with spiking neural networks, we also highlight the effectiveness of some methods compared to others.



### Bio-inspired visual attention for silicon retinas based on spiking neural networks applied to pattern classification
- **Arxiv ID**: http://arxiv.org/abs/2105.14753v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2105.14753v1)
- **Published**: 2021-05-31 07:34:13+00:00
- **Updated**: 2021-05-31 07:34:13+00:00
- **Authors**: Amélie Gruel, Jean Martinet
- **Comment**: 6 pages, 3 figures. To be published in Content-Based Multimedia
  Indexing (CBMI) 2021, Lille, France. This work was supported by the European
  Union's ERA-NET CHIST-ERA 2018 research and innovation programme under grant
  agreement ANR-19-CHR3-0008
- **Journal**: None
- **Summary**: Visual attention can be defined as the behavioral and cognitive process of selectively focusing on a discrete aspect of sensory cues while disregarding other perceivable information. This biological mechanism, more specifically saliency detection, has long been used in multimedia indexing to drive the analysis only on relevant parts of images or videos for further processing.   The recent advent of silicon retinas (or event cameras -- sensors that measure pixel-wise changes in brightness and output asynchronous events accordingly) raises the question of how to adapt attention and saliency to the unconventional type of such sensors' output. Silicon retina aims to reproduce the biological retina behaviour. In that respect, they produce punctual events in time that can be construed as neural spikes and interpreted as such by a neural network.   In particular, Spiking Neural Networks (SNNs) represent an asynchronous type of artificial neural network closer to biology than traditional artificial networks, mainly because they seek to mimic the dynamics of neural membrane and action potentials over time. SNNs receive and process information in the form of spike trains. Therefore, they make for a suitable candidate for the efficient processing and classification of incoming event patterns measured by silicon retinas. In this paper, we review the biological background behind the attentional mechanism, and introduce a case study of event videos classification with SNNs, using a biology-grounded low-level computational attention mechanism, with interesting preliminary results.



### A Protection Method of Trained CNN Model with Secret Key from Unauthorized Access
- **Arxiv ID**: http://arxiv.org/abs/2105.14756v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2105.14756v1)
- **Published**: 2021-05-31 07:37:33+00:00
- **Updated**: 2021-05-31 07:37:33+00:00
- **Authors**: AprilPyone MaungMaung, Hitoshi Kiya
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel method for protecting convolutional neural network (CNN) models with a secret key set so that unauthorized users without the correct key set cannot access trained models. The method enables us to protect not only from copyright infringement but also the functionality of a model from unauthorized access without any noticeable overhead. We introduce three block-wise transformations with a secret key set to generate learnable transformed images: pixel shuffling, negative/positive transformation, and FFX encryption. Protected models are trained by using transformed images. The results of experiments with the CIFAR and ImageNet datasets show that the performance of a protected model was close to that of non-protected models when the key set was correct, while the accuracy severely dropped when an incorrect key set was given. The protected model was also demonstrated to be robust against various attacks. Compared with the state-of-the-art model protection with passports, the proposed method does not have any additional layers in the network, and therefore, there is no overhead during training and inference processes.



### Low-Dose CT Denoising Using a Structure-Preserving Kernel Prediction Network
- **Arxiv ID**: http://arxiv.org/abs/2105.14758v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14758v3)
- **Published**: 2021-05-31 07:42:21+00:00
- **Updated**: 2021-07-24 01:12:38+00:00
- **Authors**: Lu Xu, Yuwei Zhang, Ying Liu, Daoye Wang, Mu Zhou, Jimmy Ren, Jingwei Wei, Zhaoxiang Ye
- **Comment**: ICIP2021
- **Journal**: None
- **Summary**: Low-dose CT has been a key diagnostic imaging modality to reduce the potential risk of radiation overdose to patient health. Despite recent advances, CNN-based approaches typically apply filters in a spatially invariant way and adopt similar pixel-level losses, which treat all regions of the CT image equally and can be inefficient when fine-grained structures coexist with non-uniformly distributed noises. To address this issue, we propose a Structure-preserving Kernel Prediction Network (StructKPN) that combines the kernel prediction network with a structure-aware loss function that utilizes the pixel gradient statistics and guides the model towards spatially-variant filters that enhance noise removal, prevent over-smoothing and preserve detailed structures for different regions in CT imaging. Extensive experiments demonstrated that our approach achieved superior performance on both synthetic and non-synthetic datasets, and better preserves structures that are highly desired in clinical screening and low-dose protocol optimization.



### BaMBNet: A Blur-aware Multi-branch Network for Defocus Deblurring
- **Arxiv ID**: http://arxiv.org/abs/2105.14766v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14766v1)
- **Published**: 2021-05-31 07:55:30+00:00
- **Updated**: 2021-05-31 07:55:30+00:00
- **Authors**: Pengwei Liang, Junjun Jiang, Xianming Liu, Jiayi Ma
- **Comment**: 11 pages, 8 figures
- **Journal**: None
- **Summary**: The defocus deblurring raised from the finite aperture size and exposure time is an essential problem in the computational photography. It is very challenging because the blur kernel is spatially varying and difficult to estimate by traditional methods. Due to its great breakthrough in low-level tasks, convolutional neural networks (CNNs) have been introduced to the defocus deblurring problem and achieved significant progress. However, they apply the same kernel for different regions of the defocus blurred images, thus it is difficult to handle these nonuniform blurred images. To this end, this study designs a novel blur-aware multi-branch network (BaMBNet), in which different regions (with different blur amounts) should be treated differentially. In particular, we estimate the blur amounts of different regions by the internal geometric constraint of the DP data, which measures the defocus disparity between the left and right views. Based on the assumption that different image regions with different blur amounts have different deblurring difficulties, we leverage different networks with different capacities (\emph{i.e.} parameters) to process different image regions. Moreover, we introduce a meta-learning defocus mask generation algorithm to assign each pixel to a proper branch. In this way, we can expect to well maintain the information of the clear regions while recovering the missing details of the blurred regions. Both quantitative and qualitative experiments demonstrate that our BaMBNet outperforms the state-of-the-art methods. Source code will be available at https://github.com/junjun-jiang/BaMBNet.



### Learning Inductive Attention Guidance for Partially Supervised Pancreatic Ductal Adenocarcinoma Prediction
- **Arxiv ID**: http://arxiv.org/abs/2105.14773v1
- **DOI**: 10.1109/TMI.2021.3060066
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14773v1)
- **Published**: 2021-05-31 08:16:09+00:00
- **Updated**: 2021-05-31 08:16:09+00:00
- **Authors**: Yan Wang, Peng Tang, Yuyin Zhou, Wei Shen, Elliot K. Fishman, Alan L. Yuille
- **Comment**: None
- **Journal**: None
- **Summary**: Pancreatic ductal adenocarcinoma (PDAC) is the third most common cause of cancer death in the United States. Predicting tumors like PDACs (including both classification and segmentation) from medical images by deep learning is becoming a growing trend, but usually a large number of annotated data are required for training, which is very labor-intensive and time-consuming. In this paper, we consider a partially supervised setting, where cheap image-level annotations are provided for all the training data, and the costly per-voxel annotations are only available for a subset of them. We propose an Inductive Attention Guidance Network (IAG-Net) to jointly learn a global image-level classifier for normal/PDAC classification and a local voxel-level classifier for semi-supervised PDAC segmentation. We instantiate both the global and the local classifiers by multiple instance learning (MIL), where the attention guidance, indicating roughly where the PDAC regions are, is the key to bridging them: For global MIL based normal/PDAC classification, attention serves as a weight for each instance (voxel) during MIL pooling, which eliminates the distraction from the background; For local MIL based semi-supervised PDAC segmentation, the attention guidance is inductive, which not only provides bag-level pseudo-labels to training data without per-voxel annotations for MIL training, but also acts as a proxy of an instance-level classifier. Experimental results show that our IAG-Net boosts PDAC segmentation accuracy by more than 5% compared with the state-of-the-arts.



### SN-Graph: a Minimalist 3D Object Representation for Classification
- **Arxiv ID**: http://arxiv.org/abs/2105.14784v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14784v1)
- **Published**: 2021-05-31 08:24:09+00:00
- **Updated**: 2021-05-31 08:24:09+00:00
- **Authors**: Siyu Zhang, Hui Cao, Yuqi Liu, Shen Cai, Yanting Zhang, Yuanzhan Li, Xiaoyu Chi
- **Comment**: ICME 2021
- **Journal**: None
- **Summary**: Using deep learning techniques to process 3D objects has achieved many successes. However, few methods focus on the representation of 3D objects, which could be more effective for specific tasks than traditional representations, such as point clouds, voxels, and multi-view images. In this paper, we propose a Sphere Node Graph (SN-Graph) to represent 3D objects. Specifically, we extract a certain number of internal spheres (as nodes) from the signed distance field (SDF), and then establish connections (as edges) among the sphere nodes to construct a graph, which is seamlessly suitable for 3D analysis using graph neural network (GNN). Experiments conducted on the ModelNet40 dataset show that when there are fewer nodes in the graph or the tested objects are rotated arbitrarily, the classification accuracy of SN-Graph is significantly higher than the state-of-the-art methods.



### Two Coupled Rejection Metrics Can Tell Adversarial Examples Apart
- **Arxiv ID**: http://arxiv.org/abs/2105.14785v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14785v4)
- **Published**: 2021-05-31 08:24:53+00:00
- **Updated**: 2022-03-31 16:56:39+00:00
- **Authors**: Tianyu Pang, Huishuai Zhang, Di He, Yinpeng Dong, Hang Su, Wei Chen, Jun Zhu, Tie-Yan Liu
- **Comment**: CVPR 2022
- **Journal**: None
- **Summary**: Correctly classifying adversarial examples is an essential but challenging requirement for safely deploying machine learning models. As reported in RobustBench, even the state-of-the-art adversarially trained models struggle to exceed 67% robust test accuracy on CIFAR-10, which is far from practical. A complementary way towards robustness is to introduce a rejection option, allowing the model to not return predictions on uncertain inputs, where confidence is a commonly used certainty proxy. Along with this routine, we find that confidence and a rectified confidence (R-Con) can form two coupled rejection metrics, which could provably distinguish wrongly classified inputs from correctly classified ones. This intriguing property sheds light on using coupling strategies to better detect and reject adversarial examples. We evaluate our rectified rejection (RR) module on CIFAR-10, CIFAR-10-C, and CIFAR-100 under several attacks including adaptive ones, and demonstrate that the RR module is compatible with different adversarial training frameworks on improving robustness, with little extra computation. The code is available at https://github.com/P2333/Rectified-Rejection.



### Predicting Driver Intention Using Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2105.14790v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14790v2)
- **Published**: 2021-05-31 08:34:57+00:00
- **Updated**: 2021-06-01 12:48:51+00:00
- **Authors**: Mahdi Bonyani, Mina Rahmanian, Simindokht Jahangard
- **Comment**: None
- **Journal**: None
- **Summary**: To improve driving safety and avoid car accidents, Advanced Driver Assistance Systems (ADAS) are given significant attention. Recent studies have focused on predicting driver intention as a key part of these systems. In this study, we proposed new framework in which 4 inputs are employed to anticipate diver maneuver using Brain4Cars dataset and the maneuver prediction is achieved from 5, 4, 3, 2, 1 seconds before the actual action occurs. We evaluated our framework in three scenarios: using only 1) inside view 2) outside view and 3) both inside and outside view. We divided the dataset into training, validation and test sets, also K-fold cross validation is utilized. Compared with state-of-the-art studies, our architecture is faster and achieved higher performance in second and third scenario. Accuracy, precision, recall and f1-score as evaluation metrics were utilized and the result of 82.41%, 82.28%, 82,42% and 82.24% for outside view and 98.90%, 98.96%, 98.90% and 98.88% for both inside and outside view were gained, respectively.



### RED : Looking for Redundancies for Data-Free Structured Compression of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.14797v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14797v1)
- **Published**: 2021-05-31 08:44:14+00:00
- **Updated**: 2021-05-31 08:44:14+00:00
- **Authors**: Edouard Yvinec, Arnaud Dapogny, Matthieu Cord, Kevin Bailly
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) are ubiquitous in today's computer vision land-scape, despite involving considerable computational costs. The mainstream approaches for runtime acceleration consist in pruning connections (unstructured pruning) or, better, filters (structured pruning), both often requiring data to re-train the model. In this paper, we present RED, a data-free structured, unified approach to tackle structured pruning. First, we propose a novel adaptive hashing of the scalar DNN weight distribution densities to increase the number of identical neurons represented by their weight vectors. Second, we prune the network by merging redundant neurons based on their relative similarities, as defined by their distance. Third, we propose a novel uneven depthwise separation technique to further prune convolutional layers. We demonstrate through a large variety of benchmarks that RED largely outperforms other data-free pruning methods, often reaching performance similar to unconstrained, data-driven methods.



### Scene-aware Generative Network for Human Motion Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2105.14804v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14804v1)
- **Published**: 2021-05-31 09:05:50+00:00
- **Updated**: 2021-05-31 09:05:50+00:00
- **Authors**: Jingbo Wang, Sijie Yan, Bo Dai, Dahua LIn
- **Comment**: Accepted by CVPR2021
- **Journal**: None
- **Summary**: We revisit human motion synthesis, a task useful in various real world applications, in this paper. Whereas a number of methods have been developed previously for this task, they are often limited in two aspects: focusing on the poses while leaving the location movement behind, and ignoring the impact of the environment on the human motion. In this paper, we propose a new framework, with the interaction between the scene and the human motion taken into account. Considering the uncertainty of human motion, we formulate this task as a generative task, whose objective is to generate plausible human motion conditioned on both the scene and the human initial position. This framework factorizes the distribution of human motions into a distribution of movement trajectories conditioned on scenes and that of body pose dynamics conditioned on both scenes and trajectories. We further derive a GAN based learning approach, with discriminators to enforce the compatibility between the human motion and the contextual scene as well as the 3D to 2D projection constraints. We assess the effectiveness of the proposed method on two challenging datasets, which cover both synthetic and real world environments.



### Bounded logit attention: Learning to explain image classifiers
- **Arxiv ID**: http://arxiv.org/abs/2105.14824v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14824v1)
- **Published**: 2021-05-31 09:36:05+00:00
- **Updated**: 2021-05-31 09:36:05+00:00
- **Authors**: Thomas Baumhauer, Djordje Slijepcevic, Matthias Zeppelzauer
- **Comment**: None
- **Journal**: None
- **Summary**: Explainable artificial intelligence is the attempt to elucidate the workings of systems too complex to be directly accessible to human cognition through suitable side-information referred to as "explanations". We present a trainable explanation module for convolutional image classifiers we call bounded logit attention (BLA). The BLA module learns to select a subset of the convolutional feature map for each input instance, which then serves as an explanation for the classifier's prediction. BLA overcomes several limitations of the instancewise feature selection method "learning to explain" (L2X) introduced by Chen et al. (2018): 1) BLA scales to real-world sized image classification problems, and 2) BLA offers a canonical way to learn explanations of variable size. Due to its modularity BLA lends itself to transfer learning setups and can also be employed as a post-hoc add-on to trained classifiers. Beyond explainability, BLA may serve as a general purpose method for differentiable approximation of subset selection. In a user study we find that BLA explanations are preferred over explanations generated by the popular (Grad-)CAM method.



### Q-attention: Enabling Efficient Learning for Vision-based Robotic Manipulation
- **Arxiv ID**: http://arxiv.org/abs/2105.14829v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14829v2)
- **Published**: 2021-05-31 09:44:16+00:00
- **Updated**: 2022-02-04 01:01:14+00:00
- **Authors**: Stephen James, Andrew J. Davison
- **Comment**: IEEE Robotics and Automation Letters, 2022 (+ presentation at ICRA
  2022). Videos and code found at: https://sites.google.com/view/q-attention
- **Journal**: None
- **Summary**: Despite the success of reinforcement learning methods, they have yet to have their breakthrough moment when applied to a broad range of robotic manipulation tasks. This is partly due to the fact that reinforcement learning algorithms are notoriously difficult and time consuming to train, which is exacerbated when training from images rather than full-state inputs. As humans perform manipulation tasks, our eyes closely monitor every step of the process with our gaze focusing sequentially on the objects being manipulated. With this in mind, we present our Attention-driven Robotic Manipulation (ARM) algorithm, which is a general manipulation algorithm that can be applied to a range of sparse-rewarded tasks, given only a small number of demonstrations. ARM splits the complex task of manipulation into a 3 stage pipeline: (1) a Q-attention agent extracts relevant pixel locations from RGB and point cloud inputs, (2) a next-best pose agent that accepts crops from the Q-attention agent and outputs poses, and (3) a control agent that takes the goal pose and outputs joint actions. We show that current learning algorithms fail on a range of RLBench tasks, whilst ARM is successful.



### Demographic Fairness in Biometric Systems: What do the Experts say?
- **Arxiv ID**: http://arxiv.org/abs/2105.14844v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14844v2)
- **Published**: 2021-05-31 09:58:51+00:00
- **Updated**: 2023-01-08 10:18:10+00:00
- **Authors**: Christian Rathgeb, Pawel Drozdowski, Naser Damer, Dinusha C. Frings, Christoph Busch
- **Comment**: None
- **Journal**: None
- **Summary**: Algorithmic decision systems have frequently been labelled as "biased", "racist", "sexist", or "unfair" by numerous media outlets, organisations, and researchers. There is an ongoing debate whether such assessments are justified and whether citizens and policymakers should be concerned. These and other related matters have recently become a hot topic in the context of biometric technologies, which are ubiquitous in personal, commercial, and governmental applications. Biometrics represent an essential component of many surveillance, access control, and operational identity management systems, thus directly or indirectly affecting billions of people all around the world. In order to provide a forum for experts in the field, the European Association for Biometrics organised an event series with "demographic fairness in biometric systems" as an overarching theme. The events featured presentations by international experts from academic, industry, and governmental organisations and facilitated interactions and discussions between the experts and the audience. Further consultation of experts was undertaken by means of a questionnaire. This work summarises opinions of experts and findings of said events on the topic of demographic fairness in biometric systems including several important aspects such as the developments of evaluation metrics and standards as well as related issues, e.g. the need for transparency and explainability in biometric systems or legal and ethical issues.



### Refined Deep Neural Network and U-Net for Polyps Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2105.14848v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.14848v1)
- **Published**: 2021-05-31 10:02:52+00:00
- **Updated**: 2021-05-31 10:02:52+00:00
- **Authors**: Quoc-Huy Trinh, Minh-Van Nguyen, Thiet-Gia Huynh, Minh-Triet Tran
- **Comment**: None
- **Journal**: None
- **Summary**: The Medico: Multimedia Task 2020 focuses on developing an efficient and accurate computer-aided diagnosis system for automatic segmentation [3]. We participate in task 1, Polyps segmentation task, which is to develop algorithms for segmenting polyps on a comprehensive dataset. In this task, we propose methods combining Residual module, Inception module, Adaptive Convolutional neural network with U-Net model, and PraNet for semantic segmentation of various types of polyps in endoscopic images. We select 5 runs with different architecture and parameters in our methods. Our methods show potential results in accuracy and efficiency through multiple experiments, and our team is in the Top 3 best results with a Jaccard index of 0.765.



### Learning Free-Form Deformation for 3D Face Reconstruction from In-The-Wild Images
- **Arxiv ID**: http://arxiv.org/abs/2105.14857v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14857v2)
- **Published**: 2021-05-31 10:19:20+00:00
- **Updated**: 2021-08-14 13:06:19+00:00
- **Authors**: Harim Jung, Myeong-Seok Oh, Seong-Whan Lee
- **Comment**: Accepted to SMC 2021
- **Journal**: None
- **Summary**: The 3D Morphable Model (3DMM), which is a Principal Component Analysis (PCA) based statistical model that represents a 3D face using linear basis functions, has shown promising results for reconstructing 3D faces from single-view in-the-wild images. However, 3DMM has restricted representation power due to the limited number of 3D scans and the global linear basis. To address the limitations of 3DMM, we propose a straightforward learning-based method that reconstructs a 3D face mesh through Free-Form Deformation (FFD) for the first time. FFD is a geometric modeling method that embeds a reference mesh within a parallelepiped grid and deforms the mesh by moving the sparse control points of the grid. As FFD is based on mathematically defined basis functions, it has no limitation in representation power. Thus, we can recover accurate 3D face meshes by estimating appropriate deviation of control points as deformation parameters. Although both 3DMM and FFD are parametric models, it is difficult to predict the effect of the 3DMM parameters on the face shape, while the deformation parameters of FFD are interpretable in terms of their effect on the final shape of the mesh. This practical advantage of FFD allows the resulting mesh and control points to serve as a good starting point for 3D face modeling, in that ordinary users can fine-tune the mesh by using widely available 3D software tools. Experiments on multiple datasets demonstrate how our method successfully estimates the 3D face geometry and facial expressions from 2D face images, achieving comparable performance to the state-of-the-art methods.



### Consistency Regularization for Variational Auto-Encoders
- **Arxiv ID**: http://arxiv.org/abs/2105.14859v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14859v2)
- **Published**: 2021-05-31 10:26:32+00:00
- **Updated**: 2022-06-06 19:16:30+00:00
- **Authors**: Samarth Sinha, Adji B. Dieng
- **Comment**: None
- **Journal**: NeurIPS 2021
- **Summary**: Variational auto-encoders (VAEs) are a powerful approach to unsupervised learning. They enable scalable approximate posterior inference in latent-variable models using variational inference (VI). A VAE posits a variational family parameterized by a deep neural network called an encoder that takes data as input. This encoder is shared across all the observations, which amortizes the cost of inference. However the encoder of a VAE has the undesirable property that it maps a given observation and a semantics-preserving transformation of it to different latent representations. This "inconsistency" of the encoder lowers the quality of the learned representations, especially for downstream tasks, and also negatively affects generalization. In this paper, we propose a regularization method to enforce consistency in VAEs. The idea is to minimize the Kullback-Leibler (KL) divergence between the variational distribution when conditioning on the observation and the variational distribution when conditioning on a random semantic-preserving transformation of this observation. This regularization is applicable to any VAE. In our experiments we apply it to four different VAE variants on several benchmark datasets and found it always improves the quality of the learned representations but also leads to better generalization. In particular, when applied to the Nouveau Variational Auto-Encoder (NVAE), our regularization method yields state-of-the-art performance on MNIST and CIFAR-10. We also applied our method to 3D data and found it learns representations of superior quality as measured by accuracy on a downstream classification task.



### ACNet: Mask-Aware Attention with Dynamic Context Enhancement for Robust Acne Detection
- **Arxiv ID**: http://arxiv.org/abs/2105.14891v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14891v3)
- **Published**: 2021-05-31 11:31:45+00:00
- **Updated**: 2021-12-17 05:05:15+00:00
- **Authors**: Kyungseo Min, Gun-Hee Lee, Seong-Whan Lee
- **Comment**: 6 pages, 5 figures, SMC 2021
- **Journal**: None
- **Summary**: Computer-aided diagnosis has recently received attention for its advantage of low cost and time efficiency. Although deep learning played a major role in the recent success of acne detection, there are still several challenges such as color shift by inconsistent illumination, variation in scales, and high density distribution. To address these problems, we propose an acne detection network which consists of three components, specifically: Composite Feature Refinement, Dynamic Context Enhancement, and Mask-Aware Multi-Attention. First, Composite Feature Refinement integrates semantic information and fine details to enrich feature representation, which mitigates the adverse impact of imbalanced illumination. Then, Dynamic Context Enhancement controls different receptive fields of multi-scale features for context enhancement to handle scale variation. Finally, Mask-Aware Multi-Attention detects densely arranged and small acne by suppressing uninformative regions and highlighting probable acne regions. Experiments are performed on acne image dataset ACNE04 and natural image dataset PASCAL VOC 2007. We demonstrate how our method achieves the state-of-the-art result on ACNE04 and competitive performance with previous state-of-the-art methods on the PASCAL VOC 2007.



### Connecting Language and Vision for Natural Language-Based Vehicle Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2105.14897v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14897v1)
- **Published**: 2021-05-31 11:42:03+00:00
- **Updated**: 2021-05-31 11:42:03+00:00
- **Authors**: Shuai Bai, Zhedong Zheng, Xiaohan Wang, Junyang Lin, Zhu Zhang, Chang Zhou, Yi Yang, Hongxia Yang
- **Comment**: CVPR 2021 AI CITY CHALLENGE Natural Language-Based Vehicle Retrieval
  Top 1
- **Journal**: None
- **Summary**: Vehicle search is one basic task for the efficient traffic management in terms of the AI City. Most existing practices focus on the image-based vehicle matching, including vehicle re-identification and vehicle tracking. In this paper, we apply one new modality, i.e., the language description, to search the vehicle of interest and explore the potential of this task in the real-world scenario. The natural language-based vehicle search poses one new challenge of fine-grained understanding of both vision and language modalities. To connect language and vision, we propose to jointly train the state-of-the-art vision models with the transformer-based language model in an end-to-end manner. Except for the network structure design and the training strategy, several optimization objectives are also re-visited in this work. The qualitative and quantitative experiments verify the effectiveness of the proposed method. Our proposed method has achieved the 1st place on the 5th AI City Challenge, yielding competitive performance 18.69% MRR accuracy on the private test set. We hope this work can pave the way for the future study on using language description effectively and efficiently for real-world vehicle retrieval systems. The code will be available at https://github.com/ShuaiBai623/AIC2021-T5-CLV.



### Similarity Embedding Networks for Robust Human Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/2106.15283v1
- **DOI**: 10.1145/3448021
- **Categories**: **cs.CV**, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2106.15283v1)
- **Published**: 2021-05-31 11:52:32+00:00
- **Updated**: 2021-05-31 11:52:32+00:00
- **Authors**: Chenglin Li, Carrie Lu Tong, Di Niu, Bei Jiang, Xiao Zuo, Lei Cheng, Jian Xiong, Jianming Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning models for human activity recognition (HAR) based on sensor data have been heavily studied recently. However, the generalization ability of deep models on complex real-world HAR data is limited by the availability of high-quality labeled activity data, which are hard to obtain. In this paper, we design a similarity embedding neural network that maps input sensor signals onto real vectors through carefully designed convolutional and LSTM layers. The embedding network is trained with a pairwise similarity loss, encouraging the clustering of samples from the same class in the embedded real space, and can be effectively trained on a small dataset and even on a noisy dataset with mislabeled samples. Based on the learned embeddings, we further propose both nonparametric and parametric approaches for activity recognition. Extensive evaluation based on two public datasets has shown that the proposed similarity embedding network significantly outperforms state-of-the-art deep models on HAR classification tasks, is robust to mislabeled samples in the training set, and can also be used to effectively denoise a noisy dataset.



### WiCluster: Passive Indoor 2D/3D Positioning using WiFi without Precise Labels
- **Arxiv ID**: http://arxiv.org/abs/2107.01002v2
- **DOI**: None
- **Categories**: **cs.NI**, cs.CV, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2107.01002v2)
- **Published**: 2021-05-31 12:09:46+00:00
- **Updated**: 2021-09-27 13:42:44+00:00
- **Authors**: Ilia Karmanov, Farhad G. Zanjani, Simone Merlin, Ishaque Kadampot, Daniel Dijkman
- **Comment**: IEEE Globecom 2021
- **Journal**: None
- **Summary**: We introduce WiCluster, a new machine learning (ML) approach for passive indoor positioning using radio frequency (RF) channel state information (CSI). WiCluster can predict both a zone-level position and a precise 2D or 3D position, without using any precise position labels during training. Prior CSI-based indoor positioning work has relied on non-parametric approaches using digital signal-processing (DSP) and, more recently, parametric approaches (e.g., fully supervised ML methods). However these do not handle the complexity of real-world environments well and do not meet requirements for large-scale commercial deployments: the accuracy of DSP-based method deteriorates significantly in non-line-of-sight conditions, while supervised ML methods need large amounts of hard-to-acquire centimeter accuracy position labels. In contrast, WiCluster is precise, requires weaker label-information that can be easily collected, and works well in non-line-of-sight conditions. Our first contribution is a novel dimensionality reduction method for charting. It combines a triplet-loss with a multi-scale clustering-loss to map the high-dimensional CSI representation to a 2D/3D latent space. Our second contribution is two weakly supervised losses that map this latent space into a Cartesian map, resulting in meter-accuracy position results. These losses only require simple to acquire priors: a sketch of the floorplan, approximate access-point locations and a few CSI packets that are labelled with the corresponding zone in the floorplan. Thirdly, we report results and a robustness study for 2D positioning in two single-floor office buildings and 3D positioning in a two-story home.



### The effectiveness of feature attribution methods and its correlation with automatic evaluation scores
- **Arxiv ID**: http://arxiv.org/abs/2105.14944v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2105.14944v5)
- **Published**: 2021-05-31 13:23:50+00:00
- **Updated**: 2022-07-22 05:44:50+00:00
- **Authors**: Giang Nguyen, Daeyoung Kim, Anh Nguyen
- **Comment**: NeurIPS 2021; 10 pages of Main text; 28 pages of Appendix
- **Journal**: None
- **Summary**: Explaining the decisions of an Artificial Intelligence (AI) model is increasingly critical in many real-world, high-stake applications. Hundreds of papers have either proposed new feature attribution methods, discussed or harnessed these tools in their work. However, despite humans being the target end-users, most attribution methods were only evaluated on proxy automatic-evaluation metrics (Zhang et al. 2018; Zhou et al. 2016; Petsiuk et al. 2018). In this paper, we conduct the first user study to measure attribution map effectiveness in assisting humans in ImageNet classification and Stanford Dogs fine-grained classification, and when an image is natural or adversarial (i.e., contains adversarial perturbations). Overall, feature attribution is surprisingly not more effective than showing humans nearest training-set examples. On a harder task of fine-grained dog categorization, presenting attribution maps to humans does not help, but instead hurts the performance of human-AI teams compared to AI alone. Importantly, we found automatic attribution-map evaluation measures to correlate poorly with the actual human-AI team performance. Our findings encourage the community to rigorously test their methods on the downstream human-in-the-loop applications and to rethink the existing evaluation metrics.



### SNIPS: Solving Noisy Inverse Problems Stochastically
- **Arxiv ID**: http://arxiv.org/abs/2105.14951v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14951v2)
- **Published**: 2021-05-31 13:33:21+00:00
- **Updated**: 2021-11-10 12:33:35+00:00
- **Authors**: Bahjat Kawar, Gregory Vaksman, Michael Elad
- **Comment**: Thirty-Fifth Conference on Neural Information Processing Systems
  (NeurIPS), 2021
- **Journal**: None
- **Summary**: In this work we introduce a novel stochastic algorithm dubbed SNIPS, which draws samples from the posterior distribution of any linear inverse problem, where the observation is assumed to be contaminated by additive white Gaussian noise. Our solution incorporates ideas from Langevin dynamics and Newton's method, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian denoiser. The proposed approach relies on an intricate derivation of the posterior score function that includes a singular value decomposition (SVD) of the degradation operator, in order to obtain a tractable iterative algorithm for the desired sampling. Due to its stochasticity, the algorithm can produce multiple high perceptual quality samples for the same noisy observation. We demonstrate the abilities of the proposed paradigm for image deblurring, super-resolution, and compressive sensing. We show that the samples produced are sharp, detailed and consistent with the given measurements, and their diversity exposes the inherent uncertainty in the inverse problem being solved.



### VidFace: A Full-Transformer Solver for Video FaceHallucination with Unaligned Tiny Snapshots
- **Arxiv ID**: http://arxiv.org/abs/2105.14954v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14954v1)
- **Published**: 2021-05-31 13:40:41+00:00
- **Updated**: 2021-05-31 13:40:41+00:00
- **Authors**: Yuan Gan, Yawei Luo, Xin Yu, Bang Zhang, Yi Yang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we investigate the task of hallucinating an authentic high-resolution (HR) human face from multiple low-resolution (LR) video snapshots. We propose a pure transformer-based model, dubbed VidFace, to fully exploit the full-range spatio-temporal information and facial structure cues among multiple thumbnails. Specifically, VidFace handles multiple snapshots all at once and harnesses the spatial and temporal information integrally to explore face alignments across all the frames, thus avoiding accumulating alignment errors. Moreover, we design a recurrent position embedding module to equip our transformer with facial priors, which not only effectively regularises the alignment mechanism but also supplants notorious pre-training. Finally, we curate a new large-scale video face hallucination dataset from the public Voxceleb2 benchmark, which challenges prior arts on tackling unaligned and tiny face snapshots. To the best of our knowledge, we are the first attempt to develop a unified transformer-based solver tailored for video-based face hallucination. Extensive experiments on public video face benchmarks show that the proposed method significantly outperforms the state of the arts.



### Boosting the Performance of Video Compression Artifact Reduction with Reference Frame Proposals and Frequency Domain Information
- **Arxiv ID**: http://arxiv.org/abs/2105.14962v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.14962v1)
- **Published**: 2021-05-31 13:46:11+00:00
- **Updated**: 2021-05-31 13:46:11+00:00
- **Authors**: Yi Xu, Minyi Zhao, Jing Liu, Xinjian Zhang, Longwen Gao, Shuigeng Zhou, Huyang Sun
- **Comment**: CPVR Workshop, NTIRE 2021
- **Journal**: None
- **Summary**: Many deep learning based video compression artifact removal algorithms have been proposed to recover high-quality videos from low-quality compressed videos. Recently, methods were proposed to mine spatiotemporal information via utilizing multiple neighboring frames as reference frames. However, these post-processing methods take advantage of adjacent frames directly, but neglect the information of the video itself, which can be exploited. In this paper, we propose an effective reference frame proposal strategy to boost the performance of the existing multi-frame approaches. Besides, we introduce a loss based on fast Fourier transformation~(FFT) to further improve the effectiveness of restoration. Experimental results show that our method achieves better fidelity and perceptual performance on MFQE 2.0 dataset than the state-of-the-art methods. And our method won Track 1 and Track 2, and was ranked the 2nd in Track 3 of NTIRE 2021 Quality enhancement of heavily compressed videos Challenge.



### Non-Convex Tensor Low-Rank Approximation for Infrared Small Target Detection
- **Arxiv ID**: http://arxiv.org/abs/2105.14974v2
- **DOI**: 10.1109/TGRS.2021.3130310
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14974v2)
- **Published**: 2021-05-31 14:04:58+00:00
- **Updated**: 2021-11-21 02:16:08+00:00
- **Authors**: Ting Liu, Jungang Yang, Boyang Li, Chao Xiao, Yang Sun, Yingqian Wang, Wei An
- **Comment**: This paper is accepted by IEEE Transactions on Geoscience and Remote
  Sensing
- **Journal**: None
- **Summary**: Infrared small target detection is an important fundamental task in the infrared system. Therefore, many infrared small target detection methods have been proposed, in which the low-rank model has been used as a powerful tool. However, most low-rank-based methods assign the same weights for different singular values, which will lead to inaccurate background estimation. Considering that different singular values have different importance and should be treated discriminatively, in this paper, we propose a non-convex tensor low-rank approximation (NTLA) method for infrared small target detection. In our method, NTLA regularization adaptively assigns different weights to different singular values for accurate background estimation. Based on the proposed NTLA, we propose asymmetric spatial-temporal total variation (ASTTV) regularization to achieve more accurate background estimation in complex scenes. Compared with the traditional total variation approach, ASTTV exploits different smoothness intensities for spatial and temporal regularization. We design an efficient algorithm to find the optimal solution of our method. Compared with some state-of-the-art methods, the proposed method achieves an improvement in terms of various evaluation metrics. Extensive experimental results in various complex scenes demonstrate that our method has strong robustness and low false-alarm rate. Code is available at https://github.com/LiuTing20a/ASTTV-NTLA.



### Feasibility Assessment of Multitasking in MRI Neuroimaging Analysis: Tissue Segmentation, Cross-Modality Conversion and Bias correction
- **Arxiv ID**: http://arxiv.org/abs/2105.14986v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2105.14986v1)
- **Published**: 2021-05-31 14:16:28+00:00
- **Updated**: 2021-05-31 14:16:28+00:00
- **Authors**: Mohammad Eslami, Solale Tabarestani, Malek Adjouadi
- **Comment**: None
- **Journal**: None
- **Summary**: Neuroimaging is essential in brain studies for the diagnosis and identification of disease, structure, and function of the brain in its healthy and disease states. Literature shows that there are advantages of multitasking with some deep learning (DL) schemes in challenging neuroimaging applications. This study examines the feasibility of using multitasking in three different applications, including tissue segmentation, cross-modality conversion, and bias-field correction. These applications reflect five different scenarios in which multitasking is explored and 280 training and testing sessions conducted for empirical evaluations. Two well-known networks, U-Net as a well-known convolutional neural network architecture, and a closed architecture based on the conditional generative adversarial network are implemented. Different metrics such as the normalized cross-correlation coefficient and Dice scores are used for comparison of methods and results of the different experiments. Statistical analysis is also provided by paired t-test. The present study explores the pros and cons of these methods and their practical impacts on multitasking in different implementation scenarios. This investigation shows that bias correction and cross-modality conversion applications are significantly easier than the segmentation application, and having multitasking with segmentation is not reasonable if one of them is identified as the main target application. However, when the main application is the segmentation of tissues, multitasking with cross-modality conversion is beneficial, especially for the U-net architecture.



### Urban Traffic Surveillance (UTS): A fully probabilistic 3D tracking approach based on 2D detections
- **Arxiv ID**: http://arxiv.org/abs/2105.14993v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.14993v2)
- **Published**: 2021-05-31 14:29:02+00:00
- **Updated**: 2021-06-01 12:59:51+00:00
- **Authors**: Henry Bradler, Adrian Kretz, Rudolf Mester
- **Comment**: Accepted at the 2021 IEEE Intelligent Vehicles Symposium (IV),
  Nagoya, Japan, July 11-17, 2021
- **Journal**: None
- **Summary**: Urban Traffic Surveillance (UTS) is a surveillance system based on a monocular and calibrated video camera that detects vehicles in an urban traffic scenario with dense traffic on multiple lanes and vehicles performing sharp turning maneuvers. UTS then tracks the vehicles using a 3D bounding box representation and a physically reasonable 3D motion model relying on an unscented Kalman filter based approach. Since UTS recovers positions, shape and motion information in a three-dimensional world coordinate system, it can be employed to recognize diverse traffic violations or to supply intelligent vehicles with valuable traffic information. We build on YOLOv3 as a detector yielding 2D bounding boxes and class labels for each vehicle. A 2D detector renders our system much more independent to different camera perspectives as a variety of labeled training data is available. This allows for a good generalization while also being more hardware efficient. The task of 3D tracking based on 2D detections is supported by integrating class specific prior knowledge about the vehicle shape. We quantitatively evaluate UTS using self generated synthetic data and ground truth from the CARLA simulator, due to the non-existence of datasets with an urban vehicle surveillance setting and labeled 3D bounding boxes. Additionally, we give a qualitative impression of how UTS performs on real-world data. Our implementation is capable of operating in real time on a reasonably modern workstation. To the best of our knowledge, UTS is to date the only 3D vehicle tracking system in a surveillance scenario (static camera observing moving targets).



### MAOMaps: A Photo-Realistic Benchmark For vSLAM and Map Merging Quality Assessment
- **Arxiv ID**: http://arxiv.org/abs/2105.14994v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2105.14994v1)
- **Published**: 2021-05-31 14:30:36+00:00
- **Updated**: 2021-05-31 14:30:36+00:00
- **Authors**: Andrey Bokovoy, Kirill Muravyev, Konstantin Yakovlev
- **Comment**: submitted to ECMR-2021
- **Journal**: None
- **Summary**: Running numerous experiments in simulation is a necessary step before deploying a control system on a real robot. In this paper we introduce a novel benchmark that is aimed at quantitatively evaluating the quality of vision-based simultaneous localization and mapping (vSLAM) and map merging algorithms. The benchmark consists of both a dataset and a set of tools for automatic evaluation. The dataset is photo-realistic and provides both the localization and the map ground truth data. This makes it possible to evaluate not only the localization part of the SLAM pipeline but the mapping part as well. To compare the vSLAM-built maps and the ground-truth ones we introduce a novel way to find correspondences between them that takes the SLAM context into account (as opposed to other approaches like nearest neighbors). The benchmark is ROS-compatable and is open-sourced to the community.   The data and the code are available at: \texttt{github.com/CnnDepth/MAOMaps}.



### Integrating Contextual Knowledge to Visual Features for Fine Art Classification
- **Arxiv ID**: http://arxiv.org/abs/2105.15028v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.15028v2)
- **Published**: 2021-05-31 15:09:05+00:00
- **Updated**: 2021-09-28 20:05:46+00:00
- **Authors**: Giovanna Castellano, Giovanni Sansaro, Gennaro Vessio
- **Comment**: Typos corrected. Added classification experiment. Accepted at
  DL4KG2021
- **Journal**: None
- **Summary**: Automatic art analysis has seen an ever-increasing interest from the pattern recognition and computer vision community. However, most of the current work is mainly based solely on digitized artwork images, sometimes supplemented with some metadata and textual comments. A knowledge graph that integrates a rich body of information about artworks, artists, painting schools, etc., in a unified structured framework can provide a valuable resource for more powerful information retrieval and knowledge discovery tools in the artistic domain. To this end, this paper presents ArtGraph: an artistic knowledge graph based on WikiArt and DBpedia. The graph, implemented in Neo4j, already provides knowledge discovery capabilities without having to train a learning system. In addition, the embeddings extracted from the graph are used to inject "contextual" knowledge into a deep learning model to improve the accuracy of artwork attribute prediction tasks.



### A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]
- **Arxiv ID**: http://arxiv.org/abs/2105.15034v2
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.15034v2)
- **Published**: 2021-05-31 15:13:00+00:00
- **Updated**: 2021-06-03 07:14:13+00:00
- **Authors**: Fei Tang, Michael Kopp
- **Comment**: 1 page, 8 formulae
- **Journal**: None
- **Summary**: In their recent paper titled "Large Associative Memory Problem in Neurobiology and Machine Learning" [arXiv:2008.06996] the authors gave a biologically plausible microscopic theory from which one can recover many dense associative memory models discussed in the literature. We show that the layers of the recent "MLP-mixer" [arXiv:2105.01601] as well as the essentially equivalent model in [arXiv:2105.02723] are amongst them.



### Scorpion detection and classification systems based on computer vision and deep learning for health security purposes
- **Arxiv ID**: http://arxiv.org/abs/2105.15041v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.15041v1)
- **Published**: 2021-05-31 15:26:09+00:00
- **Updated**: 2021-05-31 15:26:09+00:00
- **Authors**: Francisco Luis Giambelluca, Marcelo A. Cappelletti, Jorge Osio, Luis A. Giambelluca
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, two novel automatic and real-time systems for the detection and classification of two genera of scorpions found in La Plata city (Argentina) were developed using computer vision and deep learning techniques. The object detection technique was implemented with two different methods, YOLO (You Only Look Once) and MobileNet, based on the shape features of the scorpions. High accuracy values of 88% and 91%, and high recall values of 90% and 97%, have been achieved for both models, respectively, which guarantees that they can successfully detect scorpions. In addition, the MobileNet method has been shown to have excellent performance to detect scorpions within an uncontrolled environment and to perform multiple detections. The MobileNet model was also used for image classification in order to successfully distinguish between dangerous scorpion (Tityus) and non-dangerous scorpion (Bothriurus) with the purpose of providing a health security tool. Applications for smartphones were developed, with the advantage of the portability of the systems, which can be used as a help tool for emergency services, or for biological research purposes. The developed systems can be easily scalable to other genera and species of scorpions to extend the region where these applications can be used.



### An ordinal CNN approach for the assessment of neurological damage in Parkinson's disease patients
- **Arxiv ID**: http://arxiv.org/abs/2106.05230v1
- **DOI**: 10.1016/j.eswa.2021.115271
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.05230v1)
- **Published**: 2021-05-31 15:38:59+00:00
- **Updated**: 2021-05-31 15:38:59+00:00
- **Authors**: Javier Barbero-Gómez, Pedro-Antonio Gutiérrez, Víctor-Manuel Vargas, Juan-Antonio Vallejo-Casas, César Hervás-Martínez
- **Comment**: To be published in Expert Systems with Applications, 33 pages, 6
  figures
- **Journal**: None
- **Summary**: 3D image scans are an assessment tool for neurological damage in Parkinson's disease (PD) patients. This diagnosis process can be automatized to help medical staff through Decision Support Systems (DSSs), and Convolutional Neural Networks (CNNs) are good candidates, because they are effective when applied to spatial data. This paper proposes a 3D CNN ordinal model for assessing the level or neurological damage in PD patients. Given that CNNs need large datasets to achieve acceptable performance, a data augmentation method is adapted to work with spatial data. We consider the Ordinal Graph-based Oversampling via Shortest Paths (OGO-SP) method, which applies a gamma probability distribution for inter-class data generation. A modification of OGO-SP is proposed, the OGO-SP-$\beta$ algorithm, which applies the beta distribution for generating synthetic samples in the inter-class region, a better suited distribution when compared to gamma. The evaluation of the different methods is based on a novel 3D image dataset provided by the Hospital Universitario 'Reina Sof\'ia' (C\'ordoba, Spain). We show how the ordinal methodology improves the performance with respect to the nominal one, and how OGO-SP-$\beta$ yields better performance than OGO-SP.



### Dominant Patterns: Critical Features Hidden in Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2105.15057v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2105.15057v1)
- **Published**: 2021-05-31 15:43:04+00:00
- **Updated**: 2021-05-31 15:43:04+00:00
- **Authors**: Zhixing Ye, Shaofei Qin, Sizhe Chen, Xiaolin Huang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we find the existence of critical features hidden in Deep NeuralNetworks (DNNs), which are imperceptible but can actually dominate the outputof DNNs. We call these features dominant patterns. As the name suggests, for a natural image, if we add the dominant pattern of a DNN to it, the output of this DNN is determined by the dominant pattern instead of the original image, i.e., DNN's prediction is the same with the dominant pattern's. We design an algorithm to find such patterns by pursuing the insensitivity in the feature space. A direct application of the dominant patterns is the Universal Adversarial Perturbations(UAPs). Numerical experiments show that the found dominant patterns defeat state-of-the-art UAP methods, especially in label-free settings. In addition, dominant patterns are proved to have the potential to attack downstream tasks in which DNNs share the same backbone. We claim that DNN-specific dominant patterns reveal some essential properties of a DNN and are of great importance for its feature analysis and robustness enhancement.



### Not All Images are Worth 16x16 Words: Dynamic Transformers for Efficient Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/2105.15075v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.15075v2)
- **Published**: 2021-05-31 16:04:10+00:00
- **Updated**: 2021-10-26 14:08:00+00:00
- **Authors**: Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, Gao Huang
- **Comment**: Accepted by NeurIPS 2021
- **Journal**: None
- **Summary**: Vision Transformers (ViT) have achieved remarkable success in large-scale image recognition. They split every 2D image into a fixed number of patches, each of which is treated as a token. Generally, representing an image with more tokens would lead to higher prediction accuracy, while it also results in drastically increased computational cost. To achieve a decent trade-off between accuracy and speed, the number of tokens is empirically set to 16x16 or 14x14. In this paper, we argue that every image has its own characteristics, and ideally the token number should be conditioned on each individual input. In fact, we have observed that there exist a considerable number of "easy" images which can be accurately predicted with a mere number of 4x4 tokens, while only a small fraction of "hard" ones need a finer representation. Inspired by this phenomenon, we propose a Dynamic Transformer to automatically configure a proper number of tokens for each input image. This is achieved by cascading multiple Transformers with increasing numbers of tokens, which are sequentially activated in an adaptive fashion at test time, i.e., the inference is terminated once a sufficiently confident prediction is produced. We further design efficient feature reuse and relationship reuse mechanisms across different components of the Dynamic Transformer to reduce redundant computations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100 demonstrate that our method significantly outperforms the competitive baselines in terms of both theoretical computational efficiency and practical inference speed. Code and pre-trained models (based on PyTorch and MindSpore) are available at https://github.com/blackfeather-wang/Dynamic-Vision-Transformer and https://github.com/blackfeather-wang/Dynamic-Vision-Transformer-MindSpore.



### Large-Scale Spatio-Temporal Person Re-identification: Algorithms and Benchmark
- **Arxiv ID**: http://arxiv.org/abs/2105.15076v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.15076v6)
- **Published**: 2021-05-31 16:05:51+00:00
- **Updated**: 2021-11-27 12:15:07+00:00
- **Authors**: Xiujun Shu, Xiao Wang, Xianghao Zang, Shiliang Zhang, Yuanqi Chen, Ge Li, Qi Tian
- **Comment**: Accepted by IEEE Transactions on Circuits and Systems for Video
  Technology (TCSVT)
- **Journal**: None
- **Summary**: Person re-identification (re-ID) in the scenario with large spatial and temporal spans has not been fully explored. This is partially because that, existing benchmark datasets were mainly collected with limited spatial and temporal ranges, e.g., using videos recorded in a few days by cameras in a specific region of the campus. Such limited spatial and temporal ranges make it hard to simulate the difficulties of person re-ID in real scenarios. In this work, we contribute a novel Large-scale Spatio-Temporal LaST person re-ID dataset, including 10,862 identities with more than 228k images. Compared with existing datasets, LaST presents more challenging and high-diversity re-ID settings, and significantly larger spatial and temporal ranges. For instance, each person can appear in different cities or countries, and in various time slots from daytime to night, and in different seasons from spring to winter. To our best knowledge, LaST is a novel person re-ID dataset with the largest spatio-temporal ranges. Based on LaST, we verified its challenge by conducting a comprehensive performance evaluation of 14 re-ID algorithms. We further propose an easy-to-implement baseline that works well on such challenging re-ID setting. We also verified that models pre-trained on LaST can generalize well on existing datasets with short-term and cloth-changing scenarios. We expect LaST to inspire future works toward more realistic and challenging re-ID tasks. More information about the dataset is available at https://github.com/shuxjweb/last.git.



### SDNet: mutil-branch for single image deraining using swin
- **Arxiv ID**: http://arxiv.org/abs/2105.15077v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2105.15077v1)
- **Published**: 2021-05-31 16:06:02+00:00
- **Updated**: 2021-05-31 16:06:02+00:00
- **Authors**: Fuxiang Tan, YuTing Kong, Yingying Fan, Feng Liu, Daxin Zhou, Hao zhang, Long Chen, Liang Gao, Yurong Qian
- **Comment**: None
- **Journal**: None
- **Summary**: Rain streaks degrade the image quality and seriously affect the performance of subsequent computer vision tasks, such as autonomous driving, social security, etc. Therefore, removing rain streaks from a given rainy images is of great significance. Convolutional neural networks(CNN) have been widely used in image deraining tasks, however, the local computational characteristics of convolutional operations limit the development of image deraining tasks. Recently, the popular transformer has global computational features that can further facilitate the development of image deraining tasks. In this paper, we introduce Swin-transformer into the field of image deraining for the first time to study the performance and potential of Swin-transformer in the field of image deraining. Specifically, we improve the basic module of Swin-transformer and design a three-branch model to implement single-image rain removal. The former implements the basic rain pattern feature extraction, while the latter fuses different features to further extract and process the image features. In addition, we employ a jump connection to fuse deep features and shallow features. In terms of experiments, the existing public dataset suffers from image duplication and relatively homogeneous background. So we propose a new dataset Rain3000 to validate our model. Therefore, we propose a new dataset Rain3000 for validating our model. Experimental results on the publicly available datasets Rain100L, Rain100H and our dataset Rain3000 show that our proposed method has performance and inference speed advantages over the current mainstream single-image rain streaks removal models.The source code will be available at https://github.com/H-tfx/SDNet.



### Analysis of convolutional neural network image classifiers in a hierarchical max-pooling model with additional local pooling
- **Arxiv ID**: http://arxiv.org/abs/2106.05233v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML, Primary 62G05, secondary 62G20
- **Links**: [PDF](http://arxiv.org/pdf/2106.05233v1)
- **Published**: 2021-05-31 16:08:00+00:00
- **Updated**: 2021-05-31 16:08:00+00:00
- **Authors**: Benjamin Walter
- **Comment**: None
- **Journal**: None
- **Summary**: Image classification is considered, and a hierarchical max-pooling model with additional local pooling is introduced. Here the additional local pooling enables the hierachical model to combine parts of the image which have a variable relative distance towards each other. Various convolutional neural network image classifiers are introduced and compared in view of their rate of convergence. The finite sample size performance of the estimates is analyzed by applying them to simulated and real data.



### Can Attention Enable MLPs To Catch Up With CNNs?
- **Arxiv ID**: http://arxiv.org/abs/2105.15078v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.15078v1)
- **Published**: 2021-05-31 16:08:46+00:00
- **Updated**: 2021-05-31 16:08:46+00:00
- **Authors**: Meng-Hao Guo, Zheng-Ning Liu, Tai-Jiang Mu, Dun Liang, Ralph R. Martin, Shi-Min Hu
- **Comment**: Computational Visual Media, 2021, accepted. 4 pages, 1 figure
- **Journal**: None
- **Summary**: In the first week of May, 2021, researchers from four different institutions: Google, Tsinghua University, Oxford University and Facebook, shared their latest work [16, 7, 12, 17] on arXiv.org almost at the same time, each proposing new learning architectures, consisting mainly of linear layers, claiming them to be comparable, or even superior to convolutional-based models. This sparked immediate discussion and debate in both academic and industrial communities as to whether MLPs are sufficient, many thinking that learning architectures are returning to MLPs. Is this true? In this perspective, we give a brief history of learning architectures, including multilayer perceptrons (MLPs), convolutional neural networks (CNNs) and transformers. We then examine what the four newly proposed architectures have in common. Finally, we give our views on challenges and directions for new learning architectures, hoping to inspire future research.



### Analogous to Evolutionary Algorithm: Designing a Unified Sequence Model
- **Arxiv ID**: http://arxiv.org/abs/2105.15089v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.15089v3)
- **Published**: 2021-05-31 16:20:03+00:00
- **Updated**: 2021-12-17 13:26:47+00:00
- **Authors**: Jiangning Zhang, Chao Xu, Jian Li, Wenzhou Chen, Yabiao Wang, Ying Tai, Shuo Chen, Chengjie Wang, Feiyue Huang, Yong Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Inspired by biological evolution, we explain the rationality of Vision Transformer by analogy with the proven practical Evolutionary Algorithm (EA) and derive that both of them have consistent mathematical representation. Analogous to the dynamic local population in EA, we improve the existing transformer structure and propose a more efficient EAT model, and design task-related heads to deal with different tasks more flexibly. Moreover, we introduce the spatial-filling curve into the current vision transformer to sequence image data into a uniform sequential format. Thus we can design a unified EAT framework to address multi-modal tasks, separating the network architecture from the data format adaptation. Our approach achieves state-of-the-art results on the ImageNet classification task compared with recent vision transformer works while having smaller parameters and greater throughput. We further conduct multi-modal tasks to demonstrate the superiority of the unified EAT, e.g., Text-Based Image Retrieval, and our approach improves the rank-1 by +3.7 points over the baseline on the CSS dataset.



### Pho(SC)-CTC -- A Hybrid Approach Towards Zero-shot Word Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/2105.15093v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.15093v3)
- **Published**: 2021-05-31 16:22:33+00:00
- **Updated**: 2022-12-21 08:21:05+00:00
- **Authors**: Ravi Bhatt, Anuj Rai, Narayanan C. Krishnan, Sukalpa Chanda
- **Comment**: Accepted (International Journal on Document Analysis and
  Recognition). This paper is the extension of the paper titled "Pho(SC)Net: An
  Approach Towards Zero-shot Word Image Recognition in Historical Documents"
  published in ICDAR 2021
- **Journal**: None
- **Summary**: Annotating words in a historical document image archive for word image recognition purpose demands time and skilled human resource (like historians, paleographers). In a real-life scenario, obtaining sample images for all possible words is also not feasible. However, Zero-shot learning methods could aptly be used to recognize unseen/out-of-lexicon words in such historical document images. Based on previous state-of-the-art method for zero-shot word recognition Pho(SC)Net, we propose a hybrid model based on the CTC framework (Pho(SC)-CTC) that takes advantage of the rich features learned by Pho(SC)Net followed by a connectionist temporal classification (CTC) framework to perform the final classification. Encouraging results were obtained on two publicly available historical document datasets and one synthetic handwritten dataset, which justifies the efficacy of Pho(SC)-CTC and Pho(SC)Net.



### Toward Understanding the Feature Learning Process of Self-supervised Contrastive Learning
- **Arxiv ID**: http://arxiv.org/abs/2105.15134v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2105.15134v3)
- **Published**: 2021-05-31 16:42:09+00:00
- **Updated**: 2021-07-05 17:48:01+00:00
- **Authors**: Zixin Wen, Yuanzhi Li
- **Comment**: V3 corrected related works. Accepted to ICML2021
- **Journal**: None
- **Summary**: How can neural networks trained by contrastive learning extract features from the unlabeled data? Why does contrastive learning usually need much stronger data augmentations than supervised learning to ensure good representations? These questions involve both the optimization and statistical aspects of deep learning, but can hardly be answered by analyzing supervised learning, where the target functions are the highest pursuit. Indeed, in self-supervised learning, it is inevitable to relate to the optimization/generalization of neural networks to how they can encode the latent structures in the data, which we refer to as the feature learning process.   In this work, we formally study how contrastive learning learns the feature representations for neural networks by analyzing its feature learning process. We consider the case where our data are comprised of two types of features: the more semantically aligned sparse features which we want to learn from, and the other dense features we want to avoid. Theoretically, we prove that contrastive learning using $\mathbf{ReLU}$ networks provably learns the desired sparse features if proper augmentations are adopted. We present an underlying principle called $\textbf{feature decoupling}$ to explain the effects of augmentations, where we theoretically characterize how augmentations can reduce the correlations of dense features between positive samples while keeping the correlations of sparse features intact, thereby forcing the neural networks to learn from the self-supervision of sparse features. Empirically, we verified that the feature decoupling principle matches the underlying mechanism of contrastive learning in practice.



### Adaptive Feature Alignment for Adversarial Training
- **Arxiv ID**: http://arxiv.org/abs/2105.15157v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2105.15157v2)
- **Published**: 2021-05-31 17:01:05+00:00
- **Updated**: 2021-06-16 08:45:33+00:00
- **Authors**: Tao Wang, Ruixin Zhang, Xingyu Chen, Kai Zhao, Xiaolin Huang, Yuge Huang, Shaoxin Li, Jilin Li, Feiyue Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Recent studies reveal that Convolutional Neural Networks (CNNs) are typically vulnerable to adversarial attacks, which pose a threat to security-sensitive applications. Many adversarial defense methods improve robustness at the cost of accuracy, raising the contradiction between standard and adversarial accuracies. In this paper, we observe an interesting phenomenon that feature statistics change monotonically and smoothly w.r.t the rising of attacking strength. Based on this observation, we propose the adaptive feature alignment (AFA) to generate features of arbitrary attacking strengths. Our method is trained to automatically align features of arbitrary attacking strength. This is done by predicting a fusing weight in a dual-BN architecture. Unlike previous works that need to either retrain the model or manually tune a hyper-parameters for different attacking strengths, our method can deal with arbitrary attacking strengths with a single model without introducing any hyper-parameter. Importantly, our method improves the model robustness against adversarial samples without incurring much loss in standard accuracy. Experiments on CIFAR-10, SVHN, and tiny-ImageNet datasets demonstrate that our method outperforms the state-of-the-art under a wide range of attacking strengths.



### MSG-Transformer: Exchanging Local Spatial Information by Manipulating Messenger Tokens
- **Arxiv ID**: http://arxiv.org/abs/2105.15168v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.15168v3)
- **Published**: 2021-05-31 17:16:42+00:00
- **Updated**: 2022-03-25 13:25:08+00:00
- **Authors**: Jiemin Fang, Lingxi Xie, Xinggang Wang, Xiaopeng Zhang, Wenyu Liu, Qi Tian
- **Comment**: Accepted by CVPR 2022
- **Journal**: None
- **Summary**: Transformers have offered a new methodology of designing neural networks for visual recognition. Compared to convolutional networks, Transformers enjoy the ability of referring to global features at each stage, yet the attention module brings higher computational overhead that obstructs the application of Transformers to process high-resolution visual data. This paper aims to alleviate the conflict between efficiency and flexibility, for which we propose a specialized token for each region that serves as a messenger (MSG). Hence, by manipulating these MSG tokens, one can flexibly exchange visual information across regions and the computational complexity is reduced. We then integrate the MSG token into a multi-scale architecture named MSG-Transformer. In standard image classification and object detection, MSG-Transformer achieves competitive performance and the inference on both GPU and CPU is accelerated. Code is available at https://github.com/hustvl/MSG-Transformer.



### SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers
- **Arxiv ID**: http://arxiv.org/abs/2105.15203v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2105.15203v3)
- **Published**: 2021-05-31 17:59:51+00:00
- **Updated**: 2021-10-28 09:29:17+00:00
- **Authors**: Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo
- **Comment**: Accepted by NeurIPS 2021
- **Journal**: None
- **Summary**: We present SegFormer, a simple, efficient yet powerful semantic segmentation framework which unifies Transformers with lightweight multilayer perception (MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a novel hierarchically structured Transformer encoder which outputs multiscale features. It does not need positional encoding, thereby avoiding the interpolation of positional codes which leads to decreased performance when the testing resolution differs from training. 2) SegFormer avoids complex decoders. The proposed MLP decoder aggregates information from different layers, and thus combining both local attention and global attention to render powerful representations. We show that this simple and lightweight design is the key to efficient segmentation on Transformers. We scale our approach up to obtain a series of models from SegFormer-B0 to SegFormer-B5, reaching significantly better performance and efficiency than previous counterparts. For example, SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x smaller and 2.2% better than the previous best method. Our best model, SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows excellent zero-shot robustness on Cityscapes-C. Code will be released at: github.com/NVlabs/SegFormer.



### Continual 3D Convolutional Neural Networks for Real-time Processing of Videos
- **Arxiv ID**: http://arxiv.org/abs/2106.00050v3
- **DOI**: 10.1007/978-3-031-19772-7_22
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2106.00050v3)
- **Published**: 2021-05-31 18:30:52+00:00
- **Updated**: 2022-07-05 07:42:04+00:00
- **Authors**: Lukas Hedegaard, Alexandros Iosifidis
- **Comment**: 22 pages, 9 figures, 7 tables
- **Journal**: ECCV 2022
- **Summary**: We introduce Continual 3D Convolutional Neural Networks (Co3D CNNs), a new computational formulation of spatio-temporal 3D CNNs, in which videos are processed frame-by-frame rather than by clip. In online tasks demanding frame-wise predictions, Co3D CNNs dispense with the computational redundancies of regular 3D CNNs, namely the repeated convolutions over frames, which appear in overlapping clips. We show that Continual 3D CNNs can reuse preexisting 3D-CNN weights to reduce the per-prediction floating point operations (FLOPs) in proportion to the temporal receptive field while retaining similar memory requirements and accuracy. This is validated with multiple models on Kinetics-400 and Charades with remarkable results: CoX3D models attain state-of-the-art complexity/accuracy trade-offs on Kinetics-400 with 12.1-15.3x reductions of FLOPs and 2.3-3.8% improvements in accuracy compared to regular X3D models while reducing peak memory consumption by up to 48%. Moreover, we investigate the transient response of Co3D CNNs at start-up and perform extensive benchmarks of on-hardware processing characteristics for publicly available 3D CNNs.



### Closer Look at the Uncertainty Estimation in Semantic Segmentation under Distributional Shift
- **Arxiv ID**: http://arxiv.org/abs/2106.00076v2
- **DOI**: 10.1109/IJCNN52387.2021.9533330
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.00076v2)
- **Published**: 2021-05-31 19:50:43+00:00
- **Updated**: 2021-09-27 10:04:18+00:00
- **Authors**: Sebastian Cygert, Bartłomiej Wróblewski, Karol Woźniak, Radosław Słowiński, Andrzej Czyżewski
- **Comment**: International Joint Conference on Neural Networks 2021,
  https://ieeexplore.ieee.org/document/9533330
- **Journal**: None
- **Summary**: While recent computer vision algorithms achieve impressive performance on many benchmarks, they lack robustness - presented with an image from a different distribution, (e.g. weather or lighting conditions not considered during training), they may produce an erroneous prediction. Therefore, it is desired that such a model will be able to reliably predict its confidence measure. In this work, uncertainty estimation for the task of semantic segmentation is evaluated under a varying level of domain shift: in a cross-dataset setting and when adapting a model trained on data from the simulation. It was shown that simple color transformations already provide a strong baseline, comparable to using more sophisticated style-transfer data augmentation. Further, by constructing an ensemble consisting of models using different backbones and/or augmentation methods, it was possible to improve significantly model performance in terms of overall accuracy and uncertainty estimation under the domain shift setting. The Expected Calibration Error (ECE) on challenging GTA to Cityscapes adaptation was reduced from 4.05 to the competitive value of 1.1. Further, an ensemble of models was utilized in the self-training setting to improve the pseudo-labels generation, which resulted in a significant gain in the final model accuracy, compared to the standard fine-tuning (without ensemble).



### Deep learning for prediction of hepatocellular carcinoma recurrence after resection or liver transplantation: a discovery and validation study
- **Arxiv ID**: http://arxiv.org/abs/2106.00090v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2106.00090v1)
- **Published**: 2021-05-31 20:27:41+00:00
- **Updated**: 2021-05-31 20:27:41+00:00
- **Authors**: Zhikun Liu, Yuanpeng Liu, Yuan Hong, Jinwen Meng, Jianguo Wang, Shusen Zheng, Xiao Xu
- **Comment**: None
- **Journal**: None
- **Summary**: This study aimed to develop a classifier of prognosis after resection or liver transplantation (LT) for HCC by directly analysing the ubiquitously available histological images using deep learning based neural networks. Nucleus map set was used to train U-net to capture the nuclear architectural information. Train set included the patients with HCC treated by resection and has a distinct outcome. LT set contained patients with HCC treated by LT. Train set and its nuclear architectural information extracted by U-net were used to train MobileNet V2 based classifier (MobileNetV2_HCC_Class), purpose-built for classifying supersized heterogeneous images. The MobileNetV2_HCC_Class maintained relative higher discriminatory power than the other factors after HCC resection or LT in the independent validation set. Pathological review showed that the tumoral areas most predictive of recurrence were characterized by presence of stroma, high degree of cytological atypia, nuclear hyperchomasia, and a lack of immune infiltration. A clinically useful prognostic classifier was developed using deep learning allied to histological slides. The classifier has been extensively evaluated in independent patient populations with different treatment, and gives consistent excellent results across the classical clinical, biological and pathological features. The classifier assists in refining the prognostic prediction of HCC patients and identifying patients who would benefit from more intensive management.



### 3D map creation using crowdsourced GNSS data
- **Arxiv ID**: http://arxiv.org/abs/2106.00107v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2106.00107v1)
- **Published**: 2021-05-31 21:24:35+00:00
- **Updated**: 2021-05-31 21:24:35+00:00
- **Authors**: Terence Lines, Ana Basiri
- **Comment**: 25 pages with 11 figures
- **Journal**: None
- **Summary**: 3D maps are increasingly useful for many applications such as drone navigation, emergency services, and urban planning. However, creating 3D maps and keeping them up-to-date using existing technologies, such as laser scanners, is expensive. This paper proposes and implements a novel approach to generate 2.5D (otherwise known as 3D level-of-detail (LOD) 1) maps for free using Global Navigation Satellite Systems (GNSS) signals, which are globally available and are blocked only by obstacles between the satellites and the receivers. This enables us to find the patterns of GNSS signal availability and create 3D maps. The paper applies algorithms to GNSS signal strength patterns based on a boot-strapped technique that iteratively trains the signal classifiers while generating the map. Results of the proposed technique demonstrate the ability to create 3D maps using automatically processed GNSS data. The results show that the third dimension, i.e. height of the buildings, can be estimated with below 5 metre accuracy, which is the benchmark recommended by the CityGML standard.



### Effect of Pre-Training Scale on Intra- and Inter-Domain Full and Few-Shot Transfer Learning for Natural and Medical X-Ray Chest Images
- **Arxiv ID**: http://arxiv.org/abs/2106.00116v4
- **DOI**: 10.1109/IJCNN55064.2022.9892393
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.00116v4)
- **Published**: 2021-05-31 21:55:56+00:00
- **Updated**: 2022-12-19 00:47:51+00:00
- **Authors**: Mehdi Cherti, Jenia Jitsev
- **Comment**: Short version published in MedNeurIPS 2021. Long version published in
  IJCNN 2022. Code: https://github.com/SLAMPAI/large-scale-pretraining-transfer
- **Journal**: 2022 International Joint Conference on Neural Networks (IJCNN),
  2022, pp. 1-9
- **Summary**: Increasing model, data and compute budget scale in the pre-training has been shown to strongly improve model generalization and transfer learning in vast line of work done in language modeling and natural image recognition. However, most studies on the positive effect of larger scale were done in scope of in-domain setting, with source and target data being in close proximity. To study effect of larger scale for both in-domain and out-of-domain setting when performing full and few-shot transfer, we combine here for the first time large, openly available medical X-Ray chest imaging datasets to reach a scale for medical imaging domain comparable to ImageNet-1k, routinely used for pre-training in natural image domain. We then conduct supervised pre-training, while varying network size and source data scale and domain, being either large natural (ImageNet-1k/21k) or large medical chest X-Ray datasets, and transfer pre-trained models to different natural or medical targets. We observe strong improvement due to larger pre-training scale for intra-domain natural-natural and medical-medical transfer. For inter-domain natural-medical transfer, we find improvements due to larger pre-training scale on larger X-Ray targets in full shot regime, while for smaller targets and for few-shot regime the improvement is not visible. Remarkably, large networks pre-trained on very large natural ImageNet-21k are as good or better than networks pre-trained on largest available medical X-Ray data when performing transfer to large X-Ray targets. We conclude that substantially increasing model and generic, medical domain-agnostic natural image source data scale in the pre-training can enable high quality out-of-domain transfer to medical domain specific targets, removing dependency on large medical domain-specific source data often not available in the practice.



### Clustering-friendly Representation Learning via Instance Discrimination and Feature Decorrelation
- **Arxiv ID**: http://arxiv.org/abs/2106.00131v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.00131v1)
- **Published**: 2021-05-31 22:59:31+00:00
- **Updated**: 2021-05-31 22:59:31+00:00
- **Authors**: Yaling Tao, Kentaro Takagi, Kouta Nakata
- **Comment**: 15 pages, ICLR2021
- **Journal**: None
- **Summary**: Clustering is one of the most fundamental tasks in machine learning. Recently, deep clustering has become a major trend in clustering techniques. Representation learning often plays an important role in the effectiveness of deep clustering, and thus can be a principal cause of performance degradation. In this paper, we propose a clustering-friendly representation learning method using instance discrimination and feature decorrelation. Our deep-learning-based representation learning method is motivated by the properties of classical spectral clustering. Instance discrimination learns similarities among data and feature decorrelation removes redundant correlation among features. We utilize an instance discrimination method in which learning individual instance classes leads to learning similarity among instances. Through detailed experiments and examination, we show that the approach can be adapted to learning a latent space for clustering. We design novel softmax-formulated decorrelation constraints for learning. In evaluations of image clustering using CIFAR-10 and ImageNet-10, our method achieves accuracy of 81.5% and 95.4%, respectively. We also show that the softmax-formulated constraints are compatible with various neural networks.



### GANs Can Play Lottery Tickets Too
- **Arxiv ID**: http://arxiv.org/abs/2106.00134v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2106.00134v1)
- **Published**: 2021-05-31 23:03:00+00:00
- **Updated**: 2021-05-31 23:03:00+00:00
- **Authors**: Xuxi Chen, Zhenyu Zhang, Yongduo Sui, Tianlong Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Deep generative adversarial networks (GANs) have gained growing popularity in numerous scenarios, while usually suffer from high parameter complexities for resource-constrained real-world applications. However, the compression of GANs has less been explored. A few works show that heuristically applying compression techniques normally leads to unsatisfactory results, due to the notorious training instability of GANs. In parallel, the lottery ticket hypothesis shows prevailing success on discriminative models, in locating sparse matching subnetworks capable of training in isolation to full model performance. In this work, we for the first time study the existence of such trainable matching subnetworks in deep GANs. For a range of GANs, we certainly find matching subnetworks at 67%-74% sparsity. We observe that with or without pruning discriminator has a minor effect on the existence and quality of matching subnetworks, while the initialization weights used in the discriminator play a significant role. We then show the powerful transferability of these subnetworks to unseen tasks. Furthermore, extensive experimental results demonstrate that our found subnetworks substantially outperform previous state-of-the-art GAN compression approaches in both image generation (e.g. SNGAN) and image-to-image translation GANs (e.g. CycleGAN). Codes available at https://github.com/VITA-Group/GAN-LTH.



