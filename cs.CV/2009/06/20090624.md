# Arxiv Papers in cs.CV on 2009-06-24
### On landmark selection and sampling in high-dimensional data analysis
- **Arxiv ID**: http://arxiv.org/abs/0906.4582v1
- **DOI**: 10.1098/rsta.2009.0161
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/0906.4582v1)
- **Published**: 2009-06-24 23:40:22+00:00
- **Updated**: 2009-06-24 23:40:22+00:00
- **Authors**: Mohamed-Ali Belabbas, Patrick J. Wolfe
- **Comment**: 18 pages, 6 figures, submitted for publication
- **Journal**: Philosophical Transactions of the Royal Society, Series A, vol.
  367, pp. 4295-4312, 2009
- **Summary**: In recent years, the spectral analysis of appropriately defined kernel matrices has emerged as a principled way to extract the low-dimensional structure often prevalent in high-dimensional data. Here we provide an introduction to spectral methods for linear and nonlinear dimension reduction, emphasizing ways to overcome the computational limitations currently faced by practitioners with massive datasets. In particular, a data subsampling or landmark selection process is often employed to construct a kernel based on partial information, followed by an approximate spectral analysis termed the Nystrom extension. We provide a quantitative framework to analyse this procedure, and use it to demonstrate algorithmic performance bounds on a range of practical approaches designed to optimize the landmark selection process. We compare the practical implications of these bounds by way of real-world examples drawn from the field of computer vision, whereby low-dimensional manifold structure is shown to emerge from high-dimensional video data streams.



