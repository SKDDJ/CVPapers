# Arxiv Papers in cs.CV on 2016-02-17
### 2D SEM images turn into 3D object models
- **Arxiv ID**: http://arxiv.org/abs/1602.05256v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1602.05256v1)
- **Published**: 2016-02-17 00:41:58+00:00
- **Updated**: 2016-02-17 00:41:58+00:00
- **Authors**: Wichai Shanklin
- **Comment**: None
- **Journal**: None
- **Summary**: The scanning electron microscopy (SEM) is probably one the most fascinating examination approach that has been used since more than two decades to detailed inspection of micro scale objects. Most of the scanning electron microscopes could only produce 2D images that could not assist operational analysis of microscopic surface properties. Computer vision algorithms combined with very advanced geometry and mathematical approaches turn any SEM into a full 3D measurement device. This work focuses on a methodical literature review for automatic 3D surface reconstruction of scanning electron microscope images.



### A landmark-based algorithm for automatic pattern recognition and abnormality detection
- **Arxiv ID**: http://arxiv.org/abs/1602.05572v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05572v2)
- **Published**: 2016-02-17 02:18:27+00:00
- **Updated**: 2017-05-11 15:30:32+00:00
- **Authors**: S. Huzurbazar, Long Lee, Dongyang Kuang
- **Comment**: None
- **Journal**: None
- **Summary**: We study a class of mathematical and statistical algorithms with the aim of establishing a computer-based framework for fast and reliable automatic abnormality detection on landmark represented image templates. Under this framework, we apply a landmark-based algorithm for finding a group average as an estimator that is said to best represent the common features of the group in study. This algorithm extracts information of momentum at each landmark through the process of template matching. If ever converges, the proposed algorithm produces a local coordinate system for each member of the observing group, in terms of the residual momentum. We use a Bayesian approach on the collected residual momentum representations for making inference. For illustration, we apply this framework to a small database of brain images for detecting structure abnormality. The brain structure changes identified by our framework are highly consistent with studies in the literature.



### Density-based Denoising of Point Cloud
- **Arxiv ID**: http://arxiv.org/abs/1602.05312v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05312v1)
- **Published**: 2016-02-17 06:13:41+00:00
- **Updated**: 2016-02-17 06:13:41+00:00
- **Authors**: Faisal Zaman, Ya Ping Wong, Boon Yian Ng
- **Comment**: 9 pages, 5 figures, to be appeared in the Proceeding of 9th
  International Conference on Robotics, Vision, Signal Processing & Power
  Applications (ROVISP), 2-3 Feb 2016, Penang, Malaysia
- **Journal**: None
- **Summary**: Point cloud source data for surface reconstruction is usually contaminated with noise and outliers. To overcome this deficiency, a density-based point cloud denoising method is presented to remove outliers and noisy points. First, particle-swam optimization technique is employed for automatically approximating optimal bandwidth of multivariate kernel density estimation to ensure the robust performance of density estimation. Then, mean-shift based clustering technique is used to remove outliers through a thresholding scheme. After removing outliers from the point cloud, bilateral mesh filtering is applied to smooth the remaining points. The experimental results show that this approach, comparably, is robust and efficient.



### PlaNet - Photo Geolocation with Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1602.05314v1
- **DOI**: 10.1007/978-3-319-46484-8_3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05314v1)
- **Published**: 2016-02-17 06:27:55+00:00
- **Updated**: 2016-02-17 06:27:55+00:00
- **Authors**: Tobias Weyand, Ilya Kostrikov, James Philbin
- **Comment**: None
- **Journal**: None
- **Summary**: Is it possible to build a system to determine the location where a photo was taken using just its pixels? In general, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architectural details, which in combination may allow one to determine an approximate location and occasionally an exact location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en-masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi-scale geographic cells, and train a deep network using millions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching using global image descriptors, our model is able to use and integrate multiple visible cues. We show that the resulting model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) architecture. By learning to exploit temporal coherence to geolocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single-image model.



### Image Restoration: A General Wavelet Frame Based Model and Its Asymptotic Analysis
- **Arxiv ID**: http://arxiv.org/abs/1602.05332v1
- **DOI**: None
- **Categories**: **math.FA**, cs.CV, 42C40, 68U10, 65D15
- **Links**: [PDF](http://arxiv.org/pdf/1602.05332v1)
- **Published**: 2016-02-17 08:32:52+00:00
- **Updated**: 2016-02-17 08:32:52+00:00
- **Authors**: Bin Dong, Zuowei Shen, Peichu Xie
- **Comment**: None
- **Journal**: None
- **Summary**: Image restoration is one of the most important areas in imaging science. Mathematical tools have been widely used in image restoration, where wavelet frame based approach is one of the successful examples. In this paper, we introduce a generic wavelet frame based image restoration model, called the "general model", which includes most of the existing wavelet frame based models as special cases. Moreover, the general model also includes examples that are new to the literature. Motivated by our earlier studies [1-3], We provide an asymptotic analysis of the general model as image resolution goes to infinity, which establishes a connection between the general model in discrete setting and a new variatonal model in continuum setting. The variational model also includes some of the existing variational models as special cases, such as the total generalized variational model proposed by [4]. In the end, we introduce an algorithm solving the general model and present one numerical simulation as an example.



### Cell segmentation with random ferns and graph-cuts
- **Arxiv ID**: http://arxiv.org/abs/1602.05439v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1602.05439v1)
- **Published**: 2016-02-17 14:47:32+00:00
- **Updated**: 2016-02-17 14:47:32+00:00
- **Authors**: Arnaud Browet, Christophe De Vleeschouwer, Laurent Jacques, Navrita Mathiah, Bechara Saykali, Isabelle Migeotte
- **Comment**: submitted to ICIP
- **Journal**: None
- **Summary**: The progress in imaging techniques have allowed the study of various aspect of cellular mechanisms. To isolate individual cells in live imaging data, we introduce an elegant image segmentation framework that effectively extracts cell boundaries, even in the presence of poor edge details. Our approach works in two stages. First, we estimate pixel interior/border/exterior class probabilities using random ferns. Then, we use an energy minimization framework to compute boundaries whose localization is compliant with the pixel class probabilities. We validate our approach on a manually annotated dataset.



### On the Use of Deep Learning for Blind Image Quality Assessment
- **Arxiv ID**: http://arxiv.org/abs/1602.05531v5
- **DOI**: 10.1007/s11760-017-1166-8
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05531v5)
- **Published**: 2016-02-17 19:12:50+00:00
- **Updated**: 2017-04-04 14:12:38+00:00
- **Authors**: Simone Bianco, Luigi Celona, Paolo Napoletano, Raimondo Schettini
- **Comment**: None
- **Journal**: SIViP 12(2), 2018, 355-362
- **Summary**: In this work we investigate the use of deep learning for distortion-generic blind image quality assessment. We report on different design choices, ranging from the use of features extracted from pre-trained Convolutional Neural Networks (CNNs) as a generic image description, to the use of features extracted from a CNN fine-tuned for the image quality task. Our best proposal, named DeepBIQ, estimates the image quality by average pooling the scores predicted on multiple sub-regions of the original image. The score of each sub-region is computed using a Support Vector Regression (SVR) machine taking as input features extracted using a CNN fine-tuned for category-based image quality assessment. Experimental results on the LIVE In the Wild Image Quality Challenge Database and on the LIVE Image Quality Assessment Database show that DeepBIQ outperforms the state-of-the-art methods compared, having a Linear Correlation Coefficient (LCC) with human subjective scores of almost 0.91 and 0.98 respectively. Furthermore, in most of the cases, the quality score predictions of DeepBIQ are closer to the average observer than those of a generic human observer.



