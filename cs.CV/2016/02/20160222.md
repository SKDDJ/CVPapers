# Arxiv Papers in cs.CV on 2016-02-22
### Denoising and Covariance Estimation of Single Particle Cryo-EM Images
- **Arxiv ID**: http://arxiv.org/abs/1602.06632v3
- **DOI**: 10.1016/j.jsb.2016.04.013
- **Categories**: **cs.CV**, q-bio.BM, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1602.06632v3)
- **Published**: 2016-02-22 03:04:44+00:00
- **Updated**: 2016-04-06 19:41:52+00:00
- **Authors**: Tejal Bhamre, Teng Zhang, Amit Singer
- **Comment**: Revision for JSB
- **Journal**: None
- **Summary**: The problem of image restoration in cryo-EM entails correcting for the effects of the Contrast Transfer Function (CTF) and noise. Popular methods for image restoration include `phase flipping', which corrects only for the Fourier phases but not amplitudes, and Wiener filtering, which requires the spectral signal to noise ratio. We propose a new image restoration method which we call `Covariance Wiener Filtering' (CWF). In CWF, the covariance matrix of the projection images is used within the classical Wiener filtering framework for solving the image restoration deconvolution problem. Our estimation procedure for the covariance matrix is new and successfully corrects for the CTF. We demonstrate the efficacy of CWF by applying it to restore both simulated and experimental cryo-EM images. Results with experimental datasets demonstrate that CWF provides a good way to evaluate the particle images and to see what the dataset contains even without 2D classification and averaging.



### Creating Simplified 3D Models with High Quality Textures
- **Arxiv ID**: http://arxiv.org/abs/1602.06645v1
- **DOI**: 10.1109/DICTA.2015.7371249
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.06645v1)
- **Published**: 2016-02-22 04:45:43+00:00
- **Updated**: 2016-02-22 04:45:43+00:00
- **Authors**: Song Liu, Wanqing Li, Philip Ogunbona, Yang-Wai Chow
- **Comment**: 2015 International Conference on Digital Image Computing: Techniques
  and Applications (DICTA), Page 1 - 8
- **Journal**: None
- **Summary**: This paper presents an extension to the KinectFusion algorithm which allows creating simplified 3D models with high quality RGB textures. This is achieved through (i) creating model textures using images from an HD RGB camera that is calibrated with Kinect depth camera, (ii) using a modified scheme to update model textures in an asymmetrical colour volume that contains a higher number of voxels than that of the geometry volume, (iii) simplifying dense polygon mesh model using quadric-based mesh decimation algorithm, and (iv) creating and mapping 2D textures to every polygon in the output 3D model. The proposed method is implemented in real-time by means of GPU parallel processing. Visualization via ray casting of both geometry and colour volumes provides users with a real-time feedback of the currently scanned 3D model. Experimental results show that the proposed method is capable of keeping the model texture quality even for a heavily decimated model and that, when reconstructing small objects, photorealistic RGB textures can still be reconstructed.



### Planogram Compliance Checking Based on Detection of Recurring Patterns
- **Arxiv ID**: http://arxiv.org/abs/1602.06647v1
- **DOI**: 10.1109/MMUL.2016.19
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.06647v1)
- **Published**: 2016-02-22 04:49:14+00:00
- **Updated**: 2016-02-22 04:49:14+00:00
- **Authors**: Song Liu, Wanqing Li, Stephen Davis, Christian Ritz, Hongda Tian
- **Comment**: Accepted by MM (IEEE Multimedia Magazine) 2016
- **Journal**: None
- **Summary**: In this paper, a novel method for automatic planogram compliance checking in retail chains is proposed without requiring product template images for training. Product layout is extracted from an input image by means of unsupervised recurring pattern detection and matched via graph matching with the expected product layout specified by a planogram to measure the level of compliance. A divide and conquer strategy is employed to improve the speed. Specifically, the input image is divided into several regions based on the planogram. Recurring patterns are detected in each region respectively and then merged together to estimate the product layout. Experimental results on real data have verified the efficacy of the proposed method. Compared with a template-based method, higher accuracies are achieved by the proposed method over a wide range of products.



### Correlation Hashing Network for Efficient Cross-Modal Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1602.06697v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.06697v2)
- **Published**: 2016-02-22 09:31:45+00:00
- **Updated**: 2017-02-20 11:25:05+00:00
- **Authors**: Yue Cao, Mingsheng Long, Jianmin Wang, Philip S. Yu
- **Comment**: 7 pages
- **Journal**: None
- **Summary**: Hashing is widely applied to approximate nearest neighbor search for large-scale multimodal retrieval with storage and computation efficiency. Cross-modal hashing improves the quality of hash coding by exploiting semantic correlations across different modalities. Existing cross-modal hashing methods first transform data into low-dimensional feature vectors, and then generate binary codes by another separate quantization step. However, suboptimal hash codes may be generated since the quantization error is not explicitly minimized and the feature representation is not jointly optimized with the binary codes. This paper presents a Correlation Hashing Network (CHN) approach to cross-modal hashing, which jointly learns good data representation tailored to hash coding and formally controls the quantization error. The proposed CHN is a hybrid deep architecture that constitutes a convolutional neural network for learning good image representations, a multilayer perception for learning good text representations, two hashing layers for generating compact binary codes, and a structured max-margin loss that integrates all things together to enable learning similarity-preserving and high-quality hash codes. Extensive empirical study shows that CHN yields state of the art cross-modal retrieval performance on standard benchmarks.



### Implicit LOD using points ordering for processing and visualisation in Point Cloud Servers
- **Arxiv ID**: http://arxiv.org/abs/1602.06920v3
- **DOI**: None
- **Categories**: **cs.CG**, cs.CV, cs.SE
- **Links**: [PDF](http://arxiv.org/pdf/1602.06920v3)
- **Published**: 2016-02-22 20:19:23+00:00
- **Updated**: 2018-01-11 21:38:21+00:00
- **Authors**: RÃ©mi Cura, Julien Perret, Nicolas Paparoditis
- **Comment**: this article is a split of the previous one because the previous
  article covered two topics to lousily related
- **Journal**: None
- **Summary**: Lidar datasets now commonly reach Billions of points and are very dense. Using these point cloud becomes challenging, as the high number of points is intractable for most applications and for visualisation.In this work we propose a new paradigm to easily get a portable geometric Level Of Details (LOD) inside a Point Cloud Server.The main idea is to not store the LOD information in an external additional file, but instead to store it implicitly by exploiting the order of the points.The point cloud is divided into groups (patches). These patches are ordered so that their order gradually provides more and more details on the patch. We demonstrate the interest of our method with several classical uses of LOD, such as visualisation of massive point cloud, algorithm acceleration, fast density peak detection and correction.



