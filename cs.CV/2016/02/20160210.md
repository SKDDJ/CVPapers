# Arxiv Papers in cs.CV on 2016-02-10
### Improved Eigenfeature Regularization for Face Identification
- **Arxiv ID**: http://arxiv.org/abs/1602.03256v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03256v1)
- **Published**: 2016-02-10 03:52:11+00:00
- **Updated**: 2016-02-10 03:52:11+00:00
- **Authors**: Bappaditya Mandal
- **Comment**: 6 pages, 4 figures, ICIP 2015
- **Journal**: None
- **Summary**: In this work, we propose to divide each class (a person) into subclasses using spatial partition trees which helps in better capturing the intra-personal variances arising from the appearances of the same individual. We perform a comprehensive analysis on within-class and within-subclass eigenspectrums of face images and propose a novel method of eigenspectrum modeling which extracts discriminative features of faces from both within-subclass and total or between-subclass scatter matrices. Effective low-dimensional face discriminative features are extracted for face recognition (FR) after performing discriminant evaluation in the entire eigenspace. Experimental results on popular face databases (AR, FERET) and the challenging unconstrained YouTube Face database show the superiority of our proposed approach on all three databases.



### Gabor Wavelets in Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1602.03308v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1602.03308v1)
- **Published**: 2016-02-10 09:45:38+00:00
- **Updated**: 2016-02-10 09:45:38+00:00
- **Authors**: David Barina
- **Comment**: None
- **Journal**: None
- **Summary**: This work shows the use of a two-dimensional Gabor wavelets in image processing. Convolution with such a two-dimensional wavelet can be separated into two series of one-dimensional ones. The key idea of this work is to utilize a Gabor wavelet as a multiscale partial differential operator of a given order. Gabor wavelets are used here to detect edges, corners and blobs. A performance of such an interest point detector is compared to detectors utilizing a Haar wavelet and a derivative of a Gaussian function. The proposed approach may be useful when a fast implementation of the Gabor transform is available or when the transform is already precomputed.



### DAP3D-Net: Where, What and How Actions Occur in Videos?
- **Arxiv ID**: http://arxiv.org/abs/1602.03346v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03346v1)
- **Published**: 2016-02-10 12:25:52+00:00
- **Updated**: 2016-02-10 12:25:52+00:00
- **Authors**: Li Liu, Yi Zhou, Ling Shao
- **Comment**: None
- **Journal**: None
- **Summary**: Action parsing in videos with complex scenes is an interesting but challenging task in computer vision. In this paper, we propose a generic 3D convolutional neural network in a multi-task learning manner for effective Deep Action Parsing (DAP3D-Net) in videos. Particularly, in the training phase, action localization, classification and attributes learning can be jointly optimized on our appearancemotion data via DAP3D-Net. For an upcoming test video, we can describe each individual action in the video simultaneously as: Where the action occurs, What the action is and How the action is performed. To well demonstrate the effectiveness of the proposed DAP3D-Net, we also contribute a new Numerous-category Aligned Synthetic Action dataset, i.e., NASA, which consists of 200; 000 action clips of more than 300 categories and with 33 pre-defined action attributes in two hierarchical levels (i.e., low-level attributes of basic body part movements and high-level attributes related to action motion). We learn DAP3D-Net using the NASA dataset and then evaluate it on our collected Human Action Understanding (HAU) dataset. Experimental results show that our approach can accurately localize, categorize and describe multiple actions in realistic videos.



### Comparison of feature extraction and dimensionality reduction methods for single channel extracellular spike sorting
- **Arxiv ID**: http://arxiv.org/abs/1602.03379v1
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1602.03379v1)
- **Published**: 2016-02-10 14:21:34+00:00
- **Updated**: 2016-02-10 14:21:34+00:00
- **Authors**: Anupam Mitra, Anagh Pathak, Kaushik Majumdar
- **Comment**: 12 pages, 2 figures
- **Journal**: None
- **Summary**: Spikes in the membrane electrical potentials of neurons play a major role in the functioning of nervous systems of animals. Obtaining the spikes from different neurons has been a challenging problem for decades. Several schemes have been proposed for spike sorting to isolate the spikes of individual neurons from electrical recordings in extracellular media. However, there is much scope for improvement in the accuracies obtained using the prevailing methods of spike sorting. To determine more effective spike sorting strategies using well known methods, we compared different types of signal features and techniques for dimensionality reduction in feature space. We tried to determine an optimum or near optimum feature extraction and dimensionality reduction methods and an optimum or near optimum number of features for spike sorting. We assessed relative performance of well known methods on simulated recordings specially designed for development and benchmarking of spike sorting schemes, with varying number of spike classes and the well established method of $k$-means clustering of selected features. We found that almost all well known methods performed quite well. Nevertheless, from spike waveforms of 64 samples, sampled at 24 kHz, using principal component analysis (PCA) to select around 46 to 55 features led to the better spike sorting performance than most other methods (Wilcoxon signed rank sum test, $p < 0.001$).



### Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/1602.03409v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03409v1)
- **Published**: 2016-02-10 15:33:32+00:00
- **Updated**: 2016-02-10 15:33:32+00:00
- **Authors**: Hoo-Chang Shin, Holger R. Roth, Mingchen Gao, Le Lu, Ziyue Xu, Isabella Nogues, Jianhua Yao, Daniel Mollura, Ronald M. Summers
- **Comment**: None
- **Journal**: None
- **Summary**: Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and the revival of deep CNN. CNNs enable learning data-driven, highly representative, layered hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, with 85% sensitivity at 3 false positive per patient, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.



### Triplet Similarity Embedding for Face Verification
- **Arxiv ID**: http://arxiv.org/abs/1602.03418v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03418v2)
- **Published**: 2016-02-10 15:48:47+00:00
- **Updated**: 2016-03-13 18:06:34+00:00
- **Authors**: Swami Sankaranarayanan, Azadeh Alavi, Rama Chellappa
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we present an unconstrained face verification algorithm and evaluate it on the recently released IJB-A dataset that aims to push the boundaries of face verification methods. The proposed algorithm couples a deep CNN-based approach with a low-dimensional discriminative embedding learnt using triplet similarity constraints in a large margin fashion. Aside from yielding performance improvement, this embedding provides significant advantages in terms of memory and post-processing operations like hashing and visualization. Experiments on the IJB-A dataset show that the proposed algorithm outperforms state of the art methods in verification and identification metrics, while requiring less training time.



### Super-Resolved Retinal Image Mosaicing
- **Arxiv ID**: http://arxiv.org/abs/1602.03458v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03458v1)
- **Published**: 2016-02-10 17:30:27+00:00
- **Updated**: 2016-02-10 17:30:27+00:00
- **Authors**: Thomas KÃ¶hler, Axel Heinrich, Andreas Maier, Joachim Hornegger, Ralf P. Tornow
- **Comment**: accepted for 2016 IEEE 13th International Symposium on Biomedical
  Imaging (ISBI 2016)
- **Journal**: None
- **Summary**: The acquisition of high-resolution retinal fundus images with a large field of view (FOV) is challenging due to technological, physiological and economic reasons. This paper proposes a fully automatic framework to reconstruct retinal images of high spatial resolution and increased FOV from multiple low-resolution images captured with non-mydriatic, mobile and video-capable but low-cost cameras. Within the scope of one examination, we scan different regions on the retina by exploiting eye motion conducted by a patient guidance. Appropriate views for our mosaicing method are selected based on optic disk tracking to trace eye movements. For each view, one super-resolved image is reconstructed by fusion of multiple video frames. Finally, all super-resolved views are registered to a common reference using a novel polynomial registration scheme and combined by means of image mosaicing. We evaluated our framework for a mobile and low-cost video fundus camera. In our experiments, we reconstructed retinal images of up to 30{\deg} FOV from 10 complementary views of 15{\deg} FOV. An evaluation of the mosaics by human experts as well as a quantitative comparison to conventional color fundus images encourage the clinical usability of our framework.



### Articulated Clinician Detection Using 3D Pictorial Structures on RGB-D Data
- **Arxiv ID**: http://arxiv.org/abs/1602.03468v4
- **DOI**: 10.1016/j.media.2016.07.001
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03468v4)
- **Published**: 2016-02-10 17:56:47+00:00
- **Updated**: 2016-07-06 07:45:15+00:00
- **Authors**: Abdolrahim Kadkhodamohammadi, Afshin Gangi, Michel de Mathelin, Nicolas Padoy
- **Comment**: The supplementary video is available at https://youtu.be/iabbGSqRSgE
- **Journal**: None
- **Summary**: Reliable human pose estimation (HPE) is essential to many clinical applications, such as surgical workflow analysis, radiation safety monitoring and human-robot cooperation. Proposed methods for the operating room (OR) rely either on foreground estimation using a multi-camera system, which is a challenge in real ORs due to color similarities and frequent illumination changes, or on wearable sensors or markers, which are invasive and therefore difficult to introduce in the room. Instead, we propose a novel approach based on Pictorial Structures (PS) and on RGB-D data, which can be easily deployed in real ORs. We extend the PS framework in two ways. First, we build robust and discriminative part detectors using both color and depth images. We also present a novel descriptor for depth images, called histogram of depth differences (HDD). Second, we extend PS to 3D by proposing 3D pairwise constraints and a new method that makes exact inference tractable. Our approach is evaluated for pose estimation and clinician detection on a challenging RGB-D dataset recorded in a busy operating room during live surgeries. We conduct series of experiments to study the different part detectors in conjunction with the various 2D or 3D pairwise constraints. Our comparisons demonstrate that 3D PS with RGB-D part detectors significantly improves the results in a visually challenging operating environment.



### Optimized Kernel-based Projection Space of Riemannian Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1602.03570v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03570v3)
- **Published**: 2016-02-10 23:14:17+00:00
- **Updated**: 2016-03-15 05:24:22+00:00
- **Authors**: Azadeh Alavi, Vishal M Patel, Rama Chellappa
- **Comment**: 14 pages, 6 figures, conference
- **Journal**: None
- **Summary**: It is proven that encoding images and videos through Symmetric Positive Definite (SPD) matrices, and considering the Riemannian geometry of the resulting space, can lead to increased classification performance. Taking into account manifold geometry is typically done via embedding the manifolds in tangent spaces, or Reproducing Kernel Hilbert Spaces (RKHS). Recently, it was shown that embedding such manifolds into a Random Projection Spaces (RPS), rather than RKHS or tangent space, leads to higher classification and clustering performance. However, based on structure and dimensionality of the randomly generated hyperplanes, the classification performance over RPS may vary significantly. In addition, fine-tuning RPS is data expensive (as it requires validation-data), time consuming, and resource demanding. In this paper, we introduce an approach to learn an optimized kernel-based projection (with fixed dimensionality), by employing the concept of subspace clustering. As such, we encode the association of data points to the underlying subspace of each point, to generate meaningful hyperplanes. Further, we adopt the concept of dictionary learning and sparse coding, and discriminative analysis, for the optimized kernel-based projection space (OPS) on SPD manifolds. We validate our algorithm on several classification tasks. The experiment results also demonstrate that the proposed method outperforms state-of-the-art methods on such manifolds.



