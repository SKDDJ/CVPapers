# Arxiv Papers in cs.CV on 2016-02-12
### Global Deconvolutional Networks for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1602.03930v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03930v2)
- **Published**: 2016-02-12 00:03:38+00:00
- **Updated**: 2016-08-13 08:54:42+00:00
- **Authors**: Vladimir Nekrasov, Janghoon Ju, Jaesik Choi
- **Comment**: BMVC 2016 Conference
- **Journal**: None
- **Summary**: Semantic image segmentation is a principal problem in computer vision, where the aim is to correctly classify each individual pixel of an image into a semantic label. Its widespread use in many areas, including medical imaging and autonomous driving, has fostered extensive research in recent years. Empirical improvements in tackling this task have primarily been motivated by successful exploitation of Convolutional Neural Networks (CNNs) pre-trained for image classification and object recognition. However, the pixel-wise labelling with CNNs has its own unique challenges: (1) an accurate deconvolution, or upsampling, of low-resolution output into a higher-resolution segmentation mask and (2) an inclusion of global information, or context, within locally extracted features. To address these issues, we propose a novel architecture to conduct the equivalent of the deconvolution operation globally and acquire dense predictions. We demonstrate that it leads to improved performance of state-of-the-art semantic segmentation models on the PASCAL VOC 2012 benchmark, reaching 74.0% mean IU accuracy on the test set.



### Face Attribute Prediction Using Off-the-Shelf CNN Features
- **Arxiv ID**: http://arxiv.org/abs/1602.03935v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03935v2)
- **Published**: 2016-02-12 00:44:16+00:00
- **Updated**: 2016-06-21 14:27:33+00:00
- **Authors**: Yang Zhong, Josephine Sullivan, Haibo Li
- **Comment**: In proceeding of 2016 International Conference on Biometrics (ICB)
- **Journal**: None
- **Summary**: Predicting attributes from face images in the wild is a challenging computer vision problem. To automatically describe face attributes from face containing images, traditionally one needs to cascade three technical blocks --- face localization, facial descriptor construction, and attribute classification --- in a pipeline. As a typical classification problem, face attribute prediction has been addressed using deep learning. Current state-of-the-art performance was achieved by using two cascaded Convolutional Neural Networks (CNNs), which were specifically trained to learn face localization and attribute description. In this paper, we experiment with an alternative way of employing the power of deep representations from CNNs. Combining with conventional face localization techniques, we use off-the-shelf architectures trained for face recognition to build facial descriptors. Recognizing that the describable face attributes are diverse, our face descriptors are constructed from different levels of the CNNs for different attributes to best facilitate face attribute prediction. Experiments on two large datasets, LFWA and CelebA, show that our approach is entirely comparable to the state-of-the-art. Our findings not only demonstrate an efficient face attribute prediction approach, but also raise an important question: how to leverage the power of off-the-shelf CNN representations for novel tasks.



### An automatic method for segmentation of fission tracks in epidote crystal photomicrographs
- **Arxiv ID**: http://arxiv.org/abs/1602.03995v1
- **DOI**: 10.1016/j.cageo.2014.04.008
- **Categories**: **cs.CV**, 65T60, G.1.2; I.4.0; I.4.6; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1602.03995v1)
- **Published**: 2016-02-12 10:05:24+00:00
- **Updated**: 2016-02-12 10:05:24+00:00
- **Authors**: Alexandre Fioravante de Siqueira, Wagner Massayuki Nakasuga, Aylton Pagamisse, Carlos Alberto Tello Saenz, Aldo Eloizo Job
- **Comment**: 16 pages, 5 figures
- **Journal**: Computers & Geosciences, v. 69, pp. 55-61, aug 2014
- **Summary**: Manual identification of fission tracks has practical problems, such as variation due to observer-observation efficiency. An automatic processing method that could identify fission tracks in a photomicrograph could solve this problem and improve the speed of track counting. However, separation of non-trivial images is one of the most difficult tasks in image processing. Several commercial and free softwares are available, but these softwares are meant to be used in specific images. In this paper, an automatic method based on starlet wavelets is presented in order to separate fission tracks in mineral photomicrographs. Automatization is obtained by Matthews correlation coefficient, and results are evaluated by precision, recall and accuracy. This technique is an improvement of a method aimed at segmentation of scanning electron microscopy images. This method is applied in photomicrographs of epidote phenocrystals, in which accuracy higher than 89% was obtained in fission track segmentation, even for difficult images. Algorithms corresponding to the proposed method are available for download. Using the method presented here, an user could easily determine fission tracks in photomicrographs of mineral samples.



### Image Restoration and Reconstruction using Variable Splitting and Class-adapted Image Priors
- **Arxiv ID**: http://arxiv.org/abs/1602.04052v2
- **DOI**: None
- **Categories**: **cs.CV**, 94A08, 68U10, 47N10, I.4.5; I.4.4
- **Links**: [PDF](http://arxiv.org/pdf/1602.04052v2)
- **Published**: 2016-02-12 13:37:49+00:00
- **Updated**: 2016-05-23 13:04:39+00:00
- **Authors**: Afonso M. Teodoro, José M. Bioucas-Dias, Mário A. T. Figueiredo
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes using a Gaussian mixture model as a prior, for solving two image inverse problems, namely image deblurring and compressive imaging. We capitalize on the fact that variable splitting algorithms, like ADMM, are able to decouple the handling of the observation operator from that of the regularizer, and plug a state-of-the-art algorithm into the pure denoising step. Furthermore, we show that, when applied to a specific type of image, a Gaussian mixture model trained from an database of images of the same type is able to outperform current state-of-the-art methods.



### Convolutional Radio Modulation Recognition Networks
- **Arxiv ID**: http://arxiv.org/abs/1602.04105v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.04105v3)
- **Published**: 2016-02-12 16:28:59+00:00
- **Updated**: 2016-06-10 21:44:09+00:00
- **Authors**: Timothy J O'Shea, Johnathan Corgan, T. Charles Clancy
- **Comment**: None
- **Journal**: None
- **Summary**: We study the adaptation of convolutional neural networks to the complex temporal radio signal domain. We compare the efficacy of radio modulation classification using naively learned features against using expert features which are widely used in the field today and we show significant performance improvements. We show that blind temporal learning on large and densely encoded time series using deep convolutional neural networks is viable and a strong candidate approach for this task especially at low signal to noise ratio.



### Fast and Robust Hand Tracking Using Detection-Guided Optimization
- **Arxiv ID**: http://arxiv.org/abs/1602.04124v1
- **DOI**: 10.1109/CVPR.2015.7298941
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.04124v1)
- **Published**: 2016-02-12 17:05:04+00:00
- **Updated**: 2016-02-12 17:05:04+00:00
- **Authors**: Srinath Sridhar, Franziska Mueller, Antti Oulasvirta, Christian Theobalt
- **Comment**: 9 pages, Accepted version of paper published at CVPR 2015
- **Journal**: Computer Vision and Pattern Recognition (CVPR), 2015 IEEE
  Conference on , vol., no., pp.3213-3221, 7-12 June 2015
- **Summary**: Markerless tracking of hands and fingers is a promising enabler for human-computer interaction. However, adoption has been limited because of tracking inaccuracies, incomplete coverage of motions, low framerate, complex camera setups, and high computational requirements. In this paper, we present a fast method for accurately tracking rapid and complex articulations of the hand using a single depth camera. Our algorithm uses a novel detection-guided optimization strategy that increases the robustness and speed of pose estimation. In the detection step, a randomized decision forest classifies pixels into parts of the hand. In the optimization step, a novel objective function combines the detected part labels and a Gaussian mixture representation of the depth to estimate a pose that best fits the depth. Our approach needs comparably less computational resources which makes it extremely fast (50 fps without GPU support). The approach also supports varying static, or moving, camera-to-scene arrangements. We show the benefits of our method by evaluating on public datasets and comparing against previous work.



