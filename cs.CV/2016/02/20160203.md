# Arxiv Papers in cs.CV on 2016-02-03
### Learning Discriminative Features via Label Consistent Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1602.01168v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1602.01168v2)
- **Published**: 2016-02-03 02:41:33+00:00
- **Updated**: 2016-06-05 02:45:35+00:00
- **Authors**: Zhuolin Jiang, Yaming Wang, Larry Davis, Walt Andrews, Viktor Rozgic
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (CNN) enforces supervised information only at the output layer, and hidden layers are trained by back propagating the prediction error from the output layer without explicit supervision. We propose a supervised feature learning approach, Label Consistent Neural Network, which enforces direct supervision in late hidden layers. We associate each neuron in a hidden layer with a particular class label and encourage it to be activated for input signals from the same class. More specifically, we introduce a label consistency regularization called "discriminative representation error" loss for late hidden layers and combine it with classification error loss to build our overall objective function. This label consistency constraint alleviates the common problem of gradient vanishing and tends to faster convergence; it also makes the features derived from late hidden layers discriminative enough for classification even using a simple $k$-NN classifier, since input signals from the same class will have very similar representations. Experimental results demonstrate that our approach achieves state-of-the-art performances on several public benchmarks for action and object category recognition.



### Discriminative Sparse Neighbor Approximation for Imbalanced Learning
- **Arxiv ID**: http://arxiv.org/abs/1602.01197v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01197v1)
- **Published**: 2016-02-03 06:22:14+00:00
- **Updated**: 2016-02-03 06:22:14+00:00
- **Authors**: Chen Huang, Chen Change Loy, Xiaoou Tang
- **Comment**: 11 pages, 10 figures, In submission
- **Journal**: None
- **Summary**: Data imbalance is common in many vision tasks where one or more classes are rare. Without addressing this issue conventional methods tend to be biased toward the majority class with poor predictive accuracy for the minority class. These methods further deteriorate on small, imbalanced data that has a large degree of class overlap. In this study, we propose a novel discriminative sparse neighbor approximation (DSNA) method to ameliorate the effect of class-imbalance during prediction. Specifically, given a test sample, we first traverse it through a cost-sensitive decision forest to collect a good subset of training examples in its local neighborhood. Then we generate from this subset several class-discriminating but overlapping clusters and model each as an affine subspace. From these subspaces, the proposed DSNA iteratively seeks an optimal approximation of the test sample and outputs an unbiased prediction. We show that our method not only effectively mitigates the imbalance issue, but also allows the prediction to extrapolate to unseen data. The latter capability is crucial for achieving accurate prediction on small dataset with limited samples. The proposed imbalanced learning method can be applied to both classification and regression tasks at a wide range of imbalance levels. It significantly outperforms the state-of-the-art methods that do not possess an imbalance handling mechanism, and is found to perform comparably or even better than recent deep learning methods by using hand-crafted features only.



### Image and Information
- **Arxiv ID**: http://arxiv.org/abs/1602.01228v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01228v1)
- **Published**: 2016-02-03 09:11:45+00:00
- **Updated**: 2016-02-03 09:11:45+00:00
- **Authors**: Frank Nielsen
- **Comment**: 9 pages, 7 figures. to be published in french by Belin publisher for
  a collaborative book project on "Image and Communication"
- **Journal**: None
- **Summary**: A well-known old adage says that {\em "A picture is worth a thousand words!"} (attributed to the Chinese philosopher Confucius ca 500 years BC). But more precisely, what do we mean by information in images? And how can it be retrieved effectively by machines? We briefly highlight these puzzling questions in this column. But first of all, let us start by defining more precisely what is meant by an "Image."



### How Far are We from Solving Pedestrian Detection?
- **Arxiv ID**: http://arxiv.org/abs/1602.01237v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01237v2)
- **Published**: 2016-02-03 09:45:56+00:00
- **Updated**: 2016-06-21 11:33:13+00:00
- **Authors**: Shanshan Zhang, Rodrigo Benenson, Mohamed Omran, Jan Hosang, Bernt Schiele
- **Comment**: CVPR16 camera ready
- **Journal**: None
- **Summary**: Encouraged by the recent progress in pedestrian detection, we investigate the gap between current state-of-the-art methods and the "perfect single frame detector". We enable our analysis by creating a human baseline for pedestrian detection (over the Caltech dataset), and by manually clustering the recurrent errors of a top detector. Our results characterize both localization and background-versus-foreground errors. To address localization errors we study the impact of training annotation noise on the detector performance, and show that we can improve even with a small portion of sanitized training data. To address background/foreground discrimination, we study convnets for pedestrian detection, and discuss which factors affect their performance. Other than our in-depth analysis, we report top performance on the Caltech dataset, and provide a new sanitized set of training and test annotations.



### Learning scale-variant and scale-invariant features for deep image classification
- **Arxiv ID**: http://arxiv.org/abs/1602.01255v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01255v2)
- **Published**: 2016-02-03 10:42:04+00:00
- **Updated**: 2016-05-13 15:19:52+00:00
- **Authors**: Nanne van Noord, Eric Postma
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) require large image corpora to be trained on classification tasks. The variation in image resolutions, sizes of objects and patterns depicted, and image scales, hampers CNN training and performance, because the task-relevant information varies over spatial scales. Previous work attempting to deal with such scale variations focused on encouraging scale-invariant CNN representations. However, scale-invariant representations are incomplete representations of images, because images contain scale-variant information as well. This paper addresses the combined development of scale-invariant and scale-variant representations. We propose a multi- scale CNN method to encourage the recognition of both types of features and evaluate it on a challenging image classification task involving task-relevant characteristics at multiple scales. The results show that our multi-scale CNN outperforms single-scale CNN. This leads to the conclusion that encouraging the combined development of a scale-invariant and scale-variant representation in CNNs is beneficial to image recognition performance.



### A Framework for Fast Image Deconvolution with Incomplete Observations
- **Arxiv ID**: http://arxiv.org/abs/1602.01410v2
- **DOI**: 10.1109/TIP.2016.2603920
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1602.01410v2)
- **Published**: 2016-02-03 18:57:02+00:00
- **Updated**: 2016-08-30 17:40:01+00:00
- **Authors**: Miguel Simões, Luis B. Almeida, José Bioucas-Dias, Jocelyn Chanussot
- **Comment**: IEEE Trans. Image Process., to be published. 15 pages, 11 figures.
  MATLAB code available at
  https://github.com/alfaiate/DeconvolutionIncompleteObs
- **Journal**: None
- **Summary**: In image deconvolution problems, the diagonalization of the underlying operators by means of the FFT usually yields very large speedups. When there are incomplete observations (e.g., in the case of unknown boundaries), standard deconvolution techniques normally involve non-diagonalizable operators, resulting in rather slow methods, or, otherwise, use inexact convolution models, resulting in the occurrence of artifacts in the enhanced images. In this paper, we propose a new deconvolution framework for images with incomplete observations that allows us to work with diagonalized convolution operators, and therefore is very fast. We iteratively alternate the estimation of the unknown pixels and of the deconvolved image, using, e.g., an FFT-based deconvolution method. This framework is an efficient, high-quality alternative to existing methods of dealing with the image boundaries, such as edge tapering. It can be used with any fast deconvolution method. We give an example in which a state-of-the-art method that assumes periodic boundary conditions is extended, through the use of this framework, to unknown boundary conditions. Furthermore, we propose a specific implementation of this framework, based on the alternating direction method of multipliers (ADMM). We provide a proof of convergence for the resulting algorithm, which can be seen as a "partial" ADMM, in which not all variables are dualized. We report experimental comparisons with other primal-dual methods, where the proposed one performed at the level of the state of the art. Four different kinds of applications were tested in the experiments: deconvolution, deconvolution with inpainting, superresolution, and demosaicing, all with unknown boundaries.



### Latent-Class Hough Forests for 6 DoF Object Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1602.01464v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01464v1)
- **Published**: 2016-02-03 20:53:33+00:00
- **Updated**: 2016-02-03 20:53:33+00:00
- **Authors**: Rigas Kouskouridas, Alykhan Tejani, Andreas Doumanoglou, Danhang Tang, Tae-Kyun Kim
- **Comment**: PAMI submission, project page:
  http://www.iis.ee.ic.ac.uk/rkouskou/research/LCHF.html
- **Journal**: None
- **Summary**: In this paper we present Latent-Class Hough Forests, a method for object detection and 6 DoF pose estimation in heavily cluttered and occluded scenarios. We adapt a state of the art template matching feature into a scale-invariant patch descriptor and integrate it into a regression forest using a novel template-based split function. We train with positive samples only and we treat class distributions at the leaf nodes as latent variables. During testing we infer by iteratively updating these distributions, providing accurate estimation of background clutter and foreground occlusions and, thus, better detection rate. Furthermore, as a by-product, our Latent-Class Hough Forests can provide accurate occlusion aware segmentation masks, even in the multi-instance scenario. In addition to an existing public dataset, which contains only single-instance sequences with large amounts of clutter, we have collected two, more challenging, datasets for multiple-instance detection containing heavy 2D and 3D clutter as well as foreground occlusions. We provide extensive experiments on the various parameters of the framework such as patch size, number of trees and number of iterations to infer class distributions at test time. We also evaluate the Latent-Class Hough Forests on all datasets where we outperform state of the art methods.



### A simple method for estimating the fractal dimension from digital images: The compression dimension
- **Arxiv ID**: http://arxiv.org/abs/1602.02139v2
- **DOI**: 10.1016/j.chaos.2016.08.002
- **Categories**: **cs.GR**, cs.CV, physics.data-an
- **Links**: [PDF](http://arxiv.org/pdf/1602.02139v2)
- **Published**: 2016-02-03 23:43:26+00:00
- **Updated**: 2016-08-05 12:27:51+00:00
- **Authors**: P. Chamorro-Posada
- **Comment**: None
- **Journal**: Chaos Solitons Fract 91 (2016) 562-572
- **Summary**: The fractal structure of real world objects is often analyzed using digital images. In this context, the compression fractal dimension is put forward. It provides a simple method for the direct estimation of the dimension of fractals stored as digital image files. The computational scheme can be implemented using readily available free software. Its simplicity also makes it very interesting for introductory elaborations of basic concepts of fractal geometry, complexity, and information theory. A test of the computational scheme using limited-quality images of well-defined fractal sets obtained from the Internet and free software has been performed. Also, a systematic evaluation of the proposed method using computer generated images of the Weierstrass cosine function shows an accuracy comparable to those of the methods most commonly used to estimate the dimension of fractal data sequences applied to the same test problem.



