# Arxiv Papers in cs.CV on 2016-02-01
### Scene Invariant Crowd Segmentation and Counting Using Scale-Normalized Histogram of Moving Gradients (HoMG)
- **Arxiv ID**: http://arxiv.org/abs/1602.00386v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00386v1)
- **Published**: 2016-02-01 04:07:32+00:00
- **Updated**: 2016-02-01 04:07:32+00:00
- **Authors**: Parthipan Siva, Mohammad Javad Shafiee, Mike Jamieson, Alexander Wong
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: The problem of automated crowd segmentation and counting has garnered significant interest in the field of video surveillance. This paper proposes a novel scene invariant crowd segmentation and counting algorithm designed with high accuracy yet low computational complexity in mind, which is key for widespread industrial adoption. A novel low-complexity, scale-normalized feature called Histogram of Moving Gradients (HoMG) is introduced for highly effective spatiotemporal representation of individuals and crowds within a video. Real-time crowd segmentation is achieved via boosted cascade of weak classifiers based on sliding-window HoMG features, while linear SVM regression of crowd-region HoMG features is employed for real-time crowd counting. Experimental results using multi-camera crowd datasets show that the proposed algorithm significantly outperform state-of-the-art crowd counting algorithms, as well as achieve very promising crowd segmentation results, thus demonstrating the efficacy of the proposed method for highly-accurate, real-time video-driven crowd analysis.



### Transfer Learning Based on AdaBoost for Feature Selection from Multiple ConvNet Layer Features
- **Arxiv ID**: http://arxiv.org/abs/1602.00417v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00417v2)
- **Published**: 2016-02-01 08:02:06+00:00
- **Updated**: 2016-03-25 12:03:49+00:00
- **Authors**: Jumabek Alikhanov, Myeong Hyeon Ga, Seunghyun Ko, Geun-Sik Jo
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Networks (ConvNets) are powerful models that learn hierarchies of visual features, which could also be used to obtain image representations for transfer learning. The basic pipeline for transfer learning is to first train a ConvNet on a large dataset (source task) and then use feed-forward units activation of the trained ConvNet as image representation for smaller datasets (target task). Our key contribution is to demonstrate superior performance of multiple ConvNet layer features over single ConvNet layer features. Combining multiple ConvNet layer features will result in more complex feature space with some features being repetitive. This requires some form of feature selection. We use AdaBoost with single stumps to implicitly select only distinct features that are useful towards classification from concatenated ConvNet features. Experimental results show that using multiple ConvNet layer activation features instead of single ConvNet layer features consistently will produce superior performance. Improvements becomes significant as we increase the distance between source task and the target task.



### A Deep Learning Based Fast Image Saliency Detection Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1602.00577v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00577v1)
- **Published**: 2016-02-01 16:14:57+00:00
- **Updated**: 2016-02-01 16:14:57+00:00
- **Authors**: Hengyue Pan, Hui Jiang
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1505.01173
- **Journal**: None
- **Summary**: In this paper, we propose a fast deep learning method for object saliency detection using convolutional neural networks. In our approach, we use a gradient descent method to iteratively modify the input images based on the pixel-wise gradients to reduce a pre-defined cost function, which is defined to measure the class-specific objectness and clamp the class-irrelevant outputs to maintain image background. The pixel-wise gradients can be efficiently computed using the back-propagation algorithm. We further apply SLIC superpixels and LAB color based low level saliency features to smooth and refine the gradients. Our methods are quite computationally efficient, much faster than other deep learning based saliency methods. Experimental results on two benchmark tasks, namely Pascal VOC 2012 and MSRA10k, have shown that our proposed methods can generate high-quality salience maps, at least comparable with many slow and complicated deep learning methods. Comparing with the pure low-level methods, our approach excels in handling many difficult images, which contain complex background, highly-variable salient objects, multiple objects, and/or very small salient objects.



### Improving Vertebra Segmentation through Joint Vertebra-Rib Atlases
- **Arxiv ID**: http://arxiv.org/abs/1602.00585v1
- **DOI**: 10.1117/12.2217118
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00585v1)
- **Published**: 2016-02-01 16:36:42+00:00
- **Updated**: 2016-02-01 16:36:42+00:00
- **Authors**: Yinong Wang, Jianhua Yao, Holger R. Roth, Joseph E. Burns, Ronald M. Summers
- **Comment**: Manuscript to be presented at SPIE Medical Imaging 2016, 27 February
  - 3 March, 2016, San Diego, California, USA
- **Journal**: None
- **Summary**: Accurate spine segmentation allows for improved identification and quantitative characterization of abnormalities of the vertebra, such as vertebral fractures. However, in existing automated vertebra segmentation methods on computed tomography (CT) images, leakage into nearby bones such as ribs occurs due to the close proximity of these visibly intense structures in a 3D CT volume. To reduce this error, we propose the use of joint vertebra-rib atlases to improve the segmentation of vertebrae via multi-atlas joint label fusion. Segmentation was performed and evaluated on CTs containing 106 thoracic and lumbar vertebrae from 10 pathological and traumatic spine patients on an individual vertebra level basis. Vertebra atlases produced errors where the segmentation leaked into the ribs. The use of joint vertebra-rib atlases produced a statistically significant increase in the Dice coefficient from 92.5 $\pm$ 3.1% to 93.8 $\pm$ 2.1% for the left and right transverse processes and a decrease in the mean and max surface distance from 0.75 $\pm$ 0.60mm and 8.63 $\pm$ 4.44mm to 0.30 $\pm$ 0.27mm and 3.65 $\pm$ 2.87mm, respectively.



### Algorithm-Induced Prior for Image Restoration
- **Arxiv ID**: http://arxiv.org/abs/1602.00715v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00715v1)
- **Published**: 2016-02-01 21:24:55+00:00
- **Updated**: 2016-02-01 21:24:55+00:00
- **Authors**: Stanley H. Chan
- **Comment**: None
- **Journal**: None
- **Summary**: This paper studies a type of image priors that are constructed implicitly through the alternating direction method of multiplier (ADMM) algorithm, called the algorithm-induced prior. Different from classical image priors which are defined before running the reconstruction algorithm, algorithm-induced priors are defined by the denoising procedure used to replace one of the two modules in the ADMM algorithm. Since such prior is not explicitly defined, analyzing the performance has been difficult in the past.   Focusing on the class of symmetric smoothing filters, this paper presents an explicit expression of the prior induced by the ADMM algorithm. The new prior is reminiscent to the conventional graph Laplacian but with stronger reconstruction performance. It can also be shown that the overall reconstruction has an efficient closed-form implementation if the associated symmetric smoothing filter is low rank. The results are validated with experiments on image inpainting.



### Combining ConvNets with Hand-Crafted Features for Action Recognition Based on an HMM-SVM Classifier
- **Arxiv ID**: http://arxiv.org/abs/1602.00749v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.00749v1)
- **Published**: 2016-02-01 23:57:22+00:00
- **Updated**: 2016-02-01 23:57:22+00:00
- **Authors**: Pichao Wang, Zhaoyang Li, Yonghong Hou, Wanqing Li
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a new framework for RGB-D-based action recognition that takes advantages of hand-designed features from skeleton data and deeply learned features from depth maps, and exploits effectively both the local and global temporal information. Specifically, depth and skeleton data are firstly augmented for deep learning and making the recognition insensitive to view variance. Secondly, depth sequences are segmented using the hand-crafted features based on skeleton joints motion histogram to exploit the local temporal information. All training se gments are clustered using an Infinite Gaussian Mixture Model (IGMM) through Bayesian estimation and labelled for training Convolutional Neural Networks (ConvNets) on the depth maps. Thus, a depth sequence can be reliably encoded into a sequence of segment labels. Finally, the sequence of labels is fed into a joint Hidden Markov Model and Support Vector Machine (HMM-SVM) classifier to explore the global temporal information for final recognition.



