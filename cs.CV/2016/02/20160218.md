# Arxiv Papers in cs.CV on 2016-02-18
### Boost Picking: A Universal Method on Converting Supervised Classification to Semi-supervised Classification
- **Arxiv ID**: http://arxiv.org/abs/1602.05659v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1602.05659v3)
- **Published**: 2016-02-18 02:24:54+00:00
- **Updated**: 2016-11-12 09:25:54+00:00
- **Authors**: Fuqiang Liu, Fukun Bi, Yiding Yang, Liang Chen
- **Comment**: This paper has been withdraw by the author due to format error
- **Journal**: None
- **Summary**: This paper proposes a universal method, Boost Picking, to train supervised classification models mainly by un-labeled data. Boost Picking only adopts two weak classifiers to estimate and correct the error. It is theoretically proved that Boost Picking could train a supervised model mainly by un-labeled data as effectively as the same model trained by 100% labeled data, only if recalls of the two weak classifiers are all greater than zero and the sum of precisions is greater than one. Based on Boost Picking, we present "Test along with Training (TawT)" to improve the generalization of supervised models. Both Boost Picking and TawT are successfully tested in varied little data sets.



### Feature-Area Optimization: A Novel SAR Image Registration Method
- **Arxiv ID**: http://arxiv.org/abs/1602.05660v1
- **DOI**: 10.1109/LGRS.2015.2507982
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05660v1)
- **Published**: 2016-02-18 02:25:16+00:00
- **Updated**: 2016-02-18 02:25:16+00:00
- **Authors**: Fuqiang Liu, Fukun Bi, Liang Chen, Hao Shi, Wei Liu
- **Comment**: 5 pages, 5 figures
- **Journal**: IEEE Geoscience and Remote Sensing Letter, Year: 2016, Volume: 13,
  Pages: 242 - 246
- **Summary**: This letter proposes a synthetic aperture radar (SAR) image registration method named Feature-Area Optimization (FAO). First, the traditional area-based optimization model is reconstructed and decomposed into three key but uncertain factors: initialization, slice set and regularization. Next, structural features are extracted by scale invariant feature transform (SIFT) in dual-resolution space (SIFT-DRS), a novel SIFT-Like method dedicated to FAO. Then, the three key factors are determined based on these features. Finally, solving the factor-determined optimization model can get the registration result. A series of experiments demonstrate that the proposed method can register multi-temporal SAR images accurately and efficiently.



### Weighted Unsupervised Learning for 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1602.05920v2
- **DOI**: 10.14569/IJACSA.2016.070180
- **Categories**: **cs.CV**, cs.GR, cs.LG, cs.MM, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1602.05920v2)
- **Published**: 2016-02-18 19:40:26+00:00
- **Updated**: 2018-06-04 23:51:27+00:00
- **Authors**: Kamran Kowsari, Manal H. Alassaf
- **Comment**: IJACSA
- **Journal**: None
- **Summary**: This paper introduces a novel weighted unsupervised learning for object detection using an RGB-D camera. This technique is feasible for detecting the moving objects in the noisy environments that are captured by an RGB-D camera. The main contribution of this paper is a real-time algorithm for detecting each object using weighted clustering as a separate cluster. In a preprocessing step, the algorithm calculates the pose 3D position X, Y, Z and RGB color of each data point and then it calculates each data point's normal vector using the point's neighbor. After preprocessing, our algorithm calculates k-weights for each data point; each weight indicates membership. Resulting in clustered objects of the scene.



### RandomOut: Using a convolutional gradient norm to rescue convolutional filters
- **Arxiv ID**: http://arxiv.org/abs/1602.05931v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05931v3)
- **Published**: 2016-02-18 20:05:53+00:00
- **Updated**: 2017-05-29 04:49:22+00:00
- **Authors**: Joseph Paul Cohen, Henry Z. Lo, Wei Ding
- **Comment**: Extended version of the ICLR 2016 workshop track paper
- **Journal**: None
- **Summary**: Filters in convolutional neural networks are sensitive to their initialization. The random numbers used to initialize filters are a bias and determine if you will "win" and converge to a satisfactory local minimum so we call this The Filter Lottery. We observe that the 28x28 Inception-V3 model without Batch Normalization fails to train 26% of the time when varying the random seed alone. This is a problem that affects the trial and error process of designing a network. Because random seeds have a large impact it makes it hard to evaluate a network design without trying many different random starting weights. This work aims to reduce the bias imposed by the initial weights so a network converges more consistently. We propose to evaluate and replace specific convolutional filters that have little impact on the prediction. We use the gradient norm to evaluate the impact of a filter on error, and re-initialize filters when the gradient norm of its weights falls below a specific threshold. This consistently improves accuracy on the 28x28 Inception-V3 with a median increase of +3.3%. In effect our method RandomOut increases the number of filters explored without increasing the size of the network. We observe that the RandomOut method has more consistent generalization performance, having a standard deviation of 1.3% instead of 2% when varying random seeds, and does so faster and with fewer parameters.



### Multi-resolution Compressive Sensing Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1602.05941v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.05941v1)
- **Published**: 2016-02-18 20:50:50+00:00
- **Updated**: 2016-02-18 20:50:50+00:00
- **Authors**: Adriana Gonzalez, Hong Jiang, Gang Huang, Laurent Jacques
- **Comment**: 5 pages; 4 figures
- **Journal**: None
- **Summary**: We consider the problem of reconstructing an image from compressive measurements using a multi-resolution grid. In this context, the reconstructed image is divided into multiple regions, each one with a different resolution. This problem arises in situations where the image to reconstruct contains a certain region of interest (RoI) that is more important than the rest. Through a theoretical analysis and simulation experiments we show that the multi-resolution reconstruction provides a higher quality of the RoI compared to the traditional single-resolution approach.



### Plücker Correction Problem: Analysis and Improvements in Efficiency
- **Arxiv ID**: http://arxiv.org/abs/1602.05990v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1602.05990v1)
- **Published**: 2016-02-18 22:22:18+00:00
- **Updated**: 2016-02-18 22:22:18+00:00
- **Authors**: João R. Cardoso, Pedro Miraldo, Helder Araujo
- **Comment**: None
- **Journal**: None
- **Summary**: A given six dimensional vector represents a 3D straight line in Plucker coordinates if its coordinates satisfy the Klein quadric constraint. In many problems aiming to find the Plucker coordinates of lines, noise in the data and other type of errors contribute for obtaining 6D vectors that do not correspond to lines, because of that constraint. A common procedure to overcome this drawback is to find the Plucker coordinates of the lines that are closest to those vectors. This is known as the Plucker correction problem. In this article we propose a simple, closed-form, and global solution for this problem. When compared with the state-of-the-art method, one can conclude that our algorithm is easier and requires much less operations than previous techniques (it does not require Singular Value Decomposition techniques).



