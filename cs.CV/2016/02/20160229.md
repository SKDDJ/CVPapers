# Arxiv Papers in cs.CV on 2016-02-29
### Pandora: Description of a Painting Database for Art Movement Recognition with Baselines and Perspectives
- **Arxiv ID**: http://arxiv.org/abs/1602.08855v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.08855v1)
- **Published**: 2016-02-29 08:24:01+00:00
- **Updated**: 2016-02-29 08:24:01+00:00
- **Authors**: Corneliu Florea, Razvan Condorovici, Constantin Vertan, Raluca Boia, Laura Florea, Ruxandra Vranceanu
- **Comment**: 11 pages, 1 figure, 6 tables
- **Journal**: None
- **Summary**: To facilitate computer analysis of visual art, in the form of paintings, we introduce Pandora (Paintings Dataset for Recognizing the Art movement) database, a collection of digitized paintings labelled with respect to the artistic movement. Noting that the set of databases available as benchmarks for evaluation is highly reduced and most existing ones are limited in variability and number of images, we propose a novel large scale dataset of digital paintings. The database consists of more than 7700 images from 12 art movements. Each genre is illustrated by a number of images varying from 250 to nearly 1000. We investigate how local and global features and classification systems are able to recognize the art movement. Our experimental results suggest that accurate recognition is achievable by a combination of various categories.To facilitate computer analysis of visual art, in the form of paintings, we introduce Pandora (Paintings Dataset for Recognizing the Art movement) database, a collection of digitized paintings labelled with respect to the artistic movement. Noting that the set of databases available as benchmarks for evaluation is highly reduced and most existing ones are limited in variability and number of images, we propose a novel large scale dataset of digital paintings. The database consists of more than 7700 images from 12 art movements. Each genre is illustrated by a number of images varying from 250 to nearly 1000. We investigate how local and global features and classification systems are able to recognize the art movement. Our experimental results suggest that accurate recognition is achievable by a combination of various categories.



### FALDOI: A new minimization strategy for large displacement variational optical flow
- **Arxiv ID**: http://arxiv.org/abs/1602.08960v3
- **DOI**: None
- **Categories**: **cs.CV**, 68U10, 49M29, 65K10
- **Links**: [PDF](http://arxiv.org/pdf/1602.08960v3)
- **Published**: 2016-02-29 13:54:39+00:00
- **Updated**: 2016-09-29 11:38:52+00:00
- **Authors**: Roberto P. Palomares, Enric Meinhardt-Llopis, Coloma Ballester, Gloria Haro
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a large displacement optical flow method that introduces a new strategy to compute a good local minimum of any optical flow energy functional. The method requires a given set of discrete matches, which can be extremely sparse, and an energy functional which locally guides the interpolation from those matches. In particular, the matches are used to guide a structured coordinate-descent of the energy functional around these keypoints. It results in a two-step minimization method at the finest scale which is very robust to the inevitable outliers of the sparse matcher and able to capture large displacements of small objects. Its benefits over other variational methods that also rely on a set of sparse matches are its robustness against very few matches, high levels of noise and outliers. We validate our proposal using several optical flow variational models. The results consistently outperform the coarse-to-fine approaches and achieve good qualitative and quantitative performance on the standard optical flow benchmarks.



### Clustering Based Feature Learning on Variable Stars
- **Arxiv ID**: http://arxiv.org/abs/1602.08977v1
- **DOI**: 10.3847/0004-637X/820/2/138
- **Categories**: **astro-ph.SR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.08977v1)
- **Published**: 2016-02-29 14:26:17+00:00
- **Updated**: 2016-02-29 14:26:17+00:00
- **Authors**: Crist√≥bal Mackenzie, Karim Pichara, Pavlos Protopapas
- **Comment**: None
- **Journal**: ApJ 820 (2016) 138
- **Summary**: The success of automatic classification of variable stars strongly depends on the lightcurve representation. Usually, lightcurves are represented as a vector of many statistical descriptors designed by astronomers called features. These descriptors commonly demand significant computational power to calculate, require substantial research effort to develop and do not guarantee good performance on the final classification task. Today, lightcurve representation is not entirely automatic; algorithms that extract lightcurve features are designed by humans and must be manually tuned up for every survey. The vast amounts of data that will be generated in future surveys like LSST mean astronomers must develop analysis pipelines that are both scalable and automated. Recently, substantial efforts have been made in the machine learning community to develop methods that prescind from expert-designed and manually tuned features for features that are automatically learned from data. In this work we present what is, to our knowledge, the first unsupervised feature learning algorithm designed for variable stars. Our method first extracts a large number of lightcurve subsequences from a given set of photometric data, which are then clustered to find common local patterns in the time series. Representatives of these patterns, called exemplars, are then used to transform lightcurves of a labeled set into a new representation that can then be used to train an automatic classifier. The proposed algorithm learns the features from both labeled and unlabeled lightcurves, overcoming the bias generated when the learning process is done only with labeled data. We test our method on MACHO and OGLE datasets; the results show that the classification performance we achieve is as good and in some cases better than the performance achieved using traditional features, while the computational cost is significantly lower.



### Evaluation of Deep Learning based Pose Estimation for Sign Language Recognition
- **Arxiv ID**: http://arxiv.org/abs/1602.09065v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.09065v3)
- **Published**: 2016-02-29 17:45:10+00:00
- **Updated**: 2016-04-19 23:43:10+00:00
- **Authors**: Srujana Gattupalli, Amir Ghaderi, Vassilis Athitsos
- **Comment**: None
- **Journal**: None
- **Summary**: Human body pose estimation and hand detection are two important tasks for systems that perform computer vision-based sign language recognition(SLR). However, both tasks are challenging, especially when the input is color videos, with no depth information. Many algorithms have been proposed in the literature for these tasks, and some of the most successful recent algorithms are based on deep learning. In this paper, we introduce a dataset for human pose estimation for SLR domain. We evaluate the performance of two deep learning based pose estimation methods, by performing user-independent experiments on our dataset. We also perform transfer learning, and we obtain results that demonstrate that transfer learning can improve pose estimation accuracy. The dataset and results from these methods can create a useful baseline for future works.



### Modular Tracking Framework: A Unified Approach to Registration based Tracking
- **Arxiv ID**: http://arxiv.org/abs/1602.09130v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1602.09130v4)
- **Published**: 2016-02-29 20:39:52+00:00
- **Updated**: 2018-05-18 02:15:42+00:00
- **Authors**: Abhineet Singh, Martin Jagersand
- **Comment**: Under consideration at Computer Vision and Image Understanding
- **Journal**: None
- **Summary**: This paper presents a modular, extensible and highly efficient open source framework for registration based tracking called Modular Tracking Framework (MTF). Targeted at robotics applications, it is implemented entirely in C++ and designed from the ground up to easily integrate with systems that support any of several major vision and robotics libraries including OpenCV, ROS, ViSP and Eigen. It implements more methods, is faster, and more precise than other existing systems. Further, the theoretical basis for its design is a new way to conceptualize registration based trackers that decomposes them into three constituent sub modules - Search Method (SM), Appearance Model (AM) and State Space Model (SSM).   In the process, we integrate many important advances published after Baker \& Matthews' landmark work in 2004. In addition to being a practical solution for fast and high precision tracking, MTF can also serve as a useful research tool by allowing existing and new methods for any of the sub modules to be studied better. When a new method is introduced for one of these, the breakdown can help to experimentally find the combination of methods for the others that is optimum for it. By extensive use of generic programming, MTF makes it easy to plug in a new method for any of the sub modules so that it can not only be tested comprehensively with existing methods but also become immediately available for deployment in any project that uses the framework. With 16 AMs, 11 SMs and 13 SSMs implemented already, MTF provides over 2000 distinct single layer trackers. It also allows two or more of these to be combined together in several ways to create a practically unlimited variety of novel multi layer trackers.



