# Arxiv Papers in cs.CV on 2016-02-09
### Parameterizing Region Covariance: An Efficient Way To Apply Sparse Codes On Second Order Statistics
- **Arxiv ID**: http://arxiv.org/abs/1602.02822v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.02822v1)
- **Published**: 2016-02-09 00:07:05+00:00
- **Updated**: 2016-02-09 00:07:05+00:00
- **Authors**: Xiyang Dai, Sameh Khamis, Yangmuzi Zhang, Larry S. Davis
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse representations have been successfully applied to signal processing, computer vision and machine learning. Currently there is a trend to learn sparse models directly on structure data, such as region covariance. However, such methods when combined with region covariance often require complex computation. We present an approach to transform a structured sparse model learning problem to a traditional vectorized sparse modeling problem by constructing a Euclidean space representation for region covariance matrices. Our new representation has multiple advantages. Experiments on several vision tasks demonstrate competitive performance with the state-of-the-art methods.



### The Role of Typicality in Object Classification: Improving The Generalization Capacity of Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1602.02865v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1602.02865v1)
- **Published**: 2016-02-09 05:30:33+00:00
- **Updated**: 2016-02-09 05:30:33+00:00
- **Authors**: Babak Saleh, Ahmed Elgammal, Jacob Feldman
- **Comment**: In Submission
- **Journal**: None
- **Summary**: Deep artificial neural networks have made remarkable progress in different tasks in the field of computer vision. However, the empirical analysis of these models and investigation of their failure cases has received attention recently. In this work, we show that deep learning models cannot generalize to atypical images that are substantially different from training images. This is in contrast to the superior generalization ability of the visual system in the human brain. We focus on Convolutional Neural Networks (CNN) as the state-of-the-art models in object recognition and classification; investigate this problem in more detail, and hypothesize that training CNN models suffer from unstructured loss minimization. We propose computational models to improve the generalization capacity of CNNs by considering how typical a training image looks like. By conducting an extensive set of experiments we show that involving a typicality measure can improve the classification results on a new set of images by a large margin. More importantly, this significant improvement is achieved without fine-tuning the CNN model on the target image set.



### Detection and Visualization of Endoleaks in CT Data for Monitoring of Thoracic and Abdominal Aortic Aneurysm Stents
- **Arxiv ID**: http://arxiv.org/abs/1602.02881v1
- **DOI**: 10.1117/12.769414
- **Categories**: **cs.CV**, cs.CG, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1602.02881v1)
- **Published**: 2016-02-09 07:42:05+00:00
- **Updated**: 2016-02-09 07:42:05+00:00
- **Authors**: Jing Lu, Jan Egger, Andreas Wimmer, Stefan Gro√ükopf, Bernd Freisleben
- **Comment**: 7 pages, 7 figures, 1 table, 12 references, Proc. SPIE 6918, Medical
  Imaging 2008: Visualization, Image-Guided Procedures, and Modeling, 69181F
  (17 March 2008)
- **Journal**: None
- **Summary**: In this paper we present an efficient algorithm for the segmentation of the inner and outer boundary of thoratic and abdominal aortic aneurysms (TAA & AAA) in computed tomography angiography (CTA) acquisitions. The aneurysm segmentation includes two steps: first, the inner boundary is segmented based on a grey level model with two thresholds; then, an adapted active contour model approach is applied to the more complicated outer boundary segmentation, with its initialization based on the available inner boundary segmentation. An opacity image, which aims at enhancing important features while reducing spurious structures, is calculated from the CTA images and employed to guide the deformation of the model. In addition, the active contour model is extended by a constraint force that prevents intersections of the inner and outer boundary and keeps the outer boundary at a distance, given by the thrombus thickness, to the inner boundary. Based upon the segmentation results, we can measure the aneurysm size at each centerline point on the centerline orthogonal multiplanar reformatting (MPR) plane. Furthermore, a 3D TAA or AAA model is reconstructed from the set of segmented contours, and the presence of endoleaks is detected and highlighted. The implemented method has been evaluated on nine clinical CTA data sets with variations in anatomy and location of the pathology and has shown promising results.



### Joint Defogging and Demosaicking
- **Arxiv ID**: http://arxiv.org/abs/1602.02885v1
- **DOI**: 10.1109/TIP.2016.2631880
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.02885v1)
- **Published**: 2016-02-09 08:01:20+00:00
- **Updated**: 2016-02-09 08:01:20+00:00
- **Authors**: Y. J. Lee, K. Hirakawa, T. Q. Nguyen
- **Comment**: None
- **Journal**: None
- **Summary**: Image defogging is a technique used extensively for enhancing visual quality of images in bad weather condition. Even though defogging algorithms have been well studied, defogging performance is degraded by demosaicking artifacts and sensor noise amplification in distant scenes. In order to improve visual quality of restored images, we propose a novel approach to perform defogging and demosaicking simultaneously. We conclude that better defogging performance with fewer artifacts can be achieved when a defogging algorithm is combined with a demosaicking algorithm simultaneously. We also demonstrate that the proposed joint algorithm has the benefit of suppressing noise amplification in distant scene. In addition, we validate our theoretical analysis and observations for both synthesized datasets with ground truth fog-free images and natural scene datasets captured in a raw format.



### Challenges of Integrating A Priori Information Efficiently in the Discovery of Spatio-Temporal Objects in Large Databases
- **Arxiv ID**: http://arxiv.org/abs/1602.02938v1
- **DOI**: None
- **Categories**: **cs.CV**, 92-08, 92C37, 92C55, 68U10
- **Links**: [PDF](http://arxiv.org/pdf/1602.02938v1)
- **Published**: 2016-02-09 11:22:58+00:00
- **Updated**: 2016-02-09 11:22:58+00:00
- **Authors**: Benjamin Schott, Johannes Stegmaier, Masanari Takamiya, Ralf Mikut
- **Comment**: Proc., 25. Workshop Computational Intelligence, Dortmund, 2015
- **Journal**: None
- **Summary**: Using the knowledge discovery framework, it is possible to explore object databases and extract groups of objects with highly heterogeneous movement behavior by efficiently integrating a priori knowledge through interacting with the framework. The whole process is modular expandable and is therefore adaptive to any problem formulation. Further, the flexible use of different information allocation processes reveal a great potential to efficiently incorporate the a priori knowledge of different users in different ways. Therefore, the stepwise knowledge discovery process embedded in the knowledge discovery framework is described in detail to point out the flexibility of such a system incorporating object databases from different applications. The described framework can be used to gain knowledge out of object databases in many different fields. This knowledge can be used to gain further insights and improve the understanding of underlying phenomena. The functionality of the proposed framework is exemplarily demonstrated using a benchmark database based on real biological object data.



### Segmental Spatiotemporal CNNs for Fine-grained Action Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1602.02995v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1602.02995v4)
- **Published**: 2016-02-09 14:28:44+00:00
- **Updated**: 2016-09-30 15:08:34+00:00
- **Authors**: Colin Lea, Austin Reiter, Rene Vidal, Gregory D. Hager
- **Comment**: Updated from the ECCV 2016 version. We fixed an important
  mathematical error and made the section on segmental inference clearer
- **Journal**: None
- **Summary**: Joint segmentation and classification of fine-grained actions is important for applications of human-robot interaction, video surveillance, and human skill evaluation. However, despite substantial recent progress in large-scale action classification, the performance of state-of-the-art fine-grained action recognition approaches remains low. We propose a model for action segmentation which combines low-level spatiotemporal features with a high-level segmental classifier. Our spatiotemporal CNN is comprised of a spatial component that uses convolutional filters to capture information about objects and their relationships, and a temporal component that uses large 1D convolutional filters to capture information about how object relationships change across time. These features are used in tandem with a semi-Markov model that models transitions from one action to another. We introduce an efficient constrained segmental inference algorithm for this model that is orders of magnitude faster than the current approach. We highlight the effectiveness of our Segmental Spatiotemporal CNN on cooking and surgical action datasets for which we observe substantially improved performance relative to recent baseline methods.



### Face Recognition: Perspectives from the Real-World
- **Arxiv ID**: http://arxiv.org/abs/1602.02999v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.02999v1)
- **Published**: 2016-02-09 14:31:46+00:00
- **Updated**: 2016-02-09 14:31:46+00:00
- **Authors**: Bappaditya Mandal
- **Comment**: 11 pages, 4 figures
- **Journal**: None
- **Summary**: In this paper, we analyze some of our real-world deployment of face recognition (FR) systems for various applications and discuss the gaps between expectations of the user and what the system can deliver. We evaluate some of our proposed algorithms with ad-hoc modifications for applications such as FR on wearable devices (like Google Glass), monitoring of elderly people in senior citizens centers, FR of children in child care centers and face matching between a scanned IC/passport face image and a few live webcam images for automatic hotel/resort checkouts. We describe each of these applications, the challenges involved and proposed solutions. Since FR is intuitive in nature and we human beings use it for interactions with the outside world, people have high expectations of its performance in real-world scenarios. However, we analyze and discuss here that it is not the case, machine recognition of faces for each of these applications poses unique challenges and demands specific research components so as to adapt in the actual sites.



### EndoNet: A Deep Architecture for Recognition Tasks on Laparoscopic Videos
- **Arxiv ID**: http://arxiv.org/abs/1602.03012v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03012v2)
- **Published**: 2016-02-09 14:58:12+00:00
- **Updated**: 2016-05-23 10:46:02+00:00
- **Authors**: Andru P. Twinanda, Sherif Shehata, Didier Mutter, Jacques Marescaux, Michel de Mathelin, Nicolas Padoy
- **Comment**: Video: https://www.youtube.com/watch?v=6v0NWrFOUUM
- **Journal**: None
- **Summary**: Surgical workflow recognition has numerous potential medical applications, such as the automatic indexing of surgical video databases and the optimization of real-time operating room scheduling, among others. As a result, phase recognition has been studied in the context of several kinds of surgeries, such as cataract, neurological, and laparoscopic surgeries. In the literature, two types of features are typically used to perform this task: visual features and tool usage signals. However, the visual features used are mostly handcrafted. Furthermore, the tool usage signals are usually collected via a manual annotation process or by using additional equipment. In this paper, we propose a novel method for phase recognition that uses a convolutional neural network (CNN) to automatically learn features from cholecystectomy videos and that relies uniquely on visual information. In previous studies, it has been shown that the tool signals can provide valuable information in performing the phase recognition task. Thus, we present a novel CNN architecture, called EndoNet, that is designed to carry out the phase recognition and tool presence detection tasks in a multi-task manner. To the best of our knowledge, this is the first work proposing to use a CNN for multiple recognition tasks on laparoscopic videos. Extensive experimental comparisons to other methods show that EndoNet yields state-of-the-art results for both tasks.



### A New Spatio-Spectral Morphological Segmentation For Multi-Spectral Remote-Sensing Images
- **Arxiv ID**: http://arxiv.org/abs/1602.03145v1
- **DOI**: 10.1080/01431161.2010.512314
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.03145v1)
- **Published**: 2016-02-09 20:02:00+00:00
- **Updated**: 2016-02-09 20:02:00+00:00
- **Authors**: Guillaume Noyel, Jesus Angulo, Dominique Jeulin
- **Comment**: None
- **Journal**: International Journal of Remote Sensing, Taylor \& Francis, 2010,
  31 (22), pp.5895-5920
- **Summary**: A general framework of spatio-spectral segmentation for multi-spectral images is introduced in this paper. The method is based on classification-driven stochastic watershed (WS) by Monte Carlo simulations, and it gives more regular and reliable contours than standard WS. The present approach is decomposed into several sequential steps. First, a dimensionality-reduction stage is performed using the factor-correspondence analysis method. In this context, a new way to select the factor axes (eigenvectors) according to their spatial information is introduced. Then, a spectral classification produces a spectral pre-segmentation of the image. Subsequently, a probability density function (pdf) of contours containing spatial and spectral information is estimated by simulation using a stochastic WS approach driven by the spectral classification. The pdf of the contours is finally segmented by a WS controlled by markers from a regularization of the initial classification.



### Image encryption with dynamic chaotic Look-Up Table
- **Arxiv ID**: http://arxiv.org/abs/1602.03205v1
- **DOI**: 10.1109/SETIT.2012.6481937
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.03205v1)
- **Published**: 2016-02-09 21:54:51+00:00
- **Updated**: 2016-02-09 21:54:51+00:00
- **Authors**: Med Karim Abdmouleh, Ali Khalfallah, Med Salim Bouhlel
- **Comment**: 7 pages, 12 figures, 6th International Conference on Sciences of
  Electronics, Technologies of Information and Telecommunications (SETIT), 2012
- **Journal**: None
- **Summary**: In this paper we propose a novel image encryption scheme. The proposed method is based on the chaos theory. Our cryptosystem uses the chaos theory to define a dynamic chaotic Look-Up Table (LUT) to compute the new value of the current pixel to cipher. Applying this process on each pixel of the plain image, we generate the encrypted image. The results of different experimental tests, such as Key space analysis, Information Entropy and Histogram analysis, show that the proposed encryption image scheme seems to be protected against various attacks. A comparison between the plain and encrypted image, in terms of correlation coefficient, proves that the plain image is very different from the encrypted one.



