# Arxiv Papers in cs.CV on 2016-02-04
### Towards Better Exploiting Convolutional Neural Networks for Remote Sensing Scene Classification
- **Arxiv ID**: http://arxiv.org/abs/1602.01517v1
- **DOI**: 10.1016/j.patcog.2016.07.001
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01517v1)
- **Published**: 2016-02-04 00:53:32+00:00
- **Updated**: 2016-02-04 00:53:32+00:00
- **Authors**: Keiller Nogueira, Otávio A. B. Penatti, Jefersson A. dos Santos
- **Comment**: None
- **Journal**: None
- **Summary**: We present an analysis of three possible strategies for exploiting the power of existing convolutional neural networks (ConvNets) in different scenarios from the ones they were trained: full training, fine tuning, and using ConvNets as feature extractors. In many applications, especially including remote sensing, it is not feasible to fully design and train a new ConvNet, as this usually requires a considerable amount of labeled data and demands high computational costs. Therefore, it is important to understand how to obtain the best profit from existing ConvNets. We perform experiments with six popular ConvNets using three remote sensing datasets. We also compare ConvNets in each strategy with existing descriptors and with state-of-the-art baselines. Results point that fine tuning tends to be the best performing strategy. In fact, using the features from the fine-tuned ConvNet with linear SVM obtains the best results. We also achieved state-of-the-art results for the three datasets used.



### EIE: Efficient Inference Engine on Compressed Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1602.01528v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AR
- **Links**: [PDF](http://arxiv.org/pdf/1602.01528v2)
- **Published**: 2016-02-04 01:28:28+00:00
- **Updated**: 2016-05-03 04:27:02+00:00
- **Authors**: Song Han, Xingyu Liu, Huizi Mao, Jing Pu, Ardavan Pedram, Mark A. Horowitz, William J. Dally
- **Comment**: External Links: TheNextPlatform: http://goo.gl/f7qX0L ; O'Reilly:
  https://goo.gl/Id1HNT ; Hacker News: https://goo.gl/KM72SV ; Embedded-vision:
  http://goo.gl/joQNg8 ; Talk at NVIDIA GTC'16: http://goo.gl/6wJYvn ; Talk at
  Embedded Vision Summit: https://goo.gl/7abFNe ; Talk at Stanford University:
  https://goo.gl/6lwuer. Published as a conference paper in ISCA 2016
- **Journal**: None
- **Summary**: State-of-the-art deep neural networks (DNNs) have hundreds of millions of connections and are both computationally and memory intensive, making them difficult to deploy on embedded systems with limited hardware resources and power budgets. While custom hardware helps the computation, fetching weights from DRAM is two orders of magnitude more expensive than ALU operations, and dominates the required power.   Previously proposed 'Deep Compression' makes it possible to fit large DNNs (AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by pruning the redundant connections and having multiple connections share the same weight. We propose an energy efficient inference engine (EIE) that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing. Going from DRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x; Weight sharing gives 8x; Skipping zero activations from ReLU saves another 3x. Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to CPU and GPU implementations of the same DNN without compression. EIE has a processing power of 102GOPS/s working directly on a compressed network, corresponding to 3TOPS/s on an uncompressed network, and processes FC layers of AlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is 24,000x and 3,400x more energy efficient than a CPU and GPU respectively. Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy efficiency and area efficiency.



### Fundamental Limits in Multi-image Alignment
- **Arxiv ID**: http://arxiv.org/abs/1602.01541v1
- **DOI**: 10.1109/TSP.2016.2600517
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01541v1)
- **Published**: 2016-02-04 02:25:52+00:00
- **Updated**: 2016-02-04 02:25:52+00:00
- **Authors**: Cecilia Aguerrebere, Mauricio Delbracio, Alberto Bartesaghi, Guillermo Sapiro
- **Comment**: None
- **Journal**: None
- **Summary**: The performance of multi-image alignment, bringing different images into one coordinate system, is critical in many applications with varied signal-to-noise ratio (SNR) conditions. A great amount of effort is being invested into developing methods to solve this problem. Several important questions thus arise, including: Which are the fundamental limits in multi-image alignment performance? Does having access to more images improve the alignment? Theoretical bounds provide a fundamental benchmark to compare methods and can help establish whether improvements can be made. In this work, we tackle the problem of finding the performance limits in image registration when multiple shifted and noisy observations are available. We derive and analyze the Cram\'er-Rao and Ziv-Zakai lower bounds under different statistical models for the underlying image. The accuracy of the derived bounds is experimentally assessed through a comparison to the maximum likelihood estimator. We show the existence of different behavior zones depending on the difficulty level of the problem, given by the SNR conditions of the input images. We find that increasing the number of images is only useful below a certain SNR threshold, above which the pairwise MLE estimation proves to be optimal. The analysis we present here brings further insight into the fundamental limitations of the multi-image alignment problem.



### An ensemble diversity approach to supervised binary hashing
- **Arxiv ID**: http://arxiv.org/abs/1602.01557v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1602.01557v1)
- **Published**: 2016-02-04 04:59:54+00:00
- **Updated**: 2016-02-04 04:59:54+00:00
- **Authors**: Miguel Á. Carreira-Perpiñán, Ramin Raziperchikolaei
- **Comment**: 17 pages, 5 figures
- **Journal**: None
- **Summary**: Binary hashing is a well-known approach for fast approximate nearest-neighbor search in information retrieval. Much work has focused on affinity-based objective functions involving the hash functions or binary codes. These objective functions encode neighborhood information between data points and are often inspired by manifold learning algorithms. They ensure that the hash functions differ from each other through constraints or penalty terms that encourage codes to be orthogonal or dissimilar across bits, but this couples the binary variables and complicates the already difficult optimization. We propose a much simpler approach: we train each hash function (or bit) independently from each other, but introduce diversity among them using techniques from classifier ensembles. Surprisingly, we find that not only is this faster and trivially parallelizable, but it also improves over the more complex, coupled objective function, and achieves state-of-the-art precision and recall in experiments with image retrieval.



### Comparative Evaluation of Action Recognition Methods via Riemannian Manifolds, Fisher Vectors and GMMs: Ideal and Challenging Conditions
- **Arxiv ID**: http://arxiv.org/abs/1602.01599v3
- **DOI**: 10.1007/978-3-319-42996-0_8
- **Categories**: **cs.CV**, I.4; I.5; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1602.01599v3)
- **Published**: 2016-02-04 09:06:50+00:00
- **Updated**: 2016-10-04 07:25:28+00:00
- **Authors**: Johanna Carvajal, Arnold Wiliem, Chris McCool, Brian Lovell, Conrad Sanderson
- **Comment**: None
- **Journal**: Lecture Notes in Computer Science (LNCS), Vol. 9794, pp. 88-100,
  2016
- **Summary**: We present a comparative evaluation of various techniques for action recognition while keeping as many variables as possible controlled. We employ two categories of Riemannian manifolds: symmetric positive definite matrices and linear subspaces. For both categories we use their corresponding nearest neighbour classifiers, kernels, and recent kernelised sparse representations. We compare against traditional action recognition techniques based on Gaussian mixture models and Fisher vectors (FVs). We evaluate these action recognition techniques under ideal conditions, as well as their sensitivity in more challenging conditions (variations in scale and translation). Despite recent advancements for handling manifolds, manifold based techniques obtain the lowest performance and their kernel representations are more unstable in the presence of challenging conditions. The FV approach obtains the highest accuracy under ideal conditions. Moreover, FV best deals with moderate scale and translation changes.



### Joint Recognition and Segmentation of Actions via Probabilistic Integration of Spatio-Temporal Fisher Vectors
- **Arxiv ID**: http://arxiv.org/abs/1602.01601v3
- **DOI**: 10.1007/978-3-319-42996-0_10
- **Categories**: **cs.CV**, I.2.10; I.4; I.5; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1602.01601v3)
- **Published**: 2016-02-04 09:16:52+00:00
- **Updated**: 2016-10-04 07:30:25+00:00
- **Authors**: Johanna Carvajal, Chris McCool, Brian Lovell, Conrad Sanderson
- **Comment**: None
- **Journal**: Lecture Notes in Computer Science (LNCS), Vol. 9794, pp. 115-127,
  2016
- **Summary**: We propose a hierarchical approach to multi-action recognition that performs joint classification and segmentation. A given video (containing several consecutive actions) is processed via a sequence of overlapping temporal windows. Each frame in a temporal window is represented through selective low-level spatio-temporal features which efficiently capture relevant local dynamics. Features from each window are represented as a Fisher vector, which captures first and second order statistics. Instead of directly classifying each Fisher vector, it is converted into a vector of class probabilities. The final classification decision for each frame is then obtained by integrating the class probabilities at the frame level, which exploits the overlapping of the temporal windows. Experiments were performed on two datasets: s-KTH (a stitched version of the KTH dataset to simulate multi-actions), and the challenging CMU-MMAC dataset. On s-KTH, the proposed approach achieves an accuracy of 85.0%, significantly outperforming two recent approaches based on GMMs and HMMs which obtained 78.3% and 71.2%, respectively. On CMU-MMAC, the proposed approach achieves an accuracy of 40.9%, outperforming the GMM and HMM approaches which obtained 33.7% and 38.4%, respectively. Furthermore, the proposed system is on average 40 times faster than the GMM based approach.



### Appearance Based Robot and Human Activity Recognition System
- **Arxiv ID**: http://arxiv.org/abs/1602.01608v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.01608v2)
- **Published**: 2016-02-04 09:51:40+00:00
- **Updated**: 2016-02-10 02:44:24+00:00
- **Authors**: Bappaditya Mandal
- **Comment**: 6 pages, 4 figures
- **Journal**: None
- **Summary**: In this work, we present an appearance based human activity recognition system. It uses background modeling to segment the foreground object and extracts useful discriminative features for representing activities performed by humans and robots. Subspace based method like principal component analysis is used to extract low dimensional features from large voluminous activity images. These low dimensional features are then used to classify an activity. An apparatus is designed using a webcam, which watches a robot replicating a human fall under indoor environment. In this apparatus, a robot performs various activities (like walking, bending, moving arms) replicating humans, which also includes a sudden fall. Experimental results on robot performing various activities and standard human activity recognition databases show the efficacy of our proposed method.



### Self-Transfer Learning for Fully Weakly Supervised Object Localization
- **Arxiv ID**: http://arxiv.org/abs/1602.01625v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01625v1)
- **Published**: 2016-02-04 10:41:57+00:00
- **Updated**: 2016-02-04 10:41:57+00:00
- **Authors**: Sangheum Hwang, Hyo-Eun Kim
- **Comment**: 9 pages, 4 figures
- **Journal**: None
- **Summary**: Recent advances of deep learning have achieved remarkable performances in various challenging computer vision tasks. Especially in object localization, deep convolutional neural networks outperform traditional approaches based on extraction of data/task-driven features instead of hand-crafted features. Although location information of region-of-interests (ROIs) gives good prior for object localization, it requires heavy annotation efforts from human resources. Thus a weakly supervised framework for object localization is introduced. The term "weakly" means that this framework only uses image-level labeled datasets to train a network. With the help of transfer learning which adopts weight parameters of a pre-trained network, the weakly supervised learning framework for object localization performs well because the pre-trained network already has well-trained class-specific features. However, those approaches cannot be used for some applications which do not have pre-trained networks or well-localized large scale images. Medical image analysis is a representative among those applications because it is impossible to obtain such pre-trained networks. In this work, we present a "fully" weakly supervised framework for object localization ("semi"-weakly is the counterpart which uses pre-trained filters for weakly supervised localization) named as self-transfer learning (STL). It jointly optimizes both classification and localization networks simultaneously. By controlling a supervision level of the localization network, STL helps the localization network focus on correct ROIs without any types of priors. We evaluate the proposed STL framework using two medical image datasets, chest X-rays and mammograms, and achieve signiticantly better localization performance compared to previous weakly supervised approaches.



### A semi-automatic computer-aided method for surgical template design
- **Arxiv ID**: http://arxiv.org/abs/1602.01644v1
- **DOI**: 10.1038/srep20280
- **Categories**: **cs.GR**, cs.CG, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1602.01644v1)
- **Published**: 2016-02-04 11:33:22+00:00
- **Updated**: 2016-02-04 11:33:22+00:00
- **Authors**: Xiaojun Chen, Lu Xu, Yue Yang, Jan Egger
- **Comment**: 18 pages, 16 figures, 2 tables, 36 references
- **Journal**: Scientific Reports 6, Article number: 20280, 2016
- **Summary**: This paper presents a generalized integrated framework of semi-automatic surgical template design. Several algorithms were implemented including the mesh segmentation, offset surface generation, collision detection, ruled surface generation, etc., and a special software named TemDesigner was developed. With a simple user interface, a customized template can be semi- automatically designed according to the preoperative plan. Firstly, mesh segmentation with signed scalar of vertex is utilized to partition the inner surface from the input surface mesh based on the indicated point loop. Then, the offset surface of the inner surface is obtained through contouring the distance field of the inner surface, and segmented to generate the outer surface. Ruled surface is employed to connect inner and outer surfaces. Finally, drilling tubes are generated according to the preoperative plan through collision detection and merging. It has been applied to the template design for various kinds of surgeries, including oral implantology, cervical pedicle screw insertion, iliosacral screw insertion and osteotomy, demonstrating the efficiency, functionality and generality of our method.



### NeRD: a Neural Response Divergence Approach to Visual Salience Detection
- **Arxiv ID**: http://arxiv.org/abs/1602.01728v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01728v1)
- **Published**: 2016-02-04 16:20:26+00:00
- **Updated**: 2016-02-04 16:20:26+00:00
- **Authors**: M. J. Shafiee, P. Siva, C. Scharfenberger, P. Fieguth, A. Wong
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: In this paper, a novel approach to visual salience detection via Neural Response Divergence (NeRD) is proposed, where synaptic portions of deep neural networks, previously trained for complex object recognition, are leveraged to compute low level cues that can be used to compute image region distinctiveness. Based on this concept , an efficient visual salience detection framework is proposed using deep convolutional StochasticNets. Experimental results using CSSD and MSRA10k natural image datasets show that the proposed NeRD approach can achieve improved performance when compared to state-of-the-art image saliency approaches, while the attaining low computational complexity necessary for near-real-time computer vision applications.



### Correntropy Maximization via ADMM - Application to Robust Hyperspectral Unmixing
- **Arxiv ID**: http://arxiv.org/abs/1602.01729v1
- **DOI**: 10.1109/TGRS.2017.2696262
- **Categories**: **stat.ML**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1602.01729v1)
- **Published**: 2016-02-04 16:21:09+00:00
- **Updated**: 2016-02-04 16:21:09+00:00
- **Authors**: Fei Zhu, Abderrahim Halimi, Paul Honeine, Badong Chen, Nanning Zheng
- **Comment**: 23 pages
- **Journal**: None
- **Summary**: In hyperspectral images, some spectral bands suffer from low signal-to-noise ratio due to noisy acquisition and atmospheric effects, thus requiring robust techniques for the unmixing problem. This paper presents a robust supervised spectral unmixing approach for hyperspectral images. The robustness is achieved by writing the unmixing problem as the maximization of the correntropy criterion subject to the most commonly used constraints. Two unmixing problems are derived: the first problem considers the fully-constrained unmixing, with both the non-negativity and sum-to-one constraints, while the second one deals with the non-negativity and the sparsity-promoting of the abundances. The corresponding optimization problems are solved efficiently using an alternating direction method of multipliers (ADMM) approach. Experiments on synthetic and real hyperspectral images validate the performance of the proposed algorithms for different scenarios, demonstrating that the correntropy-based unmixing is robust to outlier bands.



### Random Feature Maps via a Layered Random Projection (LaRP) Framework for Object Classification
- **Arxiv ID**: http://arxiv.org/abs/1602.01818v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1602.01818v1)
- **Published**: 2016-02-04 20:31:44+00:00
- **Updated**: 2016-02-04 20:31:44+00:00
- **Authors**: A. G. Chung, M. J. Shafiee, A. Wong
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: The approximation of nonlinear kernels via linear feature maps has recently gained interest due to their applications in reducing the training and testing time of kernel-based learning algorithms. Current random projection methods avoid the curse of dimensionality by embedding the nonlinear feature space into a low dimensional Euclidean space to create nonlinear kernels. We introduce a Layered Random Projection (LaRP) framework, where we model the linear kernels and nonlinearity separately for increased training efficiency. The proposed LaRP framework was assessed using the MNIST hand-written digits database and the COIL-100 object database, and showed notable improvement in object classification performance relative to other state-of-the-art random projection methods.



### Leveraging Mid-Level Deep Representations For Predicting Face Attributes in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1602.01827v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01827v3)
- **Published**: 2016-02-04 20:58:02+00:00
- **Updated**: 2016-06-21 15:52:58+00:00
- **Authors**: Yang Zhong, Josephine Sullivan, Haibo Li
- **Comment**: In proceedings of 2016 International Conference on Image Processing
  (ICIP)
- **Journal**: None
- **Summary**: Predicting facial attributes from faces in the wild is very challenging due to pose and lighting variations in the real world. The key to this problem is to build proper feature representations to cope with these unfavourable conditions. Given the success of Convolutional Neural Network (CNN) in image classification, the high-level CNN feature, as an intuitive and reasonable choice, has been widely utilized for this problem. In this paper, however, we consider the mid-level CNN features as an alternative to the high-level ones for attribute prediction. This is based on the observation that face attributes are different: some of them are locally oriented while others are globally defined. Our investigations reveal that the mid-level deep representations outperform the prediction accuracy achieved by the (fine-tuned) high-level abstractions. We empirically demonstrate that the midlevel representations achieve state-of-the-art prediction performance on CelebA and LFWA datasets. Our investigations also show that by utilizing the mid-level representations one can employ a single deep network to achieve both face recognition and attribute prediction.



### Visual Tracking via Reliable Memories
- **Arxiv ID**: http://arxiv.org/abs/1602.01887v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.01887v2)
- **Published**: 2016-02-04 23:40:14+00:00
- **Updated**: 2016-02-17 22:36:07+00:00
- **Authors**: Shu Wang, Shaoting Zhang, Wei Liu, Dimitris N. Metaxas
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel visual tracking framework that intelligently discovers reliable patterns from a wide range of video to resist drift error for long-term tracking tasks. First, we design a Discrete Fourier Transform (DFT) based tracker which is able to exploit a large number of tracked samples while still ensures real-time performance. Second, we propose a clustering method with temporal constraints to explore and memorize consistent patterns from previous frames, named as reliable memories. By virtue of this method, our tracker can utilize uncontaminated information to alleviate drifting issues. Experimental results show that our tracker performs favorably against other state of-the-art methods on benchmark datasets. Furthermore, it is significantly competent in handling drifts and able to robustly track challenging long videos over 4000 frames, while most of others lose track at early frames.



