# Arxiv Papers in cs.CV on 2016-02-13
### Signer-independent Fingerspelling Recognition with Deep Neural Network Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1602.04278v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1602.04278v1)
- **Published**: 2016-02-13 03:30:34+00:00
- **Updated**: 2016-02-13 03:30:34+00:00
- **Authors**: Taehwan Kim, Weiran Wang, Hao Tang, Karen Livescu
- **Comment**: None
- **Journal**: None
- **Summary**: We study the problem of recognition of fingerspelled letter sequences in American Sign Language in a signer-independent setting. Fingerspelled sequences are both challenging and important to recognize, as they are used for many content words such as proper nouns and technical terms. Previous work has shown that it is possible to achieve almost 90% accuracies on fingerspelling recognition in a signer-dependent setting. However, the more realistic signer-independent setting presents challenges due to significant variations among signers, coupled with the dearth of available training data. We investigate this problem with approaches inspired by automatic speech recognition. We start with the best-performing approaches from prior work, based on tandem models and segmental conditional random fields (SCRFs), with features based on deep neural network (DNN) classifiers of letters and phonological features. Using DNN adaptation, we find that it is possible to bridge a large part of the gap between signer-dependent and signer-independent performance. Using only about 115 transcribed words for adaptation from the target signer, we obtain letter accuracies of up to 82.7% with frame-level adaptation labels and 69.7% with only word labels.



### Manifolds of Projective Shapes
- **Arxiv ID**: http://arxiv.org/abs/1602.04330v4
- **DOI**: None
- **Categories**: **math.ST**, cs.CV, math.GT, stat.TH, 51N15 (primary), 62H11, 62H35 (secondary), I.4.1; I.4.7
- **Links**: [PDF](http://arxiv.org/pdf/1602.04330v4)
- **Published**: 2016-02-13 13:32:22+00:00
- **Updated**: 2018-11-05 17:04:45+00:00
- **Authors**: Thomas Hotz, Florian Kelma, John T. Kent
- **Comment**: None
- **Journal**: None
- **Summary**: The projective shape of a configuration of k points or "landmarks" in RP(d) consists of the information that is invariant under projective transformations and hence is reconstructable from uncalibrated camera views. Mathematically, the space of projective shapes for these k landmarks can be described as the quotient space of k copies of RP(d) modulo the action of the projective linear group PGL(d). Using homogeneous coordinates, such configurations can be described as real k-times-(d+1)-dimensional matrices given up to left-multiplication of non-singular diagonal matrices, while the group PGL(d) acts as GL(d+1) from the right. The main purpose of this paper is to give a detailed examination of the topology of projective shape space, and, using matrix notation, it is shown how to derive subsets that are in a certain sense maximal, differentiable Hausdorff manifolds which can be provided with a Riemannian metric. A special subclass of the projective shapes consists of the Tyler regular shapes, for which geometrically motivated pre-shapes can be defined, thus allowing for the construction of a natural Riemannian metric.



### Character Proposal Network for Robust Text Extraction
- **Arxiv ID**: http://arxiv.org/abs/1602.04348v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.04348v1)
- **Published**: 2016-02-13 15:55:17+00:00
- **Updated**: 2016-02-13 15:55:17+00:00
- **Authors**: Shuye Zhang, Mude Lin, Tianshui Chen, Lianwen Jin, Liang Lin
- **Comment**: None
- **Journal**: None
- **Summary**: Maximally stable extremal regions (MSER), which is a popular method to generate character proposals/candidates, has shown superior performance in scene text detection. However, the pixel-level operation limits its capability for handling some challenging cases (e.g., multiple connected characters, separated parts of one character and non-uniform illumination). To better tackle these cases, we design a character proposal network (CPN) by taking advantage of the high capacity and fast computing of fully convolutional network (FCN). Specifically, the network simultaneously predicts characterness scores and refines the corresponding locations. The characterness scores can be used for proposal ranking to reject non-character proposals and the refining process aims to obtain the more accurate locations. Furthermore, considering the situation that different characters have different aspect ratios, we propose a multi-template strategy, designing a refiner for each aspect ratio. The extensive experiments indicate our method achieves recall rates of 93.88%, 93.60% and 96.46% on ICDAR 2013, SVT and Chinese2k datasets respectively using less than 1000 proposals, demonstrating promising performance of our character proposal network.



