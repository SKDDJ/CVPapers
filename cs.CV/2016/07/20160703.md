# Arxiv Papers in cs.CV on 2016-07-03
### A Hierarchical Distributed Processing Framework for Big Image Data
- **Arxiv ID**: http://arxiv.org/abs/1607.00577v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00577v1)
- **Published**: 2016-07-03 02:16:49+00:00
- **Updated**: 2016-07-03 02:16:49+00:00
- **Authors**: Le Dong, Zhiyu Lin, Yan Liang, Ling He, Ning Zhang, Qi Chen, Xiaochun Cao, Ebroul lzquierdo
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces an effective processing framework nominated ICP (Image Cloud Processing) to powerfully cope with the data explosion in image processing field. While most previous researches focus on optimizing the image processing algorithms to gain higher efficiency, our work dedicates to providing a general framework for those image processing algorithms, which can be implemented in parallel so as to achieve a boost in time efficiency without compromising the results performance along with the increasing image scale. The proposed ICP framework consists of two mechanisms, i.e. SICP (Static ICP) and DICP (Dynamic ICP). Specifically, SICP is aimed at processing the big image data pre-stored in the distributed system, while DICP is proposed for dynamic input. To accomplish SICP, two novel data representations named P-Image and Big-Image are designed to cooperate with MapReduce to achieve more optimized configuration and higher efficiency. DICP is implemented through a parallel processing procedure working with the traditional processing mechanism of the distributed system. Representative results of comprehensive experiments on the challenging ImageNet dataset are selected to validate the capacity of our proposed ICP framework over the traditional state-of-the-art methods, both in time efficiency and quality of results.



### 3D Deeply Supervised Network for Automatic Liver Segmentation from CT Volumes
- **Arxiv ID**: http://arxiv.org/abs/1607.00582v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00582v1)
- **Published**: 2016-07-03 02:52:56+00:00
- **Updated**: 2016-07-03 02:52:56+00:00
- **Authors**: Qi Dou, Hao Chen, Yueming Jin, Lequan Yu, Jing Qin, Pheng-Ann Heng
- **Comment**: Accepted to MICCAI 2016
- **Journal**: None
- **Summary**: Automatic liver segmentation from CT volumes is a crucial prerequisite yet challenging task for computer-aided hepatic disease diagnosis and treatment. In this paper, we present a novel 3D deeply supervised network (3D DSN) to address this challenging task. The proposed 3D DSN takes advantage of a fully convolutional architecture which performs efficient end-to-end learning and inference. More importantly, we introduce a deep supervision mechanism during the learning process to combat potential optimization difficulties, and thus the model can acquire a much faster convergence rate and more powerful discrimination capability. On top of the high-quality score map produced by the 3D DSN, a conditional random field model is further employed to obtain refined segmentation results. We evaluated our framework on the public MICCAI-SLiver07 dataset. Extensive experiments demonstrated that our method achieves competitive segmentation results to state-of-the-art approaches with a much faster processing speed.



### An Analysis System for DNA Gel Electrophoresis Images Based on Automatic Thresholding an Enhancement
- **Arxiv ID**: http://arxiv.org/abs/1607.00589v1
- **DOI**: 10.1109/EIT.2007.4374496
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00589v1)
- **Published**: 2016-07-03 04:23:25+00:00
- **Updated**: 2016-07-03 04:23:25+00:00
- **Authors**: Naima Kaabouch, Richard R. Schultz, Barry Milavetz, Lata Balakrishnan
- **Comment**: 6 pages
- **Journal**: IEEE Electro/Information Technology, 2007
- **Summary**: Gel electrophoresis, a widely used technique to separate DNA according to their size and weight, generates images that can be analyzed automatically. Manual or semiautomatic image processing presents a bottleneck for further development and leads to reproducibility issues. In this paper, we present a fully automated system with high accuracy for analyzing DNA and proteins. The proposed algorithm consists of four main steps: automatic thresholding, shifting, filtering, and data processing. Automatic thresholding, used to equalize the gray values of the gel electrophoresis image background, is one of the novel operations in this algorithm. Enhancement is also used to improve poor quality images that have faint DNA bands. Experimental results show that the proposed technique eliminates defects due to noise for average quality gel electrophoresis images, while it also improves the quality of poor images.



### Automatic Techniques for Gridding cDNA Microarray Images
- **Arxiv ID**: http://arxiv.org/abs/1607.00592v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00592v1)
- **Published**: 2016-07-03 05:03:40+00:00
- **Updated**: 2016-07-03 05:03:40+00:00
- **Authors**: Naima Kaabouch, Hamid Shahbazkia
- **Comment**: 5 pages, IEEE Electro/Information Technology, 2008
- **Journal**: None
- **Summary**: Microarray is considered an important instrument and powerful new technology for large-scale gene sequence and gene expression analysis. One of the major challenges of this technique is the image processing phase. The accuracy of this phase has an important impact on the accuracy and effectiveness of the subsequent gene expression and identification analysis. The processing can be organized mainly into four steps: gridding, spot isolation, segmentation, and quantification. Although several commercial software packages are now available, microarray image analysis still requires some intervention by the user, and thus a certain level of image processing expertise. This paper describes and compares four techniques that perform automatic gridding and spot isolation. The proposed techniques are based on template matching technique, standard deviation, sum, and derivative of these profiles. Experimental results show that the accuracy of the derivative of the sum profile is highly accurate compared to other techniques for good and poor quality microarray images.



### A Coarse-to-Fine Indoor Layout Estimation (CFILE) Method
- **Arxiv ID**: http://arxiv.org/abs/1607.00598v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00598v1)
- **Published**: 2016-07-03 05:55:47+00:00
- **Updated**: 2016-07-03 05:55:47+00:00
- **Authors**: Yuzhuo Ren, Chen Chen, Shangwen Li, C. -C. Jay Kuo
- **Comment**: None
- **Journal**: None
- **Summary**: The task of estimating the spatial layout of cluttered indoor scenes from a single RGB image is addressed in this work. Existing solutions to this problems largely rely on hand-craft features and vanishing lines, and they often fail in highly cluttered indoor rooms. The proposed coarse-to-fine indoor layout estimation (CFILE) method consists of two stages: 1) coarse layout estimation; and 2) fine layout localization. In the first stage, we adopt a fully convolutional neural network (FCN) to obtain a coarse-scale room layout estimate that is close to the ground truth globally. The proposed FCN considers combines the layout contour property and the surface property so as to provide a robust estimate in the presence of cluttered objects. In the second stage, we formulate an optimization framework that enforces several constraints such as layout contour straightness, surface smoothness and geometric constraints for layout detail refinement. Our proposed system offers the state-of-the-art performance on two commonly used benchmark datasets.



### Visualizing Natural Language Descriptions: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1607.00623v1
- **DOI**: 10.1145/2932710
- **Categories**: **cs.CL**, cs.AI, cs.CV, cs.GR, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1607.00623v1)
- **Published**: 2016-07-03 10:30:40+00:00
- **Updated**: 2016-07-03 10:30:40+00:00
- **Authors**: Kaveh Hassani, Won-Sook Lee
- **Comment**: Due to copyright most of the figures only appear in the journal
  version
- **Journal**: ACM Computing Surveys, Volume 49 Issue 1, Article No. 17, June
  2016
- **Summary**: A natural language interface exploits the conceptual simplicity and naturalness of the language to create a high-level user-friendly communication channel between humans and machines. One of the promising applications of such interfaces is generating visual interpretations of semantic content of a given natural language that can be then visualized either as a static scene or a dynamic animation. This survey discusses requirements and challenges of developing such systems and reports 26 graphical systems that exploit natural language interfaces and addresses both artificial intelligence and visualization aspects. This work serves as a frame of reference to researchers and to enable further advances in the field.



### Robust Deep Appearance Models
- **Arxiv ID**: http://arxiv.org/abs/1607.00659v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00659v1)
- **Published**: 2016-07-03 17:31:30+00:00
- **Updated**: 2016-07-03 17:31:30+00:00
- **Authors**: Kha Gia Quach, Chi Nhan Duong, Khoa Luu, Tien D. Bui
- **Comment**: 6 pages, 8 figures, submitted to ICPR 2016
- **Journal**: None
- **Summary**: This paper presents a novel Robust Deep Appearance Models to learn the non-linear correlation between shape and texture of face images. In this approach, two crucial components of face images, i.e. shape and texture, are represented by Deep Boltzmann Machines and Robust Deep Boltzmann Machines (RDBM), respectively. The RDBM, an alternative form of Robust Boltzmann Machines, can separate corrupted/occluded pixels in the texture modeling to achieve better reconstruction results. The two models are connected by Restricted Boltzmann Machines at the top layer to jointly learn and capture the variations of both facial shapes and appearances. This paper also introduces new fitting algorithms with occlusion awareness through the mask obtained from the RDBM reconstruction. The proposed approach is evaluated in various applications by using challenging face datasets, i.e. Labeled Face Parts in the Wild (LFPW), Helen, EURECOM and AR databases, to demonstrate its robustness and capabilities.



### Unsupervised Learning of 3D Structure from Images
- **Arxiv ID**: http://arxiv.org/abs/1607.00662v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1607.00662v2)
- **Published**: 2016-07-03 17:53:11+00:00
- **Updated**: 2018-06-19 17:26:53+00:00
- **Authors**: Danilo Jimenez Rezende, S. M. Ali Eslami, Shakir Mohamed, Peter Battaglia, Max Jaderberg, Nicolas Heess
- **Comment**: Appears in Advances in Neural Information Processing Systems 29 (NIPS
  2016)
- **Journal**: None
- **Summary**: A key goal of computer vision is to recover the underlying 3D structure from 2D observations of the world. In this paper we learn strong deep generative models of 3D structures, and recover these structures from 3D and 2D images via probabilistic inference. We demonstrate high-quality samples and report log-likelihoods on several datasets, including ShapeNet [2], and establish the first benchmarks in the literature. We also show how these models and their inference networks can be trained end-to-end from 2D images. This demonstrates for the first time the feasibility of learning to infer 3D representations of the world in a purely unsupervised manner.



