# Arxiv Papers in cs.CV on 2016-07-01
### Sparse Graphical Representation based Discriminant Analysis for Heterogeneous Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1607.00137v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00137v1)
- **Published**: 2016-07-01 07:41:25+00:00
- **Updated**: 2016-07-01 07:41:25+00:00
- **Authors**: Chunlei Peng, Xinbo Gao, Nannan Wang, Jie Li
- **Comment**: 13 pages, 17 figures, submitted to IEEE TNNLS
- **Journal**: None
- **Summary**: Face images captured in heterogeneous environments, e.g., sketches generated by the artists or composite-generation software, photos taken by common cameras and infrared images captured by corresponding infrared imaging devices, usually subject to large texture (i.e., style) differences. This results in heavily degraded performance of conventional face recognition methods in comparison with the performance on images captured in homogeneous environments. In this paper, we propose a novel sparse graphical representation based discriminant analysis (SGR-DA) approach to address aforementioned face recognition in heterogeneous scenarios. An adaptive sparse graphical representation scheme is designed to represent heterogeneous face images, where a Markov networks model is constructed to generate adaptive sparse vectors. To handle the complex facial structure and further improve the discriminability, a spatial partition-based discriminant analysis framework is presented to refine the adaptive sparse vectors for face matching. We conducted experiments on six commonly used heterogeneous face datasets and experimental results illustrate that our proposed SGR-DA approach achieves superior performance in comparison with state-of-the-art methods.



### Automated 5-year Mortality Prediction using Deep Learning and Radiomics Features from Chest Computed Tomography
- **Arxiv ID**: http://arxiv.org/abs/1607.00267v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00267v1)
- **Published**: 2016-07-01 14:44:37+00:00
- **Updated**: 2016-07-01 14:44:37+00:00
- **Authors**: Gustavo Carneiro, Luke Oakden-Rayner, Andrew P. Bradley, Jacinto Nascimento, Lyle Palmer
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: We propose new methods for the prediction of 5-year mortality in elderly individuals using chest computed tomography (CT). The methods consist of a classifier that performs this prediction using a set of features extracted from the CT image and segmentation maps of multiple anatomic structures. We explore two approaches: 1) a unified framework based on deep learning, where features and classifier are automatically learned in a single optimisation process; and 2) a multi-stage framework based on the design and selection/extraction of hand-crafted radiomics features, followed by the classifier learning process. Experimental results, based on a dataset of 48 annotated chest CTs, show that the deep learning model produces a mean 5-year mortality prediction accuracy of 68.5%, while radiomics produces a mean accuracy that varies between 56% to 66% (depending on the feature selection/extraction method and classifier). The successful development of the proposed models has the potential to make a profound impact in preventive and personalised healthcare.



### Noise Models in Feature-based Stereo Visual Odometry
- **Arxiv ID**: http://arxiv.org/abs/1607.00273v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1607.00273v1)
- **Published**: 2016-07-01 15:02:38+00:00
- **Updated**: 2016-07-01 15:02:38+00:00
- **Authors**: Pablo F. Alcantarilla, Oliver J. Woodford
- **Comment**: None
- **Journal**: None
- **Summary**: Feature-based visual structure and motion reconstruction pipelines, common in visual odometry and large-scale reconstruction from photos, use the location of corresponding features in different images to determine the 3D structure of the scene, as well as the camera parameters associated with each image. The noise model, which defines the likelihood of the location of each feature in each image, is a key factor in the accuracy of such pipelines, alongside optimization strategy. Many different noise models have been proposed in the literature; in this paper we investigate the performance of several. We evaluate these models specifically w.r.t. stereo visual odometry, as this task is both simple (camera intrinsics are constant and known; geometry can be initialized reliably) and has datasets with ground truth readily available (KITTI Odometry and New Tsukuba Stereo Dataset). Our evaluation shows that noise models which are more adaptable to the varying nature of noise generally perform better.



### Machine-based Multimodal Pain Assessment Tool for Infants: A Review
- **Arxiv ID**: http://arxiv.org/abs/1607.00331v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00331v3)
- **Published**: 2016-07-01 17:53:00+00:00
- **Updated**: 2019-01-16 16:16:13+00:00
- **Authors**: Ghada Zamzmi, Dmitry Goldgof, Rangachar Kasturi, Yu Sun, Terri Ashmeade
- **Comment**: None
- **Journal**: None
- **Summary**: Bedside caregivers assess infants' pain at constant intervals by observing specific behavioral and physiological signs of pain. This standard has two main limitations. The first limitation is the intermittent assessment of pain, which might lead to missing pain when the infants are left unattended. Second, it is inconsistent since it depends on the observer's subjective judgment and differs between observers. The intermittent and inconsistent assessment can induce poor treatment and, therefore, cause serious long-term consequences. To mitigate these limitations, the current standard can be augmented by an automated system that monitors infants continuously and provides quantitative and consistent assessment of pain. Several automated methods have been introduced to assess infants' pain automatically based on analysis of behavioral or physiological pain indicators. This paper comprehensively reviews the automated approaches (i.e., approaches to feature extraction) for analyzing infants' pain and the current efforts in automatic pain recognition. In addition, it reviews the databases available to the research community and discusses the current limitations of the automated pain assessment.



### Continuous Adaptation of Multi-Camera Person Identification Models through Sparse Non-redundant Representative Selection
- **Arxiv ID**: http://arxiv.org/abs/1607.00417v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.00417v1)
- **Published**: 2016-07-01 21:48:16+00:00
- **Updated**: 2016-07-01 21:48:16+00:00
- **Authors**: Abir Das, Rameswar Panda, Amit K. Roy-Chowdhury
- **Comment**: None
- **Journal**: None
- **Summary**: The problem of image-base person identification/recognition is to provide an identity to the image of an individual based on learned models that describe his/her appearance. Most traditional person identification systems rely on learning a static model on tediously labeled training data. Though labeling manually is an indispensable part of a supervised framework, for a large scale identification system labeling huge amount of data is a significant overhead. For large multi-sensor data as typically encountered in camera networks, labeling a lot of samples does not always mean more information, as redundant images are labeled several times. In this work, we propose a convex optimization based iterative framework that progressively and judiciously chooses a sparse but informative set of samples for labeling, with minimal overlap with previously labeled images. We also use a structure preserving sparse reconstruction based classifier to reduce the training burden typically seen in discriminative classifiers. The two stage approach leads to a novel framework for online update of the classifiers involving only the incorporation of new labeled data rather than any expensive training phase. We demonstrate the effectiveness of our approach on multi-camera person re-identification datasets, to demonstrate the feasibility of learning online classification models in multi-camera big data applications. Using three benchmark datasets, we validate our approach and demonstrate that our framework achieves superior performance with significantly less amount of manual labeling.



