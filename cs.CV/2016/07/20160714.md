# Arxiv Papers in cs.CV on 2016-07-14
### Concatenated image completion via tensor augmentation and completion
- **Arxiv ID**: http://arxiv.org/abs/1607.03967v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.DS
- **Links**: [PDF](http://arxiv.org/pdf/1607.03967v1)
- **Published**: 2016-07-14 00:24:33+00:00
- **Updated**: 2016-07-14 00:24:33+00:00
- **Authors**: Johann A. Bengua, Hoang D. Tuan, Ho N. Phien, Minh N. Do
- **Comment**: 7 pages, 6 figures, submitted to ICSPCS 2016
- **Journal**: None
- **Summary**: This paper proposes a novel framework called concatenated image completion via tensor augmentation and completion (ICTAC), which recovers missing entries of color images with high accuracy. Typical images are second- or third-order tensors (2D/3D) depending if they are grayscale or color, hence tensor completion algorithms are ideal for their recovery. The proposed framework performs image completion by concatenating copies of a single image that has missing entries into a third-order tensor, applying a dimensionality augmentation technique to the tensor, utilizing a tensor completion algorithm for recovering its missing entries, and finally extracting the recovered image from the tensor. The solution relies on two key components that have been recently proposed to take advantage of the tensor train (TT) rank: A tensor augmentation tool called ket augmentation (KA) that represents a low-order tensor by a higher-order tensor, and the algorithm tensor completion by parallel matrix factorization via tensor train (TMac-TT), which has been demonstrated to outperform state-of-the-art tensor completion algorithms. Simulation results for color image recovery show the clear advantage of our framework against current state-of-the-art tensor completion algorithms.



### Vision-based Traffic Flow Prediction using Dynamic Texture Model and Gaussian Process
- **Arxiv ID**: http://arxiv.org/abs/1607.03991v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.03991v2)
- **Published**: 2016-07-14 05:12:56+00:00
- **Updated**: 2016-12-15 18:22:48+00:00
- **Authors**: Bin Liu, Hao Ji, Yi Dai
- **Comment**: 8 pages, 4 figures, conference
- **Journal**: None
- **Summary**: In this paper, we describe work in progress towards a real-time vision-based traffic flow prediction (TFP) system. The proposed method consists of three elemental operators, that are dynamic texture model based motion segmentation, feature extraction and Gaussian process (GP) regression. The objective of motion segmentation is to recognize the target regions covering the moving vehicles in the sequence of visual processes. The feature extraction operator aims to extract useful features from the target regions. The extracted features are then mapped to the number of vehicles through the operator of GP regression. A training stage using historical visual data is required for determining the parameter values of the GP. Using a low-resolution visual data set, we performed preliminary evaluations on the performance of the proposed method. The results show that our method beats a benchmark solution based on Gaussian mixture model, and has the potential to be developed into qualified and practical solutions to real-time TFP.



### Adaptive Gray World-Based Color Normalization of Thin Blood Film Images
- **Arxiv ID**: http://arxiv.org/abs/1607.04032v1
- **DOI**: None
- **Categories**: **cs.CV**, 68U10
- **Links**: [PDF](http://arxiv.org/pdf/1607.04032v1)
- **Published**: 2016-07-14 08:40:07+00:00
- **Updated**: 2016-07-14 08:40:07+00:00
- **Authors**: F. Boray Tek, Andrew G. Dempster, Ä°zzet Kale
- **Comment**: 5 pages, 3 figures, conference unpublished
- **Journal**: None
- **Summary**: This paper presents an effective color normalization method for thin blood film images of peripheral blood specimens. Thin blood film images can easily be separated to foreground (cell) and background (plasma) parts. The color of the plasma region is used to estimate and reduce the differences arising from different illumination conditions. A second stage normalization based on the database-gray world algorithm transforms the color of the foreground objects to match a reference color character. The quantitative experiments demonstrate the effectiveness of the method and its advantages against two other general purpose color correction methods: simple gray world and Retinex.



### Multi-modal dictionary learning for image separation with application in art investigation
- **Arxiv ID**: http://arxiv.org/abs/1607.04147v1
- **DOI**: 10.1109/TIP.2016.2623484
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.04147v1)
- **Published**: 2016-07-14 14:25:14+00:00
- **Updated**: 2016-07-14 14:25:14+00:00
- **Authors**: Nikos Deligiannis, Joao F. C. Mota, Bruno Cornelis, Miguel R. D. Rodrigues, Ingrid Daubechies
- **Comment**: submitted to IEEE Transactions on Images Processing
- **Journal**: None
- **Summary**: In support of art investigation, we propose a new source separation method that unmixes a single X-ray scan acquired from double-sided paintings. In this problem, the X-ray signals to be separated have similar morphological characteristics, which brings previous source separation methods to their limits. Our solution is to use photographs taken from the front and back-side of the panel to drive the separation process. The crux of our approach relies on the coupling of the two imaging modalities (photographs and X-rays) using a novel coupled dictionary learning framework able to capture both common and disparate features across the modalities using parsimonious representations; the common component models features shared by the multi-modal images, whereas the innovation component captures modality-specific information. As such, our model enables the formulation of appropriately regularized convex optimization procedures that lead to the accurate separation of the X-rays. Our dictionary learning framework can be tailored both to a single- and a multi-scale framework, with the latter leading to a significant performance improvement. Moreover, to improve further on the visual quality of the separated images, we propose to train coupled dictionaries that ignore certain parts of the painting corresponding to craquelure. Experimentation on synthetic and real data - taken from digital acquisition of the Ghent Altarpiece (1432) - confirms the superiority of our method against the state-of-the-art morphological component analysis technique that uses either fixed or trained dictionaries to perform image separation.



### Adaptable Precomputation for Random Walker Image Segmentation and Registration
- **Arxiv ID**: http://arxiv.org/abs/1607.04174v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.04174v1)
- **Published**: 2016-07-14 15:59:56+00:00
- **Updated**: 2016-07-14 15:59:56+00:00
- **Authors**: Shawn Andrews, Ghassan Hamarneh
- **Comment**: 9 pages, 8 figures
- **Journal**: None
- **Summary**: The random walker (RW) algorithm is used for both image segmentation and registration, and possesses several useful properties that make it popular in medical imaging, such as being globally optimizable, allowing user interaction, and providing uncertainty information. The RW algorithm defines a weighted graph over an image and uses the graph's Laplacian matrix to regularize its solutions. This regularization reduces to solving a large system of equations, which may be excessively time consuming in some applications, such as when interacting with a human user. Techniques have been developed that precompute eigenvectors of a Laplacian offline, after image acquisition but before any analysis, in order speed up the RW algorithm online, when segmentation or registration is being performed. However, precomputation requires certain algorithm parameters be fixed offline, limiting their flexibility. In this paper, we develop techniques to update the precomputed data online when RW parameters are altered. Specifically, we dynamically determine the number of eigenvectors needed for a desired accuracy based on user input, and derive update equations for the eigenvectors when the edge weights or topology of the image graph are changed. We present results demonstrating that our techniques make RW with precomputation much more robust to offline settings while only sacrificing minimal accuracy.



### A real-time analysis of rock fragmentation using UAV technology
- **Arxiv ID**: http://arxiv.org/abs/1607.04243v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1607.04243v1)
- **Published**: 2016-07-14 18:47:18+00:00
- **Updated**: 2016-07-14 18:47:18+00:00
- **Authors**: Thomas Bamford, Kamran Esmaeili, Angela P. Schoellig
- **Comment**: 12 pages, 12 figures, 6th International Conference on Computer
  Applications in the Minerals Industries
- **Journal**: None
- **Summary**: Accurate measurement of blast-induced rock fragmentation is of great importance for many mining operations. The post-blast rock size distribution can significantly influence the efficiency of all the downstream mining and comminution processes. Image analysis methods are one of the most common methods used to measure rock fragment size distribution in mines regardless of criticism for lack of accuracy to measure fine particles and other perceived deficiencies. The current practice of collecting rock fragmentation data for image analysis is highly manual and provides data with low temporal and spatial resolution. Using UAVs for collecting images of rock fragments can not only improve the quality of the image data but also automate the data collection process. Ultimately, real-time acquisition of high temporal- and spatial-resolution data based on UAV technology will provide a broad range of opportunities for both improving blast design without interrupting the production process and reducing the cost of the human operator. This paper presents the results of a series of laboratory-scale rock fragment measurements using a quadrotor UAV equipped with a camera. The goal of this work is to highlight the benefits of aerial fragmentation analysis in terms of both prediction accuracy and time effort. A pile of rock fragments with different fragment sizes was placed in a lab that is equipped with a motion capture camera system for precise UAV localization and control. Such an environment presents optimal conditions for UAV flight and thus, is well-suited for conducting proof-of-concept experiments before testing them in large-scale field experiments. The pile was photographed by a camera attached to the UAV, and the particle size distribution curves were generated in almost real-time. The pile was also manually photographed and the results of the manual method were compared to the UAV method.



### Defensive Distillation is Not Robust to Adversarial Examples
- **Arxiv ID**: http://arxiv.org/abs/1607.04311v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1607.04311v1)
- **Published**: 2016-07-14 20:44:27+00:00
- **Updated**: 2016-07-14 20:44:27+00:00
- **Authors**: Nicholas Carlini, David Wagner
- **Comment**: None
- **Journal**: None
- **Summary**: We show that defensive distillation is not secure: it is no more resistant to targeted misclassification attacks than unprotected neural networks.



