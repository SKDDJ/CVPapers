# Arxiv Papers in cs.CV on 2016-07-31
### Deep FisherNet for Object Classification
- **Arxiv ID**: http://arxiv.org/abs/1608.00182v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1608.00182v1)
- **Published**: 2016-07-31 03:56:30+00:00
- **Updated**: 2016-07-31 03:56:30+00:00
- **Authors**: Peng Tang, Xinggang Wang, Baoguang Shi, Xiang Bai, Wenyu Liu, Zhuowen Tu
- **Comment**: submitted to NIPS 2016
- **Journal**: None
- **Summary**: Despite the great success of convolutional neural networks (CNN) for the image classification task on datasets like Cifar and ImageNet, CNN's representation power is still somewhat limited in dealing with object images that have large variation in size and clutter, where Fisher Vector (FV) has shown to be an effective encoding strategy. FV encodes an image by aggregating local descriptors with a universal generative Gaussian Mixture Model (GMM). FV however has limited learning capability and its parameters are mostly fixed after constructing the codebook. To combine together the best of the two worlds, we propose in this paper a neural network structure with FV layer being part of an end-to-end trainable system that is differentiable; we name our network FisherNet that is learnable using backpropagation. Our proposed FisherNet combines convolutional neural network training and Fisher Vector encoding in a single end-to-end structure. We observe a clear advantage of FisherNet over plain CNN and standard FV in terms of both classification accuracy and computational efficiency on the challenging PASCAL VOC object classification task.



### Visual Relationship Detection with Language Priors
- **Arxiv ID**: http://arxiv.org/abs/1608.00187v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00187v1)
- **Published**: 2016-07-31 05:54:13+00:00
- **Updated**: 2016-07-31 05:54:13+00:00
- **Authors**: Cewu Lu, Ranjay Krishna, Michael Bernstein, Li Fei-Fei
- **Comment**: ECCV 2016 Oral
- **Journal**: None
- **Summary**: Visual relationships capture a wide variety of interactions between pairs of objects in images (e.g. "man riding bicycle" and "man pushing bicycle"). Consequently, the set of possible relationships is extremely large and it is difficult to obtain sufficient training examples for all possible relationships. Because of this limitation, previous work on visual relationship detection has concentrated on predicting only a handful of relationships. Though most relationships are infrequent, their objects (e.g. "man" and "bicycle") and predicates (e.g. "riding" and "pushing") independently occur more frequently. We propose a model that uses this insight to train visual models for objects and predicates individually and later combines them together to predict multiple relationships per image. We improve on prior work by leveraging language priors from semantic word embeddings to finetune the likelihood of a predicted relationship. Our model can scale to predict thousands of types of relationships from a few examples. Additionally, we localize the objects in the predicted relationships as bounding boxes in the image. We further demonstrate that understanding relationships can improve content based image retrieval.



### A Data-driven Approach for Human Pose Tracking Based on Spatio-temporal Pictorial Structure
- **Arxiv ID**: http://arxiv.org/abs/1608.00199v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00199v1)
- **Published**: 2016-07-31 08:50:47+00:00
- **Updated**: 2016-07-31 08:50:47+00:00
- **Authors**: Soumitra Samanta, Bhabatosh Chanda
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a data-driven approach for human pose tracking in video data. We formulate the human pose tracking problem as a discrete optimization problem based on spatio-temporal pictorial structure model and solve this problem in a greedy framework very efficiently. We propose the model to track the human pose by combining the human pose estimation from single image and traditional object tracking in a video. Our pose tracking objective function consists of the following terms: likeliness of appearance of a part within a frame, temporal displacement of the part from previous frame to the current frame, and the spatial dependency of a part with its parent in the graph structure. Experimental evaluation on benchmark datasets (VideoPose2, Poses in the Wild and Outdoor Pose) as well as on our newly build ICDPose dataset shows the usefulness of our proposed method.



### Automatic 3D Point Set Reconstruction from Stereo Laparoscopic Images using Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1608.00203v1
- **DOI**: None
- **Categories**: **cs.CV**, I.5.2; I.5.4; I.4.5; I.2.10; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/1608.00203v1)
- **Published**: 2016-07-31 09:28:28+00:00
- **Updated**: 2016-07-31 09:28:28+00:00
- **Authors**: Balint Antal
- **Comment**: In Proceedings of the 6th International Joint Conference on Pervasive
  and Embedded Computing and Communication Systems (PECCS 2016), pages 116-121
  ISBN: 978-989-758-195-3
- **Journal**: None
- **Summary**: In this paper, an automatic approach to predict 3D coordinates from stereo laparoscopic images is presented. The approach maps a vector of pixel intensities to 3D coordinates through training a six layer deep neural network. The architectural aspects of the approach is presented and in detail and the method is evaluated on a publicly available dataset with promising results.



### Learning deep representation from coarse to fine for face alignment
- **Arxiv ID**: http://arxiv.org/abs/1608.00207v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00207v1)
- **Published**: 2016-07-31 11:02:40+00:00
- **Updated**: 2016-07-31 11:02:40+00:00
- **Authors**: Zhiwen Shao, Shouhong Ding, Yiru Zhao, Qinchuan Zhang, Lizhuang Ma
- **Comment**: This paper is accepted by 2016 IEEE International Conference on
  Multimedia and Expo (ICME)
- **Journal**: None
- **Summary**: In this paper, we propose a novel face alignment method that trains deep convolutional network from coarse to fine. It divides given landmarks into principal subset and elaborate subset. We firstly keep a large weight for principal subset to make our network primarily predict their locations while slightly take elaborate subset into account. Next the weight of principal subset is gradually decreased until two subsets have equivalent weights. This process contributes to learn a good initial model and search the optimal model smoothly to avoid missing fairly good intermediate models in subsequent procedures. On the challenging COFW dataset [1], our method achieves 6.33% mean error with a reduction of 21.37% compared with the best previous result [2].



### Hyperparameter Transfer Learning through Surrogate Alignment for Efficient Deep Neural Network Training
- **Arxiv ID**: http://arxiv.org/abs/1608.00218v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1608.00218v1)
- **Published**: 2016-07-31 14:09:17+00:00
- **Updated**: 2016-07-31 14:09:17+00:00
- **Authors**: Ilija Ilievski, Jiashi Feng
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, several optimization methods have been successfully applied to the hyperparameter optimization of deep neural networks (DNNs). The methods work by modeling the joint distribution of hyperparameter values and corresponding error. Those methods become less practical when applied to modern DNNs whose training may take a few days and thus one cannot collect sufficient observations to accurately model the distribution. To address this challenging issue, we propose a method that learns to transfer optimal hyperparameter values for a small source dataset to hyperparameter values with comparable performance on a dataset of interest. As opposed to existing transfer learning methods, our proposed method does not use hand-designed features. Instead, it uses surrogates to model the hyperparameter-error distributions of the two datasets and trains a neural network to learn the transfer function. Extensive experiments on three CV benchmark datasets clearly demonstrate the efficiency of our method.



### Learning Robust Features using Deep Learning for Automatic Seizure Detection
- **Arxiv ID**: http://arxiv.org/abs/1608.00220v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.00220v1)
- **Published**: 2016-07-31 14:28:15+00:00
- **Updated**: 2016-07-31 14:28:15+00:00
- **Authors**: Pierre Thodoroff, Joelle Pineau, Andrew Lim
- **Comment**: Presented at 2016 Machine Learning and Healthcare Conference (MLHC
  2016), Los Angeles, CA
- **Journal**: None
- **Summary**: We present and evaluate the capacity of a deep neural network to learn robust features from EEG to automatically detect seizures. This is a challenging problem because seizure manifestations on EEG are extremely variable both inter- and intra-patient. By simultaneously capturing spectral, temporal and spatial information our recurrent convolutional neural network learns a general spatially invariant representation of a seizure. The proposed approach exceeds significantly previous results obtained on cross-patient classifiers both in terms of sensitivity and false positive rate. Furthermore, our model proves to be robust to missing channel and variable electrode montage.



### Data-Driven Background Subtraction Algorithm for in-Camera Acceleration in Thermal Imagery
- **Arxiv ID**: http://arxiv.org/abs/1608.00229v2
- **DOI**: 10.1109/TCSVT.2017.2711259
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00229v2)
- **Published**: 2016-07-31 15:17:46+00:00
- **Updated**: 2017-10-15 14:23:43+00:00
- **Authors**: Konstantinos Makantasis, Antonis Nikitakis, Anastasios Doulamis, Nikolaos Doulamis, Yannis Papaefstathiou
- **Comment**: 15 pages. arXiv admin note: text overlap with arXiv:1506.08581
- **Journal**: IEEE Transactions on Circuits and Systems for Video Technology 99
  (2017)
- **Summary**: Detection of moving objects in videos is a crucial step towards successful surveillance and monitoring applications. A key component for such tasks is called background subtraction and tries to extract regions of interest from the image background for further processing or action. For this reason, its accuracy and real-time performance is of great significance. Although, effective background subtraction methods have been proposed, only a few of them take into consideration the special characteristics of thermal imagery. In this work, we propose a background subtraction scheme, which models the thermal responses of each pixel as a mixture of Gaussians with unknown number of components. Following a Bayesian approach, our method automatically estimates the mixture structure, while simultaneously it avoids over/under fitting. The pixel density estimate is followed by an efficient and highly accurate updating mechanism, which permits our system to be automatically adapted to dynamically changing operation conditions. We propose a reference implementation of our method in reconfigurable hardware achieving both adequate performance and low power consumption. Adopting a High Level Synthesis design, demanding floating point arithmetic operations are mapped in reconfigurable hardware; demonstrating fast-prototyping and on-field customization at the same time.



### Similarity Registration Problems for 2D/3D Ultrasound Calibration
- **Arxiv ID**: http://arxiv.org/abs/1608.00247v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00247v1)
- **Published**: 2016-07-31 18:04:54+00:00
- **Updated**: 2016-07-31 18:04:54+00:00
- **Authors**: Francisco Vasconcelos, Donald Peebles, Sebastien Ourselin, Danail Stoyanov
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a minimal solution for the similarity registration (rigid pose and scale) between two sets of 3D lines, and also between a set of co-planar points and a set of 3D lines. The first problem is solved up to 8 discrete solutions with a minimum of 2 line-line correspondences, while the second is solved up to 4 discrete solutions using 4 point-line correspondences. We use these algorithms to perform the extrinsic calibration between a pose tracking sensor and a 2D/3D ultrasound (US) curvilinear probe using a tracked needle as calibration target. The needle is tracked as a 3D line, and is scanned by the ultrasound as either a 3D line (3D US) or as a 2D point (2D US). Since the scale factor that converts US scan units to metric coordinates is unknown, the calibration is formulated as a similarity registration problem. We present results with both synthetic and real data and show that the minimum solutions outperform the correspondent non-minimal linear formulations.



### Identification of repeats in DNA sequences using nucleotide distribution uniformity
- **Arxiv ID**: http://arxiv.org/abs/1608.00567v1
- **DOI**: None
- **Categories**: **q-bio.GN**, cs.CE, cs.CV, cs.DS, 92D20, 92-08
- **Links**: [PDF](http://arxiv.org/pdf/1608.00567v1)
- **Published**: 2016-07-31 21:16:18+00:00
- **Updated**: 2016-07-31 21:16:18+00:00
- **Authors**: Changchuan Yin
- **Comment**: None
- **Journal**: None
- **Summary**: Repetitive elements are important in genomic structures, functions and regulations, yet effective methods in precisely identifying repetitive elements in DNA sequences are not fully accessible, and the relationship between repetitive elements and periodicities of genomes is not clearly understood. We present an $\textit{ab initio}$ method to quantitatively detect repetitive elements and infer the consensus repeat pattern in repetitive elements. The method uses the measure of the distribution uniformity of nucleotides at periodic positions in DNA sequences or genomes. It can identify periodicities, consensus repeat patterns, copy numbers and perfect levels of repetitive elements. The results of using the method on different DNA sequences and genomes demonstrate efficacy and accuracy in identifying repeat patterns and periodicities. The complexity of the method is linear with respect to the lengths of the analyzed sequences.



### Denoising and compression in wavelet domain via projection onto approximation coefficients
- **Arxiv ID**: http://arxiv.org/abs/1608.00265v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00265v1)
- **Published**: 2016-07-31 21:33:17+00:00
- **Updated**: 2016-07-31 21:33:17+00:00
- **Authors**: Mario Mastriani
- **Comment**: 11 pages, 10 figures, 2 tables. arXiv admin note: substantial text
  overlap with arXiv:1405.0632, arXiv:1607.03105, arXiv:1608.00268,
  arXiv:1608.00277
- **Journal**: None
- **Summary**: We describe a new filtering approach in the wavelet domain for image denoising and compression, based on the projections of details subbands coefficients (resultants of the splitting procedure, typical in wavelet domain) onto the approximation subband coefficients (much less noisy). The new algorithm is called Projection Onto Approximation Coefficients (POAC). As a result of this approach, only the approximation subband coefficients and three scalars are stored and/or transmitted to the channel. Besides, with the elimination of the details subbands coefficients, we obtain a bigger compression rate. Experimental results demonstrate that our approach compares favorably to more typical methods of denoising and compression in wavelet domain.



### Union is strength in lossy image compression
- **Arxiv ID**: http://arxiv.org/abs/1608.00268v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00268v1)
- **Published**: 2016-07-31 21:57:54+00:00
- **Updated**: 2016-07-31 21:57:54+00:00
- **Authors**: Mario Mastriani
- **Comment**: 18 pages, 21 figures, 4 tables. arXiv admin note: substantial text
  overlap with arXiv:1607.03164, arXiv:1405.0632, arXiv:1608.00265
- **Journal**: None
- **Summary**: In this work, we present a comparison between different techniques of image compression. First, the image is divided in blocks which are organized according to a certain scan. Later, several compression techniques are applied, combined or alone. Such techniques are: wavelets (Haar's basis), Karhunen-Loeve Transform, etc. Simulations show that the combined versions are the best, with minor Mean Squared Error (MSE), and higher Peak Signal to Noise Ratio (PSNR) and better image quality, even in the presence of noise.



### New wavelet-based superresolution algorithm for speckle reduction in SAR images
- **Arxiv ID**: http://arxiv.org/abs/1608.00270v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00270v1)
- **Published**: 2016-07-31 22:11:52+00:00
- **Updated**: 2016-07-31 22:11:52+00:00
- **Authors**: Mario Mastriani
- **Comment**: 8 pages, 6 figures, 1 table. arXiv admin note: substantial text
  overlap with arXiv:1607.03105, arXiv:1608.00273, arXiv:1608.00279,
  arXiv:1608.00277
- **Journal**: None
- **Summary**: This paper describes a novel projection algorithm, the Projection Onto Span Algorithm (POSA) for wavelet-based superresolution and removing speckle (in wavelet domain) of unknown variance from Synthetic Aperture Radar (SAR) images. Although the POSA is good as a new superresolution algorithm for image enhancement, image metrology and biometric identification, here one will use it like a tool of despeckling, being the first time that an algorithm of super-resolution is used for despeckling of SAR images. Specifically, the speckled SAR image is decomposed into wavelet subbands, POSA is applied to the high subbands, and reconstruct a SAR image from the modified detail coefficients. Experimental results demonstrate that the new method compares favorably to several other despeckling methods on test SAR images.



### Modeling Context in Referring Expressions
- **Arxiv ID**: http://arxiv.org/abs/1608.00272v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1608.00272v3)
- **Published**: 2016-07-31 22:21:42+00:00
- **Updated**: 2016-08-10 19:01:37+00:00
- **Authors**: Licheng Yu, Patrick Poirson, Shan Yang, Alexander C. Berg, Tamara L. Berg
- **Comment**: 19 pages, 6 figures, in ECCV 2016; authors, references and
  acknowledgement updated
- **Journal**: None
- **Summary**: Humans refer to objects in their environments all the time, especially in dialogue with other people. We explore generating and comprehending natural language referring expressions for objects in images. In particular, we focus on incorporating better measures of visual context into referring expression models and find that visual comparison to other objects within an image helps improve performance significantly. We also develop methods to tie the language generation process together, so that we generate expressions for all objects of a particular category jointly. Evaluation on three recent datasets - RefCOCO, RefCOCO+, and RefCOCOg, shows the advantages of our methods for both referring expression generation and comprehension.



### Kalman's shrinkage for wavelet-based despeckling of SAR images
- **Arxiv ID**: http://arxiv.org/abs/1608.00273v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00273v1)
- **Published**: 2016-07-31 22:24:53+00:00
- **Updated**: 2016-07-31 22:24:53+00:00
- **Authors**: Mario Mastriani, Alberto E. Giraldez
- **Comment**: 7 pages, 1 figure, 1 table. arXiv admin note: substantial text
  overlap with arXiv:1607.03105, arXiv:1608.00270, arXiv:1608.00279,
  arXiv:1608.00277, arXiv:1608.00274
- **Journal**: None
- **Summary**: In this paper, a new probability density function (pdf) is proposed to model the statistics of wavelet coefficients, and a simple Kalman's filter is derived from the new pdf using Bayesian estimation theory. Specifically, we decompose the speckled image into wavelet subbands, we apply the Kalman's filter to the high subbands, and reconstruct a despeckled image from the modified detail coefficients. Experimental results demonstrate that our method compares favorably to several other despeckling methods on test synthetic aperture radar (SAR) images.



### Denoising based on wavelets and deblurring via self-organizing map for Synthetic Aperture Radar images
- **Arxiv ID**: http://arxiv.org/abs/1608.00274v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00274v1)
- **Published**: 2016-07-31 22:32:55+00:00
- **Updated**: 2016-07-31 22:32:55+00:00
- **Authors**: Mario Mastriani
- **Comment**: 10 pages, 7 figures, 2 tables. arXiv admin note: text overlap with
  arXiv:1608.00273; text overlap with arXiv:1002.3985 by other authors without
  attribution
- **Journal**: None
- **Summary**: This work deals with unsupervised image deblurring. We present a new deblurring procedure on images provided by low-resolution synthetic aperture radar (SAR) or simply by multimedia in presence of multiplicative (speckle) or additive noise, respectively. The method we propose is defined as a two-step process. First, we use an original technique for noise reduction in wavelet domain. Then, the learning of a Kohonen self-organizing map (SOM) is performed directly on the denoised image to take out it the blur. This technique has been successfully applied to real SAR images, and the simulation results are presented to demonstrate the effectiveness of the proposed algorithms.



### Fuzzy thresholding in wavelet domain for speckle reduction in Synthetic Aperture Radar images
- **Arxiv ID**: http://arxiv.org/abs/1608.00277v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00277v1)
- **Published**: 2016-07-31 22:39:03+00:00
- **Updated**: 2016-07-31 22:39:03+00:00
- **Authors**: Mario Mastriani
- **Comment**: 14 pages, 16 figures, 4 tables. arXiv admin note: substantial text
  overlap with arXiv:1607.03105, arXiv:1608.00270, arXiv:1608.00273,
  arXiv:1608.00279; text overlap with arXiv:chao-dyn/9905033 by other authors
  without attribution
- **Journal**: None
- **Summary**: The application of wavelet transforms to Synthetic Aperture Radar (SAR) imagery has improved despeckling performance. To deduce the problem of filtering the multiplicative noise to the case of an additive noise, the wavelet decomposition is performed on the logarithm of the image gray levels. The detail coefficients produced by the bidimensional discrete wavelet transform (DWT-2D) needs to be thresholded to extract out the speckle in highest subbands. An initial threshold value is estimated according to the noise variance. In this paper, an additional fuzzy thresholding approach for automatic determination of the rate threshold level around the traditional wavelet noise thresholding (initial threshold) is applied, and used for the soft or hard-threshold performed on all the high frequency subimages. The filtered logarithmic image is then obtained by reconstruction from the thresholded coefficients. This process is applied a single time, and exclusively to the first level of decomposition. The exponential function of this reconstructed image gives the final filtered image. Experimental results on test images have demonstrated the effectiveness of this method compared to the most of methods in use at the moment.



### Neural shrinkage for wavelet-based SAR despeckling
- **Arxiv ID**: http://arxiv.org/abs/1608.00279v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00279v1)
- **Published**: 2016-07-31 22:44:45+00:00
- **Updated**: 2016-07-31 22:44:45+00:00
- **Authors**: Mario Mastriani, Alberto E. Giraldez
- **Comment**: 12 pages, 7 figures, 2 tables. arXiv admin note: text overlap with
  arXiv:1607.03105, arXiv:1608.00273, arXiv:1608.00270, arXiv:1608.00277
- **Journal**: None
- **Summary**: The wavelet shrinkage denoising approach is able to maintain local regularity of a signal while suppressing noise. However, the conventional wavelet shrinkage based methods are not time-scale adaptive to track the local time-scale variation. In this paper, a new type of Neural Shrinkage (NS) is presented with a new class of shrinkage architecture for speckle reduction in Synthetic Aperture Radar (SAR) images. The numerical results indicate that the new method outperforms the standard filters, the standard wavelet shrinkage despeckling method, and previous NS.



