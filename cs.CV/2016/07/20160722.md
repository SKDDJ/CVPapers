# Arxiv Papers in cs.CV on 2016-07-22
### Classification of Alzheimer's Disease Structural MRI Data by Deep Learning Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1607.06583v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1607.06583v2)
- **Published**: 2016-07-22 07:48:18+00:00
- **Updated**: 2017-05-19 20:41:51+00:00
- **Authors**: Saman Sarraf, Ghassem Tofighi
- **Comment**: arXiv admin note: text overlap with arXiv:1603.08631
- **Journal**: None
- **Summary**: Recently, machine learning techniques especially predictive modeling and pattern recognition in biomedical sciences from drug delivery system to medical imaging has become one of the important methods which are assisting researchers to have deeper understanding of entire issue and to solve complex medical problems. Deep learning is a powerful machine learning algorithm in classification while extracting low to high-level features. In this paper, we used convolutional neural network to classify Alzheimer's brain from normal healthy brain. The importance of classifying this kind of medical data is to potentially develop a predict model or system in order to recognize the type disease from normal subjects or to estimate the stage of the disease. Classification of clinical data such as Alzheimer's disease has been always challenging and most problematic part has been always selecting the most discriminative features. Using Convolutional Neural Network (CNN) and the famous architecture LeNet-5, we successfully classified structural MRI data of Alzheimer's subjects from normal controls where the accuracy of test data on trained data reached 98.84%. This experiment suggests us the shift and scale invariant features extracted by CNN followed by deep learning classification is most powerful method to distinguish clinical data from healthy data in fMRI. This approach also enables us to expand our methodology to predict more complicated systems.



### Can DMD obtain a Scene Background in Color?
- **Arxiv ID**: http://arxiv.org/abs/1607.06783v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06783v1)
- **Published**: 2016-07-22 18:41:01+00:00
- **Updated**: 2016-07-22 18:41:01+00:00
- **Authors**: Santosh Tirunagari, Norman Poh, Miroslaw Bober, David Windridge
- **Comment**: International Conference on Image, Vision and Computing (ICIVC 2016),
  August 3-5, 2016, Portsmouth, UK
- **Journal**: None
- **Summary**: A background model describes a scene without any foreground objects and has a number of applications, ranging from video surveillance to computational photography. Recent studies have introduced the method of Dynamic Mode Decomposition (DMD) for robustly separating video frames into a background model and foreground components. While the method introduced operates by converting color images to grayscale, we in this study propose a technique to obtain the background model in the color domain. The effectiveness of our technique is demonstrated using a publicly available Scene Background Initialisation (SBI) dataset. Our results both qualitatively and quantitatively show that DMD can successfully obtain a colored background model.



### Prior-based Coregistration and Cosegmentation
- **Arxiv ID**: http://arxiv.org/abs/1607.06787v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06787v1)
- **Published**: 2016-07-22 18:49:09+00:00
- **Updated**: 2016-07-22 18:49:09+00:00
- **Authors**: Mahsa Shakeri, Enzo Ferrante, Stavros Tsogkas, Sarah Lippe, Samuel Kadoury, Iasonas Kokkinos, Nikos Paragios
- **Comment**: The first two authors contributed equally
- **Journal**: MICCAI 2016
- **Summary**: We propose a modular and scalable framework for dense coregistration and cosegmentation with two key characteristics: first, we substitute ground truth data with the semantic map output of a classifier; second, we combine this output with population deformable registration to improve both alignment and segmentation. Our approach deforms all volumes towards consensus, taking into account image similarities and label consistency. Our pipeline can incorporate any classifier and similarity metric. Results on two datasets, containing annotations of challenging brain structures, demonstrate the potential of our method.



### An ensemble learning method for scene classification based on Hidden Markov Model image representation
- **Arxiv ID**: http://arxiv.org/abs/1607.06794v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06794v3)
- **Published**: 2016-07-22 19:06:17+00:00
- **Updated**: 2016-10-05 06:25:16+00:00
- **Authors**: Fariborz Taherkhani, Reza Hedayati
- **Comment**: This paper has been withdrawn by the authors due to significant
  errors in equations 3 and 4
- **Journal**: None
- **Summary**: Low level images representation in feature space performs poorly for classification with high accuracy since this level of representation is not able to project images into the discriminative feature space. In this work, we propose an efficient image representation model for classification. First we apply Hidden Markov Model (HMM) on ordered grids represented by different type of image descriptors in order to include causality of local properties existing in image for feature extraction and then we train up a separate classifier for each of these features sets. Finally we ensemble these classifiers efficiently in a way that they can cancel out each other errors for obtaining higher accuracy. This method is evaluated on 15 natural scene dataset. Experimental results show the superiority of the proposed method in comparison to some current existing methods



### A probabilistic patch based image representation using Conditional Random Field model for image classification
- **Arxiv ID**: http://arxiv.org/abs/1607.06797v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06797v2)
- **Published**: 2016-07-22 19:19:47+00:00
- **Updated**: 2016-10-05 06:24:06+00:00
- **Authors**: Fariborz Taherkhani
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we proposed an ordered patch based method using Conditional Random Field (CRF) in order to encode local properties and their spatial relationship in images to address texture classification, face recognition, and scene classification problems. Typical image classification approaches work without considering spatial causality among distinctive properties of an image for image representation in feature space. In this method first, each image is encoded as a sequence of ordered patches, including local properties. Second, the sequence of these ordered patches is modeled as a probabilistic feature vector by CRF to model spatial relationship of these local properties. And finally, image classification is performed on such probabilistic image representation. Experimental results on several standard image datasets indicate that proposed method outperforms some of existing image classification methods.



### Unsupervised Learning from Continuous Video in a Scalable Predictive Recurrent Network
- **Arxiv ID**: http://arxiv.org/abs/1607.06854v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06854v3)
- **Published**: 2016-07-22 22:13:04+00:00
- **Updated**: 2016-09-30 17:41:41+00:00
- **Authors**: Filip Piekniewski, Patryk Laurent, Csaba Petre, Micah Richert, Dimitry Fisher, Todd Hylton
- **Comment**: 38 pages, 20 figures, v3. Added several citations to relevant papers,
  expanded the discussion of existing approach in deep learning
- **Journal**: None
- **Summary**: Understanding visual reality involves acquiring common-sense knowledge about countless regularities in the visual world, e.g., how illumination alters the appearance of objects in a scene, and how motion changes their apparent spatial relationship. These regularities are hard to label for training supervised machine learning algorithms; consequently, algorithms need to learn these regularities from the real world in an unsupervised way. We present a novel network meta-architecture that can learn world dynamics from raw, continuous video. The components of this network can be implemented using any algorithm that possesses three key capabilities: prediction of a signal over time, reduction of signal dimensionality (compression), and the ability to use supplementary contextual information to inform the prediction. The presented architecture is highly-parallelized and scalable, and is implemented using localized connectivity, processing, and learning. We demonstrate an implementation of this architecture where the components are built from multi-layer perceptrons. We apply the implementation to create a system capable of stable and robust visual tracking of objects as seen by a moving camera. Results show performance on par with or exceeding state-of-the-art tracking algorithms. The tracker can be trained in either fully supervised or unsupervised-then-briefly-supervised regimes. Success of the briefly-supervised regime suggests that the unsupervised portion of the model extracts useful information about visual reality. The results suggest a new class of AI algorithms that uniquely combine prediction and scalability in a way that makes them suitable for learning from and --- and eventually acting within --- the real world.



