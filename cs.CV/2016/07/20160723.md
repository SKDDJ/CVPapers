# Arxiv Papers in cs.CV on 2016-07-23
### Deep Appearance Models: A Deep Boltzmann Machine Approach for Face Modeling
- **Arxiv ID**: http://arxiv.org/abs/1607.06871v3
- **DOI**: 10.1007/s11263-018-1113-3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06871v3)
- **Published**: 2016-07-23 01:12:26+00:00
- **Updated**: 2017-12-21 20:12:36+00:00
- **Authors**: Chi Nhan Duong, Khoa Luu, Kha Gia Quach, Tien D. Bui
- **Comment**: None
- **Journal**: None
- **Summary**: The "interpretation through synthesis" approach to analyze face images, particularly Active Appearance Models (AAMs) method, has become one of the most successful face modeling approaches over the last two decades. AAM models have ability to represent face images through synthesis using a controllable parameterized Principal Component Analysis (PCA) model. However, the accuracy and robustness of the synthesized faces of AAM are highly depended on the training sets and inherently on the generalizability of PCA subspaces. This paper presents a novel Deep Appearance Models (DAMs) approach, an efficient replacement for AAMs, to accurately capture both shape and texture of face images under large variations. In this approach, three crucial components represented in hierarchical layers are modeled using the Deep Boltzmann Machines (DBM) to robustly capture the variations of facial shapes and appearances. DAMs are therefore superior to AAMs in inferencing a representation for new face images under various challenging conditions. The proposed approach is evaluated in various applications to demonstrate its robustness and capabilities, i.e. facial super-resolution reconstruction, facial off-angle reconstruction or face frontalization, facial occlusion removal and age estimation using challenging face databases, i.e. Labeled Face Parts in the Wild (LFPW), Helen and FG-NET. Comparing to AAMs and other deep learning based approaches, the proposed DAMs achieve competitive results in those applications, thus this showed their advantages in handling occlusions, facial representation, and reconstruction.



### Rank Correlation Measure: A Representational Transformation for Biometric Template Protection
- **Arxiv ID**: http://arxiv.org/abs/1607.06902v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1607.06902v1)
- **Published**: 2016-07-23 08:12:01+00:00
- **Updated**: 2016-07-23 08:12:01+00:00
- **Authors**: Zhe Jin, Yen-Lung Lai, Andrew Beng Jin Teoh
- **Comment**: 6 pages, 5 figures, 2 tables, 1 algorithm
- **Journal**: None
- **Summary**: Despite a variety of theoretical-sound techniques have been proposed for biometric template protection, there is rarely practical solution that guarantees non-invertibility, cancellability, non-linkability and performance simultaneously. In this paper, a ranking-based representational transformation is proposed for fingerprint templates. The proposed method transforms a real-valued feature vector into index code such that the pairwise-order measure in the resultant codes are closely correlated with rank similarity measure. Such a ranking based technique offers two major merits: 1) Resilient to noises/perturbations in numeric values; and 2) Highly nonlinear embedding based on partial order statistics. The former takes care of the accuracy performance mitigating numeric noises/perturbations while the latter offers strong non-invertible transformation via nonlinear feature embedding from Euclidean to Rank space that leads to toughness in inversion. The experimental results demonstrate reasonable accuracy performance on benchmark FVC2002 and FVC2004 fingerprint databases, thus confirm the proposition of the rank correlation. Moreover, the security and privacy analysis justify the strong capability against the existing major privacy attacks.



### Kinematic-Layout-aware Random Forests for Depth-based Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1607.06972v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06972v3)
- **Published**: 2016-07-23 20:36:39+00:00
- **Updated**: 2016-12-09 11:32:54+00:00
- **Authors**: Seungryul Baek, Zhiyuan Shi, Masato Kawade, Tae-Kyun Kim
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we tackle the problem of 24 hours-monitoring patient actions in a ward such as "stretching an arm out of the bed", "falling out of the bed", where temporal movements are subtle or significant. In the concerned scenarios, the relations between scene layouts and body kinematics (skeletons) become important cues to recognize actions; however they are hard to be secured at a testing stage. To address this problem, we propose a kinematic-layout-aware random forest which takes into account the kinematic-layout (\ie layout and skeletons), to maximize the discriminative power of depth image appearance. We integrate the kinematic-layout in the split criteria of random forests to guide the learning process by 1) determining the switch to either the depth appearance or the kinematic-layout information, and 2) implicitly closing the gap between two distributions obtained by the kinematic-layout and the appearance, when the kinematic-layout appears useful. The kinematic-layout information is not required for the test data, thus called "privileged information prior". The proposed method has also been testified in cross-view settings, by the use of view-invariant features and enforcing the consistency among synthetic-view data. Experimental evaluations on our new dataset PATIENT, CAD-60 and UWA3D (multiview) demonstrate that our method outperforms various state-of-the-arts.



### Combined Classifiers for Invariant Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1607.06973v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1607.06973v1)
- **Published**: 2016-07-23 20:38:56+00:00
- **Updated**: 2016-07-23 20:38:56+00:00
- **Authors**: Ahmad H. A. Eid
- **Comment**: M.Sc. Thesis, 2004
- **Journal**: None
- **Summary**: No single classifier can alone solve the complex problem of face recognition. Researchers found that combining some base classifiers usually enhances their recognition rate. The weaknesses of the base classifiers are reflected on the resulting combined system. In this work, a system for combining unstable, low performance classifiers is proposed. The system is applied to face images of 392 persons. The system shows remarkable stability and high recognition rate using a reduced number of parameters. The system illustrates the possibility of designing a combined system that benefits from the strengths of its base classifiers while avoiding many of their weaknesses.



