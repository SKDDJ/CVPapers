# Arxiv Papers in cs.CV on 2016-05-13
### Cross-Domain Visual Matching via Generalized Similarity Measure and Feature Learning
- **Arxiv ID**: http://arxiv.org/abs/1605.04039v1
- **DOI**: 10.1109/TPAMI.2016.2567386
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1605.04039v1)
- **Published**: 2016-05-13 03:35:14+00:00
- **Updated**: 2016-05-13 03:35:14+00:00
- **Authors**: Liang Lin, Guangrun Wang, Wangmeng Zuo, Xiangchu Feng, Lei Zhang
- **Comment**: To appear in IEEE Transactions on Pattern Analysis and Machine
  Intelligence (T-PAMI), 2016
- **Journal**: None
- **Summary**: Cross-domain visual data matching is one of the fundamental problems in many real-world vision tasks, e.g., matching persons across ID photos and surveillance videos. Conventional approaches to this problem usually involves two steps: i) projecting samples from different domains into a common space, and ii) computing (dis-)similarity in this space based on a certain distance. In this paper, we present a novel pairwise similarity measure that advances existing models by i) expanding traditional linear projections into affine transformations and ii) fusing affine Mahalanobis distance and Cosine similarity by a data-driven combination. Moreover, we unify our similarity measure with feature representation learning via deep convolutional neural networks. Specifically, we incorporate the similarity measure matrix into the deep architecture, enabling an end-to-end way of model optimization. We extensively evaluate our generalized similarity model in several challenging cross-domain matching tasks: person re-identification under different views and face verification over different modalities (i.e., faces from still images and videos, older and younger faces, and sketch and photo portraits). The experimental results demonstrate superior performance of our model over other state-of-the-art methods.



### Track Extraction with Hidden Reciprocal Chain Models
- **Arxiv ID**: http://arxiv.org/abs/1605.04046v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04046v1)
- **Published**: 2016-05-13 05:29:33+00:00
- **Updated**: 2016-05-13 05:29:33+00:00
- **Authors**: George Stamatescu, Langford B White, Riley Bruce-Doust
- **Comment**: None
- **Journal**: None
- **Summary**: This paper develops Bayesian track extraction algorithms for targets modelled as hidden reciprocal chains (HRC). HRC are a class of finite-state random process models that generalise the familiar hidden Markov chains (HMC). HRC are able to model the "intention" of a target to proceed from a given origin to a destination, behaviour which cannot be properly captured by a HMC. While Bayesian estimation problems for HRC have previously been studied, this paper focusses principally on the problem of track extraction, of which the primary task is confirming target existence in a set of detections obtained from thresholding sensor measurements. Simulation examples are presented which show that the additional model information contained in a HRC improves detection performance when compared to HMC models.



### Fast Semantic Image Segmentation with High Order Context and Guided Filtering
- **Arxiv ID**: http://arxiv.org/abs/1605.04068v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04068v1)
- **Published**: 2016-05-13 07:21:37+00:00
- **Updated**: 2016-05-13 07:21:37+00:00
- **Authors**: Falong Shen, Gang Zeng
- **Comment**: 14 pages
- **Journal**: None
- **Summary**: This paper describes a fast and accurate semantic image segmentation approach that encodes not only the discriminative features from deep neural networks, but also the high-order context compatibility among adjacent objects as well as low level image features. We formulate the underlying problem as the conditional random field that embeds local feature extraction, clique potential construction, and guided filtering within the same framework, and provide an efficient coarse-to-fine solver. At the coarse level, we combine local feature representation and context interaction using a deep convolutional network, and directly learn the interaction from high order cliques with a message passing routine, avoiding time-consuming explicit graph inference for joint probability distribution. At the fine level, we introduce a guided filtering interpretation for the mean field algorithm, and achieve accurate object boundaries with 100+ faster than classic learning methods. The two parts are connected and jointly trained in an end-to-end fashion. Experimental results on Pascal VOC 2012 dataset have shown that the proposed algorithm outperforms the state-of-the-art, and that it achieves the rank 1 performance at the time of submission, both of which prove the effectiveness of this unified framework for semantic image segmentation.



### With Whom Do I Interact? Detecting Social Interactions in Egocentric Photo-streams
- **Arxiv ID**: http://arxiv.org/abs/1605.04129v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04129v2)
- **Published**: 2016-05-13 11:04:28+00:00
- **Updated**: 2017-05-12 11:27:50+00:00
- **Authors**: Maedeh Aghaei, Mariella Dimiccoli, Petia Radeva
- **Comment**: 6 pages, 9 figures, accepted and presented in International
  Conference on Pattern Recognition (ICPR 2016)
- **Journal**: None
- **Summary**: Given a user wearing a low frame rate wearable camera during a day, this work aims to automatically detect the moments when the user gets engaged into a social interaction solely by reviewing the automatically captured photos by the worn camera. The proposed method, inspired by the sociological concept of F-formation, exploits distance and orientation of the appearing individuals -with respect to the user- in the scene from a bird-view perspective. As a result, the interaction pattern over the sequence can be understood as a two-dimensional time series that corresponds to the temporal evolution of the distance and orientation features over time. A Long-Short Term Memory-based Recurrent Neural Network is then trained to classify each time series. Experimental evaluation over a dataset of 30.000 images has shown promising results on the proposed method for social interaction detection in egocentric photo-streams.



### Simultaneous Surface Reflectance and Fluorescence Spectra Estimation
- **Arxiv ID**: http://arxiv.org/abs/1605.04243v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04243v1)
- **Published**: 2016-05-13 16:36:09+00:00
- **Updated**: 2016-05-13 16:36:09+00:00
- **Authors**: Henryk Blasinski, Joyce Farrell, Brian Wandell
- **Comment**: None
- **Journal**: None
- **Summary**: There is widespread interest in estimating the fluorescence properties of natural materials in an image. However, the separation between reflected and fluoresced components is difficult, because it is impossible to distinguish reflected and fluoresced photons without controlling the illuminant spectrum. We show how to jointly estimate the reflectance and fluorescence from a single set of images acquired under multiple illuminants. We present a framework based on a linear approximation to the physical equations describing image formation in terms of surface spectral reflectance and fluorescence due to multiple fluorophores. We relax the non-convex, inverse estimation problem in order to jointly estimate the reflectance and fluorescence properties in a single optimization step and we use the Alternating Direction Method of Multipliers (ADMM) approach to efficiently find a solution. We provide a software implementation of the solver for our method and prior methods. We evaluate the accuracy and reliability of the method using both simulations and experimental data. To acquire data to test the methods, we built a custom imaging system using a monochrome camera, a filter wheel with bandpass transmissive filters and a small number of light emitting diodes. We compared the system and algorithm performance with the ground truth as well as with prior methods. Our approach produces lower errors compared to earlier algorithms.



### Color Homography
- **Arxiv ID**: http://arxiv.org/abs/1605.04250v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04250v2)
- **Published**: 2016-05-13 16:56:10+00:00
- **Updated**: 2016-08-01 13:25:06+00:00
- **Authors**: Graham D. Finlayson, Han Gong, Robert B. Fisher
- **Comment**: Accepted by Progress in Colour Studies 2016
- **Journal**: None
- **Summary**: We show the surprising result that colors across a change in viewing condition (changing light color, shading and camera) are related by a homography. Our homography color correction application delivers improved color fidelity compared with the linear least-square.



### An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1605.04253v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04253v2)
- **Published**: 2016-05-13 17:05:01+00:00
- **Updated**: 2017-01-11 08:33:25+00:00
- **Authors**: Wei-Lun Chao, Soravit Changpinyo, Boqing Gong, Fei Sha
- **Comment**: ECCV2016 camera-ready
- **Journal**: None
- **Summary**: Zero-shot learning (ZSL) methods have been studied in the unrealistic setting where test data are assumed to come from unseen classes only. In this paper, we advocate studying the problem of generalized zero-shot learning (GZSL) where the test data's class memberships are unconstrained. We show empirically that naively using the classifiers constructed by ZSL approaches does not perform well in the generalized setting. Motivated by this, we propose a simple but effective calibration method that can be used to balance two conflicting forces: recognizing data from seen classes versus those from unseen ones. We develop a performance metric to characterize such a trade-off and examine the utility of this metric in evaluating various ZSL approaches. Our analysis further shows that there is a large gap between the performance of existing approaches and an upper bound established via idealized semantic embeddings, suggesting that improving class semantic embeddings is vital to GZSL.



