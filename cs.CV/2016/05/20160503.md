# Arxiv Papers in cs.CV on 2016-05-03
### A propagation matting method based on the Local Sampling and KNN Classification with adaptive feature space
- **Arxiv ID**: http://arxiv.org/abs/1605.00732v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.00732v1)
- **Published**: 2016-05-03 02:09:22+00:00
- **Updated**: 2016-05-03 02:09:22+00:00
- **Authors**: Xiao Chen, Fazhi He
- **Comment**: None
- **Journal**: None
- **Summary**: Closed Form is a propagation based matting algorithm, functioning well on images with good propagation . The deficiency of the Closed Form method is that for complex areas with poor image propagation , such as hole areas or areas of long and narrow structures. The right results are usually hard to get. On these areas, if certain flags are provided, it can improve the effects of matting. In this paper, we design a matting algorithm by local sampling and the KNN classifier propagation based matting algorithm. First of all, build the corresponding features space according to the different components of image colors to reduce the influence of overlapping between the foreground and background, and to improve the classification accuracy of KNN classifier. Second, adaptively use local sampling or using local KNN classifier for processing based on the pros and cons of the sample performance of unknown image areas. Finally, based on different treatment methods for the unknown areas, we will use different weight for augmenting constraints to make the treatment more effective. In this paper, by combining qualitative observation and quantitative analysis, we will make evaluation of the experimental results through online standard set of evaluation tests. It shows that on images with good propagation , this method is as effective as the Closed Form method, while on images in complex regions, it can perform even better than Closed Form.



### Learning Attributes Equals Multi-Source Domain Generalization
- **Arxiv ID**: http://arxiv.org/abs/1605.00743v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.00743v1)
- **Published**: 2016-05-03 03:09:22+00:00
- **Updated**: 2016-05-03 03:09:22+00:00
- **Authors**: Chuang Gan, Tianbao Yang, Boqing Gong
- **Comment**: Accepted by CVPR 2016 as a spotlight presentation
- **Journal**: None
- **Summary**: Attributes possess appealing properties and benefit many computer vision problems, such as object recognition, learning with humans in the loop, and image retrieval. Whereas the existing work mainly pursues utilizing attributes for various computer vision problems, we contend that the most basic problem---how to accurately and robustly detect attributes from images---has been left under explored. Especially, the existing work rarely explicitly tackles the need that attribute detectors should generalize well across different categories, including those previously unseen. Noting that this is analogous to the objective of multi-source domain generalization, if we treat each category as a domain, we provide a novel perspective to attribute detection and propose to gear the techniques in multi-source domain generalization for the purpose of learning cross-category generalizable attribute detectors. We validate our understanding and approach with extensive experiments on four challenging datasets and three different problems.



### Automatic Identification of Retinal Arteries and Veins in Fundus Images using Local Binary Patterns
- **Arxiv ID**: http://arxiv.org/abs/1605.00763v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.00763v1)
- **Published**: 2016-05-03 07:22:49+00:00
- **Updated**: 2016-05-03 07:22:49+00:00
- **Authors**: Nima Hatami, Michael Goldbaum
- **Comment**: None
- **Journal**: Investigative Ophthalmology and Visual Science, 55 (5), 232, 2014
- **Summary**: Artery and vein (AV) classification of retinal images is a key to necessary tasks, such as automated measurement of arteriolar-to-venular diameter ratio (AVR). This paper comprehensively reviews the state-of-the art in AV classification methods. To improve on previous methods, a new Local Bi- nary Pattern-based method (LBP) is proposed. Beside its simplicity, LBP is robust against low contrast and low quality fundus images; and it helps the process by including additional AV texture and shape information. Experimental results compare the performance of the new method with the state-of-the art; and also methods with different feature extraction and classification schemas.



### Spatially Aware Dictionary Learning and Coding for Fossil Pollen Identification
- **Arxiv ID**: http://arxiv.org/abs/1605.00775v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.PE, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1605.00775v1)
- **Published**: 2016-05-03 07:54:32+00:00
- **Updated**: 2016-05-03 07:54:32+00:00
- **Authors**: Shu Kong, Surangi Punyasena, Charless Fowlkes
- **Comment**: CVMI 2016
- **Journal**: None
- **Summary**: We propose a robust approach for performing automatic species-level recognition of fossil pollen grains in microscopy images that exploits both global shape and local texture characteristics in a patch-based matching methodology. We introduce a novel criteria for selecting meaningful and discriminative exemplar patches. We optimize this function during training using a greedy submodular function optimization framework that gives a near-optimal solution with bounded approximation error. We use these selected exemplars as a dictionary basis and propose a spatially-aware sparse coding method to match testing images for identification while maintaining global shape correspondence. To accelerate the coding process for fast matching, we introduce a relaxed form that uses spatially-aware soft-thresholding during coding. Finally, we carry out an experimental study that demonstrates the effectiveness and efficiency of our exemplar selection and classification mechanisms, achieving $86.13\%$ accuracy on a difficult fine-grained species classification task distinguishing three types of fossil spruce pollen.



### Improving Image Captioning by Concept-based Sentence Reranking
- **Arxiv ID**: http://arxiv.org/abs/1605.00855v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1605.00855v1)
- **Published**: 2016-05-03 12:13:26+00:00
- **Updated**: 2016-05-03 12:13:26+00:00
- **Authors**: Xirong Li, Qin Jin
- **Comment**: None
- **Journal**: None
- **Summary**: This paper describes our winning entry in the ImageCLEF 2015 image sentence generation task. We improve Google's CNN-LSTM model by introducing concept-based sentence reranking, a data-driven approach which exploits the large amounts of concept-level annotations on Flickr. Different from previous usage of concept detection that is tailored to specific image captioning models, the propose approach reranks predicted sentences in terms of their matches with detected concepts, essentially treating the underlying model as a black box. This property makes the approach applicable to a number of existing solutions. We also experiment with fine tuning on the deep language model, which improves the performance further. Scoring METEOR of 0.1875 on the ImageCLEF 2015 test set, our system outperforms the runner-up (METEOR of 0.1687) with a clear margin.



### Recurrent Convolutional Neural Network Regression for Continuous Pain Intensity Estimation in Video
- **Arxiv ID**: http://arxiv.org/abs/1605.00894v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.00894v1)
- **Published**: 2016-05-03 13:17:03+00:00
- **Updated**: 2016-05-03 13:17:03+00:00
- **Authors**: Jing Zhou, Xiaopeng Hong, Fei Su, Guoying Zhao
- **Comment**: This paper is the pre-print technical report of the paper accepted by
  the IEEE CVPR Workshop of Affect "in-the-wild". The final version will be
  available after the workshop
- **Journal**: None
- **Summary**: Automatic pain intensity estimation possesses a significant position in healthcare and medical field. Traditional static methods prefer to extract features from frames separately in a video, which would result in unstable changes and peaks among adjacent frames. To overcome this problem, we propose a real-time regression framework based on the recurrent convolutional neural network for automatic frame-level pain intensity estimation. Given vector sequences of AAM-warped facial images, we used a sliding-window strategy to obtain fixed-length input samples for the recurrent network. We then carefully design the architecture of the recurrent network to output continuous-valued pain intensity. The proposed end-to-end pain intensity regression framework can predict the pain intensity of each frame by considering a sufficiently large historical frames while limiting the scale of the parameters within the model. Our method achieves promising results regarding both accuracy and running speed on the published UNBC-McMaster Shoulder Pain Expression Archive Database.



### Hierarchical Modeling of Multidimensional Data in Regularly Decomposed Spaces: Main Principles
- **Arxiv ID**: http://arxiv.org/abs/1605.00961v2
- **DOI**: None
- **Categories**: **cs.CV**, I.3.5; I.4.6; I.4.7; I.4.8; I.5.1; I.5.2; I.5.3; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1605.00961v2)
- **Published**: 2016-05-03 15:58:18+00:00
- **Updated**: 2016-05-05 09:57:41+00:00
- **Authors**: Olivier Guye
- **Comment**: 170 pages, 19 figures, research report
- **Journal**: None
- **Summary**: The described works have been carried out in the framework of a mid-term study initiated by the Centre Electronique de l'Armement and led by ADERSA, a French company of research under contract. The aim was to study the techniques of regular dividing of numerical data sets so as to provide tools for problem solving enabling to model multidimensional numerical objects and to be used in computer-aided design and manufacturing, in robotics, in image analysis and synthesis, in pattern recognition, in decision making, in cartography and numerical data base management. These tools are relying on the principle of regular hierarchical decomposition and led to the implementation of a multidimensional generalization of quaternary and octernary trees: the trees of order 2**k or 2**k-trees mapped in binary trees. This first tome, dedicated to the hierarchical modeling of multidimensional numerical data, describes the principles used for building, transforming, analyzing and recognizing patterns on which is relying the development of the associated algorithms. The whole so developed algorithms are detailed in pseudo-code at the end of this document. The present publication especially describes: - a building method adapted disordered and overcrowded data streams ; - its extension in inductive limits ; - the computation of the homographic transformation of a tree ; - the attribute calculus based on generalized moments and the provision of Eigen trees ; - perception procedures of objects without any covering in affine geometry ; - several supervised and unsupervised pattern recognition methods.



### Phase 2: DCL System Using Deep Learning Approaches for Land-based or Ship-based Real-Time Recognition and Localization of Marine Mammals - Machine Learning Detection Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1605.00972v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.00972v2)
- **Published**: 2016-05-03 16:36:30+00:00
- **Updated**: 2016-05-05 18:28:21+00:00
- **Authors**: Peter J. Dugan, Christopher W. Clark, Yann André LeCun, Sofie M. Van Parijs
- **Comment**: National Oceanic Partnership Program (NOPP) sponsored by ONR and
  NFWF: N000141210585
- **Journal**: None
- **Summary**: Overarching goals for this work aim to advance the state of the art for detection, classification and localization (DCL) in the field of bioacoustics. This goal is primarily achieved by building a generic framework for detection-classification (DC) using a fast, efficient and scalable architecture, demonstrating the capabilities of this system using on a variety of low-frequency mid-frequency cetacean sounds. Two primary goals are to develop transferable technologies for detection and classification in, one: the area of advanced algorithms, such as deep learning and other methods; and two: advanced systems, capable of real-time and archival processing. For each key area, we will focus on producing publications from this work and providing tools and software to the community where/when possible. Currently massive amounts of acoustic data are being collected by various institutions, corporations and national defense agencies. The long-term goal is to provide technical capability to analyze the data using automatic algorithms for (DC) based on machine intelligence. The goal of the automation is to provide effective and efficient mechanisms by which to process large acoustic datasets for understanding the bioacoustic behaviors of marine mammals. This capability will provide insights into the potential ecological impacts and influences of anthropogenic ocean sounds. This work focuses on building technologies using a maturity model based on DARPA 6.1 and 6.2 processes, for basic and applied research, respectively.



### Deep Deformation Network for Object Landmark Localization
- **Arxiv ID**: http://arxiv.org/abs/1605.01014v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.01014v2)
- **Published**: 2016-05-03 18:31:12+00:00
- **Updated**: 2016-07-24 06:46:58+00:00
- **Authors**: Xiang Yu, Feng Zhou, Manmohan Chandraker
- **Comment**: This work is going to appear at ECCV
- **Journal**: None
- **Summary**: We propose a novel cascaded framework, namely deep deformation network (DDN), for localizing landmarks in non-rigid objects. The hallmarks of DDN are its incorporation of geometric constraints within a convolutional neural network (CNN) framework, ease and efficiency of training, as well as generality of application. A novel shape basis network (SBN) forms the first stage of the cascade, whereby landmarks are initialized by combining the benefits of CNN features and a learned shape basis to reduce the complexity of the highly nonlinear pose manifold. In the second stage, a point transformer network (PTN) estimates local deformation parameterized as thin-plate spline transformation for a finer refinement. Our framework does not incorporate either handcrafted features or part connectivity, which enables an end-to-end shape prediction pipeline during both training and testing. In contrast to prior cascaded networks for landmark localization that learn a mapping from feature space to landmark locations, we demonstrate that the regularization induced through geometric priors in the DDN makes it easier to train, yet produces superior results. The efficacy and generality of the architecture is demonstrated through state-of-the-art performances on several benchmarks for multiple tasks such as facial landmark localization, human body pose estimation and bird part localization.



### Hierarchical Bayesian Noise Inference for Robust Real-time Probabilistic Object Classification
- **Arxiv ID**: http://arxiv.org/abs/1605.01042v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.01042v2)
- **Published**: 2016-05-03 19:42:18+00:00
- **Updated**: 2016-07-14 03:02:14+00:00
- **Authors**: Shayegan Omidshafiei, Brett T. Lopez, Jonathan P. How, John Vian
- **Comment**: None
- **Journal**: None
- **Summary**: Robust environment perception is essential for decision-making on robots operating in complex domains. Principled treatment of uncertainty sources in a robot's observation model is necessary for accurate mapping and object detection. This is important not only for low-level observations (e.g., accelerometer data), but for high-level observations such as semantic object labels as well. This paper presents an approach for filtering sequences of object classification probabilities using online modeling of the noise characteristics of the classifier outputs. A hierarchical Bayesian approach is used to model per-class noise distributions, while simultaneously allowing sharing of high-level noise characteristics between classes. The proposed filtering scheme, called Hierarchical Bayesian Noise Inference (HBNI), is shown to outperform classification accuracy of existing methods. The paper also presents real-time filtered classification hardware experiments running fully onboard a moving quadrotor, where the proposed approach is demonstrated to work in a challenging domain where noise-agnostic filtering fails.



### WEPSAM: Weakly Pre-Learnt Saliency Model
- **Arxiv ID**: http://arxiv.org/abs/1605.01101v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.01101v1)
- **Published**: 2016-05-03 21:47:33+00:00
- **Updated**: 2016-05-03 21:47:33+00:00
- **Authors**: Avisek Lahiri, Sourya Roy, Anirban Santara, Pabitra Mitra, Prabir Kumar Biswas
- **Comment**: None
- **Journal**: None
- **Summary**: Visual saliency detection tries to mimic human vision psychology which concentrates on sparse, important areas in natural image. Saliency prediction research has been traditionally based on low level features such as contrast, edge, etc. Recent thrust in saliency prediction research is to learn high level semantics using ground truth eye fixation datasets. In this paper we present, WEPSAM : Weakly Pre-Learnt Saliency Model as a pioneering effort of using domain specific pre-learing on ImageNet for saliency prediction using a light weight CNN architecture. The paper proposes a two step hierarchical learning, in which the first step is to develop a framework for weakly pre-training on a large scale dataset such as ImageNet which is void of human eye fixation maps. The second step refines the pre-trained model on a limited set of ground truth fixations. Analysis of loss on iSUN and SALICON datasets reveal that pre-trained network converges much faster compared to randomly initialized network. WEPSAM also outperforms some recent state-of-the-art saliency prediction models on the challenging MIT300 dataset.



### MARLow: A Joint Multiplanar Autoregressive and Low-Rank Approach for Image Completion
- **Arxiv ID**: http://arxiv.org/abs/1605.01115v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1605.01115v2)
- **Published**: 2016-05-03 23:41:57+00:00
- **Updated**: 2016-06-16 03:55:13+00:00
- **Authors**: Mading Li, Jiaying Liu, Zhiwei Xiong, Xiaoyan Sun, Zongming Guo
- **Comment**: 16 pages, 9 figures
- **Journal**: None
- **Summary**: In this paper, we propose a novel multiplanar autoregressive (AR) model to exploit the correlation in cross-dimensional planes of a similar patch group collected in an image, which has long been neglected by previous AR models. On that basis, we then present a joint multiplanar AR and low-rank based approach (MARLow) for image completion from random sampling, which exploits the nonlocal self-similarity within natural images more effectively. Specifically, the multiplanar AR model constraints the local stationarity in different cross-sections of the patch group, while the low-rank minimization captures the intrinsic coherence of nonlocal patches. The proposed approach can be readily extended to multichannel images (e.g. color images), by simultaneously considering the correlation in different channels. Experimental results demonstrate that the proposed approach significantly outperforms state-of-the-art methods, even if the pixel missing rate is as high as 90%.



