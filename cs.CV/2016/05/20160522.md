# Arxiv Papers in cs.CV on 2016-05-22
### A Rapid Pattern-Recognition Method for Driving Types Using Clustering-Based Support Vector Machines
- **Arxiv ID**: http://arxiv.org/abs/1605.06742v1
- **DOI**: 10.1109/ACC.2016.7526495
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1605.06742v1)
- **Published**: 2016-05-22 06:15:11+00:00
- **Updated**: 2016-05-22 06:15:11+00:00
- **Authors**: Wenshuo Wang, Junqiang Xi
- **Comment**: 6 pages, 9 figures, 2 tables. To be appear in 2016 American Control
  Conference, Boston, MA, USA, 2016
- **Journal**: 2017 American Control Conference
- **Summary**: A rapid pattern-recognition approach to characterize driver's curve-negotiating behavior is proposed. To shorten the recognition time and improve the recognition of driving styles, a k-means clustering-based support vector machine ( kMC-SVM) method is developed and used for classifying drivers into two types: aggressive and moderate. First, vehicle speed and throttle opening are treated as the feature parameters to reflect the driving styles. Second, to discriminate driver curve-negotiating behaviors and reduce the number of support vectors, the k-means clustering method is used to extract and gather the two types of driving data and shorten the recognition time. Then, based on the clustering results, a support vector machine approach is utilized to generate the hyperplane for judging and predicting to which types the human driver are subject. Lastly, to verify the validity of the kMC-SVM method, a cross-validation experiment is designed and conducted. The research results show that the $ k $MC-SVM is an effective method to classify driving styles with a short time, compared with SVM method.



### 3D Face Tracking and Texture Fusion in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1605.06764v1
- **DOI**: 10.1109/LSP.2016.2643284
- **Categories**: **cs.CV**, 68T45, I.4.8; I.4.9; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1605.06764v1)
- **Published**: 2016-05-22 09:52:16+00:00
- **Updated**: 2016-05-22 09:52:16+00:00
- **Authors**: Patrik Huber, Philipp Kopp, Matthias Rätsch, William Christmas, Josef Kittler
- **Comment**: None
- **Journal**: IEEE Signal Processing Letters (Volume: 24, Issue: 4, April 2017)
- **Summary**: We present a fully automatic approach to real-time 3D face reconstruction from monocular in-the-wild videos. With the use of a cascaded-regressor based face tracking and a 3D Morphable Face Model shape fitting, we obtain a semi-dense 3D face shape. We further use the texture information from multiple frames to build a holistic 3D face representation from the video frames. Our system is able to capture facial expressions and does not require any person-specific training. We demonstrate the robustness of our approach on the challenging 300 Videos in the Wild (300-VW) dataset. Our real-time fitting framework is available as an open source library at http://4dface.org.



### Sparse Signal Reconstruction with Multiple Side Information using Adaptive Weights for Multiview Sources
- **Arxiv ID**: http://arxiv.org/abs/1605.06776v1
- **DOI**: None
- **Categories**: **cs.CV**, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1605.06776v1)
- **Published**: 2016-05-22 12:00:34+00:00
- **Updated**: 2016-05-22 12:00:34+00:00
- **Authors**: Huynh Van Luong, Jürgen Seiler, André Kaup, Søren Forchhammer
- **Comment**: Submitted to the IEEE International Conference on Image Processing
  2016
- **Journal**: None
- **Summary**: This work considers reconstructing a target signal in a context of distributed sparse sources. We propose an efficient reconstruction algorithm with the aid of other given sources as multiple side information (SI). The proposed algorithm takes advantage of compressive sensing (CS) with SI and adaptive weights by solving a proposed weighted $n$-$\ell_{1}$ minimization. The proposed algorithm computes the adaptive weights in two levels, first each individual intra-SI and then inter-SI weights are iteratively updated at every reconstructed iteration. This two-level optimization leads the proposed reconstruction algorithm with multiple SI using adaptive weights (RAMSIA) to robustly exploit the multiple SIs with different qualities. We experimentally perform our algorithm on generated sparse signals and also correlated feature histograms as multiview sparse sources from a multiview image database. The results show that RAMSIA significantly outperforms both classical CS and CS with single SI, and RAMSIA with higher number of SIs gained more than the one with smaller number of SIs.



### openXBOW - Introducing the Passau Open-Source Crossmodal Bag-of-Words Toolkit
- **Arxiv ID**: http://arxiv.org/abs/1605.06778v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1605.06778v1)
- **Published**: 2016-05-22 12:14:55+00:00
- **Updated**: 2016-05-22 12:14:55+00:00
- **Authors**: Maximilian Schmitt, Björn W. Schuller
- **Comment**: 9 pages, 1 figure, pre-print
- **Journal**: None
- **Summary**: We introduce openXBOW, an open-source toolkit for the generation of bag-of-words (BoW) representations from multimodal input. In the BoW principle, word histograms were first used as features in document classification, but the idea was and can easily be adapted to, e.g., acoustic or visual low-level descriptors, introducing a prior step of vector quantisation. The openXBOW toolkit supports arbitrary numeric input features and text input and concatenates computed subbags to a final bag. It provides a variety of extensions and options. To our knowledge, openXBOW is the first publicly available toolkit for the generation of crossmodal bags-of-words. The capabilities of the tool are exemplified in two sample scenarios: time-continuous speech-based emotion recognition and sentiment analysis in tweets where improved results over other feature representation forms were observed.



### Automated Resolution Selection for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1605.06820v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.06820v1)
- **Published**: 2016-05-22 17:09:29+00:00
- **Updated**: 2016-05-22 17:09:29+00:00
- **Authors**: Fares Al-Qunaieer, Hamid R. Tizhoosh, Shahryar Rahnamayan
- **Comment**: None
- **Journal**: None
- **Summary**: It is well-known in image processing that computational cost increases rapidly with the number and dimensions of the images to be processed. Several fields, such as medical imaging, routinely use numerous very large images, which might also be 3D and/or captured at several frequency bands, all adding to the computational expense. Multiresolution analysis is a method of increasing the efficiency of the segmentation process. One multiresolution approach is the coarse-to-fine segmentation strategy, whereby the segmentation starts at a coarse resolution and is then fine-tuned during subsequent steps. The starting resolution for segmentation is generally selected arbitrarily with no clear selection criteria. The research reported in this paper showed that starting from different resolutions for image segmentation results in different accuracies and computational times, even for images of the same category (depicting similar scenes or objects). An automated method for resolution selection for an input image would thus be beneficial. This paper introduces a framework for the automated selection of the best resolution for image segmentation. We propose a measure for defining the best resolution based on user/system criteria, offering a trade-off between accuracy and computation time. A learning approach is then introduced for the selection of the resolution, whereby extracted image features are mapped to the previously determined best resolution. In the learning process, class (i.e., resolution) distribution is generally imbalanced, making effective learning from the data difficult. Experiments conducted with three datasets using two different segmentation algorithms show that the resolutions selected through learning enable much faster segmentation than the original ones, while retaining at least the original accuracy.



### Self-expressive Dictionary Learning for Dynamic 3D Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1605.06863v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.06863v1)
- **Published**: 2016-05-22 23:56:34+00:00
- **Updated**: 2016-05-22 23:56:34+00:00
- **Authors**: Enliang Zheng, Dinghuang Ji, Enrique Dunn, Jan-Michael Frahm
- **Comment**: 15 pages, journal
- **Journal**: None
- **Summary**: We target the problem of sparse 3D reconstruction of dynamic objects observed by multiple unsynchronized video cameras with unknown temporal overlap. To this end, we develop a framework to recover the unknown structure without sequencing information across video sequences. Our proposed compressed sensing framework poses the estimation of 3D structure as the problem of dictionary learning, where the dictionary is defined as an aggregation of the temporally varying 3D structures. Given the smooth motion of dynamic objects, we observe any element in the dictionary can be well approximated by a sparse linear combination of other elements in the same dictionary (i. e. self-expression). Moreover, the sparse coefficients describing a locally linear 3D structural interpolation reveal the local sequencing information. Our formulation optimizes a biconvex cost function that leverages a compressed sensing formulation and enforces both structural dependency coherence across video streams, as well as motion smoothness across estimates from common video sources. We further analyze the reconstructability of our approach under different capture scenarios, and its comparison and relation to existing methods. Experimental results on large amounts of synthetic data as well as real imagery demonstrate the effectiveness of our approach.



