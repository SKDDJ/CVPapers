# Arxiv Papers in cs.CV on 2016-05-10
### When Do Luxury Cars Hit the Road? Findings by A Big Data Approach
- **Arxiv ID**: http://arxiv.org/abs/1605.02827v2
- **DOI**: None
- **Categories**: **cs.CY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1605.02827v2)
- **Published**: 2016-05-10 02:54:39+00:00
- **Updated**: 2016-05-11 16:29:38+00:00
- **Authors**: Yang Feng, Jiebo Luo
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we focus on studying the appearing time of different kinds of cars on the road. This information will enable us to infer the life style of the car owners. The results can further be used to guide marketing towards car owners. Conventionally, this kind of study is carried out by sending out questionnaires, which is limited in scale and diversity. To solve this problem, we propose a fully automatic method to carry out this study. Our study is based on publicly available surveillance camera data. To make the results reliable, we only use the high resolution cameras (i.e. resolution greater than $1280 \times 720$). Images from the public cameras are downloaded every minute. After obtaining 50,000 images, we apply faster R-CNN (region-based convoluntional neural network) to detect the cars in the downloaded images and a fine-tuned VGG16 model is used to recognize the car makes. Based on the recognition results, we present a data-driven analysis on the relationship between car makes and their appearing times, with implications on lifestyles.



### Compact Hash Codes for Efficient Visual Descriptors Retrieval in Large Scale Databases
- **Arxiv ID**: http://arxiv.org/abs/1605.02892v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.02892v1)
- **Published**: 2016-05-10 08:53:04+00:00
- **Updated**: 2016-05-10 08:53:04+00:00
- **Authors**: Simone Ercoli, Marco Bertini, Alberto Del Bimbo
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present an efficient method for visual descriptors retrieval based on compact hash codes computed using a multiple k-means assignment. The method has been applied to the problem of approximate nearest neighbor (ANN) search of local and global visual content descriptors, and it has been tested on different datasets: three large scale public datasets of up to one billion descriptors (BIGANN) and, supported by recent progress in convolutional neural networks (CNNs), also on the CIFAR-10 and MNIST datasets. Experimental results show that, despite its simplicity, the proposed method obtains a very high performance that makes it superior to more complex state-of-the-art methods.



### Recurrent Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1605.02914v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1605.02914v3)
- **Published**: 2016-05-10 09:58:11+00:00
- **Updated**: 2017-08-05 11:56:51+00:00
- **Authors**: Vasileios Belagiannis, Andrew Zisserman
- **Comment**: FG 2017, More Info and Demo:
  http://www.robots.ox.ac.uk/~vgg/software/keypoint_detection/
- **Journal**: None
- **Summary**: We propose a novel ConvNet model for predicting 2D human body poses in an image. The model regresses a heatmap representation for each body keypoint, and is able to learn and represent both the part appearances and the context of the part configuration. We make the following three contributions: (i) an architecture combining a feed forward module with a recurrent module, where the recurrent module can be run iteratively to improve the performance, (ii) the model can be trained end-to-end and from scratch, with auxiliary losses incorporated to improve performance, (iii) we investigate whether keypoint visibility can also be predicted. The model is evaluated on two benchmark datasets. The result is a simple architecture that achieves performance on par with the state of the art, but without the complexity of a graphical model stage (or layers).



### Weakly Supervised Learning of Affordances
- **Arxiv ID**: http://arxiv.org/abs/1605.02964v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.02964v2)
- **Published**: 2016-05-10 12:04:07+00:00
- **Updated**: 2016-07-29 13:46:59+00:00
- **Authors**: Abhilash Srikantha, Juergen Gall
- **Comment**: None
- **Journal**: None
- **Summary**: Localizing functional regions of objects or affordances is an important aspect of scene understanding. In this work, we cast the problem of affordance segmentation as that of semantic image segmentation. In order to explore various levels of supervision, we introduce a pixel-annotated affordance dataset of 3090 images containing 9916 object instances with rich contextual information in terms of human-object interactions. We use a deep convolutional neural network within an expectation maximization framework to take advantage of weakly labeled data like image level annotations or keypoint annotations. We show that a further reduction in supervision is possible with a minimal loss in performance when human pose is used as context.



### Structured Receptive Fields in CNNs
- **Arxiv ID**: http://arxiv.org/abs/1605.02971v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.02971v2)
- **Published**: 2016-05-10 12:18:03+00:00
- **Updated**: 2016-05-13 11:56:08+00:00
- **Authors**: JÃ¶rn-Henrik Jacobsen, Jan van Gemert, Zhongyu Lou, Arnold W. M. Smeulders
- **Comment**: Reason for update: i) Fix Reference for "Deep roto-translation
  scattering for object classification" by Oyallon and Mallat. ii) Fixed two
  minor typos. iii) Removed implicit assumption in equation (4) where scale is
  represented with diffusion time and adapted to rest of paper where scale is
  represented with standard deviation, to avoid possible confusion
- **Journal**: None
- **Summary**: Learning powerful feature representations with CNNs is hard when training data are limited. Pre-training is one way to overcome this, but it requires large datasets sufficiently similar to the target domain. Another option is to design priors into the model, which can range from tuned hyperparameters to fully engineered representations like Scattering Networks. We combine these ideas into structured receptive field networks, a model which has a fixed filter basis and yet retains the flexibility of CNNs. This flexibility is achieved by expressing receptive fields in CNNs as a weighted sum over a fixed basis which is similar in spirit to Scattering Networks. The key difference is that we learn arbitrary effective filter sets from the basis rather than modeling the filters. This approach explicitly connects classical multiscale image analysis with general CNNs. With structured receptive field networks, we improve considerably over unstructured CNNs for small and medium dataset scenarios as well as over Scattering for large datasets. We validate our findings on ILSVRC2012, Cifar-10, Cifar-100 and MNIST. As a realistic small dataset example, we show state-of-the-art classification results on popular 3D MRI brain-disease datasets where pre-training is difficult due to a lack of large public datasets in a similar domain.



### Automatic 3D liver location and segmentation via convolutional neural networks and graph cut
- **Arxiv ID**: http://arxiv.org/abs/1605.03012v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.03012v1)
- **Published**: 2016-05-10 13:42:51+00:00
- **Updated**: 2016-05-10 13:42:51+00:00
- **Authors**: Fang Lu, Fa Wu, Peijun Hu, Zhiyi Peng, Dexing Kong
- **Comment**: 12 pages, 12 figures, 4 tables
- **Journal**: None
- **Summary**: Purpose Segmentation of the liver from abdominal computed tomography (CT) image is an essential step in some computer assisted clinical interventions, such as surgery planning for living donor liver transplant (LDLT), radiotherapy and volume measurement. In this work, we develop a deep learning algorithm with graph cut refinement to automatically segment liver in CT scans. Methods The proposed method consists of two main steps: (i) simultaneously liver detection and probabilistic segmentation using 3D convolutional neural networks (CNNs); (ii) accuracy refinement of initial segmentation with graph cut and the previously learned probability map. Results The proposed approach was validated on forty CT volumes taken from two public databases MICCAI-Sliver07 and 3Dircadb. For the MICCAI-Sliver07 test set, the calculated mean ratios of volumetric overlap error (VOE), relative volume difference (RVD), average symmetric surface distance (ASD), root mean square symmetric surface distance (RMSD) and maximum symmetric surface distance (MSD) are 5.9%, 2.7%, 0.91%, 1.88 mm, and 18.94 mm, respectively. In the case of 20 3Dircadb data, the calculated mean ratios of VOE, RVD, ASD, RMSD and MSD are 9.36%, 0.97%, 1.89%, 4.15 mm and 33.14 mm, respectively. Conclusion The proposed method is fully automatic without any user interaction. Quantitative results reveal that the proposed approach is efficient and accurate for hepatic volume estimation in a clinical setup. The high correlation between the automatic and manual references shows that the proposed method can be good enough to replace the time-consuming and non-reproducible manual segmentation method.



### PARAPH: Presentation Attack Rejection by Analyzing Polarization Hypotheses
- **Arxiv ID**: http://arxiv.org/abs/1605.03124v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.03124v1)
- **Published**: 2016-05-10 17:46:59+00:00
- **Updated**: 2016-05-10 17:46:59+00:00
- **Authors**: Ethan M. Rudd, Manuel Gunther, Terrance E. Boult
- **Comment**: Accepted to CVPR 2016 Biometrics Workshop
- **Journal**: None
- **Summary**: For applications such as airport border control, biometric technologies that can process many capture subjects quickly, efficiently, with weak supervision, and with minimal discomfort are desirable. Facial recognition is particularly appealing because it is minimally invasive yet offers relatively good recognition performance. Unfortunately, the combination of weak supervision and minimal invasiveness makes even highly accurate facial recognition systems susceptible to spoofing via presentation attacks. Thus, there is great demand for an effective and low cost system capable of rejecting such attacks.To this end we introduce PARAPH -- a novel hardware extension that exploits different measurements of light polarization to yield an image space in which presentation media are readily discernible from Bona Fide facial characteristics. The PARAPH system is inexpensive with an added cost of less than 10 US dollars. The system makes two polarization measurements in rapid succession, allowing them to be approximately pixel-aligned, with a frame rate limited by the camera, not the system. There are no moving parts above the molecular level, due to the efficient use of twisted nematic liquid crystals. We present evaluation images using three presentation attack media next to an actual face -- high quality photos on glossy and matte paper and a video of the face on an LCD. In each case, the actual face in the image generated by PARAPH is structurally discernible from the presentations, which appear either as noise (print attacks) or saturated images (replay attacks).



### Road Detection through Supervised Classification
- **Arxiv ID**: http://arxiv.org/abs/1605.03150v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.03150v1)
- **Published**: 2016-05-10 18:53:09+00:00
- **Updated**: 2016-05-10 18:53:09+00:00
- **Authors**: Yasamin Alkhorshid, Kamelia Aryafar, Sven Bauer, Gerd Wanielik
- **Comment**: None
- **Journal**: None
- **Summary**: Autonomous driving is a rapidly evolving technology. Autonomous vehicles are capable of sensing their environment and navigating without human input through sensory information such as radar, lidar, GNSS, vehicle odometry, and computer vision. This sensory input provides a rich dataset that can be used in combination with machine learning models to tackle multiple problems in supervised settings. In this paper we focus on road detection through gray-scale images as the sole sensory input. Our contributions are twofold: first, we introduce an annotated dataset of urban roads for machine learning tasks; second, we introduce a road detection framework on this dataset through supervised classification and hand-crafted feature vectors.



### DeeperCut: A Deeper, Stronger, and Faster Multi-Person Pose Estimation Model
- **Arxiv ID**: http://arxiv.org/abs/1605.03170v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.03170v3)
- **Published**: 2016-05-10 19:49:40+00:00
- **Updated**: 2016-11-30 19:03:17+00:00
- **Authors**: Eldar Insafutdinov, Leonid Pishchulin, Bjoern Andres, Mykhaylo Andriluka, Bernt Schiele
- **Comment**: ECCV'16. High-res version at
  https://www.d2.mpi-inf.mpg.de/sites/default/files/insafutdinov16arxiv.pdf
- **Journal**: None
- **Summary**: The goal of this paper is to advance the state-of-the-art of articulated pose estimation in scenes with multiple people. To that end we contribute on three fronts. We propose (1) improved body part detectors that generate effective bottom-up proposals for body parts; (2) novel image-conditioned pairwise terms that allow to assemble the proposals into a variable number of consistent body part configurations; and (3) an incremental optimization strategy that explores the search space more efficiently thus leading both to better performance and significant speed-up factors. Evaluation is done on two single-person and two multi-person pose estimation benchmarks. The proposed approach significantly outperforms best known multi-person pose estimation results while demonstrating competitive performance on the task of single person pose estimation. Models and code available at http://pose.mpi-inf.mpg.de



### Action Recognition in Video Using Sparse Coding and Relative Features
- **Arxiv ID**: http://arxiv.org/abs/1605.03222v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.03222v1)
- **Published**: 2016-05-10 21:52:25+00:00
- **Updated**: 2016-05-10 21:52:25+00:00
- **Authors**: Anali Alfaro, Domingo Mery, Alvaro Soto
- **Comment**: Accepted to CVPR 2016
- **Journal**: None
- **Summary**: This work presents an approach to category-based action recognition in video using sparse coding techniques. The proposed approach includes two main contributions: i) A new method to handle intra-class variations by decomposing each video into a reduced set of representative atomic action acts or key-sequences, and ii) A new video descriptor, ITRA: Inter-Temporal Relational Act Descriptor, that exploits the power of comparative reasoning to capture relative similarity relations among key-sequences. In terms of the method to obtain key-sequences, we introduce a loss function that, for each video, leads to the identification of a sparse set of representative key-frames capturing both, relevant particularities arising in the input video, as well as relevant generalities arising in the complete class collection. In terms of the method to obtain the ITRA descriptor, we introduce a novel scheme to quantify relative intra and inter-class similarities among local temporal patterns arising in the videos. The resulting ITRA descriptor demonstrates to be highly effective to discriminate among action categories. As a result, the proposed approach reaches remarkable action recognition performance on several popular benchmark datasets, outperforming alternative state-of-the-art techniques by a large margin.



### Measurement Bounds for Sparse Signal Reconstruction with Multiple Side Information
- **Arxiv ID**: http://arxiv.org/abs/1605.03234v2
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, math.IT, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1605.03234v2)
- **Published**: 2016-05-10 22:48:14+00:00
- **Updated**: 2017-01-18 10:20:35+00:00
- **Authors**: Huynh Van Luong, Jurgen Seiler, Andre Kaup, Soren Forchhammer, Nikos Deligiannis
- **Comment**: submitted to a journal
- **Journal**: None
- **Summary**: In the context of compressed sensing (CS), this paper considers the problem of reconstructing sparse signals with the aid of other given correlated sources as multiple side information. To address this problem, we theoretically study a generic \textcolor{black}{weighted $n$-$\ell_{1}$ minimization} framework and propose a reconstruction algorithm that leverages multiple side information signals (RAMSI). The proposed RAMSI algorithm computes adaptively optimal weights among the side information signals at every reconstruction iteration. In addition, we establish theoretical bounds on the number of measurements that are required to successfully reconstruct the sparse source by using \textcolor{black}{weighted $n$-$\ell_{1}$ minimization}. The analysis of the established bounds reveal that \textcolor{black}{weighted $n$-$\ell_{1}$ minimization} can achieve sharper bounds and significant performance improvements compared to classical CS. We evaluate experimentally the proposed RAMSI algorithm and the established bounds using synthetic sparse signals as well as correlated feature histograms, extracted from a multiview image database for object recognition. The obtained results show clearly that the proposed algorithm outperforms state-of-the-art algorithms---\textcolor{black}{including classical CS, $\ell_1\text{-}\ell_1$ minimization, Modified-CS, regularized Modified-CS, and weighted $\ell_1$ minimization}---in terms of both the theoretical bounds and the practical performance.



