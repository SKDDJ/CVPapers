# Arxiv Papers in cs.CV on 2016-05-14
### Neural Dataset Generality
- **Arxiv ID**: http://arxiv.org/abs/1605.04369v1
- **DOI**: 10.1109/ICIP.2016.7532315
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04369v1)
- **Published**: 2016-05-14 03:17:15+00:00
- **Updated**: 2016-05-14 03:17:15+00:00
- **Authors**: Ragav Venkatesan, Vijetha Gattupalli, Baoxin Li
- **Comment**: Long version of the paper accepted at IEEE International Conference
  on Image Processing 2016
- **Journal**: None
- **Summary**: Often the filters learned by Convolutional Neural Networks (CNNs) from different datasets appear similar. This is prominent in the first few layers. This similarity of filters is being exploited for the purposes of transfer learning and some studies have been made to analyse such transferability of features. This is also being used as an initialization technique for different tasks in the same dataset or for the same task in similar datasets. Off-the-shelf CNN features have capitalized on this idea to promote their networks as best transferable and most general and are used in a cavalier manner in day-to-day computer vision tasks.   It is curious that while the filters learned by these CNNs are related to the atomic structures of the images from which they are learnt, all datasets learn similar looking low-level filters. With the understanding that a dataset that contains many such atomic structures learn general filters and are therefore useful to initialize other networks with, we propose a way to analyse and quantify generality among datasets from their accuracies on transferred filters. We applied this metric on several popular character recognition, natural image and a medical image dataset, and arrived at some interesting conclusions. On further experimentation we also discovered that particular classes in a dataset themselves are more general than others.



### Gabor Barcodes for Medical Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1605.04478v1
- **DOI**: 10.1109/ICIP.2016.7532807
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04478v1)
- **Published**: 2016-05-14 22:39:29+00:00
- **Updated**: 2016-05-14 22:39:29+00:00
- **Authors**: Mina Nouredanesh, Hamid R. Tizhoosh, Ershad Banijamali
- **Comment**: To appear in proceedings of The 2016 IEEE International Conference on
  Image Processing (ICIP 2016), Sep 25-28, 2016, Phoenix, Arizona, USA
- **Journal**: None
- **Summary**: In recent years, advances in medical imaging have led to the emergence of massive databases, containing images from a diverse range of modalities. This has significantly heightened the need for automated annotation of the images on one side, and fast and memory-efficient content-based image retrieval systems on the other side. Binary descriptors have recently gained more attention as a potential vehicle to achieve these goals. One of the recently introduced binary descriptors for tagging of medical images are Radon barcodes (RBCs) that are driven from Radon transform via local thresholding. Gabor transform is also a powerful transform to extract texture-based information. Gabor features have exhibited robustness against rotation, scale, and also photometric disturbances, such as illumination changes and image noise in many applications. This paper introduces Gabor Barcodes (GBCs), as a novel framework for the image annotation. To find the most discriminative GBC for a given query image, the effects of employing Gabor filters with different parameters, i.e., different sets of scales and orientations, are investigated, resulting in different barcode lengths and retrieval performances. The proposed method has been evaluated on the IRMA dataset with 193 classes comprising of 12,677 x-ray images for indexing, and 1,733 x-rays images for testing. A total error score as low as $351$ ($\approx 80\%$ accuracy for the first hit) was achieved.



