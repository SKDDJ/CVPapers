# Arxiv Papers in cs.CV on 2016-05-15
### Joint Learning of Siamese CNNs and Temporally Constrained Metrics for Tracklet Association
- **Arxiv ID**: http://arxiv.org/abs/1605.04502v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04502v2)
- **Published**: 2016-05-15 07:09:28+00:00
- **Updated**: 2016-09-25 09:58:32+00:00
- **Authors**: Bing Wang, Li Wang, Bing Shuai, Zhen Zuo, Ting Liu, Kap Luk Chan, Gang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we study the challenging problem of multi-object tracking in a complex scene captured by a single camera. Different from the existing tracklet association-based tracking methods, we propose a novel and efficient way to obtain discriminative appearance-based tracklet affinity models. Our proposed method jointly learns the convolutional neural networks (CNNs) and temporally constrained metrics. In our method, a Siamese convolutional neural network (CNN) is first pre-trained on the auxiliary data. Then the Siamese CNN and temporally constrained metrics are jointly learned online to construct the appearance-based tracklet affinity models. The proposed method can jointly learn the hierarchical deep features and temporally constrained segment-wise metrics under a unified framework. For reliable association between tracklets, a novel loss function incorporating temporally constrained multi-task learning mechanism is proposed. By employing the proposed method, tracklet association can be accomplished even in challenging situations. Moreover, a new dataset with 40 fully annotated sequences is created to facilitate the tracking evaluation. Experimental results on five public datasets and the new large-scale dataset show that our method outperforms several state-of-the-art approaches in multi-object tracking.



### Improving the Neural Algorithm of Artistic Style
- **Arxiv ID**: http://arxiv.org/abs/1605.04603v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1605.04603v1)
- **Published**: 2016-05-15 20:11:27+00:00
- **Updated**: 2016-05-15 20:11:27+00:00
- **Authors**: Roman Novak, Yaroslav Nikulin
- **Comment**: A short class project report (15 pages)
- **Journal**: None
- **Summary**: In this work we investigate different avenues of improving the Neural Algorithm of Artistic Style (by Leon A. Gatys, Alexander S. Ecker and Matthias Bethge, arXiv:1508.06576).   While showing great results when transferring homogeneous and repetitive patterns, the original style representation often fails to capture more complex properties, like having separate styles of foreground and background. This leads to visual artifacts and undesirable textures appearing in unexpected regions when performing style transfer.   We tackle this issue with a variety of approaches, mostly by modifying the style representation in order for it to capture more information and impose a tighter constraint on the style transfer result.   In our experiments, we subjectively evaluate our best method as producing from barely noticeable to significant improvements in the quality of style transfer.



