# Arxiv Papers in cs.CV on 2016-03-01
### Robust Multi-body Feature Tracker: A Segmentation-free Approach
- **Arxiv ID**: http://arxiv.org/abs/1603.00110v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00110v2)
- **Published**: 2016-03-01 01:46:44+00:00
- **Updated**: 2016-03-15 03:03:52+00:00
- **Authors**: Pan Ji, Hongdong Li, Mathieu Salzmann, Yiran Zhong
- **Comment**: None
- **Journal**: None
- **Summary**: Feature tracking is a fundamental problem in computer vision, with applications in many computer vision tasks, such as visual SLAM and action recognition. This paper introduces a novel multi-body feature tracker that exploits a multi-body rigidity assumption to improve tracking robustness under a general perspective camera model. A conventional approach to addressing this problem would consist of alternating between solving two subtasks: motion segmentation and feature tracking under rigidity constraints for each segment. This approach, however, requires knowing the number of motions, as well as assigning points to motion groups, which is typically sensitive to the motion estimates. By contrast, here, we introduce a segmentation-free solution to multi-body feature tracking that bypasses the motion assignment step and reduces to solving a series of subproblems with closed-form solutions. Our experiments demonstrate the benefits of our approach in terms of tracking accuracy and robustness to noise.



### Learning Multilayer Channel Features for Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1603.00124v1
- **DOI**: 10.1109/TIP.2017.2694224
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00124v1)
- **Published**: 2016-03-01 03:25:45+00:00
- **Updated**: 2016-03-01 03:25:45+00:00
- **Authors**: Jiale Cao, Yanwei Pang, Xuelong Li
- **Comment**: None
- **Journal**: None
- **Summary**: Pedestrian detection based on the combination of Convolutional Neural Network (i.e., CNN) and traditional handcrafted features (i.e., HOG+LUV) has achieved great success. Generally, HOG+LUV are used to generate the candidate proposals and then CNN classifies these proposals. Despite its success, there is still room for improvement. For example, CNN classifies these proposals by the full-connected layer features while proposal scores and the features in the inner-layers of CNN are ignored. In this paper, we propose a unifying framework called Multilayer Channel Features (MCF) to overcome the drawback. It firstly integrates HOG+LUV with each layer of CNN into a multi-layer image channels. Based on the multi-layer image channels, a multi-stage cascade AdaBoost is then learned. The weak classifiers in each stage of the multi-stage cascade is learned from the image channels of corresponding layer. With more abundant features, MCF achieves the state-of-the-art on Caltech pedestrian dataset (i.e., 10.40% miss rate). Using new and accurate annotations, MCF achieves 7.98% miss rate. As many non-pedestrian detection windows can be quickly rejected by the first few stages, it accelerates detection speed by 1.43 times. By eliminating the highly overlapped detection windows with lower scores after the first stage, it's 4.07 times faster with negligible performance loss.



### Cascaded Subpatch Networks for Effective CNNs
- **Arxiv ID**: http://arxiv.org/abs/1603.00128v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00128v1)
- **Published**: 2016-03-01 03:44:49+00:00
- **Updated**: 2016-03-01 03:44:49+00:00
- **Authors**: Xiaoheng Jiang, Yanwei Pang, Manli Sun, Xuelong Li
- **Comment**: None
- **Journal**: None
- **Summary**: Conventional Convolutional Neural Networks (CNNs) use either a linear or non-linear filter to extract features from an image patch (region) of spatial size $ H\times W $ (Typically, $ H $ is small and is equal to $ W$, e.g., $ H $ is 5 or 7). Generally, the size of the filter is equal to the size $ H\times W $ of the input patch. We argue that the representation ability of equal-size strategy is not strong enough. To overcome the drawback, we propose to use subpatch filter whose spatial size $ h\times w $ is smaller than $ H\times W $. The proposed subpatch filter consists of two subsequent filters. The first one is a linear filter of spatial size $ h\times w $ and is aimed at extracting features from spatial domain. The second one is of spatial size $ 1\times 1 $ and is used for strengthening the connection between different input feature channels and for reducing the number of parameters. The subpatch filter convolves with the input patch and the resulting network is called a subpatch network. Taking the output of one subpatch network as input, we further repeat constructing subpatch networks until the output contains only one neuron in spatial domain. These subpatch networks form a new network called Cascaded Subpatch Network (CSNet). The feature layer generated by CSNet is called csconv layer. For the whole input image, we construct a deep neural network by stacking a sequence of csconv layers. Experimental results on four benchmark datasets demonstrate the effectiveness and compactness of the proposed CSNet. For example, our CSNet reaches a test error of $ 5.68\% $ on the CIFAR10 dataset without model averaging. To the best of our knowledge, this is the best result ever obtained on the CIFAR10 dataset.



### A Universal Update-pacing Framework For Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1603.00132v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00132v1)
- **Published**: 2016-03-01 04:12:41+00:00
- **Updated**: 2016-03-01 04:12:41+00:00
- **Authors**: Zexi Hu, Yuefang Gao, Dong Wang, Xuhong Tian
- **Comment**: Submitted to ICIP 2016
- **Journal**: None
- **Summary**: This paper proposes a novel framework to alleviate the model drift problem in visual tracking, which is based on paced updates and trajectory selection. Given a base tracker, an ensemble of trackers is generated, in which each tracker's update behavior will be paced and then traces the target object forward and backward to generate a pair of trajectories in an interval. Then, we implicitly perform self-examination based on trajectory pair of each tracker and select the most robust tracker. The proposed framework can effectively leverage temporal context of sequential frames and avoid to learn corrupted information. Extensive experiments on the standard benchmark suggest that the proposed framework achieves superior performance against state-of-the-art trackers.



### Storm Detection by Visual Learning Using Satellite Images
- **Arxiv ID**: http://arxiv.org/abs/1603.00146v1
- **DOI**: 10.1109/TGRS.2016.2618929
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00146v1)
- **Published**: 2016-03-01 05:26:59+00:00
- **Updated**: 2016-03-01 05:26:59+00:00
- **Authors**: Yu Zhang, Stephen Wistar, Jia Li, Michael Steinberg, James Z. Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Computers are widely utilized in today's weather forecasting as a powerful tool to leverage an enormous amount of data. Yet, despite the availability of such data, current techniques often fall short of producing reliable detailed storm forecasts. Each year severe thunderstorms cause significant damage and loss of life, some of which could be avoided if better forecasts were available. We propose a computer algorithm that analyzes satellite images from historical archives to locate visual signatures of severe thunderstorms for short-term predictions. While computers are involved in weather forecasts to solve numerical models based on sensory data, they are less competent in forecasting based on visual patterns from satellite images. In our system, we extract and summarize important visual storm evidence from satellite image sequences in the way that meteorologists interpret the images. In particular, the algorithm extracts and fits local cloud motion from image sequences to model the storm-related cloud patches. Image data from the year 2008 have been adopted to train the model, and historical thunderstorm reports in continental US from 2000 through 2013 have been used as the ground-truth and priors in the modeling process. Experiments demonstrate the usefulness and potential of the algorithm for producing more accurate thunderstorm forecasts.



### GOGMA: Globally-Optimal Gaussian Mixture Alignment
- **Arxiv ID**: http://arxiv.org/abs/1603.00150v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1603.00150v1)
- **Published**: 2016-03-01 05:38:50+00:00
- **Updated**: 2016-03-01 05:38:50+00:00
- **Authors**: Dylan Campbell, Lars Petersson
- **Comment**: Manuscript in press 2016 IEEE Conference on Computer Vision and
  Pattern Recognition
- **Journal**: None
- **Summary**: Gaussian mixture alignment is a family of approaches that are frequently used for robustly solving the point-set registration problem. However, since they use local optimisation, they are susceptible to local minima and can only guarantee local optimality. Consequently, their accuracy is strongly dependent on the quality of the initialisation. This paper presents the first globally-optimal solution to the 3D rigid Gaussian mixture alignment problem under the L2 distance between mixtures. The algorithm, named GOGMA, employs a branch-and-bound approach to search the space of 3D rigid motions SE(3), guaranteeing global optimality regardless of the initialisation. The geometry of SE(3) was used to find novel upper and lower bounds for the objective function and local optimisation was integrated into the scheme to accelerate convergence without voiding the optimality guarantee. The evaluation empirically supported the optimality proof and showed that the method performed much more robustly on two challenging datasets than an existing globally-optimal registration solution.



### Pattern recognition on the quantum Bloch sphere
- **Arxiv ID**: http://arxiv.org/abs/1603.00173v2
- **DOI**: 10.1007/s00500-016-2478-2
- **Categories**: **quant-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1603.00173v2)
- **Published**: 2016-03-01 08:11:53+00:00
- **Updated**: 2016-06-07 09:46:24+00:00
- **Authors**: Giuseppe Sergioli, Enrica Santucci, Luca Didaci, Jaroslaw A. Miszczak, Roberto Giuntini
- **Comment**: None
- **Journal**: Soft Comput (2017)
- **Summary**: We introduce a framework suitable for describing pattern recognition task using the mathematical language of density matrices. In particular, we provide a one-to-one correspondence between patterns and pure density operators. This correspondence enables us to: i) represent the Nearest Mean Classifier (NMC) in terms of quantum objects, ii) introduce a Quantum Classifier (QC). By comparing the QC with the NMC on different 2D datasets, we show the first classifier can provide additional information that are particularly beneficial on a classical computer with respect to the second classifier.



### Gland Segmentation in Colon Histology Images: The GlaS Challenge Contest
- **Arxiv ID**: http://arxiv.org/abs/1603.00275v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00275v2)
- **Published**: 2016-03-01 13:53:48+00:00
- **Updated**: 2016-09-01 14:18:51+00:00
- **Authors**: Korsuk Sirinukunwattana, Josien P. W. Pluim, Hao Chen, Xiaojuan Qi, Pheng-Ann Heng, Yun Bo Guo, Li Yang Wang, Bogdan J. Matuszewski, Elia Bruni, Urko Sanchez, Anton Böhm, Olaf Ronneberger, Bassem Ben Cheikh, Daniel Racoceanu, Philipp Kainz, Michael Pfeiffer, Martin Urschler, David R. J. Snead, Nasir M. Rajpoot
- **Comment**: None
- **Journal**: None
- **Summary**: Colorectal adenocarcinoma originating in intestinal glandular structures is the most common form of colon cancer. In clinical practice, the morphology of intestinal glands, including architectural appearance and glandular formation, is used by pathologists to inform prognosis and plan the treatment of individual patients. However, achieving good inter-observer as well as intra-observer reproducibility of cancer grading is still a major challenge in modern pathology. An automated approach which quantifies the morphology of glands is a solution to the problem. This paper provides an overview to the Gland Segmentation in Colon Histology Images Challenge Contest (GlaS) held at MICCAI'2015. Details of the challenge, including organization, dataset and evaluation criteria, are presented, along with the method descriptions and evaluation results from the top performing methods.



### Dual Smoothing and Level Set Techniques for Variational Matrix Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1603.00284v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, math.OC, 90C06, 81P50, 65K10, 62F35, 47N30
- **Links**: [PDF](http://arxiv.org/pdf/1603.00284v1)
- **Published**: 2016-03-01 14:33:12+00:00
- **Updated**: 2016-03-01 14:33:12+00:00
- **Authors**: Aleksandr Y. Aravkin, Stephen Becker
- **Comment**: 38 pages, 10 figures. arXiv admin note: text overlap with
  arXiv:1406.1089
- **Journal**: None
- **Summary**: We focus on the robust principal component analysis (RPCA) problem, and review a range of old and new convex formulations for the problem and its variants. We then review dual smoothing and level set techniques in convex optimization, present several novel theoretical results, and apply the techniques on the RPCA problem. In the final sections, we show a range of numerical experiments for simulated and real-world problems.



### Scalable Metric Learning via Weighted Approximate Rank Component Analysis
- **Arxiv ID**: http://arxiv.org/abs/1603.00370v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00370v2)
- **Published**: 2016-03-01 17:32:09+00:00
- **Updated**: 2016-03-23 14:56:19+00:00
- **Authors**: Cijo Jose, Francois Fleuret
- **Comment**: None
- **Journal**: None
- **Summary**: We are interested in the large-scale learning of Mahalanobis distances, with a particular focus on person re-identification.   We propose a metric learning formulation called Weighted Approximate Rank Component Analysis (WARCA). WARCA optimizes the precision at top ranks by combining the WARP loss with a regularizer that favors orthonormal linear mappings, and avoids rank-deficient embeddings. Using this new regularizer allows us to adapt the large-scale WSABIE procedure and to leverage the Adam stochastic optimization algorithm, which results in an algorithm that scales gracefully to very large data-sets. Also, we derive a kernelized version which allows to take advantage of state-of-the-art features for re-identification when data-set size permits kernel computation.   Benchmarks on recent and standard re-identification data-sets show that our method beats existing state-of-the-art techniques both in term of accuracy and speed. We also provide experimental analysis to shade lights on the properties of the regularizer we use, and how it improves performance.



### Technical Report: Band selection for nonlinear unmixing of hyperspectral images as a maximal clique problem
- **Arxiv ID**: http://arxiv.org/abs/1603.00437v2
- **DOI**: 10.1109/TIP.2017.2676344
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00437v2)
- **Published**: 2016-03-01 20:08:51+00:00
- **Updated**: 2016-09-19 22:53:26+00:00
- **Authors**: Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard
- **Comment**: None
- **Journal**: None
- **Summary**: Kernel-based nonlinear mixing models have been applied to unmix spectral information of hyperspectral images when the type of mixing occurring in the scene is too complex or unknown. Such methods, however, usually require the inversion of matrices of sizes equal to the number of spectral bands. Reducing the computational load of these methods remains a challenge in large scale applications. This paper proposes a centralized method for band selection (BS) in the reproducing kernel Hilbert space (RKHS). It is based upon the coherence criterion, which sets the largest value allowed for correlations between the basis kernel functions characterizing the unmixing model. We show that the proposed BS approach is equivalent to solving a maximum clique problem (MCP), that is, searching for the biggest complete subgraph in a graph. Furthermore, we devise a strategy for selecting the coherence threshold and the Gaussian kernel bandwidth using coherence bounds for linearly independent bases. Simulation results illustrate the efficiency of the proposed method.



### Convolutional Patch Representations for Image Retrieval: an Unsupervised Approach
- **Arxiv ID**: http://arxiv.org/abs/1603.00438v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00438v1)
- **Published**: 2016-03-01 20:13:07+00:00
- **Updated**: 2016-03-01 20:13:07+00:00
- **Authors**: Mattis Paulin, Julien Mairal, Matthijs Douze, Zaid Harchaoui, Florent Perronnin, Cordelia Schmid
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have recently received a lot of attention due to their ability to model local stationary structures in natural images in a multi-scale fashion, when learning all model parameters with supervision. While excellent performance was achieved for image classification when large amounts of labeled visual data are available, their success for un-supervised tasks such as image retrieval has been moderate so far. Our paper focuses on this latter setting and explores several methods for learning patch descriptors without supervision with application to matching and instance-level retrieval. To that effect, we propose a new family of convolutional descriptors for patch representation , based on the recently introduced convolutional kernel networks. We show that our descriptor, named Patch-CKN, performs better than SIFT as well as other convolutional networks learned by artificially introducing supervision and is significantly faster to train. To demonstrate its effectiveness, we perform an extensive evaluation on standard benchmarks for patch and image retrieval where we obtain state-of-the-art results. We also introduce a new dataset called RomePatches, which allows to simultaneously study descriptor performance for patch and image retrieval.



### Fourier ptychographic reconstruction using Poisson maximum likelihood and truncated Wirtinger gradient
- **Arxiv ID**: http://arxiv.org/abs/1603.04746v1
- **DOI**: 10.1038/srep27384
- **Categories**: **cs.CV**, physics.optics
- **Links**: [PDF](http://arxiv.org/pdf/1603.04746v1)
- **Published**: 2016-03-01 21:05:48+00:00
- **Updated**: 2016-03-01 21:05:48+00:00
- **Authors**: Liheng Bian, Jinli Suo, Jaebum Chung, Xiaoze Ou, Changhuei Yang, Feng Chen, Qionghai Dai
- **Comment**: None
- **Journal**: None
- **Summary**: Fourier ptychographic microscopy (FPM) is a novel computational coherent imaging technique for high space-bandwidth product imaging. Mathematically, Fourier ptychographic (FP) reconstruction can be implemented as a phase retrieval optimization process, in which we only obtain low resolution intensity images corresponding to the sub-bands of the sample's high resolution (HR) spatial spectrum, and aim to retrieve the complex HR spectrum. In real setups, the measurements always suffer from various degenerations such as Gaussian noise, Poisson noise, speckle noise and pupil location error, which would largely degrade the reconstruction. To efficiently address these degenerations, we propose a novel FP reconstruction method under a gradient descent optimization framework in this paper. The technique utilizes Poisson maximum likelihood for better signal modeling, and truncated Wirtinger gradient for error removal. Results on both simulated data and real data captured using our laser FPM setup show that the proposed method outperforms other state-of-the-art algorithms. Also, we have released our source code for non-commercial use.



### Weakly Supervised Localization using Deep Feature Maps
- **Arxiv ID**: http://arxiv.org/abs/1603.00489v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00489v2)
- **Published**: 2016-03-01 21:07:09+00:00
- **Updated**: 2016-03-29 01:10:00+00:00
- **Authors**: Archith J. Bency, Heesung Kwon, Hyungtae Lee, S. Karthikeyan, B. S. Manjunath
- **Comment**: None
- **Journal**: None
- **Summary**: Object localization is an important computer vision problem with a variety of applications. The lack of large scale object-level annotations and the relative abundance of image-level labels makes a compelling case for weak supervision in the object localization task. Deep Convolutional Neural Networks are a class of state-of-the-art methods for the related problem of object recognition. In this paper, we describe a novel object localization algorithm which uses classification networks trained on only image labels. This weakly supervised method leverages local spatial and semantic patterns captured in the convolutional layers of classification networks. We propose an efficient beam search based approach to detect and localize multiple objects in images. The proposed method significantly outperforms the state-of-the-art in standard object localization data-sets with a 8 point increase in mAP scores.



### Keypoint Density-based Region Proposal for Fine-Grained Object Detection and Classification using Regions with Convolutional Neural Network Features
- **Arxiv ID**: http://arxiv.org/abs/1603.00502v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00502v1)
- **Published**: 2016-03-01 21:48:58+00:00
- **Updated**: 2016-03-01 21:48:58+00:00
- **Authors**: JT Turner, Kalyan Gupta, Brendan Morris, David W. Aha
- **Comment**: 9 pages, 5 figures, 3 tables
- **Journal**: None
- **Summary**: Although recent advances in regional Convolutional Neural Networks (CNNs) enable them to outperform conventional techniques on standard object detection and classification tasks, their response time is still slow for real-time performance. To address this issue, we propose a method for region proposal as an alternative to selective search, which is used in current state-of-the art object detection algorithms. We evaluate our Keypoint Density-based Region Proposal (KDRP) approach and show that it speeds up detection and classification on fine-grained tasks by 100% versus the existing selective search region proposal technique without compromising classification accuracy. KDRP makes the application of CNNs to real-time detection and classification feasible.



