# Arxiv Papers in cs.CV on 2016-03-19
### A Survey of Stealth Malware: Attacks, Mitigation Measures, and Steps Toward Autonomous Open World Solutions
- **Arxiv ID**: http://arxiv.org/abs/1603.06028v2
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1603.06028v2)
- **Published**: 2016-03-19 01:23:45+00:00
- **Updated**: 2016-12-02 19:00:50+00:00
- **Authors**: Ethan M. Rudd, Andras Rozsa, Manuel GÃ¼nther, Terrance E. Boult
- **Comment**: Pre-Print of a manuscript Accepted to IEEE Communications Surveys and
  Tutorials (COMST) on December 1, 2016
- **Journal**: None
- **Summary**: As our professional, social, and financial existences become increasingly digitized and as our government, healthcare, and military infrastructures rely more on computer technologies, they present larger and more lucrative targets for malware. Stealth malware in particular poses an increased threat because it is specifically designed to evade detection mechanisms, spreading dormant, in the wild for extended periods of time, gathering sensitive information or positioning itself for a high-impact zero-day attack. Policing the growing attack surface requires the development of efficient anti-malware solutions with improved generalization to detect novel types of malware and resolve these occurrences with as little burden on human experts as possible. In this paper, we survey malicious stealth technologies as well as existing solutions for detecting and categorizing these countermeasures autonomously. While machine learning offers promising potential for increasingly autonomous solutions with improved generalization to new malware types, both at the network level and at the host level, our findings suggest that several flawed assumptions inherent to most recognition algorithms prevent a direct mapping between the stealth malware recognition problem and a machine learning solution. The most notable of these flawed assumptions is the closed world assumption: that no sample belonging to a class outside of a static training set will appear at query time. We present a formalized adaptive open world framework for stealth malware recognition and relate it mathematically to research from other machine learning domains.



### Fractal Dimension Invariant Filtering and Its CNN-based Implementation
- **Arxiv ID**: http://arxiv.org/abs/1603.06036v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06036v3)
- **Published**: 2016-03-19 03:29:57+00:00
- **Updated**: 2017-03-17 03:10:56+00:00
- **Authors**: Hongteng Xu, Junchi Yan, Nils Persson, Weiyao Lin, Hongyuan Zha
- **Comment**: CVPR 2017
- **Journal**: None
- **Summary**: Fractal analysis has been widely used in computer vision, especially in texture image processing and texture analysis. The key concept of fractal-based image model is the fractal dimension, which is invariant to bi-Lipschitz transformation of image, and thus capable of representing intrinsic structural information of image robustly. However, the invariance of fractal dimension generally does not hold after filtering, which limits the application of fractal-based image model. In this paper, we propose a novel fractal dimension invariant filtering (FDIF) method, extending the invariance of fractal dimension to filtering operations. Utilizing the notion of local self-similarity, we first develop a local fractal model for images. By adding a nonlinear post-processing step behind anisotropic filter banks, we demonstrate that the proposed filtering method is capable of preserving the local invariance of the fractal dimension of image. Meanwhile, we show that the FDIF method can be re-instantiated approximately via a CNN-based architecture, where the convolution layer extracts anisotropic structure of image and the nonlinear layer enhances the structure via preserving local fractal dimension of image. The proposed filtering method provides us with a novel geometric interpretation of CNN-based image model. Focusing on a challenging image processing task --- detecting complicated curves from the texture-like images, the proposed method obtains superior results to the state-of-art approaches.



### Learning Image Matching by Simply Watching Video
- **Arxiv ID**: http://arxiv.org/abs/1603.06041v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06041v2)
- **Published**: 2016-03-19 03:45:44+00:00
- **Updated**: 2016-03-29 04:35:49+00:00
- **Authors**: Gucan Long, Laurent Kneip, Jose M. Alvarez, Hongdong Li
- **Comment**: The second version contains additional quantitative evaluation of
  frame interpolation
- **Journal**: None
- **Summary**: This work presents an unsupervised learning based approach to the ubiquitous computer vision problem of image matching. We start from the insight that the problem of frame-interpolation implicitly solves for inter-frame correspondences. This permits the application of analysis-by-synthesis: we firstly train and apply a Convolutional Neural Network for frame-interpolation, then obtain correspondences by inverting the learned CNN. The key benefit behind this strategy is that the CNN for frame-interpolation can be trained in an unsupervised manner by exploiting the temporal coherency that is naturally contained in real-world video sequences. The present model therefore learns image matching by simply watching videos. Besides a promise to be more generally applicable, the presented approach achieves surprising performance comparable to traditional empirically designed methods.



### Generating Natural Questions About an Image
- **Arxiv ID**: http://arxiv.org/abs/1603.06059v3
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1603.06059v3)
- **Published**: 2016-03-19 07:27:15+00:00
- **Updated**: 2016-06-09 01:20:49+00:00
- **Authors**: Nasrin Mostafazadeh, Ishan Misra, Jacob Devlin, Margaret Mitchell, Xiaodong He, Lucy Vanderwende
- **Comment**: Proceedings of the 54th Annual Meeting of the Association for
  Computational Linguistics
- **Journal**: None
- **Summary**: There has been an explosion of work in the vision & language community during the past few years from image captioning to video transcription, and answering questions about images. These tasks have focused on literal descriptions of the image. To move beyond the literal, we choose to explore how questions about an image are often directed at commonsense inference and the abstract events evoked by objects in the image. In this paper, we introduce the novel task of Visual Question Generation (VQG), where the system is tasked with asking a natural and engaging question when shown an image. We provide three datasets which cover a variety of images from object-centric to event-centric, with considerably more abstract training data than provided to state-of-the-art captioning systems thus far. We train and test several generative and retrieval models to tackle the task of VQG. Evaluation results show that while such models ask reasonable questions for a variety of images, there is still a wide gap with human performance which motivates further work on connecting images with commonsense knowledge and pragmatics. Our proposed task offers a new challenge to the community which we hope furthers interest in exploring deeper connections between vision & language.



### DASA: Domain Adaptation in Stacked Autoencoders using Systematic Dropout
- **Arxiv ID**: http://arxiv.org/abs/1603.06060v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1603.06060v1)
- **Published**: 2016-03-19 07:27:56+00:00
- **Updated**: 2016-03-19 07:27:56+00:00
- **Authors**: Abhijit Guha Roy, Debdoot Sheet
- **Comment**: Accepted at Asian Conference on Pattern Recognition 2015
- **Journal**: None
- **Summary**: Domain adaptation deals with adapting behaviour of machine learning based systems trained using samples in source domain to their deployment in target domain where the statistics of samples in both domains are dissimilar. The task of directly training or adapting a learner in the target domain is challenged by lack of abundant labeled samples. In this paper we propose a technique for domain adaptation in stacked autoencoder (SAE) based deep neural networks (DNN) performed in two stages: (i) unsupervised weight adaptation using systematic dropouts in mini-batch training, (ii) supervised fine-tuning with limited number of labeled samples in target domain. We experimentally evaluate performance in the problem of retinal vessel segmentation where the SAE-DNN is trained using large number of labeled samples in the source domain (DRIVE dataset) and adapted using less number of labeled samples in target domain (STARE dataset). The performance of SAE-DNN measured using $logloss$ in source domain is $0.19$, without and with adaptation are $0.40$ and $0.18$, and $0.39$ when trained exclusively with limited samples in target domain. The area under ROC curve is observed respectively as $0.90$, $0.86$, $0.92$ and $0.87$. The high efficiency of vessel segmentation with DASA strongly substantiates our claim.



### Large scale near-duplicate image retrieval using Triples of Adjacent Ranked Features (TARF) with embedded geometric information
- **Arxiv ID**: http://arxiv.org/abs/1603.06093v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06093v1)
- **Published**: 2016-03-19 13:36:02+00:00
- **Updated**: 2016-03-19 13:36:02+00:00
- **Authors**: Sergei Fedorov, Olga Kacher
- **Comment**: None
- **Journal**: None
- **Summary**: Most approaches to large-scale image retrieval are based on the construction of the inverted index of local image descriptors or visual words. A search in such an index usually results in a large number of candidates. This list of candidates is then re-ranked with the help of a geometric verification, using a RANSAC algorithm, for example. In this paper we propose a feature representation, which is built as a combination of three local descriptors. It allows one to significantly decrease the number of false matches and to shorten the list of candidates after the initial search in the inverted index. This combination of local descriptors is both reproducible and highly discriminative, and thus can be efficiently used for large-scale near-duplicate image retrieval.



### Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1603.06098v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06098v3)
- **Published**: 2016-03-19 14:13:42+00:00
- **Updated**: 2016-08-06 18:49:45+00:00
- **Authors**: Alexander Kolesnikov, Christoph H. Lampert
- **Comment**: ECCV 2016
- **Journal**: None
- **Summary**: We introduce a new loss function for the weakly-supervised training of semantic image segmentation models based on three guiding principles: to seed with weak localization cues, to expand objects based on the information about which classes can occur in an image, and to constrain the segmentations to coincide with object boundaries. We show experimentally that training a deep convolutional neural network using the proposed loss function leads to substantially better segmentations than previous state-of-the-art methods on the challenging PASCAL VOC 2012 dataset. We furthermore give insight into the working mechanism of our method by a detailed experimental study that illustrates how the segmentation quality is affected by each term of the proposed loss function as well as their combinations.



### Buried object detection using handheld WEMI with task-driven extended functions of multiple instances
- **Arxiv ID**: http://arxiv.org/abs/1603.06121v1
- **DOI**: 10.1117/12.2223349
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06121v1)
- **Published**: 2016-03-19 17:46:45+00:00
- **Updated**: 2016-03-19 17:46:45+00:00
- **Authors**: Matthew Cook, Alina Zare, Dominic Ho
- **Comment**: Proceedings of the SPIE, 2016
- **Journal**: None
- **Summary**: Many effective supervised discriminative dictionary learning methods have been developed in the literature. However, when training these algorithms, precise ground-truth of the training data is required to provide very accurate point-wise labels. Yet, in many applications, accurate labels are not always feasible. This is especially true in the case of buried object detection in which the size of the objects are not consistent. In this paper, a new multiple instance dictionary learning algorithm for detecting buried objects using a handheld WEMI sensor is detailed. The new algorithm, Task Driven Extended Functions of Multiple Instances, can overcome data that does not have very precise point-wise labels and still learn a highly discriminative dictionary. Results are presented and discussed on measured WEMI data.



### Adaptive coherence estimator (ACE) for explosive hazard detection using wideband electromagnetic induction (WEMI)
- **Arxiv ID**: http://arxiv.org/abs/1603.06140v3
- **DOI**: 10.1117/12.2223347
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.06140v3)
- **Published**: 2016-03-19 20:33:50+00:00
- **Updated**: 2016-05-05 23:38:01+00:00
- **Authors**: Brendan Alvey, Alina Zare, Matthew Cook, Dominic K. Ho
- **Comment**: Proceedings of the SPIE, 2016, Corrected reference formatting and
  figure
- **Journal**: None
- **Summary**: The adaptive coherence estimator (ACE) estimates the squared cosine of the angle between a known target vector and a sample vector in a whitened coordinate space. The space is whitened according to an estimation of the background statistics, which directly effects the performance of the statistic as a target detector. In this paper, the ACE detection statistic is used to detect buried explosive hazards with data from a Wideband Electromagnetic Induction (WEMI) sensor. Target signatures are based on a dictionary defined using a Discrete Spectrum of Relaxation Frequencies (DSRF) model. Results are summarized as a receiver operator curve (ROC) and compared to other leading methods.



