# Arxiv Papers in cs.CV on 2016-03-08
### Hand Segmentation for Hand-Object Interaction from Depth map
- **Arxiv ID**: http://arxiv.org/abs/1603.02345v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.02345v3)
- **Published**: 2016-03-08 00:22:59+00:00
- **Updated**: 2018-01-10 03:20:52+00:00
- **Authors**: Byeongkeun Kang, Kar-Han Tan, Nan Jiang, Hung-Shuo Tai, Daniel Tretter, Truong Q. Nguyen
- **Comment**: None
- **Journal**: None
- **Summary**: Hand segmentation for hand-object interaction is a necessary preprocessing step in many applications such as augmented reality, medical application, and human-robot interaction. However, typical methods are based on color information which is not robust to objects with skin color, skin pigment difference, and light condition variations. Thus, we propose hand segmentation method for hand-object interaction using only a depth map. It is challenging because of the small depth difference between a hand and objects during an interaction. To overcome this challenge, we propose the two-stage random decision forest (RDF) method consisting of detecting hands and segmenting hands. To validate the proposed method, we demonstrate results on the publicly available dataset of hand segmentation for hand-object interaction. The proposed method achieves high accuracy in short processing time comparing to the other state-of-the-art methods.



### A hybrid approach based segmentation technique for brain tumor in MRI Images
- **Arxiv ID**: http://arxiv.org/abs/1603.02447v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.02447v1)
- **Published**: 2016-03-08 09:50:43+00:00
- **Updated**: 2016-03-08 09:50:43+00:00
- **Authors**: D. Anithadevi, K. Perumal
- **Comment**: Attended conference for this paper in NCNHCIIS 2015 at Gandhigram
  University. Published in AIRCC February 2016
- **Journal**: None
- **Summary**: Automatic image segmentation becomes very crucial for tumor detection in medical image processing.In general, manual and semi automatic segmentation techniques require more time and knowledge. However these drawbacks had overcome by automatic segmentation still there needs to develop more appropriate techniques for medical image segmentation. Therefore, we proposed hybrid approach based image segmentation using the combined features of region growing and threshold based segmentation techniques. It is followed by pre-processing stage to provide an accurate brain tumor extraction by the help of Magnetic Resonance Imaging (MRI). If the tumor has holes, the region growing segmentation algorithm cannot reveal but the proposed hybrid segmentation technique can be achieved and the result as well improved. Hence the result used to made assessment with the various performance measures as DICE, JACCARD similarity, accuracy, sensitivity and specificity. These similarity measures have been extensively used for evaluation with the ground truth of each processed image and its results are compared and analyzed.



### A non-extensive entropy feature and its application to texture classification
- **Arxiv ID**: http://arxiv.org/abs/1603.02466v1
- **DOI**: 10.1016/j.neucom.2012.09.043
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.02466v1)
- **Published**: 2016-03-08 10:31:55+00:00
- **Updated**: 2016-03-08 10:31:55+00:00
- **Authors**: Seba Susan, Madasu Hanmandlu
- **Comment**: None
- **Journal**: Neurocomputing 120 (2013): 214-225
- **Summary**: This paper proposes a new probabilistic non-extensive entropy feature for texture characterization, based on a Gaussian information measure. The highlights of the new entropy are that it is bounded by finite limits and that it is non additive in nature. The non additive property of the proposed entropy makes it useful for the representation of information content in the non-extensive systems containing some degree of regularity or correlation. The effectiveness of the proposed entropy in representing the correlated random variables is demonstrated by applying it for the texture classification problem since textures found in nature are random and at the same time contain some degree of correlation or regularity at some scale. The gray level co-occurrence probabilities (GLCP) are used for computing the entropy function. The experimental results indicate high degree of the classification accuracy. The performance of the new entropy function is found superior to other forms of entropy such as Shannon, Renyi, Tsallis and Pal and Pal entropies on comparison. Using the feature based polar interaction maps (FBIM) the proposed entropy is shown to be the best measure among the entropies compared for representing the correlated textures.



### A New Method to Visualize Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1603.02518v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.02518v3)
- **Published**: 2016-03-08 13:46:28+00:00
- **Updated**: 2017-06-12 15:54:09+00:00
- **Authors**: Luisa M. Zintgraf, Taco S. Cohen, Max Welling
- **Comment**: Please note that this version of the article is outdated. The new
  version (published at ICLR2017) includes additional experiments on MRI scans
  and can be found at arXiv:1702.04595
- **Journal**: None
- **Summary**: We present a method for visualising the response of a deep neural network to a specific input. For image data for instance our method will highlight areas that provide evidence in favor of, and against choosing a certain class. The method overcomes several shortcomings of previous methods and provides great additional insight into the decision making process of convolutional networks, which is important both to improve models and to accelerate the adoption of such methods in e.g. medicine. In experiments on ImageNet data, we illustrate how the method works and can be applied in different ways to understand deep neural nets.



### Iterative Hough Forest with Histogram of Control Points for 6 DoF Object Registration from Depth Images
- **Arxiv ID**: http://arxiv.org/abs/1603.02617v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1603.02617v2)
- **Published**: 2016-03-08 18:33:44+00:00
- **Updated**: 2017-01-09 12:43:53+00:00
- **Authors**: Caner Sahin, Rigas Kouskouridas, Tae-Kyun Kim
- **Comment**: IROS 2016
- **Journal**: None
- **Summary**: State-of-the-art techniques proposed for 6D object pose recovery depend on occlusion-free point clouds to accurately register objects in 3D space. To reduce this dependency, we introduce a novel architecture called Iterative Hough Forest with Histogram of Control Points that is capable of estimating occluded and cluttered objects' 6D pose given a candidate 2D bounding box. Our Iterative Hough Forest is learnt using patches extracted only from the positive samples. These patches are represented with Histogram of Control Points (HoCP), a "scale-variant" implicit volumetric description, which we derive from recently introduced Implicit B-Splines (IBS). The rich discriminative information provided by this scale-variance is leveraged during inference, where the initial pose estimation of the object is iteratively refined based on more discriminative control points by using our Iterative Hough Forest. We conduct experiments on several test objects of a publicly available dataset to test our architecture and to compare with the state-of-the-art.



### The red one!: On learning to refer to things based on their discriminative properties
- **Arxiv ID**: http://arxiv.org/abs/1603.02618v2
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1603.02618v2)
- **Published**: 2016-03-08 18:39:46+00:00
- **Updated**: 2016-05-23 17:04:15+00:00
- **Authors**: Angeliki Lazaridou, Nghia The Pham, Marco Baroni
- **Comment**: Accepted as an ACL-short sumbmission
- **Journal**: None
- **Summary**: As a first step towards agents learning to communicate about their visual environment, we propose a system that, given visual representations of a referent (cat) and a context (sofa), identifies their discriminative attributes, i.e., properties that distinguish them (has_tail). Moreover, despite the lack of direct supervision at the attribute level, the model learns to assign plausible attributes to objects (sofa-has_cushion). Finally, we present a preliminary experiment confirming the referential success of the predicted discriminative attributes.



### DROW: Real-Time Deep Learning based Wheelchair Detection in 2D Range Data
- **Arxiv ID**: http://arxiv.org/abs/1603.02636v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1603.02636v2)
- **Published**: 2016-03-08 19:39:19+00:00
- **Updated**: 2016-12-05 18:06:28+00:00
- **Authors**: Lucas Beyer, Alexander Hermans, Bastian Leibe
- **Comment**: Lucas Beyer and Alexander Hermans contributed equally
- **Journal**: None
- **Summary**: We introduce the DROW detector, a deep learning based detector for 2D range data. Laser scanners are lighting invariant, provide accurate range data, and typically cover a large field of view, making them interesting sensors for robotics applications. So far, research on detection in laser range data has been dominated by hand-crafted features and boosted classifiers, potentially losing performance due to suboptimal design choices. We propose a Convolutional Neural Network (CNN) based detector for this task. We show how to effectively apply CNNs for detection in 2D range data, and propose a depth preprocessing step and voting scheme that significantly improve CNN performance. We demonstrate our approach on wheelchairs and walkers, obtaining state of the art detection results. Apart from the training data, none of our design choices limits the detector to these two classes, though. We provide a ROS node for our detector and release our dataset containing 464k laser scans, out of which 24k were annotated.



### A regularization-based approach for unsupervised image segmentation
- **Arxiv ID**: http://arxiv.org/abs/1603.02649v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.02649v1)
- **Published**: 2016-03-08 20:02:28+00:00
- **Updated**: 2016-03-08 20:02:28+00:00
- **Authors**: Aleksandar Dimitriev, Matej Kristan
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel unsupervised image segmentation algorithm, which aims to segment an image into several coherent parts. It requires no user input, no supervised learning phase and assumes an unknown number of segments. It achieves this by first over-segmenting the image into several hundred superpixels. These are iteratively joined on the basis of a discriminative classifier trained on color and texture information obtained from each superpixel. The output of the classifier is regularized by a Markov random field that lends more influence to neighbouring superpixels that are more similar. In each iteration, similar superpixels fall under the same label, until only a few coherent regions remain in the image. The algorithm was tested on a standard evaluation data set, where it performs on par with state-of-the-art algorithms in term of precision and greatly outperforms the state of the art by reducing the oversegmentation of the object of interest.



### Revisiting Active Perception
- **Arxiv ID**: http://arxiv.org/abs/1603.02729v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1603.02729v2)
- **Published**: 2016-03-08 22:48:26+00:00
- **Updated**: 2016-03-13 18:29:08+00:00
- **Authors**: Ruzena Bajcsy, Yiannis Aloimonos, John K. Tsotsos
- **Comment**: None
- **Journal**: None
- **Summary**: Despite the recent successes in robotics, artificial intelligence and computer vision, a complete artificial agent necessarily must include active perception. A multitude of ideas and methods for how to accomplish this have already appeared in the past, their broader utility perhaps impeded by insufficient computational power or costly hardware. The history of these ideas, perhaps selective due to our perspectives, is presented with the goal of organizing the past literature and highlighting the seminal contributions. We argue that those contributions are as relevant today as they were decades ago and, with the state of modern computational tools, are poised to find new life in the robotic perception systems of the next decade.



### Discriminative models for robust image classification
- **Arxiv ID**: http://arxiv.org/abs/1603.02736v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1603.02736v1)
- **Published**: 2016-03-08 23:15:18+00:00
- **Updated**: 2016-03-08 23:15:18+00:00
- **Authors**: Umamahesh Srinivas
- **Comment**: Doctoral dissertation, Department of Electrical Engineering, The
  Pennsylvania State University, 2013
- **Journal**: None
- **Summary**: A variety of real-world tasks involve the classification of images into pre-determined categories. Designing image classification algorithms that exhibit robustness to acquisition noise and image distortions, particularly when the available training data are insufficient to learn accurate models, is a significant challenge. This dissertation explores the development of discriminative models for robust image classification that exploit underlying signal structure, via probabilistic graphical models and sparse signal representations.   Probabilistic graphical models are widely used in many applications to approximate high-dimensional data in a reduced complexity set-up. Learning graphical structures to approximate probability distributions is an area of active research. Recent work has focused on learning graphs in a discriminative manner with the goal of minimizing classification error. In the first part of the dissertation, we develop a discriminative learning framework that exploits the complementary yet correlated information offered by multiple representations (or projections) of a given signal/image. Specifically, we propose a discriminative tree-based scheme for feature fusion by explicitly learning the conditional correlations among such multiple projections in an iterative manner. Experiments reveal the robustness of the resulting graphical model classifier to training insufficiency.



