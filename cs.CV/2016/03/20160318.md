# Arxiv Papers in cs.CV on 2016-03-18
### From line segments to more organized Gestalts
- **Arxiv ID**: http://arxiv.org/abs/1603.05763v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.05763v1)
- **Published**: 2016-03-18 04:05:35+00:00
- **Updated**: 2016-03-18 04:05:35+00:00
- **Authors**: Boshra Rajaei, Rafael Grompone von Gioi, Jean-Michel Morel
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we reconsider the early computer vision bottom-up program, according to which higher level features (geometric structures) in an image could be built up recursively from elementary features by simple grouping principles coming from Gestalt theory. Taking advantage of the (recent) advances in reliable line segment detectors, we propose three feature detectors that constitute one step up in this bottom up pyramid. For any digital image, our unsupervised algorithm computes three classic Gestalts from the set of predetected line segments: good continuations, nonlocal alignments, and bars. The methodology is based on a common stochastic {\it a contrario model} yielding three simple detection formulas, characterized by their number of false alarms. This detection algorithm is illustrated on several digital images.



### Learning to Navigate the Energy Landscape
- **Arxiv ID**: http://arxiv.org/abs/1603.05772v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.05772v1)
- **Published**: 2016-03-18 05:45:39+00:00
- **Updated**: 2016-03-18 05:45:39+00:00
- **Authors**: Julien Valentin, Angela Dai, Matthias Nie√üner, Pushmeet Kohli, Philip Torr, Shahram Izadi, Cem Keskin
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a novel and efficient architecture for addressing computer vision problems that use `Analysis by Synthesis'. Analysis by synthesis involves the minimization of the reconstruction error which is typically a non-convex function of the latent target variables. State-of-the-art methods adopt a hybrid scheme where discriminatively trained predictors like Random Forests or Convolutional Neural Networks are used to initialize local search algorithms. While these methods have been shown to produce promising results, they often get stuck in local optima. Our method goes beyond the conventional hybrid architecture by not only proposing multiple accurate initial solutions but by also defining a navigational structure over the solution space that can be used for extremely efficient gradient-free local search. We demonstrate the efficacy of our approach on the challenging problem of RGB Camera Relocalization. To make the RGB camera relocalization problem particularly challenging, we introduce a new dataset of 3D environments which are significantly larger than those found in other publicly-available datasets. Our experiments reveal that the proposed method is able to achieve state-of-the-art camera relocalization results. We also demonstrate the generalizability of our approach on Hand Pose Estimation and Image Retrieval tasks.



### Unsupervised Cross-Media Hashing with Structure Preservation
- **Arxiv ID**: http://arxiv.org/abs/1603.05782v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, H.3.3
- **Links**: [PDF](http://arxiv.org/pdf/1603.05782v1)
- **Published**: 2016-03-18 07:10:35+00:00
- **Updated**: 2016-03-18 07:10:35+00:00
- **Authors**: Xiangyu Wang, Alex Yong-Sang Chia
- **Comment**: None
- **Journal**: None
- **Summary**: Recent years have seen the exponential growth of heterogeneous multimedia data. The need for effective and accurate data retrieval from heterogeneous data sources has attracted much research interest in cross-media retrieval. Here, given a query of any media type, cross-media retrieval seeks to find relevant results of different media types from heterogeneous data sources. To facilitate large-scale cross-media retrieval, we propose a novel unsupervised cross-media hashing method. Our method incorporates local affinity and distance repulsion constraints into a matrix factorization framework. Correspondingly, the proposed method learns hash functions that generates unified hash codes from different media types, while ensuring intrinsic geometric structure of the data distribution is preserved. These hash codes empower the similarity between data of different media types to be evaluated directly. Experimental results on two large-scale multimedia datasets demonstrate the effectiveness of the proposed method, where we outperform the state-of-the-art methods.



### A Flexible Primal-Dual Toolbox
- **Arxiv ID**: http://arxiv.org/abs/1603.05835v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.MS, I.4; G.1.6; G.4
- **Links**: [PDF](http://arxiv.org/pdf/1603.05835v2)
- **Published**: 2016-03-18 11:01:23+00:00
- **Updated**: 2016-07-20 13:11:14+00:00
- **Authors**: Hendrik Dirks
- **Comment**: 10 pages, 1 table
- **Journal**: None
- **Summary**: \textbf{FlexBox} is a flexible MATLAB toolbox for finite dimensional convex variational problems in image processing and beyond. Such problems often consist of non-differentiable parts and involve linear operators. The toolbox uses a primal-dual scheme to avoid (computationally) inefficient operator inversion and to get reliable error estimates. From the user-side, \textbf{FlexBox} expects the primal formulation of the problem, automatically decouples operators and dualizes the problem. For large-scale problems, \textbf{FlexBox} also comes with a \cpp-module, which can be used stand-alone or together with MATLAB via MEX-interfaces. Besides various pre-implemented data-fidelities and regularization-terms, \textbf{FlexBox} is able to handle arbitrary operators while being easily extendable, due to its object-oriented design. The toolbox is available at \href{http://www.flexbox.im}{http://www.flexbox.im}



### Approximated Robust Principal Component Analysis for Improved General Scene Background Subtraction
- **Arxiv ID**: http://arxiv.org/abs/1603.05875v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1603.05875v1)
- **Published**: 2016-03-18 13:53:26+00:00
- **Updated**: 2016-03-18 13:53:26+00:00
- **Authors**: Salehe Erfanian Ebadi, Valia Guerra Ones, Ebroul Izquierdo
- **Comment**: arXiv admin note: text overlap with arXiv:1511.01245 by other authors
- **Journal**: None
- **Summary**: The research reported in this paper addresses the fundamental task of separation of locally moving or deforming image areas from a static or globally moving background. It builds on the latest developments in the field of robust principal component analysis, specifically, the recently reported practical solutions for the long-standing problem of recovering the low-rank and sparse parts of a large matrix made up of the sum of these two components. This article addresses a few critical issues including: embedding global motion parameters in the matrix decomposition model, i.e., estimation of global motion parameters simultaneously with the foreground/background separation task, considering matrix block-sparsity rather than generic matrix sparsity as natural feature in video processing applications, attenuating background ghosting effects when foreground is subtracted, and more critically providing an extremely efficient algorithm to solve the low-rank/sparse matrix decomposition task. The first aspect is important for background/foreground separation in generic video sequences where the background usually obeys global displacements originated by the camera motion in the capturing process. The second aspect exploits the fact that in video processing applications the sparse matrix has a very particular structure, where the non-zero matrix entries are not randomly distributed but they build small blocks within the sparse matrix. The next feature of the proposed approach addresses removal of ghosting effects originated from foreground silhouettes and the lack of information in the occluded background regions of the image. Finally, the proposed model also tackles algorithmic complexity by introducing an extremely efficient "SVD-free" technique that can be applied in most background/foreground separation tasks for conventional video processing.



### Geometric Hypergraph Learning for Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1603.05930v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.05930v1)
- **Published**: 2016-03-18 17:32:30+00:00
- **Updated**: 2016-03-18 17:32:30+00:00
- **Authors**: Dawei Du, Honggang Qi, Longyin Wen, Qi Tian, Qingming Huang, Siwei Lyu
- **Comment**: None
- **Journal**: None
- **Summary**: Graph based representation is widely used in visual tracking field by finding correct correspondences between target parts in consecutive frames. However, most graph based trackers consider pairwise geometric relations between local parts. They do not make full use of the target's intrinsic structure, thereby making the representation easily disturbed by errors in pairwise affinities when large deformation and occlusion occur. In this paper, we propose a geometric hypergraph learning based tracking method, which fully exploits high-order geometric relations among multiple correspondences of parts in consecutive frames. Then visual tracking is formulated as the mode-seeking problem on the hypergraph in which vertices represent correspondence hypotheses and hyperedges describe high-order geometric relations. Besides, a confidence-aware sampling method is developed to select representative vertices and hyperedges to construct the geometric hypergraph for more robustness and scalability. The experiments are carried out on two challenging datasets (VOT2014 and Deform-SOT) to demonstrate that the proposed method performs favorable against other existing trackers.



### Transferring Learned Microcalcification Group Detection from 2D Mammography to 3D Digital Breast Tomosynthesis Using a Hierarchical Model and Scope-based Normalization Features
- **Arxiv ID**: http://arxiv.org/abs/1603.05955v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.05955v1)
- **Published**: 2016-03-18 18:46:36+00:00
- **Updated**: 2016-03-18 18:46:36+00:00
- **Authors**: Yin Yin, Sergei V. Fotin, Hrishikesh Haldankar, Jeffrey W. Hoffmeister, Senthil Periaswamy
- **Comment**: None
- **Journal**: None
- **Summary**: A novel hierarchical model is introduced to solve a general problem of detecting groups of similar objects. Under this model, detection of groups is performed in hierarchically organized layers while each layer represents a scope for target objects. The processing of these layers involves sequential extraction of appearance features for an individual object, consistency measurement features for nearby objects, and finally the distribution features for all objects within the group. Using the concept of scope-based normalization, the extracted features not only enhance local contrast of an individual object, but also provide consistent characterization for all related objects. As an example, a microcalcification group detection system for 2D mammography was developed, and then the learned model was transferred to 3D digital breast tomosynthesis without any retraining or fine-tuning. The detection system demonstrated state-of-the-art performance and detected 96% of cancerous lesions at the rate of 1.2 false positives per volume as measured on an independent tomosynthesis test set.



### Efficient Multi-Scale 3D CNN with Fully Connected CRF for Accurate Brain Lesion Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1603.05959v3
- **DOI**: 10.1016/j.media.2016.10.004
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1603.05959v3)
- **Published**: 2016-03-18 19:07:01+00:00
- **Updated**: 2017-01-08 13:55:35+00:00
- **Authors**: Konstantinos Kamnitsas, Christian Ledig, Virginia F. J. Newcombe, Joanna P. Simpson, Andrew D. Kane, David K. Menon, Daniel Rueckert, Ben Glocker
- **Comment**: This version was accepted in the journal Medical Image Analysis
  (MedIA)
- **Journal**: None
- **Summary**: We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumors, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available.



### A Comprehensive Performance Evaluation of Deformable Face Tracking "In-the-Wild"
- **Arxiv ID**: http://arxiv.org/abs/1603.06015v2
- **DOI**: 10.1007/s11263-017-0999-5
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1603.06015v2)
- **Published**: 2016-03-18 23:17:01+00:00
- **Updated**: 2017-02-28 22:23:40+00:00
- **Authors**: Grigorios G. Chrysos, Epameinondas Antonakos, Patrick Snape, Akshay Asthana, Stefanos Zafeiriou
- **Comment**: E. Antonakos and P. Snape contributed equally and have joint second
  authorship
- **Journal**: None
- **Summary**: Recently, technologies such as face detection, facial landmark localisation and face recognition and verification have matured enough to provide effective and efficient solutions for imagery captured under arbitrary conditions (referred to as "in-the-wild"). This is partially attributed to the fact that comprehensive "in-the-wild" benchmarks have been developed for face detection, landmark localisation and recognition/verification. A very important technology that has not been thoroughly evaluated yet is deformable face tracking "in-the-wild". Until now, the performance has mainly been assessed qualitatively by visually assessing the result of a deformable face tracking technology on short videos. In this paper, we perform the first, to the best of our knowledge, thorough evaluation of state-of-the-art deformable face tracking pipelines using the recently introduced 300VW benchmark. We evaluate many different architectures focusing mainly on the task of on-line deformable face tracking. In particular, we compare the following general strategies: (a) generic face detection plus generic facial landmark localisation, (b) generic model free tracking plus generic facial landmark localisation, as well as (c) hybrid approaches using state-of-the-art face detection, model free tracking and facial landmark localisation technologies. Our evaluation reveals future avenues for further research on the topic.



