# Arxiv Papers in cs.CV on 2016-03-02
### US-Cut: Interactive Algorithm for rapid Detection and Segmentation of Liver Tumors in Ultrasound Acquisitions
- **Arxiv ID**: http://arxiv.org/abs/1603.00546v1
- **DOI**: 10.1117/12.2216509
- **Categories**: **cs.CV**, cs.CE, cs.CG, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1603.00546v1)
- **Published**: 2016-03-02 01:42:48+00:00
- **Updated**: 2016-03-02 01:42:48+00:00
- **Authors**: Jan Egger, Philip Voglreiter, Mark Dokter, Michael Hofmann, Xiaojun Chen, Wolfram G. Zoller, Dieter Schmalstieg, Alexander Hann
- **Comment**: 6 pages, 6 figures, 1 table, 32 references
- **Journal**: SPIE Medical Imaging Conference 2016, Paper 9790-47
- **Summary**: Ultrasound (US) is the most commonly used liver imaging modality worldwide. It plays an important role in follow-up of cancer patients with liver metastases. We present an interactive segmentation approach for liver tumors in US acquisitions. Due to the low image quality and the low contrast between the tumors and the surrounding tissue in US images, the segmentation is very challenging. Thus, the clinical practice still relies on manual measurement and outlining of the tumors in the US images. We target this problem by applying an interactive segmentation algorithm to the US data, allowing the user to get real-time feedback of the segmentation results. The algorithm has been developed and tested hand-in-hand by physicians and computer scientists to make sure a future practical usage in a clinical setting is feasible. To cover typical acquisitions from the clinical routine, the approach has been evaluated with dozens of datasets where the tumors are hyperechoic (brighter), hypoechoic (darker) or isoechoic (similar) in comparison to the surrounding liver tissue. Due to the interactive real-time behavior of the approach, it was possible even in difficult cases to find satisfying segmentations of the tumors within seconds and without parameter settings, and the average tumor deviation was only 1.4mm compared with manual measurements. However, the long term goal is to ease the volumetric acquisition of liver tumors in order to evaluate for treatment response. Additional aim is the registration of intraoperative US images via the interactive segmentations to the patient's pre-interventional CT acquisitions.



### Synthesized Classifiers for Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1603.00550v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00550v3)
- **Published**: 2016-03-02 01:59:22+00:00
- **Updated**: 2016-05-27 21:48:48+00:00
- **Authors**: Soravit Changpinyo, Wei-Lun Chao, Boqing Gong, Fei Sha
- **Comment**: None
- **Journal**: None
- **Summary**: Given semantic descriptions of object classes, zero-shot learning aims to accurately recognize objects of the unseen classes, from which no examples are available at the training stage, by associating them to the seen classes, from which labeled examples are provided. We propose to tackle this problem from the perspective of manifold learning. Our main idea is to align the semantic space that is derived from external information to the model space that concerns itself with recognizing visual features. To this end, we introduce a set of "phantom" object classes whose coordinates live in both the semantic space and the model space. Serving as bases in a dictionary, they can be optimized from labeled data such that the synthesized real object classifiers achieve optimal discriminative performance. We demonstrate superior accuracy of our approach over the state of the art on four benchmark datasets for zero-shot learning, including the full ImageNet Fall 2011 dataset with more than 20,000 unseen classes.



### Learnt quasi-transitive similarity for retrieval from large collections of faces
- **Arxiv ID**: http://arxiv.org/abs/1603.00560v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00560v2)
- **Published**: 2016-03-02 03:04:37+00:00
- **Updated**: 2016-04-14 01:34:24+00:00
- **Authors**: Ognjen Arandjelovic
- **Comment**: International Conference on Computer Vision and Pattern Recognition,
  2016
- **Journal**: None
- **Summary**: We are interested in identity-based retrieval of face sets from large unlabelled collections acquired in uncontrolled environments. Given a baseline algorithm for measuring the similarity of two face sets, the meta-algorithm introduced in this paper seeks to leverage the structure of the data corpus to make the best use of the available baseline. In particular, we show how partial transitivity of inter-personal similarity can be exploited to improve the retrieval of particularly challenging sets which poorly match the query under the baseline measure. We: (i) describe the use of proxy sets as a means of computing the similarity between two sets, (ii) introduce transitivity meta-features based on the similarity of salient modes of appearance variation between sets, (iii) show how quasi-transitivity can be learnt from such features without any labelling or manual intervention, and (iv) demonstrate the effectiveness of the proposed methodology through experiments on the notoriously challenging YouTube database and two successful baselines from the literature.



### Flies as Ship Captains? Digital Evolution Unravels Selective Pressures to Avoid Collision in Drosophila
- **Arxiv ID**: http://arxiv.org/abs/1603.00802v1
- **DOI**: 10.7551/978-0-262-33936-0-ch089
- **Categories**: **q-bio.PE**, cs.CV, nlin.AO, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1603.00802v1)
- **Published**: 2016-03-02 17:36:31+00:00
- **Updated**: 2016-03-02 17:36:31+00:00
- **Authors**: Ali Tehrani-Saleh, Christoph Adami
- **Comment**: 8 pages, 10 figures, submitted to 15th Artificial Life conference
  (ALife 2016)
- **Journal**: Proceedings Artificial Life 15 (C. Gershenson, T. Froese, J.M.
  Sisqueiros, W. Aguilar, E.J. Izquierdo, H. Sayama, eds.) MIT Press
  (Cambridge, MA, 2016), pp. 554-561
- **Summary**: Flies that walk in a covered planar arena on straight paths avoid colliding with each other, but which of the two flies stops is not random. High-throughput video observations, coupled with dedicated experiments with controlled robot flies have revealed that flies utilize the type of optic flow on their retina as a determinant of who should stop, a strategy also used by ship captains to determine which of two ships on a collision course should throw engines in reverse. We use digital evolution to test whether this strategy evolves when collision avoidance is the sole penalty. We find that the strategy does indeed evolve in a narrow range of cost/benefit ratios, for experiments in which the "regressive motion" cue is error free. We speculate that these stringent conditions may not be sufficient to evolve the strategy in real flies, pointing perhaps to auxiliary costs and benefits not modeled in our study



### A Nonlinear Weighted Total Variation Image Reconstruction Algorithm for Electrical Capacitance Tomography
- **Arxiv ID**: http://arxiv.org/abs/1603.00816v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00816v2)
- **Published**: 2016-03-02 18:24:32+00:00
- **Updated**: 2016-11-21 15:01:41+00:00
- **Authors**: Kezhi Li, Daniel Holland
- **Comment**: None
- **Journal**: None
- **Summary**: A new iterative image reconstruction algorithm for electrical capacitance tomography (ECT) is proposed that is based on iterative soft thresholding of a total variation penalty and adaptive reweighted compressive sensing. This algorithm encourages sharp changes in the ECT image and overcomes the disadvantage of the $l_1$ minimization by equipping the total variation with an adaptive weighting depending on the reconstructed image. Moreover, the non-linear effect is also partially reduced due to the adoption of an updated sensitivity matrix. Simulation results show that the proposed algorithm recovers ECT images more precisely than existing state-of-the-art algorithms and therefore is suitable for the imaging of multiphase systems in industrial or medical applications.



### MOT16: A Benchmark for Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1603.00831v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00831v2)
- **Published**: 2016-03-02 19:07:56+00:00
- **Updated**: 2016-05-03 23:55:38+00:00
- **Authors**: Anton Milan, Laura Leal-Taixe, Ian Reid, Stefan Roth, Konrad Schindler
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1504.01942
- **Journal**: None
- **Summary**: Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for reseach.   Recently, a new benchmark for Multiple Object Tracking, MOTChallenge, was launched with the goal of collecting existing and new data and creating a framework for the standardized evaluation of multiple object tracking methods. The first release of the benchmark focuses on multiple people tracking, since pedestrians are by far the most studied object in the tracking community. This paper accompanies a new release of the MOTChallenge benchmark. Unlike the initial release, all videos of MOT16 have been carefully annotated following a consistent protocol. Moreover, it not only offers a significant increase in the number of labeled boxes, but also provides multiple object classes beside pedestrians and the level of visibility for every single object of interest.



### Automatic segmentation of lizard spots using an active contour model
- **Arxiv ID**: http://arxiv.org/abs/1603.00841v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00841v1)
- **Published**: 2016-03-02 19:42:55+00:00
- **Updated**: 2016-03-02 19:42:55+00:00
- **Authors**: Jhony Giraldo, Augusto Salazar
- **Comment**: None
- **Journal**: None
- **Summary**: Animal biometrics is a challenging task. In the literature, many algorithms have been used, e.g. penguin chest recognition, elephant ears recognition and leopard stripes pattern recognition, but to use technology to a large extent in this area of research, still a lot of work has to be done. One important target in animal biometrics is to automate the segmentation process, so in this paper we propose a segmentation algorithm for extracting the spots of Diploglossus millepunctatus, an endangered lizard species. The automatic segmentation is achieved with a combination of preprocessing, active contours and morphology. The parameters of each stage of the segmentation algorithm are found using an optimization procedure, which is guided by the ground truth. The results show that automatic segmentation of spots is possible. A 78.37 % of correct segmentation in average is reached.



### Shallow and Deep Convolutional Networks for Saliency Prediction
- **Arxiv ID**: http://arxiv.org/abs/1603.00845v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1603.00845v1)
- **Published**: 2016-03-02 19:54:02+00:00
- **Updated**: 2016-03-02 19:54:02+00:00
- **Authors**: Junting Pan, Kevin McGuinness, Elisa Sayrol, Noel O'Connor, Xavier Giro-i-Nieto
- **Comment**: Preprint of the paper accepted at 2016 IEEE Conference on Computer
  Vision and Pattern Recognition (CVPR). Source code and models available at
  https://github.com/imatge-upc/saliency-2016-cvpr. Junting Pan and Kevin
  McGuinness contributed equally to this work
- **Journal**: None
- **Summary**: The prediction of salient areas in images has been traditionally addressed with hand-crafted features based on neuroscience principles. This paper, however, addresses the problem with a completely data-driven approach by training a convolutional neural network (convnet). The learning process is formulated as a minimization of a loss function that measures the Euclidean distance of the predicted saliency map with the provided ground truth. The recent publication of large datasets of saliency prediction has provided enough data to train end-to-end architectures that are both fast and accurate. Two designs are proposed: a shallow convnet trained from scratch, and a another deeper solution whose first three layers are adapted from another network trained for classification. To the authors knowledge, these are the first end-to-end CNNs trained and tested for the purpose of saliency prediction.



### LiDAR Ground Filtering Algorithm for Urban Areas Using Scan Line Based Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1603.00912v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.00912v1)
- **Published**: 2016-03-02 22:09:45+00:00
- **Updated**: 2016-03-02 22:09:45+00:00
- **Authors**: Lei Wang, Yongun Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper addresses the task of separating ground points from airborne LiDAR point cloud data in urban areas. A novel ground filtering method using scan line segmentation is proposed here, which we call SLSGF. It utilizes the scan line information in LiDAR data to segment the LiDAR data. The similarity measurements are designed to make it possible to segment complex roof structures into a single segment as much as possible so the topological relationships between the roof and the ground are simpler, which will benefit the labeling process. In the labeling process, the initial ground segments are detected and a coarse to fine labeling scheme is applied. Data from ISPRS 2011 are used to test the accuracy of SLSGF; and our analytical and experimental results show that this method is computationally-efficient and noise-insensitive, thereby making a denoising process unnecessary before filtering.



