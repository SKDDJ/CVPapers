# Arxiv Papers in cs.CV on 2016-03-26
### Recognizing Car Fluents from Video
- **Arxiv ID**: http://arxiv.org/abs/1603.08067v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08067v1)
- **Published**: 2016-03-26 03:45:00+00:00
- **Updated**: 2016-03-26 03:45:00+00:00
- **Authors**: Bo Li, Tianfu Wu, Caiming Xiong, Song-Chun Zhu
- **Comment**: Accepted by CVPR 2016
- **Journal**: None
- **Summary**: Physical fluents, a term originally used by Newton [40], refers to time-varying object states in dynamic scenes. In this paper, we are interested in inferring the fluents of vehicles from video. For example, a door (hood, trunk) is open or closed through various actions, light is blinking to turn. Recognizing these fluents has broad applications, yet have received scant attention in the computer vision literature. Car fluent recognition entails a unified framework for car detection, car part localization and part status recognition, which is made difficult by large structural and appearance variations, low resolutions and occlusions. This paper learns a spatial-temporal And-Or hierarchical model to represent car fluents. The learning of this model is formulated under the latent structural SVM framework. Since there are no publicly related dataset, we collect and annotate a car fluent dataset consisting of car videos with diverse fluents. In experiments, the proposed method outperforms several highly related baseline methods in terms of car fluent recognition and car part localization.



### A generalized flow for multi-class and binary classification tasks: An Azure ML approach
- **Arxiv ID**: http://arxiv.org/abs/1603.08070v1
- **DOI**: 10.1109/BigData.2015.7363944
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08070v1)
- **Published**: 2016-03-26 03:55:53+00:00
- **Updated**: 2016-03-26 03:55:53+00:00
- **Authors**: Matthew Bihis, Sohini Roychowdhury
- **Comment**: 10 pages, 7 figures, Conference
- **Journal**: Big Data (Big Data), 2015 IEEE International Conference on, Santa
  Clara, CA, 2015, pp. 1728-1737
- **Summary**: The constant growth in the present day real-world databases pose computational challenges for a single computer. Cloud-based platforms, on the other hand, are capable of handling large volumes of information manipulation tasks, thereby necessitating their use for large real-world data set computations. This work focuses on creating a novel Generalized Flow within the cloud-based computing platform: Microsoft Azure Machine Learning Studio (MAMLS) that accepts multi-class and binary classification data sets alike and processes them to maximize the overall classification accuracy. First, each data set is split into training and testing data sets, respectively. Then, linear and nonlinear classification model parameters are estimated using the training data set. Data dimensionality reduction is then performed to maximize classification accuracy. For multi-class data sets, data centric information is used to further improve overall classification accuracy by reducing the multi-class classification to a series of hierarchical binary classification tasks. Finally, the performance of optimized classification model thus achieved is evaluated and scored on the testing data set. The classification characteristics of the proposed flow are comparatively evaluated on 3 public data sets and a local data set with respect to existing state-of-the-art methods. On the 3 public data sets, the proposed flow achieves 78-97.5% classification accuracy. Also, the local data set, created using the information regarding presence of Diabetic Retinopathy lesions in fundus images, results in 85.3-95.7% average classification accuracy, which is higher than the existing methods. Thus, the proposed generalized flow can be useful for a wide range of application-oriented "big data sets".



### Classification of Large-Scale Fundus Image Data Sets: A Cloud-Computing Framework
- **Arxiv ID**: http://arxiv.org/abs/1603.08071v1
- **DOI**: 10.1109/EMBC.2016.7591423
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08071v1)
- **Published**: 2016-03-26 04:07:30+00:00
- **Updated**: 2016-03-26 04:07:30+00:00
- **Authors**: Sohini Roychowdhury
- **Comment**: 4 pages, 6 figures, [Submitted], 38th Annual International Conference
  of the IEEE Engineering in Medicine and Biology Society 2016
- **Journal**: None
- **Summary**: Large medical image data sets with high dimensionality require substantial amount of computation time for data creation and data processing. This paper presents a novel generalized method that finds optimal image-based feature sets that reduce computational time complexity while maximizing overall classification accuracy for detection of diabetic retinopathy (DR). First, region-based and pixel-based features are extracted from fundus images for classification of DR lesions and vessel-like structures. Next, feature ranking strategies are used to distinguish the optimal classification feature sets. DR lesion and vessel classification accuracies are computed using the boosted decision tree and decision forest classifiers in the Microsoft Azure Machine Learning Studio platform, respectively. For images from the DIARETDB1 data set, 40 of its highest-ranked features are used to classify four DR lesion types with an average classification accuracy of 90.1% in 792 seconds. Also, for classification of red lesion regions and hemorrhages from microaneurysms, accuracies of 85% and 72% are observed, respectively. For images from STARE data set, 40 high-ranked features can classify minor blood vessels with an accuracy of 83.5% in 326 seconds. Such cloud-based fundus image analysis systems can significantly enhance the borderline classification performances in automated screening systems.



### Do You See What I Mean? Visual Resolution of Linguistic Ambiguities
- **Arxiv ID**: http://arxiv.org/abs/1603.08079v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1603.08079v1)
- **Published**: 2016-03-26 06:49:33+00:00
- **Updated**: 2016-03-26 06:49:33+00:00
- **Authors**: Yevgeni Berzak, Andrei Barbu, Daniel Harari, Boris Katz, Shimon Ullman
- **Comment**: EMNLP 2015
- **Journal**: Conference on Empirical Methods in Natural Language Processing
  (EMNLP), 2015, pages 1477--1487
- **Summary**: Understanding language goes hand in hand with the ability to integrate complex contextual information obtained via perception. In this work, we present a novel task for grounded language understanding: disambiguating a sentence given a visual scene which depicts one of the possible interpretations of that sentence. To this end, we introduce a new multimodal corpus containing ambiguous sentences, representing a wide range of syntactic, semantic and discourse ambiguities, coupled with videos that visualize the different interpretations for each sentence. We address this task by extending a vision model which determines if a sentence is depicted by a video. We demonstrate how such a model can be adjusted to recognize different interpretations of the same underlying sentence, allowing to disambiguate sentences in a unified fashion across the different ambiguity types.



### On Fast Bilateral Filtering using Fourier Kernels
- **Arxiv ID**: http://arxiv.org/abs/1603.08081v1
- **DOI**: 10.1109/LSP.2016.2539982
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08081v1)
- **Published**: 2016-03-26 07:09:58+00:00
- **Updated**: 2016-03-26 07:09:58+00:00
- **Authors**: Sanjay Ghosh, Kunal N. Chaudhury
- **Comment**: To appear in IEEE Signal Processing Letters (5 pages, 3 figures)
- **Journal**: None
- **Summary**: It was demonstrated in earlier work that, by approximating its range kernel using shiftable functions, the non-linear bilateral filter can be computed using a series of fast convolutions. Previous approaches based on shiftable approximation have, however, been restricted to Gaussian range kernels. In this work, we propose a novel approximation that can be applied to any range kernel, provided it has a pointwise-convergent Fourier series. More specifically, we propose to approximate the Gaussian range kernel of the bilateral filter using a Fourier basis, where the coefficients of the basis are obtained by solving a series of least-squares problems. The coefficients can be efficiently computed using a recursive form of the QR decomposition. By controlling the cardinality of the Fourier basis, we can obtain a good tradeoff between the run-time and the filtering accuracy. In particular, we are able to guarantee sub-pixel accuracy for the overall filtering, which is not provided by most existing methods for fast bilateral filtering. We present simulation results to demonstrate the speed and accuracy of the proposed algorithm.



### Learning Hough Regression Models via Bridge Partial Least Squares for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1603.08092v1
- **DOI**: 10.1016/j.neucom.2014.10.071
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08092v1)
- **Published**: 2016-03-26 09:33:30+00:00
- **Updated**: 2016-03-26 09:33:30+00:00
- **Authors**: Jianyu Tang, Hanzi Wang, Yan Yan
- **Comment**: None
- **Journal**: Neurocomputing, 2015,152(3):236-249
- **Summary**: Popular Hough Transform-based object detection approaches usually construct an appearance codebook by clustering local image features. However, how to choose appropriate values for the parameters used in the clustering step remains an open problem. Moreover, some popular histogram features extracted from overlapping image blocks may cause a high degree of redundancy and multicollinearity. In this paper, we propose a novel Hough Transform-based object detection approach. First, to address the above issues, we exploit a Bridge Partial Least Squares (BPLS) technique to establish context-encoded Hough Regression Models (HRMs), which are linear regression models that cast probabilistic Hough votes to predict object locations. BPLS is an efficient variant of Partial Least Squares (PLS). PLS-based regression techniques (including BPLS) can reduce the redundancy and eliminate the multicollinearity of a feature set. And the appropriate value of the only parameter used in PLS (i.e., the number of latent components) can be determined by using a cross-validation procedure. Second, to efficiently handle object scale changes, we propose a novel multi-scale voting scheme. In this scheme, multiple Hough images corresponding to multiple object scales can be obtained simultaneously. Third, an object in a test image may correspond to multiple true and false positive hypotheses at different scales. Based on the proposed multi-scale voting scheme, a principled strategy is proposed to fuse hypotheses to reduce false positives by evaluating normalized pointwise mutual information between hypotheses. In the experiments, we also compare the proposed HRM approach with its several variants to evaluate the influences of its components on its performance. Experimental results show that the proposed HRM approach has achieved desirable performances on popular benchmark datasets.



### Blind signal separation and identification of mixtures of images
- **Arxiv ID**: http://arxiv.org/abs/1603.08095v1
- **DOI**: 10.1109/ACSSC.2009
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08095v1)
- **Published**: 2016-03-26 10:04:41+00:00
- **Updated**: 2016-03-26 10:04:41+00:00
- **Authors**: Felipe P. do Carmo, Joaquim T. de Assis, Vania V. Estrela, Alessandra M. Coelho
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: In this paper, a fresh procedure to handle image mixtures by means of blind signal separation relying on a combination of second order and higher order statistics techniques are introduced. The problem of blind signal separation is reassigned to the wavelet domain. The key idea behind this method is that the image mixture can be decomposed into the sum of uncorrelated and/or independent sub-bands using wavelet transform. Initially, the observed image is pre-whitened in the space domain. Afterwards, an initial separation matrix is estimated from the second order statistics de-correlation model in the wavelet domain. Later, this matrix will be used as an initial separation matrix for the higher order statistics stage in order to find the best separation matrix. The suggested algorithm was tested using natural images.Experiments have confirmed that the use of the proposed process provides promising outcomes in identifying an image from noisy mixtures of images.



### Unsupervised Domain Adaptation in the Wild: Dealing with Asymmetric Label Sets
- **Arxiv ID**: http://arxiv.org/abs/1603.08105v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08105v1)
- **Published**: 2016-03-26 13:22:55+00:00
- **Updated**: 2016-03-26 13:22:55+00:00
- **Authors**: Ayush Mittal, Anant Raj, Vinay P. Namboodiri, Tinne Tuytelaars
- **Comment**: supplementary material:
  http://home.iitk.ac.in/~ayushmi/supplementary-material-unsupervised.pdf
- **Journal**: None
- **Summary**: The goal of domain adaptation is to adapt models learned on a source domain to a particular target domain. Most methods for unsupervised domain adaptation proposed in the literature to date, assume that the set of classes present in the target domain is identical to the set of classes present in the source domain. This is a restrictive assumption that limits the practical applicability of unsupervised domain adaptation techniques in real world settings ("in the wild"). Therefore, we relax this constraint and propose a technique that allows the set of target classes to be a subset of the source classes. This way, large publicly available annotated datasets with a wide variety of classes can be used as source, even if the actual set of classes in target can be more limited and, maybe most importantly, unknown beforehand.   To this end, we propose an algorithm that orders a set of source subspaces that are relevant to the target classification problem. Our method then chooses a restricted set from this ordered set of source subspaces. As an extension, even starting from multiple source datasets with varied sets of categories, this method automatically selects an appropriate subset of source categories relevant to a target dataset. Empirical analysis on a number of source and target domain datasets shows that restricting the source subspace to only a subset of categories does indeed substantially improve the eventual target classification accuracy over the baseline that considers all source classes.



### Support Driven Wavelet Frame-based Image Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1603.08108v1
- **DOI**: None
- **Categories**: **cs.CV**, 90C26, I.4.3
- **Links**: [PDF](http://arxiv.org/pdf/1603.08108v1)
- **Published**: 2016-03-26 13:45:01+00:00
- **Updated**: 2016-03-26 13:45:01+00:00
- **Authors**: Liangtian He, Yilun Wang, Zhaoyin Xiang
- **Comment**: None
- **Journal**: None
- **Summary**: The wavelet frame systems have been playing an active role in image restoration and many other image processing fields over the past decades, owing to the good capability of sparsely approximating piece-wise smooth functions such as images. In this paper, we propose a novel wavelet frame based sparse recovery model called \textit{Support Driven Sparse Regularization} (SDSR) for image deblurring, where the partial support information of frame coefficients is attained via a self-learning strategy and exploited via the proposed truncated $\ell_0$ regularization. Moreover, the state-of-the-art image restoration methods can be naturally incorporated into our proposed wavelet frame based sparse recovery framework. In particular, in order to achieve reliable support estimation of the frame coefficients, we make use of the state-of-the-art image restoration result such as that from the IDD-BM3D method as the initial reference image for support estimation. Our extensive experimental results have shown convincing improvements over existing state-of-the-art deblurring methods.



### Fast and Provably Accurate Bilateral Filtering
- **Arxiv ID**: http://arxiv.org/abs/1603.08109v1
- **DOI**: 10.1109/TIP.2016.2548363
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08109v1)
- **Published**: 2016-03-26 14:05:34+00:00
- **Updated**: 2016-03-26 14:05:34+00:00
- **Authors**: Kunal N. Chaudhury, Swapnil D. Dabhade
- **Comment**: To appear in IEEE Transactions on Image Processing (10 pages, 10
  figures, 4 tables)
- **Journal**: None
- **Summary**: The bilateral filter is a non-linear filter that uses a range filter along with a spatial filter to perform edge-preserving smoothing of images. A direct computation of the bilateral filter requires $O(S)$ operations per pixel, where $S$ is the size of the support of the spatial filter. In this paper, we present a fast and provably accurate algorithm for approximating the bilateral filter when the range kernel is Gaussian. In particular, for box and Gaussian spatial filters, the proposed algorithm can cut down the complexity to $O(1)$ per pixel for any arbitrary $S$. The algorithm has a simple implementation involving $N+1$ spatial filterings, where $N$ is the approximation order. We give a detailed analysis of the filtering accuracy that can be achieved by the proposed approximation in relation to the target bilateral filter. This allows us to to estimate the order $N$ required to obtain a given accuracy. We also present comprehensive numerical results to demonstrate that the proposed algorithm is competitive with state-of-the-art methods in terms of speed and accuracy.



### Nonrigid Optical Flow Ground Truth for Real-World Scenes with Time-Varying Shading Effects
- **Arxiv ID**: http://arxiv.org/abs/1603.08120v3
- **DOI**: 10.1109/LRA.2016.2592513
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08120v3)
- **Published**: 2016-03-26 16:08:13+00:00
- **Updated**: 2016-07-15 12:39:03+00:00
- **Authors**: Wenbin Li, Darren Cosker, Zhihan Lv, Matthew Brown
- **Comment**: preprint of our paper accepted by RA-L'16
- **Journal**: None
- **Summary**: In this paper we present a dense ground truth dataset of nonrigidly deforming real-world scenes. Our dataset contains both long and short video sequences, and enables the quantitatively evaluation for RGB based tracking and registration methods. To construct ground truth for the RGB sequences, we simultaneously capture Near-Infrared (NIR) image sequences where dense markers - visible only in NIR - represent ground truth positions. This allows for comparison with automatically tracked RGB positions and the formation of error metrics. Most previous datasets containing nonrigidly deforming sequences are based on synthetic data. Our capture protocol enables us to acquire real-world deforming objects with realistic photometric effects - such as blur and illumination change - as well as occlusion and complex deformations. A public evaluation website is constructed to allow for ranking of RGB image based optical flow and other dense tracking algorithms, with various statistical measures. Furthermore, we present an RGB-NIR multispectral optical flow model allowing for energy optimization by adoptively combining featured information from both the RGB and the complementary NIR channels. In our experiments we evaluate eight existing RGB based optical flow methods on our new dataset. We also evaluate our hybrid optical flow algorithm by comparing to two existing multispectral approaches, as well as varying our input channels across RGB, NIR and RGB-NIR.



### Video Interpolation using Optical Flow and Laplacian Smoothness
- **Arxiv ID**: http://arxiv.org/abs/1603.08124v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08124v1)
- **Published**: 2016-03-26 17:13:25+00:00
- **Updated**: 2016-03-26 17:13:25+00:00
- **Authors**: Wenbin Li, Darren Cosker
- **Comment**: None
- **Journal**: None
- **Summary**: Non-rigid video interpolation is a common computer vision task. In this paper we present an optical flow approach which adopts a Laplacian Cotangent Mesh constraint to enhance the local smoothness. Similar to Li et al., our approach adopts a mesh to the image with a resolution up to one vertex per pixel and uses angle constraints to ensure sensible local deformations between image pairs. The Laplacian Mesh constraints are expressed wholly inside the optical flow optimization, and can be applied in a straightforward manner to a wide range of image tracking and registration problems. We evaluate our approach by testing on several benchmark datasets, including the Middlebury and Garg et al. datasets. In addition, we show application of our method for constructing 3D Morphable Facial Models from dynamic 3D data.



### How useful is photo-realistic rendering for visual learning?
- **Arxiv ID**: http://arxiv.org/abs/1603.08152v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.08152v2)
- **Published**: 2016-03-26 22:56:53+00:00
- **Updated**: 2016-09-08 03:43:58+00:00
- **Authors**: Yair Movshovitz-Attias, Takeo Kanade, Yaser Sheikh
- **Comment**: Published in GMDL 2016 In conjunction with ECCV 2016
- **Journal**: None
- **Summary**: Data seems cheap to get, and in many ways it is, but the process of creating a high quality labeled dataset from a mass of data is time-consuming and expensive.   With the advent of rich 3D repositories, photo-realistic rendering systems offer the opportunity to provide nearly limitless data. Yet, their primary value for visual learning may be the quality of the data they can provide rather than the quantity. Rendering engines offer the promise of perfect labels in addition to the data: what the precise camera pose is; what the precise lighting location, temperature, and distribution is; what the geometry of the object is.   In this work we focus on semi-automating dataset creation through use of synthetic data and apply this method to an important task -- object viewpoint estimation. Using state-of-the-art rendering software we generate a large labeled dataset of cars rendered densely in viewpoint space. We investigate the effect of rendering parameters on estimation performance and show realism is important. We show that generalizing from synthetic data is not harder than the domain adaptation required between two real-image datasets and that combining synthetic images with a small amount of real data improves estimation accuracy.



