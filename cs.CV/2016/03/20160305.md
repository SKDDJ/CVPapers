# Arxiv Papers in cs.CV on 2016-03-05
### Network Morphism
- **Arxiv ID**: http://arxiv.org/abs/1603.01670v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1603.01670v2)
- **Published**: 2016-03-05 02:06:43+00:00
- **Updated**: 2016-03-08 16:36:00+00:00
- **Authors**: Tao Wei, Changhu Wang, Yong Rui, Chang Wen Chen
- **Comment**: Under review for ICML 2016
- **Journal**: None
- **Summary**: We present in this paper a systematic study on how to morph a well-trained neural network to a new one so that its network function can be completely preserved. We define this as \emph{network morphism} in this research. After morphing a parent network, the child network is expected to inherit the knowledge from its parent network and also has the potential to continue growing into a more powerful one with much shortened training time. The first requirement for this network morphism is its ability to handle diverse morphing types of networks, including changes of depth, width, kernel size, and even subnet. To meet this requirement, we first introduce the network morphism equations, and then develop novel morphing algorithms for all these morphing types for both classic and convolutional neural networks. The second requirement for this network morphism is its ability to deal with non-linearity in a network. We propose a family of parametric-activation functions to facilitate the morphing of any continuous non-linear activation neurons. Experimental results on benchmark datasets and typical neural networks demonstrate the effectiveness of the proposed network morphism scheme.



### Saliency Detection combining Multi-layer Integration algorithm with background prior and energy function
- **Arxiv ID**: http://arxiv.org/abs/1603.01684v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.01684v1)
- **Published**: 2016-03-05 06:12:44+00:00
- **Updated**: 2016-03-05 06:12:44+00:00
- **Authors**: Hanling Zhang, Chenxing Xia
- **Comment**: 25 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1505.07192 by other authors
- **Journal**: None
- **Summary**: In this paper, we propose an improved mechanism for saliency detection. Firstly,based on a neoteric background prior selecting four corners of an image as background,we use color and spatial contrast with each superpixel to obtain a salinecy map(CBP). Inspired by reverse-measurement methods to improve the accuracy of measurement in Engineering,we employ the Objectness labels as foreground prior based on part of information of CBP to construct a map(OFP).Further,an original energy function is applied to optimize both of them respectively and a single-layer saliency map(SLP)is formed by merging the above twos.Finally,to deal with the scale problem,we obtain our multi-layer map(MLP) by presenting an integration algorithm to take advantage of multiple saliency maps. Quantitative and qualitative experiments on three datasets demonstrate that our method performs favorably against the state-of-the-art algorithm.



### Underwater Fish Tracking for Moving Cameras based on Deformable Multiple Kernels
- **Arxiv ID**: http://arxiv.org/abs/1603.01695v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.01695v1)
- **Published**: 2016-03-05 08:20:25+00:00
- **Updated**: 2016-03-05 08:20:25+00:00
- **Authors**: Meng-Che Chuang, Jenq-Neng Hwang, Jian-Hui Ye, Shih-Chia Huang, Kresimir Williams
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: Fishery surveys that call for the use of single or multiple underwater cameras have been an emerging technology as a non-extractive mean to estimate the abundance of fish stocks. Tracking live fish in an open aquatic environment posts challenges that are different from general pedestrian or vehicle tracking in surveillance applications. In many rough habitats fish are monitored by cameras installed on moving platforms, where tracking is even more challenging due to inapplicability of background models. In this paper, a novel tracking algorithm based on the deformable multiple kernels (DMK) is proposed to address these challenges. Inspired by the deformable part model (DPM) technique, a set of kernels is defined to represent the holistic object and several parts that are arranged in a deformable configuration. Color histogram, texture histogram and the histogram of oriented gradients (HOG) are extracted and serve as object features. Kernel motion is efficiently estimated by the mean-shift algorithm on color and texture features to realize tracking. Furthermore, the HOG-feature deformation costs are adopted as soft constraints on kernel positions to maintain the part configuration. Experimental results on practical video set from underwater moving cameras show the reliable performance of the proposed method with much less computational cost comparing with state-of-the-art techniques.



### A Feature Learning and Object Recognition Framework for Underwater Fish Images
- **Arxiv ID**: http://arxiv.org/abs/1603.01696v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.01696v1)
- **Published**: 2016-03-05 08:33:18+00:00
- **Updated**: 2016-03-05 08:33:18+00:00
- **Authors**: Meng-Che Chuang, Jenq-Neng Hwang, Kresimir Williams
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: Live fish recognition is one of the most crucial elements of fisheries survey applications where vast amount of data are rapidly acquired. Different from general scenarios, challenges to underwater image recognition are posted by poor image quality, uncontrolled objects and environment, as well as difficulty in acquiring representative samples. Also, most existing feature extraction techniques are hindered from automation due to involving human supervision. Toward this end, we propose an underwater fish recognition framework that consists of a fully unsupervised feature learning technique and an error-resilient classifier. Object parts are initialized based on saliency and relaxation labeling to match object parts correctly. A non-rigid part model is then learned based on fitness, separation and discrimination criteria. For the classifier, an unsupervised clustering approach generates a binary class hierarchy, where each node is a classifier. To exploit information from ambiguous images, the notion of partial classification is introduced to assign coarse labels by optimizing the "benefit" of indecision made by the classifier. Experiments show that the proposed framework achieves high accuracy on both public and self-collected underwater fish images with high uncertainty and class imbalance.



### Grading of Mammalian Cumulus Oocyte Complexes using Machine Learning for in Vitro Embryo Culture
- **Arxiv ID**: http://arxiv.org/abs/1603.01739v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1603.01739v1)
- **Published**: 2016-03-05 16:27:43+00:00
- **Updated**: 2016-03-05 16:27:43+00:00
- **Authors**: Viswanath P Sudarshan, Tobias Weiser, Phalgun Chintala, Subhamoy Mandal, Rahul Dutta
- **Comment**: IEEE BHI 2016
- **Journal**: None
- **Summary**: Visual observation of Cumulus Oocyte Complexes provides only limited information about its functional competence, whereas the molecular evaluations methods are cumbersome or costly. Image analysis of mammalian oocytes can provide attractive alternative to address this challenge. However, it is complex, given the huge number of oocytes under inspection and the subjective nature of the features inspected for identification. Supervised machine learning methods like random forest with annotations from expert biologists can make the analysis task standardized and reduces inter-subject variability. We present a semi-automatic framework for predicting the class an oocyte belongs to, based on multi-object parametric segmentation on the acquired microscopic image followed by a feature based classification using random forests.



### Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artworks
- **Arxiv ID**: http://arxiv.org/abs/1603.01768v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.01768v1)
- **Published**: 2016-03-05 23:09:51+00:00
- **Updated**: 2016-03-05 23:09:51+00:00
- **Authors**: Alex J. Champandard
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have proven highly effective at image synthesis and style transfer. For most users, however, using them as tools can be a challenging task due to their unpredictable behavior that goes against common intuitions. This paper introduces a novel concept to augment such generative architectures with semantic annotations, either by manually authoring pixel labels or using existing solutions for semantic segmentation. The result is a content-aware generative algorithm that offers meaningful control over the outcome. Thus, we increase the quality of images generated by avoiding common glitches, make the results look significantly more plausible, and extend the functional range of these algorithms---whether for portraits or landscapes, etc. Applications include semantic style transfer and turning doodles with few colors into masterful paintings!



