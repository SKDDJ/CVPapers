# Arxiv Papers in cs.CV on 2016-03-13
### An efficient Exact-PGA algorithm for constant curvature manifolds
- **Arxiv ID**: http://arxiv.org/abs/1603.03984v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.03984v1)
- **Published**: 2016-03-13 02:57:34+00:00
- **Updated**: 2016-03-13 02:57:34+00:00
- **Authors**: Rudrasis Chakraborty, Dohyung Seo, Baba C. Vemuri
- **Comment**: Accepted in CVPR (IEEE Conference on Computer Vision and Pattern
  Recognition) 2016
- **Journal**: None
- **Summary**: Manifold-valued datasets are widely encountered in many computer vision tasks. A non-linear analog of the PCA, called the Principal Geodesic Analysis (PGA) suited for data lying on Riemannian manifolds was reported in literature a decade ago. Since the objective function in PGA is highly non-linear and hard to solve efficiently in general, researchers have proposed a linear approximation. Though this linear approximation is easy to compute, it lacks accuracy especially when the data exhibits a large variance. Recently, an alternative called exact PGA was proposed which tries to solve the optimization without any linearization. For general Riemannian manifolds, though it gives better accuracy than the original (linearized) PGA, for data that exhibit large variance, the optimization is not computationally efficient. In this paper, we propose an efficient exact PGA for constant curvature Riemannian manifolds (CCM-EPGA). CCM-EPGA differs significantly from existing PGA algorithms in two aspects, (i) the distance between a given manifold-valued data point and the principal submanifold is computed analytically and thus no optimization is required as in existing methods. (ii) Unlike the existing PGA algorithms, the descent into codimension-1 submanifolds does not require any optimization but is accomplished through the use of the Rimeannian inverse Exponential map and the parallel transport operations. We present theoretical and experimental results for constant curvature Riemannian manifolds depicting favorable performance of CCM-EPGA compared to existing PGA algorithms. We also present data reconstruction from principal components and directions which has not been presented in literature in this setting.



### Learning Typographic Style
- **Arxiv ID**: http://arxiv.org/abs/1603.04000v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1603.04000v1)
- **Published**: 2016-03-13 05:44:57+00:00
- **Updated**: 2016-03-13 05:44:57+00:00
- **Authors**: Shumeet Baluja
- **Comment**: None
- **Journal**: None
- **Summary**: Typography is a ubiquitous art form that affects our understanding, perception, and trust in what we read. Thousands of different font-faces have been created with enormous variations in the characters. In this paper, we learn the style of a font by analyzing a small subset of only four letters. From these four letters, we learn two tasks. The first is a discrimination task: given the four letters and a new candidate letter, does the new letter belong to the same font? Second, given the four basis letters, can we generate all of the other letters with the same characteristics as those in the basis set? We use deep neural networks to address both tasks, quantitatively and qualitatively measure the results in a variety of novel manners, and present a thorough investigation of the weaknesses and strengths of the approach.



### Learning zeroth class dictionary for human action recognition
- **Arxiv ID**: http://arxiv.org/abs/1603.04015v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.04015v3)
- **Published**: 2016-03-13 10:20:25+00:00
- **Updated**: 2016-09-28 13:14:07+00:00
- **Authors**: Jia-xin Cai, Xin Tang, Lifang Zhang, Guocan Feng
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, a discriminative two-phase dictionary learning framework is proposed for classifying human action by sparse shape representations, in which the first-phase dictionary is learned on the selected discriminative frames and the second-phase dictionary is built for recognition using reconstruction errors of the first-phase dictionary as input features. We propose a "zeroth class" trick for detecting undiscriminating frames of the test video and eliminating them before voting on the action categories. Experimental results on benchmarks demonstrate the effectiveness of our method.



### A comprehensive study of sparse codes on abnormality detection
- **Arxiv ID**: http://arxiv.org/abs/1603.04026v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.04026v1)
- **Published**: 2016-03-13 13:13:10+00:00
- **Updated**: 2016-03-13 13:13:10+00:00
- **Authors**: Huamin Ren, Hong Pan, SÃ¸ren Ingvor Olsen, Thomas B. Moeslund
- **Comment**: 7 pages
- **Journal**: None
- **Summary**: Sparse representation has been applied successfully in abnormal event detection, in which the baseline is to learn a dictionary accompanied by sparse codes. While much emphasis is put on discriminative dictionary construction, there are no comparative studies of sparse codes regarding abnormality detection. We comprehensively study two types of sparse codes solutions - greedy algorithms and convex L1-norm solutions - and their impact on abnormality detection performance. We also propose our framework of combining sparse codes with different detection methods. Our comparative experiments are carried out from various angles to better understand the applicability of sparse codes, including computation time, reconstruction error, sparsity, detection accuracy, and their performance combining various detection methods. Experiments show that combining OMP codes with maximum coordinate detection could achieve state-of-the-art performance on the UCSD dataset [14].



### Pose for Action - Action for Pose
- **Arxiv ID**: http://arxiv.org/abs/1603.04037v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.04037v2)
- **Published**: 2016-03-13 15:09:35+00:00
- **Updated**: 2017-02-10 14:01:09+00:00
- **Authors**: Umar Iqbal, Martin Garbade, Juergen Gall
- **Comment**: Accepted to FG-2017
- **Journal**: None
- **Summary**: In this work we propose to utilize information about human actions to improve pose estimation in monocular videos. To this end, we present a pictorial structure model that exploits high-level information about activities to incorporate higher-order part dependencies by modeling action specific appearance models and pose priors. However, instead of using an additional expensive action recognition framework, the action priors are efficiently estimated by our pose estimation framework. This is achieved by starting with a uniform action prior and updating the action prior during pose estimation. We also show that learning the right amount of appearance sharing among action classes improves the pose estimation. We demonstrate the effectiveness of the proposed method on two challenging datasets for pose estimation and action recognition with over 80,000 test images.



### Deep Interactive Object Selection
- **Arxiv ID**: http://arxiv.org/abs/1603.04042v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.04042v1)
- **Published**: 2016-03-13 15:42:34+00:00
- **Updated**: 2016-03-13 15:42:34+00:00
- **Authors**: Ning Xu, Brian Price, Scott Cohen, Jimei Yang, Thomas Huang
- **Comment**: Computer Vision and Pattern Recognition
- **Journal**: None
- **Summary**: Interactive object selection is a very important research problem and has many applications. Previous algorithms require substantial user interactions to estimate the foreground and background distributions. In this paper, we present a novel deep learning based algorithm which has a much better understanding of objectness and thus can reduce user interactions to just a few clicks. Our algorithm transforms user provided positive and negative clicks into two Euclidean distance maps which are then concatenated with the RGB channels of images to compose (image, user interactions) pairs. We generate many of such pairs by combining several random sampling strategies to model user click patterns and use them to fine tune deep Fully Convolutional Networks (FCNs). Finally the output probability maps of our FCN 8s model is integrated with graph cut optimization to refine the boundary segments. Our model is trained on the PASCAL segmentation dataset and evaluated on other datasets with different object classes. Experimental results on both seen and unseen objects clearly demonstrate that our algorithm has a good generalization ability and is superior to all existing interactive object selection approaches.



### Image and Depth from a Single Defocused Image Using Coded Aperture Photography
- **Arxiv ID**: http://arxiv.org/abs/1603.04046v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1603.04046v1)
- **Published**: 2016-03-13 16:29:50+00:00
- **Updated**: 2016-03-13 16:29:50+00:00
- **Authors**: Mina Masoudifar, Hamid Reza Pourreza
- **Comment**: 18 pages, 14 figures, submitted
- **Journal**: None
- **Summary**: Depth from defocus and defocus deblurring from a single image are two challenging problems that are derived from the finite depth of field in conventional cameras. Coded aperture imaging is one of the techniques that is used for improving the results of these two problems. Up to now, different methods have been proposed for improving the results of either defocus deblurring or depth estimation. In this paper, a multi-objective function is proposed for evaluating and designing aperture patterns with the aim of improving the results of both depth from defocus and defocus deblurring. Pattern evaluation is performed by considering the scene illumination condition and camera system specification. Based on the proposed criteria, a single asymmetric pattern is designed that is used for restoring a sharp image and a depth map from a single input. Since the designed pattern is asymmetric, defocus objects on the two sides of the focal plane can be distinguished. Depth estimation is performed by using a new algorithm, which is based on image quality assessment criteria and can distinguish between blurred objects lying in front or behind the focal plane. Extensive simulations as well as experiments on a variety of real scenes are conducted to compare our aperture with previously proposed ones.



