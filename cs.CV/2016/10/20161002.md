# Arxiv Papers in cs.CV on 2016-10-02
### Deep Learning Algorithms for Signal Recognition in Long Perimeter Monitoring Distributed Fiber Optic Sensors
- **Arxiv ID**: http://arxiv.org/abs/1610.00279v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1610.00279v1)
- **Published**: 2016-10-02 13:46:47+00:00
- **Updated**: 2016-10-02 13:46:47+00:00
- **Authors**: A. V. Makarenko
- **Comment**: 11 pages, 7 figures, 2 tables. Slightly extended preprint of paper
  accepted for IEEE MLSP 2016
- **Journal**: None
- **Summary**: In this paper, we show an approach to build deep learning algorithms for recognizing signals in distributed fiber optic monitoring and security systems for long perimeters. Synthesizing such detection algorithms poses a non-trivial research and development challenge, because these systems face stringent error (type I and II) requirements and operate in difficult signal-jamming environments, with intensive signal-like jamming and a variety of changing possible signal portraits of possible recognized events. To address these issues, we have developed a twolevel event detection architecture, where the primary classifier is based on an ensemble of deep convolutional networks, can recognize 7 classes of signals and receives time-space data frames as input. Using real-life data, we have shown that the applied methods result in efficient and robust multiclass detection algorithms that have a high degree of adaptability.



### Deep Feature Consistent Variational Autoencoder
- **Arxiv ID**: http://arxiv.org/abs/1610.00291v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.00291v1)
- **Published**: 2016-10-02 15:48:36+00:00
- **Updated**: 2016-10-02 15:48:36+00:00
- **Authors**: Xianxu Hou, Linlin Shen, Ke Sun, Guoping Qiu
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel method for constructing Variational Autoencoder (VAE). Instead of using pixel-by-pixel loss, we enforce deep feature consistency between the input and the output of a VAE, which ensures the VAE's output to preserve the spatial correlation characteristics of the input, thus leading the output to have a more natural visual appearance and better perceptual quality. Based on recent deep learning works such as style transfer, we employ a pre-trained deep convolutional neural network (CNN) and use its hidden features to define a feature perceptual loss for VAE training. Evaluated on the CelebA face dataset, we show that our model produces better results than other methods in the literature. We also show that our method can produce latent vectors that can capture the semantic information of face expressions and can be used to achieve state-of-the-art performance in facial attribute prediction.



### Plug-and-Play CNN for Crowd Motion Analysis: An Application in Abnormal Event Detection
- **Arxiv ID**: http://arxiv.org/abs/1610.00307v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.00307v3)
- **Published**: 2016-10-02 16:39:35+00:00
- **Updated**: 2018-01-27 00:35:07+00:00
- **Authors**: Mahdyar Ravanbakhsh, Moin Nabi, Hossein Mousavi, Enver Sangineto, Nicu Sebe
- **Comment**: To appear at WACV 2018
- **Journal**: None
- **Summary**: Most of the crowd abnormal event detection methods rely on complex hand-crafted features to represent the crowd motion and appearance. Convolutional Neural Networks (CNN) have shown to be a powerful tool with excellent representational capacities, which can leverage the need for hand-crafted features. In this paper, we show that keeping track of the changes in the CNN feature across time can facilitate capturing the local abnormality. We specifically propose a novel measure-based method which allows measuring the local abnormality in a video by combining semantic information (inherited from existing CNN models) with low-level Optical-Flow. One of the advantage of this method is that it can be used without the fine-tuning costs. The proposed method is validated on challenging abnormality detection datasets and the results show the superiority of our method compared to the state-of-the-art methods.



### MinMax Radon Barcodes for Medical Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1610.00318v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.00318v1)
- **Published**: 2016-10-02 17:29:01+00:00
- **Updated**: 2016-10-02 17:29:01+00:00
- **Authors**: H. R. Tizhoosh, Shujin Zhu, Hanson Lo, Varun Chaudhari, Tahmid Mehdi
- **Comment**: To appear in proceedings of the 12th International Symposium on
  Visual Computing, December 12-14, 2016, Las Vegas, Nevada, USA
- **Journal**: None
- **Summary**: Content-based medical image retrieval can support diagnostic decisions by clinical experts. Examining similar images may provide clues to the expert to remove uncertainties in his/her final diagnosis. Beyond conventional feature descriptors, binary features in different ways have been recently proposed to encode the image content. A recent proposal is "Radon barcodes" that employ binarized Radon projections to tag/annotate medical images with content-based binary vectors, called barcodes. In this paper, MinMax Radon barcodes are introduced which are superior to "local thresholding" scheme suggested in the literature. Using IRMA dataset with 14,410 x-ray images from 193 different classes, the advantage of using MinMax Radon barcodes over \emph{thresholded} Radon barcodes are demonstrated. The retrieval error for direct search drops by more than 15\%. As well, SURF, as a well-established non-binary approach, and BRISK, as a recent binary method are examined to compare their results with MinMax Radon barcodes when retrieving images from IRMA dataset. The results demonstrate that MinMax Radon barcodes are faster and more accurate when applied on IRMA images.



### Stacked Autoencoders for Medical Image Search
- **Arxiv ID**: http://arxiv.org/abs/1610.00320v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.00320v1)
- **Published**: 2016-10-02 17:34:02+00:00
- **Updated**: 2016-10-02 17:34:02+00:00
- **Authors**: S. Sharma, I. Umar, L. Ospina, D. Wong, H. R. Tizhoosh
- **Comment**: To appear in proceedings of the 12th International Symposium on
  Visual Computing, December 12-14, 2016, Las Vegas, Nevada, USA
- **Journal**: None
- **Summary**: Medical images can be a valuable resource for reliable information to support medical diagnosis. However, the large volume of medical images makes it challenging to retrieve relevant information given a particular scenario. To solve this challenge, content-based image retrieval (CBIR) attempts to characterize images (or image regions) with invariant content information in order to facilitate image search. This work presents a feature extraction technique for medical images using stacked autoencoders, which encode images to binary vectors. The technique is applied to the IRMA dataset, a collection of 14,410 x-ray images in order to demonstrate the ability of autoencoders to retrieve similar x-rays given test queries. Using IRMA dataset as a benchmark, it was found that stacked autoencoders gave excellent results with a retrieval error of 376 for 1,733 test images with a compression of 74.61%.



### Low-dose CT denoising with convolutional neural network
- **Arxiv ID**: http://arxiv.org/abs/1610.00321v1
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1610.00321v1)
- **Published**: 2016-10-02 17:35:58+00:00
- **Updated**: 2016-10-02 17:35:58+00:00
- **Authors**: Hu Chen, Yi Zhang, Weihua Zhang, Peixi Liao, Ke Li, Jiliu Zhou, Ge Wang
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1609.08508
- **Journal**: None
- **Summary**: To reduce the potential radiation risk, low-dose CT has attracted much attention. However, simply lowering the radiation dose will lead to significant deterioration of the image quality. In this paper, we propose a noise reduction method for low-dose CT via deep neural network without accessing original projection data. A deep convolutional neural network is trained to transform low-dose CT images towards normal-dose CT images, patch by patch. Visual and quantitative evaluation demonstrates a competing performance of the proposed method.



