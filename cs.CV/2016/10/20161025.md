# Arxiv Papers in cs.CV on 2016-10-25
### Camera Fingerprint: A New Perspective for Identifying User's Identity
- **Arxiv ID**: http://arxiv.org/abs/1610.07728v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07728v1)
- **Published**: 2016-10-25 04:31:55+00:00
- **Updated**: 2016-10-25 04:31:55+00:00
- **Authors**: Xiang Jiang, Shikui Wei, Ruizhen Zhao, Yao Zhao, Xindong Wu
- **Comment**: 12 pages, 7 figures
- **Journal**: None
- **Summary**: Identifying user's identity is a key problem in many data mining applications, such as product recommendation, customized content delivery and criminal identification. Given a set of accounts from the same or different social network platforms, user identification attempts to identify all accounts belonging to the same person. A commonly used solution is to build the relationship among different accounts by exploring their collective patterns, e.g., user profile, writing style, similar comments. However, this kind of method doesn't work well in many practical scenarios, since the information posted explicitly by users may be false due to various reasons. In this paper, we re-inspect the user identification problem from a novel perspective, i.e., identifying user's identity by matching his/her cameras. The underlying assumption is that multiple accounts belonging to the same person contain the same or similar camera fingerprint information. The proposed framework, called User Camera Identification (UCI), is based on camera fingerprints, which takes fully into account the problems of multiple cameras and reposting behaviors.



### A Novel Boundary Matching Algorithm for Video Temporal Error Concealment
- **Arxiv ID**: http://arxiv.org/abs/1610.07753v1
- **DOI**: 10.5815/ijigsp.2014.06.01
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1610.07753v1)
- **Published**: 2016-10-25 07:11:41+00:00
- **Updated**: 2016-10-25 07:11:41+00:00
- **Authors**: Seyed Mojtaba Marvasti-Zadeh, Hossein Ghanei-Yakhdan, Shohreh Kasaei
- **Comment**: arXiv admin note: text overlap with arXiv:1610.07386
- **Journal**: International Journal of Image, Graphics, and Signal Processing
  (IJIGSP), vol. 6, no. 6, pp. 1-10, May. 2014
- **Summary**: With the fast growth of communication networks, the video data transmission from these networks is extremely vulnerable. Error concealment is a technique to estimate the damaged data by employing the correctly received data at the decoder. In this paper, an efficient boundary matching algorithm for estimating damaged motion vectors (MVs) is proposed. The proposed algorithm performs error concealment for each damaged macro block (MB) according to the list of identified priority of each frame. It then uses a classic boundary matching criterion or the proposed boundary matching criterion adaptively to identify matching distortion in each boundary of candidate MB. Finally, the candidate MV with minimum distortion is selected as an MV of damaged MB and the list of priorities is updated. Experimental results show that the proposed algorithm improves both objective and subjective qualities of reconstructed frames without any significant increase in computational cost. The PSNR for test sequences in some frames is increased about 4.7, 4.5, and 4.4 dB compared to the classic boundary matching, directional boundary matching, and directional temporal boundary matching algorithm, respectively.



### Image Clustering without Ground Truth
- **Arxiv ID**: http://arxiv.org/abs/1610.07758v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, 68Txx, H.1.2; I.2
- **Links**: [PDF](http://arxiv.org/pdf/1610.07758v1)
- **Published**: 2016-10-25 07:34:47+00:00
- **Updated**: 2016-10-25 07:34:47+00:00
- **Authors**: Abhisek Dash, Sujoy Chatterjee, Tripti Prasad, Malay Bhattacharyya
- **Comment**: GroupSight Workshop, Fourth AAAI Conference on Human Computation and
  Crowdsourcing (HCOMP 2016), Austin, USA
- **Journal**: None
- **Summary**: Cluster analysis has become one of the most exercised research areas over the past few decades in computer science. As a consequence, numerous clustering algorithms have already been developed to find appropriate partitions of a set of objects. Given multiple such clustering solutions, it is a challenging task to obtain an ensemble of these solutions. This becomes more challenging when the ground truth about the number of clusters is unavailable. In this paper, we introduce a crowd-powered model to collect solutions of image clustering from the general crowd and pose it as a clustering ensemble problem with variable number of clusters. The varying number of clusters basically reflects the crowd workers' perspective toward a particular set of objects. We allow a set of crowd workers to independently cluster the images as per their perceptions. We address the problem by finding out centroid of the clusters using an appropriate distance measure and prioritize the likelihood of similarity of the individual cluster sets. The effectiveness of the proposed method is demonstrated by applying it on multiple artificial datasets obtained from crowd.



### mdBrief - A Fast Online Adaptable, Distorted Binary Descriptor for Real-Time Applications Using Calibrated Wide-Angle Or Fisheye Cameras
- **Arxiv ID**: http://arxiv.org/abs/1610.07804v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07804v1)
- **Published**: 2016-10-25 09:42:57+00:00
- **Updated**: 2016-10-25 09:42:57+00:00
- **Authors**: Steffen Urban, Stefan Hinz
- **Comment**: 18 pages, 3 tables, 14 figures
- **Journal**: None
- **Summary**: Fast binary descriptors build the core for many vision based applications with real-time demands like object detection, Visual Odometry or SLAM. Commonly it is assumed, that the acquired images and thus the patches extracted around keypoints originate from a perspective projection ignoring image distortion or completely different types of projections such as omnidirectional or fisheye. Usually the deviations from a perfect perspective projection are corrected by undistortion. Latter, however, introduces severe artifacts if the cameras field-of-view gets larger. In this paper, we propose a distorted and masked version of the BRIEF descriptor for calibrated cameras. Instead of correcting the distortion holistically, we distort the binary tests and thus adapt the descriptor to different image regions.



### Maxmin convolutional neural networks for image classification
- **Arxiv ID**: http://arxiv.org/abs/1610.07882v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07882v1)
- **Published**: 2016-10-25 14:04:11+00:00
- **Updated**: 2016-10-25 14:04:11+00:00
- **Authors**: Michael Blot, Matthieu Cord, Nicolas Thome
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNN) are widely used in computer vision, especially in image classification. However, the way in which information and invariance properties are encoded through in deep CNN architectures is still an open question. In this paper, we propose to modify the standard convo- lutional block of CNN in order to transfer more information layer after layer while keeping some invariance within the net- work. Our main idea is to exploit both positive and negative high scores obtained in the convolution maps. This behav- ior is obtained by modifying the traditional activation func- tion step before pooling. We are doubling the maps with spe- cific activations functions, called MaxMin strategy, in order to achieve our pipeline. Extensive experiments on two classical datasets, MNIST and CIFAR-10, show that our deep MaxMin convolutional net outperforms standard CNN.



### Active User Authentication for Smartphones: A Challenge Data Set and Benchmark Results
- **Arxiv ID**: http://arxiv.org/abs/1610.07930v1
- **DOI**: 10.1109/BTAS.2016.7791155
- **Categories**: **cs.CV**, cs.DB
- **Links**: [PDF](http://arxiv.org/pdf/1610.07930v1)
- **Published**: 2016-10-25 15:56:07+00:00
- **Updated**: 2016-10-25 15:56:07+00:00
- **Authors**: Upal Mahbub, Sayantan Sarkar, Vishal M. Patel, Rama Chellappa
- **Comment**: 8 pages, 12 figures, 6 tables. Best poster award at BTAS 2016
- **Journal**: None
- **Summary**: In this paper, automated user verification techniques for smartphones are investigated. A unique non-commercial dataset, the University of Maryland Active Authentication Dataset 02 (UMDAA-02) for multi-modal user authentication research is introduced. This paper focuses on three sensors - front camera, touch sensor and location service while providing a general description for other modalities. Benchmark results for face detection, face verification, touch-based user identification and location-based next-place prediction are presented, which indicate that more robust methods fine-tuned to the mobile platform are needed to achieve satisfactory verification accuracy. The dataset will be made available to the research community for promoting additional research.



### Anatomically Constrained Video-CT Registration via the V-IMLOP Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1610.07931v1
- **DOI**: 10.1007/978-3-319-46726-9_16
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07931v1)
- **Published**: 2016-10-25 15:56:13+00:00
- **Updated**: 2016-10-25 15:56:13+00:00
- **Authors**: Seth D. Billings, Ayushi Sinha, Austin Reiter, Simon Leonard, Masaru Ishii, Gregory D. Hager, Russell H. Taylor
- **Comment**: 8 pages, 4 figures, MICCAI
- **Journal**: Medical Image Computing and Computer-Assisted Intervention --
  MICCAI 2016: 19th International Conference, Athens, Greece, October 17-21,
  2016, Proceedings, Part III. Vol. 9902, pp. 133-141
- **Summary**: Functional endoscopic sinus surgery (FESS) is a surgical procedure used to treat acute cases of sinusitis and other sinus diseases. FESS is fast becoming the preferred choice of treatment due to its minimally invasive nature. However, due to the limited field of view of the endoscope, surgeons rely on navigation systems to guide them within the nasal cavity. State of the art navigation systems report registration accuracy of over 1mm, which is large compared to the size of the nasal airways. We present an anatomically constrained video-CT registration algorithm that incorporates multiple video features. Our algorithm is robust in the presence of outliers. We also test our algorithm on simulated and in-vivo data, and test its accuracy against degrading initializations.



### PATH: Person Authentication using Trace Histories
- **Arxiv ID**: http://arxiv.org/abs/1610.07935v1
- **DOI**: 10.1109/UEMCON.2016.7777911
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07935v1)
- **Published**: 2016-10-25 15:57:41+00:00
- **Updated**: 2016-10-25 15:57:41+00:00
- **Authors**: Upal Mahbub, Rama Chellappa
- **Comment**: 8 pages, 9 figures. Best Paper award at IEEE UEMCON 2016
- **Journal**: None
- **Summary**: In this paper, a solution to the problem of Active Authentication using trace histories is addressed. Specifically, the task is to perform user verification on mobile devices using historical location traces of the user as a function of time. Considering the movement of a human as a Markovian motion, a modified Hidden Markov Model (HMM)-based solution is proposed. The proposed method, namely the Marginally Smoothed HMM (MSHMM), utilizes the marginal probabilities of location and timing information of the observations to smooth-out the emission probabilities while training. Hence, it can efficiently handle unforeseen observations during the test phase. The verification performance of this method is compared to a sequence matching (SM) method , a Markov Chain-based method (MC) and an HMM with basic Laplace Smoothing (HMM-lap). Experimental results using the location information of the UMD Active Authentication Dataset-02 (UMDAA02) and the GeoLife dataset are presented. The proposed MSHMM method outperforms the compared methods in terms of equal error rate (EER). Additionally, the effects of different parameters on the proposed method are discussed.



### End-to-end Learning of Deep Visual Representations for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1610.07940v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.07940v2)
- **Published**: 2016-10-25 16:02:42+00:00
- **Updated**: 2017-05-05 15:34:09+00:00
- **Authors**: Albert Gordo, Jon Almazan, Jerome Revaud, Diane Larlus
- **Comment**: Accepted for publication at the International Journal of Computer
  Vision (IJCV). Extended version of our ECCV2016 paper "Deep Image Retrieval:
  Learning global representations for image search"
- **Journal**: None
- **Summary**: While deep learning has become a key ingredient in the top performing methods for many computer vision tasks, it has failed so far to bring similar improvements to instance-level image retrieval. In this article, we argue that reasons for the underwhelming results of deep methods on image retrieval are threefold: i) noisy training data, ii) inappropriate deep architecture, and iii) suboptimal training procedure. We address all three issues.   First, we leverage a large-scale but noisy landmark dataset and develop an automatic cleaning method that produces a suitable training set for deep retrieval. Second, we build on the recent R-MAC descriptor, show that it can be interpreted as a deep and differentiable architecture, and present improvements to enhance it. Last, we train this network with a siamese architecture that combines three streams with a triplet loss. At the end of the training process, the proposed architecture produces a global image representation in a single forward pass that is well suited for image retrieval. Extensive experiments show that our approach significantly outperforms previous retrieval approaches, including state-of-the-art methods based on costly local descriptor indexing and spatial verification. On Oxford 5k, Paris 6k and Holidays, we respectively report 94.7, 96.6, and 94.8 mean average precision. Our representations can also be heavily compressed using product quantization with little loss in accuracy. For additional material, please see www.xrce.xerox.com/Deep-Image-Retrieval.



### Predicting First Impressions with Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1610.08119v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.08119v2)
- **Published**: 2016-10-25 23:36:57+00:00
- **Updated**: 2017-05-10 22:46:28+00:00
- **Authors**: Mel McCurrie, Fernando Beletti, Lucas Parzianello, Allen Westendorp, Samuel Anthony, Walter Scheirer
- **Comment**: None
- **Journal**: None
- **Summary**: Describable visual facial attributes are now commonplace in human biometrics and affective computing, with existing algorithms even reaching a sufficient point of maturity for placement into commercial products. These algorithms model objective facets of facial appearance, such as hair and eye color, expression, and aspects of the geometry of the face. A natural extension, which has not been studied to any great extent thus far, is the ability to model subjective attributes that are assigned to a face based purely on visual judgements. For instance, with just a glance, our first impression of a face may lead us to believe that a person is smart, worthy of our trust, and perhaps even our admiration - regardless of the underlying truth behind such attributes. Psychologists believe that these judgements are based on a variety of factors such as emotional states, personality traits, and other physiognomic cues. But work in this direction leads to an interesting question: how do we create models for problems where there is no ground truth, only measurable behavior? In this paper, we introduce a new convolutional neural network-based regression framework that allows us to train predictive models of crowd behavior for social attribute assignment. Over images from the AFLW face database, these models demonstrate strong correlations with human crowd ratings.



### Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards
- **Arxiv ID**: http://arxiv.org/abs/1610.08120v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1610.08120v1)
- **Published**: 2016-10-25 23:38:02+00:00
- **Updated**: 2016-10-25 23:38:02+00:00
- **Authors**: Suchet Bargoti, James Underwood
- **Comment**: This paper is the initial version of the manuscript submitted to The
  Journal of Field Robotics in May 2016. Following reviews and revisions, the
  paper has been accepted for publication. The reviewed version includes
  extended comparison between the different classification frameworks and a
  more in-depth literature review
- **Journal**: None
- **Summary**: Ground vehicles equipped with monocular vision systems are a valuable source of high resolution image data for precision agriculture applications in orchards. This paper presents an image processing framework for fruit detection and counting using orchard image data. A general purpose image segmentation approach is used, including two feature learning algorithms; multi-scale Multi-Layered Perceptrons (MLP) and Convolutional Neural Networks (CNN). These networks were extended by including contextual information about how the image data was captured (metadata), which correlates with some of the appearance variations and/or class distributions observed in the data. The pixel-wise fruit segmentation output is processed using the Watershed Segmentation (WS) and Circular Hough Transform (CHT) algorithms to detect and count individual fruits. Experiments were conducted in a commercial apple orchard near Melbourne, Australia. The results show an improvement in fruit segmentation performance with the inclusion of metadata on the previously benchmarked MLP network. We extend this work with CNNs, bringing agrovision closer to the state-of-the-art in computer vision, where although metadata had negligible influence, the best pixel-wise F1-score of $0.791$ was achieved. The WS algorithm produced the best apple detection and counting results, with a detection F1-score of $0.858$. As a final step, image fruit counts were accumulated over multiple rows at the orchard and compared against the post-harvest fruit counts that were obtained from a grading and counting machine. The count estimates using CNN and WS resulted in the best performance for this dataset, with a squared correlation coefficient of $r^2=0.826$.



