# Arxiv Papers in cs.CV on 2016-10-11
### FaceVR: Real-Time Facial Reenactment and Eye Gaze Control in Virtual Reality
- **Arxiv ID**: http://arxiv.org/abs/1610.03151v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03151v2)
- **Published**: 2016-10-11 01:35:56+00:00
- **Updated**: 2018-03-21 21:35:57+00:00
- **Authors**: Justus Thies, Michael Zollhöfer, Marc Stamminger, Christian Theobalt, Matthias Nießner
- **Comment**: Video: https://youtu.be/jIlujM5avU8 Presented at Siggraph'18
- **Journal**: None
- **Summary**: We propose FaceVR, a novel image-based method that enables video teleconferencing in VR based on self-reenactment. State-of-the-art face tracking methods in the VR context are focused on the animation of rigged 3d avatars. While they achieve good tracking performance the results look cartoonish and not real. In contrast to these model-based approaches, FaceVR enables VR teleconferencing using an image-based technique that results in nearly photo-realistic outputs. The key component of FaceVR is a robust algorithm to perform real-time facial motion capture of an actor who is wearing a head-mounted display (HMD), as well as a new data-driven approach for eye tracking from monocular videos. Based on reenactment of a prerecorded stereo video of the person without the HMD, FaceVR incorporates photo-realistic re-rendering in real time, thus allowing artificial modifications of face and eye appearances. For instance, we can alter facial expressions or change gaze directions in the prerecorded target video. In a live setup, we apply these newly-introduced algorithmic components.



### Multiple Instance Learning Convolutional Neural Networks for Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1610.03155v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03155v1)
- **Published**: 2016-10-11 02:02:16+00:00
- **Updated**: 2016-10-11 02:02:16+00:00
- **Authors**: Miao Sun, Tony X. Han, Ming-Chang Liu, Ahmad Khodayari-Rostamabad
- **Comment**: International Conference on Pattern Recognition(ICPR) 2016, Oral
  paper
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNN) have demon- strated its successful applications in computer vision, speech recognition, and natural language processing. For object recog- nition, CNNs might be limited by its strict label requirement and an implicit assumption that images are supposed to be target- object-dominated for optimal solutions. However, the labeling procedure, necessitating laying out the locations of target ob- jects, is very tedious, making high-quality large-scale dataset prohibitively expensive. Data augmentation schemes are widely used when deep networks suffer the insufficient training data problem. All the images produced through data augmentation share the same label, which may be problematic since not all data augmentation methods are label-preserving. In this paper, we propose a weakly supervised CNN framework named Multiple Instance Learning Convolutional Neural Networks (MILCNN) to solve this problem. We apply MILCNN framework to object recognition and report state-of-the-art performance on three benchmark datasets: CIFAR10, CIFAR100 and ILSVRC2015 classification dataset.



### DOTmark - A Benchmark for Discrete Optimal Transport
- **Arxiv ID**: http://arxiv.org/abs/1610.03368v1
- **DOI**: 10.1109/ACCESS.2016.2639065
- **Categories**: **math.OC**, cs.CV, 90-08, 90-04, 90C05, 90C08
- **Links**: [PDF](http://arxiv.org/pdf/1610.03368v1)
- **Published**: 2016-10-11 14:36:46+00:00
- **Updated**: 2016-10-11 14:36:46+00:00
- **Authors**: Jörn Schrieber, Dominic Schuhmacher, Carsten Gottschlich
- **Comment**: None
- **Journal**: IEEE Access, vol. 5, pp. 271-282, 2017
- **Summary**: The Wasserstein metric or earth mover's distance (EMD) is a useful tool in statistics, machine learning and computer science with many applications to biological or medical imaging, among others. Especially in the light of increasingly complex data, the computation of these distances via optimal transport is often the limiting factor. Inspired by this challenge, a variety of new approaches to optimal transport has been proposed in recent years and along with these new methods comes the need for a meaningful comparison.   In this paper, we introduce a benchmark for discrete optimal transport, called DOTmark, which is designed to serve as a neutral collection of problems, where discrete optimal transport methods can be tested, compared to one another, and brought to their limits on large-scale instances. It consists of a variety of grayscale images, in various resolutions and classes, such as several types of randomly generated images, classical test images and real data from microscopy.   Along with the DOTmark we present a survey and a performance test for a cross section of established methods ranging from more traditional algorithms, such as the transportation simplex, to recently developed approaches, such as the shielding neighborhood method, and including also a comparison with commercial solvers.



### Crossing the Road Without Traffic Lights: An Android-based Safety Device
- **Arxiv ID**: http://arxiv.org/abs/1610.03393v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03393v1)
- **Published**: 2016-10-11 15:33:00+00:00
- **Updated**: 2016-10-11 15:33:00+00:00
- **Authors**: Adi Perry, Dor Verbin, Nahum Kiryati
- **Comment**: Planned submission to "Pattern Recognition Letters"
- **Journal**: None
- **Summary**: In the absence of pedestrian crossing lights, finding a safe moment to cross the road is often hazardous and challenging, especially for people with visual impairments. We present a reliable low-cost solution, an Android device attached to a traffic sign or lighting pole near the crossing, indicating whether it is safe to cross the road. The indication can be by sound, display, vibration, and various communication modalities provided by the Android device. The integral system camera is aimed at approaching traffic. Optical flow is computed from the incoming video stream, and projected onto an influx map, automatically acquired during a brief training period. The crossing safety is determined based on a 1-dimensional temporal signal derived from the projection. We implemented the complete system on a Samsung Galaxy K-Zoom Android smartphone, and obtained real-time operation. The system achieves promising experimental results, providing pedestrians with sufficiently early warning of approaching vehicles. The system can serve as a stand-alone safety device, that can be installed where pedestrian crossing lights are ruled out. Requiring no dedicated infrastructure, it can be powered by a solar panel and remotely maintained via the cellular network.



### Restoring STM images via Sparse Coding: noise and artifact removal
- **Arxiv ID**: http://arxiv.org/abs/1610.03437v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03437v1)
- **Published**: 2016-10-11 17:37:47+00:00
- **Updated**: 2016-10-11 17:37:47+00:00
- **Authors**: João P. Oliveira, Ana Bragança, José Bioucas-Dias, Mário Figueiredo, Luís Alcácer, Jorge Morgado, Quirina Ferreira
- **Comment**: 14 pages, 6 figures
- **Journal**: None
- **Summary**: In this article, we present a denoising algorithm to improve the interpretation and quality of scanning tunneling microscopy (STM) images. Given the high level of self-similarity of STM images, we propose a denoising algorithm by reformulating the true estimation problem as a sparse regression, often termed sparse coding. We introduce modifications to the algorithm to cope with the existence of artifacts, mainly dropouts, which appear in a structured way as consecutive line segments on the scanning direction. The resulting algorithm treats the artifacts as missing data, and the estimated values outperform those algorithms that substitute the outliers by a local filtering. We provide code implementations for both Matlab and Gwyddion.



### Quantum spectral analysis: frequency in time, with applications to signal and image processing
- **Arxiv ID**: http://arxiv.org/abs/1611.02302v8
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.02302v8)
- **Published**: 2016-10-11 18:37:33+00:00
- **Updated**: 2021-02-18 21:04:57+00:00
- **Authors**: Mario Mastriani
- **Comment**: 140 pages, 78 figures, 8 tables. arXiv admin note: text overlap with
  arXiv:0803.2507, arXiv:quant-ph/0402085,arXiv:1611.07351 by other authors
- **Journal**: None
- **Summary**: A quantum time-dependent spectrum analysis, or simply, quantum spectral analysis (QSA) is presented in this work, and it is based on Schrodinger equation, which is a partial differential equation that describes how the quantum state of a non-relativistic physical system changes with time. In classic world is named frequency in time (FIT), which is presented here in opposition and as a complement of traditional spectral analysis frequency-dependent based on Fourier theory. Besides, FIT is a metric, which assesses the impact of the flanks of a signal on its frequency spectrum, which is not taken into account by Fourier theory and even less in real time. Even more, and unlike all derived tools from Fourier Theory (i.e., continuous, discrete, fast, short-time, fractional and quantum Fourier Transform, as well as, Gabor) FIT has the following advantages: a) compact support with excellent energy output treatment, b) low computational cost, O(N) for signals and O(N2) for images, c) it does not have phase uncertainties (indeterminate phase for magnitude = 0) as Discrete and Fast Fourier Transform (DFT, FFT, respectively), d) among others. In fact, FIT constitutes one side of a triangle (which from now on is closed) and it consists of the original signal in time, spectral analysis based on Fourier Theory and FIT. Thus a toolbox is completed, which it is essential for all applications of Digital Signal Processing (DSP) and Digital Image Processing (DIP); and, even, in the latter, FIT allows edge detection (which is called flank detection in case of signals), denoising, despeckling, compression, and superresolution of still images. Such applications include signals intelligence and imagery intelligence. On the other hand, we will present other DIP tools, which are also derived from the Schrodinger equation.



### Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection
- **Arxiv ID**: http://arxiv.org/abs/1610.03466v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03466v2)
- **Published**: 2016-10-11 18:59:12+00:00
- **Updated**: 2017-05-28 15:45:56+00:00
- **Authors**: Xianzhi Du, Mostafa El-Khamy, Jungwon Lee, Larry S. Davis
- **Comment**: WACV 2017
- **Journal**: None
- **Summary**: We propose a deep neural network fusion architecture for fast and robust pedestrian detection. The proposed network fusion architecture allows for parallel processing of multiple networks for speed. A single shot deep convolutional network is trained as a object detector to generate all possible pedestrian candidates of different sizes and occlusions. This network outputs a large variety of pedestrian candidates to cover the majority of ground-truth pedestrians while also introducing a large number of false positives. Next, multiple deep neural networks are used in parallel for further refinement of these pedestrian candidates. We introduce a soft-rejection based network fusion method to fuse the soft metrics from all networks together to generate the final confidence scores. Our method performs better than existing state-of-the-arts, especially when detecting small-size and occluded pedestrians. Furthermore, we propose a method for integrating pixel-wise semantic segmentation network into the network fusion architecture as a reinforcement to the pedestrian detector. The approach outperforms state-of-the-art methods on most protocols on Caltech Pedestrian dataset, with significant boosts on several protocols. It is also faster than all other methods.



### Deep Learning Assessment of Tumor Proliferation in Breast Cancer Histological Images
- **Arxiv ID**: http://arxiv.org/abs/1610.03467v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.03467v1)
- **Published**: 2016-10-11 19:00:35+00:00
- **Updated**: 2016-10-11 19:00:35+00:00
- **Authors**: Manan Shah, Christopher Rubadue, David Suster, Dayong Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Current analysis of tumor proliferation, the most salient prognostic biomarker for invasive breast cancer, is limited to subjective mitosis counting by pathologists in localized regions of tissue images. This study presents the first data-driven integrative approach to characterize the severity of tumor growth and spread on a categorical and molecular level, utilizing multiple biologically salient deep learning classifiers to develop a comprehensive prognostic model. Our approach achieves pathologist-level performance on three-class categorical tumor severity prediction. It additionally pioneers prediction of molecular expression data from a tissue image, obtaining a Spearman's rank correlation coefficient of 0.60 with ex vivo mean calculated RNA expression. Furthermore, our framework is applied to identify over two hundred unprecedented biomarkers critical to the accurate assessment of tumor proliferation, validating our proposed integrative pipeline as the first to holistically and objectively analyze histopathological images.



### Visual Place Recognition with Probabilistic Vertex Voting
- **Arxiv ID**: http://arxiv.org/abs/1610.03548v2
- **DOI**: 10.1109/ICRA.2017.7989362
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1610.03548v2)
- **Published**: 2016-10-11 22:16:59+00:00
- **Updated**: 2018-06-07 12:32:32+00:00
- **Authors**: Mathias Gehrig, Elena Stumm, Timo Hinzmann, Roland Siegwart
- **Comment**: 8 pages
- **Journal**: 2017 IEEE International Conference on Robotics and Automation
  (ICRA)
- **Summary**: We propose a novel scoring concept for visual place recognition based on nearest neighbor descriptor voting and demonstrate how the algorithm naturally emerges from the problem formulation. Based on the observation that the number of votes for matching places can be evaluated using a binomial distribution model, loop closures can be detected with high precision. By casting the problem into a probabilistic framework, we not only remove the need for commonly employed heuristic parameters but also provide a powerful score to classify matching and non-matching places. We present methods for both a 2D-2D pose-graph vertex matching and a 2D-3D landmark matching based on the above scoring. The approach maintains accuracy while being efficient enough for online application through the use of compact (low dimensional) descriptors and fast nearest neighbor retrieval techniques. The proposed methods are evaluated on several challenging datasets in varied environments, showing state-of-the-art results with high precision and high recall.



