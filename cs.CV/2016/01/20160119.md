# Arxiv Papers in cs.CV on 2016-01-19
### Adaptive Image Denoising by Mixture Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1601.04770v3
- **DOI**: 10.1109/TIP.2016.2590318
- **Categories**: **cs.CV**, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/1601.04770v3)
- **Published**: 2016-01-19 01:41:36+00:00
- **Updated**: 2016-06-25 02:37:45+00:00
- **Authors**: Enming Luo, Stanley H. Chan, Truong Q. Nguyen
- **Comment**: 15 pages
- **Journal**: None
- **Summary**: We propose an adaptive learning procedure to learn patch-based image priors for image denoising. The new algorithm, called the Expectation-Maximization (EM) adaptation, takes a generic prior learned from a generic external database and adapts it to the noisy image to generate a specific prior. Different from existing methods that combine internal and external statistics in ad-hoc ways, the proposed algorithm is rigorously derived from a Bayesian hyper-prior perspective. There are two contributions of this paper: First, we provide full derivation of the EM adaptation algorithm and demonstrate methods to improve the computational complexity. Second, in the absence of the latent clean image, we show how EM adaptation can be modified based on pre-filtering. Experimental results show that the proposed adaptation algorithm yields consistently better denoising results than the one without adaptation and is superior to several state-of-the-art algorithms.



### Scale-aware Pixel-wise Object Proposal Networks
- **Arxiv ID**: http://arxiv.org/abs/1601.04798v3
- **DOI**: 10.1109/TIP.2016.2593342
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04798v3)
- **Published**: 2016-01-19 04:37:47+00:00
- **Updated**: 2016-07-23 12:10:00+00:00
- **Authors**: Zequn Jie, Xiaodan Liang, Jiashi Feng, Wen Feng Lu, Eng Hock Francis Tay, Shuicheng Yan
- **Comment**: accepted by IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: Object proposal is essential for current state-of-the-art object detection pipelines. However, the existing proposal methods generally fail in producing results with satisfying localization accuracy. The case is even worse for small objects which however are quite common in practice. In this paper we propose a novel Scale-aware Pixel-wise Object Proposal (SPOP) network to tackle the challenges. The SPOP network can generate proposals with high recall rate and average best overlap (ABO), even for small objects. In particular, in order to improve the localization accuracy, a fully convolutional network is employed which predicts locations of object proposals for each pixel. The produced ensemble of pixel-wise object proposals enhances the chance of hitting the object significantly without incurring heavy extra computational cost. To solve the challenge of localizing objects at small scale, two localization networks which are specialized for localizing objects with different scales are introduced, following the divide-and-conquer philosophy. Location outputs of these two networks are then adaptively combined to generate the final proposals by a large-/small-size weighting network. Extensive evaluations on PASCAL VOC 2007 show the SPOP network is superior over the state-of-the-art models. The high-quality proposals from SPOP network also significantly improve the mean average precision (mAP) of object detection with Fast-RCNN framework. Finally, the SPOP network (trained on PASCAL VOC) shows great generalization performance when testing it on ILSVRC 2013 validation set.



### Sparsity in Dynamics of Spontaneous Subtle Emotions: Analysis \& Application
- **Arxiv ID**: http://arxiv.org/abs/1601.04805v2
- **DOI**: 10.1109/TAFFC.2016.2523996
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04805v2)
- **Published**: 2016-01-19 06:13:49+00:00
- **Updated**: 2016-02-11 05:38:30+00:00
- **Authors**: Anh Cat Le Ngo, John See, Raphael Chung-Wei Phan
- **Comment**: IEEE Transaction of Affective Computing (2016)
- **Journal**: None
- **Summary**: Spontaneous subtle emotions are expressed through micro-expressions, which are tiny, sudden and short-lived dynamics of facial muscles; thus poses a great challenge for visual recognition. The abrupt but significant dynamics for the recognition task are temporally sparse while the rest, irrelevant dynamics, are temporally redundant. In this work, we analyze and enforce sparsity constrains to learn significant temporal and spectral structures while eliminate irrelevant facial dynamics of micro-expressions, which would ease the challenge in the visual recognition of spontaneous subtle emotions. The hypothesis is confirmed through experimental results of automatic spontaneous subtle emotion recognition with several sparsity levels on CASME II and SMIC, the only two publicly available spontaneous subtle emotion databases. The overall performances of the automatic subtle emotion recognition are boosted when only significant dynamics are preserved from the original sequences.



### Eye detection in digital images: challenges and solutions
- **Arxiv ID**: http://arxiv.org/abs/1601.04871v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04871v2)
- **Published**: 2016-01-19 11:02:26+00:00
- **Updated**: 2016-01-24 08:01:37+00:00
- **Authors**: Mitra Montazeri, Mahdieh Montazeri, Saeid Saryazdi
- **Comment**: 2th National Conference of Electrical Engineering (NEEC2011),2011,
  Esfehan, Iran, in Persian
- **Journal**: None
- **Summary**: Eye Detection has an important role in the field of biometric identification and known as one method of person's identification. In recent years, many efforts have been done which can detect eye automatically and with different image conditions. However, each method has its own drawbacks which can control some of these conditions. In this paper, different methods of eye detection will be categorized and explained. In each category, the advantages and disadvantages of each method will be presented.



### A Closed-Form Solution to Tensor Voting: Theory and Applications
- **Arxiv ID**: http://arxiv.org/abs/1601.04888v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04888v2)
- **Published**: 2016-01-19 12:19:45+00:00
- **Updated**: 2016-01-20 03:30:37+00:00
- **Authors**: Tai-Pang Wu, Sai-Kit Yeung, Jiaya Jia, Chi-Keung Tang, Gerard Medioni
- **Comment**: Addendum appended to the TPAMI paper
- **Journal**: TPAMI 34(8): 1482-1495 (2012)
- **Summary**: We prove a closed-form solution to tensor voting (CFTV): given a point set in any dimensions, our closed-form solution provides an exact, continuous and efficient algorithm for computing a structure-aware tensor that simultaneously achieves salient structure detection and outlier attenuation. Using CFTV, we prove the convergence of tensor voting on a Markov random field (MRF), thus termed as MRFTV, where the structure-aware tensor at each input site reaches a stationary state upon convergence in structure propagation. We then embed structure-aware tensor into expectation maximization (EM) for optimizing a single linear structure to achieve efficient and robust parameter estimation. Specifically, our EMTV algorithm optimizes both the tensor and fitting parameters and does not require random sampling consensus typically used in existing robust statistical techniques. We performed quantitative evaluation on its accuracy and robustness, showing that EMTV performs better than the original TV and other state-of-the-art techniques in fundamental matrix estimation for multiview stereo matching. The extensions of CFTV and EMTV for extracting multiple and nonlinear structures are underway. An addendum is included in this arXiv version.



### PupilNet: Convolutional Neural Networks for Robust Pupil Detection
- **Arxiv ID**: http://arxiv.org/abs/1601.04902v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04902v1)
- **Published**: 2016-01-19 13:06:16+00:00
- **Updated**: 2016-01-19 13:06:16+00:00
- **Authors**: Wolfgang Fuhl, Thiago Santini, Gjergji Kasneci, Enkelejda Kasneci
- **Comment**: 9 pages, 11 figures
- **Journal**: None
- **Summary**: Real-time, accurate, and robust pupil detection is an essential prerequisite for pervasive video-based eye-tracking. However, automated pupil detection in real-world scenarios has proven to be an intricate challenge due to fast illumination changes, pupil occlusion, non centered and off-axis eye recording, and physiological eye characteristics. In this paper, we propose and evaluate a method based on a novel dual convolutional neural network pipeline. In its first stage the pipeline performs coarse pupil position identification using a convolutional neural network and subregions from a downscaled input image to decrease computational costs. Using subregions derived from a small window around the initial pupil position estimate, the second pipeline stage employs another convolutional neural network to refine this position, resulting in an increased pupil detection rate up to 25% in comparison with the best performing state-of-the-art algorithm. Annotated data sets can be made available upon request.



### Understanding Deep Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1601.04920v1
- **DOI**: 10.1098/rsta.2015.0203
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1601.04920v1)
- **Published**: 2016-01-19 13:40:47+00:00
- **Updated**: 2016-01-19 13:40:47+00:00
- **Authors**: St√©phane Mallat
- **Comment**: 17 pages, 4 Figures
- **Journal**: None
- **Summary**: Deep convolutional networks provide state of the art classifications and regressions results over many high-dimensional problems. We review their architecture, which scatters data with a cascade of linear filter weights and non-linearities. A mathematical framework is introduced to analyze their properties. Computations of invariants involve multiscale contractions, the linearization of hierarchical symmetries, and sparse separations. Applications are discussed.



### PN-Net: Conjoined Triple Deep Network for Learning Local Image Descriptors
- **Arxiv ID**: http://arxiv.org/abs/1601.05030v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05030v1)
- **Published**: 2016-01-19 18:29:09+00:00
- **Updated**: 2016-01-19 18:29:09+00:00
- **Authors**: Vassileios Balntas, Edward Johns, Lilian Tang, Krystian Mikolajczyk
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we propose a new approach for learning local descriptors for matching image patches. It has recently been demonstrated that descriptors based on convolutional neural networks (CNN) can significantly improve the matching performance. Unfortunately their computational complexity is prohibitive for any practical application. We address this problem and propose a CNN based descriptor with improved matching performance, significantly reduced training and execution time, as well as low dimensionality.   We propose to train the network with triplets of patches that include a positive and negative pairs. To that end we introduce a new loss function that exploits the relations within the triplets. We compare our approach to recently introduced MatchNet and DeepCompare and demonstrate the advantages of our descriptor in terms of performance, memory footprint and speed i.e. when run in GPU, the extraction time of our 128 dimensional feature is comparable to the fastest available binary descriptors such as BRIEF and ORB.



### A Theory of Local Matching: SIFT and Beyond
- **Arxiv ID**: http://arxiv.org/abs/1601.05116v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1601.05116v1)
- **Published**: 2016-01-19 22:15:48+00:00
- **Updated**: 2016-01-19 22:15:48+00:00
- **Authors**: Hossein Mobahi, Stefano Soatto
- **Comment**: None
- **Journal**: None
- **Summary**: Why has SIFT been so successful? Why its extension, DSP-SIFT, can further improve SIFT? Is there a theory that can explain both? How can such theory benefit real applications? Can it suggest new algorithms with reduced computational complexity or new descriptors with better accuracy for matching? We construct a general theory of local descriptors for visual matching. Our theory relies on concepts in energy minimization and heat diffusion. We show that SIFT and DSP-SIFT approximate the solution the theory suggests. In particular, DSP-SIFT gives a better approximation to the theoretical solution; justifying why DSP-SIFT outperforms SIFT. Using the developed theory, we derive new descriptors that have fewer parameters and are potentially better in handling affine deformations.



