# Arxiv Papers in cs.CV on 2016-01-21
### RGB-D-based Action Recognition Datasets: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1601.05511v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05511v1)
- **Published**: 2016-01-21 04:58:04+00:00
- **Updated**: 2016-01-21 04:58:04+00:00
- **Authors**: Jing Zhang, Wanqing Li, Philip O. Ogunbona, Pichao Wang, Chang Tang
- **Comment**: None
- **Journal**: None
- **Summary**: Human action recognition from RGB-D (Red, Green, Blue and Depth) data has attracted increasing attention since the first work reported in 2010. Over this period, many benchmark datasets have been created to facilitate the development and evaluation of new algorithms. This raises the question of which dataset to select and how to use it in providing a fair and objective comparative evaluation against state-of-the-art methods. To address this issue, this paper provides a comprehensive review of the most commonly used action recognition related RGB-D video datasets, including 27 single-view datasets, 10 multi-view datasets, and 7 multi-person datasets. The detailed information and analysis of these datasets is a useful resource in guiding insightful selection of datasets for future research. In addition, the issues with current algorithm evaluation vis-\'{a}-vis limitations of the available datasets and evaluation protocols are also highlighted; resulting in a number of recommendations for collection of new datasets and use of evaluation protocols.



### On the Diagnostic of Road Pathway Visibility
- **Arxiv ID**: http://arxiv.org/abs/1601.05535v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05535v1)
- **Published**: 2016-01-21 07:50:42+00:00
- **Updated**: 2016-01-21 07:50:42+00:00
- **Authors**: Pierre Charbonnier, Jean-Philippe Tarel, Francois Goulette
- **Comment**: in Transport Research Arena Europe, 2010, Bruxelles, France. 2010
- **Journal**: None
- **Summary**: Visibility distance on the road pathway plays a significant role in road safety and in particular, has a clear impact on the choice of speed limits. Visibility distance is thus of importance for road engineers and authorities. While visibility distance criteria are routinely taken into account in road design, only a few systems exist for estimating it on existing road networks. Most existing systems comprise a target vehicle followed at a constant distance by an observer vehicle, which only allows to check if a given, fixed visibility distance is available. We propose two new approaches that allow estimating the maximum available visibility distance, involving only one vehicle and based on different sensor technologies, namely binocular stereovision and 3D range sensing (LIDAR). The first approach is based on the processing of two views taken by digital cameras onboard the diagnostic vehicle. The main stages of the process are: road segmentation, edge registration between the two views, road profile 3D reconstruction and finally, maximal road visibility distance estimation. The second approach involves the use of a Terrestrial LIDAR Mobile Mapping System. The triangulated 3D model of the road and its surroundings provided by the system is used to simulate targets at different distances, which allows estimating the maximum geometric visibility distance along the pathway. These approaches were developed in the context of the SARI-VIZIR PREDIT project. Both approaches are described, evaluated and compared. Their pros and cons with respect to vehicle following systems are also discussed.



### Generalized optimal sub-pattern assignment metric
- **Arxiv ID**: http://arxiv.org/abs/1601.05585v7
- **DOI**: 10.23919/ICIF.2017.8009645
- **Categories**: **cs.SY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.05585v7)
- **Published**: 2016-01-21 10:48:58+00:00
- **Updated**: 2018-09-12 14:54:49+00:00
- **Authors**: Abu Sajana Rahmathullah, Ángel F. García-Fernández, Lennart Svensson
- **Comment**: The paper received the Jean Pierre Le Cadre best paper award at the
  20th International Conference on Information Fusion, July 2017. A Matlab
  implementation of the proposed GOSPA metric is available in
  https://github.com/abusajana/GOSPA Also visit https://youtu.be/M79GTTytvCM
  for a 15-min presentation about the paper
- **Journal**: Proceedings of the 20th International Conference on Information
  Fusion (Fusion), 2017
- **Summary**: This paper presents the generalized optimal sub-pattern assignment (GOSPA) metric on the space of finite sets of targets. Compared to the well-established optimal sub-pattern assignment (OSPA) metric, GOSPA is unnormalized as a function of the cardinality and it penalizes cardinality errors differently, which enables us to express it as an optimisation over assignments instead of permutations. An important consequence of this is that GOSPA allows us to penalize localization errors for detected targets and the errors due to missed and false targets, as indicated by traditional multiple target tracking (MTT) performance measures, in a sound manner. In addition, we extend the GOSPA metric to the space of random finite sets, which is important to evaluate MTT algorithms via simulations in a rigorous way.



### Automatic 3D modelling of craniofacial form
- **Arxiv ID**: http://arxiv.org/abs/1601.05593v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1601.05593v1)
- **Published**: 2016-01-21 11:46:35+00:00
- **Updated**: 2016-01-21 11:46:35+00:00
- **Authors**: Nick Pears, Christian Duncan
- **Comment**: 57 pages
- **Journal**: None
- **Summary**: Three-dimensional models of craniofacial variation over the general population are useful for assessing pre- and post-operative head shape when treating various craniofacial conditions, such as craniosynostosis. We present a new method of automatically building both sagittal profile models and full 3D surface models of the human head using a range of techniques in 3D surface image analysis; in particular, automatic facial landmarking using supervised machine learning, global and local symmetry plane detection using a variant of trimmed iterative closest points, locally-affine template warping (for full 3D models) and a novel pose normalisation using robust iterative ellipse fitting. The PCA-based models built using the new pose normalisation are more compact than those using Generalised Procrustes Analysis and we demonstrate their utility in a clinical case study.



### Reading Car License Plates Using Deep Convolutional Neural Networks and LSTMs
- **Arxiv ID**: http://arxiv.org/abs/1601.05610v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05610v1)
- **Published**: 2016-01-21 12:42:19+00:00
- **Updated**: 2016-01-21 12:42:19+00:00
- **Authors**: Hui Li, Chunhua Shen
- **Comment**: 17 pages
- **Journal**: None
- **Summary**: In this work, we tackle the problem of car license plate detection and recognition in natural scene images. Inspired by the success of deep neural networks (DNNs) in various vision applications, here we leverage DNNs to learn high-level features in a cascade framework, which lead to improved performance on both detection and recognition.   Firstly, we train a $37$-class convolutional neural network (CNN) to detect all characters in an image, which results in a high recall, compared with conventional approaches such as training a binary text/non-text classifier. False positives are then eliminated by the second plate/non-plate CNN classifier. Bounding box refinement is then carried out based on the edge information of the license plates, in order to improve the intersection-over-union (IoU) ratio. The proposed cascade framework extracts license plates effectively with both high recall and precision. Last, we propose to recognize the license characters as a {sequence labelling} problem. A recurrent neural network (RNN) with long short-term memory (LSTM) is trained to recognize the sequential features extracted from the whole license plate via CNNs. The main advantage of this approach is that it is segmentation free. By exploring context information and avoiding errors caused by segmentation, the RNN method performs better than a baseline method of combining segmentation and deep CNN classification; and achieves state-of-the-art recognition accuracy.



### Partial Sum Minimization of Singular Values Representation on Grassmann Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1601.05613v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05613v3)
- **Published**: 2016-01-21 12:47:17+00:00
- **Updated**: 2017-04-28 03:19:27+00:00
- **Authors**: Boyue Wang, Yongli Hu, Junbin Gao, Yanfeng Sun, Baocai Yin
- **Comment**: Submitting to ACM Transactions on Knowledge Discovery from Data with
  minor revision
- **Journal**: None
- **Summary**: As a significant subspace clustering method, low rank representation (LRR) has attracted great attention in recent years. To further improve the performance of LRR and extend its applications, there are several issues to be resolved. The nuclear norm in LRR does not sufficiently use the prior knowledge of the rank which is known in many practical problems. The LRR is designed for vectorial data from linear spaces, thus not suitable for high dimensional data with intrinsic non-linear manifold structure. This paper proposes an extended LRR model for manifold-valued Grassmann data which incorporates prior knowledge by minimizing partial sum of singular values instead of the nuclear norm, namely Partial Sum minimization of Singular Values Representation (GPSSVR). The new model not only enforces the global structure of data in low rank, but also retains important information by minimizing only smaller singular values. To further maintain the local structures among Grassmann points, we also integrate the Laplacian penalty with GPSSVR. An effective algorithm is proposed to solve the optimization problem based on the GPSSVR model. The proposed model and algorithms are assessed on some widely used human action video datasets and a real scenery dataset. The experimental results show that the proposed methods obviously outperform other state-of-the-art methods.



### B-spline Shape from Motion & Shading: An Automatic Free-form Surface Modeling for Face Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1601.05644v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1601.05644v1)
- **Published**: 2016-01-21 14:11:40+00:00
- **Updated**: 2016-01-21 14:11:40+00:00
- **Authors**: Weilong Peng, Zhiyong Feng, Chao Xu
- **Comment**: 9 pages, 6 figures
- **Journal**: None
- **Summary**: Recently, many methods have been proposed for face reconstruction from multiple images, most of which involve fundamental principles of Shape from Shading and Structure from motion. However, a majority of the methods just generate discrete surface model of face. In this paper, B-spline Shape from Motion and Shading (BsSfMS) is proposed to reconstruct continuous B-spline surface for multi-view face images, according to an assumption that shading and motion information in the images contain 1st- and 0th-order derivative of B-spline face respectively. Face surface is expressed as a B-spline surface that can be reconstructed by optimizing B-spline control points. Therefore, normals and 3D feature points computed from shading and motion of images respectively are used as the 1st- and 0th- order derivative information, to be jointly applied in optimizing the B-spline face. Additionally, an IMLS (iterative multi-least-square) algorithm is proposed to handle the difficult control point optimization. Furthermore, synthetic samples and LFW dataset are introduced and conducted to verify the proposed approach, and the experimental results demonstrate the effectiveness with different poses, illuminations, expressions etc., even with wild images.



### Spatial Scaling of Satellite Soil Moisture using Temporal Correlations and Ensemble Learning
- **Arxiv ID**: http://arxiv.org/abs/1601.05767v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.05767v1)
- **Published**: 2016-01-21 20:19:19+00:00
- **Updated**: 2016-01-21 20:19:19+00:00
- **Authors**: Subit Chakrabarti, Jasmeet Judge, Tara Bongiovanni, Anand Rangarajan, Sanjay Ranka
- **Comment**: None
- **Journal**: None
- **Summary**: A novel algorithm is developed to downscale soil moisture (SM), obtained at satellite scales of 10-40 km by utilizing its temporal correlations to historical auxiliary data at finer scales. Including such correlations drastically reduces the size of the training set needed, accounts for time-lagged relationships, and enables downscaling even in the presence of short gaps in the auxiliary data. The algorithm is based upon bagged regression trees (BRT) and uses correlations between high-resolution remote sensing products and SM observations. The algorithm trains multiple regression trees and automatically chooses the trees that generate the best downscaled estimates. The algorithm was evaluated using a multi-scale synthetic dataset in north central Florida for two years, including two growing seasons of corn and one growing season of cotton per year. The time-averaged error across the region was found to be 0.01 $\mathrm{m}^3/\mathrm{m}^3$, with a standard deviation of 0.012 $\mathrm{m}^3/\mathrm{m}^3$ when 0.02% of the data were used for training in addition to temporal correlations from the past seven days, and all available data from the past year. The maximum spatially averaged errors obtained using this algorithm in downscaled SM were 0.005 $\mathrm{m}^3/\mathrm{m}^3$, for pixels with cotton land-cover. When land surface temperature~(LST) on the day of downscaling was not included in the algorithm to simulate "data gaps", the spatially averaged error increased minimally by 0.015 $\mathrm{m}^3/\mathrm{m}^3$ when LST is unavailable on the day of downscaling. The results indicate that the BRT-based algorithm provides high accuracy for downscaling SM using complex non-linear spatio-temporal correlations, under heterogeneous micro meteorological conditions.



