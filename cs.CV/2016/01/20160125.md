# Arxiv Papers in cs.CV on 2016-01-25
### Egocentric Activity Recognition with Multimodal Fisher Vector
- **Arxiv ID**: http://arxiv.org/abs/1601.06603v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.06603v1)
- **Published**: 2016-01-25 13:57:07+00:00
- **Updated**: 2016-01-25 13:57:07+00:00
- **Authors**: Sibo Song, Ngai-Man Cheung, Vijay Chandrasekhar, Bappaditya Mandal, Jie Lin
- **Comment**: 5 pages, 4 figures, ICASSP 2016 accepted
- **Journal**: None
- **Summary**: With the increasing availability of wearable devices, research on egocentric activity recognition has received much attention recently. In this paper, we build a Multimodal Egocentric Activity dataset which includes egocentric videos and sensor data of 20 fine-grained and diverse activity categories. We present a novel strategy to extract temporal trajectory-like features from sensor data. We propose to apply the Fisher Kernel framework to fuse video and temporal enhanced sensor features. Experiment results show that with careful design of feature extraction and fusion algorithm, sensor data can enhance information-rich video data. We make publicly available the Multimodal Egocentric Activity dataset to facilitate future research.



### An Unsupervised Method for Detection and Validation of The Optic Disc and The Fovea
- **Arxiv ID**: http://arxiv.org/abs/1601.06608v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1601.06608v1)
- **Published**: 2016-01-25 14:05:36+00:00
- **Updated**: 2016-01-25 14:05:36+00:00
- **Authors**: Mrinal Haloi, Samarendra Dandapat, Rohit Sinha
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we have presented a novel method for detection of retinal image features, the optic disc and the fovea, from colour fundus photographs of dilated eyes for Computer-aided Diagnosis(CAD) system. A saliency map based method was used to detect the optic disc followed by an unsupervised probabilistic Latent Semantic Analysis for detection validation. The validation concept is based on distinct vessels structures in the optic disc. By using the clinical information of standard location of the fovea with respect to the optic disc, the macula region is estimated. Accuracy of 100\% detection is achieved for the optic disc and the macula on MESSIDOR and DIARETDB1 and 98.8\% detection accuracy on STARE dataset.



### A Taxonomy of Deep Convolutional Neural Nets for Computer Vision
- **Arxiv ID**: http://arxiv.org/abs/1601.06615v1
- **DOI**: 10.3389/frobt.2015.00036
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1601.06615v1)
- **Published**: 2016-01-25 14:25:07+00:00
- **Updated**: 2016-01-25 14:25:07+00:00
- **Authors**: Suraj Srinivas, Ravi Kiran Sarvadevabhatla, Konda Reddy Mopuri, Nikita Prabhu, Srinivas S S Kruthiventi, R. Venkatesh Babu
- **Comment**: Published in Frontiers in Robotics and AI (http://goo.gl/6691Bm)
- **Journal**: Frontiers in Robotics and AI 2(36), January 2016
- **Summary**: Traditional architectures for solving computer vision problems and the degree of success they enjoyed have been heavily reliant on hand-crafted features. However, of late, deep learning techniques have offered a compelling alternative -- that of automatically learning problem-specific features. With this new paradigm, every problem in computer vision is now being re-examined from a deep learning perspective. Therefore, it has become important to understand what kind of deep networks are suitable for a given problem. Although general surveys of this fast-moving paradigm (i.e. deep-networks) exist, a survey specific to computer vision is missing. We specifically consider one form of deep networks widely used in computer vision - convolutional neural networks (CNNs). We start with "AlexNet" as our base CNN and then examine the broad variations proposed over time to suit different applications. We hope that our recipe-style survey will serve as a guide, particularly for novice practitioners intending to use deep-learning techniques for computer vision.



### Relief R-CNN : Utilizing Convolutional Features for Fast Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1601.06719v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.06719v4)
- **Published**: 2016-01-25 18:53:14+00:00
- **Updated**: 2017-04-26 07:12:14+00:00
- **Authors**: Guiying Li, Junlong Liu, Chunhui Jiang, Liangpeng Zhang, Minlong Lin, Ke Tang
- **Comment**: 9 pages, 2 figures, accepted by ISNN 2017
- **Journal**: None
- **Summary**: R-CNN style methods are sorts of the state-of-the-art object detection methods, which consist of region proposal generation and deep CNN classification. However, the proposal generation phase in this paradigm is usually time consuming, which would slow down the whole detection time in testing. This paper suggests that the value discrepancies among features in deep convolutional feature maps contain plenty of useful spatial information, and proposes a simple approach to extract the information for fast region proposal generation in testing. The proposed method, namely Relief R-CNN (R2-CNN), adopts a novel region proposal generator in a trained R-CNN style model. The new generator directly generates proposals from convolutional features by some simple rules, thus resulting in a much faster proposal generation speed and a lower demand of computation resources. Empirical studies show that R2-CNN could achieve the fastest detection speed with comparable accuracy among all the compared algorithms in testing.



### Pixel Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1601.06759v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1601.06759v3)
- **Published**: 2016-01-25 20:34:24+00:00
- **Updated**: 2016-08-19 14:10:16+00:00
- **Authors**: Aaron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu
- **Comment**: None
- **Journal**: None
- **Summary**: Modeling the distribution of natural images is a landmark problem in unsupervised learning. This task requires an image model that is at once expressive, tractable and scalable. We present a deep neural network that sequentially predicts the pixels in an image along the two spatial dimensions. Our method models the discrete probability of the raw pixel values and encodes the complete set of dependencies in the image. Architectural novelties include fast two-dimensional recurrent layers and an effective use of residual connections in deep recurrent networks. We achieve log-likelihood scores on natural images that are considerably better than the previous state of the art. Our main results also provide benchmarks on the diverse ImageNet dataset. Samples generated from the model appear crisp, varied and globally coherent.



### Survey on the attention based RNN model and its applications in computer vision
- **Arxiv ID**: http://arxiv.org/abs/1601.06823v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1601.06823v1)
- **Published**: 2016-01-25 21:54:02+00:00
- **Updated**: 2016-01-25 21:54:02+00:00
- **Authors**: Feng Wang, David M. J. Tax
- **Comment**: None
- **Journal**: None
- **Summary**: The recurrent neural networks (RNN) can be used to solve the sequence to sequence problem, where both the input and the output have sequential structures. Usually there are some implicit relations between the structures. However, it is hard for the common RNN model to fully explore the relations between the sequences. In this survey, we introduce some attention based RNN models which can focus on different parts of the input for each output item, in order to explore and take advantage of the implicit relations between the input and the output items. The different attention mechanisms are described in detail. We then introduce some applications in computer vision which apply the attention based RNN models. The superiority of the attention based RNN model is shown by the experimental results. At last some future research directions are given.



