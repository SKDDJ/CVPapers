# Arxiv Papers in cs.CV on 2016-01-18
### A Comparative Study of Object Trackers for Infrared Flying Bird Tracking
- **Arxiv ID**: http://arxiv.org/abs/1601.04386v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04386v1)
- **Published**: 2016-01-18 02:08:18+00:00
- **Updated**: 2016-01-18 02:08:18+00:00
- **Authors**: Ying Huang, Hong Zheng, Haibin Ling, Erik Blasch, Hao Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Bird strikes present a huge risk for aircraft, especially since traditional airport bird surveillance is mainly dependent on inefficient human observation. Computer vision based technology has been proposed to automatically detect birds, determine bird flying trajectories, and predict aircraft takeoff delays. However, the characteristics of bird flight using imagery and the performance of existing methods applied to flying bird task are not well known. Therefore, we perform infrared flying bird tracking experiments using 12 state-of-the-art algorithms on a real BIRDSITE-IR dataset to obtain useful clues and recommend feature analysis. We also develop a Struck-scale method to demonstrate the effectiveness of multiple scale sampling adaption in handling the object of flying bird with varying shape and scale. The general analysis can be used to develop specialized bird tracking methods for airport safety, wildness and urban bird population studies.



### Discovering Picturesque Highlights from Egocentric Vacation Videos
- **Arxiv ID**: http://arxiv.org/abs/1601.04406v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04406v1)
- **Published**: 2016-01-18 06:23:14+00:00
- **Updated**: 2016-01-18 06:23:14+00:00
- **Authors**: Vinay Bettadapura, Daniel Castro, Irfan Essa
- **Comment**: None
- **Journal**: None
- **Summary**: We present an approach for identifying picturesque highlights from large amounts of egocentric video data. Given a set of egocentric videos captured over the course of a vacation, our method analyzes the videos and looks for images that have good picturesque and artistic properties. We introduce novel techniques to automatically determine aesthetic features such as composition, symmetry and color vibrancy in egocentric videos and rank the video frames based on their photographic qualities to generate highlights. Our approach also uses contextual information such as GPS, when available, to assess the relative importance of each geographic location where the vacation videos were shot. Furthermore, we specifically leverage the properties of egocentric videos to improve our highlight detection. We demonstrate results on a new egocentric vacation dataset which includes 26.5 hours of videos taken over a 14 day vacation that spans many famous tourist destinations and also provide results from a user-study to access our results.



### Content Aware Neural Style Transfer
- **Arxiv ID**: http://arxiv.org/abs/1601.04568v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T10, I.4.10; I.5.2; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1601.04568v1)
- **Published**: 2016-01-18 15:22:48+00:00
- **Updated**: 2016-01-18 15:22:48+00:00
- **Authors**: Rujie Yin
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a content-aware style transfer algorithm for paintings and photos of similar content using pre-trained neural network, obtaining better results than the previous work. In addition, the numerical experiments show that the style pattern and the content information is not completely separated by neural network.



### Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1601.04589v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04589v1)
- **Published**: 2016-01-18 16:31:37+00:00
- **Updated**: 2016-01-18 16:31:37+00:00
- **Authors**: Chuan Li, Michael Wand
- **Comment**: 9 pages, 9 figures
- **Journal**: None
- **Summary**: This paper studies a combination of generative Markov random field (MRF) models and discriminatively trained deep convolutional neural networks (dCNNs) for synthesizing 2D images. The generative MRF acts on higher-levels of a dCNN feature pyramid, controling the image layout at an abstract level. We apply the method to both photographic and non-photo-realistic (artwork) synthesis tasks. The MRF regularizer prevents over-excitation artifacts and reduces implausible feature mixtures common to previous dCNN inversion approaches, permitting synthezing photographic content with increased visual plausibility. Unlike standard MRF-based texture synthesis, the combined system can both match and adapt local features with considerable variability, yielding results far out of reach of classic generative MRF methods.



### Comparison-based Image Quality Assessment for Parameter Selection
- **Arxiv ID**: http://arxiv.org/abs/1601.04619v1
- **DOI**: 10.1109/TIP.2016.2601783
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04619v1)
- **Published**: 2016-01-18 17:38:26+00:00
- **Updated**: 2016-01-18 17:38:26+00:00
- **Authors**: Haoyi Liang, Daniel S. Weller
- **Comment**: 12 pages, 15 figures
- **Journal**: None
- **Summary**: Image quality assessment (IQA) is traditionally classified into full-reference (FR) IQA and no-reference (NR) IQA according to whether the original image is required. Although NR-IQA is widely used in practical applications, room for improvement still remains because of the lack of the reference image. Inspired by the fact that in many applications, such as parameter selection, a series of distorted images are available, the authors propose a novel comparison-based image quality assessment (C-IQA) method. The new comparison-based framework parallels FR-IQA by requiring two input images, and resembles NR-IQA by not using the original image. As a result, the new comparison-based approach has more application scenarios than FR-IQA does, and takes greater advantage of the accessible information than the traditional single-input NR-IQA does. Further, C-IQA is compared with other state-of-the-art NR-IQA methods on two widely used IQA databases. Experimental results show that C-IQA outperforms the other NR-IQA methods for parameter selection, and the parameter trimming framework combined with C-IQA saves the computation of iterative image reconstruction up to 80%.



### Proactive Message Passing on Memory Factor Networks
- **Arxiv ID**: http://arxiv.org/abs/1601.04667v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.04667v1)
- **Published**: 2016-01-18 19:38:51+00:00
- **Updated**: 2016-01-18 19:38:51+00:00
- **Authors**: Patrick Eschenfeldt, Dan Schmidt, Stark Draper, Jonathan Yedidia
- **Comment**: 35 pages, 13 figures
- **Journal**: None
- **Summary**: We introduce a new type of graphical model that we call a "memory factor network" (MFN). We show how to use MFNs to model the structure inherent in many types of data sets. We also introduce an associated message-passing style algorithm called "proactive message passing"' (PMP) that performs inference on MFNs. PMP comes with convergence guarantees and is efficient in comparison to competing algorithms such as variants of belief propagation. We specialize MFNs and PMP to a number of distinct types of data (discrete, continuous, labelled) and inference problems (interpolation, hypothesis testing), provide examples, and discuss approaches for efficient implementation.



### The Image Torque Operator for Contour Processing
- **Arxiv ID**: http://arxiv.org/abs/1601.04669v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.04669v1)
- **Published**: 2016-01-18 19:40:50+00:00
- **Updated**: 2016-01-18 19:40:50+00:00
- **Authors**: Morimichi Nishigaki, Cornelia Ferm√ºller
- **Comment**: 32 pages
- **Journal**: None
- **Summary**: Contours are salient features for image description, but the detection and localization of boundary contours is still considered a challenging problem. This paper introduces a new tool for edge processing implementing the Gestaltism idea of edge grouping. This tool is a mid-level image operator, called the Torque operator, that is designed to help detect closed contours in images. The torque operator takes as input the raw image and creates an image map by computing from the image gradients within regions of multiple sizes a measure of how well the edges are aligned to form closed convex contours. Fundamental properties of the torque are explored and illustrated through examples. Then it is applied in pure bottom-up processing in a variety of applications, including edge detection, visual attention and segmentation and experimentally demonstrated a useful tool that can improve existing techniques. Finally, its extension as a more general grouping mechanism and application in object recognition is discussed.



