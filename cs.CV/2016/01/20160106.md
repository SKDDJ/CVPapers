# Arxiv Papers in cs.CV on 2016-01-06
### Low-rank Matrix Factorization under General Mixture Noise Distributions
- **Arxiv ID**: http://arxiv.org/abs/1601.01060v1
- **DOI**: 10.1109/TIP.2016.2593343
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.01060v1)
- **Published**: 2016-01-06 02:52:30+00:00
- **Updated**: 2016-01-06 02:52:30+00:00
- **Authors**: Xiangyong Cao, Qian Zhao, Deyu Meng, Yang Chen, Zongben Xu
- **Comment**: 13 pages, 15 figures
- **Journal**: None
- **Summary**: Many computer vision problems can be posed as learning a low-dimensional subspace from high dimensional data. The low rank matrix factorization (LRMF) represents a commonly utilized subspace learning strategy. Most of the current LRMF techniques are constructed on the optimization problems using L1-norm and L2-norm losses, which mainly deal with Laplacian and Gaussian noises, respectively. To make LRMF capable of adapting more complex noise, this paper proposes a new LRMF model by assuming noise as Mixture of Exponential Power (MoEP) distributions and proposes a penalized MoEP (PMoEP) model by combining the penalized likelihood method with MoEP distributions. Such setting facilitates the learned LRMF model capable of automatically fitting the real noise through MoEP distributions. Each component in this mixture is adapted from a series of preliminary super- or sub-Gaussian candidates. Moreover, by facilitating the local continuity of noise components, we embed Markov random field into the PMoEP model and further propose the advanced PMoEP-MRF model. An Expectation Maximization (EM) algorithm and a variational EM (VEM) algorithm are also designed to infer the parameters involved in the proposed PMoEP and the PMoEP-MRF model, respectively. The superseniority of our methods is demonstrated by extensive experiments on synthetic data, face modeling, hyperspectral image restoration and background subtraction.



### Memory Matters: Convolutional Recurrent Neural Network for Scene Text Recognition
- **Arxiv ID**: http://arxiv.org/abs/1601.01100v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.01100v1)
- **Published**: 2016-01-06 07:36:15+00:00
- **Updated**: 2016-01-06 07:36:15+00:00
- **Authors**: Guo Qiang, Tu Dan, Li Guohui, Lei Jun
- **Comment**: 6 pages, 2 figures, 2 tables
- **Journal**: None
- **Summary**: Text recognition in natural scene is a challenging problem due to the many factors affecting text appearance. In this paper, we presents a method that directly transcribes scene text images to text without needing of sophisticated character segmentation. We leverage recent advances of deep neural networks to model the appearance of scene text images with temporal dynamics. Specifically, we integrates convolutional neural network (CNN) and recurrent neural network (RNN) which is motivated by observing the complementary modeling capabilities of the two models. The main contribution of this work is investigating how temporal memory helps in an segmentation free fashion for this specific problem. By using long short-term memory (LSTM) blocks as hidden units, our model can retain long-term memory compared with HMMs which only maintain short-term state dependences. We conduct experiments on Street View House Number dataset containing highly variable number images. The results demonstrate the superiority of the proposed method over traditional HMM based methods.



### Image-based Vehicle Analysis using Deep Neural Network: A Systematic Study
- **Arxiv ID**: http://arxiv.org/abs/1601.01145v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.01145v2)
- **Published**: 2016-01-06 11:25:36+00:00
- **Updated**: 2016-08-07 09:21:08+00:00
- **Authors**: Yiren Zhou, Hossein Nejati, Thanh-Toan Do, Ngai-Man Cheung, Lynette Cheah
- **Comment**: 5 pages, 6 figures, conference
- **Journal**: None
- **Summary**: We address the vehicle detection and classification problems using Deep Neural Networks (DNNs) approaches. Here we answer to questions that are specific to our application including how to utilize DNN for vehicle detection, what features are useful for vehicle classification, and how to extend a model trained on a limited size dataset, to the cases of extreme lighting condition. Answering these questions we propose our approach that outperforms state-of-the-art methods, and achieves promising results on image with extreme lighting conditions.



### Automatic 3D object detection of Proteins in Fluorescent labeled microscope images with spatial statistical analysis
- **Arxiv ID**: http://arxiv.org/abs/1601.01216v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.01216v1)
- **Published**: 2016-01-06 15:49:49+00:00
- **Updated**: 2016-01-06 15:49:49+00:00
- **Authors**: Ramin Norousi, Volker J. Schmid
- **Comment**: None
- **Journal**: None
- **Summary**: Since manual object detection is very inaccurate and time consuming, some automatic object detection tools have been developed in recent years. At the moment, there is no image analysis software available which provides an automatic, objective assessment of 3D foci which is generally applicable. Complications arise from discrete foci which are very close or even come in contact to other foci, moreover they are of variable sizes and show variable signal-to-noise, and must be analyzed fully in 3D. Therefore we introduce the 3D-OSCOS (3D-Object Segmentation and Colocalization Analysis based on Spatial statistics) algorithm which is implemented as a user-friendly toolbox for interactive detection of 3D objects and visualization of labeled images.



### Shape Animation with Combined Captured and Simulated Dynamics
- **Arxiv ID**: http://arxiv.org/abs/1601.01232v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.01232v1)
- **Published**: 2016-01-06 16:30:27+00:00
- **Updated**: 2016-01-06 16:30:27+00:00
- **Authors**: Benjamin Allain, Li Wang, Jean-Sebastien Franco, Franck Hetroy, Edmond Boyer
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel volumetric animation generation framework to create new types of animations from raw 3D surface or point cloud sequence of captured real performances. The framework considers as input time incoherent 3D observations of a moving shape, and is thus particularly suitable for the output of performance capture platforms. In our system, a suitable virtual representation of the actor is built from real captures that allows seamless combination and simulation with virtual external forces and objects, in which the original captured actor can be reshaped, disassembled or reassembled from user-specified virtual physics. Instead of using the dominant surface-based geometric representation of the capture, which is less suitable for volumetric effects, our pipeline exploits Centroidal Voronoi tessellation decompositions as unified volumetric representation of the real captured actor, which we show can be used seamlessly as a building block for all processing stages, from capture and tracking to virtual physic simulation. The representation makes no human specific assumption and can be used to capture and re-simulate the actor with props or other moving scenery elements. We demonstrate the potential of this pipeline for virtual reanimation of a real captured event with various unprecedented volumetric visual effects, such as volumetric distortion, erosion, morphing, gravity pull, or collisions.



### Quality Adaptive Low-Rank Based JPEG Decoding with Applications
- **Arxiv ID**: http://arxiv.org/abs/1601.01339v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.01339v1)
- **Published**: 2016-01-06 22:06:58+00:00
- **Updated**: 2016-01-06 22:06:58+00:00
- **Authors**: Xiao Shu, Xiaolin Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Small compression noises, despite being transparent to human eyes, can adversely affect the results of many image restoration processes, if left unaccounted for. Especially, compression noises are highly detrimental to inverse operators of high-boosting (sharpening) nature, such as deblurring and superresolution against a convolution kernel. By incorporating the non-linear DCT quantization mechanism into the formulation for image restoration, we propose a new sparsity-based convex programming approach for joint compression noise removal and image restoration. Experimental results demonstrate significant performance gains of the new approach over existing image restoration methods.



