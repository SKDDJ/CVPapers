# Arxiv Papers in cs.CV on 2016-01-11
### Facial Expression Recognition in the Wild using Rich Deep Features
- **Arxiv ID**: http://arxiv.org/abs/1601.02487v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.02487v1)
- **Published**: 2016-01-11 15:52:27+00:00
- **Updated**: 2016-01-11 15:52:27+00:00
- **Authors**: Abubakrelsedik Karali, Ahmad Bassiouny, Motaz El-Saban
- **Comment**: in International Conference in Image Processing, 2015
- **Journal**: None
- **Summary**: Facial Expression Recognition is an active area of research in computer vision with a wide range of applications. Several approaches have been developed to solve this problem for different benchmark datasets. However, Facial Expression Recognition in the wild remains an area where much work is still needed to serve real-world applications. To this end, in this paper we present a novel approach towards facial expression recognition. We fuse rich deep features with domain knowledge through encoding discriminant facial patches. We conduct experiments on two of the most popular benchmark datasets; CK and TFE. Moreover, we present a novel dataset that, unlike its precedents, consists of natural - not acted - expression images. Experimental results show that our approach achieves state-of-the-art results over standard benchmarks and our own dataset



### 3D Gaze Estimation from 2D Pupil Positions on Monocular Head-Mounted Eye Trackers
- **Arxiv ID**: http://arxiv.org/abs/1601.02644v2
- **DOI**: 10.1145/2857491.2857530
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.02644v2)
- **Published**: 2016-01-11 21:11:31+00:00
- **Updated**: 2016-01-19 14:27:41+00:00
- **Authors**: Mohsen Mansouryar, Julian Steil, Yusuke Sugano, Andreas Bulling
- **Comment**: None
- **Journal**: None
- **Summary**: 3D gaze information is important for scene-centric attention analysis but accurate estimation and analysis of 3D gaze in real-world environments remains challenging. We present a novel 3D gaze estimation method for monocular head-mounted eye trackers. In contrast to previous work, our method does not aim to infer 3D eyeball poses but directly maps 2D pupil positions to 3D gaze directions in scene camera coordinate space. We first provide a detailed discussion of the 3D gaze estimation task and summarize different methods, including our own. We then evaluate the performance of different 3D gaze estimation approaches using both simulated and real data. Through experimental validation, we demonstrate the effectiveness of our method in reducing parallax error, and we identify research challenges for the design of 3D calibration procedures.



