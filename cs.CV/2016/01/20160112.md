# Arxiv Papers in cs.CV on 2016-01-12
### Human Attention Estimation for Natural Images: An Automatic Gaze Refinement Approach
- **Arxiv ID**: http://arxiv.org/abs/1601.02852v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1601.02852v1)
- **Published**: 2016-01-12 13:31:38+00:00
- **Updated**: 2016-01-12 13:31:38+00:00
- **Authors**: Jinsoo Choi, Tae-Hyun Oh, In So Kweon
- **Comment**: None
- **Journal**: None
- **Summary**: Photo collections and its applications today attempt to reflect user interactions in various forms. Moreover, photo collections aim to capture the users' intention with minimum effort through applications capturing user intentions. Human interest regions in an image carry powerful information about the user's behavior and can be used in many photo applications. Research on human visual attention has been conducted in the form of gaze tracking and computational saliency models in the computer vision community, and has shown considerable progress. This paper presents an integration between implicit gaze estimation and computational saliency model to effectively estimate human attention regions in images on the fly. Furthermore, our method estimates human attention via implicit calibration and incremental model updating without any active participation from the user. We also present extensive analysis and possible applications for personal photo collections.



### Learning Subclass Representations for Visually-varied Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1601.02913v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.02913v1)
- **Published**: 2016-01-12 15:30:58+00:00
- **Updated**: 2016-01-12 15:30:58+00:00
- **Authors**: Xinchao Li, Peng Xu, Yue Shi, Martha Larson, Alan Hanjalic
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a subclass-representation approach that predicts the probability of a social image belonging to one particular class. We explore the co-occurrence of user-contributed tags to find subclasses with a strong connection to the top level class. We then project each image on to the resulting subclass space to generate a subclass representation for the image. The novelty of the approach is that subclass representations make use of not only the content of the photos themselves, but also information on the co-occurrence of their tags, which determines membership in both subclasses and top-level classes. The novelty is also that the images are classified into smaller classes, which have a chance of being more visually stable and easier to model. These subclasses are used as a latent space and images are represented in this space by their probability of relatedness to all of the subclasses. In contrast to approaches directly modeling each top-level class based on the image content, the proposed method can exploit more information for visually diverse classes. The approach is evaluated on a set of $2$ million photos with 10 classes, released by the Multimedia 2013 Yahoo! Large-scale Flickr-tag Image Classification Grand Challenge. Experiments show that the proposed system delivers sound performance for visually diverse classes compared with methods that directly model top classes.



### Using Filter Banks in Convolutional Neural Networks for Texture Classification
- **Arxiv ID**: http://arxiv.org/abs/1601.02919v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1601.02919v5)
- **Published**: 2016-01-12 15:38:41+00:00
- **Updated**: 2016-09-23 09:20:56+00:00
- **Authors**: Vincent Andrearczyk, Paul F. Whelan
- **Comment**: 12 pages, 2 figures, 6 tables
- **Journal**: None
- **Summary**: Deep learning has established many new state of the art solutions in the last decade in areas such as object, scene and speech recognition. In particular Convolutional Neural Network (CNN) is a category of deep learning which obtains excellent results in object detection and recognition tasks. Its architecture is indeed well suited to object analysis by learning and classifying complex (deep) features that represent parts of an object or the object itself. However, some of its features are very similar to texture analysis methods. CNN layers can be thought of as filter banks of complexity increasing with the depth. Filter banks are powerful tools to extract texture features and have been widely used in texture analysis. In this paper we develop a simple network architecture named Texture CNN (T-CNN) which explores this observation. It is built on the idea that the overall shape information extracted by the fully connected layers of a classic CNN is of minor importance in texture analysis. Therefore, we pool an energy measure from the last convolution layer which we connect to a fully connected layer. We show that our approach can improve the performance of a network while greatly reducing the memory usage and computation.



### Deep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1601.02970v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1601.02970v1)
- **Published**: 2016-01-12 17:34:32+00:00
- **Updated**: 2016-01-12 17:34:32+00:00
- **Authors**: Radoslaw M. Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio Torralba, Aude Oliva
- **Comment**: 15 pages, 6 figures
- **Journal**: None
- **Summary**: The complex multi-stage architecture of cortical visual pathways provides the neural basis for efficient visual object recognition in humans. However, the stage-wise computations therein remain poorly understood. Here, we compared temporal (magnetoencephalography) and spatial (functional MRI) visual brain representations with representations in an artificial deep neural network (DNN) tuned to the statistics of real-world visual recognition. We showed that the DNN captured the stages of human visual processing in both time and space from early visual areas towards the dorsal and ventral streams. Further investigation of crucial DNN parameters revealed that while model architecture was important, training on real-world categorization was necessary to enforce spatio-temporal hierarchical relationships with the brain. Together our results provide an algorithmically informed view on the spatio-temporal dynamics of visual object recognition in the human visual brain.



### Subspace Clustering Based Tag Sharing for Inductive Tag Matrix Refinement with Complex Errors
- **Arxiv ID**: http://arxiv.org/abs/1601.03055v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.03055v3)
- **Published**: 2016-01-12 21:03:43+00:00
- **Updated**: 2016-06-21 15:48:06+00:00
- **Authors**: Yuqing Hou, Zhouchen Lin, Jin-ge Yao
- **Comment**: 4 pages
- **Journal**: None
- **Summary**: Annotating images with tags is useful for indexing and retrieving images. However, many available annotation data include missing or inaccurate annotations. In this paper, we propose an image annotation framework which sequentially performs tag completion and refinement. We utilize the subspace property of data via sparse subspace clustering for tag completion. Then we propose a novel matrix completion model for tag refinement, integrating visual correlation, semantic correlation and the novelly studied property of complex errors. The proposed method outperforms the state-of-the-art approaches on multiple benchmark datasets even when they contain certain levels of annotation noise.



### A metric for sets of trajectories that is practical and mathematically consistent
- **Arxiv ID**: http://arxiv.org/abs/1601.03094v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.SY, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1601.03094v3)
- **Published**: 2016-01-12 22:44:16+00:00
- **Updated**: 2020-11-14 22:59:20+00:00
- **Authors**: Jos√© Bento, Jia Jie Zhu
- **Comment**: Submitted to IEEE Transactions on Signal Processing
- **Journal**: None
- **Summary**: Metrics on the space of sets of trajectories are important for scientists in the field of computer vision, machine learning, robotics, and general artificial intelligence. However, existing notions of closeness between sets of trajectories are either mathematically inconsistent or of limited practical use. In this paper, we outline the limitations in the current mathematically-consistent metrics, which are based on OSPA (Schuhmacher et al. 2008); and the inconsistencies in the heuristic notions of closeness used in practice, whose main ideas are common to the CLEAR MOT measures (Keni and Rainer 2008) widely used in computer vision. In two steps, we then propose a new intuitive metric between sets of trajectories and address these limitations. First, we explain a solution that leads to a metric that is hard to compute. Then we modify this formulation to obtain a metric that is easy to compute while keeping the useful properties of the previous metric. Our notion of closeness is the first demonstrating the following three features: the metric 1) can be quickly computed, 2) incorporates confusion of trajectories' identity in an optimal way, and 3) is a metric in the mathematical sense.



### Creativity in Machine Learning
- **Arxiv ID**: http://arxiv.org/abs/1601.03642v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1601.03642v1)
- **Published**: 2016-01-12 23:28:07+00:00
- **Updated**: 2016-01-12 23:28:07+00:00
- **Authors**: Martin Thoma
- **Comment**: 5 pages, 4 figures
- **Journal**: None
- **Summary**: Recent machine learning techniques can be modified to produce creative results. Those results did not exist before; it is not a trivial combination of the data which was fed into the machine learning system. The obtained results come in multiple forms: As images, as text and as audio.   This paper gives a high level overview of how they are created and gives some examples. It is meant to be a summary of the current work and give people who are new to machine learning some starting points.



