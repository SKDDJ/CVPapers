# Arxiv Papers in cs.CV on 2016-01-04
### Automatic Detection and Decoding of Photogrammetric Coded Targets
- **Arxiv ID**: http://arxiv.org/abs/1601.00396v1
- **DOI**: 10.1109/ELINFOCOM.2014.6914413
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.00396v1)
- **Published**: 2016-01-04 07:28:53+00:00
- **Updated**: 2016-01-04 07:28:53+00:00
- **Authors**: Udaya Wijenayake, Sung-In Choi, Soon-Yong Park
- **Comment**: 3 pages, 4 figures, Electronics, Information and Communications
  (ICEIC), 2014 International Conference on
- **Journal**: None
- **Summary**: Close-range Photogrammetry is widely used in many industries because of the cost effectiveness and efficiency of the technique. In this research, we introduce an automated coded target detection method which can be used to enhance the efficiency of the Photogrammetry.



### Multi-task CNN Model for Attribute Prediction
- **Arxiv ID**: http://arxiv.org/abs/1601.00400v1
- **DOI**: 10.1109/TMM.2015.2477680
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.00400v1)
- **Published**: 2016-01-04 07:42:56+00:00
- **Updated**: 2016-01-04 07:42:56+00:00
- **Authors**: Abrar H. Abdulnabi, Gang Wang, Jiwen Lu, Kui Jia
- **Comment**: 11 pages, 3 figures, ieee transaction paper
- **Journal**: IEEE Transactions on Multimedia, Nov 2015, pp. 1949-1959
- **Summary**: This paper proposes a joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN). We consider learning binary semantic attributes through a multi-task CNN model, where each CNN will predict one binary attribute. The multi-task learning allows CNN models to simultaneously share visual knowledge among different attribute categories. Each CNN will generate attribute-specific feature representations, and then we apply multi-task learning on the features to predict their attributes. In our multi-task framework, we propose a method to decompose the overall model's parameters into a latent task matrix and combination matrix. Furthermore, under-sampled classifiers can leverage shared statistics from other classifiers to improve their performance. Natural grouping of attributes is applied such that attributes in the same group are encouraged to share more knowledge. Meanwhile, attributes in different groups will generally compete with each other, and consequently share less knowledge. We show the effectiveness of our method on two popular attribute datasets.



### Kernel Sparse Subspace Clustering on Symmetric Positive Definite Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1601.00414v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1601.00414v1)
- **Published**: 2016-01-04 09:00:24+00:00
- **Updated**: 2016-01-04 09:00:24+00:00
- **Authors**: Ming Yin, Yi Guo, Junbin Gao, Zhaoshui He, Shengli Xie
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse subspace clustering (SSC), as one of the most successful subspace clustering methods, has achieved notable clustering accuracy in computer vision tasks. However, SSC applies only to vector data in Euclidean space. As such, there is still no satisfactory approach to solve subspace clustering by ${\it self-expressive}$ principle for symmetric positive definite (SPD) matrices which is very useful in computer vision. In this paper, by embedding the SPD matrices into a Reproducing Kernel Hilbert Space (RKHS), a kernel subspace clustering method is constructed on the SPD manifold through an appropriate Log-Euclidean kernel, termed as kernel sparse subspace clustering on the SPD Riemannian manifold (KSSCR). By exploiting the intrinsic Riemannian geometry within data, KSSCR can effectively characterize the geodesic distance between SPD matrices to uncover the underlying subspace structure. Experimental results on two famous database demonstrate that the proposed method achieves better clustering results than the state-of-the-art approaches.



### Multimodal Classification of Events in Social Media
- **Arxiv ID**: http://arxiv.org/abs/1601.00599v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1601.00599v1)
- **Published**: 2016-01-04 18:29:33+00:00
- **Updated**: 2016-01-04 18:29:33+00:00
- **Authors**: Matthias Zeppelzauer, Daniel Schopfhauser
- **Comment**: Preprint of accepted manuscript for the Elsevier Image and Vision
  Computing Journal (IMAVIS). The paper will be published by IMAVIS under DOI
  10.1016/j.imavis.2015.12.004
- **Journal**: None
- **Summary**: A large amount of social media hosted on platforms like Flickr and Instagram is related to social events. The task of social event classification refers to the distinction of event and non-event-related content as well as the classification of event types (e.g. sports events, concerts, etc.). In this paper, we provide an extensive study of textual, visual, as well as multimodal representations for social event classification. We investigate strengths and weaknesses of the modalities and study synergy effects between the modalities. Experimental results obtained with our multimodal representation outperform state-of-the-art methods and provide a new baseline for future research.



