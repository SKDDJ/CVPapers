# Arxiv Papers in cs.CV on 2016-12-23
### Automatic Interpretation of Unordered Point Cloud Data for UAV Navigation in Construction
- **Arxiv ID**: http://arxiv.org/abs/1612.07850v2
- **DOI**: 10.1109/ICARCV.2016.7838683
- **Categories**: **cs.RO**, cs.CV, cs.SY
- **Links**: [PDF](http://arxiv.org/pdf/1612.07850v2)
- **Published**: 2016-12-23 01:23:46+00:00
- **Updated**: 2017-02-12 10:43:26+00:00
- **Authors**: M. D. Phung, C. H. Quach, D. T. Chu, N. Q. Nguyen, T. H. Dinh, Q. P. Ha
- **Comment**: In The 14th International Conference on Control, Automation, Robotics
  and Vision, ICARCV 2016
- **Journal**: None
- **Summary**: The objective of this work is to develop a data processing system that can automatically generate waypoints for navigation of an unmanned aerial vehicle (UAV) to inspect surfaces of structures like buildings and bridges. The input includes data recorded by two 2D laser scanners, orthogonally mounted on the UAV, and an inertial measurement unit (IMU). To achieve the goal, algorithms are developed to process the data collected. They are separated into three major groups: (i) the data registration and filtering to generate a 3D model of the structure and control the density of point clouds for data completeness enhancement; (ii) the surface and obstacle detection to assist the UAV in monitoring tasks; and (iii) the waypoint generation to set the flight path. Experiments on different data sets show that the developed system is able to reconstruct a 3D point cloud of the structure, extract its surfaces and objects, and generate waypoints for the UAV to accomplish inspection tasks.



### DARN: a Deep Adversial Residual Network for Intrinsic Image Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1612.07899v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.07899v2)
- **Published**: 2016-12-23 08:20:10+00:00
- **Updated**: 2018-03-20 11:05:57+00:00
- **Authors**: Louis Lettry, Kenneth Vanhoey, Luc Van Gool
- **Comment**: Published in Winter Conference on Applications of Computer Vision
  2018
- **Journal**: None
- **Summary**: We present a new deep supervised learning method for intrinsic decomposition of a single image into its albedo and shading components. Our contributions are based on a new fully convolutional neural network that estimates absolute albedo and shading jointly. Our solution relies on a single end-to-end deep sequence of residual blocks and a perceptually-motivated metric formed by two adversarially trained discriminators. As opposed to classical intrinsic image decomposition work, it is fully data-driven, hence does not require any physical priors like shading smoothness or albedo sparsity, nor does it rely on geometric information such as depth. Compared to recent deep learning techniques, we simplify the architecture, making it easier to build and train, and constrain it to generate a valid and reversible decomposition. We rediscuss and augment the set of quantitative metrics so as to account for the more challenging recovery of non scale-invariant quantities. We train and demonstrate our architecture on the publicly available MPI Sintel dataset and its intrinsic image decomposition, show attenuated overfitting issues and discuss generalizability to other data. Results show that our work outperforms the state of the art deep algorithms both on the qualitative and quantitative aspect.



### EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1612.07919v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1612.07919v2)
- **Published**: 2016-12-23 10:16:26+00:00
- **Updated**: 2017-07-30 21:52:23+00:00
- **Authors**: Mehdi S. M. Sajjadi, Bernhard Schölkopf, Michael Hirsch
- **Comment**: main paper and supplementary material
- **Journal**: None
- **Summary**: Single image super-resolution is the task of inferring a high-resolution image from a single low-resolution input. Traditionally, the performance of algorithms for this task is measured using pixel-wise reconstruction measures such as peak signal-to-noise ratio (PSNR) which have been shown to correlate poorly with the human perception of image quality. As a result, algorithms minimizing these metrics tend to produce over-smoothed images that lack high-frequency textures and do not look natural despite yielding high PSNR values.   We propose a novel application of automated texture synthesis in combination with a perceptual loss focusing on creating realistic textures rather than optimizing for a pixel-accurate reproduction of ground truth images during training. By using feed-forward fully convolutional neural networks in an adversarial training setting, we achieve a significant boost in image quality at high magnification ratios. Extensive experiments on a number of datasets show the effectiveness of our approach, yielding state-of-the-art results in both quantitative and qualitative benchmarks.



### Understanding Non-optical Remote-sensed Images: Needs, Challenges and Ways Forward
- **Arxiv ID**: http://arxiv.org/abs/1612.07921v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.07921v1)
- **Published**: 2016-12-23 10:17:00+00:00
- **Updated**: 2016-12-23 10:17:00+00:00
- **Authors**: Amit Kumar Mishra
- **Comment**: None
- **Journal**: None
- **Summary**: Non-optical remote-sensed images are going to be used more often in man- aging disaster, crime and precision agriculture. With more small satellites and unmanned air vehicles planning to carry radar and hyperspectral image sensors there is going to be an abundance of such data in the recent future. Understanding these data in real-time will be crucial in attaining some of the important sustain- able development goals. Processing non-optical images is, in many ways, different from that of optical images. Most of the recent advances in the domain of image understanding has been using optical images. In this article we shall explain the needs for image understanding in non-optical domain and the typical challenges. Then we shall describe the existing approaches and how we can move from there to the desired goal of a reliable real-time image understanding system.



### Two-stream convolutional neural network for accurate RGB-D fingertip detection using depth and edge information
- **Arxiv ID**: http://arxiv.org/abs/1612.07978v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.07978v1)
- **Published**: 2016-12-23 14:17:31+00:00
- **Updated**: 2016-12-23 14:17:31+00:00
- **Authors**: Hengkai Guo, Guijin Wang, Xinghao Chen
- **Comment**: Accepted by ICIP 2016
- **Journal**: None
- **Summary**: Accurate detection of fingertips in depth image is critical for human-computer interaction. In this paper, we present a novel two-stream convolutional neural network (CNN) for RGB-D fingertip detection. Firstly edge image is extracted from raw depth image using random forest. Then the edge information is combined with depth information in our CNN structure. We study several fusion approaches and suggest a slow fusion strategy as a promising way of fingertip detection. As shown in our experiments, our real-time algorithm outperforms state-of-the-art fingertip detection methods on the public dataset HandNet with an average 3D error of 9.9mm, and shows comparable accuracy of fingertip estimation on NYU hand dataset.



### Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge
- **Arxiv ID**: http://arxiv.org/abs/1612.08012v4
- **DOI**: 10.1016/j.media.2017.06.015
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.08012v4)
- **Published**: 2016-12-23 15:47:27+00:00
- **Updated**: 2017-07-15 12:11:40+00:00
- **Authors**: Arnaud Arindra Adiyoso Setio, Alberto Traverso, Thomas de Bel, Moira S. N. Berens, Cas van den Bogaard, Piergiorgio Cerello, Hao Chen, Qi Dou, Maria Evelina Fantacci, Bram Geurts, Robbert van der Gugten, Pheng Ann Heng, Bart Jansen, Michael M. J. de Kaste, Valentin Kotov, Jack Yu-Hung Lin, Jeroen T. M. C. Manders, Alexander Sónora-Mengana, Juan Carlos García-Naranjo, Evgenia Papavasileiou, Mathias Prokop, Marco Saletta, Cornelia M Schaefer-Prokop, Ernst T. Scholten, Luuk Scholten, Miranda M. Snoeren, Ernesto Lopez Torres, Jef Vandemeulebroucke, Nicole Walasek, Guido C. A. Zuidhof, Bram van Ginneken, Colin Jacobs
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic detection of pulmonary nodules in thoracic computed tomography (CT) scans has been an active area of research for the last two decades. However, there have only been few studies that provide a comparative performance evaluation of different systems on a common database. We have therefore set up the LUNA16 challenge, an objective evaluation framework for automatic nodule detection algorithms using the largest publicly available reference database of chest CT scans, the LIDC-IDRI data set. In LUNA16, participants develop their algorithm and upload their predictions on 888 CT scans in one of the two tracks: 1) the complete nodule detection track where a complete CAD system should be developed, or 2) the false positive reduction track where a provided set of nodule candidates should be classified. This paper describes the setup of LUNA16 and presents the results of the challenge so far. Moreover, the impact of combining individual systems on the detection performance was also investigated. It was observed that the leading solutions employed convolutional networks and used the provided set of nodule candidates. The combination of these solutions achieved an excellent sensitivity of over 95% at fewer than 1.0 false positives per scan. This highlights the potential of combining algorithms to improve the detection performance. Our observer study with four expert readers has shown that the best system detects nodules that were missed by expert readers who originally annotated the LIDC-IDRI data. We released this set of additional nodules for further development of CAD systems.



### Active Learning and Proofreading for Delineation of Curvilinear Structures
- **Arxiv ID**: http://arxiv.org/abs/1612.08036v2
- **DOI**: 10.1007/978-3-319-66185-8_19
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.08036v2)
- **Published**: 2016-12-23 17:01:31+00:00
- **Updated**: 2017-03-13 11:06:03+00:00
- **Authors**: Agata Mosinska, Jakub Tarnawski, Pascal Fua
- **Comment**: extended version with fast reconstruction
- **Journal**: Proc. of Medical Image Computing and Computer-Assisted
  Intervention (MICCAI) 2017, pages 165-173
- **Summary**: Many state-of-the-art delineation methods rely on supervised machine learning algorithms. As a result, they require manually annotated training data, which is tedious to obtain. Furthermore, even minor classification errors may significantly affect the topology of the final result. In this paper we propose a generic approach to addressing both of these problems by taking into account the influence of a potential misclassification on the resulting delineation. In an Active Learning context, we identify parts of linear structures that should be annotated first in order to train a classifier effectively. In a proofreading context, we similarly find regions of the resulting reconstruction that should be verified in priority to obtain a nearly-perfect result. In both cases, by focusing the attention of the human expert on potential classification mistakes which are the most critical parts of the delineation, we reduce the amount of required supervision. We demonstrate the effectiveness of our approach on microscopy images depicting blood vessels and neurons.



### Blind restoration for non-uniform aerial images using non-local Retinex model and shearlet-based higher-order regularization
- **Arxiv ID**: http://arxiv.org/abs/1612.08037v1
- **DOI**: 10.1117/1.JEI.26.3.033016
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.08037v1)
- **Published**: 2016-12-23 17:02:16+00:00
- **Updated**: 2016-12-23 17:02:16+00:00
- **Authors**: Rui Chen, Huizhu Jia, Xiaodong Xie, Wen Gao
- **Comment**: to be published in Journal of Electronic Imaging
- **Journal**: None
- **Summary**: Aerial images are often degraded by space-varying motion blur and simultaneous uneven illumination. To recover high-quality aerial image from its non-uniform version, we propose a novel patch-wise restoration approach based on a key observation that the degree of blurring is inevitably affected by the illuminated conditions. A non-local Retinex model is developed to accurately estimate the reflectance component from the degraded aerial image. Thereafter the uneven illumination is corrected well. And then non-uniform coupled blurring in the enhanced reflectance image is alleviated and transformed towards uniform distribution, which will facilitate the subsequent deblurring. For constructing the multi-scale sparsified regularizer, the discrete shearlet transform is improved to better represent anisotropic image features in term of directional sensitivity and selectivity. In addition, a new adaptive variant of total generalized variation is proposed for the structure-preserving regularizer. These complementary regularizers are elegantly integrated into an objective function. The final deblurred image with uniform illumination can be extracted by applying the fast alternating direction scheme to solve the derived function. The experimental results demonstrate that our algorithm can not only remove both the space-varying illumination and motion blur in the aerial image effectively but also recover the abundant details of aerial scenes with top-level objective and subjective quality, and outperforms other state-of-the-art restoration methods.



### Correlation Preserving Sparse Coding Over Multi-level Dictionaries for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1612.08049v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1612.08049v1)
- **Published**: 2016-12-23 17:38:23+00:00
- **Updated**: 2016-12-23 17:38:23+00:00
- **Authors**: Rui Chen, Huizhu Jia, Xiaodong Xie, Wen Gao
- **Comment**: to be published in IEEE Signal Processing Letters
- **Journal**: None
- **Summary**: In this letter, we propose a novel image denoising method based on correlation preserving sparse coding. Because the instable and unreliable correlations among basis set can limit the performance of the dictionary-driven denoising methods, two effective regularized strategies are employed in the coding process. Specifically, a graph-based regularizer is built for preserving the global similarity correlations, which can adaptively capture both the geometrical structures and discriminative features of textured patches. In particular, edge weights in the graph are obtained by seeking a nonnegative low-rank construction. Besides, a robust locality-constrained coding can automatically preserve not only spatial neighborhood information but also internal consistency present in noisy patches while learning overcomplete dictionary. Experimental results demonstrate that our proposed method achieves state-of-the-art denoising performance in terms of both PSNR and subjective visual quality.



