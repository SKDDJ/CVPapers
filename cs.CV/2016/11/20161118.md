# Arxiv Papers in cs.CV on 2016-11-18
### SC-DCNN: Highly-Scalable Deep Convolutional Neural Network using Stochastic Computing
- **Arxiv ID**: http://arxiv.org/abs/1611.05939v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.05939v2)
- **Published**: 2016-11-18 01:11:17+00:00
- **Updated**: 2017-01-31 16:19:46+00:00
- **Authors**: Ao Ren, Ji Li, Zhe Li, Caiwen Ding, Xuehai Qian, Qinru Qiu, Bo Yuan, Yanzhi Wang
- **Comment**: This paper is accepted by 22nd ACM International Conference on
  Architectural Support for Programming Languages and Operating Systems, 2017
- **Journal**: None
- **Summary**: With recent advancing of Internet of Things (IoTs), it becomes very attractive to implement the deep convolutional neural networks (DCNNs) onto embedded/portable systems. Presently, executing the software-based DCNNs requires high-performance server clusters in practice, restricting their widespread deployment on the mobile devices. To overcome this issue, considerable research efforts have been conducted in the context of developing highly-parallel and specific DCNN hardware, utilizing GPGPUs, FPGAs, and ASICs. Stochastic Computing (SC), which uses bit-stream to represent a number within [-1, 1] by counting the number of ones in the bit-stream, has a high potential for implementing DCNNs with high scalability and ultra-low hardware footprint. Since multiplications and additions can be calculated using AND gates and multiplexers in SC, significant reductions in power/energy and hardware footprint can be achieved compared to the conventional binary arithmetic implementations. The tremendous savings in power (energy) and hardware resources bring about immense design space for enhancing scalability and robustness for hardware DCNNs. This paper presents the first comprehensive design and optimization framework of SC-based DCNNs (SC-DCNNs). We first present the optimal designs of function blocks that perform the basic operations, i.e., inner product, pooling, and activation function. Then we propose the optimal design of four types of combinations of basic function blocks, named feature extraction blocks, which are in charge of extracting features from input feature maps. Besides, weight storage methods are investigated to reduce the area and power/energy consumption for storing weights. Finally, the whole SC-DCNN implementation is optimized, with feature extraction blocks carefully selected, to minimize area and power/energy consumption while maintaining a high network accuracy level.



### Minimal Problems for the Calibrated Trifocal Variety
- **Arxiv ID**: http://arxiv.org/abs/1611.05947v1
- **DOI**: None
- **Categories**: **math.AG**, cs.CV, math.NA, 14M20, 14Q15, 14N99, 15A69, 65H20, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1611.05947v1)
- **Published**: 2016-11-18 01:52:35+00:00
- **Updated**: 2016-11-18 01:52:35+00:00
- **Authors**: Joe Kileel
- **Comment**: 23 pages, 1 table
- **Journal**: None
- **Summary**: We determine the algebraic degree of minimal problems for the calibrated trifocal variety in computer vision. We rely on numerical algebraic geometry and the homotopy continuation software Bertini.



### Reweighted Low-Rank Tensor Decomposition based on t-SVD and its Applications in Video Denoising
- **Arxiv ID**: http://arxiv.org/abs/1611.05963v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1611.05963v4)
- **Published**: 2016-11-18 03:26:12+00:00
- **Updated**: 2017-07-09 16:54:56+00:00
- **Authors**: M. Baburaj, Sudhish N. George
- **Comment**: Algorithm 1 is inefficient since line 2 is processed n 3 times need
  to be changed There are inconsistent notations throughout the manuscript
  Unitary Tensor are not defined
- **Journal**: None
- **Summary**: The t-SVD based Tensor Robust Principal Component Analysis (TRPCA) decomposes low rank multi-linear signal corrupted by gross errors into low multi-rank and sparse component by simultaneously minimizing tensor nuclear norm and l 1 norm. But if the multi-rank of the signal is considerably large and/or large amount of noise is present, the performance of TRPCA deteriorates. To overcome this problem, this paper proposes a new efficient iterative reweighted tensor decomposition scheme based on t-SVD which significantly improves tensor multi-rank in TRPCA. Further, the sparse component of the tensor is also recovered by reweighted l 1 norm which enhances the accuracy of decomposition. The effectiveness of the proposed method is established by applying it to the video denoising problem and the experimental results reveal that the proposed algorithm outperforms its counterparts.



### Reweighted Low-Rank Tensor Completion and its Applications in Video Recovery
- **Arxiv ID**: http://arxiv.org/abs/1611.05964v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.05964v4)
- **Published**: 2016-11-18 03:28:11+00:00
- **Updated**: 2017-07-09 16:54:03+00:00
- **Authors**: Baburaj M., Sudhish N. George
- **Comment**: Algorithm 1 is inefficient since line 2 is processed n 3 times need
  to be changed There are inconsistent notations throughout the manuscript
  Unitary Tensor are not defined
- **Journal**: None
- **Summary**: This paper focus on recovering multi-dimensional data called tensor from randomly corrupted incomplete observation. Inspired by reweighted $l_1$ norm minimization for sparsity enhancement, this paper proposes a reweighted singular value enhancement scheme to improve tensor low tubular rank in the tensor completion process. An efficient iterative decomposition scheme based on t-SVD is proposed which improves low-rank signal recovery significantly. The effectiveness of the proposed method is established by applying to video completion problem, and experimental results reveal that the algorithm outperforms its counterparts.



### Finding Mirror Symmetry via Registration
- **Arxiv ID**: http://arxiv.org/abs/1611.05971v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.05971v2)
- **Published**: 2016-11-18 04:37:26+00:00
- **Updated**: 2017-03-31 01:41:41+00:00
- **Authors**: Marcelo Cicconet, David G. C. Hildebrand, Hunter Elliott
- **Comment**: Submitted to ICCV 2017
- **Journal**: None
- **Summary**: Symmetry is prevalent in nature and a common theme in man-made designs. Both the human visual system and computer vision algorithms can use symmetry to facilitate object recognition and other tasks. Detecting mirror symmetry in images and data is, therefore, useful for a number of applications. Here, we demonstrate that the problem of fitting a plane of mirror symmetry to data in any Euclidian space can be reduced to the problem of registering two datasets. The exactness of the resulting solution depends entirely on the registration accuracy. This new Mirror Symmetry via Registration (MSR) framework involves (1) data reflection with respect to an arbitrary plane, (2) registration of original and reflected datasets, and (3) calculation of the eigenvector of eigenvalue -1 for the transformation matrix representing the reflection and registration mappings. To support MSR, we also introduce a novel 2D registration method based on random sample consensus of an ensemble of normalized cross-correlation matches. With this as its registration back-end, MSR achieves state-of-the-art performance for symmetry line detection in two independent 2D testing databases. We further demonstrate the generality of MSR by testing it on a database of 3D shapes with an iterative closest point registration back-end. Finally, we explore its applicability to examining symmetry in natural systems by assessing the degree of symmetry present in myelinated axon reconstructions from a larval zebrafish.



### Fuzzy Statistical Matrices for Cell Classification
- **Arxiv ID**: http://arxiv.org/abs/1611.06009v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06009v1)
- **Published**: 2016-11-18 08:49:28+00:00
- **Updated**: 2016-11-18 08:49:28+00:00
- **Authors**: Guillaume Thibault, Izhak Shafran
- **Comment**: 21 pages, 7 figures, 5 tables
- **Journal**: None
- **Summary**: In this paper, we generalize image (texture) statistical descriptors and propose algorithms that improve their efficacy. Recently, a new method showed how the popular Co-Occurrence Matrix (COM) can be modified into a fuzzy version (FCOM) which is more effective and robust to noise. Here, we introduce new fuzzy versions of two additional higher order statistical matrices: the Run Length Matrix (RLM) and the Size Zone Matrix (SZM). We define the fuzzy zones and propose an efficient algorithm to compute the descriptors. We demonstrate the advantage of the proposed improvements over several state-of-the-art methods on three tasks from quantitative cell biology: analyzing and classifying Human Epithelial type 2 (HEp-2) cells using Indirect Immunofluorescence protocol (IFF).



### Online Visual Multi-Object Tracking via Labeled Random Finite Set Filtering
- **Arxiv ID**: http://arxiv.org/abs/1611.06011v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06011v2)
- **Published**: 2016-11-18 09:00:22+00:00
- **Updated**: 2017-08-04 09:01:51+00:00
- **Authors**: Du Yong Kim, Ba-Ngu Vo, Ba-Tuong Vo
- **Comment**: 13 pages, 9 figures
- **Journal**: None
- **Summary**: This paper proposes an online visual multi-object tracking algorithm using a top-down Bayesian formulation that seamlessly integrates state estimation, track management, clutter rejection, occlusion and mis-detection handling into a single recursion. This is achieved by modeling the multi-object state as labeled random finite set and using the Bayes recursion to propagate the multi-object filtering density forward in time. The proposed filter updates tracks with detections but switches to image data when mis-detection occurs, thereby exploiting the efficiency of detection data and the accuracy of image data. Furthermore the labeled random finite set framework enables the incorporation of prior knowledge that mis-detections of long tracks which occur in the middle of the scene are likely to be due to occlusions. Such prior knowledge can be exploited to improve occlusion handling, especially long occlusions that can lead to premature track termination in on-line multi-object tracking. Tracking performance are compared to state-of-the-art algorithms on well-known benchmark video datasets.



### Improving training of deep neural networks via Singular Value Bounding
- **Arxiv ID**: http://arxiv.org/abs/1611.06013v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06013v3)
- **Published**: 2016-11-18 09:09:56+00:00
- **Updated**: 2017-03-18 07:27:09+00:00
- **Authors**: Kui Jia
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning methods achieve great success recently on many computer vision problems, with image classification and object detection as the prominent examples. In spite of these practical successes, optimization of deep networks remains an active topic in deep learning research. In this work, we focus on investigation of the network solution properties that can potentially lead to good performance. Our research is inspired by theoretical and empirical results that use orthogonal matrices to initialize networks, but we are interested in investigating how orthogonal weight matrices perform when network training converges. To this end, we propose to constrain the solutions of weight matrices in the orthogonal feasible set during the whole process of network training, and achieve this by a simple yet effective method called Singular Value Bounding (SVB). In SVB, all singular values of each weight matrix are simply bounded in a narrow band around the value of 1. Based on the same motivation, we also propose Bounded Batch Normalization (BBN), which improves Batch Normalization by removing its potential risk of ill-conditioned layer transform. We present both theoretical and empirical results to justify our proposed methods. Experiments on benchmark image classification datasets show the efficacy of our proposed SVB and BBN. In particular, we achieve the state-of-the-art results of 3.06% error rate on CIFAR10 and 16.90% on CIFAR100, using off-the-shelf network architectures (Wide ResNets). Our preliminary results on ImageNet also show the promise in large-scale learning.



### Cross Domain Knowledge Transfer for Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1611.06026v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06026v1)
- **Published**: 2016-11-18 10:06:58+00:00
- **Updated**: 2016-11-18 10:06:58+00:00
- **Authors**: Qiqi Xiao, Kelei Cao, Haonan Chen, Fangyue Peng, Chi Zhang
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: Person Re-Identification (re-id) is a challenging task in computer vision, especially when there are limited training data from multiple camera views. In this paper, we pro- pose a deep learning based person re-identification method by transferring knowledge of mid-level attribute features and high-level classification features. Building on the idea that identity classification, attribute recognition and re- identification share the same mid-level semantic representations, they can be trained sequentially by fine-tuning one based on another. In our framework, we train identity classification and attribute recognition tasks from deep Convolutional Neural Network (dCNN) to learn person information. The information can be transferred to the person re-id task and improves its accuracy by a large margin. Further- more, a Long Short Term Memory(LSTM) based Recurrent Neural Network (RNN) component is extended by a spacial gate. This component is used in the re-id model to pay attention to certain spacial parts in each recurrent unit. Experimental results show that our method achieves 78.3% of rank-1 recognition accuracy on the CUHK03 benchmark.



### A Novel Architecture for Computing Approximate Radon Transform
- **Arxiv ID**: http://arxiv.org/abs/1701.05083v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.05083v1)
- **Published**: 2016-11-18 11:48:08+00:00
- **Updated**: 2016-11-18 11:48:08+00:00
- **Authors**: M. A. Khorsandi, N. Karimi, S. Samavi
- **Comment**: None
- **Journal**: None
- **Summary**: Radon transform is a type of transform which is used in image processing to transfer the image into intercept-slope coordinate. Its diagonal properties made it appropriate for some applications which need processes in different degrees. Radon transform computation needs a lot of arithmetic operations which makes it a compute-intensive algorithm. In literature an approximate algorithm for computing Radon transform is introduces which reduces the complexity of computations. But this algorithm is complex and need arbitrary accesses to memory. In this paper we proposed an algorithm which accesses to memory sequentially. In the following an architecture is introduced which uses pipeline to reduce the time complexity of algorithm.



### An End-to-End Spatio-Temporal Attention Model for Human Action Recognition from Skeleton Data
- **Arxiv ID**: http://arxiv.org/abs/1611.06067v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06067v1)
- **Published**: 2016-11-18 13:33:28+00:00
- **Updated**: 2016-11-18 13:33:28+00:00
- **Authors**: Sijie Song, Cuiling Lan, Junliang Xing, Wenjun Zeng, Jiaying Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Human action recognition is an important task in computer vision. Extracting discriminative spatial and temporal features to model the spatial and temporal evolutions of different actions plays a key role in accomplishing this task. In this work, we propose an end-to-end spatial and temporal attention model for human action recognition from skeleton data. We build our model on top of the Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), which learns to selectively focus on discriminative joints of skeleton within each frame of the inputs and pays different levels of attention to the outputs of different frames. Furthermore, to ensure effective training of the network, we propose a regularized cross-entropy loss to drive the model learning process and develop a joint training strategy accordingly. Experimental results demonstrate the effectiveness of the proposed model,both on the small human action recognition data set of SBU and the currently largest NTU dataset.



### DeepVO: A Deep Learning approach for Monocular Visual Odometry
- **Arxiv ID**: http://arxiv.org/abs/1611.06069v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06069v1)
- **Published**: 2016-11-18 13:41:22+00:00
- **Updated**: 2016-11-18 13:41:22+00:00
- **Authors**: Vikram Mohanty, Shubh Agrawal, Shaswat Datta, Arna Ghosh, Vishnu Dutt Sharma, Debashish Chakravarty
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Learning based techniques have been adopted with precision to solve a lot of standard computer vision problems, some of which are image classification, object detection and segmentation. Despite the widespread success of these approaches, they have not yet been exploited largely for solving the standard perception related problems encountered in autonomous navigation such as Visual Odometry (VO), Structure from Motion (SfM) and Simultaneous Localization and Mapping (SLAM). This paper analyzes the problem of Monocular Visual Odometry using a Deep Learning-based framework, instead of the regular 'feature detection and tracking' pipeline approaches. Several experiments were performed to understand the influence of a known/unknown environment, a conventional trackable feature and pre-trained activations tuned for object classification on the network's ability to accurately estimate the motion trajectory of the camera (or the vehicle). Based on these observations, we propose a Convolutional Neural Network architecture, best suited for estimating the object's pose under known environment conditions, and displays promising results when it comes to inferring the actual scale using just a single camera in real-time.



### Fast low-level pattern matching algorithm
- **Arxiv ID**: http://arxiv.org/abs/1611.06115v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, q-bio.GN
- **Links**: [PDF](http://arxiv.org/pdf/1611.06115v1)
- **Published**: 2016-11-18 15:05:30+00:00
- **Updated**: 2016-11-18 15:05:30+00:00
- **Authors**: Janja Paliska Soldo, Ana Sovic Krzic, and Damir Sersic
- **Comment**: 14 pages, 7 tables This work has been fully supported by Croatian
  Science Foundation under the project UIP-11-2013-7353 Algorithms for Genome
  Sequence Analysis
- **Journal**: None
- **Summary**: This paper focuses on pattern matching in the DNA sequence. It was inspired by a previously reported method that proposes encoding both pattern and sequence using prime numbers. Although fast, the method is limited to rather small pattern lengths, due to computing precision problem. Our approach successfully deals with large patterns, due to our implementation that uses modular arithmetic. In order to get the results very fast, the code was adapted for multithreading and parallel implementations. The method is reduced to assembly language level instructions, thus the final result shows significant time and memory savings compared to the reference algorithm.



### AFFACT - Alignment-Free Facial Attribute Classification Technique
- **Arxiv ID**: http://arxiv.org/abs/1611.06158v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06158v2)
- **Published**: 2016-11-18 17:06:22+00:00
- **Updated**: 2017-08-04 23:53:03+00:00
- **Authors**: Manuel Günther, Andras Rozsa, Terrance E. Boult
- **Comment**: This is a pre-print of the original paper accepted for oral
  presentation at the International Joint Conference on Biometrics (IJCB) 2017
- **Journal**: None
- **Summary**: Facial attributes are soft-biometrics that allow limiting the search space, e.g., by rejecting identities with non-matching facial characteristics such as nose sizes or eyebrow shapes. In this paper, we investigate how the latest versions of deep convolutional neural networks, ResNets, perform on the facial attribute classification task. We test two loss functions: the sigmoid cross-entropy loss and the Euclidean loss, and find that for classification performance there is little difference between these two. Using an ensemble of three ResNets, we obtain the new state-of-the-art facial attribute classification error of 8.00% on the aligned images of the CelebA dataset. More significantly, we introduce the Alignment-Free Facial Attribute Classification Technique (AFFACT), a data augmentation technique that allows a network to classify facial attributes without requiring alignment beyond detected face bounding boxes. To our best knowledge, we are the first to report similar accuracy when using only the detected bounding boxes -- rather than requiring alignment based on automatically detected facial landmarks -- and who can improve classification accuracy with rotating and scaling test images. We show that this approach outperforms the CelebA baseline on unaligned images with a relative improvement of 36.8%.



### End-to-End Subtitle Detection and Recognition for Videos in East Asian Languages via CNN Ensemble with Near-Human-Level Performance
- **Arxiv ID**: http://arxiv.org/abs/1611.06159v1
- **DOI**: 10.1016/j.image.2017.09.013
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06159v1)
- **Published**: 2016-11-18 17:09:14+00:00
- **Updated**: 2016-11-18 17:09:14+00:00
- **Authors**: Yan Xu, Siyuan Shan, Ziming Qiu, Zhipeng Jia, Zhengyang Shen, Yipei Wang, Mengfei Shi, Eric I-Chao Chang
- **Comment**: 35 pages
- **Journal**: None
- **Summary**: In this paper, we propose an innovative end-to-end subtitle detection and recognition system for videos in East Asian languages. Our end-to-end system consists of multiple stages. Subtitles are firstly detected by a novel image operator based on the sequence information of consecutive video frames. Then, an ensemble of Convolutional Neural Networks (CNNs) trained on synthetic data is adopted for detecting and recognizing East Asian characters. Finally, a dynamic programming approach leveraging language models is applied to constitute results of the entire body of text lines. The proposed system achieves average end-to-end accuracies of 98.2% and 98.3% on 40 videos in Simplified Chinese and 40 videos in Traditional Chinese respectively, which is a significant outperformance of other existing methods. The near-perfect accuracy of our system dramatically narrows the gap between human cognitive ability and state-of-the-art algorithms used for such a task.



### LOTS about Attacking Deep Features
- **Arxiv ID**: http://arxiv.org/abs/1611.06179v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06179v5)
- **Published**: 2016-11-18 17:59:23+00:00
- **Updated**: 2018-05-31 16:12:20+00:00
- **Authors**: Andras Rozsa, Manuel Günther, Terrance E. Boult
- **Comment**: Accepted to the International Joint Conference on Biometrics (IJCB)
  2017
- **Journal**: None
- **Summary**: Deep neural networks provide state-of-the-art performance on various tasks and are, therefore, widely used in real world applications. DNNs are becoming frequently utilized in biometrics for extracting deep features, which can be used in recognition systems for enrolling and recognizing new individuals. It was revealed that deep neural networks suffer from a fundamental problem, namely, they can unexpectedly misclassify examples formed by slightly perturbing correctly recognized inputs. Various approaches have been developed for generating these so-called adversarial examples, but they aim at attacking end-to-end networks. For biometrics, it is natural to ask whether systems using deep features are immune to or, at least, more resilient to attacks than end-to-end networks. In this paper, we introduce a general technique called the layerwise origin-target synthesis (LOTS) that can be efficiently used to form adversarial examples that mimic the deep features of the target. We analyze and compare the adversarial robustness of the end-to-end VGG Face network with systems that use Euclidean or cosine distance between gallery templates and extracted deep features. We demonstrate that iterative LOTS is very effective and show that systems utilizing deep features are easier to attack than the end-to-end network.



### Expert Gate: Lifelong Learning with a Network of Experts
- **Arxiv ID**: http://arxiv.org/abs/1611.06194v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1611.06194v2)
- **Published**: 2016-11-18 18:50:15+00:00
- **Updated**: 2017-04-19 09:25:55+00:00
- **Authors**: Rahaf Aljundi, Punarjay Chakravarty, Tinne Tuytelaars
- **Comment**: CVPR 2017 paper
- **Journal**: None
- **Summary**: In this paper we introduce a model of lifelong learning, based on a Network of Experts. New tasks / experts are learned and added to the model sequentially, building on what was learned before. To ensure scalability of this process,data from previous tasks cannot be stored and hence is not available when learning a new task. A critical issue in such context, not addressed in the literature so far, relates to the decision which expert to deploy at test time. We introduce a set of gating autoencoders that learn a representation for the task at hand, and, at test time, automatically forward the test sample to the relevant expert. This also brings memory efficiency as only one expert network has to be loaded into memory at any given time. Further, the autoencoders inherently capture the relatedness of one task to another, based on which the most relevant prior model to be used for training a new expert, with finetuning or learning without-forgetting, can be selected. We evaluate our method on image classification and video prediction problems.



### Ear Recognition: More Than a Survey
- **Arxiv ID**: http://arxiv.org/abs/1611.06203v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.06203v2)
- **Published**: 2016-11-18 19:32:03+00:00
- **Updated**: 2019-02-01 09:08:25+00:00
- **Authors**: Žiga Emeršič, Vitomir Štruc, Peter Peer
- **Comment**: 17 pages, paper accepted to Neurocomputing
- **Journal**: None
- **Summary**: Automatic identity recognition from ear images represents an active field of research within the biometric community. The ability to capture ear images from a distance and in a covert manner makes the technology an appealing choice for surveillance and security applications as well as other application domains. Significant contributions have been made in the field over recent years, but open research problems still remain and hinder a wider (commercial) deployment of the technology. This paper presents an overview of the field of automatic ear recognition (from 2D images) and focuses specifically on the most recent, descriptor-based methods proposed in this area. Open challenges are discussed and potential research directions are outlined with the goal of providing the reader with a point of reference for issues worth examining in the future. In addition to a comprehensive review on ear recognition technology, the paper also introduces a new, fully unconstrained dataset of ear images gathered from the web and a toolbox implementing several state-of-the-art techniques for ear recognition. The dataset and toolbox are meant to address some of the open issues in the field and are made publicly available to the research community.



### NoiseOut: A Simple Way to Prune Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1611.06211v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1611.06211v1)
- **Published**: 2016-11-18 19:55:29+00:00
- **Updated**: 2016-11-18 19:55:29+00:00
- **Authors**: Mohammad Babaeizadeh, Paris Smaragdis, Roy H. Campbell
- **Comment**: None
- **Journal**: None
- **Summary**: Neural networks are usually over-parameterized with significant redundancy in the number of required neurons which results in unnecessary computation and memory usage at inference time. One common approach to address this issue is to prune these big networks by removing extra neurons and parameters while maintaining the accuracy. In this paper, we propose NoiseOut, a fully automated pruning algorithm based on the correlation between activations of neurons in the hidden layers. We prove that adding additional output neurons with entirely random targets results into a higher correlation between neurons which makes pruning by NoiseOut even more efficient. Finally, we test our method on various networks and datasets. These experiments exhibit high pruning rates while maintaining the accuracy of the original network.



### ModelHub: Towards Unified Data and Lifecycle Management for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1611.06224v1
- **DOI**: None
- **Categories**: **cs.DB**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1611.06224v1)
- **Published**: 2016-11-18 20:59:25+00:00
- **Updated**: 2016-11-18 20:59:25+00:00
- **Authors**: Hui Miao, Ang Li, Larry S. Davis, Amol Deshpande
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning has improved state-of-the-art results in many important fields, and has been the subject of much research in recent years, leading to the development of several systems for facilitating deep learning. Current systems, however, mainly focus on model building and training phases, while the issues of data management, model sharing, and lifecycle management are largely ignored. Deep learning modeling lifecycle generates a rich set of data artifacts, such as learned parameters and training logs, and comprises of several frequently conducted tasks, e.g., to understand the model behaviors and to try out new models. Dealing with such artifacts and tasks is cumbersome and largely left to the users. This paper describes our vision and implementation of a data and lifecycle management system for deep learning. First, we generalize model exploration and model enumeration queries from commonly conducted tasks by deep learning modelers, and propose a high-level domain specific language (DSL), inspired by SQL, to raise the abstraction level and accelerate the modeling process. To manage the data artifacts, especially the large amount of checkpointed float parameters, we design a novel model versioning system (dlv), and a read-optimized parameter archival storage system (PAS) that minimizes storage footprint and accelerates query workloads without losing accuracy. PAS archives versioned models using deltas in a multi-resolution fashion by separately storing the less significant bits, and features a novel progressive query (inference) evaluation algorithm. Third, we show that archiving versioned models using deltas poses a new dataset versioning problem and we develop efficient algorithms for solving it. We conduct extensive experiments over several real datasets from computer vision domain to show the efficiency of the proposed techniques.



