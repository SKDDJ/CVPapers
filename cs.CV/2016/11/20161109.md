# Arxiv Papers in cs.CV on 2016-11-09
### Generative Shape Models: Joint Text Recognition and Segmentation with Very Little Training Data
- **Arxiv ID**: http://arxiv.org/abs/1611.02788v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.02788v1)
- **Published**: 2016-11-09 01:12:38+00:00
- **Updated**: 2016-11-09 01:12:38+00:00
- **Authors**: Xinghua Lou, Ken Kansky, Wolfgang Lehrach, CC Laan, Bhaskara Marthi, D. Scott Phoenix, Dileep George
- **Comment**: None
- **Journal**: Advances in Neural Information Processing Systems 2016
- **Summary**: We demonstrate that a generative model for object shapes can achieve state of the art results on challenging scene text recognition tasks, and with orders of magnitude fewer training images than required for competing discriminative methods. In addition to transcribing text from challenging images, our method performs fine-grained instance segmentation of characters. We show that our model is more robust to both affine transformations and non-affine deformations compared to previous approaches.



### Semi-Supervised Recognition of the Diploglossus Millepunctatus Lizard Species using Artificial Vision Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1611.02803v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.02803v1)
- **Published**: 2016-11-09 02:54:59+00:00
- **Updated**: 2016-11-09 02:54:59+00:00
- **Authors**: Jhony-Heriberto Giraldo-Zuluaga, Augusto Salazar, Juan M. Daza
- **Comment**: arXiv admin note: text overlap with arXiv:1603.00841
- **Journal**: None
- **Summary**: Animal biometrics is an important requirement for monitoring and conservation tasks. The classical animal biometrics risk the animals' integrity, are expensive for numerous animals, and depend on expert criterion. The non-invasive biometrics techniques offer alternatives to manage the aforementioned problems. In this paper we propose an automatic segmentation and identification algorithm based on artificial vision algorithms to recognize Diploglossus millepunctatus. Diploglossus millepunctatus is an endangered lizard species. The algorithm is based on two stages: automatic segmentation to remove the subjective evaluation, and one identification stage to reduce the analysis time. A 82.87% of correct segmentation in average is reached. Meanwhile the identification algorithm is achieved with euclidean distance point algorithms such as Iterative Closest Point and Procrustes Analysis. A performance of 92.99% on the top 1, and a 96.82% on the top 5 is reached. The developed software, and the database used in this paper are publicly available for download from the web page of the project.



### The Little Engine that Could: Regularization by Denoising (RED)
- **Arxiv ID**: http://arxiv.org/abs/1611.02862v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1611.02862v3)
- **Published**: 2016-11-09 09:32:29+00:00
- **Updated**: 2017-09-03 10:36:54+00:00
- **Authors**: Yaniv Romano, Michael Elad, Peyman Milanfar
- **Comment**: None
- **Journal**: None
- **Summary**: Removal of noise from an image is an extensively studied problem in image processing. Indeed, the recent advent of sophisticated and highly effective denoising algorithms lead some to believe that existing methods are touching the ceiling in terms of noise removal performance. Can we leverage this impressive achievement to treat other tasks in image processing? Recent work has answered this question positively, in the form of the Plug-and-Play Prior ($P^3$) method, showing that any inverse problem can be handled by sequentially applying image denoising steps. This relies heavily on the ADMM optimization technique in order to obtain this chained denoising interpretation.   Is this the only way in which tasks in image processing can exploit the image denoising engine? In this paper we provide an alternative, more powerful and more flexible framework for achieving the same goal. As opposed to the $P^3$ method, we offer Regularization by Denoising (RED): using the denoising engine in defining the regularization of the inverse problem. We propose an explicit image-adaptive Laplacian-based regularization functional, making the overall objective functional clearer and better defined. With a complete flexibility to choose the iterative optimization procedure for minimizing the above functional, RED is capable of incorporating any image denoising algorithm, treat general inverse problems very effectively, and is guaranteed to converge to the globally optimal result. We test this approach and demonstrate state-of-the-art results in the image deblurring and super-resolution problems.



### Gaussian process regression can turn non-uniform and undersampled diffusion MRI data into diffusion spectrum imaging
- **Arxiv ID**: http://arxiv.org/abs/1611.02869v1
- **DOI**: 10.1109/ISBI.2017.7950634
- **Categories**: **stat.AP**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1611.02869v1)
- **Published**: 2016-11-09 09:54:47+00:00
- **Updated**: 2016-11-09 09:54:47+00:00
- **Authors**: Jens Sjölund, Anders Eklund, Evren Özarslan, Hans Knutsson
- **Comment**: 5 pages
- **Journal**: 2017 IEEE 14th International Symposium on Biomedical Imaging (ISBI
  2017)
- **Summary**: We propose to use Gaussian process regression to accurately estimate the diffusion MRI signal at arbitrary locations in q-space. By estimating the signal on a grid, we can do synthetic diffusion spectrum imaging: reconstructing the ensemble averaged propagator (EAP) by an inverse Fourier transform. We also propose an alternative reconstruction method guaranteeing a nonnegative EAP that integrates to unity. The reconstruction is validated on data simulated from two Gaussians at various crossing angles. Moreover, we demonstrate on non-uniformly sampled in vivo data that the method is far superior to linear interpolation, and allows a drastic undersampling of the data with only a minor loss of accuracy. We envision the method as a potential replacement for standard diffusion spectrum imaging, in particular when acquistion time is limited.



### Audio Visual Speech Recognition using Deep Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1611.02879v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1611.02879v1)
- **Published**: 2016-11-09 10:24:52+00:00
- **Updated**: 2016-11-09 10:24:52+00:00
- **Authors**: Abhinav Thanda, Shankar M Venkatesan
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we propose a training algorithm for an audio-visual automatic speech recognition (AV-ASR) system using deep recurrent neural network (RNN).First, we train a deep RNN acoustic model with a Connectionist Temporal Classification (CTC) objective function. The frame labels obtained from the acoustic model are then used to perform a non-linear dimensionality reduction of the visual features using a deep bottleneck network. Audio and visual features are fused and used to train a fusion RNN. The use of bottleneck features for visual modality helps the model to converge properly during training. Our system is evaluated on GRID corpus. Our results show that presence of visual modality gives significant improvement in character error rate (CER) at various levels of noise even when the model is trained without noisy data. We also provide a comparison of two fusion methods: feature fusion and decision fusion.



### Node-Adapt, Path-Adapt and Tree-Adapt:Model-Transfer Domain Adaptation for Random Forest
- **Arxiv ID**: http://arxiv.org/abs/1611.02886v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.02886v1)
- **Published**: 2016-11-09 10:59:58+00:00
- **Updated**: 2016-11-09 10:59:58+00:00
- **Authors**: Azadeh S. Mozafari, David Vazquez, Mansour Jamzad, Antonio M. Lopez
- **Comment**: None
- **Journal**: None
- **Summary**: Random Forest (RF) is a successful paradigm for learning classifiers due to its ability to learn from large feature spaces and seamlessly integrate multi-class classification, as well as the achieved accuracy and processing efficiency. However, as many other classifiers, RF requires domain adaptation (DA) provided that there is a mismatch between the training (source) and testing (target) domains which provokes classification degradation. Consequently, different RF-DA methods have been proposed, which not only require target-domain samples but revisiting the source-domain ones, too. As novelty, we propose three inherently different methods (Node-Adapt, Path-Adapt and Tree-Adapt) that only require the learned source-domain RF and a relatively few target-domain samples for DA, i.e. source-domain samples do not need to be available. To assess the performance of our proposals we focus on image-based object detection, using the pedestrian detection problem as challenging proof-of-concept. Moreover, we use the RF with expert nodes because it is a competitive patch-based pedestrian model. We test our Node-, Path- and Tree-Adapt methods in standard benchmarks, showing that DA is largely achieved.



### Optimal Surface Segmentation with Convex Priors in Irregularly Sampled Space
- **Arxiv ID**: http://arxiv.org/abs/1611.03059v3
- **DOI**: 10.1016/j.media.2019.02.004
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.03059v3)
- **Published**: 2016-11-09 19:46:49+00:00
- **Updated**: 2019-02-14 19:38:25+00:00
- **Authors**: Abhay Shah, Michael D. Abramoff, Xiaodong Wu
- **Comment**: 20 pages, Medical Image Analysis (2019)
- **Journal**: None
- **Summary**: Optimal surface segmentation is a state-of-the-art method used for segmentation of multiple globally optimal surfaces in volumetric datasets. The method is widely used in numerous medical image segmentation applications. However, nodes in the graph based optimal surface segmentation method typically encode uniformly distributed orthogonal voxels of the volume. Thus the segmentation cannot attain an accuracy greater than a single unit voxel, i.e. the distance between two adjoining nodes in graph space. Segmentation accuracy higher than a unit voxel is achievable by exploiting partial volume information in the voxels which shall result in non-equidistant spacing between adjoining graph nodes. This paper reports a generalized graph based multiple surface segmentation method with convex priors which can optimally segment the target surfaces in an irregularly sampled space. The proposed method allows non-equidistant spacing between the adjoining graph nodes to achieve subvoxel segmentation accuracy by utilizing the partial volume information in the voxels. The partial volume information in the voxels is exploited by computing a displacement field from the original volume data to identify the subvoxel-accurate centers within each voxel resulting in non-equidistant spacing between the adjoining graph nodes. The smoothness of each surface modeled as a convex constraint governs the connectivity and regularity of the surface. We employ an edge-based graph representation to incorporate the necessary constraints and the globally optimal solution is obtained by computing a minimum s-t cut. The proposed method was validated on 10 intravascular multi-frame ultrasound image datasets for subvoxel segmentation accuracy. In all cases, the approach yielded highly accurate results. Our approach can be readily extended to higher-dimensional segmentations.



### Computationally Efficient Target Classification in Multispectral Image Data with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1611.03130v1
- **DOI**: 10.1117/12.2241383
- **Categories**: **cs.CV**, cs.AI, cs.NE, eess.IV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1611.03130v1)
- **Published**: 2016-11-09 23:13:18+00:00
- **Updated**: 2016-11-09 23:13:18+00:00
- **Authors**: Lukas Cavigelli, Dominic Bernath, Michele Magno, Luca Benini
- **Comment**: Presented at SPIE Security + Defence 2016 Proc. SPIE 9997, Target and
  Background Signatures II
- **Journal**: None
- **Summary**: Detecting and classifying targets in video streams from surveillance cameras is a cumbersome, error-prone and expensive task. Often, the incurred costs are prohibitive for real-time monitoring. This leads to data being stored locally or transmitted to a central storage site for post-incident examination. The required communication links and archiving of the video data are still expensive and this setup excludes preemptive actions to respond to imminent threats. An effective way to overcome these limitations is to build a smart camera that transmits alerts when relevant video sequences are detected. Deep neural networks (DNNs) have come to outperform humans in visual classifications tasks. The concept of DNNs and Convolutional Networks (ConvNets) can easily be extended to make use of higher-dimensional input data such as multispectral data. We explore this opportunity in terms of achievable accuracy and required computational effort. To analyze the precision of DNNs for scene labeling in an urban surveillance scenario we have created a dataset with 8 classes obtained in a field experiment. We combine an RGB camera with a 25-channel VIS-NIR snapshot sensor to assess the potential of multispectral image data for target classification. We evaluate several new DNNs, showing that the spectral information fused together with the RGB frames can be used to improve the accuracy of the system or to achieve similar accuracy with a 3x smaller computation effort. We achieve a very high per-pixel accuracy of 99.1%. Even for scarcely occurring, but particularly interesting classes, such as cars, 75% of the pixels are labeled correctly with errors occurring only around the border of the objects. This high accuracy was obtained with a training set of only 30 labeled images, paving the way for fast adaptation to various application scenarios.



