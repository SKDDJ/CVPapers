# Arxiv Papers in cs.CV on 2016-06-01
### A Comparative Study of Algorithms for Realtime Panoramic Video Blending
- **Arxiv ID**: http://arxiv.org/abs/1606.00103v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00103v2)
- **Published**: 2016-06-01 03:26:43+00:00
- **Updated**: 2016-12-24 03:01:32+00:00
- **Authors**: Zhe Zhu, Jiaming Lu, Minxuan Wang, Songhai Zhang, Ralph Martin, Hantao Liu, Shimin Hu
- **Comment**: 13 pages
- **Journal**: None
- **Summary**: Unlike image blending algorithms, video blending algorithms have been little studied. In this paper, we investigate 6 popular blending algorithms---feather blending, multi-band blending, modified Poisson blending, mean value coordinate blending, multi-spline blending and convolution pyramid blending. We consider in particular realtime panoramic video blending, a key problem in various virtual reality tasks. To evaluate the performance of the 6 algorithms on this problem, we have created a video benchmark of several videos captured under various conditions. We analyze the time and memory needed by the above 6 algorithms, for both CPU and GPU implementations (where readily parallelizable). The visual quality provided by these algorithms is also evaluated both objectively and subjectively. The video benchmark and algorithm implementations are publicly available.



### OpenSalicon: An Open Source Implementation of the Salicon Saliency Model
- **Arxiv ID**: http://arxiv.org/abs/1606.00110v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00110v1)
- **Published**: 2016-06-01 04:28:10+00:00
- **Updated**: 2016-06-01 04:28:10+00:00
- **Authors**: Christopher Thomas
- **Comment**: Github Repository: https://github.com/CLT29/OpenSALICON
- **Journal**: None
- **Summary**: In this technical report, we present our publicly downloadable implementation of the SALICON saliency model. At the time of this writing, SALICON is one of the top performing saliency models on the MIT 300 fixation prediction dataset which evaluates how well an algorithm is able to predict where humans would look in a given image. Recently, numerous models have achieved state-of-the-art performance on this benchmark, but none of the top 5 performing models (including SALICON) are available for download. To address this issue, we have created a publicly downloadable implementation of the SALICON model. It is our hope that our model will engender further research in visual attention modeling by providing a baseline for comparison of other algorithms and a platform for extending this implementation. The model we provide supports both training and testing, enabling researchers to quickly fine-tune the model on their own dataset. We also provide a pre-trained model and code for those users who only need to generate saliency maps for images without training their own model.



### Self-Paced Learning: an Implicit Regularization Perspective
- **Arxiv ID**: http://arxiv.org/abs/1606.00128v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1606.00128v3)
- **Published**: 2016-06-01 06:18:29+00:00
- **Updated**: 2016-09-18 15:32:47+00:00
- **Authors**: Yanbo Fan, Ran He, Jian Liang, Bao-Gang Hu
- **Comment**: 12 pages, 3 figures
- **Journal**: None
- **Summary**: Self-paced learning (SPL) mimics the cognitive mechanism of humans and animals that gradually learns from easy to hard samples. One key issue in SPL is to obtain better weighting strategy that is determined by minimizer function. Existing methods usually pursue this by artificially designing the explicit form of SPL regularizer. In this paper, we focus on the minimizer function, and study a group of new regularizer, named self-paced implicit regularizer that is deduced from robust loss function. Based on the convex conjugacy theory, the minimizer function for self-paced implicit regularizer can be directly learned from the latent loss function, while the analytic form of the regularizer can be even known. A general framework (named SPL-IR) for SPL is developed accordingly. We demonstrate that the learning procedure of SPL-IR is associated with latent robust loss functions, thus can provide some theoretical inspirations for its working mechanism. We further analyze the relation between SPL-IR and half-quadratic optimization. Finally, we implement SPL-IR to both supervised and unsupervised tasks, and experimental results corroborate our ideas and demonstrate the correctness and effectiveness of implicit regularizers.



### Mapping and Localization from Planar Markers
- **Arxiv ID**: http://arxiv.org/abs/1606.00151v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00151v2)
- **Published**: 2016-06-01 07:47:07+00:00
- **Updated**: 2017-01-25 08:33:27+00:00
- **Authors**: Rafael Muñoz-Salinas, Manuel J. Marín-Jimenez, Enrique Yeguas-Bolivar, Rafael Medina-Carnicer
- **Comment**: Paper submitted to journal. Code available. See webpage
  http://www.uco.es/investiga/grupos/ava/node/57/
- **Journal**: None
- **Summary**: Squared planar markers are a popular tool for fast, accurate and robust camera localization, but its use is frequently limited to a single marker, or at most, to a small set of them for which their relative pose is known beforehand. Mapping and localization from a large set of planar markers is yet a scarcely treated problem in favour of keypoint-based approaches. However, while keypoint detectors are not robust to rapid motion, large changes in viewpoint, or significant changes in appearance, fiducial markers can be robustly detected under a wider range of conditions. This paper proposes a novel method to simultaneously solve the problems of mapping and localization from a set of squared planar markers. First, a quiver of pairwise relative marker poses is created, from which an initial pose graph is obtained. The pose graph may contain small pairwise pose errors, that when propagated, leads to large errors. Thus, we distribute the rotational and translational error along the basis cycles of the graph so as to obtain a corrected pose graph. Finally, we perform a global pose optimization by minimizing the reprojection errors of the planar markers in all observed frames. The experiments conducted show that our method performs better than Structure from Motion and visual SLAM techniques.



### Multiview Rectification of Folded Documents
- **Arxiv ID**: http://arxiv.org/abs/1606.00166v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00166v1)
- **Published**: 2016-06-01 08:29:51+00:00
- **Updated**: 2016-06-01 08:29:51+00:00
- **Authors**: Shaodi You, Yasuyuki Matsushita, Sudipta Sinha, Yusuke Bou, Katsushi Ikeuchi
- **Comment**: 8 pages; under review
- **Journal**: None
- **Summary**: Digitally unwrapping images of paper sheets is crucial for accurate document scanning and text recognition. This paper presents a method for automatically rectifying curved or folded paper sheets from a few images captured from multiple viewpoints. Prior methods either need expensive 3D scanners or model deformable surfaces using over-simplified parametric representations. In contrast, our method uses regular images and is based on general developable surface models that can represent a wide variety of paper deformations. Our main contribution is a new robust rectification method based on ridge-aware 3D reconstruction of a paper sheet and unwrapping the reconstructed surface using properties of developable surfaces via $\ell_1$ conformal mapping. We present results on several examples including book pages, folded letters and shopping receipts.



### A Survey on Learning to Hash
- **Arxiv ID**: http://arxiv.org/abs/1606.00185v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00185v2)
- **Published**: 2016-06-01 09:23:48+00:00
- **Updated**: 2017-04-22 00:19:47+00:00
- **Authors**: Jingdong Wang, Ting Zhang, Jingkuan Song, Nicu Sebe, Heng Tao Shen
- **Comment**: To appear in IEEE Transactions On Pattern Analysis and Machine
  Intelligence (TPAMI)
- **Journal**: None
- **Summary**: Nearest neighbor search is a problem of finding the data points from the database such that the distances from them to the query point are the smallest. Learning to hash is one of the major solutions to this problem and has been widely studied recently. In this paper, we present a comprehensive survey of the learning to hash algorithms, categorize them according to the manners of preserving the similarities into: pairwise similarity preserving, multiwise similarity preserving, implicit similarity preserving, as well as quantization, and discuss their relations. We separate quantization from pairwise similarity preserving as the objective function is very different though quantization, as we show, can be derived from preserving the pairwise similarities. In addition, we present the evaluation protocols, and the general performance analysis, and point out that the quantization algorithms perform superiorly in terms of search accuracy, search time cost, and space cost. Finally, we introduce a few emerging topics.



### Hyperspectral Subspace Identification Using SURE
- **Arxiv ID**: http://arxiv.org/abs/1606.00219v1
- **DOI**: 10.1109/LGRS.2015.2485999
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00219v1)
- **Published**: 2016-06-01 11:01:54+00:00
- **Updated**: 2016-06-01 11:01:54+00:00
- **Authors**: Behnood Rasti, Magnus O. Ulfarsson, Johannes R. Sveinsson
- **Comment**: Technical Report. A shorten version of this paper has been published
  in the IEEE Geoscience and Remote Sensing Letters
- **Journal**: None
- **Summary**: Remote sensing hyperspectral sensors collect large volumes of high dimensional spectral and spatial data. However, due to spectral and spatial redundancy the true hyperspectral signal lies on a subspace of much lower dimension than the original data. The identification of the signal subspace is a very important first step for most hyperspectral algorithms. In this paper we investigate the important problem of identifying the hyperspectral signal subspace by minimizing the mean squared error (MSE) between the true signal and an estimate of the signal. Since the MSE is uncomputable in practice, due to its dependency on the true signal, we propose a method based on the Stein's unbiased risk estimator (SURE) that provides an unbiased estimate of the MSE. The resulting method is simple and fully automatic and we evaluate it using both simulated and real hyperspectral data sets. Experimental results shows that our proposed method compares well to recent state-of-the-art subspace identification methods.



### Improving Deep Neural Network with Multiple Parametric Exponential Linear Units
- **Arxiv ID**: http://arxiv.org/abs/1606.00305v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00305v3)
- **Published**: 2016-06-01 14:33:17+00:00
- **Updated**: 2017-01-17 08:44:56+00:00
- **Authors**: Yang Li, Chunxiao Fan, Yong Li, Qiong Wu, Yue Ming
- **Comment**: None
- **Journal**: None
- **Summary**: Activation function is crucial to the recent successes of deep neural networks. In this paper, we first propose a new activation function, Multiple Parametric Exponential Linear Units (MPELU), aiming to generalize and unify the rectified and exponential linear units. As the generalized form, MPELU shares the advantages of Parametric Rectified Linear Unit (PReLU) and Exponential Linear Unit (ELU), leading to better classification performance and convergence property. In addition, weight initialization is very important to train very deep networks. The existing methods laid a solid foundation for networks using rectified linear units but not for exponential linear units. This paper complements the current theory and extends it to the wider range. Specifically, we put forward a way of initialization, enabling training of very deep networks using exponential linear units. Experiments demonstrate that the proposed initialization not only helps the training process but leads to better generalization performance. Finally, utilizing the proposed activation function and initialization, we present a deep MPELU residual architecture that achieves state-of-the-art performance on the CIFAR-10/100 datasets. The code is available at https://github.com/Coldmooon/Code-for-MPELU.



### Deeper Depth Prediction with Fully Convolutional Residual Networks
- **Arxiv ID**: http://arxiv.org/abs/1606.00373v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00373v2)
- **Published**: 2016-06-01 18:03:00+00:00
- **Updated**: 2016-09-19 09:40:59+00:00
- **Authors**: Iro Laina, Christian Rupprecht, Vasileios Belagiannis, Federico Tombari, Nassir Navab
- **Comment**: Published at IEEE International Conference on 3D Vision (3DV) 2016
- **Journal**: None
- **Summary**: This paper addresses the problem of estimating the depth map of a scene given a single RGB image. We propose a fully convolutional architecture, encompassing residual learning, to model the ambiguous mapping between monocular images and depth maps. In order to improve the output resolution, we present a novel way to efficiently learn feature map up-sampling within the network. For optimization, we introduce the reverse Huber loss that is particularly suited for the task at hand and driven by the value distributions commonly present in depth maps. Our model is composed of a single architecture that is trained end-to-end and does not rely on post-processing techniques, such as CRFs or other additional refinement steps. As a result, it runs in real-time on images or videos. In the evaluation, we show that the proposed model contains fewer parameters and requires fewer training data than the current state of the art, while outperforming all approaches on depth estimation. Code and models are publicly available.



### A 3D Face Modelling Approach for Pose-Invariant Face Recognition in a Human-Robot Environment
- **Arxiv ID**: http://arxiv.org/abs/1606.00474v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC, cs.RO, 68T45, 68T40, 68T10, I.2.9; I.2.10; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1606.00474v1)
- **Published**: 2016-06-01 21:28:27+00:00
- **Updated**: 2016-06-01 21:28:27+00:00
- **Authors**: Michael Grupp, Philipp Kopp, Patrik Huber, Matthias Rätsch
- **Comment**: None
- **Journal**: None
- **Summary**: Face analysis techniques have become a crucial component of human-machine interaction in the fields of assistive and humanoid robotics. However, the variations in head-pose that arise naturally in these environments are still a great challenge. In this paper, we present a real-time capable 3D face modelling framework for 2D in-the-wild images that is applicable for robotics. The fitting of the 3D Morphable Model is based exclusively on automatically detected landmarks. After fitting, the face can be corrected in pose and transformed back to a frontal 2D representation that is more suitable for face recognition. We conduct face recognition experiments with non-frontal images from the MUCT database and uncontrolled, in the wild images from the PaSC database, the most challenging face recognition database to date, showing an improved performance. Finally, we present our SCITOS G5 robot system, which incorporates our framework as a means of image pre-processing for face analysis.



### Recurrent Fully Convolutional Networks for Video Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1606.00487v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.00487v3)
- **Published**: 2016-06-01 22:27:41+00:00
- **Updated**: 2016-10-31 00:05:49+00:00
- **Authors**: Sepehr Valipour, Mennatullah Siam, Martin Jagersand, Nilanjan Ray
- **Comment**: None
- **Journal**: None
- **Summary**: Image segmentation is an important step in most visual tasks. While convolutional neural networks have shown to perform well on single image segmentation, to our knowledge, no study has been been done on leveraging recurrent gated architectures for video segmentation. Accordingly, we propose a novel method for online segmentation of video sequences that incorporates temporal data. The network is built from fully convolutional element and recurrent unit that works on a sliding window over the temporal data. We also introduce a novel convolutional gated recurrent unit that preserves the spatial information and reduces the parameters learned. Our method has the advantage that it can work in an online fashion instead of operating over the whole input batch of video frames. The network is tested on the change detection dataset, and proved to have 5.5\% improvement in F-measure over a plain fully convolutional network for per frame segmentation. It was also shown to have improvement of 1.4\% for the F-measure compared to our baseline network that we call FCN 12s.



### On the equivalence between Kolmogorov-Smirnov and ROC curve metrics for binary classification
- **Arxiv ID**: http://arxiv.org/abs/1606.00496v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, I.2; I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1606.00496v1)
- **Published**: 2016-06-01 23:12:53+00:00
- **Updated**: 2016-06-01 23:12:53+00:00
- **Authors**: Paulo J. L. Adeodato, Sílvio B. Melo
- **Comment**: 5 pages, 5 figures
- **Journal**: None
- **Summary**: Binary decisions are very common in artificial intelligence. Applying a threshold on the continuous score gives the human decider the power to control the operating point to separate the two classes. The classifier,s discriminating power is measured along the continuous range of the score by the Area Under the ROC curve (AUC_ROC) in most application fields. Only finances uses the poor single point metric maximum Kolmogorov-Smirnov (KS) distance. This paper proposes the Area Under the KS curve (AUC_KS) for performance assessment and proves AUC_ROC = 0.5 + AUC_KS, as a simpler way to calculate the AUC_ROC. That is even more important for ROC averaging in ensembles of classifiers or n fold cross-validation. The proof is geometrically inspired on rotating all KS curve to make it lie on the top of the ROC chance diagonal. On the practical side, the independent variable on the abscissa on the KS curve simplifies the calculation of the AUC_ROC. On the theoretical side, this research gives insights on probabilistic interpretations of classifiers assessment and integrates the existing body of knowledge of the information theoretical ROC approach with the proposed statistical approach based on the thoroughly known KS distribution.



