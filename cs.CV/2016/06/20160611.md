# Arxiv Papers in cs.CV on 2016-06-11
### Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?
- **Arxiv ID**: http://arxiv.org/abs/1606.03556v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1606.03556v2)
- **Published**: 2016-06-11 05:41:10+00:00
- **Updated**: 2016-06-17 04:39:01+00:00
- **Authors**: Abhishek Das, Harsh Agrawal, C. Lawrence Zitnick, Devi Parikh, Dhruv Batra
- **Comment**: 9 pages, 6 figures, 3 tables; Under review at EMNLP 2016
- **Journal**: None
- **Summary**: We conduct large-scale studies on `human attention' in Visual Question Answering (VQA) to understand where humans choose to look to answer questions about images. We design and test multiple game-inspired novel attention-annotation interfaces that require the subject to sharpen regions of a blurred image to answer a question. Thus, we introduce the VQA-HAT (Human ATtention) dataset. We evaluate attention maps generated by state-of-the-art VQA models against human attention both qualitatively (via visualizations) and quantitatively (via rank-order correlation). Overall, our experiments show that current attention models in VQA do not seem to be looking at the same regions as humans.



### Universal Correspondence Network
- **Arxiv ID**: http://arxiv.org/abs/1606.03558v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03558v3)
- **Published**: 2016-06-11 06:27:09+00:00
- **Updated**: 2016-10-31 06:32:03+00:00
- **Authors**: Christopher B. Choy, JunYoung Gwak, Silvio Savarese, Manmohan Chandraker
- **Comment**: To appear at NIPS 2016 as full oral presentation
- **Journal**: None
- **Summary**: We present a deep learning framework for accurate visual correspondences and demonstrate its effectiveness for both geometric and semantic matching, spanning across rigid motions to intra-class shape or appearance variations. In contrast to previous CNN-based approaches that optimize a surrogate patch similarity objective, we use deep metric learning to directly learn a feature space that preserves either geometric or semantic similarity. Our fully convolutional architecture, along with a novel correspondence contrastive loss allows faster training by effective reuse of computations, accurate gradient computation through the use of thousands of examples per image pair and faster testing with $O(n)$ feed forward passes for $n$ keypoints, instead of $O(n^2)$ for typical patch similarity methods. We propose a convolutional spatial transformer to mimic patch normalization in traditional features like SIFT, which is shown to dramatically boost accuracy for semantic correspondences across intra-class shape variations. Extensive experiments on KITTI, PASCAL, and CUB-2011 datasets demonstrate the significant advantages of our features over prior works that use either hand-constructed or learned features.



### Alternative Technique to Asymmetry Analysis-Based Overlapping for Foot Ulcer Examination: Scalable Scanning
- **Arxiv ID**: http://arxiv.org/abs/1606.03578v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03578v1)
- **Published**: 2016-06-11 11:07:55+00:00
- **Updated**: 2016-06-11 11:07:55+00:00
- **Authors**: Naima Kaabouch, Wen-Chen Hu, Yi Chen
- **Comment**: Journal of Diabetes & Metabolism, 2012
- **Journal**: None
- **Summary**: Asymmetry analysis based on the overlapping of thermal images proved able to detect inflammation and, predict foot ulceration. This technique involves three main steps: segmentation, geometric transformation, and overlapping. However, the overlapping technique, which consists of subtracting the intensity levels of the right foot from those of the left foot, can also detect false abnormal areas if the projections of the left and right feet are not the same. In this paper, we present an alternative technique to asymmetry analysis-based overlapping. The proposed technique, scalable scanning, allows for an effective comparison even if the shapes and sizes of the feet projections appear differently in the image. The tested results show that asymmetry analysis- based scalable scanning provides fewer false abnormal areas than does asymmetry analysis -based overlapping.



### TRex: A Tomography Reconstruction Proximal Framework for Robust Sparse View X-Ray Applications
- **Arxiv ID**: http://arxiv.org/abs/1606.03601v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1606.03601v1)
- **Published**: 2016-06-11 14:19:28+00:00
- **Updated**: 2016-06-11 14:19:28+00:00
- **Authors**: Mohamed Aly, Guangming Zang, Wolfgang Heidrich, Peter Wonka
- **Comment**: None
- **Journal**: None
- **Summary**: We present TRex, a flexible and robust Tomographic Reconstruction framework using proximal algorithms. We provide an overview and perform an experimental comparison between the famous iterative reconstruction methods in terms of reconstruction quality in sparse view situations. We then derive the proximal operators for the four best methods. We show the flexibility of our framework by deriving solvers for two noise models: Gaussian and Poisson; and by plugging in three powerful regularizers. We compare our framework to state of the art methods, and show superior quality on both synthetic and real datasets.



