# Arxiv Papers in cs.CV on 2016-06-12
### Training Recurrent Answering Units with Joint Loss Minimization for VQA
- **Arxiv ID**: http://arxiv.org/abs/1606.03647v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03647v2)
- **Published**: 2016-06-12 00:47:46+00:00
- **Updated**: 2016-09-30 03:31:53+00:00
- **Authors**: Hyeonwoo Noh, Bohyung Han
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel algorithm for visual question answering based on a recurrent deep neural network, where every module in the network corresponds to a complete answering unit with attention mechanism by itself. The network is optimized by minimizing loss aggregated from all the units, which share model parameters while receiving different information to compute attention probability. For training, our model attends to a region within image feature map, updates its memory based on the question and attended image feature, and answers the question based on its memory state. This procedure is performed to compute loss in each step. The motivation of this approach is our observation that multi-step inferences are often required to answer questions while each problem may have a unique desirable number of steps, which is difficult to identify in practice. Hence, we always make the first unit in the network solve problems, but allow it to learn the knowledge from the rest of units by backpropagation unless it degrades the model. To implement this idea, we early-stop training each unit as soon as it starts to overfit. Note that, since more complex models tend to overfit on easier questions quickly, the last answering unit in the unfolded recurrent neural network is typically killed first while the first one remains last. We make a single-step prediction for a new question using the shared model. This strategy works better than the other options within our framework since the selected model is trained effectively from all units without overfitting. The proposed algorithm outperforms other multi-step attention based approaches using a single step prediction in VQA dataset.



### Color-based Segmentation of Sky/Cloud Images From Ground-based Cameras
- **Arxiv ID**: http://arxiv.org/abs/1606.03669v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03669v1)
- **Published**: 2016-06-12 06:17:10+00:00
- **Updated**: 2016-06-12 06:17:10+00:00
- **Authors**: Soumyabrata Dev, Yee Hui Lee, Stefan Winkler
- **Comment**: None
- **Journal**: None
- **Summary**: Sky/cloud images captured by ground-based cameras (a.k.a. whole sky imagers) are increasingly used nowadays because of their applications in a number of fields, including climate modeling, weather prediction, renewable energy generation, and satellite communications. Due to the wide variety of cloud types and lighting conditions in such images, accurate and robust segmentation of clouds is challenging. In this paper, we present a supervised segmentation framework for ground-based sky/cloud images based on a systematic analysis of different color spaces and components, using partial least squares (PLS) regression. Unlike other state-of-the-art methods, our proposed approach is entirely learning-based and does not require any manually-defined parameters. In addition, we release the Singapore Whole Sky IMaging SEGmentation Database (SWIMSEG), a large database of annotated sky/cloud images, to the research community.



### Segmentation of scanning electron microscopy images from natural rubber samples with gold nanoparticles using starlet wavelets
- **Arxiv ID**: http://arxiv.org/abs/1606.03671v1
- **DOI**: 10.1002/jemt.22314
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03671v1)
- **Published**: 2016-06-12 06:33:20+00:00
- **Updated**: 2016-06-12 06:33:20+00:00
- **Authors**: Alexandre Fioravante de Siqueira, Fl√°vio Camargo Cabrera, Aylton Pagamisse, Aldo Eloizo Job
- **Comment**: None
- **Journal**: None
- **Summary**: Electronic microscopy has been used for morphology evaluation of different materials structures. However, microscopy results may be affected by several factors. Image processing methods can be used to correct and improve the quality of these results. In this paper we propose an algorithm based on starlets to perform the segmentation of scanning electron microscopy images. An application is presented in order to locate gold nanoparticles in natural rubber membranes. In this application, our method showed accuracy greater than 85% for all test images. Results given by this method will be used in future studies, to computationally estimate the density distribution of gold nanoparticles in natural rubber samples and to predict reduction kinetics of gold nanoparticles at different time periods.



### A constrained clustering based approach for matching a collection of feature sets
- **Arxiv ID**: http://arxiv.org/abs/1606.03731v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03731v1)
- **Published**: 2016-06-12 15:40:30+00:00
- **Updated**: 2016-06-12 15:40:30+00:00
- **Authors**: Junchi Yan, Zhe Ren, Hongyuan Zha, Stephen Chu
- **Comment**: submission to ICPR 2016
- **Journal**: None
- **Summary**: In this paper, we consider the problem of finding the feature correspondences among a collection of feature sets, by using their point-wise unary features. This is a fundamental problem in computer vision and pattern recognition, which also closely relates to other areas such as operational research. Different from two-set matching which can be transformed to a quadratic assignment programming task that is known NP-hard, inclusion of merely unary attributes leads to a linear assignment problem for matching two feature sets. This problem has been well studied and there are effective polynomial global optimum solvers such as the Hungarian method. However, it becomes ill-posed when the unary attributes are (heavily) corrupted. The global optimal correspondence concerning the best score defined by the attribute affinity/cost between the two sets can be distinct to the ground truth correspondence since the score function is biased by noises. To combat this issue, we devise a method for matching a collection of feature sets by synergetically exploring the information across the sets. In general, our method can be perceived from a (constrained) clustering perspective: in each iteration, it assigns the features of one set to the clusters formed by the rest of feature sets, and updates the cluster centers in turn. Results on both synthetic data and real images suggest the efficacy of our method against state-of-the-arts.



### Adaptive Local Window for Level Set Segmentation of CT and MRI Liver Lesions
- **Arxiv ID**: http://arxiv.org/abs/1606.03765v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03765v1)
- **Published**: 2016-06-12 21:31:38+00:00
- **Updated**: 2016-06-12 21:31:38+00:00
- **Authors**: Assaf Hoogi, Christopher F. Beaulieu, Guilherme M. Cunha, Elhamy Heba, Claude B. Sirlin, Sandy Napel, Daniel L. Rubin
- **Comment**: 24 pages, 11 figures, 3 tables
- **Journal**: None
- **Summary**: We propose a novel method, the adaptive local window, for improving level set segmentation technique. The window is estimated separately for each contour point, over iterations of the segmentation process, and for each individual object. Our method considers the object scale, the spatial texture, and changes of the energy functional over iterations. Global and local statistics are considered by calculating several gray level co-occurrence matrices. We demonstrate the capabilities of the method in the domain of medical imaging for segmenting 233 images with liver lesions. To illustrate the strength of our method, those images were obtained by either Computed Tomography or Magnetic Resonance Imaging. Moreover, we analyzed images using three different energy models. We compare our method to a global level set segmentation and to local framework that uses predefined fixed-size square windows. The results indicate that our proposed method outperforms the other methods in terms of agreement with the manual marking and dependence on contour initialization or the energy model used. In case of complex lesions, such as low contrast lesions, heterogeneous lesions, or lesions with a noisy background, our method shows significantly better segmentation with an improvement of 0.25+- 0.13 in Dice similarity coefficient, compared with state of the art fixed-size local windows (Wilcoxon, p < 0.001).



### Human Centred Object Co-Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1606.03774v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.03774v1)
- **Published**: 2016-06-12 22:36:53+00:00
- **Updated**: 2016-06-12 22:36:53+00:00
- **Authors**: Chenxia Wu, Jiemi Zhang, Ashutosh Saxena, Silvio Savarese
- **Comment**: None
- **Journal**: None
- **Summary**: Co-segmentation is the automatic extraction of the common semantic regions given a set of images. Different from previous approaches mainly based on object visuals, in this paper, we propose a human centred object co-segmentation approach, which uses the human as another strong evidence. In order to discover the rich internal structure of the objects reflecting their human-object interactions and visual similarities, we propose an unsupervised fully connected CRF auto-encoder incorporating the rich object features and a novel human-object interaction representation. We propose an efficient learning and inference algorithm to allow the full connectivity of the CRF with the auto-encoder, that establishes pairwise relations on all pairs of the object proposals in the dataset. Moreover, the auto-encoder learns the parameters from the data itself rather than supervised learning or manually assigned parameters in the conventional CRF. In the extensive experiments on four datasets, we show that our approach is able to extract the common objects more accurately than the state-of-the-art co-segmentation algorithms.



