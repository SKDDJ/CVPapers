# Arxiv Papers in cs.CV on 2016-06-24
### Disjunctive Normal Level Set: An Efficient Parametric Implicit Method
- **Arxiv ID**: http://arxiv.org/abs/1606.07511v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.07511v1)
- **Published**: 2016-06-24 00:08:14+00:00
- **Updated**: 2016-06-24 00:08:14+00:00
- **Authors**: Fitsum Mesadi, Mujdat Cetin, Tolga Tasdizen
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Level set methods are widely used for image segmentation because of their capability to handle topological changes. In this paper, we propose a novel parametric level set method called Disjunctive Normal Level Set (DNLS), and apply it to both two phase (single object) and multiphase (multi-object) image segmentations. The DNLS is formed by union of polytopes which themselves are formed by intersections of half-spaces. The proposed level set framework has the following major advantages compared to other level set methods available in the literature. First, segmentation using DNLS converges much faster. Second, the DNLS level set function remains regular throughout its evolution. Third, the proposed multiphase version of the DNLS is less sensitive to initialization, and its computational cost and memory requirement remains almost constant as the number of objects to be simultaneously segmented grows. The experimental results show the potential of the proposed method.



### Coupled Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1606.07536v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.07536v2)
- **Published**: 2016-06-24 01:20:06+00:00
- **Updated**: 2016-09-20 17:01:49+00:00
- **Authors**: Ming-Yu Liu, Oncel Tuzel
- **Comment**: To be published in NIPS 2016
- **Journal**: None
- **Summary**: We propose coupled generative adversarial network (CoGAN) for learning a joint distribution of multi-domain images. In contrast to the existing approaches, which require tuples of corresponding images in different domains in the training set, CoGAN can learn a joint distribution without any tuple of corresponding images. It can learn a joint distribution with just samples drawn from the marginal distributions. This is achieved by enforcing a weight-sharing constraint that limits the network capacity and favors a joint distribution solution over a product of marginal distributions one. We apply CoGAN to several joint distribution learning tasks, including learning a joint distribution of color and depth images, and learning a joint distribution of face images with different attributes. For each task it successfully learns the joint distribution without any tuple of corresponding images. We also demonstrate its applications to domain adaptation and image transformation.



### Multipartite Ranking-Selection of Low-Dimensional Instances by Supervised Projection to High-Dimensional Space
- **Arxiv ID**: http://arxiv.org/abs/1606.07575v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1606.07575v1)
- **Published**: 2016-06-24 06:15:45+00:00
- **Updated**: 2016-06-24 06:15:45+00:00
- **Authors**: Arash Shahriari
- **Comment**: 15 pages, 1 figure, 2 tables, 3 algorithms, 1 appendix
- **Journal**: None
- **Summary**: Pruning of redundant or irrelevant instances of data is a key to every successful solution for pattern recognition. In this paper, we present a novel ranking-selection framework for low-length but highly correlated instances. Instead of working in the low-dimensional instance space, we learn a supervised projection to high-dimensional space spanned by the number of classes in the dataset under study. Imposing higher distinctions via exposing the notion of labels to the instances, lets to deploy one versus all ranking for each individual classes and selecting quality instances via adaptive thresholding of the overall scores. To prove the efficiency of our paradigm, we employ it for the purpose of texture understanding which is a hard recognition challenge due to high similarity of texture pixels and low dimensionality of their color features. Our experiments show considerable improvements in recognition performance over other local descriptors on several publicly available datasets.



### Fully DNN-based Multi-label regression for audio tagging
- **Arxiv ID**: http://arxiv.org/abs/1606.07695v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1606.07695v2)
- **Published**: 2016-06-24 14:17:34+00:00
- **Updated**: 2016-08-13 10:39:29+00:00
- **Authors**: Yong Xu, Qiang Huang, Wenwu Wang, Philip J. B. Jackson, Mark D. Plumbley
- **Comment**: Submitted to DCASE2016 Workshop which is as a satellite event to the
  2016 European Signal Processing Conference (EUSIPCO)
- **Journal**: None
- **Summary**: Acoustic event detection for content analysis in most cases relies on lots of labeled data. However, manually annotating data is a time-consuming task, which thus makes few annotated resources available so far. Unlike audio event detection, automatic audio tagging, a multi-label acoustic event classification task, only relies on weakly labeled data. This is highly desirable to some practical applications using audio analysis. In this paper we propose to use a fully deep neural network (DNN) framework to handle the multi-label classification task in a regression way. Considering that only chunk-level rather than frame-level labels are available, the whole or almost whole frames of the chunk were fed into the DNN to perform a multi-label regression for the expected tags. The fully DNN, which is regarded as an encoding function, can well map the audio features sequence to a multi-tag vector. A deep pyramid structure was also designed to extract more robust high-level features related to the target tags. Further improved methods were adopted, such as the Dropout and background noise aware training, to enhance its generalization capability for new audio recordings in mismatched environments. Compared with the conventional Gaussian Mixture Model (GMM) and support vector machine (SVM) methods, the proposed fully DNN-based method could well utilize the long-term temporal information with the whole chunk as the input. The results show that our approach obtained a 15% relative improvement compared with the official GMM-based method of DCASE 2016 challenge.



### A Taxonomy and Library for Visualizing Learned Features in Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1606.07757v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.07757v1)
- **Published**: 2016-06-24 16:40:24+00:00
- **Updated**: 2016-06-24 16:40:24+00:00
- **Authors**: Felix Gr√ºn, Christian Rupprecht, Nassir Navab, Federico Tombari
- **Comment**: None
- **Journal**: None
- **Summary**: Over the last decade, Convolutional Neural Networks (CNN) saw a tremendous surge in performance. However, understanding what a network has learned still proves to be a challenging task. To remedy this unsatisfactory situation, a number of groups have recently proposed different methods to visualize the learned models. In this work we suggest a general taxonomy to classify and compare these methods, subdividing the literature into three main categories and providing researchers with a terminology to base their works on. Furthermore, we introduce the FeatureVis library for MatConvNet: an extendable, easy to use open source library for visualizing CNNs. It contains implementations from each of the three main classes of visualization methods and serves as a useful tool for an enhanced understanding of the features learned by intermediate layers, as well as for the analysis of why a network might fail for certain examples.



### Captioning Images with Diverse Objects
- **Arxiv ID**: http://arxiv.org/abs/1606.07770v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1606.07770v3)
- **Published**: 2016-06-24 17:53:45+00:00
- **Updated**: 2017-07-20 18:06:27+00:00
- **Authors**: Subhashini Venugopalan, Lisa Anne Hendricks, Marcus Rohrbach, Raymond Mooney, Trevor Darrell, Kate Saenko
- **Comment**: CVPR 2017 Camera ready version. 17 pages (8 + 9 supplement), 12
  figures, 8 tables. Includes project page
  http://vsubhashini.github.io/noc.html
- **Journal**: None
- **Summary**: Recent captioning models are limited in their ability to scale and describe concepts unseen in paired image-text corpora. We propose the Novel Object Captioner (NOC), a deep visual semantic captioning model that can describe a large number of object categories not present in existing image-caption datasets. Our model takes advantage of external sources -- labeled images from object recognition datasets, and semantic knowledge extracted from unannotated text. We propose minimizing a joint objective which can learn from these diverse data sources and leverage distributional semantic embeddings, enabling the model to generalize and describe novel objects outside of image-caption datasets. We demonstrate that our model exploits semantic information to generate captions for hundreds of object categories in the ImageNet object recognition dataset that are not observed in MSCOCO image-caption training data, as well as many categories that are observed very rarely. Both automatic evaluations and human judgements show that our model considerably outperforms prior work in being able to describe many more categories of objects.



### Modeling and Inferring Human Intents and Latent Functional Objects for Trajectory Prediction
- **Arxiv ID**: http://arxiv.org/abs/1606.07827v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.07827v1)
- **Published**: 2016-06-24 20:15:12+00:00
- **Updated**: 2016-06-24 20:15:12+00:00
- **Authors**: Dan Xie, Tianmin Shu, Sinisa Todorovic, Song-Chun Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: This paper is about detecting functional objects and inferring human intentions in surveillance videos of public spaces. People in the videos are expected to intentionally take shortest paths toward functional objects subject to obstacles, where people can satisfy certain needs (e.g., a vending machine can quench thirst), by following one of three possible intent behaviors: reach a single functional object and stop, or sequentially visit several functional objects, or initially start moving toward one goal but then change the intent to move toward another. Since detecting functional objects in low-resolution surveillance videos is typically unreliable, we call them "dark matter" characterized by the functionality to attract people. We formulate the Agent-based Lagrangian Mechanics wherein human trajectories are probabilistically modeled as motions of agents in many layers of "dark-energy" fields, where each agent can select a particular force field to affect its motions, and thus define the minimum-energy Dijkstra path toward the corresponding source "dark matter". For evaluation, we compiled and annotated a new dataset. The results demonstrate our effectiveness in predicting human intent behaviors and trajectories, and localizing functional objects, as well as discovering distinct functional classes of objects by clustering human motion behavior in the vicinity of functional objects.



### Spatial Aggregation of Holistically-Nested Networks for Automated Pancreas Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1606.07830v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1606.07830v1)
- **Published**: 2016-06-24 20:21:59+00:00
- **Updated**: 2016-06-24 20:21:59+00:00
- **Authors**: Holger R. Roth, Le Lu, Amal Farag, Andrew Sohn, Ronald M. Summers
- **Comment**: This article will be presented at MICCAI (Medical Image Computing and
  Computer-Assisted Interventions), Athens, Greece, 2016
- **Journal**: None
- **Summary**: Accurate automatic organ segmentation is an important yet challenging problem for medical image analysis. The pancreas is an abdominal organ with very high anatomical variability. This inhibits traditional segmentation methods from achieving high accuracies, especially compared to other organs such as the liver, heart or kidneys. In this paper, we present a holistic learning approach that integrates semantic mid-level cues of deeply-learned organ interior and boundary maps via robust spatial aggregation using random forest. Our method generates boundary preserving pixel-wise class labels for pancreas segmentation. Quantitative evaluation is performed on CT scans of 82 patients in 4-fold cross-validation. We achieve a (mean $\pm$ std. dev.) Dice Similarity Coefficient of 78.01% $\pm$ 8.2% in testing which significantly outperforms the previous state-of-the-art approach of 71.8% $\pm$ 10.7% under the same evaluation criterion.



### Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles
- **Arxiv ID**: http://arxiv.org/abs/1606.07839v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1606.07839v3)
- **Published**: 2016-06-24 21:48:55+00:00
- **Updated**: 2016-10-05 17:12:00+00:00
- **Authors**: Stefan Lee, Senthil Purushwalkam, Michael Cogswell, Viresh Ranjan, David Crandall, Dhruv Batra
- **Comment**: None
- **Journal**: None
- **Summary**: Many practical perception systems exist within larger processes that include interactions with users or additional components capable of evaluating the quality of predicted solutions. In these contexts, it is beneficial to provide these oracle mechanisms with multiple highly likely hypotheses rather than a single prediction. In this work, we pose the task of producing multiple outputs as a learning problem over an ensemble of deep networks -- introducing a novel stochastic gradient descent based approach to minimize the loss with respect to an oracle. Our method is simple to implement, agnostic to both architecture and loss function, and parameter-free. Our approach achieves lower oracle error compared to existing methods on a wide range of tasks and deep architectures. We also show qualitatively that the diverse solutions produced often provide interpretable representations of task ambiguity.



