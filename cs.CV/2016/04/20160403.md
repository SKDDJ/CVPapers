# Arxiv Papers in cs.CV on 2016-04-03
### HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1604.00600v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.00600v1)
- **Published**: 2016-04-03 06:52:14+00:00
- **Updated**: 2016-04-03 06:52:14+00:00
- **Authors**: Tao Kong, Anbang Yao, Yurong Chen, Fuchun Sun
- **Comment**: Accepted as a spotlight oral paper by CVPR 2016
- **Journal**: None
- **Summary**: Almost all of the current top-performing object detection networks employ region proposals to guide the search for object instances. State-of-the-art region proposal methods usually need several thousand proposals to get high recall, thus hurting the detection efficiency. Although the latest Region Proposal Network method gets promising detection accuracy with several hundred proposals, it still struggles in small-size object detection and precise localization (e.g., large IoU thresholds), mainly due to the coarseness of its feature maps. In this paper, we present a deep hierarchical network, namely HyperNet, for handling region proposal generation and object detection jointly. Our HyperNet is primarily based on an elaborately designed Hyper Feature which aggregates hierarchical feature maps first and then compresses them into a uniform space. The Hyper Features well incorporate deep but highly semantic, intermediate but really complementary, and shallow but naturally high-resolution features of the image, thus enabling us to construct HyperNet by sharing them both in generating proposals and detecting objects via an end-to-end joint training strategy. For the deep VGG16 model, our method achieves completely leading recall and state-of-the-art object detection accuracy on PASCAL VOC 2007 and 2012 using only 100 proposals per image. It runs with a speed of 5 fps (including all steps) on a GPU, thus having the potential for real-time processing.



### GAL: A Global-Attributes Assisted Labeling System for Outdoor Scenes
- **Arxiv ID**: http://arxiv.org/abs/1604.00606v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.00606v1)
- **Published**: 2016-04-03 07:36:50+00:00
- **Updated**: 2016-04-03 07:36:50+00:00
- **Authors**: Yuzhuo Ren, Chen Chen, Shangwen Li, C. -C. Jay Kuo
- **Comment**: None
- **Journal**: None
- **Summary**: An approach that extracts global attributes from outdoor images to facilitate geometric layout labeling is investigated in this work. The proposed Global-attributes Assisted Labeling (GAL) system exploits both local features and global attributes. First, by following a classical method, we use local features to provide initial labels for all super-pixels. Then, we develop a set of techniques to extract global attributes from 2D outdoor images. They include sky lines, ground lines, vanishing lines, etc. Finally, we propose the GAL system that integrates global attributes in the conditional random field (CRF) framework to improve initial labels so as to offer a more robust labeling result. The performance of the proposed GAL system is demonstrated and benchmarked with several state-of-the-art algorithms against a popular outdoor scene layout dataset.



### Multi-Bias Non-linear Activation in Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1604.00676v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.00676v1)
- **Published**: 2016-04-03 19:31:22+00:00
- **Updated**: 2016-04-03 19:31:22+00:00
- **Authors**: Hongyang Li, Wanli Ouyang, Xiaogang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: As a widely used non-linear activation, Rectified Linear Unit (ReLU) separates noise and signal in a feature map by learning a threshold or bias. However, we argue that the classification of noise and signal not only depends on the magnitude of responses, but also the context of how the feature responses would be used to detect more abstract patterns in higher layers. In order to output multiple response maps with magnitude in different ranges for a particular visual pattern, existing networks employing ReLU and its variants have to learn a large number of redundant filters. In this paper, we propose a multi-bias non-linear activation (MBA) layer to explore the information hidden in the magnitudes of responses. It is placed after the convolution layer to decouple the responses to a convolution kernel into multiple maps by multi-thresholding magnitudes, thus generating more patterns in the feature space at a low computational cost. It provides great flexibility of selecting responses to different visual patterns in different magnitude ranges to form rich representations in higher layers. Such a simple and yet effective scheme achieves the state-of-the-art performance on several benchmarks.



