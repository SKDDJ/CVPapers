# Arxiv Papers in cs.CV on 2016-04-28
### Joint Line Segmentation and Transcription for End-to-End Handwritten Paragraph Recognition
- **Arxiv ID**: http://arxiv.org/abs/1604.08352v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1604.08352v1)
- **Published**: 2016-04-28 09:08:30+00:00
- **Updated**: 2016-04-28 09:08:30+00:00
- **Authors**: Th√©odore Bluche
- **Comment**: None
- **Journal**: None
- **Summary**: Offline handwriting recognition systems require cropped text line images for both training and recognition. On the one hand, the annotation of position and transcript at line level is costly to obtain. On the other hand, automatic line segmentation algorithms are prone to errors, compromising the subsequent recognition. In this paper, we propose a modification of the popular and efficient multi-dimensional long short-term memory recurrent neural networks (MDLSTM-RNNs) to enable end-to-end processing of handwritten paragraphs. More particularly, we replace the collapse layer transforming the two-dimensional representation into a sequence of predictions by a recurrent version which can recognize one line at a time. In the proposed model, a neural network performs a kind of implicit line segmentation by computing attention weights on the image representation. The experiments on paragraphs of Rimes and IAM database yield results that are competitive with those of networks trained at line level, and constitute a significant step towards end-to-end transcription of full documents.



### A Probabilistic Adaptive Search System for Exploring the Face Space
- **Arxiv ID**: http://arxiv.org/abs/1604.08524v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1604.08524v1)
- **Published**: 2016-04-28 17:23:42+00:00
- **Updated**: 2016-04-28 17:23:42+00:00
- **Authors**: Andres G. Abad, Luis I. Reyes Castro
- **Comment**: 6 pages, 12 figures
- **Journal**: None
- **Summary**: Face recall is a basic human cognitive process performed routinely, e.g., when meeting someone and determining if we have met that person before. Assisting a subject during face recall by suggesting candidate faces can be challenging. One of the reasons is that the search space - the face space - is quite large and lacks structure. A commercial application of face recall is facial composite systems - such as Identikit, PhotoFIT, and CD-FIT - where a witness searches for an image of a face that resembles his memory of a particular offender. The inherent uncertainty and cost in the evaluation of the objective function, the large size and lack of structure of the search space, and the unavailability of the gradient concept makes this problem inappropriate for traditional optimization methods. In this paper we propose a novel evolutionary approach for searching the face space that can be used as a facial composite system. The approach is inspired by methods of Bayesian optimization and differs from other applications in the use of the skew-normal distribution as its acquisition function. This choice of acquisition function provides greater granularity, with regularized, conservative, and realistic results.



### Artistic style transfer for videos
- **Arxiv ID**: http://arxiv.org/abs/1604.08610v2
- **DOI**: 10.1007/978-3-319-45886-1_3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.08610v2)
- **Published**: 2016-04-28 20:23:15+00:00
- **Updated**: 2016-10-19 20:01:09+00:00
- **Authors**: Manuel Ruder, Alexey Dosovitskiy, Thomas Brox
- **Comment**: final version appeared in GCPR-2016; minor changes to improve the
  clarity
- **Journal**: German Conference on Pattern Recognition (GCPR), LNCS 9796, pp.
  26-36 (2016)
- **Summary**: In the past, manually re-drawing an image in a certain artistic style required a professional artist and a long time. Doing this for a video sequence single-handed was beyond imagination. Nowadays computers provide new possibilities. We present an approach that transfers the style from one image (for example, a painting) to a whole video sequence. We make use of recent advances in style transfer in still images and propose new initializations and loss functions applicable to videos. This allows us to generate consistent and stable stylized video sequences, even in cases with large motion and strong occlusion. We show that the proposed method clearly outperforms simpler baselines both qualitatively and quantitatively.



