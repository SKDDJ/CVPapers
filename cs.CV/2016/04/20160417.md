# Arxiv Papers in cs.CV on 2016-04-17
### Visual saliency detection: a Kalman filter based approach
- **Arxiv ID**: http://arxiv.org/abs/1604.04825v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.04825v1)
- **Published**: 2016-04-17 03:48:45+00:00
- **Updated**: 2016-04-17 03:48:45+00:00
- **Authors**: Sourya Roy, Pabitra Mitra
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we propose a Kalman filter aided saliency detection model which is based on the conjecture that salient regions are considerably different from our "visual expectation" or they are "visually surprising" in nature. In this work, we have structured our model with an immediate objective to predict saliency in static images. However, the proposed model can be easily extended for space-time saliency prediction. Our approach was evaluated using two publicly available benchmark data sets and results have been compared with other existing saliency models. The results clearly illustrate the superior performance of the proposed model over other approaches.



### Subjects and Their Objects: Localizing Interactees for a Person-Centric View of Importance
- **Arxiv ID**: http://arxiv.org/abs/1604.04842v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.04842v1)
- **Published**: 2016-04-17 08:26:31+00:00
- **Updated**: 2016-04-17 08:26:31+00:00
- **Authors**: Chao-Yeh Chen, Kristen Grauman
- **Comment**: None
- **Journal**: None
- **Summary**: Understanding images with people often entails understanding their \emph{interactions} with other objects or people. As such, given a novel image, a vision system ought to infer which other objects/people play an important role in a given person's activity. However, existing methods are limited to learning action-specific interactions (e.g., how the pose of a tennis player relates to the position of his racquet when serving the ball) for improved recognition, making them unequipped to reason about novel interactions with actions or objects unobserved in the training data.   We propose to predict the "interactee" in novel images---that is, to localize the \emph{object} of a person's action. Given an arbitrary image with a detected person, the goal is to produce a saliency map indicating the most likely positions and scales where that person's interactee would be found. To that end, we explore ways to learn the generic, action-independent connections between (a) representations of a person's pose, gaze, and scene cues and (b) the interactee object's position and scale. We provide results on a newly collected UT Interactee dataset spanning more than 10,000 images from SUN, PASCAL, and COCO. We show that the proposed interaction-informed saliency metric has practical utility for four tasks: contextual object detection, image retargeting, predicting object importance, and data-driven natural language scene description. All four scenarios reveal the value in linking the subject to its object in order to understand the story of an image.



### Epipolar Geometry Based On Line Similarity
- **Arxiv ID**: http://arxiv.org/abs/1604.04848v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.04848v4)
- **Published**: 2016-04-17 09:14:22+00:00
- **Updated**: 2017-01-08 00:11:14+00:00
- **Authors**: Gil Ben-Artzi, Tavi Halperin, Michael Werman, Shmuel Peleg
- **Comment**: ICPR 2016, Cancun, Dec 2016
- **Journal**: ICPR'16, Cancun, Dec. 2016, pp. 1865-1870
- **Summary**: It is known that epipolar geometry can be computed from three epipolar line correspondences but this computation is rarely used in practice since there are no simple methods to find corresponding lines. Instead, methods for finding corresponding points are widely used. This paper proposes a similarity measure between lines that indicates whether two lines are corresponding epipolar lines and enables finding epipolar line correspondences as needed for the computation of epipolar geometry.   A similarity measure between two lines, suitable for video sequences of a dynamic scene, has been previously described. This paper suggests a stereo matching similarity measure suitable for images. It is based on the quality of stereo matching between the two lines, as corresponding epipolar lines yield a good stereo correspondence.   Instead of an exhaustive search over all possible pairs of lines, the search space is substantially reduced when two corresponding point pairs are given.   We validate the proposed method using real-world images and compare it to state-of-the-art methods. We found this method to be more accurate by a factor of five compared to the standard method using seven corresponding points and comparable to the 8-points algorithm.



### Generating Semi-Synthetic Validation Benchmarks for Embryomics
- **Arxiv ID**: http://arxiv.org/abs/1604.04906v1
- **DOI**: 10.1109/ISBI.2016.7493359
- **Categories**: **cs.CV**, q-bio.CB, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1604.04906v1)
- **Published**: 2016-04-17 18:29:48+00:00
- **Updated**: 2016-04-17 18:29:48+00:00
- **Authors**: Johannes Stegmaier, Julian Arz, Benjamin Schott, Jens C. Otte, Andrei Kobitski, G. Ulrich Nienhaus, Uwe Str√§hle, Peter Sanders, Ralf Mikut
- **Comment**: Accepted publication at IEEE International Symposium on Biomedical
  Imaging: From Nano to Macro (ISBI), 2016
- **Journal**: None
- **Summary**: Systematic validation is an essential part of algorithm development. The enormous dataset sizes and the complexity observed in many recent time-resolved 3D fluorescence microscopy imaging experiments, however, prohibit a comprehensive manual ground truth generation. Moreover, existing simulated benchmarks in this field are often too simple or too specialized to sufficiently validate the observed image analysis problems. We present a new semi-synthetic approach to generate realistic 3D+t benchmarks that combines challenging cellular movement dynamics of real embryos with simulated fluorescent nuclei and artificial image distortions including various parametrizable options like cell numbers, acquisition deficiencies or multiview simulations. We successfully applied the approach to simulate the development of a zebrafish embryo with thousands of cells over 14 hours of its early existence.



### Some medical applications of example-based super-resolution
- **Arxiv ID**: http://arxiv.org/abs/1604.04926v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1604.04926v1)
- **Published**: 2016-04-17 20:48:49+00:00
- **Updated**: 2016-04-17 20:48:49+00:00
- **Authors**: Ramin Zabih
- **Comment**: None
- **Journal**: None
- **Summary**: Example-based super-resolution (EBSR) reconstructs a high-resolution image from a low-resolution image, given a training set of high-resolution images. In this note I propose some applications of EBSR to medical imaging. A particular interesting application, which I call "x-ray voxelization", approximates the result of a CT scan from an x-ray image.



