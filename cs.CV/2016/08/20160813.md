# Arxiv Papers in cs.CV on 2016-08-13
### Human Pose Estimation from Depth Images via Inference Embedded Multi-task Learning
- **Arxiv ID**: http://arxiv.org/abs/1608.03932v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03932v1)
- **Published**: 2016-08-13 03:16:47+00:00
- **Updated**: 2016-08-13 03:16:47+00:00
- **Authors**: Keze Wang, Shengfu Zhai, Hui Cheng, Xiaodan Liang, Liang Lin
- **Comment**: To appear in ACM Multimedia 2016, full paper (oral), 10 pages, 11
  figures
- **Journal**: None
- **Summary**: Human pose estimation (i.e., locating the body parts / joints of a person) is a fundamental problem in human-computer interaction and multimedia applications. Significant progress has been made based on the development of depth sensors, i.e., accessible human pose prediction from still depth images [32]. However, most of the existing approaches to this problem involve several components/models that are independently designed and optimized, leading to suboptimal performances. In this paper, we propose a novel inference-embedded multi-task learning framework for predicting human pose from still depth images, which is implemented with a deep architecture of neural networks. Specifically, we handle two cascaded tasks: i) generating the heat (confidence) maps of body parts via a fully convolutional network (FCN); ii) seeking the optimal configuration of body parts based on the detected body part proposals via an inference built-in MatchNet [10], which measures the appearance and geometric kinematic compatibility of body parts and embodies the dynamic programming inference as an extra network layer. These two tasks are jointly optimized. Our extensive experiments show that the proposed deep model significantly improves the accuracy of human pose estimation over other several state-of-the-art methods or SDKs. We also release a large-scale dataset for comparison, which includes 100K depth images under challenging scenarios.



### Automated Selection of Uniform Regions for CT Image Quality Detection
- **Arxiv ID**: http://arxiv.org/abs/1608.04381v2
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.04381v2)
- **Published**: 2016-08-13 06:56:04+00:00
- **Updated**: 2016-08-19 19:08:58+00:00
- **Authors**: Maitham D Naeemi, Adam M Alessio, Sohini Roychowdhury
- **Comment**: 5 pages, 8 figures, Asilomar Conference on Signals, Systems, and
  Computers
- **Journal**: None
- **Summary**: CT images are widely used in pathology detection and follow-up treatment procedures. Accurate identification of pathological features requires diagnostic quality CT images with minimal noise and artifact variation. In this work, a novel Fourier-transform based metric for image quality (IQ) estimation is presented that correlates to additive CT image noise. In the proposed method, two windowed CT image subset regions are analyzed together to identify the extent of variation in the corresponding Fourier-domain spectrum. The two square windows are chosen such that their center pixels coincide and one window is a subset of the other. The Fourier-domain spectral difference between these two sub-sampled windows is then used to isolate spatial regions-of-interest (ROI) with low signal variation (ROI-LV) and high signal variation (ROI-HV), respectively. Finally, the spatial variance ($var$), standard deviation ($std$), coefficient of variance ($cov$) and the fraction of abdominal ROI pixels in ROI-LV ($\nu'(q)$), are analyzed with respect to CT image noise. For the phantom CT images, $var$ and $std$ correlate to CT image noise ($|r|>0.76$ ($p\ll0.001$)), though not as well as $\nu'(q)$ ($r=0.96$ ($p\ll0.001$)). However, for the combined phantom and patient CT images, $var$ and $std$ do not correlate well with CT image noise ($|r|<0.46$ ($p\ll0.001$)) as compared to $\nu'(q)$ ($r=0.95$ ($p\ll0.001$)). Thus, the proposed method and the metric, $\nu'(q)$, can be useful to quantitatively estimate CT image noise.



### Recurrent Fully Convolutional Neural Networks for Multi-slice MRI Cardiac Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1608.03974v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1608.03974v1)
- **Published**: 2016-08-13 11:19:22+00:00
- **Updated**: 2016-08-13 11:19:22+00:00
- **Authors**: Rudra P K Poudel, Pablo Lamata, Giovanni Montana
- **Comment**: MICCAI Workshop RAMBO 2016
- **Journal**: None
- **Summary**: In cardiac magnetic resonance imaging, fully-automatic segmentation of the heart enables precise structural and functional measurements to be taken, e.g. from short-axis MR images of the left-ventricle. In this work we propose a recurrent fully-convolutional network (RFCN) that learns image representations from the full stack of 2D slices and has the ability to leverage inter-slice spatial dependences through internal memory units. RFCN combines anatomical detection and segmentation into a single architecture that is trained end-to-end thus significantly reducing computational time, simplifying the segmentation pipeline, and potentially enabling real-time applications. We report on an investigation of RFCN using two datasets, including the publicly available MICCAI 2009 Challenge dataset. Comparisons have been carried out between fully convolutional networks and deep restricted Boltzmann machines, including a recurrent version that leverages inter-slice spatial correlation. Our studies suggest that RFCN produces state-of-the-art results and can substantially improve the delineation of contours near the apex of the heart.



### Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1608.03981v1
- **DOI**: 10.1109/TIP.2017.2662206
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03981v1)
- **Published**: 2016-08-13 13:33:28+00:00
- **Updated**: 2016-08-13 13:33:28+00:00
- **Authors**: Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, Lei Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise (AWGN) at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks such as Gaussian denoising, single image super-resolution and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.



