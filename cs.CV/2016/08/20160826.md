# Arxiv Papers in cs.CV on 2016-08-26
### Scalable Compression of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1608.07365v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07365v1)
- **Published**: 2016-08-26 05:08:24+00:00
- **Updated**: 2016-08-26 05:08:24+00:00
- **Authors**: Xing Wang, Jie Liang
- **Comment**: 5 pages, 4 figures, ACM Multimedia 2016
- **Journal**: None
- **Summary**: Deep neural networks generally involve some layers with mil- lions of parameters, making them difficult to be deployed and updated on devices with limited resources such as mobile phones and other smart embedded systems. In this paper, we propose a scalable representation of the network parameters, so that different applications can select the most suitable bit rate of the network based on their own storage constraints. Moreover, when a device needs to upgrade to a high-rate network, the existing low-rate network can be reused, and only some incremental data are needed to be downloaded. We first hierarchically quantize the weights of a pre-trained deep neural network to enforce weight sharing. Next, we adaptively select the bits assigned to each layer given the total bit budget. After that, we retrain the network to fine-tune the quantized centroids. Experimental results show that our method can achieve scalable compression with graceful degradation in the performance.



### An Octree-Based Approach towards Efficient Variational Range Data Fusion
- **Arxiv ID**: http://arxiv.org/abs/1608.07411v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07411v1)
- **Published**: 2016-08-26 10:01:51+00:00
- **Updated**: 2016-08-26 10:01:51+00:00
- **Authors**: Wadim Kehl, Tobias Holl, Federico Tombari, Slobodan Ilic, Nassir Navab
- **Comment**: BMVC 2016
- **Journal**: None
- **Summary**: Volume-based reconstruction is usually expensive both in terms of memory consumption and runtime. Especially for sparse geometric structures, volumetric representations produce a huge computational overhead. We present an efficient way to fuse range data via a variational Octree-based minimization approach by taking the actual range data geometry into account. We transform the data into Octree-based truncated signed distance fields and show how the optimization can be conducted on the newly created structures. The main challenge is to uphold speed and a low memory footprint without sacrificing the solutions' accuracy during optimization. We explain how to dynamically adjust the optimizer's geometric structure via joining/splitting of Octree nodes and how to define the operators. We evaluate on various datasets and outline the suitability in terms of performance and geometric accuracy.



### Mean Deviation Similarity Index: Efficient and Reliable Full-Reference Image Quality Evaluator
- **Arxiv ID**: http://arxiv.org/abs/1608.07433v4
- **DOI**: 10.1109/ACCESS.2016.2604042
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07433v4)
- **Published**: 2016-08-26 12:16:09+00:00
- **Updated**: 2017-04-19 05:41:11+00:00
- **Authors**: Hossein Ziaei Nafchi, Atena Shahkolaei, Rachid Hedjam, Mohamed Cheriet
- **Comment**: 11 pages, 8 figures, 6 tables
- **Journal**: None
- **Summary**: Applications of perceptual image quality assessment (IQA) in image and video processing, such as image acquisition, image compression, image restoration and multimedia communication, have led to the development of many IQA metrics. In this paper, a reliable full reference IQA model is proposed that utilize gradient similarity (GS), chromaticity similarity (CS), and deviation pooling (DP). By considering the shortcomings of the commonly used GS to model human visual system (HVS), a new GS is proposed through a fusion technique that is more likely to follow HVS. We propose an efficient and effective formulation to calculate the joint similarity map of two chromatic channels for the purpose of measuring color changes. In comparison with a commonly used formulation in the literature, the proposed CS map is shown to be more efficient and provide comparable or better quality predictions. Motivated by a recent work that utilizes the standard deviation pooling, a general formulation of the DP is presented in this paper and used to compute a final score from the proposed GS and CS maps. This proposed formulation of DP benefits from the Minkowski pooling and a proposed power pooling as well. The experimental results on six datasets of natural images, a synthetic dataset, and a digitally retouched dataset show that the proposed index provides comparable or better quality predictions than the most recent and competing state-of-the-art IQA metrics in the literature, it is reliable and has low complexity. The MATLAB source code of the proposed metric is available at https://www.mathworks.com/matlabcentral/fileexchange/59809.



### Hard Negative Mining for Metric Learning Based Zero-Shot Classification
- **Arxiv ID**: http://arxiv.org/abs/1608.07441v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1608.07441v1)
- **Published**: 2016-08-26 12:42:43+00:00
- **Updated**: 2016-08-26 12:42:43+00:00
- **Authors**: Maxime Bucher, Stéphane Herbin, Frédéric Jurie
- **Comment**: None
- **Journal**: ECCV 16 WS TASK-CV: Transferring and Adapting Source Knowledge in
  Computer Vision, Oct 2016, Amsterdam, Netherlands. ECCV 16 WS TASK-CV:
  Transferring and Adapting Source Knowledge in Computer Vision
- **Summary**: Zero-Shot learning has been shown to be an efficient strategy for domain adaptation. In this context, this paper builds on the recent work of Bucher et al. [1], which proposed an approach to solve Zero-Shot classification problems (ZSC) by introducing a novel metric learning based objective function. This objective function allows to learn an optimal embedding of the attributes jointly with a measure of similarity between images and attributes. This paper extends their approach by proposing several schemes to control the generation of the negative pairs, resulting in a significant improvement of the performance and giving above state-of-the-art results on three challenging ZSC datasets.



### Who Leads the Clothing Fashion: Style, Color, or Texture? A Computational Study
- **Arxiv ID**: http://arxiv.org/abs/1608.07444v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07444v1)
- **Published**: 2016-08-26 12:53:56+00:00
- **Updated**: 2016-08-26 12:53:56+00:00
- **Authors**: Qin Zou, Zheng Zhang, Qian Wang, Qingquan Li, Long Chen, Song Wang
- **Comment**: None
- **Journal**: None
- **Summary**: It is well known that clothing fashion is a distinctive and often habitual trend in the style in which a person dresses. Clothing fashions are usually expressed with visual stimuli such as style, color, and texture. However, it is not clear which visual stimulus places higher/lower influence on the updating of clothing fashion. In this study, computer vision and machine learning techniques are employed to analyze the influence of different visual stimuli on clothing-fashion updates. Specifically, a classification-based model is proposed to quantify the influence of different visual stimuli, in which each visual stimulus's influence is quantified by its corresponding accuracy in fashion classification. Experimental results demonstrate that, on clothing-fashion updates, the style holds a higher influence than the color, and the color holds a higher influence than the texture.



### Fine Hand Segmentation using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1608.07454v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07454v1)
- **Published**: 2016-08-26 13:40:08+00:00
- **Updated**: 2016-08-26 13:40:08+00:00
- **Authors**: Tadej Vodopivec, Vincent Lepetit, Peter Peer
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a method for extracting very accurate masks of hands in egocentric views. Our method is based on a novel Deep Learning architecture: In contrast with current Deep Learning methods, we do not use upscaling layers applied to a low-dimensional representation of the input image. Instead, we extract features with convolutional layers and map them directly to a segmentation mask with a fully connected layer. We show that this approach, when applied in a multi-scale fashion, is both accurate and efficient enough for real-time. We demonstrate it on a new dataset made of images captured in various environments, from the outdoors to offices.



### A Fast Ellipse Detector Using Projective Invariant Pruning
- **Arxiv ID**: http://arxiv.org/abs/1608.07470v1
- **DOI**: 10.1109/TIP.2017.2704660
- **Categories**: **cs.CV**, cs.CG, I.4.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1608.07470v1)
- **Published**: 2016-08-26 14:25:15+00:00
- **Updated**: 2016-08-26 14:25:15+00:00
- **Authors**: Qi Jia, Xin Fan, Zhongxuan Luo, Lianbo Song, Tie Qiu
- **Comment**: 14 pages, 34 figures, journal
- **Journal**: None
- **Summary**: Detecting elliptical objects from an image is a central task in robot navigation and industrial diagnosis where the detection time is always a critical issue. Existing methods are hardly applicable to these real-time scenarios of limited hardware resource due to the huge number of fragment candidates (edges or arcs) for fitting ellipse equations. In this paper, we present a fast algorithm detecting ellipses with high accuracy. The algorithm leverage a newly developed projective invariant to significantly prune the undesired candidates and to pick out elliptical ones. The invariant is able to reflect the intrinsic geometry of a planar curve, giving the value of -1 on any three collinear points and +1 for any six points on an ellipse. Thus, we apply the pruning and picking by simply comparing these binary values. Moreover, the calculation of the invariant only involves the determinant of a 3*3 matrix. Extensive experiments on three challenging data sets with 650 images demonstrate that our detector runs 20%-50% faster than the state-of-the-art algorithms with the comparable or higher precision.



### Mitosis Detection in Intestinal Crypt Images with Hough Forest and Conditional Random Fields
- **Arxiv ID**: http://arxiv.org/abs/1608.07616v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.07616v1)
- **Published**: 2016-08-26 21:53:30+00:00
- **Updated**: 2016-08-26 21:53:30+00:00
- **Authors**: Gerda Bortsova, Michael Sterr, Lichao Wang, Fausto Milletari, Nassir Navab, Anika Böttcher, Heiko Lickert, Fabian Theis, Tingying Peng
- **Comment**: Accepted at the 7th International Conference on Machine Learning in
  Medical Imaging
- **Journal**: None
- **Summary**: Intestinal enteroendocrine cells secrete hormones that are vital for the regulation of glucose metabolism but their differentiation from intestinal stem cells is not fully understood. Asymmetric stem cell divisions have been linked to intestinal stem cell homeostasis and secretory fate commitment. We monitored cell divisions using 4D live cell imaging of cultured intestinal crypts to characterize division modes by means of measurable features such as orientation or shape. A statistical analysis of these measurements requires annotation of mitosis events, which is currently a tedious and time-consuming task that has to be performed manually. To assist data processing, we developed a learning based method to automatically detect mitosis events. The method contains a dual-phase framework for joint detection of dividing cells (mothers) and their progeny (daughters). In the first phase we detect mother and daughters independently using Hough Forest whilst in the second phase we associate mother and daughters by modelling their joint probability as Conditional Random Field (CRF). The method has been evaluated on 32 movies and has achieved an AUC of 72%, which can be used in conjunction with manual correction and dramatically speed up the processing pipeline.



