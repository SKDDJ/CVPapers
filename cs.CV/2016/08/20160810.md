# Arxiv Papers in cs.CV on 2016-08-10
### Fashion Landmark Detection in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1608.03049v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03049v1)
- **Published**: 2016-08-10 05:07:10+00:00
- **Updated**: 2016-08-10 05:07:10+00:00
- **Authors**: Ziwei Liu, Sijie Yan, Ping Luo, Xiaogang Wang, Xiaoou Tang
- **Comment**: To appear in European Conference on Computer Vision (ECCV) 2016
- **Journal**: None
- **Summary**: Visual fashion analysis has attracted many attentions in the recent years. Previous work represented clothing regions by either bounding boxes or human joints. This work presents fashion landmark detection or fashion alignment, which is to predict the positions of functional key points defined on the fashion items, such as the corners of neckline, hemline, and cuff. To encourage future studies, we introduce a fashion landmark dataset with over 120K images, where each image is labeled with eight landmarks. With this dataset, we study fashion alignment by cascading multiple convolutional neural networks in three stages. These stages gradually improve the accuracies of landmark predictions. Extensive experiments demonstrate the effectiveness of the proposed method, as well as its generalization ability to pose estimation. Fashion landmark is also compared to clothing bounding boxes and human joints in two applications, fashion attribute prediction and clothes retrieval, showing that fashion landmark is a more discriminative representation to understand fashion images.



### Object Detection, Tracking, and Motion Segmentation for Object-level Video Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1608.03066v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03066v1)
- **Published**: 2016-08-10 07:46:56+00:00
- **Updated**: 2016-08-10 07:46:56+00:00
- **Authors**: Benjamin Drayer, Thomas Brox
- **Comment**: None
- **Journal**: None
- **Summary**: We present an approach for object segmentation in videos that combines frame-level object detection with concepts from object tracking and motion segmentation. The approach extracts temporally consistent object tubes based on an off-the-shelf detector. Besides the class label for each tube, this provides a location prior that is independent of motion. For the final video segmentation, we combine this information with motion cues. The method overcomes the typical problems of weakly supervised/unsupervised video segmentation, such as scenes with no motion, dominant camera motion, and objects that move as a unit. In contrast to most tracking methods, it provides an accurate, temporally consistent segmentation of each object. We report results on four video segmentation datasets: YouTube Objects, SegTrackv2, egoMotion, and FBMS.



### 3D Human Pose Estimation Using Convolutional Neural Networks with 2D Pose Information
- **Arxiv ID**: http://arxiv.org/abs/1608.03075v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03075v2)
- **Published**: 2016-08-10 08:18:30+00:00
- **Updated**: 2016-09-08 02:25:08+00:00
- **Authors**: Sungheon Park, Jihye Hwang, Nojun Kwak
- **Comment**: ECCV 2016 workshop
- **Journal**: None
- **Summary**: While there has been a success in 2D human pose estimation with convolutional neural networks (CNNs), 3D human pose estimation has not been thoroughly studied. In this paper, we tackle the 3D human pose estimation task with end-to-end learning using CNNs. Relative 3D positions between one joint and the other joints are learned via CNNs. The proposed method improves the performance of CNN with two novel ideas. First, we added 2D pose information to estimate a 3D pose from an image by concatenating 2D pose estimation result with the features from an image. Second, we have found that more accurate 3D poses are obtained by combining information on relative positions with respect to multiple joints, instead of just one root joint. Experimental results show that the proposed method achieves comparable performance to the state-of-the-art methods on Human 3.6m dataset.



### DeepCAMP: Deep Convolutional Action & Attribute Mid-Level Patterns
- **Arxiv ID**: http://arxiv.org/abs/1608.03217v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03217v1)
- **Published**: 2016-08-10 15:43:10+00:00
- **Updated**: 2016-08-10 15:43:10+00:00
- **Authors**: Ali Diba, Ali Mohammad Pazandeh, Hamed Pirsiavash, Luc Van Gool
- **Comment**: in CVPR 2016
- **Journal**: None
- **Summary**: The recognition of human actions and the determination of human attributes are two tasks that call for fine-grained classification. Indeed, often rather small and inconspicuous objects and features have to be detected to tell their classes apart. In order to deal with this challenge, we propose a novel convolutional neural network that mines mid-level image patches that are sufficiently dedicated to resolve the corresponding subtleties. In particular, we train a newly de- signed CNN (DeepPattern) that learns discriminative patch groups. There are two innovative aspects to this. On the one hand we pay attention to contextual information in an origi- nal fashion. On the other hand, we let an iteration of feature learning and patch clustering purify the set of dedicated patches that we use. We validate our method for action clas- sification on two challenging datasets: PASCAL VOC 2012 Action and Stanford 40 Actions, and for attribute recogni- tion we use the Berkeley Attributes of People dataset. Our discriminative mid-level mining CNN obtains state-of-the- art results on these datasets, without a need for annotations about parts and poses.



### Gaze2Segment: A Pilot Study for Integrating Eye-Tracking Technology into Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1608.03235v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1608.03235v1)
- **Published**: 2016-08-10 16:44:00+00:00
- **Updated**: 2016-08-10 16:44:00+00:00
- **Authors**: Naji Khosravan, Haydar Celik, Baris Turkbey, Ruida Cheng, Evan McCreedy, Matthew McAuliffe, Sandra Bednarova, Elizabeth Jones, Xinjian Chen, Peter L. Choyke, Bradford J. Wood, Ulas Bagci
- **Comment**: MICCAI-Medical Computer Vision 2016, 11 pages
- **Journal**: None
- **Summary**: This study introduced a novel system, called Gaze2Segment, integrating biological and computer vision techniques to support radiologists' reading experience with an automatic image segmentation task. During diagnostic assessment of lung CT scans, the radiologists' gaze information were used to create a visual attention map. This map was then combined with a computer-derived saliency map, extracted from the gray-scale CT images. The visual attention map was used as an input for indicating roughly the location of a object of interest. With computer-derived saliency information, on the other hand, we aimed at finding foreground and background cues for the object of interest. At the final step, these cues were used to initiate a seed-based delineation process. Segmentation accuracy of the proposed Gaze2Segment was found to be 86% with dice similarity coefficient and 1.45 mm with Hausdorff distance. To the best of our knowledge, Gaze2Segment is the first true integration of eye-tracking technology into a medical image segmentation task without the need for any further user-interaction.



### Fractional Calculus In Image Processing: A Review
- **Arxiv ID**: http://arxiv.org/abs/1608.03240v1
- **DOI**: None
- **Categories**: **cs.CV**, 26A33
- **Links**: [PDF](http://arxiv.org/pdf/1608.03240v1)
- **Published**: 2016-08-10 17:45:33+00:00
- **Updated**: 2016-08-10 17:45:33+00:00
- **Authors**: Qi Yang, Dali Chen, Tiebiao Zhao, YangQuan Chen
- **Comment**: 26 pages, 9 figures, 117 conference
- **Journal**: None
- **Summary**: Over the last decade, it has been demonstrated that many systems in science and engineering can be modeled more accurately by fractional-order than integer-order derivatives, and many methods are developed to solve the problem of fractional systems. Due to the extra free parameter order, fractional-order based methods provide additional degree of freedom in optimization performance. Not surprisingly, many fractional-order based methods have been used in image processing field. Herein recent studies are reviewed in ten sub-fields, which include image enhancement, image denoising, image edge detection, image segmentation, image registration, image recognition, image fusion, image encryption, image compression and image restoration. In sum, it is well proved that as a fundamental mathematic tool, fractional-order derivative shows great success in image processing.



### Approximate search with quantized sparse representations
- **Arxiv ID**: http://arxiv.org/abs/1608.03308v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.03308v1)
- **Published**: 2016-08-10 22:00:00+00:00
- **Updated**: 2016-08-10 22:00:00+00:00
- **Authors**: Himalaya Jain, Patrick Pérez, Rémi Gribonval, Joaquin Zepeda, Hervé Jégou
- **Comment**: ECCV 2016
- **Journal**: None
- **Summary**: This paper tackles the task of storing a large collection of vectors, such as visual descriptors, and of searching in it. To this end, we propose to approximate database vectors by constrained sparse coding, where possible atom weights are restricted to belong to a finite subset. This formulation encompasses, as particular cases, previous state-of-the-art methods such as product or residual quantization. As opposed to traditional sparse coding methods, quantized sparse coding includes memory usage as a design constraint, thereby allowing us to index a large collection such as the BIGANN billion-sized benchmark. Our experiments, carried out on standard benchmarks, show that our formulation leads to competitive solutions when considering different trade-offs between learning/coding time, index size and search quality.



