# Arxiv Papers in cs.CV on 2016-08-24
### Computer-Aided Colorectal Tumor Classification in NBI Endoscopy Using CNN Features
- **Arxiv ID**: http://arxiv.org/abs/1608.06709v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06709v1)
- **Published**: 2016-08-24 04:36:55+00:00
- **Updated**: 2016-08-24 04:36:55+00:00
- **Authors**: Toru Tamaki, Shoji Sonoyama, Tsubasa Hirakawa, Bisser Raytchev, Kazufumi Kaneda, Tetsushi Koide, Shigeto Yoshida, Hiroshi Mieno, Shinji Tanaka
- **Comment**: 5 pages, FCV2016
- **Journal**: None
- **Summary**: In this paper we report results for recognizing colorectal NBI endoscopic images by using features extracted from convolutional neural network (CNN). In this comparative study, we extract features from different layers from different CNN models, and then train linear SVM classifiers. Experimental results with 10-fold cross validations show that features from first few convolution layers are enough to achieve similar performance (i.e., recognition rate of 95%) with non-CNN local features such as Bag-of-Visual words, Fisher vector, and VLAD.



### Transfer Learning for Endoscopic Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1608.06713v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06713v1)
- **Published**: 2016-08-24 04:51:53+00:00
- **Updated**: 2016-08-24 04:51:53+00:00
- **Authors**: Shoji Sonoyama, Toru Tamaki, Tsubasa Hirakawa, Bisser Raytchev, Kazufumi Kaneda, Tetsushi Koide, Shigeto Yoshida, Hiroshi Mieno, Shinji Tanaka
- **Comment**: 5 pages, FCV2016
- **Journal**: None
- **Summary**: In this paper we propose a method for transfer learning of endoscopic images. For transferring between features obtained from images taken by different (old and new) endoscopes, we extend the Max-Margin Domain Transfer (MMDT) proposed by Hoffman et al. in order to use L2 distance constraints as regularization, called Max-Margin Domain Transfer with L2 Distance Constraints (MMDTL2). Furthermore, we develop the dual formulation of the optimization problem in order to reduce the computation cost. Experimental results demonstrate that the proposed MMDTL2 outperforms MMDT for real data sets taken by different endoscopes.



### A Novel Approach for Shot Boundary Detection in Videos
- **Arxiv ID**: http://arxiv.org/abs/1608.06716v1
- **DOI**: 10.1007/978-81-322-1143-3_17
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06716v1)
- **Published**: 2016-08-24 05:19:52+00:00
- **Updated**: 2016-08-24 05:19:52+00:00
- **Authors**: D. S. Guru, Mahamad Suhil, P. Lolika
- **Comment**: 12 pages, 2 figures, 2 tables; Conference: Multimedia Processing,
  Communication and Computing Applications, 2012
- **Journal**: ICMCCA, Springer LNEE 213, pp. 209-220, Springer India (2013)
- **Summary**: This paper presents a novel approach for video shot boundary detection. The proposed approach is based on split and merge concept. A fisher linear discriminant criterion is used to guide the process of both splitting and merging. For the purpose of capturing the between class and within class scatter we employ 2D2 FLD method which works on texture feature of regions in each frame of a video. Further to reduce the complexity of the process we propose to employ spectral clustering to group related regions together to a single there by achieving reduction in dimension. The proposed method is experimentally also validated on a cricket video. It is revealed that shots obtained by the proposed approach are highly cohesive and loosely coupled



### A Study of Vision based Human Motion Recognition and Analysis
- **Arxiv ID**: http://arxiv.org/abs/1608.06761v1
- **DOI**: 10.4018/IJACI.2016070104
- **Categories**: **cs.CV**, I.2.10, I.4.8, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1608.06761v1)
- **Published**: 2016-08-24 09:23:14+00:00
- **Updated**: 2016-08-24 09:23:14+00:00
- **Authors**: Geetanjali Vinayak Kale, Varsha Hemant Patil
- **Comment**: 5 Figures, 18 Pages, International Journal of Ambient Computing and
  Intelligence, Volume 7 Issue 2,July-December 2016
- **Journal**: None
- **Summary**: Vision based human motion recognition has fascinated many researchers due to its critical challenges and a variety of applications. The applications range from simple gesture recognition to complicated behaviour understanding in surveillance system. This leads to major development in the techniques related to human motion representation and recognition. This paper discusses applications, general framework of human motion recognition, and the details of each of its components. The paper emphasizes on human motion representation and the recognition methods along with their advantages and disadvantages. This study also discusses the selected literature, popular datasets, and concludes with the challenges in the domain along with a future direction. The human motion recognition domain has been active for more than two decades, and has provided a large amount of literature. A bird's eye view for new researchers in the domain is presented in the paper.



### Automatic Synchronization of Multi-User Photo Galleries
- **Arxiv ID**: http://arxiv.org/abs/1608.06770v2
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.06770v2)
- **Published**: 2016-08-24 10:17:16+00:00
- **Updated**: 2017-01-16 11:19:49+00:00
- **Authors**: E. Sansone, K. Apostolidis, N. Conci, G. Boato, V. Mezaris, F. G. B. De Natale
- **Comment**: ACCEPTED to IEEE Transactions on Multimedia
- **Journal**: None
- **Summary**: In this paper we address the issue of photo galleries synchronization, where pictures related to the same event are collected by different users. Existing solutions to address the problem are usually based on unrealistic assumptions, like time consistency across photo galleries, and often heavily rely on heuristics, limiting therefore the applicability to real-world scenarios. We propose a solution that achieves better generalization performance for the synchronization task compared to the available literature. The method is characterized by three stages: at first, deep convolutional neural network features are used to assess the visual similarity among the photos; then, pairs of similar photos are detected across different galleries and used to construct a graph; eventually, a probabilistic graphical model is used to estimate the temporal offset of each pair of galleries, by traversing the minimum spanning tree extracted from this graph. The experimental evaluation is conducted on four publicly available datasets covering different types of events, demonstrating the strength of our proposed method. A thorough discussion of the obtained results is provided for a critical assessment of the quality in synchronization.



### In the Saddle: Chasing Fast and Repeatable Features
- **Arxiv ID**: http://arxiv.org/abs/1608.06800v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06800v1)
- **Published**: 2016-08-24 12:57:34+00:00
- **Updated**: 2016-08-24 12:57:34+00:00
- **Authors**: Javier Aldana-Iuit, Dmytro Mishkin, Ondrej Chum, Jiri Matas
- **Comment**: None
- **Journal**: None
- **Summary**: A novel similarity-covariant feature detector that extracts points whose neighbourhoods, when treated as a 3D intensity surface, have a saddle-like intensity profile. The saddle condition is verified efficiently by intensity comparisons on two concentric rings that must have exactly two dark-to-bright and two bright-to-dark transitions satisfying certain geometric constraints. Experiments show that the Saddle features are general, evenly spread and appearing in high density in a range of images. The Saddle detector is among the fastest proposed. In comparison with detector with similar speed, the Saddle features show superior matching performance on number of challenging datasets.



### Kullback-Leibler Penalized Sparse Discriminant Analysis for Event-Related Potential Classification
- **Arxiv ID**: http://arxiv.org/abs/1608.06863v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1608.06863v1)
- **Published**: 2016-08-24 15:32:51+00:00
- **Updated**: 2016-08-24 15:32:51+00:00
- **Authors**: Victoria Peterson, Hugo Leonardo Rufiner, Ruben Daniel Spies
- **Comment**: 27 pages, 4 figures
- **Journal**: None
- **Summary**: A brain computer interface (BCI) is a system which provides direct communication between the mind of a person and the outside world by using only brain activity (EEG). The event-related potential (ERP)-based BCI problem consists of a binary pattern recognition. Linear discriminant analysis (LDA) is widely used to solve this type of classification problems, but it fails when the number of features is large relative to the number of observations. In this work we propose a penalized version of the sparse discriminant analysis (SDA), called Kullback-Leibler penalized sparse discriminant analysis (KLSDA). This method inherits both the discriminative feature selection and classification properties of SDA and it also improves SDA performance through the addition of Kullback-Leibler class discrepancy information. The KLSDA method is design to automatically select the optimal regularization parameters. Numerical experiments with two real ERP-EEG datasets show that this new method outperforms standard SDA.



### Towards Bayesian Deep Learning: A Framework and Some Existing Methods
- **Arxiv ID**: http://arxiv.org/abs/1608.06884v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1608.06884v2)
- **Published**: 2016-08-24 16:15:22+00:00
- **Updated**: 2016-09-03 15:32:04+00:00
- **Authors**: Hao Wang, Dit-Yan Yeung
- **Comment**: To appear in IEEE Transactions on Knowledge and Data Engineering
  (TKDE), 2016. This is a slightly shorter version of the survey
  arXiv:1604.01662
- **Journal**: None
- **Summary**: While perception tasks such as visual object recognition and text understanding play an important role in human intelligence, the subsequent tasks that involve inference, reasoning and planning require an even higher level of intelligence. The past few years have seen major advances in many perception tasks using deep learning models. For higher-level inference, however, probabilistic graphical models with their Bayesian nature are still more powerful and flexible. To achieve integrated intelligence that involves both perception and inference, it is naturally desirable to tightly integrate deep learning and Bayesian models within a principled probabilistic framework, which we call Bayesian deep learning. In this unified framework, the perception of text or images using deep learning can boost the performance of higher-level inference and in return, the feedback from the inference process is able to enhance the perception of text or images. This paper proposes a general framework for Bayesian deep learning and reviews its recent applications on recommender systems, topic models, and control. In this paper, we also discuss the relationship and differences between Bayesian deep learning and other related topics like Bayesian treatment of neural networks.



### Absolute Pose Estimation from Line Correspondences using Direct Linear Transformation
- **Arxiv ID**: http://arxiv.org/abs/1608.06891v2
- **DOI**: 10.1016/j.cviu.2017.05.002
- **Categories**: **cs.CV**, 68T45, I.4.8; I.4.1
- **Links**: [PDF](http://arxiv.org/pdf/1608.06891v2)
- **Published**: 2016-08-24 16:37:03+00:00
- **Updated**: 2017-05-13 10:38:02+00:00
- **Authors**: Bronislav Přibyl, Pavel Zemčík, Martin Čadík
- **Comment**: 37 pages, 6 figures, 4 tables. Accepted for publication in Computer
  Vision and Image Understanding
- **Journal**: None
- **Summary**: This work is concerned with camera pose estimation from correspondences of 3D/2D lines, i. e. with the Perspective-n-Line (PnL) problem. We focus on large line sets, which can be efficiently solved by methods using linear formulation of PnL. We propose a novel method "DLT-Combined-Lines" based on the Direct Linear Transformation (DLT) algorithm, which benefits from a new combination of two existing DLT methods for pose estimation. The method represents 2D structure by lines, and 3D structure by both points and lines. The redundant 3D information reduces the minimum required line correspondences to 5. A cornerstone of the method is a combined projection matri xestimated by the DLT algorithm. It contains multiple estimates of camera rotation and translation, which can be recovered after enforcing constraints of the matrix. Multiplicity of the estimates is exploited to improve the accuracy of the proposed method. For large line sets (10 and more), the method is comparable to the state-of-theart in accuracy of orientation estimation. It achieves state-of-the-art accuracy in estimation of camera position and it yields the smallest reprojection error under strong image noise. The method achieves top-3 results on real world data. The proposed method is also highly computationally effective, estimating the pose of 1000 lines in 12 ms on a desktop computer.



### A 4D Light-Field Dataset and CNN Architectures for Material Recognition
- **Arxiv ID**: http://arxiv.org/abs/1608.06985v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.06985v1)
- **Published**: 2016-08-24 23:30:22+00:00
- **Updated**: 2016-08-24 23:30:22+00:00
- **Authors**: Ting-Chun Wang, Jun-Yan Zhu, Ebi Hiroaki, Manmohan Chandraker, Alexei A. Efros, Ravi Ramamoorthi
- **Comment**: European Conference on Computer Vision (ECCV) 2016
- **Journal**: None
- **Summary**: We introduce a new light-field dataset of materials, and take advantage of the recent success of deep learning to perform material recognition on the 4D light-field. Our dataset contains 12 material categories, each with 100 images taken with a Lytro Illum, from which we extract about 30,000 patches in total. To the best of our knowledge, this is the first mid-size dataset for light-field images. Our main goal is to investigate whether the additional information in a light-field (such as multiple sub-aperture views and view-dependent reflectance effects) can aid material recognition. Since recognition networks have not been trained on 4D images before, we propose and compare several novel CNN architectures to train on light-field images. In our experiments, the best performing CNN architecture achieves a 7% boost compared with 2D image classification (70% to 77%). These results constitute important baselines that can spur further research in the use of CNNs for light-field applications. Upon publication, our dataset also enables other novel applications of light-fields, including object detection, image segmentation and view interpolation.



