# Arxiv Papers in cs.CV on 2016-08-02
### Global Vertices and the Noising Paradox
- **Arxiv ID**: http://arxiv.org/abs/1608.00668v1
- **DOI**: 10.1007/s11263-017-1034-6
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00668v1)
- **Published**: 2016-08-02 01:30:28+00:00
- **Updated**: 2016-08-02 01:30:28+00:00
- **Authors**: Konstantinos A. Raftopoulos, Stefanos D. Kollias, Marin Ferecatu
- **Comment**: 19 pages, 11 figures
- **Journal**: Int J Comput Vis (2017)
- **Summary**: A theoretical and experimental analysis related to the identification of vertices of unknown shapes is presented. Shapes are seen as real functions of their closed boundary. Unlike traditional approaches, which see curvature as the rate of change of the tangent to the curve, an alternative global perspective of curvature is examined providing insight into the process of noise-enabled vertex localization. The analysis leads to a paradox, that certain vertices can be localized better in the presence of noise. The concept of noising is thus considered and a relevant global method for localizing "Global Vertices" is investigated. Theoretical analysis reveals that induced noise can help localizing certain vertices if combined with global descriptors. Experiments with noise and a comparison to localized methods validate the theoretical results.



### Spatio-temporal Co-Occurrence Characterizations for Human Action Classification
- **Arxiv ID**: http://arxiv.org/abs/1610.05174v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.05174v1)
- **Published**: 2016-08-02 02:22:42+00:00
- **Updated**: 2016-08-02 02:22:42+00:00
- **Authors**: Aznul Qalid Md Sabri, Jacques Boonaert, Erma Rahayu Mohd Faizal Abdullah, Ali Mohammed Mansoor
- **Comment**: None
- **Journal**: None
- **Summary**: The human action classification task is a widely researched topic and is still an open problem. Many state-of-the-arts approaches involve the usage of bag-of-video-words with spatio-temporal local features to construct characterizations for human actions. In order to improve beyond this standard approach, we investigate the usage of co-occurrences between local features. We propose the usage of co-occurrences information to characterize human actions. A trade-off factor is used to define an optimal trade-off between vocabulary size and classification rate. Next, a spatio-temporal co-occurrence technique is applied to extract co-occurrence information between labeled local features. Novel characterizations for human actions are then constructed. These include a vector quantized correlogram-elements vector, a highly discriminative PCA (Principal Components Analysis) co-occurrence vector and a Haralick texture vector. Multi-channel kernel SVM (support vector machine) is utilized for classification. For evaluation, the well known KTH as well as the challenging UCF-Sports action datasets are used. We obtained state-of-the-arts classification performance. We also demonstrated that we are able to fully utilize co-occurrence information, and improve the standard bag-of-video-words approach.



### A Survey of Visual Analysis of Human Motion and Its Applications
- **Arxiv ID**: http://arxiv.org/abs/1608.00700v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1608.00700v2)
- **Published**: 2016-08-02 05:50:11+00:00
- **Updated**: 2016-08-23 05:15:03+00:00
- **Authors**: Qifei Wang
- **Comment**: 5 pages, conference paper in VCIP 2016
- **Journal**: None
- **Summary**: This paper summarizes the recent progress in human motion analysis and its applications. In the beginning, we reviewed the motion capture systems and the representation model of human's motion data. Next, we sketched the advanced human motion data processing technologies, including motion data filtering, temporal alignment, and segmentation. The following parts overview the state-of-the-art approaches of action recognition and dynamics measuring since these two are the most active research areas in human motion analysis. The last part discusses some emerging applications of the human motion analysis in healthcare, human robot interaction, security surveillance, virtual reality and animation. The promising research topics of human motion analysis in the future is also summarized in the last part.



### Semantically Guided Depth Upsampling
- **Arxiv ID**: http://arxiv.org/abs/1608.00753v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00753v1)
- **Published**: 2016-08-02 09:44:53+00:00
- **Updated**: 2016-08-02 09:44:53+00:00
- **Authors**: Nick Schneider, Lukas Schneider, Peter Pinggera, Uwe Franke, Marc Pollefeys, Christoph Stiller
- **Comment**: German Conference on Pattern Recognition 2016 (Oral)
- **Journal**: None
- **Summary**: We present a novel method for accurate and efficient up- sampling of sparse depth data, guided by high-resolution imagery. Our approach goes beyond the use of intensity cues only and additionally exploits object boundary cues through structured edge detection and semantic scene labeling for guidance. Both cues are combined within a geodesic distance measure that allows for boundary-preserving depth in- terpolation while utilizing local context. We model the observed scene structure by locally planar elements and formulate the upsampling task as a global energy minimization problem. Our method determines glob- ally consistent solutions and preserves fine details and sharp depth bound- aries. In our experiments on several public datasets at different levels of application, we demonstrate superior performance of our approach over the state-of-the-art, even for very sparse measurements.



### Interactive Removal and Ground Truth for Difficult Shadow Scenes
- **Arxiv ID**: http://arxiv.org/abs/1608.00762v1
- **DOI**: 10.1364/JOSAA.33.001798
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00762v1)
- **Published**: 2016-08-02 10:51:07+00:00
- **Updated**: 2016-08-02 10:51:07+00:00
- **Authors**: Han Gong, Darren P. Cosker
- **Comment**: Accepted by JOSA A
- **Journal**: None
- **Summary**: A user-centric method for fast, interactive, robust and high-quality shadow removal is presented. Our algorithm can perform detection and removal in a range of difficult cases: such as highly textured and colored shadows. To perform detection an on-the-fly learning approach is adopted guided by two rough user inputs for the pixels of the shadow and the lit area. After detection, shadow removal is performed by registering the penumbra to a normalized frame which allows us efficient estimation of non-uniform shadow illumination changes, resulting in accurate and robust removal. Another major contribution of this work is the first validated and multi-scene category ground truth for shadow removal algorithms. This data set containing 186 images eliminates inconsistencies between shadow and shadow-free images and provides a range of different shadow types such as soft, textured, colored and broken shadow. Using this data, the most thorough comparison of state-of-the-art shadow removal methods to date is performed, showing our proposed new algorithm to outperform the state-of-the-art across several measures and shadow category. To complement our dataset, an online shadow removal benchmark website is also presented to encourage future open comparisons in this challenging field of research.



### Dense semantic labeling of sub-decimeter resolution images with convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1608.00775v2
- **DOI**: 10.1109/TGRS.2016.2616585
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00775v2)
- **Published**: 2016-08-02 11:33:44+00:00
- **Updated**: 2016-10-10 15:07:33+00:00
- **Authors**: Michele Volpi, Devis Tuia
- **Comment**: Accepted in IEEE Transactions on Geoscience and Remote Sensing, 2016
- **Journal**: None
- **Summary**: Semantic labeling (or pixel-level land-cover classification) in ultra-high resolution imagery (< 10cm) requires statistical models able to learn high level concepts from spatial data, with large appearance variations. Convolutional Neural Networks (CNNs) achieve this goal by learning discriminatively a hierarchy of representations of increasing abstraction.   In this paper we present a CNN-based system relying on an downsample-then-upsample architecture. Specifically, it first learns a rough spatial map of high-level representations by means of convolutions and then learns to upsample them back to the original resolution by deconvolutions. By doing so, the CNN learns to densely label every pixel at the original resolution of the image. This results in many advantages, including i) state-of-the-art numerical accuracy, ii) improved geometric accuracy of predictions and iii) high efficiency at inference time.   We test the proposed system on the Vaihingen and Potsdam sub-decimeter resolution datasets, involving semantic labeling of aerial images of 9cm and 5cm resolution, respectively. These datasets are composed by many large and fully annotated tiles allowing an unbiased evaluation of models making use of spatial information. We do so by comparing two standard CNN architectures to the proposed one: standard patch classification, prediction of local label patches by employing only convolutions and full patch labeling by employing deconvolutions. All the systems compare favorably or outperform a state-of-the-art baseline relying on superpixels and powerful appearance descriptors. The proposed full patch labeling CNN outperforms these models by a large margin, also showing a very appealing inference time.



### Shape and Centroid Independent Clustring Algorithm for Crowd Management Applications
- **Arxiv ID**: http://arxiv.org/abs/1608.00785v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00785v1)
- **Published**: 2016-08-02 12:19:21+00:00
- **Updated**: 2016-08-02 12:19:21+00:00
- **Authors**: Yasser Mohammad Seddiq, A. A. Alharbiy, Moayyad Hamza Ghunaim
- **Comment**: 4 pages, 5 figures
- **Journal**: None
- **Summary**: Clustering techniques play an important role in data mining and its related applications. Among the challenging applications that require robust and real-time processing are crowd management and group trajectory applications. In this paper, a robust and low-complexity clustering algorithm is proposed. It is capable of processing data in a manner that is shape and centroid independent. The algorithm is of low complexity due to the novel technique to compute the matrix power. The algorithm was tested on real and synthetic data and test results are reported.



### CUHK & ETHZ & SIAT Submission to ActivityNet Challenge 2016
- **Arxiv ID**: http://arxiv.org/abs/1608.00797v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00797v1)
- **Published**: 2016-08-02 12:58:30+00:00
- **Updated**: 2016-08-02 12:58:30+00:00
- **Authors**: Yuanjun Xiong, Limin Wang, Zhe Wang, Bowen Zhang, Hang Song, Wei Li, Dahua Lin, Yu Qiao, Luc Van Gool, Xiaoou Tang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents the method that underlies our submission to the untrimmed video classification task of ActivityNet Challenge 2016. We follow the basic pipeline of temporal segment networks and further raise the performance via a number of other techniques. Specifically, we use the latest deep model architecture, e.g., ResNet and Inception V3, and introduce new aggregation schemes (top-k and attention-weighted pooling). Additionally, we incorporate the audio as a complementary channel, extracting relevant information via a CNN applied to the spectrograms. With these techniques, we derive an ensemble of deep models, which, together, attains a high classification accuracy (mAP $93.23\%$) on the testing set and secured the first place in the challenge.



### Aggregating Binary Local Descriptors for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1608.00813v2
- **DOI**: 10.1007/s11042-017-4450-2
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00813v2)
- **Published**: 2016-08-02 13:28:16+00:00
- **Updated**: 2017-02-03 15:19:15+00:00
- **Authors**: Giuseppe Amato, Fabrizio Falchi, Lucia Vadicamo
- **Comment**: None
- **Journal**: None
- **Summary**: Content-Based Image Retrieval based on local features is computationally expensive because of the complexity of both extraction and matching of local feature. On one hand, the cost for extracting, representing, and comparing local visual descriptors has been dramatically reduced by recently proposed binary local features. On the other hand, aggregation techniques provide a meaningful summarization of all the extracted feature of an image into a single descriptor, allowing us to speed up and scale up the image search. Only a few works have recently mixed together these two research directions, defining aggregation methods for binary local features, in order to leverage on the advantage of both approaches. In this paper, we report an extensive comparison among state-of-the-art aggregation methods applied to binary features. Then, we mathematically formalize the application of Fisher Kernels to Bernoulli Mixture Models. Finally, we investigate the combination of the aggregated binary features with the emerging Convolutional Neural Network (CNN) features. Our results show that aggregation methods on binary features are effective and represent a worthwhile alternative to the direct matching. Moreover, the combination of the CNN with the Fisher Vector (FV) built upon binary features allowed us to obtain a relative improvement over the CNN results that is in line with that recently obtained using the combination of the CNN with the FV built upon SIFTs. The advantage of using the FV built upon binary features is that the extraction process of binary features is about two order of magnitude faster than SIFTs.



### A study of the effect of JPG compression on adversarial images
- **Arxiv ID**: http://arxiv.org/abs/1608.00853v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1608.00853v1)
- **Published**: 2016-08-02 14:57:18+00:00
- **Updated**: 2016-08-02 14:57:18+00:00
- **Authors**: Gintare Karolina Dziugaite, Zoubin Ghahramani, Daniel M. Roy
- **Comment**: 8 pages, 4 figures
- **Journal**: None
- **Summary**: Neural network image classifiers are known to be vulnerable to adversarial images, i.e., natural images which have been modified by an adversarial perturbation specifically designed to be imperceptible to humans yet fool the classifier. Not only can adversarial images be generated easily, but these images will often be adversarial for networks trained on disjoint subsets of data or with different architectures. Adversarial images represent a potential security risk as well as a serious machine learning challenge---it is clear that vulnerable neural networks perceive images very differently from humans. Noting that virtually every image classification data set is composed of JPG images, we evaluate the effect of JPG compression on the classification of adversarial images. For Fast-Gradient-Sign perturbations of small magnitude, we found that JPG compression often reverses the drop in classification accuracy to a large extent, but not always. As the magnitude of the perturbations increases, JPG recompression alone is insufficient to reverse the effect.



### Temporal Segment Networks: Towards Good Practices for Deep Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1608.00859v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00859v1)
- **Published**: 2016-08-02 15:06:50+00:00
- **Updated**: 2016-08-02 15:06:50+00:00
- **Authors**: Limin Wang, Yuanjun Xiong, Zhe Wang, Yu Qiao, Dahua Lin, Xiaoou Tang, Luc Van Gool
- **Comment**: Accepted by ECCV 2016. Based on this method, we won the ActivityNet
  challenge 2016 in untrimmed video classification
- **Journal**: None
- **Summary**: Deep convolutional networks have achieved great success for visual recognition in still images. However, for action recognition in videos, the advantage over traditional methods is not so evident. This paper aims to discover the principles to design effective ConvNet architectures for action recognition in videos and learn these models given limited training samples. Our first contribution is temporal segment network (TSN), a novel framework for video-based action recognition. which is based on the idea of long-range temporal structure modeling. It combines a sparse temporal sampling strategy and video-level supervision to enable efficient and effective learning using the whole action video. The other contribution is our study on a series of good practices in learning ConvNets on video data with the help of temporal segment network. Our approach obtains the state-the-of-art performance on the datasets of HMDB51 ( $ 69.4\% $) and UCF101 ($ 94.2\% $). We also visualize the learned ConvNet models, which qualitatively demonstrates the effectiveness of temporal segment network and the proposed good practices.



### Towards Learning to Perceive and Reason About Liquids
- **Arxiv ID**: http://arxiv.org/abs/1608.00887v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.00887v1)
- **Published**: 2016-08-02 16:30:18+00:00
- **Updated**: 2016-08-02 16:30:18+00:00
- **Authors**: Connor Schenck, Dieter Fox
- **Comment**: Published in International Symposium on Experimental Robotics (ISER)
  2016. arXiv admin note: text overlap with arXiv:1606.06266
- **Journal**: None
- **Summary**: Recent advances in AI and robotics have claimed many incredible results with deep learning, yet no work to date has applied deep learning to the problem of liquid perception and reasoning. In this paper, we apply fully-convolutional deep neural networks to the tasks of detecting and tracking liquids. We evaluate three models: a single-frame network, multi-frame network, and a LSTM recurrent network. Our results show that the best liquid detection results are achieved when aggregating data over multiple frames and that the LSTM network outperforms the other two in both tasks. This suggests that LSTM-based neural networks have the potential to be a key component for enabling robots to handle liquids using robust, closed-loop controllers.



### PicHunt: Social Media Image Retrieval for Improved Law Enforcement
- **Arxiv ID**: http://arxiv.org/abs/1608.00905v2
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.00905v2)
- **Published**: 2016-08-02 17:09:19+00:00
- **Updated**: 2016-09-15 11:16:36+00:00
- **Authors**: Sonal Goel, Niharika Sachdeva, Ponnurangam Kumaraguru, A V Subramanyam, Divam Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: First responders are increasingly using social media to identify and reduce crime for well-being and safety of the society. Images shared on social media hurting religious, political, communal and other sentiments of people, often instigate violence and create law & order situations in society. This results in the need for first responders to inspect the spread of such images and users propagating them on social media. In this paper, we present a comparison between different hand-crafted features and a Convolutional Neural Network (CNN) model to retrieve similar images, which outperforms state-of-art hand-crafted features. We propose an Open-Source-Intelligent (OSINT) real-time image search system, robust to retrieve modified images that allows first responders to analyze the current spread of images, sentiments floating and details of users propagating such content. The system also aids officials to save time of manually analyzing the content by reducing the search space on an average by 67%.



### Modeling Spatial and Temporal Cues for Multi-label Facial Action Unit Detection
- **Arxiv ID**: http://arxiv.org/abs/1608.00911v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.00911v1)
- **Published**: 2016-08-02 17:37:38+00:00
- **Updated**: 2016-08-02 17:37:38+00:00
- **Authors**: Wen-Sheng Chu, Fernando De la Torre, Jeffrey F. Cohn
- **Comment**: None
- **Journal**: None
- **Summary**: Facial action units (AUs) are essential to decode human facial expressions. Researchers have focused on training AU detectors with a variety of features and classifiers. However, several issues remain. These are spatial representation, temporal modeling, and AU correlation. Unlike most studies that tackle these issues separately, we propose a hybrid network architecture to jointly address them. Specifically, spatial representations are extracted by a Convolutional Neural Network (CNN), which, as analyzed in this paper, is able to reduce person-specific biases caused by hand-crafted features (eg, SIFT and Gabor). To model temporal dependencies, Long Short-Term Memory (LSTMs) are stacked on top of these representations, regardless of the lengths of input videos. The outputs of CNNs and LSTMs are further aggregated into a fusion network to produce per-frame predictions of 12 AUs. Our network naturally addresses the three issues, and leads to superior performance compared to existing methods that consider these issues independently. Extensive experiments were conducted on two large spontaneous datasets, GFT and BP4D, containing more than 400,000 frames coded with 12 AUs. On both datasets, we report significant improvement over a standard multi-label CNN and feature-based state-of-the-art. Finally, we provide visualization of the learned AU models, which, to our best knowledge, reveal how machines see facial AUs for the first time.



### Automated X-ray Image Analysis for Cargo Security: Critical Review and Future Promise
- **Arxiv ID**: http://arxiv.org/abs/1608.01017v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.01017v1)
- **Published**: 2016-08-02 22:22:41+00:00
- **Updated**: 2016-08-02 22:22:41+00:00
- **Authors**: Thomas W. Rogers, Nicolas Jaccard, Edward J. Morton, Lewis D. Griffin
- **Comment**: Submission to Journal of X-ray Science and Technology
- **Journal**: None
- **Summary**: We review the relatively immature field of automated image analysis for X-ray cargo imagery. There is increasing demand for automated analysis methods that can assist in the inspection and selection of containers, due to the ever-growing volumes of traded cargo and the increasing concerns that customs- and security-related threats are being smuggled across borders by organised crime and terrorist networks. We split the field into the classical pipeline of image preprocessing and image understanding. Preprocessing includes: image manipulation; quality improvement; Threat Image Projection (TIP); and material discrimination and segmentation. Image understanding includes: Automated Threat Detection (ATD); and Automated Contents Verification (ACV). We identify several gaps in the literature that need to be addressed and propose ideas for future research. Where the current literature is sparse we borrow from the single-view, multi-view, and CT X-ray baggage domains, which have some characteristics in common with X-ray cargo.



### Incremental Real-Time Multibody VSLAM with Trajectory Optimization Using Stereo Camera
- **Arxiv ID**: http://arxiv.org/abs/1608.01024v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.01024v1)
- **Published**: 2016-08-02 23:03:19+00:00
- **Updated**: 2016-08-02 23:03:19+00:00
- **Authors**: N Dinesh Reddy, Iman Abbasnejad, Sheetal Reddy, Amit Kumar Mondal, Vindhya Devalla
- **Comment**: Available on IROS
- **Journal**: None
- **Summary**: Real time outdoor navigation in highly dynamic environments is an crucial problem. The recent literature on real time static SLAM don't scale up to dynamic outdoor environments. Most of these methods assume moving objects as outliers or discard the information provided by them. We propose an algorithm to jointly infer the camera trajectory and the moving object trajectory simultaneously. In this paper, we perform a sparse scene flow based motion segmentation using a stereo camera. The segmented objects motion models are used for accurate localization of the camera trajectory as well as the moving objects. We exploit the relationship between moving objects for improving the accuracy of the poses. We formulate the poses as a factor graph incorporating all the constraints. We achieve exact incremental solution by solving a full nonlinear optimization problem in real time. The evaluation is performed on the challenging KITTI dataset with multiple moving cars.Our method outperforms the previous baselines in outdoor navigation.



### One-Class Slab Support Vector Machine
- **Arxiv ID**: http://arxiv.org/abs/1608.01026v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.01026v1)
- **Published**: 2016-08-02 23:06:35+00:00
- **Updated**: 2016-08-02 23:06:35+00:00
- **Authors**: Victor Fragoso, Walter Scheirer, Joao Hespanha, Matthew Turk
- **Comment**: None
- **Journal**: None
- **Summary**: This work introduces the one-class slab SVM (OCSSVM), a one-class classifier that aims at improving the performance of the one-class SVM. The proposed strategy reduces the false positive rate and increases the accuracy of detecting instances from novel classes. To this end, it uses two parallel hyperplanes to learn the normal region of the decision scores of the target class. OCSSVM extends one-class SVM since it can scale and learn non-linear decision functions via kernel methods. The experiments on two publicly available datasets show that OCSSVM can consistently outperform the one-class SVM and perform comparable to or better than other state-of-the-art one-class classifiers.



