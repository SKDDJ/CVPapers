# Arxiv Papers in cs.CV on 2016-08-16
### SenTion: A framework for Sensing Facial Expressions
- **Arxiv ID**: http://arxiv.org/abs/1608.04489v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.04489v1)
- **Published**: 2016-08-16 05:27:30+00:00
- **Updated**: 2016-08-16 05:27:30+00:00
- **Authors**: Rahul Islam, Karan Ahuja, Sandip Karmakar, Ferdous Barbhuiya
- **Comment**: None
- **Journal**: None
- **Summary**: Facial expressions are an integral part of human cognition and communication, and can be applied in various real life applications. A vital precursor to accurate expression recognition is feature extraction. In this paper, we propose SenTion: A framework for sensing facial expressions. We propose a novel person independent and scale invariant method of extracting Inter Vector Angles (IVA) as geometric features, which proves to be robust and reliable across databases. SenTion employs a novel framework of combining geometric (IVA's) and appearance based features (Histogram of Gradients) to create a hybrid model, that achieves state of the art recognition accuracy. We evaluate the performance of SenTion on two famous face expression data set, namely: CK+ and JAFFE; and subsequently evaluate the viability of facial expression systems by a user study. Extensive experiments showed that SenTion framework yielded dramatic improvements in facial expression recognition and could be employed in real-world applications with low resolution imaging and minimal computational resources in real-time, achieving 15-18 fps on a 2.4 GHz CPU with no GPU.



### Dynamic Network Surgery for Efficient DNNs
- **Arxiv ID**: http://arxiv.org/abs/1608.04493v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1608.04493v2)
- **Published**: 2016-08-16 06:23:05+00:00
- **Updated**: 2016-11-10 00:17:25+00:00
- **Authors**: Yiwen Guo, Anbang Yao, Yurong Chen
- **Comment**: Accepted by NIPS 2016
- **Journal**: None
- **Summary**: Deep learning has become a ubiquitous technology to improve machine intelligence. However, most of the existing deep models are structurally very complex, making them difficult to be deployed on the mobile platforms with limited computational power. In this paper, we propose a novel network compression method called dynamic network surgery, which can remarkably reduce the network complexity by making on-the-fly connection pruning. Unlike the previous methods which accomplish this task in a greedy way, we properly incorporate connection splicing into the whole process to avoid incorrect pruning and make it as a continual network maintenance. The effectiveness of our method is proved with experiments. Without any accuracy loss, our method can efficiently compress the number of parameters in LeNet-5 and AlexNet by a factor of $\bm{108}\times$ and $\bm{17.7}\times$ respectively, proving that it outperforms the recent pruning method by considerable margins. Code and some models are available at https://github.com/yiwenguo/Dynamic-Network-Surgery.



### Unconstrained Two-parallel-plane Model for Focused Plenoptic Cameras Calibration
- **Arxiv ID**: http://arxiv.org/abs/1608.04509v1
- **DOI**: None
- **Categories**: **cs.CV**, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1608.04509v1)
- **Published**: 2016-08-16 08:02:55+00:00
- **Updated**: 2016-08-16 08:02:55+00:00
- **Authors**: Chunping Zhang, Zhe Ji, Qing Wang
- **Comment**: 20 pages, 10 figures, 1 table
- **Journal**: None
- **Summary**: The plenoptic camera can capture both angular and spatial information of the rays, enabling 3D reconstruction by single exposure. The geometry of the recovered scene structure is affected by the calibration of the plenoptic camera significantly. In this paper, we propose a novel unconstrained two-parallel-plane (TPP) model with 7 parameters to describe a 4D light field. By reconstructing scene points from ray-ray association, a 3D projective transformation is deduced to establish the relationship between the scene structure and the TPP parameters. Based on the transformation, we simplify the focused plenoptic camera as a TPP model and calibrate its intrinsic parameters. Our calibration method includes a close-form solution and a nonlinear optimization by minimizing re-projection error. Experiments on both simulated data and real scene data verify the performance of the calibration on the focused plenoptic camera.



### A Comparative Study for the Nuclear Norms Minimization Methods
- **Arxiv ID**: http://arxiv.org/abs/1608.04517v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.04517v4)
- **Published**: 2016-08-16 08:31:35+00:00
- **Updated**: 2019-05-10 08:58:01+00:00
- **Authors**: Zhiyuan Zha, Bihan Wen, Jiachao Zhang, Jiantao Zhou, Ce Zhu
- **Comment**: None
- **Journal**: 2019 IEEE International Conference on Image Processing
- **Summary**: The nuclear norm minimization (NNM) is commonly used to approximate the matrix rank by shrinking all singular values equally. However, the singular values have clear physical meanings in many practical problems, and NNM may not be able to faithfully approximate the matrix rank. To alleviate the above-mentioned limitation of NNM, recent studies have suggested that the weighted nuclear norm minimization (WNNM) can achieve a better rank estimation than NNM, which heuristically set the weight being inverse to the singular values. However, it still lacks a rigorous explanation why WNNM is more effective than NMM in various applications. In this paper, we analyze NNM and WNNM from the perspective of group sparse representation (GSR). Concretely, an adaptive dictionary learning method is devised to connect the rank minimization and GSR models. Based on the proposed dictionary, we prove that NNM and WNNM are equivalent to L1-norm minimization and the weighted L1-norm minimization in GSR, respectively. Inspired by enhancing sparsity of the weighted L1-norm minimization in comparison with L1-norm minimization in sparse representation, we thus explain that WNNM is more effective than NMM. By integrating the image nonlocal self-similarity (NSS) prior with the WNNM model, we then apply it to solve the image denoising problem. Experimental results demonstrate that WNNM is more effective than NNM and outperforms several state-of-the-art methods in both objective and perceptual quality.



### An image compression and encryption scheme based on deep learning
- **Arxiv ID**: http://arxiv.org/abs/1608.05001v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1608.05001v2)
- **Published**: 2016-08-16 14:51:25+00:00
- **Updated**: 2016-10-09 02:27:20+00:00
- **Authors**: Fei Hu, Changjiu Pu, Haowei Gao, Mengzi Tang, Li Li
- **Comment**: 6 pages, 6 figures
- **Journal**: None
- **Summary**: Stacked Auto-Encoder (SAE) is a kind of deep learning algorithm for unsupervised learning. Which has multi layers that project the vector representation of input data into a lower vector space. These projection vectors are dense representations of the input data. As a result, SAE can be used for image compression. Using chaotic logistic map, the compression ones can further be encrypted. In this study, an application of image compression and encryption is suggested using SAE and chaotic logistic map. Experiments show that this application is feasible and effective. It can be used for image transmission and image protection on internet simultaneously.



### Temporally Consistent Motion Segmentation from RGB-D Video
- **Arxiv ID**: http://arxiv.org/abs/1608.04642v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T45, I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1608.04642v1)
- **Published**: 2016-08-16 15:56:11+00:00
- **Updated**: 2016-08-16 15:56:11+00:00
- **Authors**: Peter Bertholet, Alexandru-Eugen Ichim, Matthias Zwicker
- **Comment**: None
- **Journal**: None
- **Summary**: We present a method for temporally consistent motion segmentation from RGB-D videos assuming a piecewise rigid motion model. We formulate global energies over entire RGB-D sequences in terms of the segmentation of each frame into a number of objects, and the rigid motion of each object through the sequence. We develop a novel initialization procedure that clusters feature tracks obtained from the RGB data by leveraging the depth information. We minimize the energy using a coordinate descent approach that includes novel techniques to assemble object motion hypotheses. A main benefit of our approach is that it enables us to fuse consistently labeled object segments from all RGB-D frames of an input sequence into individual 3D object reconstructions.



### Towards Evaluating the Robustness of Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1608.04644v2
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.04644v2)
- **Published**: 2016-08-16 15:59:35+00:00
- **Updated**: 2017-03-22 17:46:16+00:00
- **Authors**: Nicholas Carlini, David Wagner
- **Comment**: None
- **Journal**: None
- **Summary**: Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input $x$ and any target classification $t$, it is possible to find a new input $x'$ that is similar to $x$ but classified as $t$. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from $95\%$ to $0.5\%$.   In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with $100\%$ probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to previous adversarial example generation algorithms, our attacks are often much more effective (and never worse). Furthermore, we propose using high-confidence adversarial examples in a simple transferability test we show can also be used to break defensive distillation. We hope our attacks will be used as a benchmark in future defense attempts to create neural networks that resist adversarial examples.



### Variational Gaussian Process Auto-Encoder for Ordinal Prediction of Facial Action Units
- **Arxiv ID**: http://arxiv.org/abs/1608.04664v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1608.04664v2)
- **Published**: 2016-08-16 16:31:39+00:00
- **Updated**: 2016-09-05 21:25:48+00:00
- **Authors**: Stefanos Eleftheriadis, Ognjen Rudovic, Marc P. Deisenroth, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: We address the task of simultaneous feature fusion and modeling of discrete ordinal outputs. We propose a novel Gaussian process(GP) auto-encoder modeling approach. In particular, we introduce GP encoders to project multiple observed features onto a latent space, while GP decoders are responsible for reconstructing the original features. Inference is performed in a novel variational framework, where the recovered latent representations are further constrained by the ordinal output labels. In this way, we seamlessly integrate the ordinal structure in the learned manifold, while attaining robust fusion of the input features. We demonstrate the representation abilities of our model on benchmark datasets from machine learning and affect analysis. We further evaluate the model on the tasks of feature fusion and joint ordinal prediction of facial action units. Our experiments demonstrate the benefits of the proposed approach compared to the state of the art.



### Medical image denoising using convolutional denoising autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1608.04667v2
- **DOI**: 10.1109/ICDMW.2016.0041
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1608.04667v2)
- **Published**: 2016-08-16 16:39:20+00:00
- **Updated**: 2016-09-18 01:09:57+00:00
- **Authors**: Lovedeep Gondara
- **Comment**: To appear: 6 pages, paper to be published at the Fourth Workshop on
  Data Mining in Biomedical Informatics and Healthcare at ICDM, 2016
- **Journal**: None
- **Summary**: Image denoising is an important pre-processing step in medical image analysis. Different algorithms have been proposed in past three decades with varying denoising performances. More recently, having outperformed all conventional methods, deep learning based models have shown a great promise. These methods are however limited for requirement of large training sample size and high computational costs. In this paper we show that using small sample size, denoising autoencoders constructed using convolutional layers can be used for efficient denoising of medical images. Heterogeneous images can be combined to boost sample size for increased denoising performance. Simplest of networks can reconstruct images with corruption levels so high that noise and signal are not differentiable to human eye.



### Parameterized Principal Component Analysis
- **Arxiv ID**: http://arxiv.org/abs/1608.04695v2
- **DOI**: 10.1016/j.patcog.2018.01.018
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.04695v2)
- **Published**: 2016-08-16 18:23:13+00:00
- **Updated**: 2017-05-02 19:16:36+00:00
- **Authors**: Ajay Gupta, Adrian Barbu
- **Comment**: 36 pages, 15 figures
- **Journal**: Pattern Recognition 78, No. 6, 215-227, 2018
- **Summary**: When modeling multivariate data, one might have an extra parameter of contextual information that could be used to treat some observations as more similar to others. For example, images of faces can vary by age, and one would expect the face of a 40 year old to be more similar to the face of a 30 year old than to a baby face. We introduce a novel manifold approximation method, parameterized principal component analysis (PPCA) that models data with linear subspaces that change continuously according to the extra parameter of contextual information (e.g. age), instead of ad-hoc atlases. Special care has been taken in the loss function and the optimization method to encourage smoothly changing subspaces across the parameter values. The approach ensures that each observation's projection will share information with observations that have similar parameter values, but not with observations that have large parameter differences. We tested PPCA on artificial data based on known, smooth functions of an added parameter, as well as on three real datasets with different types of parameters. We compared PPCA to PCA, sparse PCA and to independent principal component analysis (IPCA), which groups observations by their parameter values and projects each group using PCA with no sharing of information for different groups. PPCA recovers the known functions with less error and projects the datasets' test set observations with consistently less reconstruction error than IPCA does. In some cases where the manifold is truly nonlinear, PCA outperforms all the other manifold approximation methods compared.



