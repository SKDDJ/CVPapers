# Arxiv Papers in cs.CV on 2016-08-19
### We Can "See" You via Wi-Fi - WiFi Action Recognition via Vision-based Methods
- **Arxiv ID**: http://arxiv.org/abs/1608.05461v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05461v2)
- **Published**: 2016-08-19 00:39:57+00:00
- **Updated**: 2017-04-03 04:59:23+00:00
- **Authors**: Jen-Yin Chang, Kuan-Ying Lee, Yu-Lin Wei, Kate Ching-Ju Lin, Winston Hsu
- **Comment**: 10 pages, 10 figures, submit to IEEE Transactions on Multimedia
- **Journal**: None
- **Summary**: Recently, Wi-Fi has caught tremendous attention for its ubiquity, and, motivated by Wi-Fi's low cost and privacy preservation, researchers have been putting lots of investigation into its potential on action recognition and even person identification. In this paper, we offer an comprehensive overview on these two topics in Wi-Fi. Also, through looking at these two topics from an unprecedented perspective, we could achieve generality instead of designing specific ad-hoc features for each scenario. Observing the great resemblance of Channel State Information (CSI, a fine-grained information captured from the received Wi-Fi signal) to texture, we proposed a brand-new framework based on computer vision methods. To minimize the effect of location dependency embedded in CSI, we propose a novel de-noising method based on Singular Value Decomposition (SVD) to eliminate the background energy and effectively extract the channel information of signals reflected by human bodies. From the experiments conducted, we demonstrate the feasibility and efficacy of the proposed methods. Also, we conclude factors that would affect the performance and highlight a few promising issues that require further deliberation.



### A Recurrent Encoder-Decoder Network for Sequential Face Alignment
- **Arxiv ID**: http://arxiv.org/abs/1608.05477v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05477v2)
- **Published**: 2016-08-19 02:28:50+00:00
- **Updated**: 2016-08-23 01:23:48+00:00
- **Authors**: Xi Peng, Rogerio S. Feris, Xiaoyu Wang, Dimitris N. Metaxas
- **Comment**: European Conference on Computer Vision (ECCV), 2016
- **Journal**: None
- **Summary**: We propose a novel recurrent encoder-decoder network model for real-time video-based face alignment. Our proposed model predicts 2D facial point maps regularized by a regression loss, while uniquely exploiting recurrent learning at both spatial and temporal dimensions. At the spatial level, we add a feedback loop connection between the combined output response map and the input, in order to enable iterative coarse-to-fine face alignment using a single network model. At the temporal level, we first decouple the features in the bottleneck of the network into temporal-variant factors, such as pose and expression, and temporal-invariant factors, such as identity information. Temporal recurrent learning is then applied to the decoupled temporal-variant features, yielding better generalization and significantly more accurate results at test time. We perform a comprehensive experimental analysis, showing the importance of each component of our proposed model, as well as superior results over the state-of-the-art in standard datasets.



### Critical Points for Two-view Triangulation
- **Arxiv ID**: http://arxiv.org/abs/1608.05512v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, math.AG
- **Links**: [PDF](http://arxiv.org/pdf/1608.05512v1)
- **Published**: 2016-08-19 07:05:15+00:00
- **Updated**: 2016-08-19 07:05:15+00:00
- **Authors**: Hon-Leung Lee
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Two-view triangulation is a problem of minimizing a quadratic polynomial under an equality constraint. We derive a polynomial that encodes the local minimizers of this problem using the theory of Lagrange multipliers. This offers a simpler derivation of the critical points that are given in Hartley-Sturm [6].



### On the Existence of a Projective Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1608.05518v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05518v2)
- **Published**: 2016-08-19 07:30:33+00:00
- **Updated**: 2020-11-12 06:45:06+00:00
- **Authors**: Hon-Leung Lee
- **Comment**: 7 pages, 1 figure
- **Journal**: None
- **Summary**: In this note we study the connection between the existence of a projective reconstruction and the existence of a fundamental matrix satisfying the epipolar constraints.



### Rigid Slice-To-Volume Medical Image Registration through Markov Random Fields
- **Arxiv ID**: http://arxiv.org/abs/1608.05562v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05562v1)
- **Published**: 2016-08-19 10:29:50+00:00
- **Updated**: 2016-08-19 10:29:50+00:00
- **Authors**: Roque Porchetto, Franco Stramana, Nikos Paragios, Enzo Ferrante
- **Comment**: Bayesian and Graphical Models for Biomedical Imaging Workshop, BAMBI
  (MICCAI 2016, Athens, Greece)
- **Journal**: None
- **Summary**: Rigid slice-to-volume registration is a challenging task, which finds application in medical imaging problems like image fusion for image guided surgeries and motion correction for volume reconstruction. It is usually formulated as an optimization problem and solved using standard continuous methods. In this paper, we discuss how this task be formulated as a discrete labeling problem on a graph. Inspired by previous works on discrete estimation of linear transformations using Markov Random Fields (MRFs), we model it using a pairwise MRF, where the nodes are associated to the rigid parameters, and the edges encode the relation between the variables. We compare the performance of the proposed method to a continuous formulation optimized using simplex, and we discuss how it can be used to further improve the accuracy of our approach. Promising results are obtained using a monomodal dataset composed of magnetic resonance images (MRI) of a beating heart.



### Learning Spatially Regularized Correlation Filters for Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1608.05571v1
- **DOI**: 10.1109/ICCV.2015.490
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05571v1)
- **Published**: 2016-08-19 11:11:49+00:00
- **Updated**: 2016-08-19 11:11:49+00:00
- **Authors**: Martin Danelljan, Gustav HÃ¤ger, Fahad Shahbaz Khan, Michael Felsberg
- **Comment**: ICCV 2015
- **Journal**: International Conference on Computer Vision, (ICCV) 2015, pp.
  4310-4318. IEEE (2015)
- **Summary**: Robust and accurate visual tracking is one of the most challenging computer vision problems. Due to the inherent lack of training data, a robust approach for constructing a target appearance model is crucial. Recently, discriminatively learned correlation filters (DCF) have been successfully applied to address this problem for tracking. These methods utilize a periodic assumption of the training samples to efficiently learn a classifier on all patches in the target neighborhood. However, the periodic assumption also introduces unwanted boundary effects, which severely degrade the quality of the tracking model.   We propose Spatially Regularized Discriminative Correlation Filters (SRDCF) for tracking. A spatial regularization component is introduced in the learning to penalize correlation filter coefficients depending on their spatial location. Our SRDCF formulation allows the correlation filters to be learned on a significantly larger set of negative training samples, without corrupting the positive samples. We further propose an optimization strategy, based on the iterative Gauss-Seidel method, for efficient online learning of our SRDCF. Experiments are performed on four benchmark datasets: OTB-2013, ALOV++, OTB-2015, and VOT2014. Our approach achieves state-of-the-art results on all four datasets. On OTB-2013 and OTB-2015, we obtain an absolute gain of 8.0% and 8.2% respectively, in mean overlap precision, compared to the best existing trackers.



### Detecting Vanishing Points using Global Image Context in a Non-Manhattan World
- **Arxiv ID**: http://arxiv.org/abs/1608.05684v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1608.05684v1)
- **Published**: 2016-08-19 18:08:55+00:00
- **Updated**: 2016-08-19 18:08:55+00:00
- **Authors**: Menghua Zhai, Scott Workman, Nathan Jacobs
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  2016
- **Journal**: None
- **Summary**: We propose a novel method for detecting horizontal vanishing points and the zenith vanishing point in man-made environments. The dominant trend in existing methods is to first find candidate vanishing points, then remove outliers by enforcing mutual orthogonality. Our method reverses this process: we propose a set of horizon line candidates and score each based on the vanishing points it contains. A key element of our approach is the use of global image context, extracted with a deep convolutional network, to constrain the set of candidates under consideration. Our method does not make a Manhattan-world assumption and can operate effectively on scenes with only a single horizontal vanishing point. We evaluate our approach on three benchmark datasets and achieve state-of-the-art performance on each. In addition, our approach is significantly faster than the previous best method.



### Fundamental principles of cortical computation: unsupervised learning with prediction, compression and feedback
- **Arxiv ID**: http://arxiv.org/abs/1608.06277v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1608.06277v1)
- **Published**: 2016-08-19 21:05:35+00:00
- **Updated**: 2016-08-19 21:05:35+00:00
- **Authors**: Micah Richert, Dimitry Fisher, Filip Piekniewski, Eugene M. Izhikevich, Todd L. Hylton
- **Comment**: None
- **Journal**: None
- **Summary**: There has been great progress in understanding of anatomical and functional microcircuitry of the primate cortex. However, the fundamental principles of cortical computation - the principles that allow the visual cortex to bind retinal spikes into representations of objects, scenes and scenarios - have so far remained elusive. In an attempt to come closer to understanding the fundamental principles of cortical computation, here we present a functional, phenomenological model of the primate visual cortex. The core part of the model describes four hierarchical cortical areas with feedforward, lateral, and recurrent connections. The three main principles implemented in the model are information compression, unsupervised learning by prediction, and use of lateral and top-down context. We show that the model reproduces key aspects of the primate ventral stream of visual processing including Simple and Complex cells in V1, increasingly complicated feature encoding, and increased separability of object representations in higher cortical areas. The model learns representations of the visual environment that allow for accurate classification and state-of-the-art visual tracking performance on novel objects.



