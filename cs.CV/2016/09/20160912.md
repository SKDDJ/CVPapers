# Arxiv Papers in cs.CV on 2016-09-12
### Segmentation and Classification of Skin Lesions for Disease Diagnosis
- **Arxiv ID**: http://arxiv.org/abs/1609.03277v1
- **DOI**: 10.1016/j.procs.2015.03.090
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03277v1)
- **Published**: 2016-09-12 06:05:55+00:00
- **Updated**: 2016-09-12 06:05:55+00:00
- **Authors**: Sumithra R, Mahamad Suhil, D. S. Guru
- **Comment**: 10 pages, 6 figures, 2 Tables in Elsevier, Proceedia Computer
  Science, International Conference on Advanced Computing Technologies and
  Applications (ICACTA-2015)
- **Journal**: None
- **Summary**: In this paper, a novel approach for automatic segmentation and classification of skin lesions is proposed. Initially, skin images are filtered to remove unwanted hairs and noise and then the segmentation process is carried out to extract lesion areas. For segmentation, a region growing method is applied by automatic initialization of seed points. The segmentation performance is measured with different well known measures and the results are appreciable. Subsequently, the extracted lesion areas are represented by color and texture features. SVM and k-NN classifiers are used along with their fusion for the classification using the extracted features. The performance of the system is tested on our own dataset of 726 samples from 141 images consisting of 5 different classes of diseases. The results are very promising with 46.71% and 34% of F-measure using SVM and k-NN classifier respectively and with 61% of F-measure for fusion of SVM and k-NN.



### Semi-Supervised Sparse Representation Based Classification for Face Recognition with Insufficient Labeled Samples
- **Arxiv ID**: http://arxiv.org/abs/1609.03279v2
- **DOI**: 10.1109/TIP.2017.2675341
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03279v2)
- **Published**: 2016-09-12 06:45:15+00:00
- **Updated**: 2017-03-24 06:26:12+00:00
- **Authors**: Yuan Gao, Jiayi Ma, Alan L. Yuille
- **Comment**: To appear in IEEE Transactions on Image Processing, 2017
- **Journal**: None
- **Summary**: This paper addresses the problem of face recognition when there is only few, or even only a single, labeled examples of the face that we wish to recognize. Moreover, these examples are typically corrupted by nuisance variables, both linear (i.e., additive nuisance variables such as bad lighting, wearing of glasses) and non-linear (i.e., non-additive pixel-wise nuisance variables such as expression changes). The small number of labeled examples means that it is hard to remove these nuisance variables between the training and testing faces to obtain good recognition performance. To address the problem we propose a method called Semi-Supervised Sparse Representation based Classification (S$^3$RC). This is based on recent work on sparsity where faces are represented in terms of two dictionaries: a gallery dictionary consisting of one or more examples of each person, and a variation dictionary representing linear nuisance variables (e.g., different lighting conditions, different glasses). The main idea is that (i) we use the variation dictionary to characterize the linear nuisance variables via the sparsity framework, then (ii) prototype face images are estimated as a gallery dictionary via a Gaussian Mixture Model (GMM), with mixed labeled and unlabeled samples in a semi-supervised manner, to deal with the non-linear nuisance variations between labeled and unlabeled samples. We have done experiments with insufficient labeled samples, even when there is only a single labeled sample per person. Our results on the AR, Multi-PIE, CAS-PEAL, and LFW databases demonstrate that the proposed method is able to deliver significantly improved performance over existing methods.



### Fast Algorithm of High-resolution Microwave Imaging Using the Non-parametric Generalized Reflectivity Model
- **Arxiv ID**: http://arxiv.org/abs/1611.03341v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1611.03341v1)
- **Published**: 2016-09-12 07:34:44+00:00
- **Updated**: 2016-09-12 07:34:44+00:00
- **Authors**: Long Gang Wang, Lianlin Li, Tie Jun Cui
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents an efficient algorithm of high-resolution microwave imaging based on the concept of generalized reflectivity. The contribution made in this paper is two-fold. We introduce the concept of non-parametric generalized reflectivity (GR, for short) as a function of operational frequencies and view angles, etc. The GR extends the conventional Born-based imaging model, i.e., single-scattering model, into that accounting for more realistic interaction between the electromagnetic wavefield and imaged scene. Afterwards, the GR-based microwave imaging is formulated in the convex of sparsity-regularized optimization. Typically, the sparsity-regularized optimization requires the implementation of iterative strategy, which is computationally expensive, especially for large-scale problems. To break this bottleneck, we convert the imaging problem into the problem of physics-driven image processing by introducing a dual transformation. Moreover, this image processing is performed over overlapping patches, which can be efficiently solved in the parallel or distributed manner. In this way, the proposed high-resolution imaging methodology could be applicable to large-scale microwave imaging problems. Selected simulation results are provided to demonstrate the state-of-art performance of proposed methodology.



### Image denoising via group sparsity residual constraint
- **Arxiv ID**: http://arxiv.org/abs/1609.03302v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03302v5)
- **Published**: 2016-09-12 08:34:59+00:00
- **Updated**: 2017-03-03 01:17:39+00:00
- **Authors**: Zhiyuan Zha, Xin Liu, Ziheng Zhou, Xiaohua Huang, Jingang Shi, Zhenhong Shang, Lan Tang, Yechao Bai, Qiong Wang, Xinggan Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Group sparsity has shown great potential in various low-level vision tasks (e.g, image denoising, deblurring and inpainting). In this paper, we propose a new prior model for image denoising via group sparsity residual constraint (GSRC). To enhance the performance of group sparse-based image denoising, the concept of group sparsity residual is proposed, and thus, the problem of image denoising is translated into one that reduces the group sparsity residual. To reduce the residual, we first obtain some good estimation of the group sparse coefficients of the original image by the first-pass estimation of noisy image, and then centralize the group sparse coefficients of noisy image to the estimation. Experimental results have demonstrated that the proposed method not only outperforms many state-of-the-art denoising methods such as BM3D and WNNM, but results in a faster speed.



### FALCON: Feature Driven Selective Classification for Energy-Efficient Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1609.03396v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03396v2)
- **Published**: 2016-09-12 13:40:13+00:00
- **Updated**: 2017-03-08 15:16:19+00:00
- **Authors**: Priyadarshini Panda, Aayush Ankit, Parami Wijesinghe, Kaushik Roy
- **Comment**: 13 pages, 13 figures, Accepted for publication in IEEE TCAD, 2017
- **Journal**: None
- **Summary**: Machine-learning algorithms have shown outstanding image recognition or classification performance for computer vision applications. However, the compute and energy requirement for implementing such classifier models for large-scale problems is quite high. In this paper, we propose Feature Driven Selective Classification (FALCON) inspired by the biological visual attention mechanism in the brain to optimize the energy-efficiency of machine-learning classifiers. We use the consensus in the characteristic features (color/texture) across images in a dataset to decompose the original classification problem and construct a tree of classifiers (nodes) with a generic-to-specific transition in the classification hierarchy. The initial nodes of the tree separate the instances based on feature information and selectively enable the latter nodes to perform object specific classification. The proposed methodology allows selective activation of only those branches and nodes of the classification tree that are relevant to the input while keeping the remaining nodes idle. Additionally, we propose a programmable and scalable Neuromorphic Engine (NeuE) that utilizes arrays of specialized neural computational elements to execute the FALCON based classifier models for diverse datasets. The structure of FALCON facilitates the reuse of nodes while scaling up from small classification problems to larger ones thus allowing us to construct classifier implementations that are significantly more efficient. We evaluate our approach for a 12-object classification task on the Caltech101 dataset and 10-object task on CIFAR-10 dataset by constructing FALCON models on the NeuE platform in 45nm technology. Our results demonstrate significant improvement in energy-efficiency and training time for minimal loss in output quality.



### Active Canny: Edge Detection and Recovery with Open Active Contour Models
- **Arxiv ID**: http://arxiv.org/abs/1609.03415v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1609.03415v1)
- **Published**: 2016-09-12 14:13:26+00:00
- **Updated**: 2016-09-12 14:13:26+00:00
- **Authors**: Muhammet Bastan, S. Saqib Bukhari, Thomas M. Breuel
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce an edge detection and recovery framework based on open active contour models (snakelets). This is motivated by the noisy or broken edges output by standard edge detection algorithms, like Canny. The idea is to utilize the local continuity and smoothness cues provided by strong edges and grow them to recover the missing edges. This way, the strong edges are used to recover weak or missing edges by considering the local edge structures, instead of blindly linking them if gradient magnitudes are above some threshold. We initialize short snakelets on the gradient magnitudes or binary edges automatically and then deform and grow them under the influence of gradient vector flow. The output snakelets are able to recover most of the breaks or weak edges, and they provide a smooth edge representation of the image; they can also be used for higher level analysis, like contour segmentation.



### MUG: A Parameterless No-Reference JPEG Quality Evaluator Robust to Block Size and Misalignment
- **Arxiv ID**: http://arxiv.org/abs/1609.03461v2
- **DOI**: 10.1109/LSP.2016.2608865
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03461v2)
- **Published**: 2016-09-12 16:11:26+00:00
- **Updated**: 2016-09-19 16:33:48+00:00
- **Authors**: Hossein Ziaei Nafchi, Atena Shahkolaei, Rachid Hedjam, Mohamed Cheriet
- **Comment**: 5 pages, 4 figures, 3 tables
- **Journal**: None
- **Summary**: In this letter, a very simple no-reference image quality assessment (NR-IQA) model for JPEG compressed images is proposed. The proposed metric called median of unique gradients (MUG) is based on the very simple facts of unique gradient magnitudes of JPEG compressed images. MUG is a parameterless metric and does not need training. Unlike other NR-IQAs, MUG is independent to block size and cropping. A more stable index called MUG+ is also introduced. The experimental results on six benchmark datasets of natural images and a benchmark dataset of synthetic images show that MUG is comparable to the state-of-the-art indices in literature. In addition, its performance remains unchanged for the case of the cropped images in which block boundaries are not known. The MATLAB source code of the proposed metrics is available at https://dl.dropboxusercontent.com/u/74505502/MUG.m and https://dl.dropboxusercontent.com/u/74505502/MUGplus.m.



### Hyperspectral Unmixing with Endmember Variability using Partial Membership Latent Dirichlet Allocation
- **Arxiv ID**: http://arxiv.org/abs/1609.03500v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03500v1)
- **Published**: 2016-09-12 17:32:41+00:00
- **Updated**: 2016-09-12 17:32:41+00:00
- **Authors**: Sheng Zou, Alina Zare
- **Comment**: None
- **Journal**: None
- **Summary**: The application of Partial Membership Latent Dirichlet Allocation(PM-LDA) for hyperspectral endmember estimation and spectral unmixing is presented. PM-LDA provides a model for a hyperspectral image analysis that accounts for spectral variability and incorporates spatial information through the use of superpixel-based 'documents.' In our application of PM-LDA, we employ the Normal Compositional Model in which endmembers are represented as Normal distributions to account for spectral variability and proportion vectors are modeled as random variables governed by a Dirichlet distribution. The use of the Dirichlet distribution enforces positivity and sum-to-one constraints on the proportion values. Algorithm results on real hyperspectral data indicate that PM-LDA produces endmember distributions that represent the ground truth classes and their associated variability.



### Examining Representational Similarity in ConvNets and the Primate Visual Cortex
- **Arxiv ID**: http://arxiv.org/abs/1609.03529v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1609.03529v1)
- **Published**: 2016-09-12 19:00:24+00:00
- **Updated**: 2016-09-12 19:00:24+00:00
- **Authors**: Abhimanyu Dubey, Jayadeva, Sumeet Agarwal
- **Comment**: 4 pages, short abstract, Accepted to the Workshop on Biological and
  Artificial Vision, ECCV, 2016
- **Journal**: None
- **Summary**: We compare several ConvNets with different depth and regularization techniques with multi-unit macaque IT cortex recordings and assess the impact of the same on representational similarity with the primate visual cortex. We find that with increasing depth and validation performance, ConvNet features are closer to cortical IT representations.



### Fully-Trainable Deep Matching
- **Arxiv ID**: http://arxiv.org/abs/1609.03532v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03532v1)
- **Published**: 2016-09-12 19:07:04+00:00
- **Updated**: 2016-09-12 19:07:04+00:00
- **Authors**: James Thewlis, Shuai Zheng, Philip H. S. Torr, Andrea Vedaldi
- **Comment**: British Machine Vision Conference (BMVC) 2016
- **Journal**: None
- **Summary**: Deep Matching (DM) is a popular high-quality method for quasi-dense image matching. Despite its name, however, the original DM formulation does not yield a deep neural network that can be trained end-to-end via backpropagation. In this paper, we remove this limitation by rewriting the complete DM algorithm as a convolutional neural network. This results in a novel deep architecture for image matching that involves a number of new layer types and that, similar to recent networks for image segmentation, has a U-topology. We demonstrate the utility of the approach by improving the performance of DM by learning it end-to-end on an image matching task.



### A Multi-Scale Cascade Fully Convolutional Network Face Detector
- **Arxiv ID**: http://arxiv.org/abs/1609.03536v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03536v1)
- **Published**: 2016-09-12 19:13:46+00:00
- **Updated**: 2016-09-12 19:13:46+00:00
- **Authors**: Zhenheng Yang, Ram Nevatia
- **Comment**: Accepted to ICPR 16'
- **Journal**: None
- **Summary**: Face detection is challenging as faces in images could be present at arbitrary locations and in different scales. We propose a three-stage cascade structure based on fully convolutional neural networks (FCNs). It first proposes the approximate locations where the faces may be, then aims to find the accurate location by zooming on to the faces. Each level of the FCN cascade is a multi-scale fully-convolutional network, which generates scores at different locations and in different scales. A score map is generated after each FCN stage. Probable regions of face are selected and fed to the next stage. The number of proposals is decreased after each level, and the areas of regions are decreased to more precisely fit the face. Compared to passing proposals directly between stages, passing probable regions can decrease the number of proposals and reduce the cases where first stage doesn't propose good bounding boxes. We show that by using FCN and score map, the FCN cascade face detector can achieve strong performance on public datasets.



### Dilemma First Search for Effortless Optimization of NP-Hard Problems
- **Arxiv ID**: http://arxiv.org/abs/1609.03545v1
- **DOI**: None
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1609.03545v1)
- **Published**: 2016-09-12 19:36:02+00:00
- **Updated**: 2016-09-12 19:36:02+00:00
- **Authors**: Julien Weissenberg, Hayko Riemenschneider, Ralf Dragon, Luc Van Gool
- **Comment**: To be published at ICPR 2016
- **Journal**: None
- **Summary**: To tackle the exponentiality associated with NP-hard problems, two paradigms have been proposed. First, Branch & Bound, like Dynamic Programming, achieve efficient exact inference but requires extensive information and analysis about the problem at hand. Second, meta-heuristics are easier to implement but comparatively inefficient. As a result, a number of problems have been left unoptimized and plain greedy solutions are used. We introduce a theoretical framework and propose a powerful yet simple search method called Dilemma First Search (DFS). DFS exploits the decision heuristic needed for the greedy solution for further optimization. DFS is useful when it is hard to design efficient exact inference. We evaluate DFS on two problems: First, the Knapsack problem, for which efficient algorithms exist, serves as a toy example. Second, Decision Tree inference, where state-of-the-art algorithms rely on the greedy or randomness-based solutions. We further show that decision trees benefit from optimizations that are performed in a fraction of the iterations required by a random-based search.



### Generative Visual Manipulation on the Natural Image Manifold
- **Arxiv ID**: http://arxiv.org/abs/1609.03552v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03552v3)
- **Published**: 2016-09-12 19:46:08+00:00
- **Updated**: 2018-12-16 22:00:59+00:00
- **Authors**: Jun-Yan Zhu, Philipp Krähenbühl, Eli Shechtman, Alexei A. Efros
- **Comment**: In European Conference on Computer Vision (ECCV 2016)
- **Journal**: None
- **Summary**: Realistic image manipulation is challenging because it requires modifying the image appearance in a user-controlled way, while preserving the realism of the result. Unless the user has considerable artistic skill, it is easy to "fall off" the manifold of natural images while editing. In this paper, we propose to learn the natural image manifold directly from data using a generative adversarial neural network. We then define a class of image editing operations, and constrain their output to lie on that learned manifold at all times. The model automatically adjusts the output keeping all edits as realistic as possible. All our manipulations are expressed in terms of constrained optimization and are applied in near-real time. We evaluate our algorithm on the task of realistic photo manipulation of shape and color. The presented method can further be used for changing one image to look like the other, as well as generating novel imagery from scratch based on user's scribbles.



### Detecting Text in Natural Image with Connectionist Text Proposal Network
- **Arxiv ID**: http://arxiv.org/abs/1609.03605v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03605v1)
- **Published**: 2016-09-12 21:12:46+00:00
- **Updated**: 2016-09-12 21:12:46+00:00
- **Authors**: Zhi Tian, Weilin Huang, Tong He, Pan He, Yu Qiao
- **Comment**: To appear in ECCV, 2016
- **Journal**: None
- **Summary**: We propose a novel Connectionist Text Proposal Network (CTPN) that accurately localizes text lines in natural image. The CTPN detects a text line in a sequence of fine-scale text proposals directly in convolutional feature maps. We develop a vertical anchor mechanism that jointly predicts location and text/non-text score of each fixed-width proposal, considerably improving localization accuracy. The sequential proposals are naturally connected by a recurrent neural network, which is seamlessly incorporated into the convolutional network, resulting in an end-to-end trainable model. This allows the CTPN to explore rich context information of image, making it powerful to detect extremely ambiguous text. The CTPN works reliably on multi-scale and multi- language text without further post-processing, departing from previous bottom-up methods requiring multi-step post-processing. It achieves 0.88 and 0.61 F-measure on the ICDAR 2013 and 2015 benchmarks, surpass- ing recent results [8, 35] by a large margin. The CTPN is computationally efficient with 0:14s/image, by using the very deep VGG16 model [27]. Online demo is available at: http://textdet.com/.



### Reliable Attribute-Based Object Recognition Using High Predictive Value Classifiers
- **Arxiv ID**: http://arxiv.org/abs/1609.03619v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03619v2)
- **Published**: 2016-09-12 22:20:12+00:00
- **Updated**: 2016-10-24 03:38:27+00:00
- **Authors**: Wentao Luan, Yezhou Yang, Cornelia Fermuller, John Baras
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the problem of object recognition in 3D using an ensemble of attribute-based classifiers. We propose two new concepts to improve classification in practical situations, and show their implementation in an approach implemented for recognition from point-cloud data. First, the viewing conditions can have a strong influence on classification performance. We study the impact of the distance between the camera and the object and propose an approach to fuse multiple attribute classifiers, which incorporates distance into the decision making. Second, lack of representative training samples often makes it difficult to learn the optimal threshold value for best positive and negative detection rate. We address this issue, by setting in our attribute classifiers instead of just one threshold value, two threshold values to distinguish a positive, a negative and an uncertainty class, and we prove the theoretical correctness of this approach. Empirical studies demonstrate the effectiveness and feasibility of the proposed concepts.



