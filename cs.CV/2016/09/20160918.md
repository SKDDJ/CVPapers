# Arxiv Papers in cs.CV on 2016-09-18
### Pose from Action: Unsupervised Learning of Pose Features based on Motion
- **Arxiv ID**: http://arxiv.org/abs/1609.05420v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.05420v1)
- **Published**: 2016-09-18 04:18:42+00:00
- **Updated**: 2016-09-18 04:18:42+00:00
- **Authors**: Senthil Purushwalkam, Abhinav Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: Human actions are comprised of a sequence of poses. This makes videos of humans a rich and dense source of human poses. We propose an unsupervised method to learn pose features from videos that exploits a signal which is complementary to appearance and can be used as supervision: motion. The key idea is that humans go through poses in a predictable manner while performing actions. Hence, given two poses, it should be possible to model the motion that caused the change between them. We represent each of the poses as a feature in a CNN (Appearance ConvNet) and generate a motion encoding from optical flow maps using a separate CNN (Motion ConvNet). The data for this task is automatically generated allowing us to train without human supervision. We demonstrate the strength of the learned representation by finetuning the trained model for Pose Estimation on the FLIC dataset, for static image action recognition on PASCAL and for action recognition in videos on UCF101 and HMDB51.



### Consistent Discretization and Minimization of the L1 Norm on Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1609.05434v1
- **DOI**: None
- **Categories**: **cs.NA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1609.05434v1)
- **Published**: 2016-09-18 06:56:57+00:00
- **Updated**: 2016-09-18 06:56:57+00:00
- **Authors**: Alex Bronstein, Yoni Choukroun, Ron Kimmel, Matan Sela
- **Comment**: None
- **Journal**: None
- **Summary**: The L1 norm has been tremendously popular in signal and image processing in the past two decades due to its sparsity-promoting properties. More recently, its generalization to non-Euclidean domains has been found useful in shape analysis applications. For example, in conjunction with the minimization of the Dirichlet energy, it was shown to produce a compactly supported quasi-harmonic orthonormal basis, dubbed as compressed manifold modes. The continuous L1 norm on the manifold is often replaced by the vector l1 norm applied to sampled functions. We show that such an approach is incorrect in the sense that it does not consistently discretize the continuous norm and warn against its sensitivity to the specific sampling. We propose two alternative discretizations resulting in an iteratively-reweighed l2 norm. We demonstrate the proposed strategy on the compressed modes problem, which reduces to a sequence of simple eigendecomposition problems not requiring non-convex optimization on Stiefel manifolds and producing more stable and accurate results.



### Set-Point Regulation of Linear Continuous-Time Systems using Neuromorphic Vision Sensors
- **Arxiv ID**: http://arxiv.org/abs/1609.05483v1
- **DOI**: None
- **Categories**: **cs.SY**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1609.05483v1)
- **Published**: 2016-09-18 13:11:19+00:00
- **Updated**: 2016-09-18 13:11:19+00:00
- **Authors**: Prince Singh, Sze Zheng Yong, Emilio Frazzoli
- **Comment**: Submitted to IEEE Transactions on Automatic Control
- **Journal**: None
- **Summary**: Recently developed neuromorphic vision sensors have become promising candidates for agile and autonomous robotic applications primarily due to, in particular, their high temporal resolution and low latency. Each pixel of this sensor independently fires an asynchronous stream of "retinal events" once a change in the light field is detected. Existing computer vision algorithms can only process periodic frames and so a new class of algorithms needs to be developed that can efficiently process these events for control tasks. In this paper, we investigate the problem of regulating a continuous-time linear time invariant (LTI) system to a desired point using measurements from a neuromorphic sensor. We present an $H_\infty$ controller that regulates the LTI system to a desired set-point and provide the set of neuromorphic sensor based cameras for the given system that fulfill the regulation task. The effectiveness of our approach is illustrated on an unstable system.



### Learning camera viewpoint using CNN to improve 3D body pose estimation
- **Arxiv ID**: http://arxiv.org/abs/1609.05522v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.05522v1)
- **Published**: 2016-09-18 17:56:15+00:00
- **Updated**: 2016-09-18 17:56:15+00:00
- **Authors**: Mona Fathollahi Ghezelghieh, Rangachar Kasturi, Sudeep Sarkar
- **Comment**: To appear at the International Conference on 3D Vision (3DV), 2016
- **Journal**: None
- **Summary**: The objective of this work is to estimate 3D human pose from a single RGB image. Extracting image representations which incorporate both spatial relation of body parts and their relative depth plays an essential role in accurate3D pose reconstruction. In this paper, for the first time, we show that camera viewpoint in combination to 2D joint lo-cations significantly improves 3D pose accuracy without the explicit use of perspective geometry mathematical models.To this end, we train a deep Convolutional Neural Net-work (CNN) to learn categorical camera viewpoint. To make the network robust against clothing and body shape of the subject in the image, we utilized 3D computer rendering to synthesize additional training images. We test our framework on the largest 3D pose estimation bench-mark, Human3.6m, and achieve up to 20% error reduction compared to the state-of-the-art approaches that do not use body part segmentation.



### From Multiview Image Curves to 3D Drawings
- **Arxiv ID**: http://arxiv.org/abs/1609.05561v1
- **DOI**: 10.1007/978-3-319-46493-0_5
- **Categories**: **cs.CV**, cs.CG, cs.GR, cs.RO, 65D17, 68U05, 68U10, 53A20, I.4.8; I.4.10; I.4.6; I.3.5; J.6
- **Links**: [PDF](http://arxiv.org/pdf/1609.05561v1)
- **Published**: 2016-09-18 22:20:35+00:00
- **Updated**: 2016-09-18 22:20:35+00:00
- **Authors**: Anil Usumezbas, Ricardo Fabbri, Benjamin B. Kimia
- **Comment**: Expanded ECCV 2016 version with tweaked figures and including an
  overview of the supplementary material available at
  multiview-3d-drawing.sourceforge.net
- **Journal**: Lecture Notes in Computer Science, 9908, pp 70-87, september 2016
- **Summary**: Reconstructing 3D scenes from multiple views has made impressive strides in recent years, chiefly by correlating isolated feature points, intensity patterns, or curvilinear structures. In the general setting - without controlled acquisition, abundant texture, curves and surfaces following specific models or limiting scene complexity - most methods produce unorganized point clouds, meshes, or voxel representations, with some exceptions producing unorganized clouds of 3D curve fragments. Ideally, many applications require structured representations of curves, surfaces and their spatial relationships. This paper presents a step in this direction by formulating an approach that combines 2D image curves into a collection of 3D curves, with topological connectivity between them represented as a 3D graph. This results in a 3D drawing, which is complementary to surface representations in the same sense as a 3D scaffold complements a tent taut over it. We evaluate our results against truth on synthetic and real datasets.



