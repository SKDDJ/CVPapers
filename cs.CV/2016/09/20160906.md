# Arxiv Papers in cs.CV on 2016-09-06
### Evolutionary Synthesis of Deep Neural Networks via Synaptic Cluster-driven Genetic Encoding
- **Arxiv ID**: http://arxiv.org/abs/1609.01360v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1609.01360v2)
- **Published**: 2016-09-06 01:08:03+00:00
- **Updated**: 2016-11-22 16:00:01+00:00
- **Authors**: Mohammad Javad Shafiee, Alexander Wong
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: There has been significant recent interest towards achieving highly efficient deep neural network architectures. A promising paradigm for achieving this is the concept of evolutionary deep intelligence, which attempts to mimic biological evolution processes to synthesize highly-efficient deep neural networks over successive generations. An important aspect of evolutionary deep intelligence is the genetic encoding scheme used to mimic heredity, which can have a significant impact on the quality of offspring deep neural networks. Motivated by the neurobiological phenomenon of synaptic clustering, we introduce a new genetic encoding scheme where synaptic probability is driven towards the formation of a highly sparse set of synaptic clusters. Experimental results for the task of image classification demonstrated that the synthesized offspring networks using this synaptic cluster-driven genetic encoding scheme can achieve state-of-the-art performance while having network architectures that are not only significantly more efficient (with a ~125-fold decrease in synapses for MNIST) compared to the original ancestor network, but also tailored for GPU-accelerated machine learning applications.



### Object Specific Deep Learning Feature and Its Application to Face Detection
- **Arxiv ID**: http://arxiv.org/abs/1609.01366v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01366v1)
- **Published**: 2016-09-06 01:35:13+00:00
- **Updated**: 2016-09-06 01:35:13+00:00
- **Authors**: Xianxu Hou, Ke Sun, Linlin Shen, Guoping Qiu
- **Comment**: None
- **Journal**: None
- **Summary**: We present a method for discovering and exploiting object specific deep learning features and use face detection as a case study. Motivated by the observation that certain convolutional channels of a Convolutional Neural Network (CNN) exhibit object specific responses, we seek to discover and exploit the convolutional channels of a CNN in which neurons are activated by the presence of specific objects in the input image. A method for explicitly fine-tuning a pre-trained CNN to induce an object specific channel (OSC) and systematically identifying it for the human face object has been developed. Based on the basic OSC features, we introduce a multi-resolution approach to constructing robust face heatmaps for fast face detection in unconstrained settings. We show that multi-resolution OSC can be used to develop state of the art face detectors which have the advantage of being simple and compact.



### Reconstructing Articulated Rigged Models from RGB-D Videos
- **Arxiv ID**: http://arxiv.org/abs/1609.01371v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01371v2)
- **Published**: 2016-09-06 02:10:21+00:00
- **Updated**: 2016-09-09 15:20:38+00:00
- **Authors**: Dimitrios Tzionas, Juergen Gall
- **Comment**: Accepted for publication - European Conference on Computer Vision
  Workshops 2016 (ECCVW'16) - Workshop on Recovering 6D Object Pose (R6D'16)
- **Journal**: None
- **Summary**: Although commercial and open-source software exist to reconstruct a static object from a sequence recorded with an RGB-D sensor, there is a lack of tools that build rigged models of articulated objects that deform realistically and can be used for tracking or animation. In this work, we fill this gap and propose a method that creates a fully rigged model of an articulated object from depth data of a single sensor. To this end, we combine deformable mesh tracking, motion segmentation based on spectral clustering and skeletonization based on mean curvature flow. The fully rigged model then consists of a watertight mesh, embedded skeleton, and skinning weights.



### An Adaptive Parameter Estimation for Guided Filter based Image Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/1609.01380v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01380v1)
- **Published**: 2016-09-06 03:43:32+00:00
- **Updated**: 2016-09-06 03:43:32+00:00
- **Authors**: Hang Yang, Zhongbo Zhang, Yujing Guan
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: Image deconvolution is still to be a challenging ill-posed problem for recovering a clear image from a given blurry image, when the point spread function is known. Although competitive deconvolution methods are numerically impressive and approach theoretical limits, they are becoming more complex, making analysis, and implementation difficult. Furthermore, accurate estimation of the regularization parameter is not easy for successfully solving image deconvolution problems. In this paper, we develop an effective approach for image restoration based on one explicit image filter - guided filter. By applying the decouple of denoising and deblurring techniques to the deconvolution model, we reduce the optimization complexity and achieve a simple but effective algorithm to automatically compute the parameter in each iteration, which is based on Morozov's discrepancy principle. Experimental results demonstrate that the proposed algorithm outperforms many state-of-the-art deconvolution methods in terms of both ISNR and visual quality.



### Delaunay Triangulation on Skeleton of Flowers for Classification
- **Arxiv ID**: http://arxiv.org/abs/1609.01828v1
- **DOI**: 10.1016/j.procs.2015.03.125
- **Categories**: **cs.CV**, I.4.6; I.4.7; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1609.01828v1)
- **Published**: 2016-09-06 06:53:05+00:00
- **Updated**: 2016-09-06 06:53:05+00:00
- **Authors**: Y H Sharath Kumar, N Vinay Kumar, D S Guru
- **Comment**: 10 pages, 5 figures, 1 table
- **Journal**: Procedia Computer Science, Volume 45, 2015, Pages 226-235
- **Summary**: In this work, we propose a Triangle based approach to classify flower images. Initially, flowers are segmented using whorl based region merging segmentation. Skeleton of a flower is obtained from the segmented flower using a skeleton pruning method. The Delaunay triangulation is obtained from the endpoints and junction points detected on the skeleton. The length and angle features are extracted from the obtained Delaunay triangles and then are aggregated to represent in the form of interval-valued type data. A suitable classifier has been explored for the purpose of classification. To corroborate the efficacy of the proposed method, an experiment is conducted on our own data set of 30 classes of flowers, containing 3000 samples.



### Features Fusion for Classification of Logos
- **Arxiv ID**: http://arxiv.org/abs/1609.01414v1
- **DOI**: 10.1016/j.procs.2016.05.245
- **Categories**: **cs.CV**, I.4.7; I.4.8; I.4.9; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/1609.01414v1)
- **Published**: 2016-09-06 07:29:56+00:00
- **Updated**: 2016-09-06 07:29:56+00:00
- **Authors**: N. Vinay Kumar, Pratheek, V. Vijaya Kantha, K. N. Govindaraju, D. S. Guru
- **Comment**: 10 pages, 5 figures, 9 tables
- **Journal**: Procedia Computer Science, Volume 85, 2016, Pages 370-379
- **Summary**: In this paper, a logo classification system based on the appearance of logo images is proposed. The proposed classification system makes use of global characteristics of logo images for classification. Color, texture, and shape of a logo wholly describe the global characteristics of logo images. The various combinations of these characteristics are used for classification. The combination contains only with single feature or with fusion of two features or fusion of all three features considered at a time respectively. Further, the system categorizes the logo image into: a logo image with fully text or with fully symbols or containing both symbols and texts.. The K-Nearest Neighbour (K-NN) classifier is used for classification. Due to the lack of color logo image dataset in the literature, the same is created consisting 5044 color logo images. Finally, the performance of the classification system is evaluated through accuracy, precision, recall and F-measure computed from the confusion matrix. The experimental results show that the most promising results are obtained for fusion of features.



### Statistical Meta-Analysis of Presentation Attacks for Secure Multibiometric Systems
- **Arxiv ID**: http://arxiv.org/abs/1609.01461v1
- **DOI**: 10.1109/TPAMI.2016.2558154
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1609.01461v1)
- **Published**: 2016-09-06 09:44:47+00:00
- **Updated**: 2016-09-06 09:44:47+00:00
- **Authors**: Battista Biggio, Giorgio Fumera, Gian Luca Marcialis, Fabio Roli
- **Comment**: Published in: IEEE Transactions on Pattern Analysis and Machine
  Intelligence, 2016
- **Journal**: IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2016
- **Summary**: Prior work has shown that multibiometric systems are vulnerable to presentation attacks, assuming that their matching score distribution is identical to that of genuine users, without fabricating any fake trait. We have recently shown that this assumption is not representative of current fingerprint and face presentation attacks, leading one to overestimate the vulnerability of multibiometric systems, and to design less effective fusion rules. In this paper, we overcome these limitations by proposing a statistical meta-model of face and fingerprint presentation attacks that characterizes a wider family of fake score distributions, including distributions of known and, potentially, unknown attacks. This allows us to perform a thorough security evaluation of multibiometric systems against presentation attacks, quantifying how their vulnerability may vary also under attacks that are different from those considered during design, through an uncertainty analysis. We empirically show that our approach can reliably predict the performance of multibiometric systems even under never-before-seen face and fingerprint presentation attacks, and that the secure fusion rules designed using our approach can exhibit an improved trade-off between the performance in the absence and in the presence of attack. We finally argue that our method can be extended to other biometrics besides faces and fingerprints.



### Microscopic Pedestrian Flow Characteristics: Development of an Image Processing Data Collection and Simulation Model
- **Arxiv ID**: http://arxiv.org/abs/1610.00029v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.00029v1)
- **Published**: 2016-09-06 09:46:23+00:00
- **Updated**: 2016-09-06 09:46:23+00:00
- **Authors**: Kardi Teknomo
- **Comment**: 140 pages, Teknomo, Kardi, Microscopic Pedestrian Flow
  Characteristics: Development of an Image Processing Data Collection and
  Simulation Model, Ph.D. Dissertation, Tohoku University Japan, Sendai, 2002
- **Journal**: None
- **Summary**: Microscopic pedestrian studies consider detailed interaction of pedestrians to control their movement in pedestrian traffic flow. The tools to collect the microscopic data and to analyze microscopic pedestrian flow are still very much in its infancy. The microscopic pedestrian flow characteristics need to be understood. Manual, semi manual and automatic image processing data collection systems were developed. It was found that the microscopic speed resemble a normal distribution with a mean of 1.38 m/second and standard deviation of 0.37 m/second. The acceleration distribution also bear a resemblance to the normal distribution with an average of 0.68 m/ square second. A physical based microscopic pedestrian simulation model was also developed. Both Microscopic Video Data Collection and Microscopic Pedestrian Simulation Model generate a database called NTXY database. The formulations of the flow performance or microscopic pedestrian characteristics are explained. Sensitivity of the simulation and relationship between the flow performances are described. Validation of the simulation using real world data is then explained through the comparison between average instantaneous speed distributions of the real world data with the result of the simulations. The simulation model is then applied for some experiments on a hypothetical situation to gain more understanding of pedestrian behavior in one way and two way situations, to know the behavior of the system if the number of elderly pedestrian increases and to evaluate a policy of lane-like segregation toward pedestrian crossing and inspects the performance of the crossing. It was revealed that the microscopic pedestrian studies have been successfully applied to give more understanding to the behavior of microscopic pedestrians flow, predict the theoretical and practical situation and evaluate some design policies before its implementation.



### Multi-instance Dynamic Ordinal Random Fields for Weakly-Supervised Pain Intensity Estimation
- **Arxiv ID**: http://arxiv.org/abs/1609.01465v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01465v1)
- **Published**: 2016-09-06 10:00:26+00:00
- **Updated**: 2016-09-06 10:00:26+00:00
- **Authors**: Adria Ruiz, Ognjen Rudovic, Xavier Binefa, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we address the Multi-Instance-Learning (MIL) problem when bag labels are naturally represented as ordinal variables (Multi--Instance--Ordinal Regression). Moreover, we consider the case where bags are temporal sequences of ordinal instances. To model this, we propose the novel Multi-Instance Dynamic Ordinal Random Fields (MI-DORF). In this model, we treat instance-labels inside the bag as latent ordinal states. The MIL assumption is modelled by incorporating a high-order cardinality potential relating bag and instance-labels,into the energy function. We show the benefits of the proposed approach on the task of weakly-supervised pain intensity estimation from the UNBC Shoulder-Pain Database. In our experiments, the proposed approach significantly outperforms alternative non-ordinal methods that either ignore the MIL assumption, or do not model dynamic information in target data.



### Joint Alignment of Multiple Point Sets with Batch and Incremental Expectation-Maximization
- **Arxiv ID**: http://arxiv.org/abs/1609.01466v2
- **DOI**: 10.1109/TPAMI.2017.2717829
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01466v2)
- **Published**: 2016-09-06 10:00:46+00:00
- **Updated**: 2017-03-06 10:47:50+00:00
- **Authors**: Georgios Evangelidis, Radu Horaud
- **Comment**: 14 pages, 12 figures, 5 tables
- **Journal**: IEEE Transactions on Pattern Analysis and Machine Intelligence,
  40(6), 1397 - 1410, 2018
- **Summary**: This paper addresses the problem of registering multiple point sets. Solutions to this problem are often approximated by repeatedly solving for pairwise registration, which results in an uneven treatment of the sets forming a pair: a model set and a data set. The main drawback of this strategy is that the model set may contain noise and outliers, which negatively affects the estimation of the registration parameters. In contrast, the proposed formulation treats all the point sets on an equal footing. Indeed, all the points are drawn from a central Gaussian mixture, hence the registration is cast into a clustering problem. We formally derive batch and incremental EM algorithms that robustly estimate both the GMM parameters and the rotations and translations that optimally align the sets. Moreover, the mixture's means play the role of the registered set of points while the variances provide rich information about the contribution of each component to the alignment. We thoroughly test the proposed algorithms on simulated data and on challenging real data collected with range sensors. We compare them with several state-of-the-art algorithms, and we show their potential for surface reconstruction from depth data.



### Comparison of several short-term traffic speed forecasting models
- **Arxiv ID**: http://arxiv.org/abs/1609.02409v1
- **DOI**: None
- **Categories**: **cs.CV**, math.PR, stat.AP, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/1609.02409v1)
- **Published**: 2016-09-06 10:30:37+00:00
- **Updated**: 2016-09-06 10:30:37+00:00
- **Authors**: John Boaz Lee, Kardi Teknomo
- **Comment**: 6 pages, Lee, J. B. and Teknomo, K. (2014) A review of various
  short-term traffic speed forecasting models, Proceeding of the 12th National
  Conference in Information Technology Education (NCITE 2014), October 23 - 25,
  2014, Boracay, Philippines
- **Journal**: None
- **Summary**: The widespread adoption of smartphones in recent years has made it possible for us to collect large amounts of traffic data. Special software installed on the phones of drivers allow us to gather GPS trajectories of their vehicles on the road network. In this paper, we simulate the trajectories of multiple agents on a road network and use various models to forecast the short-term traffic speed of various links. Our results show that traditional techniques like multiple regression and artificial neural networks work well but simpler adaptive models that do not require prior training also perform comparatively well.



### Automation of Pedestrian Tracking in a Crowded Situation
- **Arxiv ID**: http://arxiv.org/abs/1609.01710v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CY, cs.MA
- **Links**: [PDF](http://arxiv.org/pdf/1609.01710v1)
- **Published**: 2016-09-06 10:36:23+00:00
- **Updated**: 2016-09-06 10:36:23+00:00
- **Authors**: Saman Saadat, Kardi Teknomo
- **Comment**: 10 Pages, Saadat, S., and Teknomo, K., Automation of Pedestrian
  Tracking in a Crowded Situation, the Fifth International Conference on
  Pedestrian and Evacuation Dynamics, March 8-10, 2010, National Institute of
  Standards and Technology, Gaithersburg, MD USA
- **Journal**: None
- **Summary**: Studies on microscopic pedestrian requires large amounts of trajectory data from real-world pedestrian crowds. Such data collection, if done manually, needs tremendous effort and is very time consuming. Though many studies have asserted the possibility of automating this task using video cameras, we found that only a few have demonstrated good performance in very crowded situations or from a top-angled view scene. This paper deals with tracking pedestrian crowd under heavy occlusions from an angular scene. Our automated tracking system consists of two modules that perform sequentially. The first module detects moving objects as blobs. The second module is a tracking system. We employ probability distribution from the detection of each pedestrian and use Bayesian update to track the next position. The result of such tracking is a database of pedestrian trajectories over time and space. With certain prior information, we showed that the system can track a large number of people under occlusion and clutter scene.



### Animal Classification System: A Block Based Approach
- **Arxiv ID**: http://arxiv.org/abs/1609.01829v1
- **DOI**: 10.1016/j.procs.2015.03.156
- **Categories**: **cs.CV**, I.4.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1609.01829v1)
- **Published**: 2016-09-06 11:19:41+00:00
- **Updated**: 2016-09-06 11:19:41+00:00
- **Authors**: Y H Sharath Kumar, Manohar N, H K Chethan
- **Comment**: 8 pages, 2 figures, 3 tables
- **Journal**: Procedia Computer Science, Volume 45, 2015, Pages 336-343
- **Summary**: In this work, we propose a method for the classification of animal in images. Initially, a graph cut based method is used to perform segmentation in order to eliminate the background from the given image. The segmented animal images are partitioned in to number of blocks and then the color texture moments are extracted from different blocks. Probabilistic neural network and K-nearest neighbors are considered here for classification. To corroborate the efficacy of the proposed method, an experiment was conducted on our own data set of 25 classes of animals, which consisted of 4000 sample images. The experiment was conducted by picking images randomly from the database to study the effect of classification accuracy, and the results show that the K-nearest neighbors classifier achieves good performance.



### Depth Estimation Through a Generative Model of Light Field Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1609.01499v1
- **DOI**: 10.1007/978-3-319-45886-1_35
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1609.01499v1)
- **Published**: 2016-09-06 11:43:08+00:00
- **Updated**: 2016-09-06 11:43:08+00:00
- **Authors**: Mehdi S. M. Sajjadi, Rolf Köhler, Bernhard Schölkopf, Michael Hirsch
- **Comment**: German Conference on Pattern Recognition (GCPR) 2016
- **Journal**: None
- **Summary**: Light field photography captures rich structural information that may facilitate a number of traditional image processing and computer vision tasks. A crucial ingredient in such endeavors is accurate depth recovery. We present a novel framework that allows the recovery of a high quality continuous depth map from light field data. To this end we propose a generative model of a light field that is fully parametrized by its corresponding depth map. The model allows for the integration of powerful regularization techniques such as a non-local means prior, facilitating accurate depth map estimation.



### Template shape estimation: correcting an asymptotic bias
- **Arxiv ID**: http://arxiv.org/abs/1610.01502v2
- **DOI**: None
- **Categories**: **cs.CV**, math.DG
- **Links**: [PDF](http://arxiv.org/pdf/1610.01502v2)
- **Published**: 2016-09-06 12:45:26+00:00
- **Updated**: 2017-02-02 12:54:28+00:00
- **Authors**: Nina Miolane, Susan Holmes, Xavier Pennec
- **Comment**: None
- **Journal**: None
- **Summary**: We use tools from geometric statistics to analyze the usual estimation procedure of a template shape. This applies to shapes from landmarks, curves, surfaces, images etc. We demonstrate the asymptotic bias of the template shape estimation using the stratified geometry of the shape space. We give a Taylor expansion of the bias with respect to a parameter $\sigma$ describing the measurement error on the data. We propose two bootstrap procedures that quantify the bias and correct it, if needed. They are applicable for any type of shape data. We give a rule of thumb to provide intuition on whether the bias has to be corrected. This exhibits the parameters that control the bias' magnitude. We illustrate our results on simulated and real shape data.



### Confidence-aware Levenberg-Marquardt optimization for joint motion estimation and super-resolution
- **Arxiv ID**: http://arxiv.org/abs/1609.01524v1
- **DOI**: 10.1109/ICIP.2016.7532535
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01524v1)
- **Published**: 2016-09-06 12:54:04+00:00
- **Updated**: 2016-09-06 12:54:04+00:00
- **Authors**: Cosmin Bercea, Andreas Maier, Thomas Köhler
- **Comment**: accepted for ICIP 2016
- **Journal**: 2016 IEEE International Conference on Image Processing (ICIP)
- **Summary**: Motion estimation across low-resolution frames and the reconstruction of high-resolution images are two coupled subproblems of multi-frame super-resolution. This paper introduces a new joint optimization approach for motion estimation and image reconstruction to address this interdependence. Our method is formulated via non-linear least squares optimization and combines two principles of robust super-resolution. First, to enhance the robustness of the joint estimation, we propose a confidence-aware energy minimization framework augmented with sparse regularization. Second, we develop a tailor-made Levenberg-Marquardt iteration scheme to jointly estimate motion parameters and the high-resolution image along with the corresponding model confidence parameters. Our experiments on simulated and real images confirm that the proposed approach outperforms decoupled motion estimation and image reconstruction as well as related state-of-the-art joint estimation algorithms.



### Best-Buddies Similarity - Robust Template Matching using Mutual Nearest Neighbors
- **Arxiv ID**: http://arxiv.org/abs/1609.01571v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01571v1)
- **Published**: 2016-09-06 14:24:36+00:00
- **Updated**: 2016-09-06 14:24:36+00:00
- **Authors**: Shaul Oron, Tali Dekel, Tianfan Xue, William T. Freeman, Shai Avidan
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel method for template matching in unconstrained environments. Its essence is the Best-Buddies Similarity (BBS), a useful, robust, and parameter-free similarity measure between two sets of points. BBS is based on counting the number of Best-Buddies Pairs (BBPs)--pairs of points in source and target sets, where each point is the nearest neighbor of the other. BBS has several key features that make it robust against complex geometric deformations and high levels of outliers, such as those arising from background clutter and occlusions. We study these properties, provide a statistical analysis that justifies them, and demonstrate the consistent success of BBS on a challenging real-world dataset while using different types of features.



### Discriminating image textures with the multiscale two-dimensional complexity-entropy causality plane
- **Arxiv ID**: http://arxiv.org/abs/1609.01625v2
- **DOI**: 10.1016/j.chaos.2016.09.005
- **Categories**: **physics.data-an**, cond-mat.stat-mech, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1609.01625v2)
- **Published**: 2016-09-06 15:57:16+00:00
- **Updated**: 2016-09-07 16:44:47+00:00
- **Authors**: Luciano Zunino, Haroldo V. Ribeiro
- **Comment**: Accepted for publication in Chaos, Solitons & Fractals
- **Journal**: Chaos, Solitons & Fractals 91, 679-688 (2017(
- **Summary**: The aim of this paper is to further explore the usefulness of the two-dimensional complexity-entropy causality plane as a texture image descriptor. A multiscale generalization is introduced in order to distinguish between different roughness features of images at small and large spatial scales. Numerically generated two-dimensional structures are initially considered for illustrating basic concepts in a controlled framework. Then, more realistic situations are studied. Obtained results allow us to confirm that intrinsic spatial correlations of images are successfully unveiled by implementing this multiscale symbolic information-theory approach. Consequently, we conclude that the proposed representation space is a versatile and practical tool for identifying, characterizing and discriminating image textures.



### Review of the Fingerprint Liveness Detection (LivDet) competition series: 2009 to 2015
- **Arxiv ID**: http://arxiv.org/abs/1609.01648v1
- **DOI**: 10.1016/j.imavis.2016.07.002
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01648v1)
- **Published**: 2016-09-06 16:39:37+00:00
- **Updated**: 2016-09-06 16:39:37+00:00
- **Authors**: Luca Ghiani, David A. Yambay, Valerio Mura, Gian Luca Marcialis, Fabio Roli, Stephanie A. Schuckers
- **Comment**: None
- **Journal**: None
- **Summary**: A spoof attack, a subset of presentation attacks, is the use of an artificial replica of a biometric in an attempt to circumvent a biometric sensor. Liveness detection, or presentation attack detection, distinguishes between live and fake biometric traits and is based on the principle that additional information can be garnered above and beyond the data procured by a standard authentication system to determine if a biometric measure is authentic. The goals for the Liveness Detection (LivDet) competitions are to compare software-based fingerprint liveness detection and artifact detection algorithms (Part 1), as well as fingerprint systems which incorporate liveness detection or artifact detection capabilities (Part 2), using a standardized testing protocol and large quantities of spoof and live tests. The competitions are open to all academic and industrial institutions which have a solution for either softwarebased or system-based fingerprint liveness detection. The LivDet competitions have been hosted in 2009, 2011, 2013 and 2015 and have shown themselves to provide a crucial look at the current state of the art in liveness detection schemes. There has been a noticeable increase in the number of participants in LivDet competitions as well as a noticeable decrease in error rates across competitions. Participants have grown from four to the most recent thirteen submissions for Fingerprint Part 1. Fingerprints Part 2 has held steady at two submissions each competition in 2011 and 2013 and only one for the 2015 edition. The continuous increase of competitors demonstrates a growing interest in the topic.



### Improving Color Constancy by Discounting the Variation of Camera Spectral Sensitivity
- **Arxiv ID**: http://arxiv.org/abs/1609.01670v2
- **DOI**: 10.1364/JOSAA.34.001448
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01670v2)
- **Published**: 2016-09-06 17:50:23+00:00
- **Updated**: 2016-11-01 15:33:30+00:00
- **Authors**: Shao-Bing Gao, Ming Zhang, Chao-Yi Li, Yong-Jie Li
- **Comment**: This work was finished in June 2014 and then submitted to IEEE TIP in
  September 21,2015 and in April 18, 2016
- **Journal**: None
- **Summary**: It is an ill-posed problem to recover the true scene colors from a color biased image by discounting the effects of scene illuminant and camera spectral sensitivity (CSS) at the same time. Most color constancy (CC) models have been designed to first estimate the illuminant color, which is then removed from the color biased image to obtain an image taken under white light, without the explicit consideration of CSS effect on CC. This paper first studies the CSS effect on illuminant estimation arising in the inter-dataset-based CC (inter-CC), i.e., training a CC model on one dataset and then testing on another dataset captured by a distinct CSS. We show the clear degradation of existing CC models for inter-CC application. Then a simple way is proposed to overcome such degradation by first learning quickly a transform matrix between the two distinct CSSs (CSS-1 and CSS-2). The learned matrix is then used to convert the data (including the illuminant ground truth and the color biased images) rendered under CSS-1 into CSS-2, and then train and apply the CC model on the color biased images under CSS-2, without the need of burdensome acquiring of training set under CSS-2. Extensive experiments on synthetic and real images show that our method can clearly improve the inter-CC performance for traditional CC algorithms. We suggest that by taking the CSS effect into account, it is more likely to obtain the truly color constant images invariant to the changes of both illuminant and camera sensors.



### Making a Case for Learning Motion Representations with Phase
- **Arxiv ID**: http://arxiv.org/abs/1609.01693v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01693v2)
- **Published**: 2016-09-06 18:47:40+00:00
- **Updated**: 2016-09-08 11:59:03+00:00
- **Authors**: S. L. Pintea, J. C. van Gemert
- **Comment**: ECCV 2016 Workshop on Brave new ideas for motion representations in
  videos
- **Journal**: None
- **Summary**: This work advocates Eulerian motion representation learning over the current standard Lagrangian optical flow model. Eulerian motion is well captured by using phase, as obtained by decomposing the image through a complex-steerable pyramid. We discuss the gain of Eulerian motion in a set of practical use cases: (i) action recognition, (ii) motion prediction in static images, (iii) motion transfer in static images and, (iv) motion transfer in video. For each task we motivate the phase-based direction and provide a possible approach.



### Human pose estimation via Convolutional Part Heatmap Regression
- **Arxiv ID**: http://arxiv.org/abs/1609.01743v1
- **DOI**: 10.1007/978-3-319-46478-7_44
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01743v1)
- **Published**: 2016-09-06 20:25:30+00:00
- **Updated**: 2016-09-06 20:25:30+00:00
- **Authors**: Adrian Bulat, Georgios Tzimiropoulos
- **Comment**: accepted to ECCV 2016
- **Journal**: None
- **Summary**: This paper is on human pose estimation using Convolutional Neural Networks. Our main contribution is a CNN cascaded architecture specifically designed for learning part relationships and spatial context, and robustly inferring pose even for the case of severe part occlusions. To this end, we propose a detection-followed-by-regression CNN cascade. The first part of our cascade outputs part detection heatmaps and the second part performs regression on these heatmaps. The benefits of the proposed architecture are multi-fold: It guides the network where to focus in the image and effectively encodes part constraints and context. More importantly, it can effectively cope with occlusions because part detection heatmaps for occluded parts provide low confidence scores which subsequently guide the regression part of our network to rely on contextual information in order to predict the location of these parts. Additionally, we show that the proposed cascade is flexible enough to readily allow the integration of various CNN architectures for both detection and regression, including recent ones based on residual learning. Finally, we illustrate that our cascade achieves top performance on the MPII and LSP data sets. Code can be downloaded from http://www.cs.nott.ac.uk/~psxab5/



### Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking
- **Arxiv ID**: http://arxiv.org/abs/1609.01775v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.01775v2)
- **Published**: 2016-09-06 21:58:25+00:00
- **Updated**: 2016-09-19 17:27:19+00:00
- **Authors**: Ergys Ristani, Francesco Solera, Roger S. Zou, Rita Cucchiara, Carlo Tomasi
- **Comment**: ECCV 2016 Workshop on Benchmarking Multi-Target Tracking
- **Journal**: None
- **Summary**: To help accelerate progress in multi-target, multi-camera tracking systems, we present (i) a new pair of precision-recall measures of performance that treats errors of all types uniformly and emphasizes correct identification over sources of error; (ii) the largest fully-annotated and calibrated data set to date with more than 2 million frames of 1080p, 60fps video taken by 8 cameras observing more than 2,700 identities over 85 minutes; and (iii) a reference software system as a comparison baseline. We show that (i) our measures properly account for bottom-line identity match performance in the multi-camera setting; (ii) our data set poses realistic challenges to current trackers; and (iii) the performance of our system is comparable to the state of the art.



