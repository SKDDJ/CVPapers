# Arxiv Papers in cs.CV on 2016-09-10
### Simultaneous independent image display technique on multiple 3D objects
- **Arxiv ID**: http://arxiv.org/abs/1609.02994v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1609.02994v1)
- **Published**: 2016-09-10 02:16:51+00:00
- **Updated**: 2016-09-10 02:16:51+00:00
- **Authors**: Takuto Hirukawa, Marco Visentini-Scarzanella, Hiroshi Kawasaki, Ryo Furukawa, Shinsaku Hiura
- **Comment**: Accepted to ACCV 2016
- **Journal**: None
- **Summary**: We propose a new system to visualize depth-dependent patterns and images on solid objects with complex geometry using multiple projectors. The system, despite consisting of conventional passive LCD projectors, is able to project different images and patterns depending on the spatial location of the object. The technique is based on the simple principle that multiple patterns projected from multiple projectors interfere constructively with each other when their patterns are projected on the same object. Previous techniques based on the same principle can only achieve 1) low resolution volume colorization or 2) high resolution images but only on a limited number of flat planes. In this paper, we discretize a 3D object into a number of 3D points so that high resolution images can be projected onto the complex shapes. We also propose a dynamic ranges expansion technique as well as an efficient optimization procedure based on epipolar constraints.   Such technique can be used to the extend projection mapping to have spatial dependency, which is desirable for practical applications. We also demonstrate the system potential as a visual instructor for object placement and assembling. Experiments prove the effectiveness of our method.



### Rectifier Neural Network with a Dual-Pathway Architecture for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1609.03024v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03024v3)
- **Published**: 2016-09-10 10:18:30+00:00
- **Updated**: 2020-12-09 15:11:00+00:00
- **Authors**: Keting Zhang, Liqing Zhang
- **Comment**: 5 pages, 6 figures
- **Journal**: None
- **Summary**: Recently deep neural networks based on tanh activation function have shown their impressive power in image denoising. In this letter, we try to use rectifier function instead of tanh and propose a dual-pathway rectifier neural network by combining two rectifier neurons with reversed input and output weights in the same hidden layer. We drive the equivalent activation function and compare it to some typical activation functions for image denoising under the same network architecture. The experimental results show that our model achieves superior performances faster especially when the noise is small.



### Sequential Deep Trajectory Descriptor for Action Recognition with Three-stream CNN
- **Arxiv ID**: http://arxiv.org/abs/1609.03056v2
- **DOI**: 10.1109/TMM.2017.2666540
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03056v2)
- **Published**: 2016-09-10 14:24:38+00:00
- **Updated**: 2017-02-10 02:49:10+00:00
- **Authors**: Yemin Shi, Yonghong Tian, Yaowei Wang, Tiejun Huang
- **Comment**: 10 pages, 29 figures, T-MM
- **Journal**: None
- **Summary**: Learning the spatial-temporal representation of motion information is crucial to human action recognition. Nevertheless, most of the existing features or descriptors cannot capture motion information effectively, especially for long-term motion. To address this problem, this paper proposes a long-term motion descriptor called sequential Deep Trajectory Descriptor (sDTD). Specifically, we project dense trajectories into two-dimensional planes, and subsequently a CNN-RNN network is employed to learn an effective representation for long-term motion. Unlike the popular two-stream ConvNets, the sDTD stream is introduced into a three-stream framework so as to identify actions from a video sequence. Consequently, this three-stream framework can simultaneously capture static spatial features, short-term motion and long-term motion in the video. Extensive experiments were conducted on three challenging datasets: KTH, HMDB51 and UCF101. Experimental results show that our method achieves state-of-the-art performance on the KTH and UCF101 datasets, and is comparable to the state-of-the-art methods on the HMDB51 dataset.



### Style-Transfer via Texture-Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1609.03057v3
- **DOI**: 10.1109/TIP.2017.2678168
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03057v3)
- **Published**: 2016-09-10 14:26:48+00:00
- **Updated**: 2016-09-20 05:41:08+00:00
- **Authors**: Michael Elad, Peyman Milanfar
- **Comment**: None
- **Journal**: None
- **Summary**: Style-transfer is a process of migrating a style from a given image to the content of another, synthesizing a new image which is an artistic mixture of the two. Recent work on this problem adopting Convolutional Neural-networks (CNN) ignited a renewed interest in this field, due to the very impressive results obtained. There exists an alternative path towards handling the style-transfer task, via generalization of texture-synthesis algorithms. This approach has been proposed over the years, but its results are typically less impressive compared to the CNN ones.   In this work we propose a novel style-transfer algorithm that extends the texture-synthesis work of Kwatra et. al. (2005), while aiming to get stylized images that get closer in quality to the CNN ones. We modify Kwatra's algorithm in several key ways in order to achieve the desired transfer, with emphasis on a consistent way for keeping the content intact in selected regions, while producing hallucinated and rich style in others. The results obtained are visually pleasing and diverse, shown to be competitive with the recent CNN style-transfer algorithms. The proposed algorithm is fast and flexible, being able to process any pair of content + style images.



### A Tube-and-Droplet-based Approach for Representing and Analyzing Motion Trajectories
- **Arxiv ID**: http://arxiv.org/abs/1609.03058v2
- **DOI**: 10.1109/TPAMI.2016.2608884
- **Categories**: **cs.CV**, cs.AI, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1609.03058v2)
- **Published**: 2016-09-10 14:33:06+00:00
- **Updated**: 2017-04-26 12:17:26+00:00
- **Authors**: Weiyao Lin, Yang Zhou, Hongteng Xu, Junchi Yan, Mingliang Xu, Jianxin Wu, Zicheng Liu
- **Comment**: IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI:
  10.1109/TPAMI.2016.2608884, 2016. Code for our work is available at
  http://min.sjtu.edu.cn/lwydemo/Trajectory%20analysis.htm
- **Journal**: None
- **Summary**: Trajectory analysis is essential in many applications. In this paper, we address the problem of representing motion trajectories in a highly informative way, and consequently utilize it for analyzing trajectories. Our approach first leverages the complete information from given trajectories to construct a thermal transfer field which provides a context-rich way to describe the global motion pattern in a scene. Then, a 3D tube is derived which depicts an input trajectory by integrating its surrounding motion patterns contained in the thermal transfer field. The 3D tube effectively: 1) maintains the movement information of a trajectory, 2) embeds the complete contextual motion pattern around a trajectory, 3) visualizes information about a trajectory in a clear and unified way. We further introduce a droplet-based process. It derives a droplet vector from a 3D tube, so as to characterize the high-dimensional 3D tube information in a simple but effective way. Finally, we apply our tube-and-droplet representation to trajectory analysis applications including trajectory clustering, trajectory classification & abnormality detection, and 3D action recognition. Experimental comparisons with state-of-the-art algorithms demonstrate the effectiveness of our approach.



### A Perspective on Deep Imaging
- **Arxiv ID**: http://arxiv.org/abs/1609.04375v2
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1609.04375v2)
- **Published**: 2016-09-10 15:45:48+00:00
- **Updated**: 2016-11-04 13:02:27+00:00
- **Authors**: Ge Wang
- **Comment**: 9 pages, 10 figures, 49 references, and accepted by IEEE Access
- **Journal**: None
- **Summary**: The combination of tomographic imaging and deep learning, or machine learning in general, promises to empower not only image analysis but also image reconstruction. The latter aspect is considered in this perspective article with an emphasis on medical imaging to develop a new generation of image reconstruction theories and techniques. This direction might lead to intelligent utilization of domain knowledge from big data, innovative approaches for image reconstruction, and superior performance in clinical and preclinical applications. To realize the full impact of machine learning on medical imaging, major challenges must be addressed.



### Using Spatial Pooler of Hierarchical Temporal Memory to classify noisy videos with predefined complexity
- **Arxiv ID**: http://arxiv.org/abs/1609.03093v2
- **DOI**: 10.1016/j.neucom.2017.02.046
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.03093v2)
- **Published**: 2016-09-10 21:51:54+00:00
- **Updated**: 2016-12-27 11:13:40+00:00
- **Authors**: Maciej Wielgosz, Marcin Pietro≈Ñ
- **Comment**: submitted to Neurocomputing; paper similar to arXiv:1608.01966
- **Journal**: Neurocomputing 240 (2017), 84-97
- **Summary**: This paper examines the performance of a Spatial Pooler (SP) of a Hierarchical Temporal Memory (HTM) in the task of noisy object recognition. To address this challenge, a dedicated custom-designed system based on the SP, histogram calculation module and SVM classifier was implemented. In addition to implementing their own version of HTM, the authors also designed a profiler which is capable of tracing all of the key parameters of the system. This was necessary, since an analysis and monitoring of the system performance turned out to be extremely difficult using conventional testing and debugging tools. The system was initially trained on artificially prepared videos without noise and then tested with a set of noisy video streams. This approach was intended to mimic a real life scenario where an agent or a system trained to deal with ideal objects faces a task of classifying distorted and noisy ones in its regular working conditions. The authors conducted a series of experiments for various macro parameters of HTM SP, as well as for different levels of video reduction ratios. The experiments allowed them to evaluate the performance of two different system setups (i.e. 'Multiple HTMs' and 'Single HTM') under various noise conditions with 32--frame video files. Results of all the tests were compared to SVM baseline setup. It was determined that the system featuring SP is capable of achieving approximately 12 times the noise reduction for a video signal with with distorted bits accounting for 13\% of the total. Furthermore, the system featuring SP performed better also in the experiments without a noise component and achieved a max F1 score of 0.96. The experiments also revealed that a rise of column and synapse number of SP has a substantial impact on the performance of the system. Consequently, the highest F1 score values were obtained for 256 and 4096 synapses and columns respectively.



