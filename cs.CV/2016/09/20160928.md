# Arxiv Papers in cs.CV on 2016-09-28
### Improved phase-unwrapping method using geometric constraints
- **Arxiv ID**: http://arxiv.org/abs/1610.04261v1
- **DOI**: 10.1080/09500340.2017.1284279
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1610.04261v1)
- **Published**: 2016-09-28 01:52:13+00:00
- **Updated**: 2016-09-28 01:52:13+00:00
- **Authors**: Guangliang Du, Minmin Wang, Canlin Zhou, Shuchun Si, Hui Li, Zhenkun Lei, Yanjie Li
- **Comment**: 15 pages, 11 figures
- **Journal**: None
- **Summary**: Conventional dual-frequency fringe projection algorithm often suffers from phase unwrapping failure when the frequency ratio between the high frequency and the low one is too large. Zhang et.al. proposed an enhanced two-frequency phase-shifting method to use geometric constraints of digital fringe projection(DFP) to reduce the noise impact due to the large frequency ratio. However, this method needs to calibrate the DFP system and calculate the minimum phase map at the nearest position from the camera perspective, these procedures are are relatively complex and more time-cosuming. In this paper, we proposed an improved method, which eliminates the system calibration and determination in Zhang's method,meanwhile does not need to use the low frequency fringe pattern. In the proposed method,we only need a set of high frequency fringe patterns to measure the object after the high frequency is directly estimated by the experiment. Thus the proposed method can simplify the procedure and improve the speed. Finally, the experimental evaluation is conducted to prove the validity of the proposed method.The results demonstrate that the proposed method can overcome the main disadvantages encountered by Zhang's method.



### Scalable Discrete Supervised Hash Learning with Asymmetric Matrix Factorization
- **Arxiv ID**: http://arxiv.org/abs/1609.08740v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08740v1)
- **Published**: 2016-09-28 02:37:23+00:00
- **Updated**: 2016-09-28 02:37:23+00:00
- **Authors**: Shifeng Zhang, Jianmin Li, Jinma Guo, Bo Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Hashing method maps similar data to binary hashcodes with smaller hamming distance, and it has received a broad attention due to its low storage cost and fast retrieval speed. However, the existing limitations make the present algorithms difficult to deal with large-scale datasets: (1) discrete constraints are involved in the learning of the hash function; (2) pairwise or triplet similarity is adopted to generate efficient hashcodes, resulting both time and space complexity are greater than O(n^2). To address these issues, we propose a novel discrete supervised hash learning framework which can be scalable to large-scale datasets. First, the discrete learning procedure is decomposed into a binary classifier learning scheme and binary codes learning scheme, which makes the learning procedure more efficient. Second, we adopt the Asymmetric Low-rank Matrix Factorization and propose the Fast Clustering-based Batch Coordinate Descent method, such that the time and space complexity is reduced to O(n). The proposed framework also provides a flexible paradigm to incorporate with arbitrary hash function, including deep neural networks and kernel methods. Experiments on large-scale datasets demonstrate that the proposed method is superior or comparable with state-of-the-art hashing algorithms.



### Video Summarization using Deep Semantic Features
- **Arxiv ID**: http://arxiv.org/abs/1609.08758v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08758v1)
- **Published**: 2016-09-28 03:41:49+00:00
- **Updated**: 2016-09-28 03:41:49+00:00
- **Authors**: Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkil√§, Naokazu Yokoya
- **Comment**: 16 pages, the 13th Asian Conference on Computer Vision (ACCV'16)
- **Journal**: None
- **Summary**: This paper presents a video summarization technique for an Internet video to provide a quick way to overview its content. This is a challenging problem because finding important or informative parts of the original video requires to understand its content. Furthermore the content of Internet videos is very diverse, ranging from home videos to documentaries, which makes video summarization much more tough as prior knowledge is almost not available. To tackle this problem, we propose to use deep video features that can encode various levels of content semantics, including objects, actions, and scenes, improving the efficiency of standard video summarization techniques. For this, we design a deep neural network that maps videos as well as descriptions to a common semantic space and jointly trained it with associated pairs of videos and descriptions. To generate a video summary, we extract the deep features from each segment of the original video and apply a clustering-based summarization technique to them. We evaluate our video summaries using the SumMe dataset as well as baseline approaches. The results demonstrated the advantages of incorporating our deep semantic features in a video summarization technique.



### Understanding data augmentation for classification: when to warp?
- **Arxiv ID**: http://arxiv.org/abs/1609.08764v2
- **DOI**: None
- **Categories**: **cs.CV**, I.5.2; I.4.7
- **Links**: [PDF](http://arxiv.org/pdf/1609.08764v2)
- **Published**: 2016-09-28 04:37:32+00:00
- **Updated**: 2016-11-26 11:08:19+00:00
- **Authors**: Sebastien C. Wong, Adam Gatt, Victor Stamatescu, Mark D. McDonnell
- **Comment**: 6 pages, 6 figures, DICTA 2016 conference
- **Journal**: None
- **Summary**: In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.



### Towards the effectiveness of Deep Convolutional Neural Network based Fast Random Forest Classifier
- **Arxiv ID**: http://arxiv.org/abs/1609.08864v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08864v1)
- **Published**: 2016-09-28 11:35:17+00:00
- **Updated**: 2016-09-28 11:35:17+00:00
- **Authors**: Mrutyunjaya Panda
- **Comment**: 11 pages, 9 figures, 1 table
- **Journal**: None
- **Summary**: Deep Learning is considered to be a quite young in the area of machine learning research, found its effectiveness in dealing complex yet high dimensional dataset that includes but limited to images, text and speech etc. with multiple levels of representation and abstraction. As there are a plethora of research on these datasets by various researchers , a win over them needs lots of attention. Careful setting of Deep learning parameters is of paramount importance in order to avoid the overfitting unlike conventional methods with limited parameter settings. Deep Convolutional neural network (DCNN) with multiple layers of compositions and appropriate settings might be is an efficient machine learning method that can outperform the conventional methods in a great way. However, due to its slow adoption in learning, there are also always a chance of overfitting during feature selection process, which can be addressed by employing a regularization method called dropout. Fast Random Forest (FRF) is a powerful ensemble classifier especially when the datasets are noisy and when the number of attributes is large in comparison to the number of instances, as is the case of Bioinformatics datasets. Several publicly available Bioinformatics dataset, Handwritten digits recognition and Image segmentation dataset are considered for evaluation of the proposed approach. The excellent performance obtained by the proposed DCNN based feature selection with FRF classifier on high dimensional datasets makes it a fast and accurate classifier in comparison the state-of-the-art.



### A Discriminative Framework for Anomaly Detection in Large Videos
- **Arxiv ID**: http://arxiv.org/abs/1609.08938v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1609.08938v1)
- **Published**: 2016-09-28 14:48:32+00:00
- **Updated**: 2016-09-28 14:48:32+00:00
- **Authors**: Allison Del Giorno, J. Andrew Bagnell, Martial Hebert
- **Comment**: 14 pages without references, 16 pages with. 7 figures. Accepted to
  ECCV 2016
- **Journal**: None
- **Summary**: We address an anomaly detection setting in which training sequences are unavailable and anomalies are scored independently of temporal ordering. Current algorithms in anomaly detection are based on the classical density estimation approach of learning high-dimensional models and finding low-probability events. These algorithms are sensitive to the order in which anomalies appear and require either training data or early context assumptions that do not hold for longer, more complex videos. By defining anomalies as examples that can be distinguished from other examples in the same video, our definition inspires a shift in approaches from classical density estimation to simple discriminative learning. Our contributions include a novel framework for anomaly detection that is (1) independent of temporal ordering of anomalies, and (2) unsupervised, requiring no separate training sequences. We show that our algorithm can achieve state-of-the-art results even when we adjust the setting by removing training sequences from standard datasets.



### Graph Based Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1609.08965v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08965v1)
- **Published**: 2016-09-28 15:32:59+00:00
- **Updated**: 2016-09-28 15:32:59+00:00
- **Authors**: Michael Edwards, Xianghua Xie
- **Comment**: 11 pages, accepted into BMVC 2016
- **Journal**: None
- **Summary**: The benefit of localized features within the regular domain has given rise to the use of Convolutional Neural Networks (CNNs) in machine learning, with great proficiency in the image classification. The use of CNNs becomes problematic within the irregular spatial domain due to design and convolution of a kernel filter being non-trivial. One solution to this problem is to utilize graph signal processing techniques and the convolution theorem to perform convolutions on the graph of the irregular domain to obtain feature map responses to learnt filters. We propose graph convolution and pooling operators analogous to those in the regular domain. We also provide gradient calculations on the input data and spectral filters, which allow for the deep learning of an irregular spatial domain problem. Signal filters take the form of spectral multipliers, applying convolution in the graph spectral domain. Applying smooth multipliers results in localized convolutions in the spatial domain, with smoother multipliers providing sharper feature maps. Algebraic Multigrid is presented as a graph pooling method, reducing the resolution of the graph through agglomeration of nodes between layers of the network. Evaluation of performance on the MNIST digit classification problem in both the regular and irregular domain is presented, with comparison drawn to standard CNN. The proposed graph CNN provides a deep learning method for the irregular domains present in the machine learning community, obtaining 94.23% on the regular grid, and 94.96% on a spatially irregular subsampled MNIST.



### Deep Architectures for Face Attributes
- **Arxiv ID**: http://arxiv.org/abs/1609.09018v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.09018v1)
- **Published**: 2016-09-28 17:57:46+00:00
- **Updated**: 2016-09-28 17:57:46+00:00
- **Authors**: Tobi Baumgartner, Jack Culpepper
- **Comment**: 11 pages, 2 figures, accepted in "Workshop on Facial Informatics in
  conjunction with ACCV '16"
- **Journal**: None
- **Summary**: We train a deep convolutional neural network to perform identity classification using a new dataset of public figures annotated with age, gender, ethnicity and emotion labels, and then fine-tune it for attribute classification. An optimal sharing pattern of computational resources within this network is determined by experiment, requiring only 1 G flops to produce all predictions. Rather than fine-tune by relearning weights in one additional layer after the penultimate layer of the identity network, we try several different depths for each attribute. We find that prediction of age and emotion is improved by fine-tuning from earlier layers onward, presumably because deeper layers are progressively invariant to non-identity related changes in the input.



### Learning to Push by Grasping: Using multiple tasks for effective learning
- **Arxiv ID**: http://arxiv.org/abs/1609.09025v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1609.09025v1)
- **Published**: 2016-09-28 18:13:02+00:00
- **Updated**: 2016-09-28 18:13:02+00:00
- **Authors**: Lerrel Pinto, Abhinav Gupta
- **Comment**: Under review at the International Conference on Robotics and
  Automation (ICRA) 2017
- **Journal**: None
- **Summary**: Recently, end-to-end learning frameworks are gaining prevalence in the field of robot control. These frameworks input states/images and directly predict the torques or the action parameters. However, these approaches are often critiqued due to their huge data requirements for learning a task. The argument of the difficulty in scalability to multiple tasks is well founded, since training these tasks often require hundreds or thousands of examples. But do end-to-end approaches need to learn a unique model for every task? Intuitively, it seems that sharing across tasks should help since all tasks require some common understanding of the environment. In this paper, we attempt to take the next step in data-driven end-to-end learning frameworks: move from the realm of task-specific models to joint learning of multiple robot tasks. In an astonishing result we show that models with multi-task learning tend to perform better than task-specific models trained with same amounts of data. For example, a deep-network learned with 2.5K grasp and 2.5K push examples performs better on grasping than a network trained on 5K grasp examples.



### A Simple, Fast and Highly-Accurate Algorithm to Recover 3D Shape from 2D Landmarks on a Single Image
- **Arxiv ID**: http://arxiv.org/abs/1609.09058v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.09058v1)
- **Published**: 2016-09-28 19:58:37+00:00
- **Updated**: 2016-09-28 19:58:37+00:00
- **Authors**: Ruiqi Zhao, Yan Wang, Aleix Martinez
- **Comment**: None
- **Journal**: None
- **Summary**: Three-dimensional shape reconstruction of 2D landmark points on a single image is a hallmark of human vision, but is a task that has been proven difficult for computer vision algorithms. We define a feed-forward deep neural network algorithm that can reconstruct 3D shapes from 2D landmark points almost perfectly (i.e., with extremely small reconstruction errors), even when these 2D landmarks are from a single image. Our experimental results show an improvement of up to two-fold over state-of-the-art computer vision algorithms; 3D shape reconstruction of human faces is given at a reconstruction error < .004, cars at .0022, human bodies at .022, and highly-deformable flags at an error of .0004. Our algorithm was also a top performer at the 2016 3D Face Alignment in the Wild Challenge competition (done in conjunction with the European Conference on Computer Vision, ECCV) that required the reconstruction of 3D face shape from a single image. The derived algorithm can be trained in a couple hours and testing runs at more than 1, 000 frames/s on an i7 desktop. We also present an innovative data augmentation approach that allows us to train the system efficiently with small number of samples. And the system is robust to noise (e.g., imprecise landmark points) and missing data (e.g., occluded or undetected landmark points).



### Recurrent Convolutional Networks for Pulmonary Nodule Detection in CT Imaging
- **Arxiv ID**: http://arxiv.org/abs/1609.09143v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1609.09143v2)
- **Published**: 2016-09-28 22:32:24+00:00
- **Updated**: 2016-09-30 12:30:14+00:00
- **Authors**: Petros-Pavlos Ypsilantis, Giovanni Montana
- **Comment**: None
- **Journal**: None
- **Summary**: Computed tomography (CT) generates a stack of cross-sectional images covering a region of the body. The visual assessment of these images for the identification of potential abnormalities is a challenging and time consuming task due to the large amount of information that needs to be processed. In this article we propose a deep artificial neural network architecture, ReCTnet, for the fully-automated detection of pulmonary nodules in CT scans. The architecture learns to distinguish nodules and normal structures at the pixel level and generates three-dimensional probability maps highlighting areas that are likely to harbour the objects of interest. Convolutional and recurrent layers are combined to learn expressive image representations exploiting the spatial dependencies across axial slices. We demonstrate that leveraging intra-slice dependencies substantially increases the sensitivity to detect pulmonary nodules without inflating the false positive rate. On the publicly available LIDC/IDRI dataset consisting of 1,018 annotated CT scans, ReCTnet reaches a detection sensitivity of 90.5% with an average of 4.5 false positives per scan. Comparisons with a competing multi-channel convolutional neural network for multi-slice segmentation and other published methodologies using the same dataset provide evidence that ReCTnet offers significant performance gains.



### Similarity Mapping with Enhanced Siamese Network for Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1609.09156v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1609.09156v2)
- **Published**: 2016-09-28 23:52:50+00:00
- **Updated**: 2017-01-24 00:51:57+00:00
- **Authors**: Minyoung Kim, Stefano Alletto, Luca Rigazio
- **Comment**: 1) accepted as a poster presentation at WiML (Women in Machine
  Learning) workshop 2016, colocated with NIPS 2016 in Barcelona, Spain, 2)
  accepted as a poster presentation at MLITS (Machine Learning for Intelligent
  Transportation Systems) Workshop held in conjunction with the NIPS 2016 in
  Barcelona, Spain
- **Journal**: None
- **Summary**: Multi-object tracking has recently become an important area of computer vision, especially for Advanced Driver Assistance Systems (ADAS). Despite growing attention, achieving high performance tracking is still challenging, with state-of-the- art systems resulting in high complexity with a large number of hyper parameters. In this paper, we focus on reducing overall system complexity and the number hyper parameters that need to be tuned to a specific environment. We introduce a novel tracking system based on similarity mapping by Enhanced Siamese Neural Network (ESNN), which accounts for both appearance and geometric information, and is trainable end-to-end. Our system achieves competitive performance in both speed and accuracy on MOT16 challenge, compared to known state-of-the-art methods.



