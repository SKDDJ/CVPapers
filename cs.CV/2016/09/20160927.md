# Arxiv Papers in cs.CV on 2016-09-27
### De-noising, Stabilizing and Completing 3D Reconstructions On-the-go using Plane Priors
- **Arxiv ID**: http://arxiv.org/abs/1609.08267v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08267v2)
- **Published**: 2016-09-27 05:59:12+00:00
- **Updated**: 2017-03-28 01:45:24+00:00
- **Authors**: Maksym Dzitsiuk, Jürgen Sturm, Robert Maier, Lingni Ma, Daniel Cremers
- **Comment**: None
- **Journal**: None
- **Summary**: Creating 3D maps on robots and other mobile devices has become a reality in recent years. Online 3D reconstruction enables many exciting applications in robotics and AR/VR gaming. However, the reconstructions are noisy and generally incomplete. Moreover, during onine reconstruction, the surface changes with every newly integrated depth image which poses a significant challenge for physics engines and path planning algorithms. This paper presents a novel, fast and robust method for obtaining and using information about planar surfaces, such as walls, floors, and ceilings as a stage in 3D reconstruction based on Signed Distance Fields. Our algorithm recovers clean and accurate surfaces, reduces the movement of individual mesh vertices caused by noise during online reconstruction and fills in the occluded and unobserved regions. We implemented and evaluated two different strategies to generate plane candidates and two strategies for merging them. Our implementation is optimized to run in real-time on mobile devices such as the Tango tablet. In an extensive set of experiments, we validated that our approach works well in a large number of natural environments despite the presence of significant amount of occlusion, clutter and noise, which occur frequently. We further show that plane fitting enables in many cases a meaningful semantic segmentation of real-world scenes.



### Image Retrieval with Fisher Vectors of Binary Features
- **Arxiv ID**: http://arxiv.org/abs/1609.08291v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08291v1)
- **Published**: 2016-09-27 07:33:58+00:00
- **Updated**: 2016-09-27 07:33:58+00:00
- **Authors**: Yusuke Uchida, Shigeyuki Sakazawa, Shin'ichi Satoh
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, the Fisher vector representation of local features has attracted much attention because of its effectiveness in both image classification and image retrieval. Another trend in the area of image retrieval is the use of binary features such as ORB, FREAK, and BRISK. Considering the significant performance improvement for accuracy in both image classification and retrieval by the Fisher vector of continuous feature descriptors, if the Fisher vector were also to be applied to binary features, we would receive similar benefits in binary feature based image retrieval and classification. In this paper, we derive the closed-form approximation of the Fisher vector of binary features modeled by the Bernoulli mixture model. We also propose accelerating the Fisher vector by using the approximate value of posterior probability. Experiments show that the Fisher vector representation significantly improves the accuracy of image retrieval compared with a bag of binary words approach.



### Automated Breast Lesion Segmentation in Ultrasound Images
- **Arxiv ID**: http://arxiv.org/abs/1609.08364v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08364v1)
- **Published**: 2016-09-27 11:51:16+00:00
- **Updated**: 2016-09-27 11:51:16+00:00
- **Authors**: Ibrahim Sadek, Mohamed Elawady, Viktor Stefanovski
- **Comment**: Course Work in 'Medical Image Analysis' Module, VIBOT 2013
- **Journal**: None
- **Summary**: The main objective of this project is to segment different breast ultrasound images to find out lesion area by discarding the low contrast regions as well as the inherent speckle noise. The proposed method consists of three stages (removing noise, segmentation, classification) in order to extract the correct lesion. We used normalized cuts approach to segment ultrasound images into regions of interest where we can possibly finds the lesion, and then K-means classifier is applied to decide finally the location of the lesion. For every original image, an annotated ground-truth image is given to perform comparison with the obtained experimental results, providing accurate evaluation measures.



### Tensor Based Second Order Variational Model for Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1609.08387v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08387v1)
- **Published**: 2016-09-27 12:51:09+00:00
- **Updated**: 2016-09-27 12:51:09+00:00
- **Authors**: Jinming Duan, Wil OC Ward, Luke Sibbett, Zhenkuan Pan, Li Bai
- **Comment**: None
- **Journal**: None
- **Summary**: Second order total variation (SOTV) models have advantages for image reconstruction over their first order counterparts including their ability to remove the staircase artefact in the reconstructed image, but they tend to blur the reconstructed image. To overcome this drawback, we introduce a new Tensor Weighted Second Order (TWSO) model for image reconstruction. Specifically, we develop a novel regulariser for the SOTV model that uses the Frobenius norm of the product of the SOTV Hessian matrix and the anisotropic tensor. We then adapt the alternating direction method of multipliers (ADMM) to solve the proposed model by breaking down the original problem into several subproblems. All the subproblems have closed-forms and can thus be solved efficiently. The proposed method is compared with a range of state-of-the-art approaches such as tensor-based anisotropic diffusion, total generalised variation, Euler's elastica, etc. Numerical experimental results of the method on both synthetic and real images from the Berkeley database BSDS500 demonstrate that the proposed method eliminates both the staircase and blurring effects and outperforms the existing approaches for image inpainting and denoising applications.



### Semi Automatic Color Segmentation of Document Pages
- **Arxiv ID**: http://arxiv.org/abs/1609.08393v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08393v1)
- **Published**: 2016-09-27 13:04:44+00:00
- **Updated**: 2016-09-27 13:04:44+00:00
- **Authors**: Stéphane Bres, Véronique Eglin, Vincent Poulain
- **Comment**: None
- **Journal**: International Workshop on Document Analysis System, Apr 2016,
  Santorini, France
- **Summary**: -This paper presents a semi automatic method used to segment color documents into different uniform color plans. The practical application is dedicated to administrative documents segmentation. In these documents, like in many other cases, color has a semantic meaning: it is then possible to identify some specific regions like manual annotations, rubber stamps or colored highlighting. A first step of user-controlled learning of the desired color plans is made on few sample documents. An automatic process can then be performed on the much bigger set as a batch. Our experiments show very interesting results in with a very competitive processing time.



### House price estimation from visual and textual features
- **Arxiv ID**: http://arxiv.org/abs/1609.08399v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08399v1)
- **Published**: 2016-09-27 13:15:31+00:00
- **Updated**: 2016-09-27 13:15:31+00:00
- **Authors**: Eman Ahmed, Mohamed Moustafa
- **Comment**: NCTA 2016. Final paper is on SCITEPRESS digital library
- **Journal**: None
- **Summary**: Most existing automatic house price estimation systems rely only on some textual data like its neighborhood area and the number of rooms. The final price is estimated by a human agent who visits the house and assesses it visually. In this paper, we propose extracting visual features from house photographs and combining them with the house's textual information. The combined features are fed to a fully connected multilayer Neural Network (NN) that estimates the house price as its single output. To train and evaluate our network, we have collected the first houses dataset (to our knowledge) that combines both images and textual attributes. The dataset is composed of 535 sample houses from the state of California, USA. Our experiments showed that adding the visual features increased the R-value by a factor of 3 and decreased the Mean Square Error (MSE) by one order of magnitude compared with textual-only features. Additionally, when trained on the benchmark textual-only features housing dataset, our proposed NN still outperformed the existing model published results.



### Learning convolutional neural network to maximize Pos@Top performance measure
- **Arxiv ID**: http://arxiv.org/abs/1609.08417v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08417v3)
- **Published**: 2016-09-27 13:27:40+00:00
- **Updated**: 2017-03-01 02:55:45+00:00
- **Authors**: Yanyan Geng, Ru-Ze Liang, Weizhi Li, Jingbin Wang, Gaoyuan Liang, Chenhao Xu, Jing-Yan Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In the machine learning problems, the performance measure is used to evaluate the machine learning models. Recently, the number positive data points ranked at the top positions (Pos@Top) has been a popular performance measure in the machine learning community. In this paper, we propose to learn a convolutional neural network (CNN) model to maximize the Pos@Top performance measure. The CNN model is used to represent the multi-instance data point, and a classifier function is used to predict the label from the its CNN representation. We propose to minimize the loss function of Pos@Top over a training set to learn the filters of CNN and the classifier parameter. The classifier parameter vector is solved by the Lagrange multiplier method, and the filters are updated by the gradient descent method alternately in an iterative algorithm. Experiments over benchmark data sets show that the proposed method outperforms the state-of-the-art Pos@Top maximization methods.



### Non-flat Ground Detection Based on A Local Descriptor
- **Arxiv ID**: http://arxiv.org/abs/1609.08436v9
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08436v9)
- **Published**: 2016-09-27 13:41:04+00:00
- **Updated**: 2018-06-06 00:54:05+00:00
- **Authors**: Kangru Wang, Lei Qu, Lili Chen, Yuzhang Gu, DongChen zhu, Xiaolin Zhang
- **Comment**: 9 pages, submitted to IEICE Transactions on Information and Systems
- **Journal**: None
- **Summary**: The detection of road and free space remains challenging for non-flat plane, especially with the varying latitudinal and longitudinal slope or in the case of multi-ground plane. In this paper, we propose a framework of the ground plane detection with stereo vision. The main contribution of this paper is a newly proposed descriptor which is implemented in the disparity image to obtain a disparity texture image. The ground plane regions can be distinguished from their surroundings effectively in the disparity texture image. Because the descriptor is implemented in the local area of the image, it can address well the problem of non-flat plane. And we also present a complete framework to detect the ground plane regions base on the disparity texture image with convolutional neural network architecture.



### Flows Generating Nonlinear Eigenfunctions
- **Arxiv ID**: http://arxiv.org/abs/1609.08438v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1609.08438v1)
- **Published**: 2016-09-27 13:42:13+00:00
- **Updated**: 2016-09-27 13:42:13+00:00
- **Authors**: Raz Z. Nossek, Guy Gilboa
- **Comment**: None
- **Journal**: None
- **Summary**: Nonlinear variational methods have become very powerful tools for many image processing tasks. Recently a new line of research has emerged, dealing with nonlinear eigenfunctions induced by convex functionals. This has provided new insights and better theoretical understanding of convex regularization and introduced new processing methods. However, the theory of nonlinear eigenvalue problems is still at its infancy. We present a new flow that can generate nonlinear eigenfunctions of the form $T(u)=\lambda u$, where $T(u)$ is a nonlinear operator and $\lambda \in \mathbb{R} $ is the eigenvalue. We develop the theory where $T(u)$ is a subgradient element of a regularizing one-homogeneous functional, such as total-variation (TV) or total-generalized-variation (TGV). We introduce two flows: a forward flow and an inverse flow; for which the steady state solution is a nonlinear eigenfunction. The forward flow monotonically smooths the solution (with respect to the regularizer) and simultaneously increases the $L^2$ norm. The inverse flow has the opposite characteristics. For both flows, the steady state depends on the initial condition, thus different initial conditions yield different eigenfunctions. This enables a deeper investigation into the space of nonlinear eigenfunctions, allowing to produce numerically diverse examples, which may be unknown yet. In addition we suggest an indicator to measure the affinity of a function to an eigenfunction and relate it to pseudo-eigenfunctions in the linear case.



### Blind Facial Image Quality Enhancement using Non-Rigid Semantic Patches
- **Arxiv ID**: http://arxiv.org/abs/1609.08475v2
- **DOI**: 10.1109/TIP.2017.2686003
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08475v2)
- **Published**: 2016-09-27 14:29:33+00:00
- **Updated**: 2017-04-30 07:39:56+00:00
- **Authors**: Ester Hait, Guy Gilboa
- **Comment**: Please see the updated published version: Hait, Ester, and Guy
  Gilboa. Blind Facial Image Quality Enhancement using Non-Rigid Semantic
  Patches. IEEE Transactions on Image Processing 26.6 (2017): 2705
- **Journal**: None
- **Summary**: We propose to combine semantic data and registration algorithms to solve various image processing problems such as denoising, super-resolution and color-correction. It is shown how such new techniques can achieve significant quality enhancement, both visually and quantitatively, in the case of facial image enhancement. Our model assumes prior high quality data of the person to be processed, but no knowledge of the degradation model. We try to overcome the classical processing limits by using semantically-aware patches, with adaptive size and location regions of coherent structure and context, as building blocks. The method is demonstrated on the problem of cellular photography enhancement of dark facial images for different identities, expressions and poses.



### Task Specific Adversarial Cost Function
- **Arxiv ID**: http://arxiv.org/abs/1609.08661v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08661v1)
- **Published**: 2016-09-27 20:47:42+00:00
- **Updated**: 2016-09-27 20:47:42+00:00
- **Authors**: Antonia Creswell, Anil A. Bharath
- **Comment**: Submitted to TPAMI
- **Journal**: None
- **Summary**: The cost function used to train a generative model should fit the purpose of the model. If the model is intended for tasks such as generating perceptually correct samples, it is beneficial to maximise the likelihood of a sample drawn from the model, Q, coming from the same distribution as the training data, P. This is equivalent to minimising the Kullback-Leibler (KL) distance, KL[Q||P]. However, if the model is intended for tasks such as retrieval or classification it is beneficial to maximise the likelihood that a sample drawn from the training data is captured by the model, equivalent to minimising KL[P||Q]. The cost function used in adversarial training optimises the Jensen-Shannon entropy which can be seen as an even interpolation between KL[Q||P] and KL[P||Q]. Here, we propose an alternative adversarial cost function which allows easy tuning of the model for either task. Our task specific cost function is evaluated on a dataset of hand-written characters in the following tasks: Generation, retrieval and one-shot learning.



### A Transportation $L^p$ Distance for Signal Analysis
- **Arxiv ID**: http://arxiv.org/abs/1609.08669v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08669v1)
- **Published**: 2016-09-27 21:08:22+00:00
- **Updated**: 2016-09-27 21:08:22+00:00
- **Authors**: Matthew Thorpe, Serim Park, Soheil Kolouri, Gustavo K. Rohde, Dejan Slepčev
- **Comment**: None
- **Journal**: None
- **Summary**: Transport based distances, such as the Wasserstein distance and earth mover's distance, have been shown to be an effective tool in signal and image analysis. The success of transport based distances is in part due to their Lagrangian nature which allows it to capture the important variations in many signal classes. However these distances require the signal to be nonnegative and normalized. Furthermore, the signals are considered as measures and compared by redistributing (transporting) them, which does not directly take into account the signal intensity. Here we study a transport-based distance, called the $TL^p$ distance, that combines Lagrangian and intensity modelling and is directly applicable to general, non-positive and multi-channelled signals. The framework allows the application of existing numerical methods. We give an overview of the basic properties of this distance and applications to classification, with multi-channelled, non-positive one and two-dimensional signals, and color transfer.



### YouTube-8M: A Large-Scale Video Classification Benchmark
- **Arxiv ID**: http://arxiv.org/abs/1609.08675v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1609.08675v1)
- **Published**: 2016-09-27 21:21:49+00:00
- **Updated**: 2016-09-27 21:21:49+00:00
- **Authors**: Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan Varadarajan, Sudheendra Vijayanarasimhan
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Many recent advancements in Computer Vision are attributed to large datasets. Open-source software packages for Machine Learning and inexpensive commodity hardware have reduced the barrier of entry for exploring novel approaches at scale. It is possible to train models over millions of examples within a few days. Although large-scale datasets exist for image understanding, such as ImageNet, there are no comparable size video classification datasets.   In this paper, we introduce YouTube-8M, the largest multi-label video classification dataset, composed of ~8 million videos (500K hours of video), annotated with a vocabulary of 4800 visual entities. To get the videos and their labels, we used a YouTube video annotation system, which labels videos with their main topics. While the labels are machine-generated, they have high-precision and are derived from a variety of human-based signals including metadata and query click signals. We filtered the video labels (Knowledge Graph entities) using both automated and manual curation strategies, including asking human raters if the labels are visually recognizable. Then, we decoded each video at one-frame-per-second, and used a Deep CNN pre-trained on ImageNet to extract the hidden representation immediately prior to the classification layer. Finally, we compressed the frame features and make both the features and video-level labels available for download.   We trained various (modest) classification models on the dataset, evaluated them using popular evaluation metrics, and report them as baselines. Despite the size of the dataset, some of our models train to convergence in less than a day on a single machine using TensorFlow. We plan to release code for training a TensorFlow model and for computing metrics.



### A Fast Factorization-based Approach to Robust PCA
- **Arxiv ID**: http://arxiv.org/abs/1609.08677v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1609.08677v1)
- **Published**: 2016-09-27 21:32:16+00:00
- **Updated**: 2016-09-27 21:32:16+00:00
- **Authors**: Chong Peng, Zhao Kang, Qiang Chen
- **Comment**: ICDM 2016
- **Journal**: None
- **Summary**: Robust principal component analysis (RPCA) has been widely used for recovering low-rank matrices in many data mining and machine learning problems. It separates a data matrix into a low-rank part and a sparse part. The convex approach has been well studied in the literature. However, state-of-the-art algorithms for the convex approach usually have relatively high complexity due to the need of solving (partial) singular value decompositions of large matrices. A non-convex approach, AltProj, has also been proposed with lighter complexity and better scalability. Given the true rank $r$ of the underlying low rank matrix, AltProj has a complexity of $O(r^2dn)$, where $d\times n$ is the size of data matrix. In this paper, we propose a novel factorization-based model of RPCA, which has a complexity of $O(kdn)$, where $k$ is an upper bound of the true rank. Our method does not need the precise value of the true rank. From extensive experiments, we observe that AltProj can work only when $r$ is precisely known in advance; however, when the needed rank parameter $r$ is specified to a value different from the true rank, AltProj cannot fully separate the two parts while our method succeeds. Even when both work, our method is about 4 times faster than AltProj. Our method can be used as a light-weight, scalable tool for RPCA in the absence of the precise value of the true rank.



### Understanding and Exploiting Object Interaction Landscapes
- **Arxiv ID**: http://arxiv.org/abs/1609.08685v2
- **DOI**: None
- **Categories**: **cs.GR**, cs.CG, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1609.08685v2)
- **Published**: 2016-09-27 22:00:56+00:00
- **Updated**: 2016-11-08 20:13:56+00:00
- **Authors**: Sören Pirk, Vojtech Krs, Kaimo Hu, Suren Deepak Rajasekaran, Hao Kang, Bedrich Benes, Yusuke Yoshiyasu, Leonidas J. Guibas
- **Comment**: 14 pages, 19 figures
- **Journal**: None
- **Summary**: Interactions play a key role in understanding objects and scenes, for both virtual and real world agents. We introduce a new general representation for proximal interactions among physical objects that is agnostic to the type of objects or interaction involved. The representation is based on tracking particles on one of the participating objects and then observing them with sensors appropriately placed in the interaction volume or on the interaction surfaces. We show how to factorize these interaction descriptors and project them into a particular participating object so as to obtain a new functional descriptor for that object, its interaction landscape, capturing its observed use in a spatio-temporal framework. Interaction landscapes are independent of the particular interaction and capture subtle dynamic effects in how objects move and behave when in functional use. Our method relates objects based on their function, establishes correspondences between shapes based on functional key points and regions, and retrieves peer and partner objects with respect to an interaction.



