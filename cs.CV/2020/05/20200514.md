# Arxiv Papers in cs.CV on 2020-05-14
### W-Cell-Net: Multi-frame Interpolation of Cellular Microscopy Videos
- **Arxiv ID**: http://arxiv.org/abs/2005.06684v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.06684v1)
- **Published**: 2020-05-14 01:33:38+00:00
- **Updated**: 2020-05-14 01:33:38+00:00
- **Authors**: Rohit Saha, Abenezer Teklemariam, Ian Hsu, Alan M. Moses
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Neural Networks are increasingly used in video frame interpolation tasks such as frame rate changes as well as generating fake face videos. Our project aims to apply recent advances in Deep video interpolation to increase the temporal resolution of fluorescent microscopy time-lapse movies. To our knowledge, there is no previous work that uses Convolutional Neural Networks (CNN) to generate frames between two consecutive microscopy images. We propose a fully convolutional autoencoder network that takes as input two images and generates upto seven intermediate images. Our architecture has two encoders each with a skip connection to a single decoder. We evaluate the performance of several variants of our model that differ in network architecture and loss function. Our best model out-performs state of the art video frame interpolation algorithms. We also show qualitative and quantitative comparisons with state-of-the-art video frame interpolation algorithms. We believe deep video interpolation represents a new approach to improve the time-resolution of fluorescent microscopy.



### Tensor completion via nonconvex tensor ring rank minimization with guaranteed convergence
- **Arxiv ID**: http://arxiv.org/abs/2005.09674v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.09674v1)
- **Published**: 2020-05-14 03:13:17+00:00
- **Updated**: 2020-05-14 03:13:17+00:00
- **Authors**: Meng Ding, Ting-Zhu Huang, Xi-Le Zhao, Tian-Hui Ma
- **Comment**: None
- **Journal**: None
- **Summary**: In recent studies, the tensor ring (TR) rank has shown high effectiveness in tensor completion due to its ability of capturing the intrinsic structure within high-order tensors. A recently proposed TR rank minimization method is based on the convex relaxation by penalizing the weighted sum of nuclear norm of TR unfolding matrices. However, this method treats each singular value equally and neglects their physical meanings, which usually leads to suboptimal solutions in practice. In this paper, we propose to use the logdet-based function as a nonconvex smooth relaxation of the TR rank for tensor completion, which can more accurately approximate the TR rank and better promote the low-rankness of the solution. To solve the proposed nonconvex model efficiently, we develop an alternating direction method of multipliers algorithm and theoretically prove that, under some mild assumptions, our algorithm converges to a stationary point. Extensive experiments on color images, multispectral images, and color videos demonstrate that the proposed method outperforms several state-of-the-art competitors in both visual and quantitative comparison. Key words: nonconvex optimization, tensor ring rank, logdet function, tensor completion, alternating direction method of multipliers.



### Noise Homogenization via Multi-Channel Wavelet Filtering for High-Fidelity Sample Generation in GANs
- **Arxiv ID**: http://arxiv.org/abs/2005.06707v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.06707v1)
- **Published**: 2020-05-14 03:40:11+00:00
- **Updated**: 2020-05-14 03:40:11+00:00
- **Authors**: Shaoning Zeng, Bob Zhang
- **Comment**: 12 pages, 2 figures
- **Journal**: None
- **Summary**: In the generator of typical Generative Adversarial Networks (GANs), a noise is inputted to generate fake samples via a series of convolutional operations. However, current noise generation models merely relies on the information from the pixel space, which increases the difficulty to approach the target distribution. Fortunately, the long proven wavelet transformation is able to decompose multiple spectral information from the images. In this work, we propose a novel multi-channel wavelet-based filtering method for GANs, to cope with this problem. When embedding a wavelet deconvolution layer in the generator, the resultant GAN, called WaveletGAN, takes advantage of the wavelet deconvolution to learn a filtering with multiple channels, which can efficiently homogenize the generated noise via an averaging operation, so as to generate high-fidelity samples. We conducted benchmark experiments on the Fashion-MNIST, KMNIST and SVHN datasets through an open GAN benchmark tool. The results show that WaveletGAN has excellent performance in generating high-fidelity samples, thanks to the smallest FIDs obtained on these datasets.



### Domain Conditioned Adaptation Network
- **Arxiv ID**: http://arxiv.org/abs/2005.06717v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.06717v1)
- **Published**: 2020-05-14 04:23:24+00:00
- **Updated**: 2020-05-14 04:23:24+00:00
- **Authors**: Shuang Li, Chi Harold Liu, Qiuxia Lin, Binhui Xie, Zhengming Ding, Gao Huang, Jian Tang
- **Comment**: Accepted by AAAI 2020
- **Journal**: None
- **Summary**: Tremendous research efforts have been made to thrive deep domain adaptation (DA) by seeking domain-invariant features. Most existing deep DA models only focus on aligning feature representations of task-specific layers across domains while integrating a totally shared convolutional architecture for source and target. However, we argue that such strongly-shared convolutional layers might be harmful for domain-specific feature learning when source and target data distribution differs to a large extent. In this paper, we relax a shared-convnets assumption made by previous DA methods and propose a Domain Conditioned Adaptation Network (DCAN), which aims to excite distinct convolutional channels with a domain conditioned channel attention mechanism. As a result, the critical low-level domain-dependent knowledge could be explored appropriately. As far as we know, this is the first work to explore the domain-wise convolutional channel activation for deep DA networks. Moreover, to effectively align high-level feature distributions across two domains, we further deploy domain conditioned feature correction blocks after task-specific layers, which will explicitly correct the domain discrepancy. Extensive experiments on three cross-domain benchmarks demonstrate the proposed approach outperforms existing methods by a large margin, especially on very tough cross-domain learning tasks.



### Enhanced Residual Networks for Context-based Image Outpainting
- **Arxiv ID**: http://arxiv.org/abs/2005.06723v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.06723v1)
- **Published**: 2020-05-14 05:14:26+00:00
- **Updated**: 2020-05-14 05:14:26+00:00
- **Authors**: Przemek Gardias, Eric Arthur, Huaming Sun
- **Comment**: 6 pages, 5 figures
- **Journal**: None
- **Summary**: Although humans perform well at predicting what exists beyond the boundaries of an image, deep models struggle to understand context and extrapolation through retained information. This task is known as image outpainting and involves generating realistic expansions of an image's boundaries. Current models use generative adversarial networks to generate results which lack localized image feature consistency and appear fake. We propose two methods to improve this issue: the use of a local and global discriminator, and the addition of residual blocks within the encoding section of the network. Comparisons of our model and the baseline's L1 loss, mean squared error (MSE) loss, and qualitative differences reveal our model is able to naturally extend object boundaries and produce more internally consistent images compared to current methods but produces lower fidelity images.



### Low-Dose CT Image Denoising Using Parallel-Clone Networks
- **Arxiv ID**: http://arxiv.org/abs/2005.06724v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.06724v1)
- **Published**: 2020-05-14 05:21:33+00:00
- **Updated**: 2020-05-14 05:21:33+00:00
- **Authors**: Siqi Li, Guobao Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have a great potential to improve image denoising in low-dose computed tomography (LDCT). Popular ways to increase the network capacity include adding more layers or repeating a modularized clone model in a sequence. In such sequential architectures, the noisy input image and end output image are commonly used only once in the training model, which however limits the overall learning performance. In this paper, we propose a parallel-clone neural network method that utilizes a modularized network model and exploits the benefit of parallel input, parallel-output loss, and clone-toclone feature transfer. The proposed model keeps a similar or less number of unknown network weights as compared to conventional models but can accelerate the learning process significantly. The method was evaluated using the Mayo LDCT dataset and compared with existing deep learning models. The results show that the use of parallel input, parallel-output loss, and clone-to-clone feature transfer all can contribute to an accelerated convergence of deep learning and lead to improved image quality in testing. The parallel-clone network has been demonstrated promising for LDCT image denoising.



### Dense-Resolution Network for Point Cloud Classification and Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2005.06734v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.06734v2)
- **Published**: 2020-05-14 06:13:53+00:00
- **Updated**: 2020-11-17 08:02:25+00:00
- **Authors**: Shi Qiu, Saeed Anwar, Nick Barnes
- **Comment**: To appear in WACV2021. Codes and models are available at:
  https://github.com/ShiQiu0419/DRNet
- **Journal**: None
- **Summary**: Point cloud analysis is attracting attention from Artificial Intelligence research since it can be widely used in applications such as robotics, Augmented Reality, self-driving. However, it is always challenging due to irregularities, unorderedness, and sparsity. In this article, we propose a novel network named Dense-Resolution Network (DRNet) for point cloud analysis. Our DRNet is designed to learn local point features from the point cloud in different resolutions. In order to learn local point groups more effectively, we present a novel grouping method for local neighborhood searching and an error-minimizing module for capturing local features. In addition to validating the network on widely used point cloud segmentation and classification benchmarks, we also test and visualize the performance of the components. Comparing with other state-of-the-art methods, our network shows superiority on ModelNet40, ShapeNet synthetic and ScanObjectNN real point cloud datasets.



### The Information & Mutual Information Ratio for Counting Image Features and Their Matches
- **Arxiv ID**: http://arxiv.org/abs/2005.06739v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/2005.06739v1)
- **Published**: 2020-05-14 06:27:01+00:00
- **Updated**: 2020-05-14 06:27:01+00:00
- **Authors**: Ali Khajegili Mirabadi, Stefano Rini
- **Comment**: 8-th Iran Workshop on Communication and Information Theory, 2020
- **Journal**: None
- **Summary**: Feature extraction and description is an important topic of computer vision, as it is the starting point of a number of tasks such as image reconstruction, stitching, registration, and recognition among many others. In this paper, two new image features are proposed: the Information Ratio (IR) and the Mutual Information Ratio (MIR). The IR is a feature of a single image, while the MIR describes features common across two or more images.We begin by introducing the IR and the MIR and motivate these features in an information theoretical context as the ratio of the self-information of an intensity level over the information contained over the pixels of the same intensity. Notably, the relationship of the IR and MIR with the image entropy and mutual information, classic information measures, are discussed. Finally, the effectiveness of these features is tested through feature extraction over INRIA Copydays datasets and feature matching over the Oxfords Affine Covariant Regions. These numerical evaluations validate the relevance of the IR and MIR in practical computer vision tasks



### Large Scale Font Independent Urdu Text Recognition System
- **Arxiv ID**: http://arxiv.org/abs/2005.06752v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.06752v1)
- **Published**: 2020-05-14 06:57:24+00:00
- **Updated**: 2020-05-14 06:57:24+00:00
- **Authors**: Atique Ur Rehman, Sibt Ul Hussain
- **Comment**: None
- **Journal**: None
- **Summary**: OCR algorithms have received a significant improvement in performance recently, mainly due to the increase in the capabilities of artificial intelligence algorithms. However, this advancement is not evenly distributed over all languages. Urdu is among the languages which did not receive much attention, especially in the font independent perspective. There exists no automated system that can reliably recognize printed Urdu text in images and videos across different fonts. To help bridge this gap, we have developed Qaida, a large scale data set with 256 fonts, and a complete Urdu lexicon. We have also developed a Convolutional Neural Network (CNN) based classification model which can recognize Urdu ligatures with 84.2% accuracy. Moreover, we demonstrate that our recognition network can not only recognize the text in the fonts it is trained on but can also reliably recognize text in unseen (new) fonts. To this end, this paper makes following contributions: (i) we introduce a large scale, multiple fonts based data set for printed Urdu text recognition;(ii) we have designed, trained and evaluated a CNN based model for Urdu text recognition; (iii) we experiment with incremental learning methods to produce state-of-the-art results for Urdu text recognition. All the experiment choices were thoroughly validated via detailed empirical analysis. We believe that this study can serve as the basis for further improvement in the performance of font independent Urdu OCR systems.



### TAM: Temporal Adaptive Module for Video Recognition
- **Arxiv ID**: http://arxiv.org/abs/2005.06803v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.06803v3)
- **Published**: 2020-05-14 08:22:45+00:00
- **Updated**: 2021-08-18 12:19:06+00:00
- **Authors**: Zhaoyang Liu, Limin Wang, Wayne Wu, Chen Qian, Tong Lu
- **Comment**: ICCV 2021 camera-ready version. Code is available at
  https://github.com/liu-zhy/temporal-adaptive-module
- **Journal**: None
- **Summary**: Video data is with complex temporal dynamics due to various factors such as camera motion, speed variation, and different activities. To effectively capture this diverse motion pattern, this paper presents a new temporal adaptive module ({\bf TAM}) to generate video-specific temporal kernels based on its own feature map. TAM proposes a unique two-level adaptive modeling scheme by decoupling the dynamic kernel into a location sensitive importance map and a location invariant aggregation weight. The importance map is learned in a local temporal window to capture short-term information, while the aggregation weight is generated from a global view with a focus on long-term structure. TAM is a modular block and could be integrated into 2D CNNs to yield a powerful video architecture (TANet) with a very small extra computational cost. The extensive experiments on Kinetics-400 and Something-Something datasets demonstrate that our TAM outperforms other temporal modeling methods consistently, and achieves the state-of-the-art performance under the similar complexity. The code is available at \url{ https://github.com/liu-zhy/temporal-adaptive-module}.



### A Semi-Supervised Assessor of Neural Architectures
- **Arxiv ID**: http://arxiv.org/abs/2005.06821v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.06821v1)
- **Published**: 2020-05-14 09:02:33+00:00
- **Updated**: 2020-05-14 09:02:33+00:00
- **Authors**: Yehui Tang, Yunhe Wang, Yixing Xu, Hanting Chen, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, Chang Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Neural architecture search (NAS) aims to automatically design deep neural networks of satisfactory performance. Wherein, architecture performance predictor is critical to efficiently value an intermediate neural architecture. But for the training of this predictor, a number of neural architectures and their corresponding real performance often have to be collected. In contrast with classical performance predictor optimized in a fully supervised way, this paper suggests a semi-supervised assessor of neural architectures. We employ an auto-encoder to discover meaningful representations of neural architectures. Taking each neural architecture as an individual instance in the search space, we construct a graph to capture their intrinsic similarities, where both labeled and unlabeled architectures are involved. A graph convolutional neural network is introduced to predict the performance of architectures based on the learned representations and their relation modeled by the graph. Extensive experimental results on the NAS-Benchmark-101 dataset demonstrated that our method is able to make a significant reduction on the required fully trained architectures for finding efficient architectures.



### Detection and Retrieval of Out-of-Distribution Objects in Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2005.06831v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.06831v1)
- **Published**: 2020-05-14 09:21:14+00:00
- **Updated**: 2020-05-14 09:21:14+00:00
- **Authors**: Philipp Oberdiek, Matthias Rottmann, Gernot A. Fink
- **Comment**: None
- **Journal**: None
- **Summary**: When deploying deep learning technology in self-driving cars, deep neural networks are constantly exposed to domain shifts. These include, e.g., changes in weather conditions, time of day, and long-term temporal shift. In this work we utilize a deep neural network trained on the Cityscapes dataset containing urban street scenes and infer images from a different dataset, the A2D2 dataset, containing also countryside and highway images. We present a novel pipeline for semantic segmenation that detects out-of-distribution (OOD) segments by means of the deep neural network's prediction and performs image retrieval after feature extraction and dimensionality reduction on image patches. In our experiments we demonstrate that the deployed OOD approach is suitable for detecting out-of-distribution concepts. Furthermore, we evaluate the image patch retrieval qualitatively as well as quantitatively by means of the semi-compatible A2D2 ground truth and obtain mAP values of up to 52.2%.



### A multicenter study on radiomic features from T$_2$-weighted images of a customized MR pelvic phantom setting the basis for robust radiomic models in clinics
- **Arxiv ID**: http://arxiv.org/abs/2005.06833v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.06833v2)
- **Published**: 2020-05-14 09:24:48+00:00
- **Updated**: 2020-05-18 12:46:35+00:00
- **Authors**: Linda Bianchini, Joao Santinha, Nuno Loução, Mario Figueiredo, Francesca Botta, Daniela Origgi, Marta Cremonesi, Enrico Cassano, Nikolaos Papanikolaou, Alessandro Lascialfari
- **Comment**: 32 pages, 8 figures (7 + 1 supplemental), 8 tables (5 + 3
  supplemental); Submitted to Magnetic Resonance in Medicine
- **Journal**: None
- **Summary**: In this study we investigated the repeatability and reproducibility of radiomic features extracted from MRI images and provide a workflow to identify robust features. 2D and 3D T$_2$-weighted images of a pelvic phantom were acquired on three scanners of two manufacturers and two magnetic field strengths. The repeatability and reproducibility of the radiomic features were assessed respectively by intraclass correlation coefficient (ICC) and concordance correlation coefficient (CCC), considering repeated acquisitions with or without phantom repositioning, and with different scanner/acquisition type, and acquisition parameters. The features showing ICC/CCC > 0.9 were selected, and their dependence on shape information (Spearman's $\rho$> 0.8) was analyzed. They were classified for their ability to distinguish textures, after shuffling voxel intensities. From 944 2D features, 79.9% to 96.4% showed excellent repeatability in fixed position across all scanners. Much lower range (11.2% to 85.4%) was obtained after phantom repositioning. 3D extraction did not improve repeatability performance. Excellent reproducibility between scanners was observed in 4.6% to 15.6% of the features, at fixed imaging parameters. 82.4% to 94.9% of features showed excellent agreement when extracted from images acquired with TEs 5 ms apart (values decreased when increasing TE intervals) and 90.7% of the features exhibited excellent reproducibility for changes in TR. 2.0% of non-shape features were identified as providing only shape information. This study demonstrates that radiomic features are affected by specific MRI protocols. The use of our radiomic pelvic phantom allowed to identify unreliable features for radiomic analysis on T$_2$-weighted images. This paper proposes a general workflow to identify repeatable, reproducible, and informative radiomic features, fundamental to ensure robustness of clinical studies.



### RegQCNET: Deep Quality Control for Image-to-template Brain MRI Affine Registration
- **Arxiv ID**: http://arxiv.org/abs/2005.06835v2
- **DOI**: 10.1088/1361-6560/abb6be
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.06835v2)
- **Published**: 2020-05-14 09:27:24+00:00
- **Updated**: 2020-09-16 16:58:46+00:00
- **Authors**: Baudouin Denis de Senneville, José V. Manjon, Pierrick Coupé
- **Comment**: None
- **Journal**: Physics in Medicine and Biology, 2020
- **Summary**: Affine registration of one or several brain image(s) onto a common reference space is a necessary prerequisite for many image processing tasks, such as brain segmentation or functional analysis. Manual assessment of registration quality is a tedious and time-consuming task, especially in studies comprising a large amount of data. An automated and reliable quality control (QC) becomes mandatory. Moreover, the computation time of the QC must be also compatible with the processing of massive datasets. Therefore, an automated deep neural network approaches appear as a method of choice to automatically assess registration quality.   In the current study, a compact 3D convolutional neural network (CNN), referred to as RegQCNET, is introduced to quantitatively predict the amplitude of an affine registration mismatch between a registered image and a reference template. This quantitative estimation of registration error is expressed using metric unit system. Therefore, a meaningful task-specific threshold can be manually or automatically defined in order to distinguish usable and non-usable images.   The robustness of the proposed RegQCNET is first analyzed on lifespan brain images undergoing various simulated spatial transformations and intensity variations between training and testing. Secondly, the potential of RegQCNET to classify images as usable or non-usable is evaluated using both manual and automatic thresholds. During our experiments, automatic thresholds are estimated using several computer-assisted classification models through cross-validation. To this end we used expert's visual quality control estimated on a lifespan cohort of 3953 brains. Finally, the RegQCNET accuracy is compared to usual image features.   Results show that the proposed deep learning QC is robust, fast and accurate to estimate affine registration error in processing pipeline.



### ZynqNet: An FPGA-Accelerated Embedded Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2005.06892v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.06892v1)
- **Published**: 2020-05-14 11:54:04+00:00
- **Updated**: 2020-05-14 11:54:04+00:00
- **Authors**: David Gschwend
- **Comment**: 85 pages, 26 figures. Code available at
  http://github.com/dgschwend/zynqnet
- **Journal**: None
- **Summary**: Image Understanding is becoming a vital feature in ever more applications ranging from medical diagnostics to autonomous vehicles. Many applications demand for embedded solutions that integrate into existing systems with tight real-time and power constraints. Convolutional Neural Networks (CNNs) presently achieve record-breaking accuracies in all image understanding benchmarks, but have a very high computational complexity. Embedded CNNs thus call for small and efficient, yet very powerful computing platforms. This master thesis explores the potential of FPGA-based CNN acceleration and demonstrates a fully functional proof-of-concept CNN implementation on a Zynq System-on-Chip. The ZynqNet Embedded CNN is designed for image classification on ImageNet and consists of ZynqNet CNN, an optimized and customized CNN topology, and the ZynqNet FPGA Accelerator, an FPGA-based architecture for its evaluation. ZynqNet CNN is a highly efficient CNN topology. Detailed analysis and optimization of prior topologies using the custom-designed Netscope CNN Analyzer have enabled a CNN with 84.5% top-5 accuracy at a computational complexity of only 530 million multiplyaccumulate operations. The topology is highly regular and consists exclusively of convolutional layers, ReLU nonlinearities and one global pooling layer. The CNN fits ideally onto the FPGA accelerator. The ZynqNet FPGA Accelerator allows an efficient evaluation of ZynqNet CNN. It accelerates the full network based on a nested-loop algorithm which minimizes the number of arithmetic operations and memory accesses. The FPGA accelerator has been synthesized using High-Level Synthesis for the Xilinx Zynq XC-7Z045, and reaches a clock frequency of 200MHz with a device utilization of 80% to 90 %.



### Classification of Arrhythmia by Using Deep Learning with 2-D ECG Spectral Image Representation
- **Arxiv ID**: http://arxiv.org/abs/2005.06902v2
- **DOI**: 10.3390/rs12101685
- **Categories**: **eess.SP**, cs.CV, cs.LG, 68T10, 62H30, I.4.7; I.5; I.2.10; G.3
- **Links**: [PDF](http://arxiv.org/pdf/2005.06902v2)
- **Published**: 2020-05-14 12:11:41+00:00
- **Updated**: 2020-05-25 16:44:45+00:00
- **Authors**: Amin Ullah, Syed M. Anwar, Muhammad Bilal, Raja M Mehmood
- **Comment**: 14 pages, 5 figures, accepted for future publication in Remote
  Sensing MDPI Journal
- **Journal**: Remote Sensing. 2020; 12(10):1685
- **Summary**: The electrocardiogram (ECG) is one of the most extensively employed signals used in the diagnosis and prediction of cardiovascular diseases (CVDs). The ECG signals can capture the heart's rhythmic irregularities, commonly known as arrhythmias. A careful study of ECG signals is crucial for precise diagnoses of patients' acute and chronic heart conditions. In this study, we propose a two-dimensional (2-D) convolutional neural network (CNN) model for the classification of ECG signals into eight classes; namely, normal beat, premature ventricular contraction beat, paced beat, right bundle branch block beat, left bundle branch block beat, atrial premature contraction beat, ventricular flutter wave beat, and ventricular escape beat. The one-dimensional ECG time series signals are transformed into 2-D spectrograms through short-time Fourier transform. The 2-D CNN model consisting of four convolutional layers and four pooling layers is designed for extracting robust features from the input spectrograms. Our proposed methodology is evaluated on a publicly available MIT-BIH arrhythmia dataset. We achieved a state-of-the-art average classification accuracy of 99.11\%, which is better than those of recently reported results in classifying similar types of arrhythmias. The performance is significant in other indices as well, including sensitivity and specificity, which indicates the success of the proposed method.



### Temperate Fish Detection and Classification: a Deep Learning based Approach
- **Arxiv ID**: http://arxiv.org/abs/2005.07518v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07518v1)
- **Published**: 2020-05-14 12:40:57+00:00
- **Updated**: 2020-05-14 12:40:57+00:00
- **Authors**: Kristian Muri Knausgård, Arne Wiklund, Tonje Knutsen Sørdalen, Kim Halvorsen, Alf Ring Kleiven, Lei Jiao, Morten Goodwin
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1904.02768
- **Journal**: None
- **Summary**: A wide range of applications in marine ecology extensively uses underwater cameras. Still, to efficiently process the vast amount of data generated, we need to develop tools that can automatically detect and recognize species captured on film. Classifying fish species from videos and images in natural environments can be challenging because of noise and variation in illumination and the surrounding habitat. In this paper, we propose a two-step deep learning approach for the detection and classification of temperate fishes without pre-filtering. The first step is to detect each single fish in an image, independent of species and sex. For this purpose, we employ the You Only Look Once (YOLO) object detection technique. In the second step, we adopt a Convolutional Neural Network (CNN) with the Squeeze-and-Excitation (SE) architecture for classifying each fish in the image without pre-filtering. We apply transfer learning to overcome the limited training samples of temperate fishes and to improve the accuracy of the classification. This is done by training the object detection model with ImageNet and the fish classifier via a public dataset (Fish4Knowledge), whereupon both the object detection and classifier are updated with temperate fishes of interest. The weights obtained from pre-training are applied to post-training as a priori. Our solution achieves the state-of-the-art accuracy of 99.27\% on the pre-training. The percentage values for accuracy on the post-training are good; 83.68\% and 87.74\% with and without image augmentation, respectively, indicating that the solution is viable with a more extensive dataset.



### S2IGAN: Speech-to-Image Generation via Adversarial Learning
- **Arxiv ID**: http://arxiv.org/abs/2005.06968v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.06968v2)
- **Published**: 2020-05-14 13:39:56+00:00
- **Updated**: 2020-09-15 08:17:22+00:00
- **Authors**: Xinsheng Wang, Tingting Qiao, Jihua Zhu, Alan Hanjalic, Odette Scharenborg
- **Comment**: Accepted to Interspeech2020
- **Journal**: None
- **Summary**: An estimated half of the world's languages do not have a written form, making it impossible for these languages to benefit from any existing text-based technologies. In this paper, a speech-to-image generation (S2IG) framework is proposed which translates speech descriptions to photo-realistic images without using any text information, thus allowing unwritten languages to potentially benefit from this technology. The proposed S2IG framework, named S2IGAN, consists of a speech embedding network (SEN) and a relation-supervised densely-stacked generative model (RDG). SEN learns the speech embedding with the supervision of the corresponding visual information. Conditioned on the speech embedding produced by SEN, the proposed RDG synthesizes images that are semantically consistent with the corresponding speech descriptions. Extensive experiments on two public benchmark datasets CUB and Oxford-102 demonstrate the effectiveness of the proposed S2IGAN on synthesizing high-quality and semantically-consistent images from the speech signal, yielding a good performance and a solid baseline for the S2IG task.



### Reinforced Coloring for End-to-End Instance Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2005.07058v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07058v2)
- **Published**: 2020-05-14 15:15:47+00:00
- **Updated**: 2020-05-19 02:40:36+00:00
- **Authors**: Tuan Tran Anh, Khoa Nguyen-Tuan, Tran Minh Quan, Won-Ki Jeong
- **Comment**: None
- **Journal**: None
- **Summary**: Instance segmentation is one of the actively studied research topics in computer vision in which many objects of interest should be separated individually. While many feed-forward networks produce high-quality segmentation on different types of images, their results often suffer from topological errors (merging or splitting) for segmentation of many objects, requiring post-processing. Existing iterative methods, on the other hand, extract a single object at a time using discriminative knowledge-based properties (shapes, boundaries, etc.) without relying on post-processing, but they do not scale well. To exploit the advantages of conventional single-object-per-step segmentation methods without impairing the scalability, we propose a novel iterative deep reinforcement learning agent that learns how to differentiate multiple objects in parallel. Our reward function for the trainable agent is designed to favor grouping pixels belonging to the same object using a graph coloring algorithm. We demonstrate that the proposed method can efficiently perform instance segmentation of many objects without heavy post-processing.



### On Learned Operator Correction in Inverse Problems
- **Arxiv ID**: http://arxiv.org/abs/2005.07069v2
- **DOI**: None
- **Categories**: **math.NA**, cs.CV, cs.LG, cs.NA, eess.IV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/2005.07069v2)
- **Published**: 2020-05-14 15:37:28+00:00
- **Updated**: 2020-10-21 13:41:59+00:00
- **Authors**: Sebastian Lunz, Andreas Hauptmann, Tanja Tarvainen, Carola-Bibiane Schönlieb, Simon Arridge
- **Comment**: 28 pages, 11 Figures
- **Journal**: None
- **Summary**: We discuss the possibility to learn a data-driven explicit model correction for inverse problems and whether such a model correction can be used within a variational framework to obtain regularised reconstructions. This paper discusses the conceptual difficulty to learn such a forward model correction and proceeds to present a possible solution as forward-adjoint correction that explicitly corrects in both data and solution spaces. We then derive conditions under which solutions to the variational problem with a learned correction converge to solutions obtained with the correct operator. The proposed approach is evaluated on an application to limited view photoacoustic tomography and compared to the established framework of Bayesian approximation error method.



### FaceFilter: Audio-visual speech separation using still images
- **Arxiv ID**: http://arxiv.org/abs/2005.07074v1
- **DOI**: 10.21437/Interspeech.2020-1065
- **Categories**: **cs.SD**, cs.CV, cs.MM, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2005.07074v1)
- **Published**: 2020-05-14 15:42:31+00:00
- **Updated**: 2020-05-14 15:42:31+00:00
- **Authors**: Soo-Whan Chung, Soyeon Choe, Joon Son Chung, Hong-Goo Kang
- **Comment**: Under submission as a conference paper. Video examples:
  https://youtu.be/ku9xoLh62E
- **Journal**: None
- **Summary**: The objective of this paper is to separate a target speaker's speech from a mixture of two speakers using a deep audio-visual speech separation network. Unlike previous works that used lip movement on video clips or pre-enrolled speaker information as an auxiliary conditional feature, we use a single face image of the target speaker. In this task, the conditional feature is obtained from facial appearance in cross-modal biometric task, where audio and visual identity representations are shared in latent space. Learnt identities from facial images enforce the network to isolate matched speakers and extract the voices from mixed speech. It solves the permutation problem caused by swapped channel outputs, frequently occurred in speech separation tasks. The proposed method is far more practical than video-based speech separation since user profile images are readily available on many platforms. Also, unlike speaker-aware separation methods, it is applicable on separation with unseen speakers who have never been enrolled before. We show strong qualitative and quantitative results on challenging real-world examples.



### Bayesian Bits: Unifying Quantization and Pruning
- **Arxiv ID**: http://arxiv.org/abs/2005.07093v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2005.07093v3)
- **Published**: 2020-05-14 16:00:34+00:00
- **Updated**: 2020-10-27 11:27:24+00:00
- **Authors**: Mart van Baalen, Christos Louizos, Markus Nagel, Rana Ali Amjad, Ying Wang, Tijmen Blankevoort, Max Welling
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce Bayesian Bits, a practical method for joint mixed precision quantization and pruning through gradient based optimization. Bayesian Bits employs a novel decomposition of the quantization operation, which sequentially considers doubling the bit width. At each new bit width, the residual error between the full precision value and the previously rounded value is quantized. We then decide whether or not to add this quantized residual error for a higher effective bit width and lower quantization noise. By starting with a power-of-two bit width, this decomposition will always produce hardware-friendly configurations, and through an additional 0-bit option, serves as a unified view of pruning and quantization. Bayesian Bits then introduces learnable stochastic gates, which collectively control the bit width of the given tensor. As a result, we can obtain low bit solutions by performing approximate inference over the gates, with prior distributions that encourage most of them to be switched off. We experimentally validate our proposed method on several benchmark datasets and show that we can learn pruned, mixed precision networks that provide a better trade-off between accuracy and efficiency than their static bit width equivalents.



### Ambient Sound Helps: Audiovisual Crowd Counting in Extreme Conditions
- **Arxiv ID**: http://arxiv.org/abs/2005.07097v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.07097v2)
- **Published**: 2020-05-14 16:05:47+00:00
- **Updated**: 2020-05-16 20:56:26+00:00
- **Authors**: Di Hu, Lichao Mou, Qingzhong Wang, Junyu Gao, Yuansheng Hua, Dejing Dou, Xiao Xiang Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Visual crowd counting has been recently studied as a way to enable people counting in crowd scenes from images. Albeit successful, vision-based crowd counting approaches could fail to capture informative features in extreme conditions, e.g., imaging at night and occlusion. In this work, we introduce a novel task of audiovisual crowd counting, in which visual and auditory information are integrated for counting purposes. We collect a large-scale benchmark, named auDiovISual Crowd cOunting (DISCO) dataset, consisting of 1,935 images and the corresponding audio clips, and 170,270 annotated instances. In order to fuse the two modalities, we make use of a linear feature-wise fusion module that carries out an affine transformation on visual and auditory features. Finally, we conduct extensive experiments using the proposed dataset and approach. Experimental results show that introducing auditory information can benefit crowd counting under different illumination, noise, and occlusion conditions. The dataset and code will be released. Code and data have been made available



### Robust On-Manifold Optimization for Uncooperative Space Relative Navigation with a Single Camera
- **Arxiv ID**: http://arxiv.org/abs/2005.07110v1
- **DOI**: 10.2514/1.G004794
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07110v1)
- **Published**: 2020-05-14 16:23:04+00:00
- **Updated**: 2020-05-14 16:23:04+00:00
- **Authors**: Duarte Rondao, Nabil Aouf, Mark A. Richardson, Vincent Dubanchet
- **Comment**: 42 pages, 17 figures
- **Journal**: None
- **Summary**: Optical cameras are gaining popularity as the suitable sensor for relative navigation in space due to their attractive sizing, power and cost properties when compared to conventional flight hardware or costly laser-based systems. However, a camera cannot infer depth information on its own, which is often solved by introducing complementary sensors or a second camera. In this paper, an innovative model-based approach is instead demonstrated to estimate the six-dimensional pose of a target object relative to the chaser spacecraft using solely a monocular setup. The observed facet of the target is tackled as a classification problem, where the three-dimensional shape is learned offline using Gaussian mixture modeling. The estimate is refined by minimizing two different robust loss functions based on local feature correspondences. The resulting pseudo-measurements are then processed and fused with an extended Kalman filter. The entire optimization framework is designed to operate directly on the $SE\text{(3)}$ manifold, uncoupling the process and measurement models from the global attitude state representation. It is validated on realistic synthetic and laboratory datasets of a rendezvous trajectory with the complex spacecraft Envisat. It is demonstrated how it achieves an estimate of the relative pose with high accuracy over its full tumbling motion.



### PENNI: Pruned Kernel Sharing for Efficient CNN Inference
- **Arxiv ID**: http://arxiv.org/abs/2005.07133v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.07133v2)
- **Published**: 2020-05-14 16:57:41+00:00
- **Updated**: 2020-06-25 02:28:00+00:00
- **Authors**: Shiyu Li, Edward Hanson, Hai Li, Yiran Chen
- **Comment**: 9 pages, 5 figures, to appear on ICML2020
- **Journal**: None
- **Summary**: Although state-of-the-art (SOTA) CNNs achieve outstanding performance on various tasks, their high computation demand and massive number of parameters make it difficult to deploy these SOTA CNNs onto resource-constrained devices. Previous works on CNN acceleration utilize low-rank approximation of the original convolution layers to reduce computation cost. However, these methods are very difficult to conduct upon sparse models, which limits execution speedup since redundancies within the CNN model are not fully exploited. We argue that kernel granularity decomposition can be conducted with low-rank assumption while exploiting the redundancy within the remaining compact coefficients. Based on this observation, we propose PENNI, a CNN model compression framework that is able to achieve model compactness and hardware efficiency simultaneously by (1) implementing kernel sharing in convolution layers via a small number of basis kernels and (2) alternately adjusting bases and coefficients with sparse constraints. Experiments show that we can prune 97% parameters and 92% FLOPs on ResNet18 CIFAR10 with no accuracy loss, and achieve 44% reduction in run-time memory consumption and a 53% reduction in inference latency.



### Towards Understanding the Adversarial Vulnerability of Skeleton-based Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/2005.07151v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.07151v2)
- **Published**: 2020-05-14 17:12:52+00:00
- **Updated**: 2020-06-06 15:21:59+00:00
- **Authors**: Tianhang Zheng, Sheng Liu, Changyou Chen, Junsong Yuan, Baochun Li, Kui Ren
- **Comment**: None
- **Journal**: None
- **Summary**: Skeleton-based action recognition has attracted increasing attention due to its strong adaptability to dynamic circumstances and potential for broad applications such as autonomous and anonymous surveillance. With the help of deep learning techniques, it has also witnessed substantial progress and currently achieved around 90\% accuracy in benign environment. On the other hand, research on the vulnerability of skeleton-based action recognition under different adversarial settings remains scant, which may raise security concerns about deploying such techniques into real-world systems. However, filling this research gap is challenging due to the unique physical constraints of skeletons and human actions. In this paper, we attempt to conduct a thorough study towards understanding the adversarial vulnerability of skeleton-based action recognition. We first formulate generation of adversarial skeleton actions as a constrained optimization problem by representing or approximating the physiological and physical constraints with mathematical formulations. Since the primal optimization problem with equality constraints is intractable, we propose to solve it by optimizing its unconstrained dual problem using ADMM. We then specify an efficient plug-in defense, inspired by recent theories and empirical observations, against the adversarial skeleton actions. Extensive evaluations demonstrate the effectiveness of the attack and defense method under different settings.



### OctSqueeze: Octree-Structured Entropy Model for LiDAR Compression
- **Arxiv ID**: http://arxiv.org/abs/2005.07178v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07178v2)
- **Published**: 2020-05-14 17:48:49+00:00
- **Updated**: 2021-01-08 22:27:07+00:00
- **Authors**: Lila Huang, Shenlong Wang, Kelvin Wong, Jerry Liu, Raquel Urtasun
- **Comment**: CVPR 2020 (Oral)
- **Journal**: None
- **Summary**: We present a novel deep compression algorithm to reduce the memory footprint of LiDAR point clouds. Our method exploits the sparsity and structural redundancy between points to reduce the bitrate. Towards this goal, we first encode the LiDAR points into an octree, a data-efficient structure suitable for sparse point clouds. We then design a tree-structured conditional entropy model that models the probabilities of the octree symbols to encode the octree into a compact bitstream. We validate the effectiveness of our method over two large-scale datasets. The results demonstrate that our approach reduces the bitrate by 10-20% at the same reconstruction quality, compared to the previous state-of-the-art. Importantly, we also show that for the same bitrate, our approach outperforms other compression algorithms when performing downstream 3D segmentation and detection tasks using compressed representations. Our algorithm can be used to reduce the onboard and offboard storage of LiDAR points for applications such as self-driving cars, where a single vehicle captures 84 billion points per day



### SAGE: Sequential Attribute Generator for Analyzing Glioblastomas using Limited Dataset
- **Arxiv ID**: http://arxiv.org/abs/2005.07225v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07225v2)
- **Published**: 2020-05-14 19:14:28+00:00
- **Updated**: 2022-06-03 21:28:33+00:00
- **Authors**: Padmaja Jonnalagedda, Brent Weinberg, Jason Allen, Taejin L. Min, Shiv Bhanu, Bir Bhanu
- **Comment**: None
- **Journal**: None
- **Summary**: While deep learning approaches have shown remarkable performance in many imaging tasks, most of these methods rely on availability of large quantities of data. Medical image data, however, is scarce and fragmented. Generative Adversarial Networks (GANs) have recently been very effective in handling such datasets by generating more data. If the datasets are very small, however, GANs cannot learn the data distribution properly, resulting in less diverse or low-quality results. One such limited dataset is that for the concurrent gain of 19 and 20 chromosomes (19/20 co-gain), a mutation with positive prognostic value in Glioblastomas (GBM). In this paper, we detect imaging biomarkers for the mutation to streamline the extensive and invasive prognosis pipeline. Since this mutation is relatively rare, i.e. small dataset, we propose a novel generative framework - the Sequential Attribute GEnerator (SAGE), that generates detailed tumor imaging features while learning from a limited dataset. Experiments show that not only does SAGE generate high quality tumors when compared to standard Deep Convolutional GAN (DC-GAN) and Wasserstein GAN with Gradient Penalty (WGAN-GP), it also captures the imaging biomarkers accurately.



### Evolved Explainable Classifications for Lymph Node Metastases
- **Arxiv ID**: http://arxiv.org/abs/2005.07229v1
- **DOI**: 10.1016/j.neunet.2021.12.014
- **Categories**: **cs.CV**, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2005.07229v1)
- **Published**: 2020-05-14 19:27:24+00:00
- **Updated**: 2020-05-14 19:27:24+00:00
- **Authors**: Iam Palatnik de Sousa, Marley Maria Bernardes Rebuzzi Vellasco, Eduardo Costa da Silva
- **Comment**: None
- **Journal**: None
- **Summary**: A novel evolutionary approach for Explainable Artificial Intelligence is presented: the "Evolved Explanations" model (EvEx). This methodology consists in combining Local Interpretable Model Agnostic Explanations (LIME) with Multi-Objective Genetic Algorithms to allow for automated segmentation parameter tuning in image classification tasks. In this case, the dataset studied is Patch-Camelyon, comprised of patches from pathology whole slide images. A publicly available Convolutional Neural Network (CNN) was trained on this dataset to provide a binary classification for presence/absence of lymph node metastatic tissue. In turn, the classifications are explained by means of evolving segmentations, seeking to optimize three evaluation goals simultaneously. The final explanation is computed as the mean of all explanations generated by Pareto front individuals, evolved by the developed genetic algorithm. To enhance reproducibility and traceability of the explanations, each of them was generated from several different seeds, randomly chosen. The observed results show remarkable agreement between different seeds. Despite the stochastic nature of LIME explanations, regions of high explanation weights proved to have good agreement in the heat maps, as computed by pixel-wise relative standard deviations. The found heat maps coincide with expert medical segmentations, which demonstrates that this methodology can find high quality explanations (according to the evaluation metrics), with the novel advantage of automated parameter fine tuning. These results give additional insight into the inner workings of neural network black box decision making for medical data.



### DiResNet: Direction-aware Residual Network for Road Extraction in VHR Remote Sensing Images
- **Arxiv ID**: http://arxiv.org/abs/2005.07232v2
- **DOI**: 10.1109/TGRS.2020.3034011
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.07232v2)
- **Published**: 2020-05-14 19:33:21+00:00
- **Updated**: 2020-05-24 21:44:08+00:00
- **Authors**: Lei Ding, Lorenzo Bruzzone
- **Comment**: 12 pages, 13 figures. IEEE Transactions on Geoscience and Remote
  Sensing, 2020
- **Journal**: Ding L, Bruzzone L. DiResNet: Direction-Aware Residual Network for
  Road Extraction in VHR Remote Sensing Images[J]. IEEE Transactions on
  Geoscience and Remote Sensing, 2020
- **Summary**: The binary segmentation of roads in very high resolution (VHR) remote sensing images (RSIs) has always been a challenging task due to factors such as occlusions (caused by shadows, trees, buildings, etc.) and the intra-class variances of road surfaces. The wide use of convolutional neural networks (CNNs) has greatly improved the segmentation accuracy and made the task end-to-end trainable. However, there are still margins to improve in terms of the completeness and connectivity of the results. In this paper, we consider the specific context of road extraction and present a direction-aware residual network (DiResNet) that includes three main contributions: 1) An asymmetric residual segmentation network with deconvolutional layers and a structural supervision to enhance the learning of road topology (DiResSeg); 2) A pixel-level supervision of local directions to enhance the embedding of linear features; 3) A refinement network to optimize the segmentation results (DiResRef). Ablation studies on two benchmark datasets (the Massachusetts dataset and the DeepGlobe dataset) have confirmed the effectiveness of the presented designs. Comparative experiments with other approaches show that the proposed method has advantages in both overall accuracy and F1-score. The code is available at: https://github.com/ggsDing/DiResNet.



### An Artificial-intelligence/Statistics Solution to Quantify Material Distortion for Thermal Compensation in Additive Manufacturing
- **Arxiv ID**: http://arxiv.org/abs/2005.09084v1
- **DOI**: None
- **Categories**: **cs.CE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2005.09084v1)
- **Published**: 2020-05-14 20:02:47+00:00
- **Updated**: 2020-05-14 20:02:47+00:00
- **Authors**: Chao Wang, Shaofan Li, Danielle Zeng, Xinhai Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a probabilistic statistics solution or artificial intelligence (AI) approach to identify and quantify permanent (non-zero strain) continuum/material deformation only based on the scanned material data in the spatial configuration and the shape of the initial design configuration or the material configuration. The challenge of this problem is that we only know the scanned material data in the spatial configuration and the shape of the design configuration of three-dimensional (3D) printed products, whereas for a specific scanned material point we do not know its corresponding material coordinates in the initial or designed referential configuration, provided that we do not know the detailed information on actual physical deformation process. Different from physics-based modeling, the method developed here is a data-driven artificial intelligence method, which solves the problem with incomplete deformation data or with missing information of actual physical deformation process. We coined the method is an AI-based material deformation finding algorithm.   This method has practical significance and important applications in finding and designing thermal compensation configuration of a 3D printed product in additive manufacturing, which is at the heart of the cutting edge 3D printing technology. In this paper, we demonstrate that the proposed AI continuum/material deformation finding approach can accurately find permanent thermal deformation configuration for a complex 3D printed structure component, and hence to identify the thermal compensation design configuration in order to minimizing the impact of temperature fluctuations on 3D printed structure components that are sensitive to changes of temperature.



### Bi3D: Stereo Depth Estimation via Binary Classifications
- **Arxiv ID**: http://arxiv.org/abs/2005.07274v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2005.07274v2)
- **Published**: 2020-05-14 21:33:00+00:00
- **Updated**: 2020-06-01 16:44:34+00:00
- **Authors**: Abhishek Badki, Alejandro Troccoli, Kihwan Kim, Jan Kautz, Pradeep Sen, Orazio Gallo
- **Comment**: To be presented at CVPR 2020
- **Journal**: None
- **Summary**: Stereo-based depth estimation is a cornerstone of computer vision, with state-of-the-art methods delivering accurate results in real time. For several applications such as autonomous navigation, however, it may be useful to trade accuracy for lower latency. We present Bi3D, a method that estimates depth via a series of binary classifications. Rather than testing if objects are at a particular depth $D$, as existing stereo methods do, it classifies them as being closer or farther than $D$. This property offers a powerful mechanism to balance accuracy and latency. Given a strict time budget, Bi3D can detect objects closer than a given distance in as little as a few milliseconds, or estimate depth with arbitrarily coarse quantization, with complexity linear with the number of quantization levels. Bi3D can also use the allotted quantization levels to get continuous depth, but in a specific depth range. For standard stereo (i.e., continuous depth on the whole range), our method is close to or on par with state-of-the-art, finely tuned stereo methods.



### SUPER: A Novel Lane Detection System
- **Arxiv ID**: http://arxiv.org/abs/2005.07277v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.07277v1)
- **Published**: 2020-05-14 21:40:39+00:00
- **Updated**: 2020-05-14 21:40:39+00:00
- **Authors**: Pingping Lu, Chen Cui, Shaobing Xu, Huei Peng, Fan Wang
- **Comment**: None
- **Journal**: None
- **Summary**: AI-based lane detection algorithms were actively studied over the last few years. Many have demonstrated superior performance compared with traditional feature-based methods. The accuracy, however, is still generally in the low 80% or high 90%, or even lower when challenging images are used. In this paper, we propose a real-time lane detection system, called Scene Understanding Physics-Enhanced Real-time (SUPER) algorithm. The proposed method consists of two main modules: 1) a hierarchical semantic segmentation network as the scene feature extractor and 2) a physics enhanced multi-lane parameter optimization module for lane inference. We train the proposed system using heterogeneous data from Cityscapes, Vistas and Apollo, and evaluate the performance on four completely separate datasets (that were never seen before), including Tusimple, Caltech, URBAN KITTI-ROAD, and X-3000. The proposed approach performs the same or better than lane detection models already trained on the same dataset and performs well even on datasets it was never trained on. Real-world vehicle tests were also conducted. Preliminary test results show promising real-time lane-detection performance compared with the Mobileye.



### Taskology: Utilizing Task Relations at Scale
- **Arxiv ID**: http://arxiv.org/abs/2005.07289v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2005.07289v2)
- **Published**: 2020-05-14 22:53:46+00:00
- **Updated**: 2021-03-17 04:10:16+00:00
- **Authors**: Yao Lu, Sören Pirk, Jan Dlabal, Anthony Brohan, Ankita Pasad, Zhao Chen, Vincent Casser, Anelia Angelova, Ariel Gordon
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition, 2021
- **Journal**: None
- **Summary**: Many computer vision tasks address the problem of scene understanding and are naturally interrelated e.g. object classification, detection, scene segmentation, depth estimation, etc. We show that we can leverage the inherent relationships among collections of tasks, as they are trained jointly, supervising each other through their known relationships via consistency losses. Furthermore, explicitly utilizing the relationships between tasks allows improving their performance while dramatically reducing the need for labeled data, and allows training with additional unsupervised or simulated data. We demonstrate a distributed joint training algorithm with task-level parallelism, which affords a high degree of asynchronicity and robustness. This allows learning across multiple tasks, or with large amounts of input data, at scale. We demonstrate our framework on subsets of the following collection of tasks: depth and normal prediction, semantic segmentation, 3D motion and ego-motion estimation, and object tracking and 3D detection in point clouds. We observe improved performance across these tasks, especially in the low-label regime.



### DeepFaceFlow: In-the-wild Dense 3D Facial Motion Estimation
- **Arxiv ID**: http://arxiv.org/abs/2005.07298v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2005.07298v1)
- **Published**: 2020-05-14 23:56:48+00:00
- **Updated**: 2020-05-14 23:56:48+00:00
- **Authors**: Mohammad Rami Koujan, Anastasios Roussos, Stefanos Zafeiriou
- **Comment**: to be published in the IEEE conference on Computer Vision and Pattern
  Recognition (CVPR). 2020
- **Journal**: None
- **Summary**: Dense 3D facial motion capture from only monocular in-the-wild pairs of RGB images is a highly challenging problem with numerous applications, ranging from facial expression recognition to facial reenactment. In this work, we propose DeepFaceFlow, a robust, fast, and highly-accurate framework for the dense estimation of 3D non-rigid facial flow between pairs of monocular images. Our DeepFaceFlow framework was trained and tested on two very large-scale facial video datasets, one of them of our own collection and annotation, with the aid of occlusion-aware and 3D-based loss function. We conduct comprehensive experiments probing different aspects of our approach and demonstrating its improved performance against state-of-the-art flow and 3D reconstruction methods. Furthermore, we incorporate our framework in a full-head state-of-the-art facial video synthesis method and demonstrate the ability of our method in better representing and capturing the facial dynamics, resulting in a highly-realistic facial video synthesis. Given registered pairs of images, our framework generates 3D flow maps at ~60 fps.



