# Arxiv Papers in cs.CV on 2020-07-02
### Automatic Detection of COVID-19 Cases on X-ray images Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2007.05494v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.05494v1)
- **Published**: 2020-07-02 00:46:13+00:00
- **Updated**: 2020-07-02 00:46:13+00:00
- **Authors**: Lucas P. Soares, Cesar P. Soares
- **Comment**: 6 pages, 4 figures
- **Journal**: None
- **Summary**: In recent months the world has been surprised by the rapid advance of COVID-19. In order to face this disease and minimize its socio-economic impacts, in addition to surveillance and treatment, diagnosis is a crucial procedure. However, the realization of this is hampered by the delay and the limited access to laboratory tests, demanding new strategies to carry out case triage. In this scenario, deep learning models are being proposed as a possible option to assist the diagnostic process based on chest X-ray and computed tomography images. Therefore, this research aims to automate the process of detecting COVID-19 cases from chest images, using convolutional neural networks (CNN) through deep learning techniques. The results can contribute to expand access to other forms of detection of COVID-19 and to speed up the process of identifying this disease. All databases used, the codes built, and the results obtained from the models' training are available for open access. This action facilitates the involvement of other researchers in enhancing these models since this can contribute to the improvement of results and, consequently, the progress in confronting COVID-19.



### Understanding Road Layout from Videos as a Whole
- **Arxiv ID**: http://arxiv.org/abs/2007.00822v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.00822v1)
- **Published**: 2020-07-02 00:59:15+00:00
- **Updated**: 2020-07-02 00:59:15+00:00
- **Authors**: Buyu Liu, Bingbing Zhuang, Samuel Schulter, Pan Ji, Manmohan Chandraker
- **Comment**: CVPR 2020
- **Journal**: None
- **Summary**: In this paper, we address the problem of inferring the layout of complex road scenes from video sequences. To this end, we formulate it as a top-view road attributes prediction problem and our goal is to predict these attributes for each frame both accurately and consistently. In contrast to prior work, we exploit the following three novel aspects: leveraging camera motions in videos, including context cuesand incorporating long-term video information. Specifically, we introduce a model that aims to enforce prediction consistency in videos. Our model consists of one LSTM and one Feature Transform Module (FTM). The former implicitly incorporates the consistency constraint with its hidden states, and the latter explicitly takes the camera motion into consideration when aggregating information along videos. Moreover, we propose to incorporate context information by introducing road participants, e.g. objects, into our model. When the entire video sequence is available, our model is also able to encode both local and global cues, e.g. information from both past and future frames. Experiments on two data sets show that: (1) Incorporating either globalor contextual cues improves the prediction accuracy and leveraging both gives the best performance. (2) Introducing the LSTM and FTM modules improves the prediction consistency in videos. (3) The proposed method outperforms the SOTA by a large margin.



### Uncertainty-Guided Efficient Interactive Refinement of Fetal Brain Segmentation from Stacks of MRI Slices
- **Arxiv ID**: http://arxiv.org/abs/2007.00833v1
- **DOI**: 10.1007/978-3-030-59719-1_28
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.00833v1)
- **Published**: 2020-07-02 01:50:42+00:00
- **Updated**: 2020-07-02 01:50:42+00:00
- **Authors**: Guotai Wang, Michael Aertsen, Jan Deprest, Sebastien Ourselin, Tom Vercauteren, Shaoting Zhang
- **Comment**: 10 pages, 4 figures, Accepted by MICCAI 2020
- **Journal**: None
- **Summary**: Segmentation of the fetal brain from stacks of motion-corrupted fetal MRI slices is important for motion correction and high-resolution volume reconstruction. Although Convolutional Neural Networks (CNNs) have been widely used for automatic segmentation of the fetal brain, their results may still benefit from interactive refinement for challenging slices. To improve the efficiency of interactive refinement process, we propose an Uncertainty-Guided Interactive Refinement (UGIR) framework. We first propose a grouped convolution-based CNN to obtain multiple automatic segmentation predictions with uncertainty estimation in a single forward pass, then guide the user to provide interactions only in a subset of slices with the highest uncertainty. A novel interactive level set method is also proposed to obtain a refined result given the initial segmentation and user interactions. Experimental results show that: (1) our proposed CNN obtains uncertainty estimation in real time which correlates well with mis-segmentations, (2) the proposed interactive level set is effective and efficient for refinement, (3) UGIR obtains accurate refinement results with around 30% improvement of efficiency by using uncertainty to guide user interactions. Our code is available online.



### Surface Denoising based on Normal Filtering in a Robust Statistics Framework
- **Arxiv ID**: http://arxiv.org/abs/2007.00842v1
- **DOI**: 10.1007/978-981-16-5576-0_6
- **Categories**: **cs.GR**, cs.CG, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.00842v1)
- **Published**: 2020-07-02 02:31:24+00:00
- **Updated**: 2020-07-02 02:31:24+00:00
- **Authors**: Sunil Kumar Yadav, Martin Skrodzki, Eric Zimmermann, Konrad Polthier
- **Comment**: In: Cheng, J., Dinghua, X., Saeki, O., Shirai, T. (eds) Proceedings
  of the Forum (2021)
- **Journal**: None
- **Summary**: During a surface acquisition process using 3D scanners, noise is inevitable and an important step in geometry processing is to remove these noise components from these surfaces (given as points-set or triangulated mesh). The noise-removal process (denoising) can be performed by filtering the surface normals first and by adjusting the vertex positions according to filtered normals afterwards. Therefore, in many available denoising algorithms, the computation of noise-free normals is a key factor. A variety of filters have been introduced for noise-removal from normals, with different focus points like robustness against outliers or large amplitude of noise. Although these filters are performing well in different aspects, a unified framework is missing to establish the relation between them and to provide a theoretical analysis beyond the performance of each method.   In this paper, we introduce such a framework to establish relations between a number of widely-used nonlinear filters for face normals in mesh denoising and vertex normals in point set denoising. We cover robust statistical estimation with M-smoothers and their application to linear and non-linear normal filtering. Although these methods originate in different mathematical theories - which include diffusion-, bilateral-, and directional curvature-based algorithms - we demonstrate that all of them can be cast into a unified framework of robust statistics using robust error norms and their corresponding influence functions. This unification contributes to a better understanding of the individual methods and their relations with each other. Furthermore, the presented framework provides a platform for new techniques to combine the advantages of known filters and to compare them with available methods.



### Low-light Environment Neural Surveillance
- **Arxiv ID**: http://arxiv.org/abs/2007.00843v1
- **DOI**: 10.1109/MLSP49062.2020.9231894
- **Categories**: **cs.CV**, cs.LG, I.4.9; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2007.00843v1)
- **Published**: 2020-07-02 02:45:41+00:00
- **Updated**: 2020-07-02 02:45:41+00:00
- **Authors**: Michael Potter, Henry Gridley, Noah Lichtenstein, Kevin Hines, John Nguyen, Jacob Walsh
- **Comment**: Pre-print, accepted to IEEE International Workshop on Machine
  Learning for Signal Processing 2020 Conference Proceedings. Code and dataset
  are available at https://github.com/mcgridles/
- **Journal**: None
- **Summary**: We design and implement an end-to-end system for real-time crime detection in low-light environments. Unlike Closed-Circuit Television, which performs reactively, the Low-Light Environment Neural Surveillance provides real time crime alerts. The system uses a low-light video feed processed in real-time by an optical-flow network, spatial and temporal networks, and a Support Vector Machine to identify shootings, assaults, and thefts. We create a low-light action-recognition dataset, LENS-4, which will be publicly available. An IoT infrastructure set up via Amazon Web Services interprets messages from the local board hosting the camera for action recognition and parses the results in the cloud to relay messages. The system achieves 71.5% accuracy at 20 FPS. The user interface is a mobile app which allows local authorities to receive notifications and to view a video of the crime scene. Citizens have a public app which enables law enforcement to push crime alerts based on user proximity.



### MSA-MIL: A deep residual multiple instance learning model based on multi-scale annotation for classification and visualization of glomerular spikes
- **Arxiv ID**: http://arxiv.org/abs/2007.00858v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2007.00858v2)
- **Published**: 2020-07-02 03:49:44+00:00
- **Updated**: 2020-07-18 17:04:28+00:00
- **Authors**: Yilin Chen, Ming Li, Yongfei Wu, Xueyu Liu, Fang Hao, Daoxiang Zhou, Xiaoshuang Zhou, Chen Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Membranous nephropathy (MN) is a frequent type of adult nephrotic syndrome, which has a high clinical incidence and can cause various complications. In the biopsy microscope slide of membranous nephropathy, spikelike projections on the glomerular basement membrane is a prominent feature of the MN. However, due to the whole biopsy slide contains large number of glomeruli, and each glomerulus includes many spike lesions, the pathological feature of the spikes is not obvious. It thus is time-consuming for doctors to diagnose glomerulus one by one and is difficult for pathologists with less experience to diagnose. In this paper, we establish a visualized classification model based on the multi-scale annotation multi-instance learning (MSA-MIL) to achieve glomerular classification and spikes visualization. The MSA-MIL model mainly involves three parts. Firstly, U-Net is used to extract the region of the glomeruli to ensure that the features learned by the succeeding algorithm are focused inside the glomeruli itself. Secondly, we use MIL to train an instance-level classifier combined with MSA method to enhance the learning ability of the network by adding a location-level labeled reinforced dataset, thereby obtaining an example-level feature representation with rich semantics. Lastly, the predicted scores of each tile in the image are summarized to obtain glomerular classification and visualization of the classification results of the spikes via the usage of sliding window method. The experimental results confirm that the proposed MSA-MIL model can effectively and accurately classify normal glomeruli and spiked glomerulus and visualize the position of spikes in the glomerulus. Therefore, the proposed model can provide a good foundation for assisting the clinical doctors to diagnose the glomerular membranous nephropathy.



### An encoder-decoder-based method for COVID-19 lung infection segmentation
- **Arxiv ID**: http://arxiv.org/abs/2007.00861v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.00861v2)
- **Published**: 2020-07-02 04:02:03+00:00
- **Updated**: 2020-07-04 20:00:32+00:00
- **Authors**: Omar Elharrouss, Nandhini Subramanian, Somaya Al-Maadeed
- **Comment**: None
- **Journal**: None
- **Summary**: The novelty of the COVID-19 disease and the speed of spread has created a colossal chaos, impulse among researchers worldwide to exploit all the resources and capabilities to understand and analyze characteristics of the coronavirus in term of the ways it spreads and virus incubation time. For that, the existing medical features like CT and X-ray images are used. For example, CT-scan images can be used for the detection of lung infection. But the challenges of these features such as the quality of the image and infection characteristics limitate the effectiveness of these features. Using artificial intelligence (AI) tools and computer vision algorithms, the accuracy of detection can be more accurate and can help to overcome these issues. This paper proposes a multi-task deep-learning-based method for lung infection segmentation using CT-scan images. Our proposed method starts by segmenting the lung regions that can be infected. Then, segmenting the infections in these regions. Also, to perform a multi-class segmentation the proposed model is trained using the two-stream inputs. The multi-task learning used in this paper allows us to overcome shortage of labeled data. Also, the multi-input stream allows the model to do the learning on many features that can improve the results. To evaluate the proposed method, many features have been used. Also, from the experiments, the proposed method can segment lung infections with a high degree performance even with shortage of data and labeled images. In addition, comparing with the state-of-the-art method our method achieves good performance results.



### Noticing Motion Patterns: Temporal CNN with a Novel Convolution Operator for Human Trajectory Prediction
- **Arxiv ID**: http://arxiv.org/abs/2007.00862v4
- **DOI**: 10.1109/LRA.2020.3047771
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2007.00862v4)
- **Published**: 2020-07-02 04:07:01+00:00
- **Updated**: 2021-08-30 21:14:52+00:00
- **Authors**: Dapeng Zhao, Jean Oh
- **Comment**: Published by IEEE Robotics and Automation Letters (RA-L)
  (https://ieeexplore.ieee.org/abstract/document/9309403)
- **Journal**: IEEE Robotics and Automation Letters, vol. 6, no. 2, pp. 628-634,
  April 2021
- **Summary**: We propose a Convolutional Neural Network-based approach to learn, detect,and extract patterns in sequential trajectory data, known here as Social Pattern Extraction Convolution (Social-PEC). A set of experiments carried out on the human trajectory prediction problem shows that our model performs comparably to the state of the art and outperforms in some cases. More importantly,the proposed approach unveils the obscurity in the previous use of pooling layer, presenting a way to intuitively explain the decision-making process.



### Hardware Acceleration of Sparse and Irregular Tensor Computations of ML Models: A Survey and Insights
- **Arxiv ID**: http://arxiv.org/abs/2007.00864v2
- **DOI**: 10.1109/JPROC.2021.3098483
- **Categories**: **cs.AR**, cs.CV, cs.DC, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2007.00864v2)
- **Published**: 2020-07-02 04:08:40+00:00
- **Updated**: 2021-07-22 17:41:44+00:00
- **Authors**: Shail Dave, Riyadh Baghdadi, Tony Nowatzki, Sasikanth Avancha, Aviral Shrivastava, Baoxin Li
- **Comment**: Accepted for publication in Proceedings of the IEEE
- **Journal**: None
- **Summary**: Machine learning (ML) models are widely used in many important domains. For efficiently processing these computational- and memory-intensive applications, tensors of these over-parameterized models are compressed by leveraging sparsity, size reduction, and quantization of tensors. Unstructured sparsity and tensors with varying dimensions yield irregular computation, communication, and memory access patterns; processing them on hardware accelerators in a conventional manner does not inherently leverage acceleration opportunities. This paper provides a comprehensive survey on the efficient execution of sparse and irregular tensor computations of ML models on hardware accelerators. In particular, it discusses enhancement modules in the architecture design and the software support; categorizes different hardware designs and acceleration techniques and analyzes them in terms of hardware and execution costs; analyzes achievable accelerations for recent DNNs; highlights further opportunities in terms of hardware/software/model co-design optimizations (inter/intra-module). The takeaways from this paper include: understanding the key challenges in accelerating sparse, irregular-shaped, and quantized tensors; understanding enhancements in accelerator systems for supporting their efficient computations; analyzing trade-offs in opting for a specific design choice for encoding, storing, extracting, communicating, computing, and load-balancing the non-zeros; understanding how structured sparsity can improve storage efficiency and balance computations; understanding how to compile and map models with sparse tensors on the accelerators; understanding recent design trends for efficient accelerations and further opportunities.



### Image Analysis Based on Nonnegative/Binary Matrix Factorization
- **Arxiv ID**: http://arxiv.org/abs/2007.00889v1
- **DOI**: 10.7566/JPSJ.89.085001
- **Categories**: **cs.CV**, cond-mat.stat-mech
- **Links**: [PDF](http://arxiv.org/pdf/2007.00889v1)
- **Published**: 2020-07-02 05:22:36+00:00
- **Updated**: 2020-07-02 05:22:36+00:00
- **Authors**: Hinako Asaoka, Kazue Kudo
- **Comment**: 3 pages, 1 figure
- **Journal**: J. Phys. Soc. Jpn. 89, 085001 (2020)
- **Summary**: Using nonnegative/binary matrix factorization (NBMF), a matrix can be decomposed into a nonnegative matrix and a binary matrix. Our analysis of facial images, based on NBMF and using the Fujitsu Digital Annealer, leads to successful image reconstruction and image classification. The NBMF algorithm converges in fewer iterations than those required for the convergence of nonnegative matrix factorization (NMF), although both techniques perform comparably in image classification.



### ACFD: Asymmetric Cartoon Face Detector
- **Arxiv ID**: http://arxiv.org/abs/2007.00899v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.00899v1)
- **Published**: 2020-07-02 05:57:34+00:00
- **Updated**: 2020-07-02 05:57:34+00:00
- **Authors**: Bin Zhang, Jian Li, Yabiao Wang, Zhipeng Cui, Yili Xia, Chengjie Wang, Jilin Li, Feiyue Huang
- **Comment**: 1st place of IJCAI 2020 iCartoon Face Challenge (Detection Track)
- **Journal**: None
- **Summary**: Cartoon face detection is a more challenging task than human face detection due to many difficult scenarios is involved. Aiming at the characteristics of cartoon faces, such as huge differences within the intra-faces, in this paper, we propose an asymmetric cartoon face detector, named ACFD. Specifically, it consists of the following modules: a novel backbone VoVNetV3 comprised of several asymmetric one-shot aggregation modules (AOSA), asymmetric bi-directional feature pyramid network (ABi-FPN), dynamic anchor match strategy (DAM) and the corresponding margin binary classification loss (MBC). In particular, to generate features with diverse receptive fields, multi-scale pyramid features are extracted by VoVNetV3, and then fused and enhanced simultaneously by ABi-FPN for handling the faces in some extreme poses and have disparate aspect ratios. Besides, DAM is used to match enough high-quality anchors for each face, and MBC is for the strong power of discrimination. With the effectiveness of these modules, our ACFD achieves the 1st place on the detection track of 2020 iCartoon Face Challenge under the constraints of model size 200MB, inference time 50ms per image, and without any pretrained models.



### The Impact of Explanations on AI Competency Prediction in VQA
- **Arxiv ID**: http://arxiv.org/abs/2007.00900v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2007.00900v1)
- **Published**: 2020-07-02 06:11:28+00:00
- **Updated**: 2020-07-02 06:11:28+00:00
- **Authors**: Kamran Alipour, Arijit Ray, Xiao Lin, Jurgen P. Schulze, Yi Yao, Giedrius T. Burachas
- **Comment**: Submitted to HCCAI 2020
- **Journal**: None
- **Summary**: Explainability is one of the key elements for building trust in AI systems. Among numerous attempts to make AI explainable, quantifying the effect of explanations remains a challenge in conducting human-AI collaborative tasks. Aside from the ability to predict the overall behavior of AI, in many applications, users need to understand an AI agent's competency in different aspects of the task domain. In this paper, we evaluate the impact of explanations on the user's mental model of AI agent competency within the task of visual question answering (VQA). We quantify users' understanding of competency, based on the correlation between the actual system performance and user rankings. We introduce an explainable VQA system that uses spatial and object features and is powered by the BERT language model. Each group of users sees only one kind of explanation to rank the competencies of the VQA model. The proposed model is evaluated through between-subject experiments to probe explanations' impact on the user's perception of competency. The comparison between two VQA models shows BERT based explanations and the use of object features improve the user's prediction of the model's competencies.



### A deep primal-dual proximal network for image restoration
- **Arxiv ID**: http://arxiv.org/abs/2007.00959v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.00959v3)
- **Published**: 2020-07-02 08:29:52+00:00
- **Updated**: 2021-12-20 14:12:15+00:00
- **Authors**: Mingyuan Jiu, Nelly Pustelnik
- **Comment**: None
- **Journal**: None
- **Summary**: Image restoration remains a challenging task in image processing. Numerous methods tackle this problem, often solved by minimizing a non-smooth penalized co-log-likelihood function. Although the solution is easily interpretable with theoretic guarantees, its estimation relies on an optimization process that can take time. Considering the research effort in deep learning for image classification and segmentation, this class of methods offers a serious alternative to perform image restoration but stays challenging to solve inverse problems. In this work, we design a deep network, named DeepPDNet, built from primal-dual proximal iterations associated with the minimization of a standard penalized likelihood with an analysis prior, allowing us to take advantage of both worlds.   We reformulate a specific instance of the Condat-Vu primal-dual hybrid gradient (PDHG) algorithm as a deep network with fixed layers. The learned parameters are both the PDHG algorithm step-sizes and the analysis linear operator involved in the penalization (including the regularization parameter). These parameters are allowed to vary from a layer to another one. Two different learning strategies: "Full learning" and "Partial learning" are proposed, the first one is the most efficient numerically while the second one relies on standard constraints ensuring convergence in the standard PDHG iterations. Moreover, global and local sparse analysis prior are studied to seek a better feature representation. We apply the proposed methods to image restoration on the MNIST and BSD68 datasets and to single image super-resolution on the BSD100 and SET14 datasets. Extensive results show that the proposed DeepPDNet demonstrates excellent performance on the MNIST and the more complex BSD68, BSD100, and SET14 datasets for image restoration and single image super-resolution task.



### Iterative Bounding Box Annotation for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2007.00961v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.00961v1)
- **Published**: 2020-07-02 08:40:12+00:00
- **Updated**: 2020-07-02 08:40:12+00:00
- **Authors**: Bishwo Adhikari, Heikki Huttunen
- **Comment**: Accepted at ICPR 2020
- **Journal**: None
- **Summary**: Manual annotation of bounding boxes for object detection in digital images is tedious, and time and resource consuming. In this paper, we propose a semi-automatic method for efficient bounding box annotation. The method trains the object detector iteratively on small batches of labeled images and learns to propose bounding boxes for the next batch, after which the human annotator only needs to correct possible errors. We propose an experimental setup for simulating the human actions and use it for comparing different iteration strategies, such as the order in which the data is presented to the annotator. We experiment on our method with three datasets and show that it can reduce the human annotation effort significantly, saving up to 75% of total manual annotation work.



### MPLP: Learning a Message Passing Learning Protocol
- **Arxiv ID**: http://arxiv.org/abs/2007.00970v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.00970v2)
- **Published**: 2020-07-02 09:03:14+00:00
- **Updated**: 2020-07-03 10:28:35+00:00
- **Authors**: Ettore Randazzo, Eyvind Niklasson, Alexander Mordvintsev
- **Comment**: Code at
  https://github.com/google-research/self-organising-systems/tree/master/mplp;
  code base link fixed
- **Journal**: None
- **Summary**: We present a novel method for learning the weights of an artificial neural network - a Message Passing Learning Protocol (MPLP). In MPLP, we abstract every operations occurring in ANNs as independent agents. Each agent is responsible for ingesting incoming multidimensional messages from other agents, updating its internal state, and generating multidimensional messages to be passed on to neighbouring agents. We demonstrate the viability of MPLP as opposed to traditional gradient-based approaches on simple feed-forward neural networks, and present a framework capable of generalizing to non-traditional neural network architectures. MPLP is meta learned using end-to-end gradient-based meta-optimisation. We further discuss the observed properties of MPLP and hypothesize its applicability on various fields of deep learning.



### PerceptionGAN: Real-world Image Construction from Provided Text through Perceptual Understanding
- **Arxiv ID**: http://arxiv.org/abs/2007.00977v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.LG, 68Txx, 68-XX, I.4; I.5; I.3; I.2
- **Links**: [PDF](http://arxiv.org/pdf/2007.00977v1)
- **Published**: 2020-07-02 09:23:08+00:00
- **Updated**: 2020-07-02 09:23:08+00:00
- **Authors**: Kanish Garg, Ajeet kumar Singh, Dorien Herremans, Brejesh Lall
- **Comment**: Proceedings of IEEE International Conference on Imaging, Vision &
  Pattern Recognition, (IVPR 2020, Japan)
- **Journal**: Proceedings of IEEE International Conference on Imaging, Vision &
  Pattern Recognition, (IVPR 2020, Japan)
- **Summary**: Generating an image from a provided descriptive text is quite a challenging task because of the difficulty in incorporating perceptual information (object shapes, colors, and their interactions) along with providing high relevancy related to the provided text. Current methods first generate an initial low-resolution image, which typically has irregular object shapes, colors, and interaction between objects. This initial image is then improved by conditioning on the text. However, these methods mainly address the problem of using text representation efficiently in the refinement of the initially generated image, while the success of this refinement process depends heavily on the quality of the initially generated image, as pointed out in the DM-GAN paper. Hence, we propose a method to provide good initialized images by incorporating perceptual understanding in the discriminator module. We improve the perceptual information at the first stage itself, which results in significant improvement in the final generated image. In this paper, we have applied our approach to the novel StackGAN architecture. We then show that the perceptual information included in the initial image is improved while modeling image distribution at multiple stages. Finally, we generated realistic multi-colored images conditioned by text. These images have good quality along with containing improved basic perceptual information. More importantly, the proposed method can be integrated into the pipeline of other state-of-the-art text-based-image-generation models to generate initial low-resolution images. We also worked on improving the refinement process in StackGAN by augmenting the third stage of the generator-discriminator pair in the StackGAN architecture. Our experimental analysis and comparison with the state-of-the-art on a large but sparse dataset MS COCO further validate the usefulness of our proposed approach.



### RGB-D-based Framework to Acquire, Visualize and Measure the Human Body for Dietetic Treatments
- **Arxiv ID**: http://arxiv.org/abs/2007.00981v1
- **DOI**: 10.3390/s20133690
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.00981v1)
- **Published**: 2020-07-02 09:30:47+00:00
- **Updated**: 2020-07-02 09:30:47+00:00
- **Authors**: Andrés Fuster-Guilló, Jorge Azorín-López, Marcelo Saval-Calvo, Juan Miguel Castillo-Zaragoza, Nahuel Garcia-DUrso, Robert B Fisher
- **Comment**: None
- **Journal**: Sensors, 20(13), 3690 (2020)
- **Summary**: This research aims to improve dietetic-nutritional treatment using state-of-the-art RGB-D sensors and virtual reality (VR) technology. Recent studies show that adherence to treatment can be improved using multimedia technologies. However, there are few studies using 3D data and VR technologies for this purpose. On the other hand, obtaining 3D measurements of the human body and analyzing them over time (4D) in patients undergoing dietary treatment is a challenging field. The main contribution of the work is to provide a framework to study the effect of 4D body model visualization on adherence to obesity treatment. The system can obtain a complete 3D model of a body using low-cost technology, allowing future straightforward transference with sufficient accuracy and realistic visualization, enabling the analysis of the evolution (4D) of the shape during the treatment of obesity. The 3D body models will be used for studying the effect of visualization on adherence to obesity treatment using 2D and VR devices. Moreover, we will use the acquired 3D models to obtain measurements of the body. An analysis of the accuracy of the proposed methods for obtaining measurements with both synthetic and real objects has been carried out.



### Rethinking Channel Dimensions for Efficient Model Design
- **Arxiv ID**: http://arxiv.org/abs/2007.00992v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.00992v3)
- **Published**: 2020-07-02 10:01:12+00:00
- **Updated**: 2021-06-08 06:14:03+00:00
- **Authors**: Dongyoon Han, Sangdoo Yun, Byeongho Heo, YoungJoon Yoo
- **Comment**: 13 pages, 8 figures, CVPR 2021
- **Journal**: None
- **Summary**: Designing an efficient model within the limited computational cost is challenging. We argue the accuracy of a lightweight model has been further limited by the design convention: a stage-wise configuration of the channel dimensions, which looks like a piecewise linear function of the network stage. In this paper, we study an effective channel dimension configuration towards better performance than the convention. To this end, we empirically study how to design a single layer properly by analyzing the rank of the output feature. We then investigate the channel configuration of a model by searching network architectures concerning the channel configuration under the computational cost restriction. Based on the investigation, we propose a simple yet effective channel configuration that can be parameterized by the layer index. As a result, our proposed model following the channel parameterization achieves remarkable performance on ImageNet classification and transfer learning tasks including COCO object detection, COCO instance segmentation, and fine-grained classifications. Code and ImageNet pretrained models are available at https://github.com/clovaai/rexnet.



### Grading video interviews with fairness considerations
- **Arxiv ID**: http://arxiv.org/abs/2007.05461v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.05461v1)
- **Published**: 2020-07-02 10:06:13+00:00
- **Updated**: 2020-07-02 10:06:13+00:00
- **Authors**: Abhishek Singhania, Abhishek Unnam, Varun Aggarwal
- **Comment**: Submitted to NeurIPS2020
- **Journal**: None
- **Summary**: There has been considerable interest in predicting human emotions and traits using facial images and videos. Lately, such work has come under criticism for poor labeling practices, inconclusive prediction results and fairness considerations. We present a careful methodology to automatically derive social skills of candidates based on their video response to interview questions. We, for the first time, include video data from multiple countries encompassing multiple ethnicities. Also, the videos were rated by individuals from multiple racial backgrounds, following several best practices, to achieve a consensus and unbiased measure of social skills. We develop two machine-learning models to predict social skills. The first model employs expert-guidance to use plausibly causal features. The second uses deep learning and depends solely on the empirical correlations present in the data. We compare errors of both these models, study the specificity of the models and make recommendations. We further analyze fairness by studying the errors of models by race and gender. We verify the usefulness of our models by determining how well they predict interview outcomes for candidates. Overall, the study provides strong support for using artificial intelligence for video interview scoring, while taking care of fairness and ethical considerations.



### PGD-UNet: A Position-Guided Deformable Network for Simultaneous Segmentation of Organs and Tumors
- **Arxiv ID**: http://arxiv.org/abs/2007.01001v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2007.01001v1)
- **Published**: 2020-07-02 10:23:57+00:00
- **Updated**: 2020-07-02 10:23:57+00:00
- **Authors**: Ziqiang Li, Hong Pan, Yaping Zhu, A. K. Qin
- **Comment**: Accepted by the 2020 International Joint Conference on Neural
  Networks (IJCNN 2020)
- **Journal**: None
- **Summary**: Precise segmentation of organs and tumors plays a crucial role in clinical applications. It is a challenging task due to the irregular shapes and various sizes of organs and tumors as well as the significant class imbalance between the anatomy of interest (AOI) and the background region. In addition, in most situation tumors and normal organs often overlap in medical images, but current approaches fail to delineate both tumors and organs accurately. To tackle such challenges, we propose a position-guided deformable UNet, namely PGD-UNet, which exploits the spatial deformation capabilities of deformable convolution to deal with the geometric transformation of both organs and tumors. Position information is explicitly encoded into the network to enhance the capabilities of deformation. Meanwhile, we introduce a new pooling module to preserve position information lost in conventional max-pooling operation. Besides, due to unclear boundaries between different structures as well as the subjectivity of annotations, labels are not necessarily accurate for medical image segmentation tasks. It may cause the overfitting of the trained network due to label noise. To address this issue, we formulate a novel loss function to suppress the influence of potential label noise on the training process. Our method was evaluated on two challenging segmentation tasks and achieved very promising segmentation accuracy in both tasks.



### A Novel DNN Training Framework via Data Sampling and Multi-Task Optimization
- **Arxiv ID**: http://arxiv.org/abs/2007.01016v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.01016v1)
- **Published**: 2020-07-02 10:58:57+00:00
- **Updated**: 2020-07-02 10:58:57+00:00
- **Authors**: Boyu Zhang, A. K. Qin, Hong Pan, Timos Sellis
- **Comment**: Accepted by the 2020 International Joint Conference on Neural
  Networks (IJCNN 2020)
- **Journal**: None
- **Summary**: Conventional DNN training paradigms typically rely on one training set and one validation set, obtained by partitioning an annotated dataset used for training, namely gross training set, in a certain way. The training set is used for training the model while the validation set is used to estimate the generalization performance of the trained model as the training proceeds to avoid over-fitting. There exist two major issues in this paradigm. Firstly, the validation set may hardly guarantee an unbiased estimate of generalization performance due to potential mismatching with test data. Secondly, training a DNN corresponds to solve a complex optimization problem, which is prone to getting trapped into inferior local optima and thus leads to undesired training results. To address these issues, we propose a novel DNN training framework. It generates multiple pairs of training and validation sets from the gross training set via random splitting, trains a DNN model of a pre-specified structure on each pair while making the useful knowledge (e.g., promising network parameters) obtained from one model training process to be transferred to other model training processes via multi-task optimization, and outputs the best, among all trained models, which has the overall best performance across the validation sets from all pairs. The knowledge transfer mechanism featured in this new framework can not only enhance training effectiveness by helping the model training process to escape from local optima but also improve on generalization performance via implicit regularization imposed on one model training process from other model training processes. We implement the proposed framework, parallelize the implementation on a GPU cluster, and apply it to train several widely used DNN models. Experimental results demonstrate the superiority of the proposed framework over the conventional training paradigm.



### Spectral-Spatial Recurrent-Convolutional Networks for In-Vivo Hyperspectral Tumor Type Classification
- **Arxiv ID**: http://arxiv.org/abs/2007.01042v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01042v1)
- **Published**: 2020-07-02 12:00:53+00:00
- **Updated**: 2020-07-02 12:00:53+00:00
- **Authors**: Marcel Bengs, Nils Gessert, Wiebke Laffers, Dennis Eggert, Stephan Westermann, Nina A. Mueller, Andreas O. H. Gerstner, Christian Betz, Alexander Schlaefer
- **Comment**: Accepted at MICCAI 2020
- **Journal**: None
- **Summary**: Early detection of cancerous tissue is crucial for long-term patient survival. In the head and neck region, a typical diagnostic procedure is an endoscopic intervention where a medical expert manually assesses tissue using RGB camera images. While healthy and tumor regions are generally easier to distinguish, differentiating benign and malignant tumors is very challenging. This requires an invasive biopsy, followed by histological evaluation for diagnosis. Also, during tumor resection, tumor margins need to be verified by histological analysis. To avoid unnecessary tissue resection, a non-invasive, image-based diagnostic tool would be very valuable. Recently, hyperspectral imaging paired with deep learning has been proposed for this task, demonstrating promising results on ex-vivo specimens. In this work, we demonstrate the feasibility of in-vivo tumor type classification using hyperspectral imaging and deep learning. We analyze the value of using multiple hyperspectral bands compared to conventional RGB images and we study several machine learning models' ability to make use of the additional spectral information. Based on our insights, we address spectral and spatial processing using recurrent-convolutional models for effective spectral aggregating and spatial feature learning. Our best model achieves an AUC of 76.3%, significantly outperforming previous conventional and deep learning methods.



### 4D Spatio-Temporal Convolutional Networks for Object Position Estimation in OCT Volumes
- **Arxiv ID**: http://arxiv.org/abs/2007.01044v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01044v1)
- **Published**: 2020-07-02 12:02:20+00:00
- **Updated**: 2020-07-02 12:02:20+00:00
- **Authors**: Marcel Bengs, Nils Gessert, Alexander Schlaefer
- **Comment**: Accepted at CURAC 2020
- **Journal**: None
- **Summary**: Tracking and localizing objects is a central problem in computer-assisted surgery. Optical coherence tomography (OCT) can be employed as an optical tracking system, due to its high spatial and temporal resolution. Recently, 3D convolutional neural networks (CNNs) have shown promising performance for pose estimation of a marker object using single volumetric OCT images. While this approach relied on spatial information only, OCT allows for a temporal stream of OCT image volumes capturing the motion of an object at high volumes rates. In this work, we systematically extend 3D CNNs to 4D spatio-temporal CNNs to evaluate the impact of additional temporal information for marker object tracking. Across various architectures, our results demonstrate that using a stream of OCT volumes and employing 4D spatio-temporal convolutions leads to a 30% lower mean absolute error compared to single volume processing with 3D CNNs.



### Are there any 'object detectors' in the hidden layers of CNNs trained to identify objects or scenes?
- **Arxiv ID**: http://arxiv.org/abs/2007.01062v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV, 68-T02, I.2.6; I.2.10; I.4.10; I.4.0; J.4
- **Links**: [PDF](http://arxiv.org/pdf/2007.01062v1)
- **Published**: 2020-07-02 12:33:37+00:00
- **Updated**: 2020-07-02 12:33:37+00:00
- **Authors**: Ella M. Gale, Nicholas Martin, Ryan Blything, Anh Nguyen, Jeffrey S. Bowers
- **Comment**: Published in Vision Research 2020, 19 pages, 8 figures
- **Journal**: Vision Research, 2020
- **Summary**: Various methods of measuring unit selectivity have been developed with the aim of better understanding how neural networks work. But the different measures provide divergent estimates of selectivity, and this has led to different conclusions regarding the conditions in which selective object representations are learned and the functional relevance of these representations. In an attempt to better characterize object selectivity, we undertake a comparison of various selectivity measures on a large set of units in AlexNet, including localist selectivity, precision, class-conditional mean activity selectivity (CCMAS), network dissection,the human interpretation of activation maximization (AM) images, and standard signal-detection measures. We find that the different measures provide different estimates of object selectivity, with precision and CCMAS measures providing misleadingly high estimates. Indeed, the most selective units had a poor hit-rate or a high false-alarm rate (or both) in object classification, making them poor object detectors. We fail to find any units that are even remotely as selective as the 'grandmother cell' units reported in recurrent neural networks. In order to generalize these results, we compared selectivity measures on units in VGG-16 and GoogLeNet trained on the ImageNet or Places-365 datasets that have been described as 'object detectors'. Again, we find poor hit-rates and high false-alarm rates for object classification. We conclude that signal-detection measures provide a better assessment of single-unit selectivity compared to common alternative approaches, and that deep convolutional networks of image classification do not learn object detectors in their hidden layers.



### Attention-Oriented Action Recognition for Real-Time Human-Robot Interaction
- **Arxiv ID**: http://arxiv.org/abs/2007.01065v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01065v1)
- **Published**: 2020-07-02 12:41:28+00:00
- **Updated**: 2020-07-02 12:41:28+00:00
- **Authors**: Ziyang Song, Ziyi Yin, Zejian Yuan, Chong Zhang, Wanchao Chi, Yonggen Ling, Shenghao Zhang
- **Comment**: 8 pages, 8 figures
- **Journal**: None
- **Summary**: Despite the notable progress made in action recognition tasks, not much work has been done in action recognition specifically for human-robot interaction. In this paper, we deeply explore the characteristics of the action recognition task in interaction scenarios and propose an attention-oriented multi-level network framework to meet the need for real-time interaction. Specifically, a Pre-Attention network is employed to roughly focus on the interactor in the scene at low resolution firstly and then perform fine-grained pose estimation at high resolution. The other compact CNN receives the extracted skeleton sequence as input for action recognition, utilizing attention-like mechanisms to capture local spatial-temporal patterns and global semantic information effectively. To evaluate our approach, we construct a new action dataset specially for the recognition task in interaction scenarios. Experimental results on our dataset and high efficiency (112 fps at 640 x 480 RGBD) on the mobile computing platform (Nvidia Jetson AGX Xavier) demonstrate excellent applicability of our method on action recognition in real-time human-robot interaction.



### Scene Graph Reasoning for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2007.01072v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01072v1)
- **Published**: 2020-07-02 13:02:54+00:00
- **Updated**: 2020-07-02 13:02:54+00:00
- **Authors**: Marcel Hildebrandt, Hang Li, Rajat Koner, Volker Tresp, Stephan Günnemann
- **Comment**: ICML Workshop Graph Representation Learning and Beyond (GRL+)
- **Journal**: None
- **Summary**: Visual question answering is concerned with answering free-form questions about an image. Since it requires a deep linguistic understanding of the question and the ability to associate it with various objects that are present in the image, it is an ambitious task and requires techniques from both computer vision and natural language processing. We propose a novel method that approaches the task by performing context-driven, sequential reasoning based on the objects and their semantic and spatial relationships present in the scene. As a first step, we derive a scene graph which describes the objects in the image, as well as their attributes and their mutual relationships. A reinforcement agent then learns to autonomously navigate over the extracted scene graph to generate paths, which are then the basis for deriving answers. We conduct a first experimental study on the challenging GQA dataset with manually curated scene graphs, where our method almost reaches the level of human performance.



### Mining and Tailings Dam Detection In Satellite Imagery Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2007.01076v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01076v1)
- **Published**: 2020-07-02 13:08:39+00:00
- **Updated**: 2020-07-02 13:08:39+00:00
- **Authors**: Remis Balaniuk, Olga Isupova, Steven Reece
- **Comment**: Preprint submitted to Remote Sensing of Environment
- **Journal**: None
- **Summary**: This work explores the combination of free cloud computing, free open-source software, and deep learning methods to analyse a real, large-scale problem: the automatic country-wide identification and classification of surface mines and mining tailings dams in Brazil. Locations of officially registered mines and dams were obtained from the Brazilian government open data resource. Multispectral Sentinel-2 satellite imagery, obtained and processed at the Google Earth Engine platform, was used to train and test deep neural networks using the TensorFlow 2 API and Google Colab platform. Fully Convolutional Neural Networks were used in an innovative way, to search for unregistered ore mines and tailing dams in large areas of the Brazilian territory. The efficacy of the approach is demonstrated by the discovery of 263 mines that do not have an official mining concession. This exploratory work highlights the potential of a set of new technologies, freely available, for the construction of low cost data science tools that have high social impact. At the same time, it discusses and seeks to suggest practical solutions for the complex and serious problem of illegal mining and the proliferation of tailings dams, which pose high risks to the population and the environment, especially in developing countries. Code is made publicly available at: https://github.com/remis/mining-discovery-with-deep-learning.



### Estimating Blink Probability for Highlight Detection in Figure Skating Videos
- **Arxiv ID**: http://arxiv.org/abs/2007.01089v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2007.01089v1)
- **Published**: 2020-07-02 13:23:03+00:00
- **Updated**: 2020-07-02 13:23:03+00:00
- **Authors**: Tamami Nakano, Atsuya Sakata, Akihiro Kishimoto
- **Comment**: None
- **Journal**: None
- **Summary**: Highlight detection in sports videos has a broad viewership and huge commercial potential. It is thus imperative to detect highlight scenes more suitably for human interest with high temporal accuracy. Since people instinctively suppress blinks during attention-grabbing events and synchronously generate blinks at attention break points in videos, the instantaneous blink rate can be utilized as a highly accurate temporal indicator of human interest. Therefore, in this study, we propose a novel, automatic highlight detection method based on the blink rate. The method trains a one-dimensional convolution network (1D-CNN) to assess blink rates at each video frame from the spatio-temporal pose features of figure skating videos. Experiments show that the method successfully estimates the blink rate in 94% of the video clips and predicts the temporal change in the blink rate around a jump event with high accuracy. Moreover, the method detects not only the representative athletic action, but also the distinctive artistic expression of figure skating performance as key frames. This suggests that the blink-rate-based supervised learning approach enables high-accuracy highlight detection that more closely matches human sensibility.



### Trace-Norm Adversarial Examples
- **Arxiv ID**: http://arxiv.org/abs/2007.01855v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01855v1)
- **Published**: 2020-07-02 13:37:19+00:00
- **Updated**: 2020-07-02 13:37:19+00:00
- **Authors**: Ehsan Kazemi, Thomas Kerdreux, Liqiang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: White box adversarial perturbations are sought via iterative optimization algorithms most often minimizing an adversarial loss on a $l_p$ neighborhood of the original image, the so-called distortion set. Constraining the adversarial search with different norms results in disparately structured adversarial examples. Here we explore several distortion sets with structure-enhancing algorithms. These new structures for adversarial examples, yet pervasive in optimization, are for instance a challenge for adversarial theoretical certification which again provides only $l_p$ certificates. Because adversarial robustness is still an empirical field, defense mechanisms should also reasonably be evaluated against differently structured attacks. Besides, these structured adversarial perturbations may allow for larger distortions size than their $l_p$ counter-part while remaining imperceptible or perceptible as natural slight distortions of the image. Finally, they allow some control on the generation of the adversarial perturbation, like (localized) bluriness.



### A Brief Review of Deep Multi-task Learning and Auxiliary Task Learning
- **Arxiv ID**: http://arxiv.org/abs/2007.01126v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01126v1)
- **Published**: 2020-07-02 14:23:39+00:00
- **Updated**: 2020-07-02 14:23:39+00:00
- **Authors**: Partoo Vafaeikia, Khashayar Namdar, Farzad Khalvati
- **Comment**: None
- **Journal**: None
- **Summary**: Multi-task learning (MTL) optimizes several learning tasks simultaneously and leverages their shared information to improve generalization and the prediction of the model for each task. Auxiliary tasks can be added to the main task to ultimately boost the performance. In this paper, we provide a brief review on the recent deep multi-task learning (dMTL) approaches followed by methods on selecting useful auxiliary tasks that can be used in dMTL to improve the performance of the model for the main task.



### Automatic Page Segmentation Without Decompressing the Run-Length Compressed Text Documents
- **Arxiv ID**: http://arxiv.org/abs/2007.01142v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01142v1)
- **Published**: 2020-07-02 14:29:35+00:00
- **Updated**: 2020-07-02 14:29:35+00:00
- **Authors**: Mohammed Javed, P. Nagabhushan
- **Comment**: Appeared in the Ph.D. Thesis (2016) of Dr. Mohammed Javed, entitled
  "On the Possibility of Processing Document Images in Compressed Domain" from
  Department of Studies in Computer Science, University of Mysore, Karnataka,
  India
- **Journal**: None
- **Summary**: Page segmentation is considered to be the crucial stage for the automatic analysis of documents with complex layouts. This has traditionally been carried out in uncompressed documents, although most of the documents in real life exist in a compressed form warranted by the requirement to make storage and transfer efficient. However, carrying out page segmentation directly in compressed documents without going through the stage of decompression is a challenging goal. This research paper proposes demonstrating the possibility of carrying out a page segmentation operation directly in the run-length data of the CCITT Group-3 compressed text document, which could be single- or multi-columned and might even have some text regions in the inverted text color mode. Therefore, before carrying out the segmentation of the text document into columns, each column into paragraphs, each paragraph into text lines, each line into words, and, finally, each word into characters, a pre-processing of the text document needs to be carried out. The pre-processing stage identifies the normal text regions and inverted text regions, and the inverted text regions are toggled to the normal mode. In the sequel to initiate column separation, a new strategy of incremental assimilation of white space runs in the vertical direction and the auto-estimation of certain related parameters is proposed. A procedure to realize column-segmentation employing these extracted parameters has been devised. Subsequently, what follows first is a two-level horizontal row separation process, which segments every column into paragraphs, and in turn, into text-lines. Then, there is a two-level vertical column separation process, which completes the separation into words and characters.



### JUMPS: Joints Upsampling Method for Pose Sequences
- **Arxiv ID**: http://arxiv.org/abs/2007.01151v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01151v4)
- **Published**: 2020-07-02 14:36:40+00:00
- **Updated**: 2020-10-14 15:00:49+00:00
- **Authors**: Lucas Mourot, François Le Clerc, Cédric Thébault, Pierre Hellier
- **Comment**: 8 pages, 7 figures, 2 tables
- **Journal**: None
- **Summary**: Human Pose Estimation is a low-level task useful forsurveillance, human action recognition, and scene understandingat large. It also offers promising perspectives for the animationof synthetic characters. For all these applications, and especiallythe latter, estimating the positions of many joints is desirablefor improved performance and realism. To this purpose, wepropose a novel method called JUMPS for increasing the numberof joints in 2D pose estimates and recovering occluded ormissing joints. We believe this is the first attempt to addressthe issue. We build on a deep generative model that combines aGenerative Adversarial Network (GAN) and an encoder. TheGAN learns the distribution of high-resolution human posesequences, the encoder maps the input low-resolution sequencesto its latent space. Inpainting is obtained by computing the latentrepresentation whose decoding by the GAN generator optimallymatches the joints locations at the input. Post-processing a 2Dpose sequence using our method provides a richer representationof the character motion. We show experimentally that thelocalization accuracy of the additional joints is on average onpar with the original pose estimates.



### Learning to Segment from Scribbles using Multi-scale Adversarial Attention Gates
- **Arxiv ID**: http://arxiv.org/abs/2007.01152v3
- **DOI**: 10.1109/TMI.2021.3069634
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01152v3)
- **Published**: 2020-07-02 14:39:08+00:00
- **Updated**: 2021-03-25 15:54:11+00:00
- **Authors**: Gabriele Valvano, Andrea Leo, Sotirios A. Tsaftaris
- **Comment**: Paper accepted for publication at: IEEE Transaction on Medical
  Imaging - Project page:
  https://vios-s.github.io/multiscale-adversarial-attention-gates
- **Journal**: IEEE Transactions on Medical Imaging, 2021
- **Summary**: Large, fine-grained image segmentation datasets, annotated at pixel-level, are difficult to obtain, particularly in medical imaging, where annotations also require expert knowledge. Weakly-supervised learning can train models by relying on weaker forms of annotation, such as scribbles. Here, we learn to segment using scribble annotations in an adversarial game. With unpaired segmentation masks, we train a multi-scale GAN to generate realistic segmentation masks at multiple resolutions, while we use scribbles to learn their correct position in the image. Central to the model's success is a novel attention gating mechanism, which we condition with adversarial signals to act as a shape prior, resulting in better object localization at multiple scales. Subject to adversarial conditioning, the segmentor learns attention maps that are semantic, suppress the noisy activations outside the objects, and reduce the vanishing gradient problem in the deeper layers of the segmentor. We evaluated our model on several medical (ACDC, LVSC, CHAOS) and non-medical (PPSS) datasets, and we report performance levels matching those achieved by models trained with fully annotated segmentation masks. We also demonstrate extensions in a variety of settings: semi-supervised learning; combining multiple scribble sources (a crowdsourcing scenario) and multi-task learning (combining scribble and mask supervision). We release expert-made scribble annotations for the ACDC dataset, and the code used for the experiments, at https://vios-s.github.io/multiscale-adversarial-attention-gates



### Spot the conversation: speaker diarisation in the wild
- **Arxiv ID**: http://arxiv.org/abs/2007.01216v3
- **DOI**: 10.21437/Interspeech.2020-2337
- **Categories**: **cs.SD**, cs.CV, eess.AS, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01216v3)
- **Published**: 2020-07-02 15:55:54+00:00
- **Updated**: 2021-08-15 04:01:36+00:00
- **Authors**: Joon Son Chung, Jaesung Huh, Arsha Nagrani, Triantafyllos Afouras, Andrew Zisserman
- **Comment**: The dataset will be available for download from
  http://www.robots.ox.ac.uk/~vgg/data/voxceleb/voxconverse.html . The
  development set will be released in July 2020, and the test set will be
  released in October 2020
- **Journal**: None
- **Summary**: The goal of this paper is speaker diarisation of videos collected 'in the wild'. We make three key contributions. First, we propose an automatic audio-visual diarisation method for YouTube videos. Our method consists of active speaker detection using audio-visual methods and speaker verification using self-enrolled speaker models. Second, we integrate our method into a semi-automatic dataset creation pipeline which significantly reduces the number of hours required to annotate videos with diarisation labels. Finally, we use this pipeline to create a large-scale diarisation dataset called VoxConverse, collected from 'in the wild' videos, which we will release publicly to the research community. Our dataset consists of overlapping speech, a large and diverse speaker pool, and challenging background conditions.



### Globally Optimal Surface Segmentation using Deep Learning with Learnable Smoothness Priors
- **Arxiv ID**: http://arxiv.org/abs/2007.01217v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01217v1)
- **Published**: 2020-07-02 15:56:46+00:00
- **Updated**: 2020-07-02 15:56:46+00:00
- **Authors**: Leixin Zhou, Xiaodong Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Automated surface segmentation is important and challenging in many medical image analysis applications. Recent deep learning based methods have been developed for various object segmentation tasks. Most of them are a classification based approach, e.g. U-net, which predicts the probability of being target object or background for each voxel. One problem of those methods is lacking of topology guarantee for segmented objects, and usually post processing is needed to infer the boundary surface of the object. In this paper, a novel model based on convolutional neural network (CNN) followed by a learnable surface smoothing block is proposed to tackle the surface segmentation problem with end-to-end training. To the best of our knowledge, this is the first study to learn smoothness priors end-to-end with CNN for direct surface segmentation with global optimality. Experiments carried out on Spectral Domain Optical Coherence Tomography (SD-OCT) retinal layer segmentation and Intravascular Ultrasound (IVUS) vessel wall segmentation demonstrated very promising results.



### Learning ordered pooling weights in image classification
- **Arxiv ID**: http://arxiv.org/abs/2007.01243v2
- **DOI**: 10.1016/j.neucom.2020.06.028
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01243v2)
- **Published**: 2020-07-02 16:51:05+00:00
- **Updated**: 2021-06-10 16:38:56+00:00
- **Authors**: J. I. Forcen, Miguel Pagola, Edurne Barrenechea, Humberto Bustince
- **Comment**: None
- **Journal**: None
- **Summary**: Spatial pooling is an important step in computer vision systems like Convolutional Neural Networks or the Bag-of-Words method. The spatial pooling purpose is to combine neighbouring descriptors to obtain a single descriptor for a given region (local or global). The resultant combined vector must be as discriminant as possible, in other words, must contain relevant information, while removing irrelevant and confusing details. Maximum and average are the most common aggregation functions used in the pooling step. To improve the aggregation of relevant information without degrading their discriminative power for image classification, we introduce a simple but effective scheme based on Ordered Weighted Average (OWA) aggregation operators. We present a method to learn the weights of the OWA aggregation operator in a Bag-of-Words framework and in Convolutional Neural Networks, and provide an extensive evaluation showing that OWA based pooling outperforms classical aggregation operators.



### Autonomous and cooperative design of the monitor positions for a team of UAVs to maximize the quantity and quality of detected objects
- **Arxiv ID**: http://arxiv.org/abs/2007.01247v1
- **DOI**: 10.1109/LRA.2020.3004780
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01247v1)
- **Published**: 2020-07-02 16:52:57+00:00
- **Updated**: 2020-07-02 16:52:57+00:00
- **Authors**: Dimitrios I. Koutras, Athanasios Ch. Kapoutsis, Elias B. Kosmatopoulos
- **Comment**: 8 pages, 8 figures
- **Journal**: None
- **Summary**: This paper tackles the problem of positioning a swarm of UAVs inside a completely unknown terrain, having as objective to maximize the overall situational awareness. The situational awareness is expressed by the number and quality of unique objects of interest, inside the UAVs' fields of view. YOLOv3 and a system to identify duplicate objects of interest were employed to assign a single score to each UAVs' configuration. Then, a novel navigation algorithm, capable of optimizing the previously defined score, without taking into consideration the dynamics of either UAVs or environment, is proposed. A cornerstone of the proposed approach is that it shares the same convergence characteristics as the block coordinate descent (BCD) family of approaches. The effectiveness and performance of the proposed navigation scheme were evaluated utilizing a series of experiments inside the AirSim simulator. The experimental evaluation indicates that the proposed navigation algorithm was able to consistently navigate the swarm of UAVs to "strategic" monitoring positions and also adapt to the different number of swarm sizes. Source code is available at https://github.com/dimikout3/ConvCAOAirSim.



### Image Processing and Quality Control for Abdominal Magnetic Resonance Imaging in the UK Biobank
- **Arxiv ID**: http://arxiv.org/abs/2007.01251v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2007.01251v2)
- **Published**: 2020-07-02 17:01:25+00:00
- **Updated**: 2020-07-16 07:29:04+00:00
- **Authors**: Nicolas Basty, Yi Liu, Madeleine Cule, E. Louise Thomas, Jimmy D. Bell, Brandon Whitcher
- **Comment**: Fixed 2 references
- **Journal**: None
- **Summary**: An end-to-end image analysis pipeline is presented for the abdominal MRI protocol used in the UK Biobank on the first 38,971 participants. Emphasis is on the processing steps necessary to ensure a high-level of data quality and consistency is produced in order to prepare the datasets for downstream quantitative analysis, such as segmentation and parameter estimation. Quality control procedures have been incorporated to detect and, where possible, correct issues in the raw data. Detection of fat-water swaps in the Dixon series is performed by a deep learning model and corrected automatically. Bone joints are predicted using a hybrid atlas-based registration and deep learning model for the shoulders, hips and knees. Simultaneous estimation of proton density fat fraction and transverse relaxivity (R2*) is performed using both the magnitude and phase information for the single-slice multiecho series. Approximately 98.1% of the two-point Dixon acquisitions were successfully processed and passed quality control, with 99.98% of the high-resolution T1-weighted 3D volumes succeeding. Approximately 99.98% of the single-slice multiecho acquisitions covering the liver were successfully processed and passed quality control, with 97.6% of the single-slice multiecho acquisitions covering the pancreas succeeding. At least one fat-water swap was detected in 1.8% of participants. With respect to the bone joints, approximately 3.3% of participants were missing at least one knee joint and 0.8% were missing at least one shoulder joint. For the participants who received both single-slice multiecho acquisition protocols for the liver a systematic difference between the two protocols was identified and modeled using multiple linear regression. The findings presented here will be invaluable for scientists who seek to use image-derived phenotypes from the abdominal MRI protocol.



### Globally Optimal Segmentation of Mutually Interacting Surfaces using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2007.01259v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.2.1, I.4.6
- **Links**: [PDF](http://arxiv.org/pdf/2007.01259v3)
- **Published**: 2020-07-02 17:13:35+00:00
- **Updated**: 2020-07-21 16:08:35+00:00
- **Authors**: Hui Xie, Zhe Pan, Leixin Zhou, Fahim A Zaman, Danny Chen, Jost B Jonas, Yaxing Wang, Xiaodong Wu
- **Comment**: 11 pages main content and reference, plus 10 pages appendix, total 21
  pages
- **Journal**: None
- **Summary**: Segmentation of multiple surfaces in medical images is a challenging problem, further complicated by the frequent presence of weak boundary and mutual influence between adjacent objects. The traditional graph-based optimal surface segmentation method has proven its effectiveness with its ability of capturing various surface priors in a uniform graph model. However, its efficacy heavily relies on handcrafted features that are used to define the surface cost for the "goodness" of a surface. Recently, deep learning (DL) is emerging as powerful tools for medical image segmentation thanks to its superior feature learning capability. Unfortunately, due to the scarcity of training data in medical imaging, it is nontrivial for DL networks to implicitly learn the global structure of the target surfaces, including surface interactions. In this work, we propose to parameterize the surface cost functions in the graph model and leverage DL to learn those parameters. The multiple optimal surfaces are then simultaneously detected by minimizing the total surface cost while explicitly enforcing the mutual surface interaction constraints. The optimization problem is solved by the primal-dual Internal Point Method, which can be implemented by a layer of neural networks, enabling efficient end-to-end training of the whole network. Experiments on Spectral Domain Optical Coherence Tomography (SD-OCT) retinal layer segmentation and Intravascular Ultrasound (IVUS) vessel wall segmentation demonstrated very promising results. All source code is public to facilitate further research at this direction.



### Curriculum Manager for Source Selection in Multi-Source Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2007.01261v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01261v1)
- **Published**: 2020-07-02 17:15:01+00:00
- **Updated**: 2020-07-02 17:15:01+00:00
- **Authors**: Luyu Yang, Yogesh Balaji, Ser-Nam Lim, Abhinav Shrivastava
- **Comment**: None
- **Journal**: None
- **Summary**: The performance of Multi-Source Unsupervised Domain Adaptation depends significantly on the effectiveness of transfer from labeled source domain samples. In this paper, we proposed an adversarial agent that learns a dynamic curriculum for source samples, called Curriculum Manager for Source Selection (CMSS). The Curriculum Manager, an independent network module, constantly updates the curriculum during training, and iteratively learns which domains or samples are best suited for aligning to the target. The intuition behind this is to force the Curriculum Manager to constantly re-measure the transferability of latent domains over time to adversarially raise the error rate of the domain discriminator. CMSS does not require any knowledge of the domain labels, yet it outperforms other methods on four well-known benchmarks by significant margins. We also provide interpretable results that shed light on the proposed method.



### RELATE: Physically Plausible Multi-Object Scene Synthesis Using Structured Latent Spaces
- **Arxiv ID**: http://arxiv.org/abs/2007.01272v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01272v2)
- **Published**: 2020-07-02 17:27:27+00:00
- **Updated**: 2020-11-09 18:03:58+00:00
- **Authors**: Sebastien Ehrhardt, Oliver Groth, Aron Monszpart, Martin Engelcke, Ingmar Posner, Niloy Mitra, Andrea Vedaldi
- **Comment**: None
- **Journal**: None
- **Summary**: We present RELATE, a model that learns to generate physically plausible scenes and videos of multiple interacting objects. Similar to other generative approaches, RELATE is trained end-to-end on raw, unlabeled data. RELATE combines an object-centric GAN formulation with a model that explicitly accounts for correlations between individual objects. This allows the model to generate realistic scenes and videos from a physically-interpretable parameterization. Furthermore, we show that modeling the object correlation is necessary to learn to disentangle object positions and identity. We find that RELATE is also amenable to physically realistic scene editing and that it significantly outperforms prior art in object-centric scene generation in both synthetic (CLEVR, ShapeStacks) and real-world data (cars). In addition, in contrast to state-of-the-art methods in object-centric generative modeling, RELATE also extends naturally to dynamic scenes and generates videos of high visual fidelity. Source code, datasets and more results are available at http://geometry.cs.ucl.ac.uk/projects/2020/relate/.



### Image Shape Manipulation from a Single Augmented Training Sample
- **Arxiv ID**: http://arxiv.org/abs/2007.01289v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.01289v2)
- **Published**: 2020-07-02 17:55:27+00:00
- **Updated**: 2021-11-25 14:02:24+00:00
- **Authors**: Yael Vinker, Eliahu Horwitz, Nir Zabari, Yedid Hoshen
- **Comment**: ICCV 2021 (Oral). Project page: http://www.vision.huji.ac.il/deepsim/
- **Journal**: None
- **Summary**: In this paper, we present DeepSIM, a generative model for conditional image manipulation based on a single image. We find that extensive augmentation is key for enabling single image training, and incorporate the use of thin-plate-spline (TPS) as an effective augmentation. Our network learns to map between a primitive representation of the image to the image itself. The choice of a primitive representation has an impact on the ease and expressiveness of the manipulations and can be automatic (e.g. edges), manual (e.g. segmentation) or hybrid such as edges on top of segmentations. At manipulation time, our generator allows for making complex image changes by modifying the primitive input representation and mapping it through the network. Our method is shown to achieve remarkable performance on image manipulation tasks.



### Not All Unlabeled Data are Equal: Learning to Weight Data in Semi-supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/2007.01293v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01293v2)
- **Published**: 2020-07-02 17:59:05+00:00
- **Updated**: 2020-10-29 04:29:54+00:00
- **Authors**: Zhongzheng Ren, Raymond A. Yeh, Alexander G. Schwing
- **Comment**: NeurIPS camera ready
- **Journal**: None
- **Summary**: Existing semi-supervised learning (SSL) algorithms use a single weight to balance the loss of labeled and unlabeled examples, i.e., all unlabeled examples are equally weighted. But not all unlabeled data are equal. In this paper we study how to use a different weight for every unlabeled example. Manual tuning of all those weights -- as done in prior work -- is no longer possible. Instead, we adjust those weights via an algorithm based on the influence function, a measure of a model's dependency on one training example. To make the approach efficient, we propose a fast and effective approximation of the influence function. We demonstrate that this technique outperforms state-of-the-art methods on semi-supervised image and language classification tasks.



### A Closer Look at Local Aggregation Operators in Point Cloud Analysis
- **Arxiv ID**: http://arxiv.org/abs/2007.01294v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.01294v1)
- **Published**: 2020-07-02 17:59:12+00:00
- **Updated**: 2020-07-02 17:59:12+00:00
- **Authors**: Ze Liu, Han Hu, Yue Cao, Zheng Zhang, Xin Tong
- **Comment**: Code available at https://github.com/zeliu98/CloserLook3D
- **Journal**: None
- **Summary**: Recent advances of network architecture for point cloud processing are mainly driven by new designs of local aggregation operators. However, the impact of these operators to network performance is not carefully investigated due to different overall network architecture and implementation details in each solution. Meanwhile, most of operators are only applied in shallow architectures. In this paper, we revisit the representative local aggregation operators and study their performance using the same deep residual architecture. Our investigation reveals that despite the different designs of these operators, all of these operators make surprisingly similar contributions to the network performance under the same network input and feature numbers and result in the state-of-the-art accuracy on standard benchmarks. This finding stimulate us to rethink the necessity of sophisticated design of local aggregation operator for point cloud processing. To this end, we propose a simple local aggregation operator without learnable weights, named Position Pooling (PosPool), which performs similarly or slightly better than existing sophisticated operators. In particular, a simple deep residual network with PosPool layers achieves outstanding performance on all benchmarks, which outperforms the previous state-of-the methods on the challenging PartNet datasets by a large margin (7.4 mIoU). The code is publicly available at https://github.com/zeliu98/CloserLook3D



### Learning-based Defect Recognition for Quasi-Periodic Microscope Images
- **Arxiv ID**: http://arxiv.org/abs/2007.01309v2
- **DOI**: 10.1016/j.micron.2021.103069
- **Categories**: **cond-mat.mtrl-sci**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01309v2)
- **Published**: 2020-07-02 18:00:02+00:00
- **Updated**: 2020-08-09 11:14:57+00:00
- **Authors**: Nik Dennler, Antonio Foncubierta-Rodriguez, Titus Neupert, Marilyne Sousa
- **Comment**: 11 pages + references and appendix, 5 figures. V2: Added references.
  Corrected typos. Elaborated methodology. In sample figure, replaced grain
  boundary image with more representative image. Results are unchanged
- **Journal**: None
- **Summary**: Controlling crystalline material defects is crucial, as they affect properties of the material that may be detrimental or beneficial for the final performance of a device. Defect analysis on the sub-nanometer scale is enabled by high-resolution (scanning) transmission electron microscopy [HR(S)TEM], where the identification of defects is currently carried out based on human expertise. However, the process is tedious, highly time consuming and, in some cases, yields ambiguous results. Here we propose a semi-supervised machine learning method that assists in the detection of lattice defects from atomic resolution microscope images. It involves a convolutional neural network that classifies image patches as defective or non-defective, a graph-based heuristic that chooses one non-defective patch as a model, and finally an automatically generated convolutional filter bank, which highlights symmetry breaking such as stacking faults, twin defects and grain boundaries. Additionally, we suggest a variance filter to segment amorphous regions and beam defects. The algorithm is tested on III-V/Si crystalline materials and successfully evaluated against different metrics, showing promising results even for extremely small training data sets. By combining the data-driven classification generality, robustness and speed of deep learning with the effectiveness of image filters in segmenting faulty symmetry arrangements, we provide a valuable open-source tool to the microscopist community that can streamline future HR(S)TEM analyses of crystalline materials.



### Domain Adaptation for Robust Workload Level Alignment Between Sessions and Subjects using fNIRS
- **Arxiv ID**: http://arxiv.org/abs/2007.06706v2
- **DOI**: 10.1117/1.JBO.26.2.022908
- **Categories**: **cs.CV**, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2007.06706v2)
- **Published**: 2020-07-02 18:03:50+00:00
- **Updated**: 2020-11-30 01:52:13+00:00
- **Authors**: Boyang Lyu, Thao Pham, Giles Blaney, Zachary Haga, Angelo Sassaroli, Sergio Fantini, Shuchin Aeron
- **Comment**: None
- **Journal**: None
- **Summary**: Significance: We demonstrated the potential of using domain adaptation on functional Near-Infrared Spectroscopy (fNIRS) data to classify different levels of n-back tasks that involve working memory. Aim: Domain shift in fNIRS data is a challenge in the workload level alignment across different experiment sessions and subjects. In order to address this problem, two domain adaptation approaches -- Gromov-Wasserstein (G-W) and Fused Gromov-Wasserstein (FG-W) were used. Approach: Specifically, we used labeled data from one session or one subject to classify trials in another session (within the same subject) or another subject. We applied G-W for session-by-session alignment and FG-W for subject-by-subject alignment to fNIRS data acquired during different n-back task levels. We compared these approaches with three supervised methods: multi-class Support Vector Machine (SVM), Convolutional Neural Network (CNN), and Recurrent Neural Network (RNN). Results: In a sample of six subjects, G-W resulted in an alignment accuracy of 68 $\pm$ 4 % (weighted mean $\pm$ standard error) for session-by-session alignment, FG-W resulted in an alignment accuracy of 55 $\pm$ 2 % for subject-by-subject alignment. In each of these cases, 25 % accuracy represents chance. Alignment accuracy results from both G-W and FG-W are significantly greater than those from SVM, CNN and RNN. We also showed that removal of motion artifacts from the fNIRS data plays an important role in improving alignment performance. Conclusions: Domain adaptation has potential for session-by-session and subject-by-subject alignment of mental workload by using fNIRS data.



### Clustering of Electromagnetic Showers and Particle Interactions with Graph Neural Networks in Liquid Argon Time Projection Chambers Data
- **Arxiv ID**: http://arxiv.org/abs/2007.01335v3
- **DOI**: None
- **Categories**: **physics.ins-det**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01335v3)
- **Published**: 2020-07-02 18:32:25+00:00
- **Updated**: 2020-12-15 04:42:41+00:00
- **Authors**: Francois Drielsma, Qing Lin, Pierre Côte de Soux, Laura Dominé, Ran Itay, Dae Heun Koh, Bradley J. Nelson, Kazuhiro Terao, Ka Vang Tsang, Tracy L. Usher
- **Comment**: None
- **Journal**: None
- **Summary**: Liquid Argon Time Projection Chambers (LArTPCs) are a class of detectors that produce high resolution images of charged particles within their sensitive volume. In these images, the clustering of distinct particles into superstructures is of central importance to the current and future neutrino physics program. Electromagnetic (EM) activity typically exhibits spatially detached fragments of varying morphology and orientation that are challenging to efficiently assemble using traditional algorithms. Similarly, particles that are spatially removed from each other in the detector may originate from a common interaction. Graph Neural Networks (GNNs) were developed in recent years to find correlations between objects embedded in an arbitrary space. The Graph Particle Aggregator (GrapPA) first leverages GNNs to predict the adjacency matrix of EM shower fragments and to identify the origin of showers, i.e. primary fragments. On the PILArNet public LArTPC simulation dataset, the algorithm achieves achieves a shower clustering accuracy characterized by a mean adjusted Rand index (ARI) of 97.8 % and a primary identification accuracy of 99.8 %. It yields a relative shower energy resolution of $(4.1+1.4/\sqrt{E (\text{GeV})})\,\%$ and a shower direction resolution of $(2.1/\sqrt{E(\text{GeV})})^{\circ}$. The optimized algorithm is then applied to the related task of clustering particle instances into interactions and yields a mean ARI of 99.2 % for an interaction density of $\sim\mathcal{O}(1)\,m^{-3}$.



### Path Signatures on Lie Groups
- **Arxiv ID**: http://arxiv.org/abs/2007.06633v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, math.DG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.06633v2)
- **Published**: 2020-07-02 18:38:49+00:00
- **Updated**: 2020-07-15 17:29:03+00:00
- **Authors**: Darrick Lee, Robert Ghrist
- **Comment**: 64 pages, 11 figures
- **Journal**: None
- **Summary**: Path signatures are powerful nonparametric tools for time series analysis, shown to form a universal and characteristic feature map for Euclidean valued time series data. We lift the theory of path signatures to the setting of Lie group valued time series, adapting these tools for time series with underlying geometric constraints. We prove that this generalized path signature is universal and characteristic. To demonstrate universality, we analyze the human action recognition problem in computer vision, using $SO(3)$ representations for the time series, providing comparable performance to other shallow learning approaches, while offering an easily interpretable feature set. We also provide a two-sample hypothesis test for Lie group-valued random walks to illustrate its characteristic property. Finally we provide algorithms and a Julia implementation of these methods.



### Decoder-free Robustness Disentanglement without (Additional) Supervision
- **Arxiv ID**: http://arxiv.org/abs/2007.01356v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2007.01356v1)
- **Published**: 2020-07-02 19:51:40+00:00
- **Updated**: 2020-07-02 19:51:40+00:00
- **Authors**: Yifei Wang, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Adversarial Training (AT) is proposed to alleviate the adversarial vulnerability of machine learning models by extracting only robust features from the input, which, however, inevitably leads to severe accuracy reduction as it discards the non-robust yet useful features. This motivates us to preserve both robust and non-robust features and separate them with disentangled representation learning. Our proposed Adversarial Asymmetric Training (AAT) algorithm can reliably disentangle robust and non-robust representations without additional supervision on robustness. Empirical results show our method does not only successfully preserve accuracy by combining two representations, but also achieve much better disentanglement than previous work.



### Deep Learning Models for Visual Inspection on Automotive Assembling Line
- **Arxiv ID**: http://arxiv.org/abs/2007.01857v1
- **DOI**: 10.22161/ijaers.74.56
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01857v1)
- **Published**: 2020-07-02 20:00:45+00:00
- **Updated**: 2020-07-02 20:00:45+00:00
- **Authors**: Muriel Mazzetto, Marcelo Teixeira, Érick Oliveira Rodrigues, Dalcimar Casanova
- **Comment**: arXiv admin note: text overlap with arXiv:1802.08717,
  arXiv:1703.05921 by other authors
- **Journal**: International Journal of Advanced Engineering Research and Science
  7(4) (2020) 473-494
- **Summary**: Automotive manufacturing assembly tasks are built upon visual inspections such as scratch identification on machined surfaces, part identification and selection, etc, which guarantee product and process quality. These tasks can be related to more than one type of vehicle that is produced within the same manufacturing line. Visual inspection was essentially human-led but has recently been supplemented by the artificial perception provided by computer vision systems (CVSs). Despite their relevance, the accuracy of CVSs varies accordingly to environmental settings such as lighting, enclosure and quality of image acquisition. These issues entail costly solutions and override part of the benefits introduced by computer vision systems, mainly when it interferes with the operating cycle time of the factory. In this sense, this paper proposes the use of deep learning-based methodologies to assist in visual inspection tasks while leaving very little footprints in the manufacturing environment and exploring it as an end-to-end tool to ease CVSs setup. The proposed approach is illustrated by four proofs of concept in a real automotive assembly line based on models for object detection, semantic segmentation, and anomaly detection.



### Low-Power Object Counting with Hierarchical Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2007.01369v1
- **DOI**: 10.1145/3370748.3406569
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01369v1)
- **Published**: 2020-07-02 20:13:01+00:00
- **Updated**: 2020-07-02 20:13:01+00:00
- **Authors**: Abhinav Goel, Caleb Tung, Sara Aghajanzadeh, Isha Ghodgaonkar, Shreya Ghosh, George K. Thiruvathukal, Yung-Hsiang Lu
- **Comment**: Paper accepted to ISLPED 2020: ACM/IEEE International Symposium on
  Low Power Electronics and Design
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) can achieve state-of-the-art accuracy in many computer vision tasks, such as object counting. Object counting takes two inputs: an image and an object query and reports the number of occurrences of the queried object. To achieve high accuracy on such tasks, DNNs require billions of operations, making them difficult to deploy on resource-constrained, low-power devices. Prior work shows that a significant number of DNN operations are redundant and can be eliminated without affecting the accuracy. To reduce these redundancies, we propose a hierarchical DNN architecture for object counting. This architecture uses a Region Proposal Network (RPN) to propose regions-of-interest (RoIs) that may contain the queried objects. A hierarchical classifier then efficiently finds the RoIs that actually contain the queried objects. The hierarchy contains groups of visually similar object categories. Small DNNs are used at each node of the hierarchy to classify between these groups. The RoIs are incrementally processed by the hierarchical classifier. If the object in an RoI is in the same group as the queried object, then the next DNN in the hierarchy processes the RoI further; otherwise, the RoI is discarded. By using a few small DNNs to process each image, this method reduces the memory requirement, inference time, energy consumption, and number of operations with negligible accuracy loss when compared with the existing object counters.



### DATE: Defense Against TEmperature Side-Channel Attacks in DVFS Enabled MPSoCs
- **Arxiv ID**: http://arxiv.org/abs/2007.01377v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.AR, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2007.01377v1)
- **Published**: 2020-07-02 20:41:23+00:00
- **Updated**: 2020-07-02 20:41:23+00:00
- **Authors**: Somdip Dey, Amit Kumar Singh, Xiaohang Wang, Klaus Dieter McDonald-Maier
- **Comment**: 13 pages, 18 figures, 3 tables
- **Journal**: None
- **Summary**: Given the constant rise in utilizing embedded devices in daily life, side channels remain a challenge to information flow control and security in such systems. One such important security flaw could be exploited through temperature side-channel attacks, where heat dissipation and propagation from the processing elements are observed over time in order to deduce security flaws. In our proposed methodology, DATE: Defense Against TEmperature side-channel attacks, we propose a novel approach of reducing spatial and temporal thermal gradient, which makes the system more secure against temperature side-channel attacks, and at the same time increases the reliability of the device in terms of lifespan. In this paper, we have also introduced a new metric, Thermal-Security-in-Multi-Processors (TSMP), which is capable of quantifying the security against temperature side-channel attacks on computing systems, and DATE is evaluated to be 139.24% more secure at the most for certain applications than the state-of-the-art, while reducing thermal cycle by 67.42% at the most.



### D-NetPAD: An Explainable and Interpretable Iris Presentation Attack Detector
- **Arxiv ID**: http://arxiv.org/abs/2007.01381v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.01381v1)
- **Published**: 2020-07-02 20:44:36+00:00
- **Updated**: 2020-07-02 20:44:36+00:00
- **Authors**: Renu Sharma, Arun Ross
- **Comment**: None
- **Journal**: None
- **Summary**: An iris recognition system is vulnerable to presentation attacks, or PAs, where an adversary presents artifacts such as printed eyes, plastic eyes, or cosmetic contact lenses to circumvent the system. In this work, we propose an effective and robust iris PA detector called D-NetPAD based on the DenseNet convolutional neural network architecture. It demonstrates generalizability across PA artifacts, sensors and datasets. Experiments conducted on a proprietary dataset and a publicly available dataset (LivDet-2017) substantiate the effectiveness of the proposed method for iris PA detection. The proposed method results in a true detection rate of 98.58\% at a false detection rate of 0.2\% on the proprietary dataset and outperfoms state-of-the-art methods on the LivDet-2017 dataset. We visualize intermediate feature distributions and fixation heatmaps using t-SNE plots and Grad-CAM, respectively, in order to explain the performance of D-NetPAD. Further, we conduct a frequency analysis to explain the nature of features being extracted by the network. The source code and trained model are available at https://github.com/iPRoBe-lab/D-NetPAD.



### Deep Interactive Learning: An Efficient Labeling Approach for Deep Learning-Based Osteosarcoma Treatment Response Assessment
- **Arxiv ID**: http://arxiv.org/abs/2007.01383v1
- **DOI**: 10.1007/978-3-030-59722-1_52
- **Categories**: **eess.IV**, cs.CV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2007.01383v1)
- **Published**: 2020-07-02 20:46:53+00:00
- **Updated**: 2020-07-02 20:46:53+00:00
- **Authors**: David Joon Ho, Narasimhan P. Agaram, Peter J. Schueffler, Chad M. Vanderbilt, Marc-Henri Jean, Meera R. Hameed, Thomas J. Fuchs
- **Comment**: Accepted at MICCAI 2020
- **Journal**: None
- **Summary**: Osteosarcoma is the most common malignant primary bone tumor. Standard treatment includes pre-operative chemotherapy followed by surgical resection. The response to treatment as measured by ratio of necrotic tumor area to overall tumor area is a known prognostic factor for overall survival. This assessment is currently done manually by pathologists by looking at glass slides under the microscope which may not be reproducible due to its subjective nature. Convolutional neural networks (CNNs) can be used for automated segmentation of viable and necrotic tumor on osteosarcoma whole slide images. One bottleneck for supervised learning is that large amounts of accurate annotations are required for training which is a time-consuming and expensive process. In this paper, we describe Deep Interactive Learning (DIaL) as an efficient labeling approach for training CNNs. After an initial labeling step is done, annotators only need to correct mislabeled regions from previous segmentation predictions to improve the CNN model until the satisfactory predictions are achieved. Our experiments show that our CNN model trained by only 7 hours of annotation using DIaL can successfully estimate ratios of necrosis within expected inter-observer variation rate for non-standardized manual surgical pathology task.



### Posterior Adaptation With New Priors
- **Arxiv ID**: http://arxiv.org/abs/2007.01386v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01386v4)
- **Published**: 2020-07-02 21:07:05+00:00
- **Updated**: 2022-01-25 13:26:42+00:00
- **Authors**: Jim Davis
- **Comment**: None
- **Journal**: None
- **Summary**: Classification approaches based on the direct estimation and analysis of posterior probabilities will degrade if the original class priors begin to change. We prove that a unique (up to scale) solution is possible to recover the data likelihoods for a test example from its original class posteriors and dataset priors. Given the recovered likelihoods and a set of new priors, the posteriors can be re-computed using Bayes' Rule to reflect the influence of the new priors. The method is simple to compute and allows a dynamic update of the original posteriors.



### Learn Faster and Forget Slower via Fast and Stable Task Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2007.01388v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.01388v2)
- **Published**: 2020-07-02 21:13:55+00:00
- **Updated**: 2020-11-29 16:01:50+00:00
- **Authors**: Farshid Varno, Lucas May Petry, Lisa Di Jorio, Stan Matwin
- **Comment**: 52 pages, 15 figures, 1 table
- **Journal**: None
- **Summary**: Training Deep Neural Networks (DNNs) is still highly time-consuming and compute-intensive. It has been shown that adapting a pretrained model may significantly accelerate this process. With a focus on classification, we show that current fine-tuning techniques make the pretrained models catastrophically forget the transferred knowledge even before anything about the new task is learned. Such rapid knowledge loss undermines the merits of transfer learning and may result in a much slower convergence rate compared to when the maximum amount of knowledge is exploited. We investigate the source of this problem from different perspectives and to alleviate it, introduce Fast And Stable Task-adaptation (FAST), an easy to apply fine-tuning algorithm. The paper provides a novel geometric perspective on how the loss landscape of source and target tasks are linked in different transfer learning strategies. We empirically show that compared to prevailing fine-tuning practices, FAST learns the target task faster and forgets the source task slower.



### Learning Orientation Distributions for Object Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/2007.01418v2
- **DOI**: 10.1109/IROS45743.2020.9340860
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2007.01418v2)
- **Published**: 2020-07-02 22:30:56+00:00
- **Updated**: 2020-08-11 01:12:11+00:00
- **Authors**: Brian Okorn, Mengyun Xu, Martial Hebert, David Held
- **Comment**: None
- **Journal**: None
- **Summary**: For robots to operate robustly in the real world, they should be aware of their uncertainty. However, most methods for object pose estimation return a single point estimate of the object's pose. In this work, we propose two learned methods for estimating a distribution over an object's orientation. Our methods take into account both the inaccuracies in the pose estimation as well as the object symmetries. Our first method, which regresses from deep learned features to an isotropic Bingham distribution, gives the best performance for orientation distribution estimation for non-symmetric objects. Our second method learns to compare deep features and generates a non-parameteric histogram distribution. This method gives the best performance on objects with unknown symmetries, accurately modeling both symmetric and non-symmetric objects, without any requirement of symmetry annotation. We show that both of these methods can be used to augment an existing pose estimator. Our evaluation compares our methods to a large number of baseline approaches for uncertainty estimation across a variety of different types of objects.



### Persistent Neurons
- **Arxiv ID**: http://arxiv.org/abs/2007.01419v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML, I.2; I.5
- **Links**: [PDF](http://arxiv.org/pdf/2007.01419v2)
- **Published**: 2020-07-02 22:36:49+00:00
- **Updated**: 2021-03-18 09:16:24+00:00
- **Authors**: Yimeng Min
- **Comment**: add some new results
- **Journal**: None
- **Summary**: Neural networks (NN)-based learning algorithms are strongly affected by the choices of initialization and data distribution. Different optimization strategies have been proposed for improving the learning trajectory and finding a better optima. However, designing improved optimization strategies is a difficult task under the conventional landscape view. Here, we propose persistent neurons, a trajectory-based strategy that optimizes the learning task using information from previous converged solutions. More precisely, we utilize the end of trajectories and let the parameters explore new landscapes by penalizing the model from converging to the previous solutions under the same initialization. Persistent neurons can be regarded as a stochastic gradient method with informed bias where individual updates are corrupted by deterministic error terms. Specifically, we show that persistent neurons, under certain data distribution, is able to converge to more optimal solutions while initializations under popular framework find bad local minima. We further demonstrate that persistent neurons helps improve the model's performance under both good and poor initializations. We evaluate the full and partial persistent model and show it can be used to boost the performance on a range of NN structures, such as AlexNet and residual neural network (ResNet).



### Joint Frequency and Image Space Learning for MRI Reconstruction and Analysis
- **Arxiv ID**: http://arxiv.org/abs/2007.01441v4
- **DOI**: 10.59275/j.melba.2022-16cc
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2007.01441v4)
- **Published**: 2020-07-02 23:54:46+00:00
- **Updated**: 2022-06-18 02:22:11+00:00
- **Authors**: Nalini M. Singh, Juan Eugenio Iglesias, Elfar Adalsteinsson, Adrian V. Dalca, Polina Golland
- **Comment**: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://www.melba-journal.org/papers/2022:018.html
- **Journal**: None
- **Summary**: We propose neural network layers that explicitly combine frequency and image feature representations and show that they can be used as a versatile building block for reconstruction from frequency space data. Our work is motivated by the challenges arising in MRI acquisition where the signal is a corrupted Fourier transform of the desired image. The proposed joint learning schemes enable both correction of artifacts native to the frequency space and manipulation of image space representations to reconstruct coherent image structures at every layer of the network. This is in contrast to most current deep learning approaches for image reconstruction that treat frequency and image space features separately and often operate exclusively in one of the two spaces. We demonstrate the advantages of joint convolutional learning for a variety of tasks, including motion correction, denoising, reconstruction from undersampled acquisitions, and combined undersampling and motion correction on simulated and real world multicoil MRI data. The joint models produce consistently high quality output images across all tasks and datasets. When integrated into a state of the art unrolled optimization network with physics-inspired data consistency constraints for undersampled reconstruction, the proposed architectures significantly improve the optimization landscape, which yields an order of magnitude reduction of training time. This result suggests that joint representations are particularly well suited for MRI signals in deep learning networks. Our code and pretrained models are publicly available at https://github.com/nalinimsingh/interlacer.



