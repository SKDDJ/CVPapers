# Arxiv Papers in cs.CV on 2020-11-01
### A comparison of Monte Carlo dropout and bootstrap aggregation on the performance and uncertainty estimation in radiation therapy dose prediction with deep learning neural networks
- **Arxiv ID**: http://arxiv.org/abs/2011.00388v2
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.00388v2)
- **Published**: 2020-11-01 00:24:43+00:00
- **Updated**: 2021-01-12 02:28:03+00:00
- **Authors**: Dan Nguyen, Azar Sadeghnejad Barkousaraie, Gyanendra Bohara, Anjali Balagopal, Rafe McBeth, Mu-Han Lin, Steve Jiang
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, artificial intelligence technologies and algorithms have become a major focus for advancements in treatment planning for radiation therapy. As these are starting to become incorporated into the clinical workflow, a major concern from clinicians is not whether the model is accurate, but whether the model can express to a human operator when it does not know if its answer is correct. We propose to use Monte Carlo dropout (MCDO) and the bootstrap aggregation (bagging) technique on deep learning models to produce uncertainty estimations for radiation therapy dose prediction. We show that both models are capable of generating a reasonable uncertainty map, and, with our proposed scaling technique, creating interpretable uncertainties and bounds on the prediction and any relevant metrics. Performance-wise, bagging provides statistically significant reduced loss value and errors in most of the metrics investigated in this study. The addition of bagging was able to further reduce errors by another 0.34% for Dmean and 0.19% for Dmax, on average, when compared to the baseline framework. Overall, the bagging framework provided significantly lower MAE of 2.62, as opposed to the baseline framework's MAE of 2.87. The usefulness of bagging, from solely a performance standpoint, does highly depend on the problem and the acceptable predictive error, and its high upfront computational cost during training should be factored in to deciding whether it is advantageous to use it. In terms of deployment with uncertainty estimations turned on, both frameworks offer the same performance time of about 12 seconds. As an ensemble-based metaheuristic, bagging can be used with existing machine learning architectures to improve stability and performance, and MCDO can be applied to any deep learning models that have dropout as part of their architecture.



### A Framework of Combining Short-Term Spatial/Frequency Feature Extraction and Long-Term IndRNN for Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/2011.00395v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.00395v2)
- **Published**: 2020-11-01 01:28:23+00:00
- **Updated**: 2020-11-06 03:02:53+00:00
- **Authors**: Beidi Zhao, Shuai Li, Yanbo Gao, Chuankun Li, Wanqing Li
- **Comment**: 19 pages, 11 figures
- **Journal**: None
- **Summary**: Smartphone sensors based human activity recognition is attracting increasing interests nowadays with the popularization of smartphones. With the high sampling rates of smartphone sensors, it is a highly long-range temporal recognition problem, especially with the large intra-class distances such as the smartphones carried at different locations such as in the bag or on the body, and the small inter-class distances such as taking train or subway. To address this problem, we propose a new framework of combining short-term spatial/frequency feature extraction and a long-term Independently Recurrent Neural Network (IndRNN) for activity recognition. Considering the periodic characteristics of the sensor data, short-term temporal features are first extracted in the spatial and frequency domains. Then the IndRNN, which is able to capture long-term patterns, is used to further obtain the long-term features for classification. In view of the large differences when the smartphone is carried at different locations, a group based location recognition is first developed to pinpoint the location of the smartphone. The Sussex-Huawei Locomotion (SHL) dataset from the SHL Challenge is used for evaluation. An earlier version of the proposed method has won the second place award in the SHL Challenge 2020 (the first place if not considering multiple models fusion approach). The proposed method is further improved in this paper and achieves 80.72$\%$ accuracy, better than the existing methods using a single model.



### Temporally-Continuous Probabilistic Prediction using Polynomial Trajectory Parameterization
- **Arxiv ID**: http://arxiv.org/abs/2011.00399v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.00399v1)
- **Published**: 2020-11-01 01:51:44+00:00
- **Updated**: 2020-11-01 01:51:44+00:00
- **Authors**: Zhaoen Su, Chao Wang, Henggang Cui, Nemanja Djuric, Carlos Vallespi-Gonzalez, David Bradley
- **Comment**: None
- **Journal**: IEEE/RSJ International Conference on Intelligent Robots and
  Systems (IROS 2021)
- **Summary**: A commonly-used representation for motion prediction of actors is a sequence of waypoints (comprising positions and orientations) for each actor at discrete future time-points. While this approach is simple and flexible, it can exhibit unrealistic higher-order derivatives (such as acceleration) and approximation errors at intermediate time steps. To address this issue we propose a simple and general representation for temporally continuous probabilistic trajectory prediction that is based on polynomial trajectory parameterization. We evaluate the proposed representation on supervised trajectory prediction tasks using two large self-driving data sets. The results show realistic higher-order derivatives and better accuracy at interpolated time-points, as well as the benefits of the inferred noise distributions over the trajectories. Extensive experimental studies based on existing state-of-the-art models demonstrate the effectiveness of the proposed approach relative to other representations in predicting the future motions of vehicle, bicyclist, and pedestrian traffic actors.



### Dark Reciprocal-Rank: Boosting Graph-Convolutional Self-Localization Network via Teacher-to-student Knowledge Transfer
- **Arxiv ID**: http://arxiv.org/abs/2011.00402v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2011.00402v1)
- **Published**: 2020-11-01 02:08:43+00:00
- **Updated**: 2020-11-01 02:08:43+00:00
- **Authors**: Koji Takeda, Kanji Tanaka
- **Comment**: 5 pages, 6 figures
- **Journal**: None
- **Summary**: In visual robot self-localization, graph-based scene representation and matching have recently attracted research interest as robust and discriminative methods for selflocalization. Although effective, their computational and storage costs do not scale well to large-size environments. To alleviate this problem, we formulate self-localization as a graph classification problem and attempt to use the graph convolutional neural network (GCN) as a graph classification engine. A straightforward approach is to use visual feature descriptors that are employed by state-of-the-art self-localization systems, directly as graph node features. However, their superior performance in the original self-localization system may not necessarily be replicated in GCN-based self-localization. To address this issue, we introduce a novel teacher-to-student knowledge-transfer scheme based on rank matching, in which the reciprocal-rank vector output by an off-the-shelf state-of-the-art teacher self-localization model is used as the dark knowledge to transfer. Experiments indicate that the proposed graph-convolutional self-localization network can significantly outperform state-of-the-art self-localization systems, as well as the teacher classifier.



### Efficient Pipelines for Vision-Based Context Sensing
- **Arxiv ID**: http://arxiv.org/abs/2011.00427v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.NI
- **Links**: [PDF](http://arxiv.org/pdf/2011.00427v1)
- **Published**: 2020-11-01 05:09:13+00:00
- **Updated**: 2020-11-01 05:09:13+00:00
- **Authors**: Xiaochen Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Context awareness is an essential part of mobile and ubiquitous computing. Its goal is to unveil situational information about mobile users like locations and activities. The sensed context can enable many services like navigation, AR, and smarting shopping. Such context can be sensed in different ways including visual sensors. There is an emergence of vision sources deployed worldwide. The cameras could be installed on roadside, in-house, and on mobile platforms. This trend provides huge amount of vision data that could be used for context sensing. However, the vision data collection and analytics are still highly manual today. It is hard to deploy cameras at large scale for data collection. Organizing and labeling context from the data are also labor intensive. In recent years, advanced vision algorithms and deep neural networks are used to help analyze vision data. But this approach is limited by data quality, labeling effort, and dependency on hardware resources. In summary, there are three major challenges for today's vision-based context sensing systems: data collection and labeling at large scale, process large data volumes efficiently with limited hardware resources, and extract accurate context out of vision data. The thesis explores the design space that consists of three dimensions: sensing task, sensor types, and task locations. Our prior work explores several points in this design space. We make contributions by (1) developing efficient and scalable solutions for different points in the design space of vision-based sensing tasks; (2) achieving state-of-the-art accuracy in those applications; (3) and developing guidelines for designing such sensing systems.



### Two-layer clustering-based sparsifying transform learning for low-dose CT reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2011.00428v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2011.00428v1)
- **Published**: 2020-11-01 05:15:37+00:00
- **Updated**: 2020-11-01 05:15:37+00:00
- **Authors**: Xikai Yang, Yong Long, Saiprasad Ravishankar
- **Comment**: 5 pages, 3 figures, submitted to ISBI2021
- **Journal**: None
- **Summary**: Achieving high-quality reconstructions from low-dose computed tomography (LDCT) measurements is of much importance in clinical settings. Model-based image reconstruction methods have been proven to be effective in removing artifacts in LDCT. In this work, we propose an approach to learn a rich two-layer clustering-based sparsifying transform model (MCST2), where image patches and their subsequent feature maps (filter residuals) are clustered into groups with different learned sparsifying filters per group. We investigate a penalized weighted least squares (PWLS) approach for LDCT reconstruction incorporating learned MCST2 priors. Experimental results show the superior performance of the proposed PWLS-MCST2 approach compared to other related recent schemes.



### A Parallel Approach for Real-Time Face Recognition from a Large Database
- **Arxiv ID**: http://arxiv.org/abs/2011.00443v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/2011.00443v1)
- **Published**: 2020-11-01 07:40:10+00:00
- **Updated**: 2020-11-01 07:40:10+00:00
- **Authors**: Ashish Ranjan, Varun Nagesh Jolly Behera, Motahar Reza
- **Comment**: None
- **Journal**: None
- **Summary**: We present a new facial recognition system, capable of identifying a person, provided their likeness has been previously stored in the system, in real time. The system is based on storing and comparing facial embeddings of the subject, and identifying them later within a live video feed. This system is highly accurate, and is able to tag people with their ID in real time. It is able to do so, even when using a database containing thousands of facial embeddings, by using a parallelized searching technique. This makes the system quite fast and allows it to be highly scalable.



### HM4: Hidden Markov Model with Memory Management for Visual Place Recognition
- **Arxiv ID**: http://arxiv.org/abs/2011.00450v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2011.00450v1)
- **Published**: 2020-11-01 08:49:24+00:00
- **Updated**: 2020-11-01 08:49:24+00:00
- **Authors**: Anh-Dzung Doan, Yasir Latif, Tat-Jun Chin, Ian Reid
- **Comment**: Accepted for publication by IEEE Robotics and Automation Letters
- **Journal**: None
- **Summary**: Visual place recognition needs to be robust against appearance variability due to natural and man-made causes. Training data collection should thus be an ongoing process to allow continuous appearance changes to be recorded. However, this creates an unboundedly-growing database that poses time and memory scalability challenges for place recognition methods. To tackle the scalability issue for visual place recognition in autonomous driving, we develop a Hidden Markov Model approach with a two-tiered memory management. Our algorithm, dubbed HM$^4$, exploits temporal look-ahead to transfer promising candidate images between passive storage and active memory when needed. The inference process takes into account both promising images and a coarse representations of the full database. We show that this allows constant time and space inference for a fixed coverage area. The coarse representations can also be updated incrementally to absorb new data. To further reduce the memory requirements, we derive a compact image representation inspired by Locality Sensitive Hashing (LSH). Through experiments on real world data, we demonstrate the excellent scalability and accuracy of the approach under appearance changes and provide comparisons against state-of-the-art techniques.



### Dynamic radiomics: a new methodology to extract quantitative time-related features from tomographic images
- **Arxiv ID**: http://arxiv.org/abs/2011.00454v3
- **DOI**: 10.1007/s10489-021-03053-3
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00454v3)
- **Published**: 2020-11-01 09:23:16+00:00
- **Updated**: 2021-06-03 07:52:06+00:00
- **Authors**: Fengying Che, Ruichuan Shi, Jian Wu, Haoran Li, Shuqin Li, Weixing Chen, Hao Zhang, Zhi Li, Xiaoyu Cui
- **Comment**: Appl Intell (2022)
- **Journal**: None
- **Summary**: The feature extraction methods of radiomics are mainly based on static tomographic images at a certain moment, while the occurrence and development of disease is a dynamic process that cannot be fully reflected by only static characteristics. This study proposes a new dynamic radiomics feature extraction workflow that uses time-dependent tomographic images of the same patient, focuses on the changes in image features over time, and then quantifies them as new dynamic features for diagnostic or prognostic evaluation. We first define the mathematical paradigm of dynamic radiomics and introduce three specific methods that can describe the transformation process of features over time. Three different clinical problems are used to validate the performance of the proposed dynamic feature with conventional 2D and 3D static features.



### 3D-LaneNet+: Anchor Free Lane Detection using a Semi-Local Representation
- **Arxiv ID**: http://arxiv.org/abs/2011.01535v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.01535v2)
- **Published**: 2020-11-01 11:07:13+00:00
- **Updated**: 2020-11-04 12:25:04+00:00
- **Authors**: Netalee Efrat, Max Bluvstein, Shaul Oron, Dan Levi, Noa Garnett, Bat El Shlomo
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2003.05257
- **Journal**: Machine Learning for Autonomous Driving Workshop at the 34th
  Conference on Neural Information ProcessingSystems (NeurIPS 2020), Vancouver,
  Canada
- **Summary**: 3D-LaneNet+ is a camera-based DNN method for anchor free 3D lane detection which is able to detect 3d lanes of any arbitrary topology such as splits, merges, as well as short and perpendicular lanes. We follow recently proposed 3D-LaneNet, and extend it to enable the detection of these previously unsupported lane topologies. Our output representation is an anchor free, semi-local tile representation that breaks down lanes into simple lane segments whose parameters can be learnt. In addition we learn, per lane instance, feature embedding that reasons for the global connectivity of locally detected segments to form full 3d lanes. This combination allows 3D-LaneNet+ to avoid using lane anchors, non-maximum suppression, and lane model fitting as in the original 3D-LaneNet. We demonstrate the efficacy of 3D-LaneNet+ using both synthetic and real world data. Results show significant improvement relative to the original 3D-LaneNet that can be attributed to better generalization to complex lane topologies, curvatures and surface geometries.



### Generating Correct Answers for Progressive Matrices Intelligence Tests
- **Arxiv ID**: http://arxiv.org/abs/2011.00496v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.00496v1)
- **Published**: 2020-11-01 13:21:07+00:00
- **Updated**: 2020-11-01 13:21:07+00:00
- **Authors**: Niv Pekar, Yaniv Benny, Lior Wolf
- **Comment**: To appear in the 34th Conference on Neural Information Processing
  Systems (NeurIPS 2020)
- **Journal**: None
- **Summary**: Raven's Progressive Matrices are multiple-choice intelligence tests, where one tries to complete the missing location in a $3\times 3$ grid of abstract images. Previous attempts to address this test have focused solely on selecting the right answer out of the multiple choices. In this work, we focus, instead, on generating a correct answer given the grid, without seeing the choices, which is a harder task, by definition. The proposed neural model combines multiple advances in generative models, including employing multiple pathways through the same network, using the reparameterization trick along two pathways to make their encoding compatible, a dynamic application of variational losses, and a complex perceptual loss that is coupled with a selective backpropagation procedure. Our algorithm is able not only to generate a set of plausible answers, but also to be competitive to the state of the art methods in multiple-choice tests.



### Learning Euler's Elastica Model for Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2011.00526v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00526v1)
- **Published**: 2020-11-01 15:14:37+00:00
- **Updated**: 2020-11-01 15:14:37+00:00
- **Authors**: Xu Chen, Xiangde Luo, Yitian Zhao, Shaoting Zhang, Guotai Wang, Yalin Zheng
- **Comment**: 9 pages, 4 figures
- **Journal**: None
- **Summary**: Image segmentation is a fundamental topic in image processing and has been studied for many decades. Deep learning-based supervised segmentation models have achieved state-of-the-art performance but most of them are limited by using pixel-wise loss functions for training without geometrical constraints. Inspired by Euler's Elastica model and recent active contour models introduced into the field of deep learning, we propose a novel active contour with elastica (ACE) loss function incorporating Elastica (curvature and length) and region information as geometrically-natural constraints for the image segmentation tasks. We introduce the mean curvature i.e. the average of all principal curvatures, as a more effective image prior to representing curvature in our ACE loss function. Furthermore, based on the definition of the mean curvature, we propose a fast solution to approximate the ACE loss in three-dimensional (3D) by using Laplace operators for 3D image segmentation. We evaluate our ACE loss function on four 2D and 3D natural and biomedical image datasets. Our results show that the proposed loss function outperforms other mainstream loss functions on different segmentation networks. Our source code is available at https://github.com/HiLab-git/ACELoss.



### A Dilated Residual Hierarchically Fashioned Segmentation Framework for Extracting Gleason Tissues and Grading Prostate Cancer from Whole Slide Images
- **Arxiv ID**: http://arxiv.org/abs/2011.00527v5
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00527v5)
- **Published**: 2020-11-01 15:15:30+00:00
- **Updated**: 2021-07-25 14:12:01+00:00
- **Authors**: Taimur Hassan, Bilal Hassan, Ayman El-Baz, Naoufel Werghi
- **Comment**: Accepted in IEEE SAS-2021, Source Code is available at
  https://github.com/taimurhassan/cancer
- **Journal**: None
- **Summary**: Prostate cancer (PCa) is the second deadliest form of cancer in males, and it can be clinically graded by examining the structural representations of Gleason tissues. This paper proposes \RV{a new method} for segmenting the Gleason tissues \RV{(patch-wise) in order to grade PCa from the whole slide images (WSI).} Also, the proposed approach encompasses two main contributions: 1) A synergy of hybrid dilation factors and hierarchical decomposition of latent space representation for effective Gleason tissues extraction, and 2) A three-tiered loss function which can penalize different semantic segmentation models for accurately extracting the highly correlated patterns. In addition to this, the proposed framework has been extensively evaluated on a large-scale PCa dataset containing 10,516 whole slide scans (with around 71.7M patches), where it outperforms state-of-the-art schemes by 3.22% (in terms of mean intersection-over-union) for extracting the Gleason tissues and 6.91% (in terms of F1 score) for grading the progression of PCa.



### On Numerosity of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.08674v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.08674v1)
- **Published**: 2020-11-01 15:30:43+00:00
- **Updated**: 2020-11-01 15:30:43+00:00
- **Authors**: Xi Zhang, Xiaolin Wu
- **Comment**: Accepted to NeurIPS 2020
- **Journal**: None
- **Summary**: Recently, a provocative claim was published that number sense spontaneously emerges in a deep neural network trained merely for visual object recognition. This has, if true, far reaching significance to the fields of machine learning and cognitive science alike. In this paper, we prove the above claim to be unfortunately incorrect. The statistical analysis to support the claim is flawed in that the sample set used to identify number-aware neurons is too small, compared to the huge number of neurons in the object recognition network. By this flawed analysis one could mistakenly identify number-sensing neurons in any randomly initialized deep neural networks that are not trained at all. With the above critique we ask the question what if a deep convolutional neural network is carefully trained for numerosity? Our findings are mixed. Even after being trained with number-depicting images, the deep learning approach still has difficulties to acquire the abstract concept of numbers, a cognitive task that preschoolers perform with ease. But on the other hand, we do find some encouraging evidences suggesting that deep neural networks are more robust to distribution shift for small numbers than for large numbers.



### Adversarial Self-Supervised Scene Flow Estimation
- **Arxiv ID**: http://arxiv.org/abs/2011.00551v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2011.00551v1)
- **Published**: 2020-11-01 16:37:37+00:00
- **Updated**: 2020-11-01 16:37:37+00:00
- **Authors**: Victor Zuanazzi, Joris van Vugt, Olaf Booij, Pascal Mettes
- **Comment**: Published at 3DV 2020
- **Journal**: None
- **Summary**: This work proposes a metric learning approach for self-supervised scene flow estimation. Scene flow estimation is the task of estimating 3D flow vectors for consecutive 3D point clouds. Such flow vectors are fruitful, \eg for recognizing actions, or avoiding collisions. Training a neural network via supervised learning for scene flow is impractical, as this requires manual annotations for each 3D point at each new timestamp for each scene. To that end, we seek for a self-supervised approach, where a network learns a latent metric to distinguish between points translated by flow estimations and the target point cloud. Our adversarial metric learning includes a multi-scale triplet loss on sequences of two-point clouds as well as a cycle consistency loss. Furthermore, we outline a benchmark for self-supervised scene flow estimation: the Scene Flow Sandbox. The benchmark consists of five datasets designed to study individual aspects of flow estimation in progressive order of complexity, from a moving object to real-world scenes. Experimental evaluation on the benchmark shows that our approach obtains state-of-the-art self-supervised scene flow results, outperforming recent neighbor-based approaches. We use our proposed benchmark to expose shortcomings and draw insights on various training setups. We find that our setup captures motion coherence and preserves local geometries. Dealing with occlusions, on the other hand, is still an open challenge.



### Memory Group Sampling Based Online Action Recognition Using Kinetic Skeleton Features
- **Arxiv ID**: http://arxiv.org/abs/2011.00553v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2011.00553v2)
- **Published**: 2020-11-01 16:43:08+00:00
- **Updated**: 2020-11-03 05:09:10+00:00
- **Authors**: Guoliang Liu, Qinghui Zhang, Yichao Cao, Junwei Li, Hao Wu, Guohui Tian
- **Comment**: None
- **Journal**: None
- **Summary**: Online action recognition is an important task for human centered intelligent services, which is still difficult to achieve due to the varieties and uncertainties of spatial and temporal scales of human actions. In this paper, we propose two core ideas to handle the online action recognition problem. First, we combine the spatial and temporal skeleton features to depict the actions, which include not only the geometrical features, but also multi-scale motion features, such that both the spatial and temporal information of the action are covered. Second, we propose a memory group sampling method to combine the previous action frames and current action frames, which is based on the truth that the neighbouring frames are largely redundant, and the sampling mechanism ensures that the long-term contextual information is also considered. Finally, an improved 1D CNN network is employed for training and testing using the features from sampled frames. The comparison results to the state of the art methods using the public datasets show that the proposed method is fast and efficient, and has competitive performance



### LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud-based Deep Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.00566v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2011.00566v1)
- **Published**: 2020-11-01 17:17:10+00:00
- **Updated**: 2020-11-01 17:17:10+00:00
- **Authors**: Hang Zhou, Dongdong Chen, Jing Liao, Weiming Zhang, Kejiang Chen, Xiaoyi Dong, Kunlin Liu, Gang Hua, Nenghai Yu
- **Comment**: CVPR 2020, code available at: https://github.com/RyanHangZhou/LG-GAN
- **Journal**: None
- **Summary**: Deep neural networks have made tremendous progress in 3D point-cloud recognition. Recent works have shown that these 3D recognition networks are also vulnerable to adversarial samples produced from various attack methods, including optimization-based 3D Carlini-Wagner attack, gradient-based iterative fast gradient method, and skeleton-detach based point-dropping. However, after a careful analysis, these methods are either extremely slow because of the optimization/iterative scheme, or not flexible to support targeted attack of a specific category. To overcome these shortcomings, this paper proposes a novel label guided adversarial network (LG-GAN) for real-time flexible targeted point cloud attack. To the best of our knowledge, this is the first generation based 3D point cloud attack method. By feeding the original point clouds and target attack label into LG-GAN, it can learn how to deform the point clouds to mislead the recognition network into the specific label only with a single forward pass. In detail, LGGAN first leverages one multi-branch adversarial network to extract hierarchical features of the input point clouds, then incorporates the specified label information into multiple intermediate features using the label encoder. Finally, the encoded features will be fed into the coordinate reconstruction decoder to generate the target adversarial sample. By evaluating different point-cloud recognition models (e.g., PointNet, PointNet++ and DGCNN), we demonstrate that the proposed LG-GAN can support flexible targeted attack on the fly while guaranteeing good attack performance and higher efficiency simultaneously.



### DeepOpht: Medical Report Generation for Retinal Images via Deep Models and Visual Explanation
- **Arxiv ID**: http://arxiv.org/abs/2011.00569v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2011.00569v1)
- **Published**: 2020-11-01 17:28:12+00:00
- **Updated**: 2020-11-01 17:28:12+00:00
- **Authors**: Jia-Hong Huang, Chao-Han Huck Yang, Fangyu Liu, Meng Tian, Yi-Chieh Liu, Ting-Wei Wu, I-Hung Lin, Kang Wang, Hiromasa Morikawa, Hernghua Chang, Jesper Tegner, Marcel Worring
- **Comment**: Accepted to IEEE WACV 2021
- **Journal**: None
- **Summary**: In this work, we propose an AI-based method that intends to improve the conventional retinal disease treatment procedure and help ophthalmologists increase diagnosis efficiency and accuracy. The proposed method is composed of a deep neural networks-based (DNN-based) module, including a retinal disease identifier and clinical description generator, and a DNN visual explanation module. To train and validate the effectiveness of our DNN-based module, we propose a large-scale retinal disease image dataset. Also, as ground truth, we provide a retinal image dataset manually labeled by ophthalmologists to qualitatively show, the proposed AI-based method is effective. With our experimental results, we show that the proposed method is quantitatively and qualitatively effective. Our method is capable of creating meaningful retinal image descriptions and visual explanations that are clinically relevant.



### Topology-Based Feature Design and Tracking for Multi-Center Cyclones
- **Arxiv ID**: http://arxiv.org/abs/2011.08676v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CG, cs.CV, cs.GR, I.3.5; I.3.6; I.3.8; J.2
- **Links**: [PDF](http://arxiv.org/pdf/2011.08676v1)
- **Published**: 2020-11-01 17:39:27+00:00
- **Updated**: 2020-11-01 17:39:27+00:00
- **Authors**: Wito Engelke, Talha Bin Masood, Jakob Beran, Rodrigo Caballero, Ingrid Hotz
- **Comment**: 13 pages, 9 figures, 8th workshop on Topological Methods in Data
  Analysis and Visualization (TopoInVis 2019)
- **Journal**: None
- **Summary**: In this paper, we propose a concept to design, track, and compare application-specific feature definitions expressed as sets of critical points. Our work has been inspired by the observation that in many applications a large variety of different feature definitions for the same concept are used. Often, these definitions compete with each other and it is unclear which definition should be used in which context. A prominent example is the definition of cyclones in climate research. Despite the differences, frequently these feature definitions can be related to topological concepts.   In our approach, we provide a cyclone tracking framework that supports interactive feature definition and comparison based on a precomputed tracking graph that stores all extremal points as well as their temporal correspondents. The framework combines a set of independent building blocks: critical point extraction, critical point tracking, feature definition, and track exploration. One of the major advantages of such an approach is the flexibility it provides, that is, each block is exchangeable. Moreover, it also enables us to perform the most expensive analysis, the construction of a full tracking graph, as a prepossessing step, while keeping the feature definition interactive. Different feature definitions can be explored and compared interactively based on this tracking graph. Features are specified by rules for grouping critical points, while feature tracking corresponds to filtering and querying the full tracking graph by specific requests. We demonstrate this method for cyclone identification and tracking in the context of climate research.



### Do not trust the neighbors! Adversarial Metric Learning for Self-Supervised Scene Flow Estimation
- **Arxiv ID**: http://arxiv.org/abs/2011.07945v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.07945v1)
- **Published**: 2020-11-01 17:41:32+00:00
- **Updated**: 2020-11-01 17:41:32+00:00
- **Authors**: Victor Zuanazzi
- **Comment**: Master Thesis
- **Journal**: None
- **Summary**: Scene flow is the task of estimating 3D motion vectors to individual points of a dynamic 3D scene. Motion vectors have shown to be beneficial for downstream tasks such as action classification and collision avoidance. However, data collected via LiDAR sensors and stereo cameras are computation and labor intensive to precisely annotate for scene flow. We address this annotation bottleneck on two ends. We propose a 3D scene flow benchmark and a novel self-supervised setup for training flow models. The benchmark consists of datasets designed to study individual aspects of flow estimation in progressive order of complexity, from a single object in motion to real-world scenes. Furthermore, we introduce Adversarial Metric Learning for self-supervised flow estimation. The flow model is fed with sequences of point clouds to perform flow estimation. A second model learns a latent metric to distinguish between the points translated by the flow estimations and the target point cloud. This latent metric is learned via a Multi-Scale Triplet loss, which uses intermediary feature vectors for the loss calculation. We use our proposed benchmark to draw insights about the performance of the baselines and of different models when trained using our setup. We find that our setup is able to keep motion coherence and preserve local geometries, which many self-supervised baselines fail to grasp. Dealing with occlusions, on the other hand, is still an open challenge.



### Human Leg Motion Tracking by Fusing IMUs and RGB Camera Data Using Extended Kalman Filter
- **Arxiv ID**: http://arxiv.org/abs/2011.00574v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.00574v2)
- **Published**: 2020-11-01 17:54:53+00:00
- **Updated**: 2020-12-07 22:20:27+00:00
- **Authors**: Omid Taheri, Hassan Salarieh, Aria Alasty
- **Comment**: This paper results from O. Taheri's MSc Thesis (2017) at the Sharif
  University of Technology
- **Journal**: None
- **Summary**: Human motion capture is frequently used to study rehabilitation and clinical problems, as well as to provide realistic animation for the entertainment industry. IMU-based systems, as well as Marker-based motion tracking systems, are the most popular methods to track movement due to their low cost of implementation and lightweight. This paper proposes a quaternion-based Extended Kalman filter approach to recover the human leg segments motions with a set of IMU sensors data fused with camera-marker system data. In this paper, an Extended Kalman Filter approach is developed to fuse the data of two IMUs and one RGB camera for human leg motion tracking. Based on the complementary properties of the inertial sensors and camera-marker system, in the introduced new measurement model, the orientation data of the upper leg and the lower leg is updated through three measurement equations. The positioning of the human body is made possible by the tracked position of the pelvis joint by the camera marker system. A mathematical model has been utilized to estimate joints' depth in 2D images. The efficiency of the proposed algorithm is evaluated by an optical motion tracker system.



### FusiformNet: Extracting Discriminative Facial Features on Different Levels
- **Arxiv ID**: http://arxiv.org/abs/2011.00577v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.00577v3)
- **Published**: 2020-11-01 18:00:59+00:00
- **Updated**: 2020-11-26 15:49:48+00:00
- **Authors**: Kyo Takano
- **Comment**: FusiformNet for unsupervised feature extraction
- **Journal**: None
- **Summary**: Over the last several years, research on facial recognition based on Deep Neural Network has evolved with approaches like task-specific loss functions, image normalization and augmentation, network architectures, etc. However, there have been few approaches with attention to how human faces differ from person to person. Premising that inter-personal differences are found both generally and locally on the human face, I propose FusiformNet, a novel framework for feature extraction that leverages the nature of discriminative facial features. Tested on Image-Unrestricted setting of Labeled Faces in the Wild benchmark, this method achieved a state-of-the-art accuracy of 96.67% without labeled outside data, image augmentation, normalization, or special loss functions. Likewise, the method also performed on a par with previous state-of-the-arts when pre-trained on CASIA-WebFace dataset. Considering its ability to extract both general and local facial features, the utility of FusiformNet may not be limited to facial recognition but also extend to other DNN-based tasks.



### COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.00597v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG, I.2.7; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2011.00597v1)
- **Published**: 2020-11-01 18:54:09+00:00
- **Updated**: 2020-11-01 18:54:09+00:00
- **Authors**: Simon Ging, Mohammadreza Zolfaghari, Hamed Pirsiavash, Thomas Brox
- **Comment**: 27 pages, 5 figures, 19 tables. To be published in the 34th
  conference on Neural Information Processing Systems (NeurIPS 2020). The first
  two authors contributed equally to this work
- **Journal**: None
- **Summary**: Many real-world video-text tasks involve different levels of granularity, such as frames and words, clip and sentences or videos and paragraphs, each with distinct semantics. In this paper, we propose a Cooperative hierarchical Transformer (COOT) to leverage this hierarchy information and model the interactions between different levels of granularity and different modalities. The method consists of three major components: an attention-aware feature aggregation layer, which leverages the local temporal context (intra-level, e.g., within a clip), a contextual transformer to learn the interactions between low-level and high-level semantics (inter-level, e.g. clip-video, sentence-paragraph), and a cross-modal cycle-consistency loss to connect video and text. The resulting method compares favorably to the state of the art on several benchmarks while having few parameters. All code is available open-source at https://github.com/gingsi/coot-videotext



### Convolution Neural Networks for Semantic Segmentation: Application to Small Datasets of Biomedical Images
- **Arxiv ID**: http://arxiv.org/abs/2011.01747v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.01747v1)
- **Published**: 2020-11-01 19:09:12+00:00
- **Updated**: 2020-11-01 19:09:12+00:00
- **Authors**: Vitaly Nikolaev
- **Comment**: None
- **Journal**: None
- **Summary**: This thesis studies how the segmentation results, produced by convolutional neural networks (CNN), is different from each other when applied to small biomedical datasets. We use different architectures, parameters and hyper-parameters, trying to find out the better configurations for our task, and trying to find out underlying regularities. Two working datasets are from biomedical area of research. We conducted a lot of experiments with the two types of networks and the received results have shown the preference of some conditions of experiments and parameters of the networks over the others. All testing results are given in the tables and some selected resulting graphs and segmentation predictions are shown for better illustration.



### Unsupervised Metric Relocalization Using Transform Consistency Loss
- **Arxiv ID**: http://arxiv.org/abs/2011.00608v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2011.00608v1)
- **Published**: 2020-11-01 19:24:27+00:00
- **Updated**: 2020-11-01 19:24:27+00:00
- **Authors**: Mike Kasper, Fernando Nobre, Christoffer Heckman, Nima Keivan
- **Comment**: Accepted for publication in the 4th Conference on Robot Learning
  (CoRL 2020), Cambridge MA, USA
- **Journal**: None
- **Summary**: Training networks to perform metric relocalization traditionally requires accurate image correspondences. In practice, these are obtained by restricting domain coverage, employing additional sensors, or capturing large multi-view datasets. We instead propose a self-supervised solution, which exploits a key insight: localizing a query image within a map should yield the same absolute pose, regardless of the reference image used for registration. Guided by this intuition, we derive a novel transform consistency loss. Using this loss function, we train a deep neural network to infer dense feature and saliency maps to perform robust metric relocalization in dynamic environments. We evaluate our framework on synthetic and real-world data, showing our approach outperforms other supervised methods when a limited amount of ground-truth information is available.



### Triage of Potential COVID-19 Patients from Chest X-ray Images using Hierarchical Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.00618v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.00618v2)
- **Published**: 2020-11-01 20:01:22+00:00
- **Updated**: 2020-12-15 15:47:46+00:00
- **Authors**: Kapal Dev, Sunder Ali Khowaja, Ankur Singh Bist, Vaibhav Saini, Surbhi Bhatia
- **Comment**: 23 pages, 9 figures, 4 tables
- **Journal**: None
- **Summary**: The current COVID-19 pandemic has motivated the researchers to use artificial intelligence techniques for a potential alternative to reverse transcription-polymerase chain reaction (RT-PCR) due to the limited scale of testing. The chest X-ray (CXR) is one of the alternatives to achieve fast diagnosis but the unavailability of large-scale annotated data makes the clinical implementation of machine learning-based COVID detection difficult. Another issue is the usage of ImageNet pre-trained networks which does not extract reliable feature representations from medical images. In this paper, we propose the use of hierarchical convolutional network (HCN) architecture to naturally augment the data along with diversified features. The HCN uses the first convolution layer from COVIDNet followed by the convolutional layers from well-known pre-trained networks to extract the features. The use of the convolution layer from COVIDNet ensures the extraction of representations relevant to the CXR modality. We also propose the use of ECOC for encoding multiclass problems to binary classification for improving the recognition performance. Experimental results show that HCN architecture is capable of achieving better results in comparison to the existing studies. The proposed method can accurately triage potential COVID-19 patients through CXR images for sharing the testing load and increasing the testing capacity.



### Tracking Partially-Occluded Deformable Objects while Enforcing Geometric Constraints
- **Arxiv ID**: http://arxiv.org/abs/2011.00627v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00627v1)
- **Published**: 2020-11-01 21:13:18+00:00
- **Updated**: 2020-11-01 21:13:18+00:00
- **Authors**: Yixuan Wang, Dale McConachie, Dmitry Berenson
- **Comment**: 7 pages, 5 figures, submitted to 2021 International Conference on
  Robotics and Automation
- **Journal**: None
- **Summary**: In order to manipulate a deformable object, such as rope or cloth, in unstructured environments, robots need a way to estimate its current shape. However, tracking the shape of a deformable object can be challenging because of the object's high flexibility, (self-)occlusion, and interaction with obstacles. Building a high-fidelity physics simulation to aid in tracking is difficult for novel environments. Instead we focus on tracking the object based on RGBD images and geometric motion estimates and obstacles. Our key contributions over previous work in this vein are: 1) A better way to handle severe occlusion by using a motion model to regularize the tracking estimate; and 2) The formulation of \textit{convex} geometric constraints, which allow us to prevent self-intersection and penetration into known obstacles via a post-processing step. These contributions allow us to outperform previous methods by a large margin in terms of accuracy in scenarios with severe occlusion and obstacles.



### Brain Tumor Classification Using Medial Residual Encoder Layers
- **Arxiv ID**: http://arxiv.org/abs/2011.00628v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00628v2)
- **Published**: 2020-11-01 21:19:38+00:00
- **Updated**: 2021-12-09 05:59:06+00:00
- **Authors**: Zahra SobhaniNia, Nader Karimi, Pejman Khadivi, Roshank Roshandel, Shadrokh Samavi
- **Comment**: 4 pages, 4 figures
- **Journal**: None
- **Summary**: According to the World Health Organization (WHO), cancer is the second leading cause of death worldwide, responsible for over 9.5 million deaths in 2018 alone. Brain tumors count for one out of every four cancer deaths. Therefore, accurate and timely diagnosis of brain tumors will lead to more effective treatments. Physicians classify brain tumors only with biopsy operation by brain surgery, and after diagnosing the type of tumor, a treatment plan is considered for the patient. Automatic systems based on machine learning algorithms can allow physicians to diagnose brain tumors with noninvasive measures. To date, several image classification approaches have been proposed to aid diagnosis and treatment. For brain tumor classification in this work, we offer a system based on deep learning, containing encoder blocks. These blocks are fed with post-max-pooling features as residual learning. Our approach shows promising results by improving the tumor classification accuracy in Magnetic resonance imaging (MRI) images using a limited medical image dataset. Experimental evaluations of this model on a dataset consisting of 3064 MR images show 95.98% accuracy, which is better than previous studies on this database.



### Bifurcated Autoencoder for Segmentation of COVID-19 Infected Regions in CT Images
- **Arxiv ID**: http://arxiv.org/abs/2011.00631v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.00631v1)
- **Published**: 2020-11-01 21:32:00+00:00
- **Updated**: 2020-11-01 21:32:00+00:00
- **Authors**: Parham Yazdekhasty, Ali Zindar, Zahra Nabizadeh-ShahreBabak, Roshank Roshandel, Pejman Khadivi, Nader Karimi, Shadrokh Samavi
- **Comment**: 11 pages, 3 Figures
- **Journal**: None
- **Summary**: The new coronavirus infection has shocked the world since early 2020 with its aggressive outbreak. Rapid detection of the disease saves lives, and relying on medical imaging (Computed Tomography and X-ray) to detect infected lungs has shown to be effective. Deep learning and convolutional neural networks have been used for image analysis in this context. However, accurate identification of infected regions has proven challenging for two main reasons. Firstly, the characteristics of infected areas differ in different images. Secondly, insufficient training data makes it challenging to train various machine learning algorithms, including deep-learning models. This paper proposes an approach to segment lung regions infected by COVID-19 to help cardiologists diagnose the disease more accurately, faster, and more manageable. We propose a bifurcated 2-D model for two types of segmentation. This model uses a shared encoder and a bifurcated connection to two separate decoders. One decoder is for segmentation of the healthy region of the lungs, while the other is for the segmentation of the infected regions. Experiments on publically available images show that the bifurcated structure segments infected regions of the lungs better than state of the art.



