# Arxiv Papers in cs.CV on 2020-11-20
### ClickTrain: Efficient and Accurate End-to-End Deep Learning Training via Fine-Grained Architecture-Preserving Pruning
- **Arxiv ID**: http://arxiv.org/abs/2011.10170v4
- **DOI**: 10.1145/3447818.3459988
- **Categories**: **cs.CV**, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/2011.10170v4)
- **Published**: 2020-11-20 01:46:56+00:00
- **Updated**: 2021-05-01 03:33:27+00:00
- **Authors**: Chengming Zhang, Geng Yuan, Wei Niu, Jiannan Tian, Sian Jin, Donglin Zhuang, Zhe Jiang, Yanzhi Wang, Bin Ren, Shuaiwen Leon Song, Dingwen Tao
- **Comment**: 12 pages, 15 figures, 2 tables, published by ICS'21
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) are becoming increasingly deeper, wider, and non-linear because of the growing demand on prediction accuracy and analysis quality. The wide and deep CNNs, however, require a large amount of computing resources and processing time. Many previous works have studied model pruning to improve inference performance, but little work has been done for effectively reducing training cost. In this paper, we propose ClickTrain: an efficient and accurate end-to-end training and pruning framework for CNNs. Different from the existing pruning-during-training work, ClickTrain provides higher model accuracy and compression ratio via fine-grained architecture-preserving pruning. By leveraging pattern-based pruning with our proposed novel accurate weight importance estimation, dynamic pattern generation and selection, and compiler-assisted computation optimizations, ClickTrain generates highly accurate and fast pruned CNN models for direct deployment without any extra time overhead, compared with the baseline training. ClickTrain also reduces the end-to-end time cost of the pruning-after-training method by up to 2.3X with comparable accuracy and compression ratio. Moreover, compared with the state-of-the-art pruning-during-training approach, ClickTrain provides significant improvements both accuracy and compression ratio on the tested CNN models and datasets, under similar limited training time.



### FLAVA: Find, Localize, Adjust and Verify to Annotate LiDAR-Based Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/2011.10174v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2011.10174v1)
- **Published**: 2020-11-20 02:22:36+00:00
- **Updated**: 2020-11-20 02:22:36+00:00
- **Authors**: Tai Wang, Conghui He, Zhe Wang, Jianping Shi, Dahua Lin
- **Comment**: Full technical report for the UIST 2020 Poster version
- **Journal**: None
- **Summary**: Recent years have witnessed the rapid progress of perception algorithms on top of LiDAR, a widely adopted sensor for autonomous driving systems. These LiDAR-based solutions are typically data hungry, requiring a large amount of data to be labeled for training and evaluation. However, annotating this kind of data is very challenging due to the sparsity and irregularity of point clouds and more complex interaction involved in this procedure. To tackle this problem, we propose FLAVA, a systematic approach to minimizing human interaction in the annotation process. Specifically, we divide the annotation pipeline into four parts: find, localize, adjust and verify. In addition, we carefully design the UI for different stages of the annotation procedure, thus keeping the annotators to focus on the aspects that are most important to each stage. Furthermore, our system also greatly reduces the amount of interaction by introducing a light-weight yet effective mechanism to propagate the annotation results. Experimental results show that our method can remarkably accelerate the procedure and improve the annotation quality.



### ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2011.10185v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10185v2)
- **Published**: 2020-11-20 02:52:53+00:00
- **Updated**: 2021-06-01 09:01:10+00:00
- **Authors**: Zhouyong Liu, Shun Luo, Wubin Li, Jingben Lu, Yufan Wu, Shilei Sun, Chunguo Li, Luxi Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (CNNs) are powerful models that have achieved excellent performance on difficult computer vision tasks. Although CNNs perform well whenever large labeled training samples are available, they work badly on video frame synthesis due to objects deforming and moving, scene lighting changes, and cameras moving in video sequence. In this paper, we present a novel and general end-to-end architecture, called convolutional Transformer or ConvTransformer, for video frame sequence learning and video frame synthesis. The core ingredient of ConvTransformer is the proposed attention layer, i.e., multi-head convolutional self-attention layer, that learns the sequential dependence of video sequence. ConvTransformer uses an encoder, built upon multi-head convolutional self-attention layer, to encode the sequential dependence between the input frames, and then a decoder decodes the long-term dependence between the target synthesized frames and the input frames. Experiments on video future frame extrapolation task show ConvTransformer to be superior in quality while being more parallelizable to recent approaches built upon convolutional LSTM (ConvLSTM). To the best of our knowledge, this is the first time that ConvTransformer architecture is proposed and applied to video frame synthesis.



### Targeted Self Supervision for Classification on a Small COVID-19 CT Scan Dataset
- **Arxiv ID**: http://arxiv.org/abs/2011.10188v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10188v1)
- **Published**: 2020-11-20 03:07:17+00:00
- **Updated**: 2020-11-20 03:07:17+00:00
- **Authors**: Nicolas Ewen, Naimul Khan
- **Comment**: Submitted to ISBI 2021
- **Journal**: None
- **Summary**: Traditionally, convolutional neural networks need large amounts of data labelled by humans to train. Self supervision has been proposed as a method of dealing with small amounts of labelled data. The aim of this study is to determine whether self supervision can increase classification performance on a small COVID-19 CT scan dataset. This study also aims to determine whether the proposed self supervision strategy, targeted self supervision, is a viable option for a COVID-19 imaging dataset. A total of 10 experiments are run comparing the classification performance of the proposed method of self supervision with different amounts of data. The experiments run with the proposed self supervision strategy perform significantly better than their non-self supervised counterparts. We get almost 8% increase in accuracy with full self supervision when compared to no self supervision. The results suggest that self supervision can improve classification performance on a small COVID-19 CT scan dataset. Code for targeted self supervision can be found at this link: https://github.com/Mewtwo/Targeted-Self-Supervision/tree/main/COVID-CT



### MobileDepth: Efficient Monocular Depth Prediction on Mobile Devices
- **Arxiv ID**: http://arxiv.org/abs/2011.10189v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10189v1)
- **Published**: 2020-11-20 03:08:54+00:00
- **Updated**: 2020-11-20 03:08:54+00:00
- **Authors**: Yekai Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Depth prediction is fundamental for many useful applications on computer vision and robotic systems. On mobile phones, the performance of some useful applications such as augmented reality, autofocus and so on could be enhanced by accurate depth prediction. In this work, an efficient fully convolutional network architecture for depth prediction has been proposed, which uses RegNetY 06 as the encoder and split-concatenate shuffle blocks as decoder. At the same time, an appropriate combination of data augmentation, hyper-parameters and loss functions to efficiently train the lightweight network has been provided. Also, an Android application has been developed which can load CNN models to predict depth map by the monocular images captured from the mobile camera and evaluate the average latency and frame per second of the models. As a result, the network achieves 82.7% {\delta}1 accuracy on NYU Depth v2 dataset and at the same time, have only 62ms latency on ARM A76 CPUs so that it can predict the depth map from the mobile camera in real-time.



### Action Duration Prediction for Segment-Level Alignment of Weakly-Labeled Videos
- **Arxiv ID**: http://arxiv.org/abs/2011.10190v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10190v1)
- **Published**: 2020-11-20 03:16:53+00:00
- **Updated**: 2020-11-20 03:16:53+00:00
- **Authors**: Reza Ghoddoosian, Saif Sayed, Vassilis Athitsos
- **Comment**: Accepted to WACV 2021
- **Journal**: None
- **Summary**: This paper focuses on weakly-supervised action alignment, where only the ordered sequence of video-level actions is available for training. We propose a novel Duration Network, which captures a short temporal window of the video and learns to predict the remaining duration of a given action at any point in time with a level of granularity based on the type of that action. Further, we introduce a Segment-Level Beam Search to obtain the best alignment, that maximizes our posterior probability. Segment-Level Beam Search efficiently aligns actions by considering only a selected set of frames that have more confident predictions. The experimental results show that our alignments for long videos are more robust than existing models. Moreover, the proposed method achieves state of the art results in certain cases on the popular Breakfast and Hollywood Extended datasets.



### Discriminative Localized Sparse Representations for Breast Cancer Screening
- **Arxiv ID**: http://arxiv.org/abs/2011.10201v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10201v1)
- **Published**: 2020-11-20 04:15:17+00:00
- **Updated**: 2020-11-20 04:15:17+00:00
- **Authors**: Sokratis Makrogiannis, Chelsea E. Harris, Keni Zheng
- **Comment**: None
- **Journal**: None
- **Summary**: Breast cancer is the most common cancer among women both in developed and developing countries. Early detection and diagnosis of breast cancer may reduce its mortality and improve the quality of life. Computer-aided detection (CADx) and computer-aided diagnosis (CAD) techniques have shown promise for reducing the burden of human expert reading and improve the accuracy and reproducibility of results. Sparse analysis techniques have produced relevant results for representing and recognizing imaging patterns. In this work we propose a method for Label Consistent Spatially Localized Ensemble Sparse Analysis (LC-SLESA). In this work we apply dictionary learning to our block based sparse analysis method to classify breast lesions as benign or malignant. The performance of our method in conjunction with LC-KSVD dictionary learning is evaluated using 10-, 20-, and 30-fold cross validation on the MIAS dataset. Our results indicate that the proposed sparse analyses may be a useful component for breast cancer screening applications.



### CLIPPER: A Graph-Theoretic Framework for Robust Data Association
- **Arxiv ID**: http://arxiv.org/abs/2011.10202v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10202v2)
- **Published**: 2020-11-20 04:15:54+00:00
- **Updated**: 2021-04-09 12:57:02+00:00
- **Authors**: Parker C. Lusk, Kaveh Fathian, Jonathan P. How
- **Comment**: accepted ICRA'21
- **Journal**: None
- **Summary**: We present CLIPPER (Consistent LInking, Pruning, and Pairwise Error Rectification), a framework for robust data association in the presence of noise and outliers. We formulate the problem in a graph-theoretic framework using the notion of geometric consistency. State-of-the-art techniques that use this framework utilize either combinatorial optimization techniques that do not scale well to large-sized problems, or use heuristic approximations that yield low accuracy in high-noise, high-outlier regimes. In contrast, CLIPPER uses a relaxation of the combinatorial problem and returns solutions that are guaranteed to correspond to the optima of the original problem. Low time complexity is achieved with an efficient projected gradient ascent approach. Experiments indicate that CLIPPER maintains a consistently low runtime of 15 ms where exact methods can require up to 24 s at their peak, even on small-sized problems with 200 associations. When evaluated on noisy point cloud registration problems, CLIPPER achieves 100% precision and 98% recall in 90% outlier regimes while competing algorithms begin degrading by 70% outliers. In an instance of associating noisy points of the Stanford Bunny with 990 outlier associations and only 10 inlier associations, CLIPPER successfully returns 8 inlier associations with 100% precision in 138 ms. Code is available at https://mit-acl.github.io/clipper.



### DoDNet: Learning to segment multi-organ and tumors from multiple partially labeled datasets
- **Arxiv ID**: http://arxiv.org/abs/2011.10217v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10217v1)
- **Published**: 2020-11-20 04:56:39+00:00
- **Updated**: 2020-11-20 04:56:39+00:00
- **Authors**: Jianpeng Zhang, Yutong Xie, Yong Xia, Chunhua Shen
- **Comment**: None
- **Journal**: None
- **Summary**: Due to the intensive cost of labor and expertise in annotating 3D medical images at a voxel level, most benchmark datasets are equipped with the annotations of only one type of organs and/or tumors, resulting in the so-called partially labeling issue. To address this, we propose a dynamic on-demand network (DoDNet) that learns to segment multiple organs and tumors on partially labeled datasets. DoDNet consists of a shared encoder-decoder architecture, a task encoding module, a controller for generating dynamic convolution filters, and a single but dynamic segmentation head. The information of the current segmentation task is encoded as a task-aware prior to tell the model what the task is expected to solve. Different from existing approaches which fix kernels after training, the kernels in dynamic head are generated adaptively by the controller, conditioned on both input image and assigned task. Thus, DoDNet is able to segment multiple organs and tumors, as done by multiple networks or a multi-head network, in a much efficient and flexible manner. We have created a large-scale partially labeled dataset, termed MOTS, and demonstrated the superior performance of our DoDNet over other competitors on seven organ and tumor segmentation tasks. We also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task and achieved state-of-the-art performance. This study provides a general 3D medical image segmentation model that has been pre-trained on a large-scale partially labelled dataset and can be extended (after fine-tuning) to downstream volumetric medical data segmentation tasks. The dataset and code areavailableat: https://git.io/DoDNet



### Complexity Controlled Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.10223v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10223v1)
- **Published**: 2020-11-20 05:35:55+00:00
- **Updated**: 2020-11-20 05:35:55+00:00
- **Authors**: Himanshu Pant, Jayadeva, Sumit Soman
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: One of the issues faced in training Generative Adversarial Nets (GANs) and their variants is the problem of mode collapse, wherein the training stability in terms of the generative loss increases as more training data is used. In this paper, we propose an alternative architecture via the Low-Complexity Neural Network (LCNN), which attempts to learn models with low complexity. The motivation is that controlling model complexity leads to models that do not overfit the training data. We incorporate the LCNN loss function for GANs, Deep Convolutional GANs (DCGANs) and Spectral Normalized GANs (SNGANs), in order to develop hybrid architectures called the LCNN-GAN, LCNN-DCGAN and LCNN-SNGAN respectively. On various large benchmark image datasets, we show that the use of our proposed models results in stable training while avoiding the problem of mode collapse, resulting in better training stability. We also show how the learning behavior can be controlled by a hyperparameter in the LCNN functional, which also provides an improved inception score.



### Efficient Conditional Pre-training for Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.10231v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10231v5)
- **Published**: 2020-11-20 06:16:15+00:00
- **Updated**: 2021-11-18 20:17:10+00:00
- **Authors**: Shuvam Chakraborty, Burak Uzkent, Kumar Ayush, Kumar Tanmay, Evan Sheehan, Stefano Ermon
- **Comment**: None
- **Journal**: None
- **Summary**: Almost all the state-of-the-art neural networks for computer vision tasks are trained by (1) pre-training on a large-scale dataset and (2) finetuning on the target dataset. This strategy helps reduce dependence on the target dataset and improves convergence rate and generalization on the target task. Although pre-training on large-scale datasets is very useful, its foremost disadvantage is high training cost. To address this, we propose efficient filtering methods to select relevant subsets from the pre-training dataset. Additionally, we discover that lowering image resolutions in the pre-training step offers a great trade-off between cost and performance. We validate our techniques by pre-training on ImageNet in both the unsupervised and supervised settings and finetuning on a diverse collection of target datasets and tasks. Our proposed methods drastically reduce pre-training cost and provide strong performance boosts. Finally, we improve standard ImageNet pre-training by 1-3% by tuning available models on our subsets and pre-training on a dataset filtered from a larger scale dataset.



### Deep Snapshot HDR Imaging Using Multi-Exposure Color Filter Array
- **Arxiv ID**: http://arxiv.org/abs/2011.10232v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10232v1)
- **Published**: 2020-11-20 06:31:37+00:00
- **Updated**: 2020-11-20 06:31:37+00:00
- **Authors**: Takeru Suda, Masayuki Tanaka, Yusuke Monno, Masatoshi Okutomi
- **Comment**: Accepted at ACCV2020 (Oral). Project page:
  http://www.ok.sc.e.titech.ac.jp/res/DSHDR/
- **Journal**: None
- **Summary**: In this paper, we propose a deep snapshot high dynamic range (HDR) imaging framework that can effectively reconstruct an HDR image from the RAW data captured using a multi-exposure color filter array (ME-CFA), which consists of a mosaic pattern of RGB filters with different exposure levels. To effectively learn the HDR image reconstruction network, we introduce the idea of luminance normalization that simultaneously enables effective loss computation and input data normalization by considering relative local contrasts in the "normalized-by-luminance" HDR domain. This idea makes it possible to equally handle the errors in both bright and dark areas regardless of absolute luminance levels, which significantly improves the visual image quality in a tone-mapped domain. Experimental results using two public HDR image datasets demonstrate that our framework outperforms other snapshot methods and produces high-quality HDR images with fewer visual artifacts.



### Shuffle and Learn: Minimizing Mutual Information for Unsupervised Hashing
- **Arxiv ID**: http://arxiv.org/abs/2011.10239v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10239v1)
- **Published**: 2020-11-20 07:14:55+00:00
- **Updated**: 2020-11-20 07:14:55+00:00
- **Authors**: Fangrui Liu, Zheng Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Unsupervised binary representation allows fast data retrieval without any annotations, enabling practical application like fast person re-identification and multimedia retrieval. It is argued that conflicts in binary space are one of the major barriers to high-performance unsupervised hashing as current methods failed to capture the precise code conflicts in the full domain. A novel relaxation method called Shuffle and Learn is proposed to tackle code conflicts in the unsupervised hash. Approximated derivatives for joint probability and the gradients for the binary layer are introduced to bridge the update from the hash to the input. Proof on $\epsilon$-Convergence of joint probability with approximated derivatives is provided to guarantee the preciseness on update applied on the mutual information. The proposed algorithm is carried out with iterative global updates to minimize mutual information, diverging the code before regular unsupervised optimization. Experiments suggest that the proposed method can relax the code optimization from local optimum and help to generate binary representations that are more discriminative and informative without any annotations. Performance benchmarks on image retrieval with the unsupervised binary code are conducted on three open datasets, and the model achieves state-of-the-art accuracy on image retrieval task for all those datasets. Datasets and reproducible code are provided.



### Compressive Shack-Hartmann Wavefront Sensor based on Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.10241v2
- **DOI**: 10.1093/mnras/staa4045
- **Categories**: **astro-ph.IM**, astro-ph.GA, astro-ph.SR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10241v2)
- **Published**: 2020-11-20 07:18:21+00:00
- **Updated**: 2020-12-31 09:04:38+00:00
- **Authors**: Peng Jia, Mingyang Ma, Dongmei Cai, Weihua Wang, Juanjuan Li, Can Li
- **Comment**: To appear in the MNRAS and the complete code can be downloaded from:
  https://nadc.china-vo.org/article/20200722160959?id=101045
- **Journal**: None
- **Summary**: The Shack-Hartmann wavefront sensor is widely used to measure aberrations induced by atmospheric turbulence in adaptive optics systems. However if there exists strong atmospheric turbulence or the brightness of guide stars is low, the accuracy of wavefront measurements will be affected. In this paper, we propose a compressive Shack-Hartmann wavefront sensing method. Instead of reconstructing wavefronts with slope measurements of all sub-apertures, our method reconstructs wavefronts with slope measurements of sub-apertures which have spot images with high signal to noise ratio. Besides, we further propose to use a deep neural network to accelerate wavefront reconstruction speed. During the training stage of the deep neural network, we propose to add a drop-out layer to simulate the compressive sensing process, which could increase development speed of our method. After training, the compressive Shack-Hartmann wavefront sensing method can reconstruct wavefronts in high spatial resolution with slope measurements from only a small amount of sub-apertures. We integrate the straightforward compressive Shack-Hartmann wavefront sensing method with image deconvolution algorithm to develop a high-order image restoration method. We use images restored by the high-order image restoration method to test the performance of our the compressive Shack-Hartmann wavefront sensing method. The results show that our method can improve the accuracy of wavefront measurements and is suitable for real-time applications.



### Point Spread Function Estimation for Wide Field Small Aperture Telescopes with Deep Neural Networks and Calibration Data
- **Arxiv ID**: http://arxiv.org/abs/2011.10243v2
- **DOI**: 10.1093/mnras/stab1461
- **Categories**: **astro-ph.IM**, astro-ph.GA, astro-ph.SR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10243v2)
- **Published**: 2020-11-20 07:26:02+00:00
- **Updated**: 2021-05-18 11:48:57+00:00
- **Authors**: Peng Jia, Xuebo Wu, Zhengyang Li, Bo Li, Weihua Wang, Qiang Liu, Adam Popowicz
- **Comment**: Accepted by the MNRAS
- **Journal**: None
- **Summary**: The point spread function (PSF) reflects states of a telescope and plays an important role in development of data processing methods, such as PSF based astrometry, photometry and image restoration. However, for wide field small aperture telescopes (WFSATs), estimating PSF in any position of the whole field of view is hard, because aberrations induced by the optical system are quite complex and the signal to noise ratio of star images is often too low for PSF estimation. In this paper, we further develop our deep neural network (DNN) based PSF modelling method and show its applications in PSF estimation. During the telescope alignment and testing stage, our method collects system calibration data through modification of optical elements within engineering tolerances (tilting and decentering). Then we use these data to train a DNN (Tel--Net). After training, the Tel--Net can estimate PSF in any field of view from several discretely sampled star images. We use both simulated and experimental data to test performance of our method. The results show that the Tel--Net can successfully reconstruct PSFs of WFSATs of any states and in any positions of the FoV. Its results are significantly more precise than results obtained by the compared classic method - Inverse Distance Weight (IDW) interpolation. Our method provides foundations for developing of deep neural network based data processing methods for WFSATs, which require strong prior information of PSFs.



### Consistency-Aware Graph Network for Human Interaction Understanding
- **Arxiv ID**: http://arxiv.org/abs/2011.10250v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10250v3)
- **Published**: 2020-11-20 07:49:21+00:00
- **Updated**: 2021-03-23 15:32:12+00:00
- **Authors**: Zhenhua Wang, Jiajun Meng, Dongyan Guo, Jianhua Zhang, Javen Qinfeng Shi, Shengyong Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Compared with the progress made on human activity classification, much less success has been achieved on human interaction understanding (HIU). Apart from the latter task is much more challenging, the main cause is that recent approaches learn human interactive relations via shallow graphical models, which is inadequate to model complicated human interactions. In this paper, we propose a consistency-aware graph network, which combines the representative ability of graph network and the consistency-aware reasoning to facilitate the HIU task. Our network consists of three components, a backbone CNN to extract image features, a factor graph network to learn third-order interactive relations among participants, and a consistency-aware reasoning module to enforce labeling and grouping consistencies. Our key observation is that the consistency-aware-reasoning bias for HIU can be embedded into an energy function, minimizing which delivers consistent predictions. An efficient mean-field inference algorithm is proposed, such that all modules of our network could be trained jointly in an end-to-end manner. Experimental results show that our approach achieves leading performance on three benchmarks.



### On-Device Text Image Super Resolution
- **Arxiv ID**: http://arxiv.org/abs/2011.10251v1
- **DOI**: 10.1109/ICPR48806.2021.9412222
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10251v1)
- **Published**: 2020-11-20 07:49:48+00:00
- **Updated**: 2020-11-20 07:49:48+00:00
- **Authors**: Dhruval Jain, Arun D Prabhu, Gopi Ramena, Manoj Goyal, Debi Prasanna Mohanty, Sukumar Moharana, Naresh Purre
- **Comment**: Accepted to the International Conference on Pattern
  Recognition(ICPR), 2020
- **Journal**: None
- **Summary**: Recent research on super-resolution (SR) has witnessed major developments with the advancements of deep convolutional neural networks. There is a need for information extraction from scenic text images or even document images on device, most of which are low-resolution (LR) images. Therefore, SR becomes an essential pre-processing step as Bicubic Upsampling, which is conventionally present in smartphones, performs poorly on LR images. To give the user more control over his privacy, and to reduce the carbon footprint by reducing the overhead of cloud computing and hours of GPU usage, executing SR models on the edge is a necessity in the recent times. There are various challenges in running and optimizing a model on resource-constrained platforms like smartphones. In this paper, we present a novel deep neural network that reconstructs sharper character edges and thus boosts OCR confidence. The proposed architecture not only achieves significant improvement in PSNR over bicubic upsampling on various benchmark datasets but also runs with an average inference time of 11.7 ms per image. We have outperformed state-of-the-art on the Text330 dataset. We also achieve an OCR accuracy of 75.89% on the ICDAR 2015 TextSR dataset, where ground truth has an accuracy of 78.10%.



### Cascade Attentive Dropout for Weakly Supervised Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2011.10258v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10258v1)
- **Published**: 2020-11-20 08:08:13+00:00
- **Updated**: 2020-11-20 08:08:13+00:00
- **Authors**: Wenlong Gao, Ying Chen, Yong Peng
- **Comment**: None
- **Journal**: None
- **Summary**: Weakly supervised object detection (WSOD) aims to classify and locate objects with only image-level supervision. Many WSOD approaches adopt multiple instance learning as the initial model, which is prone to converge to the most discriminative object regions while ignoring the whole object, and therefore reduce the model detection performance. In this paper, a novel cascade attentive dropout strategy is proposed to alleviate the part domination problem, together with an improved global context module. We purposely discard attentive elements in both channel and space dimensions, and capture the inter-pixel and inter-channel dependencies to induce the model to better understand the global context. Extensive experiments have been conducted on the challenging PASCAL VOC 2007 benchmarks, which achieve 49.8% mAP and 66.0% CorLoc, outperforming state-of-the-arts.



### Edge Adaptive Hybrid Regularization Model For Image Deblurring
- **Arxiv ID**: http://arxiv.org/abs/2011.10260v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10260v2)
- **Published**: 2020-11-20 08:12:23+00:00
- **Updated**: 2021-04-06 09:02:24+00:00
- **Authors**: Tingting Zhang, Jie Chen, Caiying Wu, Zhifei He, Tieyong Zeng, Qiyu Jin
- **Comment**: None
- **Journal**: None
- **Summary**: The parameter selection is crucial to regularization based image restoration methods. Generally speaking, a spatially fixed parameter for regularization item in the whole image does not perform well for both edge and smooth areas. A larger parameter of regularization item reduces noise better in smooth areas but blurs edge regions, while a small parameter sharpens edge but causes residual noise. In this paper, an automated spatially adaptive regularization model, which combines the harmonic and TV models, is proposed for reconstruction of noisy and blurred images. In the proposed model, it detects the edges and then spatially adjusts the parameters of Tikhonov and TV regularization terms for each pixel according to the edge information. Accordingly, the edge information matrix will be also dynamically updated during the iterations. Computationally, the newly-established model is convex, which can be solved by the semi-proximal alternating direction method of multipliers (sPADMM) with a linear-rate convergence rate. Numerical simulation results demonstrate that the proposed model effectively reserves the image edges and eliminates the noise and blur at the same time. In comparison to state-of-the-art algorithms, it outperforms other methods in terms of PSNR, SSIM and visual quality.



### SLADE: A Self-Training Framework For Distance Metric Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.10269v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10269v2)
- **Published**: 2020-11-20 08:26:10+00:00
- **Updated**: 2021-03-29 20:15:39+00:00
- **Authors**: Jiali Duan, Yen-Liang Lin, Son Tran, Larry S. Davis, C. -C. Jay Kuo
- **Comment**: Accepted by CVPR 2021
- **Journal**: None
- **Summary**: Most existing distance metric learning approaches use fully labeled data to learn the sample similarities in an embedding space. We present a self-training framework, SLADE, to improve retrieval performance by leveraging additional unlabeled data. We first train a teacher model on the labeled data and use it to generate pseudo labels for the unlabeled data. We then train a student model on both labels and pseudo labels to generate final feature embeddings. We use self-supervised representation learning to initialize the teacher model. To better deal with noisy pseudo labels generated by the teacher network, we design a new feature basis learning component for the student network, which learns basis functions of feature representations for unlabeled data. The learned basis vectors better measure the pairwise similarity and are used to select high-confident samples for training the student network. We evaluate our method on standard retrieval benchmarks: CUB-200, Cars-196 and In-shop. Experimental results demonstrate that our approach significantly improves the performance over the state-of-the-art methods.



### Learning Synthetic to Real Transfer for Localization and Navigational Tasks
- **Arxiv ID**: http://arxiv.org/abs/2011.10274v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, I.2.9
- **Links**: [PDF](http://arxiv.org/pdf/2011.10274v2)
- **Published**: 2020-11-20 08:37:03+00:00
- **Updated**: 2020-11-23 16:43:22+00:00
- **Authors**: Maxime Pietrantoni, Boris Chidlovskii, Tomi Silander
- **Comment**: None
- **Journal**: None
- **Summary**: Autonomous navigation consists in an agent being able to navigate without human intervention or supervision, it affects both high level planning and low level control. Navigation is at the crossroad of multiple disciplines, it combines notions of computer vision, robotics and control. This work aimed at creating, in a simulation, a navigation pipeline whose transfer to the real world could be done with as few efforts as possible. Given the limited time and the wide range of problematic to be tackled, absolute navigation performances while important was not the main objective. The emphasis was rather put on studying the sim2real gap which is one the major bottlenecks of modern robotics and autonomous navigation. To design the navigation pipeline four main challenges arise; environment, localization, navigation and planning. The iGibson simulator is picked for its photo-realistic textures and physics engine. A topological approach to tackle space representation was picked over metric approaches because they generalize better to new environments and are less sensitive to change of conditions. The navigation pipeline is decomposed as a localization module, a planning module and a local navigation module. These modules utilize three different networks, an image representation extractor, a passage detector and a local policy. The laters are trained on specifically tailored tasks with some associated datasets created for those specific tasks. Localization is the ability for the agent to localize itself against a specific space representation. It must be reliable, repeatable and robust to a wide variety of transformations. Localization is tackled as an image retrieval task using a deep neural network trained on an auxiliary task as a feature descriptor extractor. The local policy is trained with behavioral cloning from expert trajectories gathered with ROS navigation stack.



### Joint Representation of Temporal Image Sequences and Object Motion for Video Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2011.10278v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10278v1)
- **Published**: 2020-11-20 08:46:12+00:00
- **Updated**: 2020-11-20 08:46:12+00:00
- **Authors**: Junho Koh, Jaekyum Kim, Younji Shin, Byeongwon Lee, Seungji Yang, Jun Won Choi
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new video object detector (VoD) method referred to as temporal feature aggregation and motion-aware VoD (TM-VoD), which produces a joint representation of temporal image sequences and object motion. The proposed TM-VoD aggregates visual feature maps extracted by convolutional neural networks applying the temporal attention gating and spatial feature alignment. This temporal feature aggregation is performed in two stages in a hierarchical fashion. In the first stage, the visual feature maps are fused at a pixel level via gated attention model. In the second stage, the proposed method aggregates the features after aligning the object features using temporal box offset calibration and weights them according to the cosine similarity measure. The proposed TM-VoD also finds the representation of the motion of objects in two successive steps. The pixel-level motion features are first computed based on the incremental changes between the adjacent visual feature maps. Then, box-level motion features are obtained from both the region of interest (RoI)-aligned pixel-level motion features and the sequential changes of the box coordinates. Finally, all these features are concatenated to produce a joint representation of the objects for VoD. The experiments conducted on the ImageNet VID dataset demonstrate that the proposed method outperforms existing VoD methods and achieves a performance comparable to that of state-of-the-art VoDs.



### ScalarFlow: A Large-Scale Volumetric Data Set of Real-world Scalar Transport Flows for Computer Animation and Machine Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.10284v1
- **DOI**: 10.1145/3355089.3356545
- **Categories**: **cs.GR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10284v1)
- **Published**: 2020-11-20 08:55:00+00:00
- **Updated**: 2020-11-20 08:55:00+00:00
- **Authors**: Marie-Lena Eckert, Kiwon Um, Nils Thuerey
- **Comment**: Details and data at:
  https://ge.in.tum.de/publications/2019-scalarflow-eckert/
- **Journal**: None
- **Summary**: In this paper, we present ScalarFlow, a first large-scale data set of reconstructions of real-world smoke plumes. We additionally propose a framework for accurate physics-based reconstructions from a small number of video streams. Central components of our algorithm are a novel estimation of unseen inflow regions and an efficient regularization scheme. Our data set includes a large number of complex and natural buoyancy-driven flows. The flows transition to turbulent flows and contain observable scalar transport processes. As such, the ScalarFlow data set is tailored towards computer graphics, vision, and learning applications. The published data set will contain volumetric reconstructions of velocity and density, input image sequences, together with calibration data, code, and instructions how to recreate the commodity hardware capture setup. We further demonstrate one of the many potential application areas: a first perceptual evaluation study, which reveals that the complexity of the captured flows requires a huge simulation resolution for regular solvers in order to recreate at least parts of the natural complexity contained in the captured data.



### Learning Object-Centric Video Models by Contrasting Sets
- **Arxiv ID**: http://arxiv.org/abs/2011.10287v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10287v1)
- **Published**: 2020-11-20 09:13:42+00:00
- **Updated**: 2020-11-20 09:13:42+00:00
- **Authors**: Sindy Löwe, Klaus Greff, Rico Jonschkowski, Alexey Dosovitskiy, Thomas Kipf
- **Comment**: NeurIPS 2020 Workshop on Object Representations for Learning and
  Reasoning
- **Journal**: None
- **Summary**: Contrastive, self-supervised learning of object representations recently emerged as an attractive alternative to reconstruction-based training. Prior approaches focus on contrasting individual object representations (slots) against one another. However, a fundamental problem with this approach is that the overall contrastive loss is the same for (i) representing a different object in each slot, as it is for (ii) (re-)representing the same object in all slots. Thus, this objective does not inherently push towards the emergence of object-centric representations in the slots. We address this problem by introducing a global, set-based contrastive loss: instead of contrasting individual slot representations against one another, we aggregate the representations and contrast the joined sets against one another. Additionally, we introduce attention-based encoders to this contrastive setup which simplifies training and provides interpretable object masks. Our results on two synthetic video datasets suggest that this approach compares favorably against previous contrastive methods in terms of reconstruction, future prediction and object separation performance.



### Image Denoising by Gaussian Patch Mixture Model and Low Rank Patches
- **Arxiv ID**: http://arxiv.org/abs/2011.10290v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10290v1)
- **Published**: 2020-11-20 09:28:04+00:00
- **Updated**: 2020-11-20 09:28:04+00:00
- **Authors**: Jing Guo, Shuping Wang, Chen Luo, Qiyu Jin, Michael Kwok-Po Ng
- **Comment**: None
- **Journal**: None
- **Summary**: Non-local self-similarity based low rank algorithms are the state-of-the-art methods for image denoising. In this paper, a new method is proposed by solving two issues: how to improve similar patches matching accuracy and build an appropriate low rank matrix approximation model for Gaussian noise. For the first issue, similar patches can be found locally or globally. Local patch matching is to find similar patches in a large neighborhood which can alleviate noise effect, but the number of patches may be insufficient. Global patch matching is to determine enough similar patches but the error rate of patch matching may be higher. Based on this, we first use local patch matching method to reduce noise and then use Gaussian patch mixture model to achieve global patch matching. The second issue is that there is no low rank matrix approximation model to adapt to Gaussian noise. We build a new model according to the characteristics of Gaussian noise, then prove that there is a globally optimal solution of the model. By solving the two issues, experimental results are reported to show that the proposed approach outperforms the state-of-the-art denoising methods includes several deep learning ones in both PSNR / SSIM values and visual quality.



### 3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2012.05342v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2012.05342v1)
- **Published**: 2020-11-20 09:55:12+00:00
- **Updated**: 2020-11-20 09:55:12+00:00
- **Authors**: Pierre-Etienne Martin, Jenny Benois-Pineau, Renaud Péteri, Julien Morlier
- **Comment**: None
- **Journal**: 25th International Conference on Pattern Recognition (ICPR2020),
  Jan 2021, Milano, Italy
- **Summary**: The paper addresses the problem of recognition of actions in video with low inter-class variability such as Table Tennis strokes. Two stream, "twin" convolutional neural networks are used with 3D convolutions both on RGB data and optical flow. Actions are recognized by classification of temporal windows. We introduce 3D attention modules and examine their impact on classification efficiency. In the context of the study of sportsmen performances, a corpus of the particular actions of table tennis strokes is considered. The use of attention blocks in the network speeds up the training step and improves the classification scores up to 5% with our twin model. We visualize the impact on the obtained features and notice correlation between attention and player movements and position. Score comparison of state-of-the-art action classification method and proposed approach with attentional blocks is performed on the corpus. Proposed model with attention blocks outperforms previous model without them and our baseline.



### Segmentation overlapping wear particles with few labelled data and imbalance sample
- **Arxiv ID**: http://arxiv.org/abs/2011.10313v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10313v1)
- **Published**: 2020-11-20 10:04:16+00:00
- **Updated**: 2020-11-20 10:04:16+00:00
- **Authors**: Peng Peng, Jiugen Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Ferrograph image segmentation is of significance for obtaining features of wear particles. However, wear particles are usually overlapped in the form of debris chains, which makes challenges to segment wear debris. An overlapping wear particle segmentation network (OWPSNet) is proposed in this study to segment the overlapped debris chains. The proposed deep learning model includes three parts: a region segmentation network, an edge detection network and a feature refine module. The region segmentation network is an improved U shape network, and it is applied to separate the wear debris form background of ferrograph image. The edge detection network is used to detect the edges of wear particles. Then, the feature refine module combines low-level features and high-level semantic features to obtain the final results. In order to solve the problem of sample imbalance, we proposed a square dice loss function to optimize the model. Finally, extensive experiments have been carried out on a ferrograph image dataset. Results show that the proposed model is capable of separating overlapping wear particles. Moreover, the proposed square dice loss function can improve the segmentation results, especially for the segmentation results of wear particle edge.



### Assessing out-of-domain generalization for robust building damage detection
- **Arxiv ID**: http://arxiv.org/abs/2011.10328v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.4.6; I.4.0; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/2011.10328v1)
- **Published**: 2020-11-20 10:30:43+00:00
- **Updated**: 2020-11-20 10:30:43+00:00
- **Authors**: Vitus Benson, Alexander Ecker
- **Comment**: Published at NeurIPS 2020 Workshop on Artificial Intelligence for
  Humanitarian Assistance and Disaster Response (AI+HADR 2020)
- **Journal**: None
- **Summary**: An important step for limiting the negative impact of natural disasters is rapid damage assessment after a disaster occurred. For instance, building damage detection can be automated by applying computer vision techniques to satellite imagery. Such models operate in a multi-domain setting: every disaster is inherently different (new geolocation, unique circumstances), and models must be robust to a shift in distribution between disaster imagery available for training and the images of the new event. Accordingly, estimating real-world performance requires an out-of-domain (OOD) test set. However, building damage detection models have so far been evaluated mostly in the simpler yet unrealistic in-distribution (IID) test setting. Here we argue that future work should focus on the OOD regime instead. We assess OOD performance of two competitive damage detection models and find that existing state-of-the-art models show a substantial generalization gap: their performance drops when evaluated OOD on new disasters not used during training. Moreover, IID performance is not predictive of OOD performance, rendering current benchmarks uninformative about real-world performance. Code and model weights are available at https://github.com/ecker-lab/robust-bdd.



### ANIMC: A Soft Framework for Auto-weighted Noisy and Incomplete Multi-view Clustering
- **Arxiv ID**: http://arxiv.org/abs/2011.10331v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10331v3)
- **Published**: 2020-11-20 10:37:27+00:00
- **Updated**: 2021-09-28 04:02:45+00:00
- **Authors**: Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu
- **Comment**: Publisheded in IEEE Transactions on Artificial Intelligence
- **Journal**: IEEE Transactions on Artificial Intelligence 2021
- **Summary**: Multi-view clustering has wide applications in many image processing scenarios. In these scenarios, original image data often contain missing instances and noises, which is ignored by most multi-view clustering methods. However, missing instances may make these methods difficult to use directly and noises will lead to unreliable clustering results. In this paper, we propose a novel Auto-weighted Noisy and Incomplete Multi-view Clustering framework (ANIMC) via a soft auto-weighted strategy and a doubly soft regular regression model. Firstly, by designing adaptive semi-regularized nonnegative matrix factorization (adaptive semi-RNMF), the soft auto-weighted strategy assigns a proper weight to each view and adds a soft boundary to balance the influence of noises and incompleteness. Secondly, by proposing{\theta}-norm, the doubly soft regularized regression model adjusts the sparsity of our model by choosing different{\theta}. Compared with existing methods, ANIMC has three unique advantages: 1) it is a soft algorithm to adjust our framework in different scenarios, thereby improving its generalization ability; 2) it automatically learns a proper weight for each view, thereby reducing the influence of noises; 3) it performs doubly soft regularized regression that aligns the same instances in different views, thereby decreasing the impact of missing instances. Extensive experimental results demonstrate its superior advantages over other state-of-the-art methods.



### Self-Supervised Small Soccer Player Detection and Tracking
- **Arxiv ID**: http://arxiv.org/abs/2011.10336v1
- **DOI**: 10.1145/3422844.3423054
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10336v1)
- **Published**: 2020-11-20 10:57:18+00:00
- **Updated**: 2020-11-20 10:57:18+00:00
- **Authors**: Samuel Hurault, Coloma Ballester, Gloria Haro
- **Comment**: In Proceedings of the 3rd International Workshop on Multimedia
  Content Analysis in Sports (MMSports '20)
- **Journal**: Proceedings of the 3rd International Workshop on Multimedia
  Content Analysis in Sports (2020) 9-18
- **Summary**: In a soccer game, the information provided by detecting and tracking brings crucial clues to further analyze and understand some tactical aspects of the game, including individual and team actions. State-of-the-art tracking algorithms achieve impressive results in scenarios on which they have been trained for, but they fail in challenging ones such as soccer games. This is frequently due to the player small relative size and the similar appearance among players of the same team. Although a straightforward solution would be to retrain these models by using a more specific dataset, the lack of such publicly available annotated datasets entails searching for other effective solutions. In this work, we propose a self-supervised pipeline which is able to detect and track low-resolution soccer players under different recording conditions without any need of ground-truth data. Extensive quantitative and qualitative experimental results are presented evaluating its performance. We also present a comparison to several state-of-the-art methods showing that both the proposed detector and the proposed tracker achieve top-tier results, in particular in the presence of small players.



### RidgeSfM: Structure from Motion via Robust Pairwise Matching Under Depth Uncertainty
- **Arxiv ID**: http://arxiv.org/abs/2011.10359v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10359v1)
- **Published**: 2020-11-20 11:59:20+00:00
- **Updated**: 2020-11-20 11:59:20+00:00
- **Authors**: Benjamin Graham, David Novotny
- **Comment**: Presenting at 3DV 2020. Source code released at
  https://github.com/facebookresearch/RidgeSfM
- **Journal**: None
- **Summary**: We consider the problem of simultaneously estimating a dense depth map and camera pose for a large set of images of an indoor scene. While classical SfM pipelines rely on a two-step approach where cameras are first estimated using a bundle adjustment in order to ground the ensuing multi-view stereo stage, both our poses and dense reconstructions are a direct output of an altered bundle adjuster. To this end, we parametrize each depth map with a linear combination of a limited number of basis "depth-planes" predicted in a monocular fashion by a deep net. Using a set of high-quality sparse keypoint matches, we optimize over the per-frame linear combinations of depth planes and camera poses to form a geometrically consistent cloud of keypoints. Although our bundle adjustment only considers sparse keypoints, the inferred linear coefficients of the basis planes immediately give us dense depth maps. RidgeSfM is able to collectively align hundreds of frames, which is its main advantage over recent memory-heavy deep alternatives that can align at most 10 frames. Quantitative comparisons reveal performance superior to a state-of-the-art large-scale SfM pipeline.



### Neural Scene Graphs for Dynamic Scenes
- **Arxiv ID**: http://arxiv.org/abs/2011.10379v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2011.10379v3)
- **Published**: 2020-11-20 12:37:10+00:00
- **Updated**: 2021-03-05 16:21:16+00:00
- **Authors**: Julian Ost, Fahim Mannan, Nils Thuerey, Julian Knodt, Felix Heide
- **Comment**: Updated Project Page http://light.princeton.edu/neural-scene-graphs
- **Journal**: None
- **Summary**: Recent implicit neural rendering methods have demonstrated that it is possible to learn accurate view synthesis for complex scenes by predicting their volumetric density and color supervised solely by a set of RGB images. However, existing methods are restricted to learning efficient representations of static scenes that encode all scene objects into a single neural network, and lack the ability to represent dynamic scenes and decompositions into individual scene objects. In this work, we present the first neural rendering method that decomposes dynamic scenes into scene graphs. We propose a learned scene graph representation, which encodes object transformation and radiance, to efficiently render novel arrangements and views of the scene. To this end, we learn implicitly encoded scenes, combined with a jointly learned latent representation to describe objects with a single implicit function. We assess the proposed method on synthetic and real automotive data, validating that our approach learns dynamic scenes -- only by observing a video of this scene -- and allows for rendering novel photo-realistic views of novel scene compositions with unseen sets of objects at unseen poses.



### Born Identity Network: Multi-way Counterfactual Map Generation to Explain a Classifier's Decision
- **Arxiv ID**: http://arxiv.org/abs/2011.10381v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10381v4)
- **Published**: 2020-11-20 12:43:08+00:00
- **Updated**: 2021-04-08 05:24:34+00:00
- **Authors**: Kwanseok Oh, Jee Seok Yoon, Heung-Il Suk
- **Comment**: 17 pages, 10 figures
- **Journal**: None
- **Summary**: There exists an apparent negative correlation between performance and interpretability of deep learning models. In an effort to reduce this negative correlation, we propose a Born Identity Network (BIN), which is a post-hoc approach for producing multi-way counterfactual maps. A counterfactual map transforms an input sample to be conditioned and classified as a target label, which is similar to how humans process knowledge through counterfactual thinking. For example, a counterfactual map can localize hypothetical abnormalities from a normal brain image that may cause it to be diagnosed with a disease. Specifically, our proposed BIN consists of two core components: Counterfactual Map Generator and Target Attribution Network. The Counterfactual Map Generator is a variation of conditional GAN which can synthesize a counterfactual map conditioned on an arbitrary target label. The Target Attribution Network provides adequate assistance for generating synthesized maps by conditioning a target label into the Counterfactual Map Generator. We have validated our proposed BIN in qualitative and quantitative analysis on MNIST, 3D Shapes, and ADNI datasets, and showed the comprehensibility and fidelity of our method from various ablation studies.



### Combining Deep Transfer Learning with Signal-image Encoding for Multi-Modal Mental Wellbeing Classification
- **Arxiv ID**: http://arxiv.org/abs/2012.03711v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2012.03711v1)
- **Published**: 2020-11-20 13:37:23+00:00
- **Updated**: 2020-11-20 13:37:23+00:00
- **Authors**: Kieran Woodward, Eiman Kanjo, Athanasios Tsanas
- **Comment**: None
- **Journal**: None
- **Summary**: The quantification of emotional states is an important step to understanding wellbeing. Time series data from multiple modalities such as physiological and motion sensor data have proven to be integral for measuring and quantifying emotions. Monitoring emotional trajectories over long periods of time inherits some critical limitations in relation to the size of the training data. This shortcoming may hinder the development of reliable and accurate machine learning models. To address this problem, this paper proposes a framework to tackle the limitation in performing emotional state recognition on multiple multimodal datasets: 1) encoding multivariate time series data into coloured images; 2) leveraging pre-trained object recognition models to apply a Transfer Learning (TL) approach using the images from step 1; 3) utilising a 1D Convolutional Neural Network (CNN) to perform emotion classification from physiological data; 4) concatenating the pre-trained TL model with the 1D CNN. Furthermore, the possibility of performing TL to infer stress from physiological data is explored by initially training a 1D CNN using a large physical activity dataset and then applying the learned knowledge to the target dataset. We demonstrate that model performance when inferring real-world wellbeing rated on a 5-point Likert scale can be enhanced using our framework, resulting in up to 98.5% accuracy, outperforming a conventional CNN by 4.5%. Subject-independent models using the same approach resulted in an average of 72.3% accuracy (SD 0.038). The proposed CNN-TL-based methodology may overcome problems with small training datasets, thus improving on the performance of conventional deep learning methods.



### Smart obervation method with wide field small aperture telescopes for real time transient detection
- **Arxiv ID**: http://arxiv.org/abs/2011.10407v1
- **DOI**: None
- **Categories**: **astro-ph.IM**, astro-ph.GA, astro-ph.SR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10407v1)
- **Published**: 2020-11-20 13:48:32+00:00
- **Updated**: 2020-11-20 13:48:32+00:00
- **Authors**: Peng Jia, Qiang Liu, Yongyang Sun, Yitian Zheng, Wenbo Liu, Yifei Zhao
- **Comment**: To appear in Proc. of SPIE 2020, Paper Number (11449-80), Comments
  are welcome
- **Journal**: None
- **Summary**: Wide field small aperture telescopes (WFSATs) are commonly used for fast sky survey. Telescope arrays composed by several WFSATs are capable to scan sky several times per night. Huge amount of data would be obtained by them and these data need to be processed immediately. In this paper, we propose ARGUS (Astronomical taRGets detection framework for Unified telescopes) for real-time transit detection. The ARGUS uses a deep learning based astronomical detection algorithm implemented in embedded devices in each WFSATs to detect astronomical targets. The position and probability of a detection being an astronomical targets will be sent to a trained ensemble learning algorithm to output information of celestial sources. After matching these sources with star catalog, ARGUS will directly output type and positions of transient candidates. We use simulated data to test the performance of ARGUS and find that ARGUS can increase the performance of WFSATs in transient detection tasks robustly.



### Robust super-resolution depth imaging via a multi-feature fusion deep network
- **Arxiv ID**: http://arxiv.org/abs/2011.11444v2
- **DOI**: 10.1364/OE.415563
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.11444v2)
- **Published**: 2020-11-20 14:24:12+00:00
- **Updated**: 2021-02-01 11:25:46+00:00
- **Authors**: Alice Ruget, Stephen McLaughlin, Robert K. Henderson, Istvan Gyongy, Abderrahim Halimi, Jonathan Leach
- **Comment**: None
- **Journal**: None
- **Summary**: Three-dimensional imaging plays an important role in imaging applications where it is necessary to record depth. The number of applications that use depth imaging is increasing rapidly, and examples include self-driving autonomous vehicles and auto-focus assist on smartphone cameras. Light detection and ranging (LIDAR) via single-photon sensitive detector (SPAD) arrays is an emerging technology that enables the acquisition of depth images at high frame rates. However, the spatial resolution of this technology is typically low in comparison to the intensity images recorded by conventional cameras. To increase the native resolution of depth images from a SPAD camera, we develop a deep network built specifically to take advantage of the multiple features that can be extracted from a camera's histogram data. The network is designed for a SPAD camera operating in a dual-mode such that it captures alternate low resolution depth and high resolution intensity images at high frame rates, thus the system does not require any additional sensor to provide intensity images. The network then uses the intensity images and multiple features extracted from downsampled histograms to guide the upsampling of the depth. Our network provides significant image resolution enhancement and image denoising across a wide range of signal-to-noise ratios and photon levels. We apply the network to a range of 3D data, demonstrating denoising and a four-fold resolution enhancement of depth.



### SalSum: Saliency-based Video Summarization using Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.10432v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10432v1)
- **Published**: 2020-11-20 14:53:08+00:00
- **Updated**: 2020-11-20 14:53:08+00:00
- **Authors**: George Pantazis, George Dimas, Dimitris K. Iakovidis
- **Comment**: 18 pages, 5 figures. Submitted to Multimedia Tools and Applications
- **Journal**: None
- **Summary**: The huge amount of video data produced daily by camera-based systems, such as surveilance, medical and telecommunication systems, emerges the need for effective video summarization (VS) methods. These methods should be capable of creating an overview of the video content. In this paper, we propose a novel VS method based on a Generative Adversarial Network (GAN) model pre-trained with human eye fixations. The main contribution of the proposed method is that it can provide perceptually compatible video summaries by combining both perceived color and spatiotemporal visual attention cues in a unsupervised scheme. Several fusion approaches are considered for robustness under uncertainty, and personalization. The proposed method is evaluated in comparison to state-of-the-art VS approaches on the benchmark dataset VSUMM. The experimental results conclude that SalSum outperforms the state-of-the-art approaches by providing the highest f-measure score on the VSUMM benchmark.



### Crowdsourcing Airway Annotations in Chest Computed Tomography Images
- **Arxiv ID**: http://arxiv.org/abs/2011.10433v1
- **DOI**: 10.1371/journal.pone.0249580
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2011.10433v1)
- **Published**: 2020-11-20 14:54:32+00:00
- **Updated**: 2020-11-20 14:54:32+00:00
- **Authors**: Veronika Cheplygina, Adria Perez-Rovira, Wieying Kuo, Harm A. W. M. Tiddens, Marleen de Bruijne
- **Comment**: None
- **Journal**: None
- **Summary**: Measuring airways in chest computed tomography (CT) scans is important for characterizing diseases such as cystic fibrosis, yet very time-consuming to perform manually. Machine learning algorithms offer an alternative, but need large sets of annotated scans for good performance. We investigate whether crowdsourcing can be used to gather airway annotations. We generate image slices at known locations of airways in 24 subjects and request the crowd workers to outline the airway lumen and airway wall. After combining multiple crowd workers, we compare the measurements to those made by the experts in the original scans. Similar to our preliminary study, a large portion of the annotations were excluded, possibly due to workers misunderstanding the instructions. After excluding such annotations, moderate to strong correlations with the expert can be observed, although these correlations are slightly lower than inter-expert correlations. Furthermore, the results across subjects in this study are quite variable. Although the crowd has potential in annotating airways, further development is needed for it to be robust enough for gathering annotations in practice. For reproducibility, data and code are available online: \url{http://github.com/adriapr/crowdairway.git}.



### Bridging Scene Understanding and Task Execution with Flexible Simulation Environments
- **Arxiv ID**: http://arxiv.org/abs/2011.10452v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10452v1)
- **Published**: 2020-11-20 15:29:23+00:00
- **Updated**: 2020-11-20 15:29:23+00:00
- **Authors**: Zachary Ravichandran, J. Daniel Griffith, Benjamin Smith, Costas Frost
- **Comment**: None
- **Journal**: None
- **Summary**: Significant progress has been made in scene understanding which seeks to build 3D, metric and object-oriented representations of the world. Concurrently, reinforcement learning has made impressive strides largely enabled by advances in simulation. Comparatively, there has been less focus in simulation for perception algorithms. Simulation is becoming increasingly vital as sophisticated perception approaches such as metric-semantic mapping or 3D dynamic scene graph generation require precise 3D, 2D, and inertial information in an interactive environment. To that end, we present TESSE (Task Execution with Semantic Segmentation Environments), an open source simulator for developing scene understanding and task execution algorithms. TESSE has been used to develop state-of-the-art solutions for metric-semantic mapping and 3D dynamic scene graph generation. Additionally, TESSE served as the platform for the GOSEEK Challenge at the International Conference of Robotics and Automation (ICRA) 2020, an object search competition with an emphasis on reinforcement learning. Code for TESSE is available at https://github.com/MIT-TESSE.



### Improvement of Classification in One-Stage Detector
- **Arxiv ID**: http://arxiv.org/abs/2011.10465v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10465v1)
- **Published**: 2020-11-20 15:56:44+00:00
- **Updated**: 2020-11-20 15:56:44+00:00
- **Authors**: Wu Kehe, Chen Zuge, Zhang Xiaoliang, Li Wei
- **Comment**: 17 pages, 5 figures
- **Journal**: None
- **Summary**: RetinaNet proposed Focal Loss for classification task and improved one-stage detectors greatly. However, there is still a gap between it and two-stage detectors. We analyze the prediction of RetinaNet and find that the misalignment of classification and localization is the main factor. Most of predicted boxes, whose IoU with ground-truth boxes are greater than 0.5, while their classification scores are lower than 0.5, which shows that the classification task still needs to be optimized. In this paper we proposed an object confidence task for this problem, and it shares features with classification task. This task uses IoUs between samples and ground-truth boxes as targets, and it only uses losses of positive samples in training, which can increase loss weight of positive samples in classification task training. Also the joint of classification score and object confidence will be used to guide NMS. Our method can not only improve classification task, but also ease misalignment of classification and localization. To evaluate the effectiveness of this method, we show our experiments on MS COCO 2017 dataset. Without whistles and bells, our method can improve AP by 0.7% and 1.0% on COCO validation dataset with ResNet50 and ResNet101 respectively at same training configs, and it can achieve 38.4% AP with two times training time. Code is at: http://github.com/chenzuge1/RetinaNet-Conf.git.



### DeepPhaseCut: Deep Relaxation in Phase for Unsupervised Fourier Phase Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2011.10475v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2011.10475v1)
- **Published**: 2020-11-20 16:10:08+00:00
- **Updated**: 2020-11-20 16:10:08+00:00
- **Authors**: Eunju Cha, Chanseok Lee, Mooseok Jang, Jong Chul Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Fourier phase retrieval is a classical problem of restoring a signal only from the measured magnitude of its Fourier transform. Although Fienup-type algorithms, which use prior knowledge in both spatial and Fourier domains, have been widely used in practice, they can often stall in local minima. Modern methods such as PhaseLift and PhaseCut may offer performance guarantees with the help of convex relaxation. However, these algorithms are usually computationally intensive for practical use. To address this problem, we propose a novel, unsupervised, feed-forward neural network for Fourier phase retrieval which enables immediate high quality reconstruction. Unlike the existing deep learning approaches that use a neural network as a regularization term or an end-to-end blackbox model for supervised training, our algorithm is a feed-forward neural network implementation of PhaseCut algorithm in an unsupervised learning framework. Specifically, our network is composed of two generators: one for the phase estimation using PhaseCut loss, followed by another generator for image reconstruction, all of which are trained simultaneously using a cycleGAN framework without matched data. The link to the classical Fienup-type algorithms and the recent symmetry-breaking learning approach is also revealed. Extensive experiments demonstrate that the proposed method outperforms all existing approaches in Fourier phase retrieval problems.



### Recovering the Imperfect: Cell Segmentation in the Presence of Dynamically Localized Proteins
- **Arxiv ID**: http://arxiv.org/abs/2011.10486v1
- **DOI**: 10.1007/978-3-030-61166-8_9
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10486v1)
- **Published**: 2020-11-20 16:30:55+00:00
- **Updated**: 2020-11-20 16:30:55+00:00
- **Authors**: Özgün Çiçek, Yassine Marrakchi, Enoch Boasiako Antwi, Barbara Di Ventura, Thomas Brox
- **Comment**: Accepted at MICCAI Workshop on Medical Image Learning with Less
  Labels and Imperfect Data, 2020
- **Journal**: None
- **Summary**: Deploying off-the-shelf segmentation networks on biomedical data has become common practice, yet if structures of interest in an image sequence are visible only temporarily, existing frame-by-frame methods fail. In this paper, we provide a solution to segmentation of imperfect data through time based on temporal propagation and uncertainty estimation. We integrate uncertainty estimation into Mask R-CNN network and propagate motion-corrected segmentation masks from frames with low uncertainty to those frames with high uncertainty to handle temporary loss of signal for segmentation. We demonstrate the value of this approach over frame-by-frame segmentation and regular temporal propagation on data from human embryonic kidney (HEK293T) cells transiently transfected with a fluorescent protein that moves in and out of the nucleus over time. The method presented here will empower microscopic experiments aimed at understanding molecular and cellular function.



### Synthetic Image Rendering Solves Annotation Problem in Deep Learning Nanoparticle Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2011.10505v1
- **DOI**: None
- **Categories**: **cs.LG**, cond-mat.mtrl-sci, cs.CV, eess.IV, physics.app-ph
- **Links**: [PDF](http://arxiv.org/pdf/2011.10505v1)
- **Published**: 2020-11-20 17:05:36+00:00
- **Updated**: 2020-11-20 17:05:36+00:00
- **Authors**: Leonid Mill, David Wolff, Nele Gerrits, Patrick Philipp, Lasse Kling, Florian Vollnhals, Andrew Ignatenko, Christian Jaremenko, Yixing Huang, Olivier De Castro, Jean-Nicolas Audinot, Inge Nelissen, Tom Wirtz, Andreas Maier, Silke Christiansen
- **Comment**: None
- **Journal**: None
- **Summary**: Nanoparticles occur in various environments as a consequence of man-made processes, which raises concerns about their impact on the environment and human health. To allow for proper risk assessment, a precise and statistically relevant analysis of particle characteristics (such as e.g. size, shape and composition) is required that would greatly benefit from automated image analysis procedures. While deep learning shows impressive results in object detection tasks, its applicability is limited by the amount of representative, experimentally collected and manually annotated training data. Here, we present an elegant, flexible and versatile method to bypass this costly and tedious data acquisition process. We show that using a rendering software allows to generate realistic, synthetic training data to train a state-of-the art deep neural network. Using this approach, we derive a segmentation accuracy that is comparable to man-made annotations for toxicologically relevant metal-oxide nanoparticle ensembles which we chose as examples. Our study paves the way towards the use of deep learning for automated, high-throughput particle detection in a variety of imaging techniques such as microscopies and spectroscopies, for a wide variety of studies and applications, including the detection of plastic micro- and nanoparticles.



### Seismic Facies Analysis: A Deep Domain Adaptation Approach
- **Arxiv ID**: http://arxiv.org/abs/2011.10510v3
- **DOI**: None
- **Categories**: **physics.geo-ph**, cs.AI, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10510v3)
- **Published**: 2020-11-20 17:09:06+00:00
- **Updated**: 2021-10-27 04:25:17+00:00
- **Authors**: M Quamer Nasim, Tannistha Maiti, Ayush Srivastava, Tarry Singh, Jie Mei
- **Comment**: 22 pages, 13 figures, 5 tables, and supplementary material included
  in the end of the paper
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) can learn accurately from large quantities of labeled input data, but often fail to do so when labelled data are scarce. DNNs sometimes fail to generalize ontest data sampled from different input distributions. Unsupervised Deep Domain Adaptation (DDA)techniques have been proven useful when no labels are available, and when distribution shifts are observed in the target domain (TD). In the present study, experiments are performed on seismic images of the F3 block 3D dataset from offshore Netherlands (source domain; SD) and Penobscot 3D survey data from Canada (target domain; TD). Three geological classes from SD and TD that have similar reflection patterns are considered. A deep neural network architecture named EarthAdaptNet (EAN) is proposed to semantically segment the seismic images when few classes have data scarcity, and we use a transposed residual unit to replace the traditional dilated convolution in the decoder block. The EAN achieved a pixel-level accuracy >84% and an accuracy of ~70% for the minority classes, showing improved performance compared to existing architectures. In addition, we introduce the CORAL (Correlation Alignment) method to the EAN to create an unsupervised deep domain adaptation network (EAN-DDA) for the classification of seismic reflections from F3 and Penobscot, to demonstrate possible approaches when labelled data are unavailable. Maximum class accuracy achieved was ~99% for class 2 of Penobscot, with an overall accuracy>50%. Taken together, the EAN-DDA has the potential to classify target domain seismic facies classes with high accuracy.



### Intrinsic Image Decomposition using Paradigms
- **Arxiv ID**: http://arxiv.org/abs/2011.10512v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10512v1)
- **Published**: 2020-11-20 17:10:12+00:00
- **Updated**: 2020-11-20 17:10:12+00:00
- **Authors**: D. A. Forsyth, Jason J. Rock
- **Comment**: None
- **Journal**: None
- **Summary**: Intrinsic image decomposition is the classical task of mapping image to albedo. The WHDR dataset allows methods to be evaluated by comparing predictions to human judgements ("lighter", "same as", "darker"). The best modern intrinsic image methods learn a map from image to albedo using rendered models and human judgements. This is convenient for practical methods, but cannot explain how a visual agent without geometric, surface and illumination models and a renderer could learn to recover intrinsic images.   This paper describes a method that learns intrinsic image decomposition without seeing WHDR annotations, rendered data, or ground truth data. The method relies on paradigms - fake albedos and fake shading fields - together with a novel smoothing procedure that ensures good behavior at short scales on real images. Long scale error is controlled by averaging. Our method achieves WHDR scores competitive with those of strong recent methods allowed to see training WHDR annotations, rendered data, and ground truth data. Because our method is unsupervised, we can compute estimates of the test/train variance of WHDR scores; these are quite large, and it is unsafe to rely small differences in reported WHDR.



### Exploring Simple Siamese Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.10566v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10566v1)
- **Published**: 2020-11-20 18:59:33+00:00
- **Updated**: 2020-11-20 18:59:33+00:00
- **Authors**: Xinlei Chen, Kaiming He
- **Comment**: Technical report, 10 pages
- **Journal**: None
- **Summary**: Siamese networks have become a common structure in various recent models for unsupervised visual representation learning. These models maximize the similarity between two augmentations of one image, subject to certain conditions for avoiding collapsing solutions. In this paper, we report surprising empirical results that simple Siamese networks can learn meaningful representations even using none of the following: (i) negative sample pairs, (ii) large batches, (iii) momentum encoders. Our experiments show that collapsing solutions do exist for the loss and structure, but a stop-gradient operation plays an essential role in preventing collapsing. We provide a hypothesis on the implication of stop-gradient, and further show proof-of-concept experiments verifying it. Our "SimSiam" method achieves competitive results on ImageNet and downstream tasks. We hope this simple baseline will motivate people to rethink the roles of Siamese architectures for unsupervised representation learning. Code will be made available.



### ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos
- **Arxiv ID**: http://arxiv.org/abs/2011.10600v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10600v1)
- **Published**: 2020-11-20 19:19:48+00:00
- **Updated**: 2020-11-20 19:19:48+00:00
- **Authors**: Yasser Dahou, Marouane Tliba, Kevin McGuinness, Noel O'Connor
- **Comment**: None
- **Journal**: None
- **Summary**: The spherical domain representation of 360 video/image presents many challenges related to the storage, processing, transmission and rendering of omnidirectional videos (ODV). Models of human visual attention can be used so that only a single viewport is rendered at a time, which is important when developing systems that allow users to explore ODV with head mounted displays (HMD). Accordingly, researchers have proposed various saliency models for 360 video/images. This paper proposes ATSal, a novel attention based (head-eye) saliency model for 360\degree videos. The attention mechanism explicitly encodes global static visual attention allowing expert models to focus on learning the saliency on local patches throughout consecutive frames. We compare the proposed approach to other state-of-the-art saliency models on two datasets: Salient360! and VR-EyeTracking. Experimental results on over 80 ODV videos (75K+ frames) show that the proposed method outperforms the existing state-of-the-art.



### Large Scale Neural Architecture Search with Polyharmonic Splines
- **Arxiv ID**: http://arxiv.org/abs/2011.10608v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10608v1)
- **Published**: 2020-11-20 19:50:35+00:00
- **Updated**: 2020-11-20 19:50:35+00:00
- **Authors**: Ulrich Finkler, Michele Merler, Rameswar Panda, Mayoore S. Jaiswal, Hui Wu, Kandan Ramakrishnan, Chun-Fu Chen, Minsik Cho, David Kung, Rogerio Feris, Bishwaranjan Bhattacharjee
- **Comment**: None
- **Journal**: None
- **Summary**: Neural Architecture Search (NAS) is a powerful tool to automatically design deep neural networks for many tasks, including image classification. Due to the significant computational burden of the search phase, most NAS methods have focused so far on small, balanced datasets. All attempts at conducting NAS at large scale have employed small proxy sets, and then transferred the learned architectures to larger datasets by replicating or stacking the searched cells. We propose a NAS method based on polyharmonic splines that can perform search directly on large scale, imbalanced target datasets. We demonstrate the effectiveness of our method on the ImageNet22K benchmark[16], which contains 14 million images distributed in a highly imbalanced manner over 21,841 categories. By exploring the search space of the ResNet [23] and Big-Little Net ResNext [11] architectures directly on ImageNet22K, our polyharmonic splines NAS method designed a model which achieved a top-1 accuracy of 40.03% on ImageNet22K, an absolute improvement of 3.13% over the state of the art with similar global batch size [15].



### Semantic SLAM with Autonomous Object-Level Data Association
- **Arxiv ID**: http://arxiv.org/abs/2011.10625v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10625v1)
- **Published**: 2020-11-20 20:33:39+00:00
- **Updated**: 2020-11-20 20:33:39+00:00
- **Authors**: Zhentian Qian, Kartik Patath, Jie Fu, Jing Xiao
- **Comment**: None
- **Journal**: None
- **Summary**: It is often desirable to capture and map semantic information of an environment during simultaneous localization and mapping (SLAM). Such semantic information can enable a robot to better distinguish places with similar low-level geometric and visual features and perform high-level tasks that use semantic information about objects to be manipulated and environments to be navigated. While semantic SLAM has gained increasing attention, there is little research on semanticlevel data association based on semantic objects, i.e., object-level data association. In this paper, we propose a novel object-level data association algorithm based on bag of words algorithm, formulated as a maximum weighted bipartite matching problem. With object-level data association solved, we develop a quadratic-programming-based semantic object initialization scheme using dual quadric and introduce additional constraints to improve the success rate of object initialization. The integrated semantic-level SLAM system can achieve high-accuracy object-level data association and real-time semantic mapping as demonstrated in the experiments. The online semantic map building and semantic-level localization capabilities facilitate semantic-level mapping and task planning in a priori unknown environment.



### Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images
- **Arxiv ID**: http://arxiv.org/abs/2011.10650v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.10650v2)
- **Published**: 2020-11-20 21:35:31+00:00
- **Updated**: 2021-03-16 18:33:19+00:00
- **Authors**: Rewon Child
- **Comment**: 17 pages, 14 figures
- **Journal**: None
- **Summary**: We present a hierarchical VAE that, for the first time, generates samples quickly while outperforming the PixelCNN in log-likelihood on all natural image benchmarks. We begin by observing that, in theory, VAEs can actually represent autoregressive models, as well as faster, better models if they exist, when made sufficiently deep. Despite this, autoregressive models have historically outperformed VAEs in log-likelihood. We test if insufficient depth explains why by scaling a VAE to greater stochastic depth than previously explored and evaluating it CIFAR-10, ImageNet, and FFHQ. In comparison to the PixelCNN, these very deep VAEs achieve higher likelihoods, use fewer parameters, generate samples thousands of times faster, and are more easily applied to high-resolution images. Qualitative studies suggest this is because the VAE learns efficient hierarchical visual representations. We release our source code and models at https://github.com/openai/vdvae.



### Upgraded W-Net with Attention Gates and its Application in Unsupervised 3D Liver Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2011.10654v1
- **DOI**: 10.5220/0010221504880494
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10654v1)
- **Published**: 2020-11-20 21:45:28+00:00
- **Updated**: 2020-11-20 21:45:28+00:00
- **Authors**: Dhanunjaya Mitta, Soumick Chatterjee, Oliver Speck, Andreas Nürnberger
- **Comment**: None
- **Journal**: Proceedings of the 10th International Conference on Pattern
  Recognition Applications and Methods 2021 - Volume 1
- **Summary**: Segmentation of biomedical images can assist radiologists to make a better diagnosis and take decisions faster by helping in the detection of abnormalities, such as tumors. Manual or semi-automated segmentation, however, can be a time-consuming task. Most deep learning based automated segmentation methods are supervised and rely on manually segmented ground-truth. A possible solution for the problem would be an unsupervised deep learning based approach for automated segmentation, which this research work tries to address. We use a W-Net architecture and modified it, such that it can be applied to 3D volumes. In addition, to suppress noise in the segmentation we added attention gates to the skip connections. The loss for the segmentation output was calculated using soft N-Cuts and for the reconstruction output using SSIM. Conditional Random Fields were used as a post-processing step to fine-tune the results. The proposed method has shown promising results, with a dice coefficient of 0.88 for the liver segmentation compared against manual segmentation.



### From Recognition to Prediction: Analysis of Human Action and Trajectory Prediction in Video
- **Arxiv ID**: http://arxiv.org/abs/2011.10670v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10670v3)
- **Published**: 2020-11-20 22:23:34+00:00
- **Updated**: 2021-07-16 13:45:43+00:00
- **Authors**: Junwei Liang
- **Comment**: Ph.D. Thesis. Version 2: Defense. See here:
  https://junweiliang.github.io/thesis/
- **Journal**: None
- **Summary**: With the advancement in computer vision deep learning, systems now are able to analyze an unprecedented amount of rich visual information from videos to enable applications such as autonomous driving, socially-aware robot assistant and public safety monitoring. Deciphering human behaviors to predict their future paths/trajectories and what they would do from videos is important in these applications. However, human trajectory prediction still remains a challenging task, as scene semantics and human intent are difficult to model. Many systems do not provide high-level semantic attributes to reason about pedestrian future. This design hinders prediction performance in video data from diverse domains and unseen scenarios. To enable optimal future human behavioral forecasting, it is crucial for the system to be able to detect and analyze human activities as well as scene semantics, passing informative features to the subsequent prediction module for context understanding.



### A Review and Comparative Study on Probabilistic Object Detection in Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/2011.10671v2
- **DOI**: 10.1109/TITS.2021.3096854
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2011.10671v2)
- **Published**: 2020-11-20 22:30:36+00:00
- **Updated**: 2021-07-11 07:04:10+00:00
- **Authors**: Di Feng, Ali Harakeh, Steven Waslander, Klaus Dietmayer
- **Comment**: Accepted in the IEEE Transactions on Intelligent Transportation
  Systems
- **Journal**: None
- **Summary**: Capturing uncertainty in object detection is indispensable for safe autonomous driving. In recent years, deep learning has become the de-facto approach for object detection, and many probabilistic object detectors have been proposed. However, there is no summary on uncertainty estimation in deep object detection, and existing methods are not only built with different network architectures and uncertainty estimation methods, but also evaluated on different datasets with a wide range of evaluation metrics. As a result, a comparison among methods remains challenging, as does the selection of a model that best suits a particular application. This paper aims to alleviate this problem by providing a review and comparative study on existing probabilistic object detection methods for autonomous driving applications. First, we provide an overview of generic uncertainty estimation in deep learning, and then systematically survey existing methods and evaluation metrics for probabilistic object detection. Next, we present a strict comparative study for probabilistic object detection based on an image detector and three public autonomous driving datasets. Finally, we present a discussion of the remaining challenges and future works. Code has been made available at https://github.com/asharakeh/pod_compare.git



### An Effective Anti-Aliasing Approach for Residual Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.10675v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10675v1)
- **Published**: 2020-11-20 22:55:57+00:00
- **Updated**: 2020-11-20 22:55:57+00:00
- **Authors**: Cristina Vasconcelos, Hugo Larochelle, Vincent Dumoulin, Nicolas Le Roux, Ross Goroshin
- **Comment**: None
- **Journal**: None
- **Summary**: Image pre-processing in the frequency domain has traditionally played a vital role in computer vision and was even part of the standard pipeline in the early days of deep learning. However, with the advent of large datasets, many practitioners concluded that this was unnecessary due to the belief that these priors can be learned from the data itself. Frequency aliasing is a phenomenon that may occur when sub-sampling any signal, such as an image or feature map, causing distortion in the sub-sampled output. We show that we can mitigate this effect by placing non-trainable blur filters and using smooth activation functions at key locations, particularly where networks lack the capacity to learn them. These simple architectural changes lead to substantial improvements in out-of-distribution generalization on both image classification under natural corruptions on ImageNet-C [10] and few-shot learning on Meta-Dataset [17], without introducing additional trainable parameters and using the default hyper-parameters of open source codebases.



### Open-Vocabulary Object Detection Using Captions
- **Arxiv ID**: http://arxiv.org/abs/2011.10678v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.10678v2)
- **Published**: 2020-11-20 23:05:46+00:00
- **Updated**: 2021-03-14 18:45:04+00:00
- **Authors**: Alireza Zareian, Kevin Dela Rosa, Derek Hao Hu, Shih-Fu Chang
- **Comment**: To be presented at CVPR 2021 (oral paper)
- **Journal**: None
- **Summary**: Despite the remarkable accuracy of deep neural networks in object detection, they are costly to train and scale due to supervision requirements. Particularly, learning more object categories typically requires proportionally more bounding box annotations. Weakly supervised and zero-shot learning techniques have been explored to scale object detectors to more categories with less supervision, but they have not been as successful and widely adopted as supervised models. In this paper, we put forth a novel formulation of the object detection problem, namely open-vocabulary object detection, which is more general, more practical, and more effective than weakly supervised and zero-shot approaches. We propose a new method to train object detectors using bounding box annotations for a limited set of object categories, as well as image-caption pairs that cover a larger variety of objects at a significantly lower cost. We show that the proposed method can detect and localize objects for which no bounding box annotation is provided during training, at a significantly higher accuracy than zero-shot approaches. Meanwhile, objects with bounding box annotation can be detected almost as accurately as supervised methods, which is significantly better than weakly supervised baselines. Accordingly, we establish a new state of the art for scalable object detection.



### HAWQV3: Dyadic Neural Network Quantization
- **Arxiv ID**: http://arxiv.org/abs/2011.10680v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.10680v3)
- **Published**: 2020-11-20 23:51:43+00:00
- **Updated**: 2021-06-23 07:49:12+00:00
- **Authors**: Zhewei Yao, Zhen Dong, Zhangcheng Zheng, Amir Gholami, Jiali Yu, Eric Tan, Leyuan Wang, Qijing Huang, Yida Wang, Michael W. Mahoney, Kurt Keutzer
- **Comment**: None
- **Journal**: ICML 2021
- **Summary**: Current low-precision quantization algorithms often have the hidden cost of conversion back and forth from floating point to quantized integer values. This hidden cost limits the latency improvement realized by quantizing Neural Networks. To address this, we present HAWQV3, a novel mixed-precision integer-only quantization framework. The contributions of HAWQV3 are the following: (i) An integer-only inference where the entire computational graph is performed only with integer multiplication, addition, and bit shifting, without any floating point operations or even integer division; (ii) A novel hardware-aware mixed-precision quantization method where the bit-precision is calculated by solving an integer linear programming problem that balances the trade-off between model perturbation and other constraints, e.g., memory footprint and latency; (iii) Direct hardware deployment and open source contribution for 4-bit uniform/mixed-precision quantization in TVM, achieving an average speed up of $1.45\times$ for uniform 4-bit, as compared to uniform 8-bit for ResNet50 on T4 GPUs; and (iv) extensive evaluation of the proposed methods on ResNet18/50 and InceptionV3, for various model compression levels with/without mixed precision. For ResNet50, our INT8 quantization achieves an accuracy of $77.58\%$, which is $2.68\%$ higher than prior integer-only work, and our mixed-precision INT4/8 quantization can reduce INT8 latency by $23\%$ and still achieve $76.73\%$ accuracy. Our framework and the TVM implementation have been open sourced.



