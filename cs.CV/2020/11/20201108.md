# Arxiv Papers in cs.CV on 2020-11-08
### Channel Pruning Guided by Spatial and Channel Attention for DNNs in Intelligent Edge Computing
- **Arxiv ID**: http://arxiv.org/abs/2011.03891v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2011.03891v2)
- **Published**: 2020-11-08 02:40:06+00:00
- **Updated**: 2021-06-21 12:48:48+00:00
- **Authors**: Mengran Liu, Weiwei Fang, Xiaodong Ma, Wenyuan Xu, Naixue Xiong, Yi Ding
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) have achieved remarkable success in many computer vision tasks recently, but the huge number of parameters and the high computation overhead hinder their deployments on resource-constrained edge devices. It is worth noting that channel pruning is an effective approach for compressing DNN models. A critical challenge is to determine which channels are to be removed, so that the model accuracy will not be negatively affected. In this paper, we first propose Spatial and Channel Attention (SCA), a new attention module combining both spatial and channel attention that respectively focuses on "where" and "what" are the most informative parts. Guided by the scale values generated by SCA for measuring channel importance, we further propose a new channel pruning approach called Channel Pruning guided by Spatial and Channel Attention (CPSCA). Experimental results indicate that SCA achieves the best inference accuracy, while incurring negligibly extra resource consumption, compared to other state-of-the-art attention modules. Our evaluation on two benchmark datasets shows that, with the guidance of SCA, our CPSCA approach achieves higher inference accuracy than other state-of-the-art pruning methods under the same pruning ratios.



### Cross-Modal Self-Attention Distillation for Prostate Cancer Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2011.03908v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, I.4.6; I.2.6; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/2011.03908v1)
- **Published**: 2020-11-08 06:19:13+00:00
- **Updated**: 2020-11-08 06:19:13+00:00
- **Authors**: Guokai Zhang, Xiaoang Shen, Ye Luo, Jihao Luo, Zeju Wang, Weigang Wang, Binghui Zhao, Jianwei Lu
- **Comment**: 2020 IEEE International Conference on Bioinformatics and Biomedicine
  (BIBM)
- **Journal**: None
- **Summary**: Automatic segmentation of the prostate cancer from the multi-modal magnetic resonance images is of critical importance for the initial staging and prognosis of patients. However, how to use the multi-modal image features more efficiently is still a challenging problem in the field of medical image segmentation. In this paper, we develop a cross-modal self-attention distillation network by fully exploiting the encoded information of the intermediate layers from different modalities, and the extracted attention maps of different modalities enable the model to transfer the significant spatial information with more details. Moreover, a novel spatial correlated feature fusion module is further employed for learning more complementary correlation and non-linear information of different modality images. We evaluate our model in five-fold cross-validation on 358 MRI with biopsy confirmed. Extensive experiment results demonstrate that our proposed network achieves state-of-the-art performance.



### Faster object tracking pipeline for real time tracking
- **Arxiv ID**: http://arxiv.org/abs/2011.03910v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03910v1)
- **Published**: 2020-11-08 06:33:48+00:00
- **Updated**: 2020-11-08 06:33:48+00:00
- **Authors**: Parthesh Soni, Falak Shah, Nisarg Vyas
- **Comment**: 12 pages, 6 figures
- **Journal**: None
- **Summary**: Multi-object tracking (MOT) is a challenging practical problem for vision based applications. Most recent approaches for MOT use precomputed detections from models such as Faster RCNN, performing fine-tuning of bounding boxes and association in subsequent phases. However, this is not suitable for actual industrial applications due to unavailability of detections upfront. In their recent work, Wang et al. proposed a tracking pipeline that uses a Joint detection and embedding model and performs target localization and association in realtime. Upon investigating the tracking by detection paradigm, we find that the tracking pipeline can be made faster by performing localization and association tasks parallely with model prediction. This, and other computational optimizations such as using mixed precision model and performing batchwise detection result in a speed-up of the tracking pipeline by 57.8\% (19 FPS to 30 FPS) on FullHD resolution. Moreover, the speed is independent of the object density in image sequence. The main contribution of this paper is showcasing a generic pipeline which can be used to speed up detection based object tracking methods. We also reviewed different batch sizes for optimal performance, taking into consideration GPU memory usage and speed.



### Integrating Human Gaze into Attention for Egocentric Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/2011.03920v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03920v1)
- **Published**: 2020-11-08 08:02:30+00:00
- **Updated**: 2020-11-08 08:02:30+00:00
- **Authors**: Kyle Min, Jason J. Corso
- **Comment**: WACV 2021 camera ready (Supplementary material: on CVF soon)
- **Journal**: None
- **Summary**: It is well known that human gaze carries significant information about visual attention. However, there are three main difficulties in incorporating the gaze data in an attention mechanism of deep neural networks: 1) the gaze fixation points are likely to have measurement errors due to blinking and rapid eye movements; 2) it is unclear when and how much the gaze data is correlated with visual attention; and 3) gaze data is not always available in many real-world situations. In this work, we introduce an effective probabilistic approach to integrate human gaze into spatiotemporal attention for egocentric activity recognition. Specifically, we represent the locations of gaze fixation points as structured discrete latent variables to model their uncertainties. In addition, we model the distribution of gaze fixations using a variational method. The gaze distribution is learned during the training process so that the ground-truth annotations of gaze locations are no longer needed in testing situations since they are predicted from the learned gaze distribution. The predicted gaze locations are used to provide informative attentional cues to improve the recognition performance. Our method outperforms all the previous state-of-the-art approaches on EGTEA, which is a large-scale dataset for egocentric activity recognition provided with gaze measurements. We also perform an ablation study and qualitative analysis to demonstrate that our attention mechanism is effective.



### Point Transformer for Shape Classification and Retrieval of 3D and ALS Roof PointClouds
- **Arxiv ID**: http://arxiv.org/abs/2011.03921v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03921v2)
- **Published**: 2020-11-08 08:11:02+00:00
- **Updated**: 2021-02-20 08:54:37+00:00
- **Authors**: Dimple A Shajahan, Mukund Varma T, Ramanathan Muthuganapathy
- **Comment**: Submitted on June, 16 2020
- **Journal**: None
- **Summary**: The success of deep learning methods led to significant breakthroughs in 3-D point cloud processing tasks with applications in remote sensing. Existing methods utilize convolutions that have some limitations, as they assume a uniform input distribution and cannot learn long-range dependencies. Recent works have shown that adding attention in conjunction with these methods improves performance. This raises a question: can attention layers completely replace convolutions? This paper proposes a fully attentional model - {\em Point Transformer}, for deriving a rich point cloud representation. The model's shape classification and retrieval performance are evaluated on a large-scale urban dataset - RoofN3D and a standard benchmark dataset ModelNet40. Extensive experiments are conducted to test the model's robustness to unseen point corruptions for analyzing its effectiveness on real datasets. The proposed method outperforms other state-of-the-art models in the RoofN3D dataset, gives competitive results in the ModelNet40 benchmark, and showcases high robustness to various unseen point corruptions. Furthermore, the model is highly memory and space efficient when compared to other methods.



### Multi-Temporal Convolutions for Human Action Recognition in Videos
- **Arxiv ID**: http://arxiv.org/abs/2011.03949v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03949v2)
- **Published**: 2020-11-08 10:40:26+00:00
- **Updated**: 2021-03-31 15:02:49+00:00
- **Authors**: Alexandros Stergiou, Ronald Poppe
- **Comment**: None
- **Journal**: None
- **Summary**: Effective extraction of temporal patterns is crucial for the recognition of temporally varying actions in video. We argue that the fixed-sized spatio-temporal convolution kernels used in convolutional neural networks (CNNs) can be improved to extract informative motions that are executed at different time scales. To address this challenge, we present a novel spatio-temporal convolution block that is capable of extracting spatio-temporal patterns at multiple temporal resolutions. Our proposed multi-temporal convolution (MTConv) blocks utilize two branches that focus on brief and prolonged spatio-temporal patterns, respectively. The extracted time-varying features are aligned in a third branch, with respect to global motion patterns through recurrent cells. The proposed blocks are lightweight and can be integrated into any 3D-CNN architecture. This introduces a substantial reduction in computational costs. Extensive experiments on Kinetics, Moments in Time and HACS action recognition benchmark datasets demonstrate competitive performance of MTConvs compared to the state-of-the-art with a significantly lower computational footprint.



### Principles of Stochastic Computing: Fundamental Concepts and Applications
- **Arxiv ID**: http://arxiv.org/abs/2011.05153v1
- **DOI**: None
- **Categories**: **cs.ET**, cs.CV, 60G05, 60G07, 60G35, 60G57, 60G60, 60-01, 60-03, A.1; G.3; I.0; K.2
- **Links**: [PDF](http://arxiv.org/pdf/2011.05153v1)
- **Published**: 2020-11-08 10:40:59+00:00
- **Updated**: 2020-11-08 10:40:59+00:00
- **Authors**: S. Rahimi Kari
- **Comment**: 11 pages, 19 figures
- **Journal**: None
- **Summary**: The semiconductor and IC industry is facing the issue of high energy consumption. In modern days computers and processing systems are designed based on the Turing machine and Von Neumann's architecture. This architecture mainly focused on designing systems based on deterministic behaviors. To tackle energy consumption and reliability in systems, Stochastic Computing was introduced. In this research, we aim to review and study the principles behind stochastic computing and its implementation techniques. By utilizing stochastic computing, we can achieve higher energy efficiency and smaller area sizes in terms of designing arithmetic units. Also, we aim to popularize the affiliation of Stochastic systems in designing futuristic BLSI and Neuromorphic systems.



### FlowCaps: Optical Flow Estimation with Capsule Networks For Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/2011.03958v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03958v1)
- **Published**: 2020-11-08 11:35:08+00:00
- **Updated**: 2020-11-08 11:35:08+00:00
- **Authors**: Vinoj Jayasundara, Debaditya Roy, Basura Fernando
- **Comment**: None
- **Journal**: None
- **Summary**: Capsule networks (CapsNets) have recently shown promise to excel in most computer vision tasks, especially pertaining to scene understanding. In this paper, we explore CapsNet's capabilities in optical flow estimation, a task at which convolutional neural networks (CNNs) have already outperformed other approaches. We propose a CapsNet-based architecture, termed FlowCaps, which attempts to a) achieve better correspondence matching via finer-grained, motion-specific, and more-interpretable encoding crucial for optical flow estimation, b) perform better-generalizable optical flow estimation, c) utilize lesser ground truth data, and d) significantly reduce the computational complexity in achieving good performance, in comparison to its CNN-counterparts.



### The quantization error in a Self-Organizing Map as a contrast and colour specific indicator of single-pixel change in large random patterns
- **Arxiv ID**: http://arxiv.org/abs/2011.03970v1
- **DOI**: 10.1016/j.neunet.2019.08.014
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.03970v1)
- **Published**: 2020-11-08 12:41:24+00:00
- **Updated**: 2020-11-08 12:41:24+00:00
- **Authors**: John M Wandeto, Birgitta Dresp-Langley
- **Comment**: None
- **Journal**: Neural Networks, 2019 Nov;119:273-285. PMID: 31473578
- **Summary**: The quantization error in a fixed-size Self-Organizing Map (SOM) with unsupervised winner-take-all learning has previously been used successfully to detect, in minimal computation time, highly meaningful changes across images in medical time series and in time series of satellite images. Here, the functional properties of the quantization error in SOM are explored further to show that the metric is capable of reliably discriminating between the finest differences in local contrast intensities and contrast signs. While this capability of the QE is akin to functional characteristics of a specific class of retinal ganglion cells (the so-called Y-cells) in the visual systems of the primate and the cat, the sensitivity of the QE surpasses the capacity limits of human visual detection. Here, the quantization error in the SOM is found to reliably signal changes in contrast or colour when contrast information is removed from or added to the image, but not when the amount and relative weight of contrast information is constant and only the local spatial position of contrast elements in the pattern changes. While the RGB Mean reflects coarser changes in colour or contrast well enough, the SOM-QE is shown to outperform the RGB Mean in the detection of single-pixel changes in images with up to five million pixels. This could have important implications in the context of unsupervised image learning and computational building block approaches to large sets of image data (big data), including deep learning blocks, and automatic detection of contrast change at the nanoscale in Transmission or Scanning Electron Micrographs (TEM, SEM), or at the subpixel level in multispectral and hyper-spectral imaging data.



### Adaptive Linear Span Network for Object Skeleton Detection
- **Arxiv ID**: http://arxiv.org/abs/2011.03972v1
- **DOI**: 10.1109/TIP.2021.3078079
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2011.03972v1)
- **Published**: 2020-11-08 12:51:14+00:00
- **Updated**: 2020-11-08 12:51:14+00:00
- **Authors**: Chang Liu, Yunjie Tian, Jianbin Jiao, Qixiang Ye
- **Comment**: 13 pages, 9 figures
- **Journal**: None
- **Summary**: Conventional networks for object skeleton detection are usually hand-crafted. Although effective, they require intensive priori knowledge to configure representative features for objects in different scale granularity.In this paper, we propose adaptive linear span network (AdaLSN), driven by neural architecture search (NAS), to automatically configure and integrate scale-aware features for object skeleton detection. AdaLSN is formulated with the theory of linear span, which provides one of the earliest explanations for multi-scale deep feature fusion. AdaLSN is materialized by defining a mixed unit-pyramid search space, which goes beyond many existing search spaces using unit-level or pyramid-level features.Within the mixed space, we apply genetic architecture search to jointly optimize unit-level operations and pyramid-level connections for adaptive feature space expansion. AdaLSN substantiates its versatility by achieving significantly higher accuracy and latency trade-off compared with state-of-the-arts. It also demonstrates general applicability to image-to-mask tasks such as edge detection and road extraction. Code is available at \href{https://github.com/sunsmarterjie/SDL-Skeleton}{\color{magenta}github.com/sunsmarterjie/SDL-Skeleton}.



### Learning-based 3D Occupancy Prediction for Autonomous Navigation in Occluded Environments
- **Arxiv ID**: http://arxiv.org/abs/2011.03981v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.03981v2)
- **Published**: 2020-11-08 13:51:34+00:00
- **Updated**: 2021-03-27 10:54:16+00:00
- **Authors**: Lizi Wang, Hongkai Ye, Qianhao Wang, Yuman Gao, Chao Xu, Fei Gao
- **Comment**: None
- **Journal**: None
- **Summary**: In autonomous navigation of mobile robots, sensors suffer from massive occlusion in cluttered environments, leaving significant amount of space unknown during planning. In practice, treating the unknown space in optimistic or pessimistic ways both set limitations on planning performance, thus aggressiveness and safety cannot be satisfied at the same time. However, humans can infer the exact shape of the obstacles from only partial observation and generate non-conservative trajectories that avoid possible collisions in occluded space. Mimicking human behavior, in this paper, we propose a method based on deep neural network to predict occupancy distribution of unknown space reliably. Specifically, the proposed method utilizes contextual information of environments and learns from prior knowledge to predict obstacle distributions in occluded space. We use unlabeled and no-ground-truth data to train our network and successfully apply it to real-time navigation in unseen environments without any refinement. Results show that our method leverages the performance of a kinodynamic planner by improving security with no reduction of speed in clustered environments.



### Real-time Surgical Environment Enhancement for Robot-Assisted Minimally Invasive Surgery Based on Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2011.04003v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2011.04003v1)
- **Published**: 2020-11-08 15:40:05+00:00
- **Updated**: 2020-11-08 15:40:05+00:00
- **Authors**: Ruoxi Wang, Dandan Zhang, Qingbiao Li, Xiao-Yun Zhou, Benny Lo
- **Comment**: None
- **Journal**: None
- **Summary**: In Robot-Assisted Minimally Invasive Surgery (RAMIS), a camera assistant is normally required to control the position and zooming ratio of the laparoscope, following the surgeon's instructions. However, moving the laparoscope frequently may lead to unstable and suboptimal views, while the adjustment of zooming ratio may interrupt the workflow of the surgical operation. To this end, we propose a multi-scale Generative Adversarial Network (GAN)-based video super-resolution method to construct a framework for automatic zooming ratio adjustment. It can provide automatic real-time zooming for high-quality visualization of the Region Of Interest (ROI) during the surgical operation. In the pipeline of the framework, the Kernel Correlation Filter (KCF) tracker is used for tracking the tips of the surgical tools, while the Semi-Global Block Matching (SGBM) based depth estimation and Recurrent Neural Network (RNN)-based context-awareness are developed to determine the upscaling ratio for zooming. The framework is validated with the JIGSAW dataset and Hamlyn Centre Laparoscopic/Endoscopic Video Datasets, with results demonstrating its practicability.



### Long Range Arena: A Benchmark for Efficient Transformers
- **Arxiv ID**: http://arxiv.org/abs/2011.04006v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CL, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/2011.04006v1)
- **Published**: 2020-11-08 15:53:56+00:00
- **Updated**: 2020-11-08 15:53:56+00:00
- **Authors**: Yi Tay, Mostafa Dehghani, Samira Abnar, Yikang Shen, Dara Bahri, Philip Pham, Jinfeng Rao, Liu Yang, Sebastian Ruder, Donald Metzler
- **Comment**: None
- **Journal**: None
- **Summary**: Transformers do not scale very well to long sequence lengths largely because of quadratic self-attention complexity. In the recent months, a wide spectrum of efficient, fast Transformers have been proposed to tackle this problem, more often than not claiming superior or comparable model quality to vanilla Transformer models. To this date, there is no well-established consensus on how to evaluate this class of models. Moreover, inconsistent benchmarking on a wide spectrum of tasks and datasets makes it difficult to assess relative model quality amongst many models. This paper proposes a systematic and unified benchmark, LRA, specifically focused on evaluating model quality under long-context scenarios. Our benchmark is a suite of tasks consisting of sequences ranging from $1K$ to $16K$ tokens, encompassing a wide range of data types and modalities such as text, natural, synthetic images, and mathematical expressions requiring similarity, structural, and visual-spatial reasoning. We systematically evaluate ten well-established long-range Transformer models (Reformers, Linformers, Linear Transformers, Sinkhorn Transformers, Performers, Synthesizers, Sparse Transformers, and Longformers) on our newly proposed benchmark suite. LRA paves the way towards better understanding this class of efficient Transformer models, facilitates more research in this direction, and presents new challenging tasks to tackle. Our benchmark code will be released at https://github.com/google-research/long-range-arena.



### Predictive Analysis of Diabetic Retinopathy with Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2011.04052v2
- **DOI**: 10.1109/ICNTE51185.2021.9487789
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2011.04052v2)
- **Published**: 2020-11-08 18:54:57+00:00
- **Updated**: 2020-12-21 05:40:46+00:00
- **Authors**: Shreyas Rajesh Labhsetwar, Raj Sunil Salvi, Piyush Arvind Kolte, Veerasai Subramaniam venkatesh, Alistair Michael Baretto
- **Comment**: ICNTE
- **Journal**: 2021 4th Biennial International Conference on Nascent Technologies
  in Engineering (ICNTE), 2021, pp. 1-6
- **Summary**: With the prevalence of Diabetes, the Diabetes Mellitus Retinopathy (DR) is becoming a major health problem across the world. The long-term medical complications arising due to DR have a significant impact on the patient as well as the society, as the disease mostly affects individuals in their most productive years. Early detection and treatment can help reduce the extent of damage to the patients. The rise of Convolutional Neural Networks for predictive analysis in the medical field paves the way for a robust solution to DR detection. This paper studies the performance of several highly efficient and scalable CNN architectures for Diabetic Retinopathy Classification with the help of Transfer Learning. The research focuses on VGG16, Resnet50 V2 and EfficientNet B0 models. The classification performance is analyzed using several performance metrics including True Positive Rate, False Positive Rate, Accuracy, etc. Also, several performance graphs are plotted for visualizing the architecture performance including Confusion Matrix, ROC Curve, etc. The results indicate that Transfer Learning with ImageNet weights using VGG 16 model demonstrates the best classification performance with the best Accuracy of 95%. It is closely followed by ResNet50 V2 architecture with the best Accuracy of 93%. This paper shows that predictive analysis of DR from retinal images is achieved with Transfer Learning on Convolutional Neural Networks.



### Performance Analysis of Optimizers for Plant Disease Classification with Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2011.04056v2
- **DOI**: 10.1109/ICNTE51185.2021.9487698
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.04056v2)
- **Published**: 2020-11-08 19:03:02+00:00
- **Updated**: 2020-12-22 07:10:05+00:00
- **Authors**: Shreyas Rajesh Labhsetwar, Soumya Haridas, Riyali Panmand, Rutuja Deshpande, Piyush Arvind Kolte, Sandhya Pati
- **Comment**: conference
- **Journal**: 2021 4th Biennial International Conference on Nascent Technologies
  in Engineering (ICNTE), 2021, pp. 1-6
- **Summary**: Crop failure owing to pests & diseases are inherent within Indian agriculture, leading to annual losses of 15 to 25% of productivity, resulting in a huge economic loss. This research analyzes the performance of various optimizers for predictive analysis of plant diseases with deep learning approach. The research uses Convolutional Neural Networks for classification of farm or plant leaf samples of 3 crops into 15 classes. The various optimizers used in this research include RMSprop, Adam and AMSgrad. Optimizers Performance is visualised by plotting the Training and Validation Accuracy and Loss curves, ROC curves and Confusion Matrix. The best performance is achieved using Adam optimizer, with the maximum validation accuracy being 98%. This paper focuses on the research analysis proving that plant diseases can be predicted and pre-empted using deep learning methodology with the help of satellite, drone based or mobile based images that result in reducing crop failure and agricultural losses.



### Analysis of Dimensional Influence of Convolutional Neural Networks for Histopathological Cancer Classification
- **Arxiv ID**: http://arxiv.org/abs/2011.04057v2
- **DOI**: 10.1109/ICNTE51185.2021.9487582
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2011.04057v2)
- **Published**: 2020-11-08 19:07:43+00:00
- **Updated**: 2020-12-22 07:03:38+00:00
- **Authors**: Shreyas Rajesh Labhsetwar, Alistair Michael Baretto, Raj Sunil Salvi, Piyush Arvind Kolte, Veerasai Subramaniam Venkatesh
- **Comment**: conference
- **Journal**: 2021 4th Biennial International Conference on Nascent Technologies
  in Engineering (ICNTE), 2021, pp. 1-6
- **Summary**: Convolutional Neural Networks can be designed with different levels of complexity depending upon the task at hand. This paper analyzes the effect of dimensional changes to the CNN architecture on its performance on the task of Histopathological Cancer Classification. The research starts with a baseline 10-layer CNN model with (3 X 3) convolution filters. Thereafter, the baseline architecture is scaled in multiple dimensions including width, depth, resolution and a combination of all of these. Width scaling involves inculcating greater number of neurons per CNN layer, whereas depth scaling involves deepening the hierarchical layered structure. Resolution scaling is performed by increasing the dimensions of the input image, and compound scaling involves a hybrid combination of width, depth and resolution scaling. The results indicate that histopathological cancer scans are very complex in nature and hence require high resolution images fed to a large hierarchy of Convolution, MaxPooling, Dropout and Batch Normalization layers to extract all the intricacies and perform perfect classification. Since compound scaling the baseline model ensures that all the three dimensions: width, depth and resolution are scaled, the best performance is obtained with compound scaling. This research shows that better performance of CNN models is achieved by compound scaling of the baseline model for the task of Histopathological Cancer Classification.



### AI on the Bog: Monitoring and Evaluating Cranberry Crop Risk
- **Arxiv ID**: http://arxiv.org/abs/2011.04064v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2011.04064v1)
- **Published**: 2020-11-08 20:03:20+00:00
- **Updated**: 2020-11-08 20:03:20+00:00
- **Authors**: Peri Akiva, Benjamin Planche, Aditi Roy, Kristin Dana, Peter Oudemans, Michael Mars
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV) 2021
- **Journal**: None
- **Summary**: Machine vision for precision agriculture has attracted considerable research interest in recent years. The goal of this paper is to develop an end-to-end cranberry health monitoring system to enable and support real time cranberry over-heating assessment to facilitate informed decisions that may sustain the economic viability of the farm. Toward this goal, we propose two main deep learning-based modules for: 1) cranberry fruit segmentation to delineate the exact fruit regions in the cranberry field image that are exposed to sun, 2) prediction of cloud coverage conditions and sun irradiance to estimate the inner temperature of exposed cranberries. We develop drone-based field data and ground-based sky data collection systems to collect video imagery at multiple time points for use in crop health analysis. Extensive evaluation on the data set shows that it is possible to predict exposed fruit's inner temperature with high accuracy (0.02% MAPE). The sun irradiance prediction error was found to be 8.41-20.36% MAPE in the 5-20 minutes time horizon. With 62.54% mIoU for segmentation and 13.46 MAE for counting accuracies in exposed fruit identification, this system is capable of giving informed feedback to growers to take precautionary action (e.g. irrigation) in identified crop field regions with higher risk of sunburn in the near future. Though this novel system is applied for cranberry health monitoring, it represents a pioneering step forward for efficient farming and is useful in precision agriculture beyond the problem of cranberry overheating.



### A Psychophysically Oriented Saliency Map Prediction Model
- **Arxiv ID**: http://arxiv.org/abs/2011.04076v13
- **DOI**: 10.1007/s00138-023-01405-2
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.04076v13)
- **Published**: 2020-11-08 20:58:05+00:00
- **Updated**: 2022-08-25 20:29:20+00:00
- **Authors**: Qiang Li
- **Comment**: 20 pages, 12 figures, 3 tables
- **Journal**: Machine Vision and Applications 34, 47 (2023)
- **Summary**: Visual attention is one of the most significant characteristics for selecting and understanding the outside redundancy world. The human vision system cannot process all information simultaneously due to the visual information bottleneck. In order to reduce the redundant input of visual information, the human visual system mainly focuses on dominant parts of scenes. This is commonly known as visual saliency map prediction. This paper proposed a new psychophysical saliency prediction architecture, WECSF, inspired by multi-channel model of visual cortex functioning in humans. The model consists of opponent color channels, wavelet transform, wavelet energy map, and contrast sensitivity function for extracting low-level image features and providing a maximum approximation to the human visual system. The proposed model is evaluated using several datasets, including the MIT1003, MIT300, TORONTO, SID4VAM, and UCF Sports datasets. We also quantitatively and qualitatively compare the saliency prediction performance with that of other state-of-the-art models. Our model achieved strongly stable and better performance with different metrics on natural images, psychophysical synthetic images and dynamic videos. Additionally, we found that Fourier and spectral-inspired saliency prediction models outperformed other state-of-the-art non-neural network and even deep neural network models on psychophysical synthetic images. It can be explained and supported by the Fourier Vision Hypothesis. In the meantime, we suggest that deep neural networks need specific architectures and goals to be able to predict salient performance on psychophysical synthetic images better and more reliably. Finally, the proposed model could be used as a computational model of primate vision system and help us understand mechanism of primate vision system.



### Kimera-Multi: a System for Distributed Multi-Robot Metric-Semantic Simultaneous Localization and Mapping
- **Arxiv ID**: http://arxiv.org/abs/2011.04087v1
- **DOI**: 10.1109/ICRA48506.2021.9561090
- **Categories**: **cs.RO**, cs.CV, cs.MA
- **Links**: [PDF](http://arxiv.org/pdf/2011.04087v1)
- **Published**: 2020-11-08 21:38:12+00:00
- **Updated**: 2020-11-08 21:38:12+00:00
- **Authors**: Yun Chang, Yulun Tian, Jonathan P. How, Luca Carlone
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: We present the first fully distributed multi-robot system for dense metric-semantic Simultaneous Localization and Mapping (SLAM). Our system, dubbed Kimera-Multi, is implemented by a team of robots equipped with visual-inertial sensors, and builds a 3D mesh model of the environment in real-time, where each face of the mesh is annotated with a semantic label (e.g., building, road, objects). In Kimera-Multi, each robot builds a local trajectory estimate and a local mesh using Kimera. Then, when two robots are within communication range, they initiate a distributed place recognition and robust pose graph optimization protocol with a novel incremental maximum clique outlier rejection; the protocol allows the robots to improve their local trajectory estimates by leveraging inter-robot loop closures. Finally, each robot uses its improved trajectory estimate to correct the local mesh using mesh deformation techniques. We demonstrate Kimera-Multi in photo-realistic simulations and real data. Kimera-Multi (i) is able to build accurate 3D metric-semantic meshes, (ii) is robust to incorrect loop closures while requiring less computation than state-of-the-art distributed SLAM back-ends, and (iii) is efficient, both in terms of computation at each robot as well as communication bandwidth.



### Image Clustering using an Augmented Generative Adversarial Network and Information Maximization
- **Arxiv ID**: http://arxiv.org/abs/2011.04094v1
- **DOI**: 10.1109/TNNLS.2021.3085125
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2011.04094v1)
- **Published**: 2020-11-08 22:20:33+00:00
- **Updated**: 2020-11-08 22:20:33+00:00
- **Authors**: Foivos Ntelemis, Yaochu Jin, Spencer A. Thomas
- **Comment**: None
- **Journal**: None
- **Summary**: Image clustering has recently attracted significant attention due to the increased availability of unlabelled datasets. The efficiency of traditional clustering algorithms heavily depends on the distance functions used and the dimensionality of the features. Therefore, performance degradation is often observed when tackling either unprocessed images or high-dimensional features extracted from processed images. To deal with these challenges, we propose a deep clustering framework consisting of a modified generative adversarial network (GAN) and an auxiliary classifier. The modification employs Sobel operations prior to the discriminator of the GAN to enhance the separability of the learned features. The discriminator is then leveraged to generate representations as the input to an auxiliary classifier. An adaptive objective function is utilised to train the auxiliary classifier for clustering the representations, aiming to increase the robustness by minimizing the divergence of multiple representations generated by the discriminator. The auxiliary classifier is implemented with a group of multiple cluster-heads, where a tolerance hyper-parameter is used to tackle imbalanced data. Our results indicate that the proposed method significantly outperforms state-of-the-art clustering methods on CIFAR-10 and CIFAR-100, and is competitive on the STL10 and MNIST datasets.



