# Arxiv Papers in cs.CV on 2020-09-28
### AIM 2020 Challenge on Video Temporal Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2009.12987v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.12987v1)
- **Published**: 2020-09-28 00:10:29+00:00
- **Updated**: 2020-09-28 00:10:29+00:00
- **Authors**: Sanghyun Son, Jaerin Lee, Seungjun Nah, Radu Timofte, Kyoung Mu Lee
- **Comment**: Published in ECCV 2020 Workshop (Advances in Image Manipulation)
- **Journal**: None
- **Summary**: Videos in the real-world contain various dynamics and motions that may look unnaturally discontinuous in time when the recordedframe rate is low. This paper reports the second AIM challenge on Video Temporal Super-Resolution (VTSR), a.k.a. frame interpolation, with a focus on the proposed solutions, results, and analysis. From low-frame-rate (15 fps) videos, the challenge participants are required to submit higher-frame-rate (30 and 60 fps) sequences by estimating temporally intermediate frames. To simulate realistic and challenging dynamics in the real-world, we employ the REDS_VTSR dataset derived from diverse videos captured in a hand-held camera for training and evaluation purposes. There have been 68 registered participants in the competition, and 5 teams (one withdrawn) have competed in the final testing phase. The winning team proposes the enhanced quadratic video interpolation method and achieves state-of-the-art on the VTSR task.



### Long-Tailed Classification by Keeping the Good and Removing the Bad Momentum Causal Effect
- **Arxiv ID**: http://arxiv.org/abs/2009.12991v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.12991v4)
- **Published**: 2020-09-28 00:32:11+00:00
- **Updated**: 2021-02-11 04:10:13+00:00
- **Authors**: Kaihua Tang, Jianqiang Huang, Hanwang Zhang
- **Comment**: This paper is accepted by NeurIPS 2020. The code is available on
  GitHub: https://github.com/KaihuaTang/Long-Tailed-Recognition.pytorch
- **Journal**: None
- **Summary**: As the class size grows, maintaining a balanced dataset across many classes is challenging because the data are long-tailed in nature; it is even impossible when the sample-of-interest co-exists with each other in one collectable unit, e.g., multiple visual instances in one image. Therefore, long-tailed classification is the key to deep learning at scale. However, existing methods are mainly based on re-weighting/re-sampling heuristics that lack a fundamental theory. In this paper, we establish a causal inference framework, which not only unravels the whys of previous methods, but also derives a new principled solution. Specifically, our theory shows that the SGD momentum is essentially a confounder in long-tailed classification. On one hand, it has a harmful causal effect that misleads the tail prediction biased towards the head. On the other hand, its induced mediation also benefits the representation learning and head prediction. Our framework elegantly disentangles the paradoxical effects of the momentum, by pursuing the direct causal effect caused by an input sample. In particular, we use causal intervention in training, and counterfactual reasoning in inference, to remove the "bad" while keep the "good". We achieve new state-of-the-arts on three long-tailed visual recognition benchmarks: Long-tailed CIFAR-10/-100, ImageNet-LT for image classification and LVIS for instance segmentation.



### Sparse-data based 3D surface reconstruction with vector matching
- **Arxiv ID**: http://arxiv.org/abs/2009.12994v1
- **DOI**: None
- **Categories**: **math.NA**, cs.CV, cs.NA, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/2009.12994v1)
- **Published**: 2020-09-28 00:36:49+00:00
- **Updated**: 2020-09-28 00:36:49+00:00
- **Authors**: Bin Wu, Xue-Cheng Tai, Talal Rahman
- **Comment**: None
- **Journal**: None
- **Summary**: Three dimensional surface reconstruction based on two dimensional sparse information in the form of only a small number of level lines of the surface with moderately complex structures, containing both structured and unstructured geometries, is considered in this paper. A new model has been proposed which is based on the idea of using normal vector matching combined with a first order and a second order total variation regularizers. A fast algorithm based on the augmented Lagrangian is also proposed. Numerical experiments are provided showing the effectiveness of the model and the algorithm in reconstructing surfaces with detailed features and complex structures for both synthetic and real world digital maps.



### Interventional Few-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2009.13000v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13000v2)
- **Published**: 2020-09-28 01:16:54+00:00
- **Updated**: 2020-12-04 06:51:09+00:00
- **Authors**: Zhongqi Yue, Hanwang Zhang, Qianru Sun, Xian-Sheng Hua
- **Comment**: Accepted by NeurIPS 2020
- **Journal**: None
- **Summary**: We uncover an ever-overlooked deficiency in the prevailing Few-Shot Learning (FSL) methods: the pre-trained knowledge is indeed a confounder that limits the performance. This finding is rooted from our causal assumption: a Structural Causal Model (SCM) for the causalities among the pre-trained knowledge, sample features, and labels. Thanks to it, we propose a novel FSL paradigm: Interventional Few-Shot Learning (IFSL). Specifically, we develop three effective IFSL algorithmic implementations based on the backdoor adjustment, which is essentially a causal intervention towards the SCM of many-shot learning: the upper-bound of FSL in a causal view. It is worth noting that the contribution of IFSL is orthogonal to existing fine-tuning and meta-learning based FSL methods, hence IFSL can improve all of them, achieving a new 1-/5-shot state-of-the-art on \textit{mini}ImageNet, \textit{tiered}ImageNet, and cross-domain CUB. Code is released at https://github.com/yue-zhongqi/ifsl.



### NAS-Navigator: Visual Steering for Explainable One-Shot Deep Neural Network Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2009.13008v3
- **DOI**: 10.1109/TVCG.2022.3209361
- **Categories**: **cs.LG**, cs.CV, cs.HC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.13008v3)
- **Published**: 2020-09-28 01:48:45+00:00
- **Updated**: 2022-08-06 02:22:25+00:00
- **Authors**: Anjul Tyagi, Cong Xie, Klaus Mueller
- **Comment**: Pre-print of the accepted paper at IEEE Transactions on Visualization
  and Computer Graphics, 2022
- **Journal**: IEEE Transactions of Visualization and Computer Graphics, 2022
- **Summary**: Recent advancements in the area of deep learning have shown the effectiveness of very large neural networks in several applications. However, as these deep neural networks continue to grow in size, it becomes more and more difficult to configure their many parameters to obtain good results. Presently, analysts must experiment with many different configurations and parameter settings, which is labor-intensive and time-consuming. On the other hand, the capacity of fully automated techniques for neural network architecture search is limited without the domain knowledge of human experts. To deal with the problem, we formulate the task of neural network architecture optimization as a graph space exploration, based on the one-shot architecture search technique. In this approach, a super-graph of all candidate architectures is trained in one-shot and the optimal neural network is identified as a sub-graph. In this paper, we present a framework that allows analysts to effectively build the solution sub-graph space and guide the network search by injecting their domain knowledge. Starting with the network architecture space composed of basic neural network components, analysts are empowered to effectively select the most promising components via our one-shot search scheme. Applying this technique in an iterative manner allows analysts to converge to the best performing neural network architecture for a given application. During the exploration, analysts can use their domain knowledge aided by cues provided from a scatterplot visualization of the search space to edit different components and guide the search for faster convergence. We designed our interface in collaboration with several deep learning researchers and its final effectiveness is evaluated with a user study and two case studies.



### Cloud Removal for Remote Sensing Imagery via Spatial Attention Generative Adversarial Network
- **Arxiv ID**: http://arxiv.org/abs/2009.13015v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13015v2)
- **Published**: 2020-09-28 02:13:23+00:00
- **Updated**: 2020-11-14 08:17:05+00:00
- **Authors**: Heng Pan
- **Comment**: None
- **Journal**: None
- **Summary**: Optical remote sensing imagery has been widely used in many fields due to its high resolution and stable geometric properties. However, remote sensing imagery is inevitably affected by climate, especially clouds. Removing the cloud in the high-resolution remote sensing satellite image is an indispensable pre-processing step before analyzing it. For the sake of large-scale training data, neural networks have been successful in many image processing tasks, but the use of neural networks to remove cloud in remote sensing imagery is still relatively small. We adopt generative adversarial network to solve this task and introduce the spatial attention mechanism into the remote sensing imagery cloud removal task, proposes a model named spatial attention generative adversarial network (SpA GAN), which imitates the human visual mechanism, and recognizes and focuses the cloud area with local-to-global spatial attention, thereby enhancing the information recovery of these areas and generating cloudless images with better quality...



### Concentrated Multi-Grained Multi-Attention Network for Video Based Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2009.13019v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13019v1)
- **Published**: 2020-09-28 02:18:06+00:00
- **Updated**: 2020-09-28 02:18:06+00:00
- **Authors**: Panwen Hu, Jiazhen Liu, Rui Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Occlusion is still a severe problem in the video-based Re-IDentification (Re-ID) task, which has a great impact on the success rate. The attention mechanism has been proved to be helpful in solving the occlusion problem by a large number of existing methods. However, their attention mechanisms still lack the capability to extract sufficient discriminative information into the final representations from the videos. The single attention module scheme employed by existing methods cannot exploit multi-scale spatial cues, and the attention of the single module will be dispersed by multiple salient parts of the person. In this paper, we propose a Concentrated Multi-grained Multi-Attention Network (CMMANet) where two multi-attention modules are designed to extract multi-grained information through processing multi-scale intermediate features. Furthermore, multiple attention submodules in each multi-attention module can automatically discover multiple discriminative regions of the video frames. To achieve this goal, we introduce a diversity loss to diversify the submodules in each multi-attention module, and a concentration loss to integrate their attention responses so that each submodule can strongly focus on a specific meaningful part. The experimental results show that the proposed approach outperforms the state-of-the-art methods by large margins on multiple public datasets.



### Kernel Based Progressive Distillation for Adder Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2009.13044v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13044v3)
- **Published**: 2020-09-28 03:29:19+00:00
- **Updated**: 2020-10-15 03:39:58+00:00
- **Authors**: Yixing Xu, Chang Xu, Xinghao Chen, Wei Zhang, Chunjing Xu, Yunhe Wang
- **Comment**: Accepted by NeurIPS 2020, spotlight
- **Journal**: None
- **Summary**: Adder Neural Networks (ANNs) which only contain additions bring us a new way of developing deep neural networks with low energy consumption. Unfortunately, there is an accuracy drop when replacing all convolution filters by adder filters. The main reason here is the optimization difficulty of ANNs using $\ell_1$-norm, in which the estimation of gradient in back propagation is inaccurate. In this paper, we present a novel method for further improving the performance of ANNs without increasing the trainable parameters via a progressive kernel based knowledge distillation (PKKD) method. A convolutional neural network (CNN) with the same architecture is simultaneously initialized and trained as a teacher network, features and weights of ANN and CNN will be transformed to a new space to eliminate the accuracy drop. The similarity is conducted in a higher-dimensional space to disentangle the difference of their distributions using a kernel based method. Finally, the desired ANN is learned based on the information from both the ground-truth and teacher, progressively. The effectiveness of the proposed method for learning ANN with higher performance is then well-verified on several benchmarks. For instance, the ANN-50 trained using the proposed PKKD method obtains a 76.8\% top-1 accuracy on ImageNet dataset, which is 0.6\% higher than that of the ResNet-50.



### Event-based Action Recognition Using Timestamp Image Encoding Network
- **Arxiv ID**: http://arxiv.org/abs/2009.13049v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13049v1)
- **Published**: 2020-09-28 03:48:14+00:00
- **Updated**: 2020-09-28 03:48:14+00:00
- **Authors**: Chaoxing Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Event camera is an asynchronous, high frequency vision sensor with low power consumption, which is suitable for human action recognition task. It is vital to encode the spatial-temporal information of event data properly and use standard computer vision tool to learn from the data. In this work, we propose a timestamp image encoding 2D network, which takes the encoded spatial-temporal images of the event data as input and output the action label. Experiment results show that our method can achieve the same level of performance as those RGB-based benchmarks on real world action recognition, and also achieve the SOTA result on gesture recognition.



### Rotated Binary Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2009.13055v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13055v3)
- **Published**: 2020-09-28 04:22:26+00:00
- **Updated**: 2020-10-22 09:06:18+00:00
- **Authors**: Mingbao Lin, Rongrong Ji, Zihan Xu, Baochang Zhang, Yan Wang, Yongjian Wu, Feiyue Huang, Chia-Wen Lin
- **Comment**: Accepted by NeurIPS2020 (The 34th Conference on Neural Information
  Processing Systems)
- **Journal**: None
- **Summary**: Binary Neural Network (BNN) shows its predominance in reducing the complexity of deep neural networks. However, it suffers severe performance degradation. One of the major impediments is the large quantization error between the full-precision weight vector and its binary vector. Previous works focus on compensating for the norm gap while leaving the angular bias hardly touched. In this paper, for the first time, we explore the influence of angular bias on the quantization error and then introduce a Rotated Binary Neural Network (RBNN), which considers the angle alignment between the full-precision weight vector and its binarized version. At the beginning of each training epoch, we propose to rotate the full-precision weight vector to its binary vector to reduce the angular bias. To avoid the high complexity of learning a large rotation matrix, we further introduce a bi-rotation formulation that learns two smaller rotation matrices. In the training stage, we devise an adjustable rotated weight vector for binarization to escape the potential local optimum. Our rotation leads to around 50% weight flips which maximize the information gain. Finally, we propose a training-aware approximation of the sign function for the gradient backward. Experiments on CIFAR-10 and ImageNet demonstrate the superiorities of RBNN over many state-of-the-arts. Our source code, experimental settings, training logs and binary models are available at https://github.com/lmbxmu/RBNN.



### Distribution Matching for Crowd Counting
- **Arxiv ID**: http://arxiv.org/abs/2009.13077v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13077v2)
- **Published**: 2020-09-28 04:57:23+00:00
- **Updated**: 2020-10-25 23:53:54+00:00
- **Authors**: Boyu Wang, Huidong Liu, Dimitris Samaras, Minh Hoai
- **Comment**: NeurIPS 2020
- **Journal**: None
- **Summary**: In crowd counting, each training image contains multiple people, where each person is annotated by a dot. Existing crowd counting methods need to use a Gaussian to smooth each annotated dot or to estimate the likelihood of every pixel given the annotated point. In this paper, we show that imposing Gaussians to annotations hurts generalization performance. Instead, we propose to use Distribution Matching for crowd COUNTing (DM-Count). In DM-Count, we use Optimal Transport (OT) to measure the similarity between the normalized predicted density map and the normalized ground truth density map. To stabilize OT computation, we include a Total Variation loss in our model. We show that the generalization error bound of DM-Count is tighter than that of the Gaussian smoothed methods. In terms of Mean Absolute Error, DM-Count outperforms the previous state-of-the-art methods by a large margin on two large-scale counting datasets, UCF-QNRF and NWPU, and achieves the state-of-the-art results on the ShanghaiTech and UCF-CC50 datasets. DM-Count reduced the error of the state-of-the-art published result by approximately 16%. Code is available at https://github.com/cvlab-stonybrook/DM-Count.



### PERF-Net: Pose Empowered RGB-Flow Net
- **Arxiv ID**: http://arxiv.org/abs/2009.13087v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13087v2)
- **Published**: 2020-09-28 06:06:51+00:00
- **Updated**: 2021-10-20 00:05:04+00:00
- **Authors**: Yinxiao Li, Zhichao Lu, Xuehan Xiong, Jonathan Huang
- **Comment**: 10 pages, 5 figures, 7 tables
- **Journal**: None
- **Summary**: In recent years, many works in the video action recognition literature have shown that two stream models (combining spatial and temporal input streams) are necessary for achieving state of the art performance. In this paper we show the benefits of including yet another stream based on human pose estimated from each frame -- specifically by rendering pose on input RGB frames. At first blush, this additional stream may seem redundant given that human pose is fully determined by RGB pixel values -- however we show (perhaps surprisingly) that this simple and flexible addition can provide complementary gains. Using this insight, we then propose a new model, which we dub PERF-Net (short for Pose Empowered RGB-Flow Net), which combines this new pose stream with the standard RGB and flow based input streams via distillation techniques and show that our model outperforms the state-of-the-art by a large margin in a number of human action recognition datasets while not requiring flow or pose to be explicitly computed at inference time. The proposed pose stream is also part of the winner solution of the ActivityNet Kinetics Challenge 2020.



### NITI: Training Integer Neural Networks Using Integer-only Arithmetic
- **Arxiv ID**: http://arxiv.org/abs/2009.13108v2
- **DOI**: 10.1109/TPDS.2022.3149787
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13108v2)
- **Published**: 2020-09-28 07:41:36+00:00
- **Updated**: 2022-02-11 11:08:39+00:00
- **Authors**: Maolin Wang, Seyedramin Rasoulinezhad, Philip H. W. Leong, Hayden K. H. So
- **Comment**: None
- **Journal**: None
- **Summary**: While integer arithmetic has been widely adopted for improved performance in deep quantized neural network inference, training remains a task primarily executed using floating point arithmetic. This is because both high dynamic range and numerical accuracy are central to the success of most modern training algorithms. However, due to its potential for computational, storage and energy advantages in hardware accelerators, neural network training methods that can be implemented with low precision integer-only arithmetic remains an active research challenge. In this paper, we present NITI, an efficient deep neural network training framework that stores all parameters and intermediate values as integers, and computes exclusively with integer arithmetic. A pseudo stochastic rounding scheme that eliminates the need for external random number generation is proposed to facilitate conversion from wider intermediate results to low precision storage. Furthermore, a cross-entropy loss backpropagation scheme computed with integer-only arithmetic is proposed. A proof-of-concept open-source software implementation of NITI that utilizes native 8-bit integer operations in modern GPUs to achieve end-to-end training is presented. When compared with an equivalent training setup implemented with floating point storage and arithmetic, NITI achieves negligible accuracy degradation on the MNIST and CIFAR10 datasets using 8-bit integer storage and computation. On ImageNet, 16-bit integers are needed for weight accumulation with an 8-bit datapath. This achieves training results comparable to all-floating-point implementations.



### Learning to Stop: A Simple yet Effective Approach to Urban Vision-Language Navigation
- **Arxiv ID**: http://arxiv.org/abs/2009.13112v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13112v3)
- **Published**: 2020-09-28 07:44:46+00:00
- **Updated**: 2020-10-18 05:41:06+00:00
- **Authors**: Jiannan Xiang, Xin Eric Wang, William Yang Wang
- **Comment**: Findings of EMNLP 2020
- **Journal**: None
- **Summary**: Vision-and-Language Navigation (VLN) is a natural language grounding task where an agent learns to follow language instructions and navigate to specified destinations in real-world environments. A key challenge is to recognize and stop at the correct location, especially for complicated outdoor environments. Existing methods treat the STOP action equally as other actions, which results in undesirable behaviors that the agent often fails to stop at the destination even though it might be on the right path. Therefore, we propose Learning to Stop (L2Stop), a simple yet effective policy module that differentiates STOP and other actions. Our approach achieves the new state of the art on a challenging urban VLN dataset Touchdown, outperforming the baseline by 6.89% (absolute improvement) on Success weighted by Edit Distance (SED).



### RRPN++: Guidance Towards More Accurate Scene Text Detection
- **Arxiv ID**: http://arxiv.org/abs/2009.13118v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13118v1)
- **Published**: 2020-09-28 08:00:35+00:00
- **Updated**: 2020-09-28 08:00:35+00:00
- **Authors**: Jianqi Ma
- **Comment**: Tech report, code will be released
- **Journal**: None
- **Summary**: RRPN is among the outstanding scene text detection approaches, but the manually-designed anchor and coarse proposal refinement make the performance still far from perfection. In this paper, we propose RRPN++ to exploit the potential of RRPN-based model by several improvements. Based on RRPN, we propose the Anchor-free Pyramid Proposal Networks (APPN) to generate first-stage proposals, which adopts the anchor-free design to reduce proposal number and accelerate the inference speed. In our second stage, both the detection branch and the recognition branch are incorporated to perform multi-task learning. In inference stage, the detection branch outputs the proposal refinement and the recognition branch predicts the transcript of the refined text region. Further, the recognition branch also helps rescore the proposals and eliminate the false positive proposals by the jointing filtering strategy. With these enhancements, we boost the detection results by $6\%$ of F-measure in ICDAR2015 compared to RRPN. Experiments conducted on other benchmarks also illustrate the superior performance and efficiency of our model.



### Medical Image Segmentation Using Deep Learning: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2009.13120v3
- **DOI**: 10.1049/ipr2.12419
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13120v3)
- **Published**: 2020-09-28 08:05:02+00:00
- **Updated**: 2021-12-22 08:27:04+00:00
- **Authors**: Risheng Wang, Tao Lei, Ruixia Cui, Bingtao Zhang, Hongying Meng, Asoke K. Nandi
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning has been widely used for medical image segmentation and a large number of papers has been presented recording the success of deep learning in the field. In this paper, we present a comprehensive thematic survey on medical image segmentation using deep learning techniques. This paper makes two original contributions. Firstly, compared to traditional surveys that directly divide literatures of deep learning on medical image segmentation into many groups and introduce literatures in detail for each group, we classify currently popular literatures according to a multi-level structure from coarse to fine. Secondly, this paper focuses on supervised and weakly supervised learning approaches, without including unsupervised approaches since they have been introduced in many old surveys and they are not popular currently. For supervised learning approaches, we analyze literatures in three aspects: the selection of backbone networks, the design of network blocks, and the improvement of loss functions. For weakly supervised learning approaches, we investigate literature according to data augmentation, transfer learning, and interactive segmentation, separately. Compared to existing surveys, this survey classifies the literatures very differently from before and is more convenient for readers to understand the relevant rationale and will guide them to think of appropriate improvements in medical image segmentation based on deep learning approaches.



### Interpretable Detail-Fidelity Attention Network for Single Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2009.13134v1
- **DOI**: 10.1109/TIP.2021.3050856
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13134v1)
- **Published**: 2020-09-28 08:31:23+00:00
- **Updated**: 2020-09-28 08:31:23+00:00
- **Authors**: Yuanfei Huang, Jie Li, Xinbo Gao, Yanting Hu, Wen Lu
- **Comment**: 14 pages, submitted to IEEE Transactions, codes are available at
  https://github.com/YuanfeiHuang/DeFiAN
- **Journal**: None
- **Summary**: Benefiting from the strong capabilities of deep CNNs for feature representation and nonlinear mapping, deep-learning-based methods have achieved excellent performance in single image super-resolution. However, most existing SR methods depend on the high capacity of networks which is initially designed for visual recognition, and rarely consider the initial intention of super-resolution for detail fidelity. Aiming at pursuing this intention, there are two challenging issues to be solved: (1) learning appropriate operators which is adaptive to the diverse characteristics of smoothes and details; (2) improving the ability of model to preserve the low-frequency smoothes and reconstruct the high-frequency details. To solve them, we propose a purposeful and interpretable detail-fidelity attention network to progressively process these smoothes and details in divide-and-conquer manner, which is a novel and specific prospect of image super-resolution for the purpose on improving the detail fidelity, instead of blindly designing or employing the deep CNNs architectures for merely feature representation in local receptive fields. Particularly, we propose a Hessian filtering for interpretable feature representation which is high-profile for detail inference, a dilated encoder-decoder and a distribution alignment cell to improve the inferred Hessian features in morphological manner and statistical manner respectively. Extensive experiments demonstrate that the proposed methods achieve superior performances over the state-of-the-art methods quantitatively and qualitatively. Code is available at https://github.com/YuanfeiHuang/DeFiAN.



### Segmentation and Analysis of a Sketched Truss Frame Using Morphological Image Processing Techniques
- **Arxiv ID**: http://arxiv.org/abs/2009.13144v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13144v1)
- **Published**: 2020-09-28 08:50:18+00:00
- **Updated**: 2020-09-28 08:50:18+00:00
- **Authors**: Mirsalar Kamari, Oguz Gunes
- **Comment**: None
- **Journal**: Conference: (ICCACS) International Conference On Civil
  Engineering, Architecture and Cityscape, July 2016, Istanbul, Turkey
- **Summary**: Development of computational tools to analyze and assess the building capacities has had a major impact in civil engineering. The interaction with the structural software packages is becoming easier and the modeling tools are becoming smarter by automating the users role during their interaction with the software. One of the difficulties and the most time consuming steps involved in the structural modeling is defining the geometry of the structure to provide the analysis. This paper is dedicated to the development of a methodology to automate analysis of a hand sketched or computer generated truss frame drawn on a piece of paper. First, we focus on the segmentation methodologies for hand sketched truss components using the morphological image processing techniques, and then we provide a real time analysis of the truss. We visualize and augment the results on the input image to facilitate the public understanding of the truss geometry and internal forces. MATLAB is used as the programming language for the image processing purposes, and the truss is analyzed using Sap2000 API to integrate with MATLAB to provide a convenient structural analysis. This paper highlights the potential of the automation of the structural analysis using image processing to quickly assess the efficiency of structural systems. Further development of this framework is likely to revolutionize the way that structures are modeled and analyzed.



### Amodal 3D Reconstruction for Robotic Manipulation via Stability and Connectivity
- **Arxiv ID**: http://arxiv.org/abs/2009.13146v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13146v1)
- **Published**: 2020-09-28 08:52:54+00:00
- **Updated**: 2020-09-28 08:52:54+00:00
- **Authors**: William Agnew, Christopher Xie, Aaron Walsman, Octavian Murad, Caelen Wang, Pedro Domingos, Siddhartha Srinivasa
- **Comment**: None
- **Journal**: None
- **Summary**: Learning-based 3D object reconstruction enables single- or few-shot estimation of 3D object models. For robotics, this holds the potential to allow model-based methods to rapidly adapt to novel objects and scenes. Existing 3D reconstruction techniques optimize for visual reconstruction fidelity, typically measured by chamfer distance or voxel IOU. We find that when applied to realistic, cluttered robotics environments, these systems produce reconstructions with low physical realism, resulting in poor task performance when used for model-based control. We propose ARM, an amodal 3D reconstruction system that introduces (1) a stability prior over object shapes, (2) a connectivity prior, and (3) a multi-channel input representation that allows for reasoning over relationships between groups of objects. By using these priors over the physical properties of objects, our system improves reconstruction quality not just by standard visual metrics, but also performance of model-based control on a variety of robotics manipulation tasks in challenging, cluttered environments. Code is available at github.com/wagnew3/ARM.



### Automated Pancreas Segmentation Using Multi-institutional Collaborative Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2009.13148v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13148v1)
- **Published**: 2020-09-28 08:54:10+00:00
- **Updated**: 2020-09-28 08:54:10+00:00
- **Authors**: Pochuan Wang, Chen Shen, Holger R. Roth, Dong Yang, Daguang Xu, Masahiro Oda, Kazunari Misawa, Po-Ting Chen, Kao-Lang Liu, Wei-Chih Liao, Weichung Wang, Kensaku Mori
- **Comment**: Accepted by MICCAI DCL Workshop 2020
- **Journal**: None
- **Summary**: The performance of deep learning-based methods strongly relies on the number of datasets used for training. Many efforts have been made to increase the data in the medical image analysis field. However, unlike photography images, it is hard to generate centralized databases to collect medical images because of numerous technical, legal, and privacy issues. In this work, we study the use of federated learning between two institutions in a real-world setting to collaboratively train a model without sharing the raw data across national boundaries. We quantitatively compare the segmentation models obtained with federated learning and local training alone. Our experimental results show that federated learning models have higher generalizability than standalone training.



### Trainable Structure Tensors for Autonomous Baggage Threat Detection Under Extreme Occlusion
- **Arxiv ID**: http://arxiv.org/abs/2009.13158v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13158v2)
- **Published**: 2020-09-28 09:12:10+00:00
- **Updated**: 2020-10-05 07:26:46+00:00
- **Authors**: Taimur Hassan, Samet Akcay, Mohammed Bennamoun, Salman Khan, Naoufel Werghi
- **Comment**: ACCV-2020 Camera Ready, Source Code:
  https://github.com/taimurhassan/TST
- **Journal**: None
- **Summary**: Detecting baggage threats is one of the most difficult tasks, even for expert officers. Many researchers have developed computer-aided screening systems to recognize these threats from the baggage X-ray scans. However, all of these frameworks are limited in identifying the contraband items under extreme occlusion. This paper presents a novel instance segmentation framework that utilizes trainable structure tensors to highlight the contours of the occluded and cluttered contraband items (by scanning multiple predominant orientations), while simultaneously suppressing the irrelevant baggage content. The proposed framework has been extensively tested on four publicly available X-ray datasets where it outperforms the state-of-the-art frameworks in terms of mean average precision scores. Furthermore, to the best of our knowledge, it is the only framework that has been validated on combined grayscale and colored scans obtained from four different types of X-ray scanners.



### Video Face Recognition System: RetinaFace-mnet-faster and Secondary Search
- **Arxiv ID**: http://arxiv.org/abs/2009.13167v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/2009.13167v2)
- **Published**: 2020-09-28 09:31:38+00:00
- **Updated**: 2020-09-29 01:47:49+00:00
- **Authors**: Qian Li, Nan Guo, Xiaochun Ye, Dongrui Fan, Zhimin Tang
- **Comment**: Accepted by FICC(Future of Information and Communication Conference)
- **Journal**: None
- **Summary**: Face recognition is widely used in the scene. However, different visual environments require different methods, and face recognition has a difficulty in complex environments. Therefore, this paper mainly experiments complex faces in the video. First, we design an image pre-processing module for fuzzy scene or under-exposed faces to enhance images. Our experimental results demonstrate that effective images pre-processing improves the accuracy of 0.11%, 0.2% and 1.4% on LFW, WIDER FACE and our datasets, respectively. Second, we propose RetinacFace-mnet-faster for detection and a confidence threshold specification for face recognition, reducing the lost rate. Our experimental results show that our RetinaFace-mnet-faster for 640*480 resolution on the Tesla P40 and single-thread improve speed of 16.7% and 70.2%, respectively. Finally, we design secondary search mechanism with HNSW to improve performance. Ours is suitable for large-scale datasets, and experimental results show that our method is 82% faster than the violent retrieval for the single-frame detection.



### Deep EvoGraphNet Architecture For Time-Dependent Brain Graph Data Synthesis From a Single Timepoint
- **Arxiv ID**: http://arxiv.org/abs/2009.13217v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13217v1)
- **Published**: 2020-09-28 11:10:38+00:00
- **Updated**: 2020-09-28 11:10:38+00:00
- **Authors**: Ahmed Nebli, Ugur Ali Kaplan, Islem Rekik
- **Comment**: None
- **Journal**: None
- **Summary**: Learning how to predict the brain connectome (i.e. graph) development and aging is of paramount importance for charting the future of within-disorder and cross-disorder landscape of brain dysconnectivity evolution. Indeed, predicting the longitudinal (i.e., time-dependent ) brain dysconnectivity as it emerges and evolves over time from a single timepoint can help design personalized treatments for disordered patients in a very early stage. Despite its significance, evolution models of the brain graph are largely overlooked in the literature. Here, we propose EvoGraphNet, the first end-to-end geometric deep learning-powered graph-generative adversarial network (gGAN) for predicting time-dependent brain graph evolution from a single timepoint. Our EvoGraphNet architecture cascades a set of time-dependent gGANs, where each gGAN communicates its predicted brain graphs at a particular timepoint to train the next gGAN in the cascade at follow-up timepoint. Therefore, we obtain each next predicted timepoint by setting the output of each generator as the input of its successor which enables us to predict a given number of timepoints using only one single timepoint in an end- to-end fashion. At each timepoint, to better align the distribution of the predicted brain graphs with that of the ground-truth graphs, we further integrate an auxiliary Kullback-Leibler divergence loss function. To capture time-dependency between two consecutive observations, we impose an l1 loss to minimize the sparse distance between two serialized brain graphs. A series of benchmarks against variants and ablated versions of our EvoGraphNet showed that we can achieve the lowest brain graph evolution prediction error using a single baseline timepoint. Our EvoGraphNet code is available at http://github.com/basiralab/EvoGraphNet.



### Scalable Transfer Learning with Expert Models
- **Arxiv ID**: http://arxiv.org/abs/2009.13239v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.13239v1)
- **Published**: 2020-09-28 12:07:10+00:00
- **Updated**: 2020-09-28 12:07:10+00:00
- **Authors**: Joan Puigcerver, Carlos Riquelme, Basil Mustafa, Cedric Renggli, André Susano Pinto, Sylvain Gelly, Daniel Keysers, Neil Houlsby
- **Comment**: None
- **Journal**: None
- **Summary**: Transfer of pre-trained representations can improve sample efficiency and reduce computational requirements for new tasks. However, representations used for transfer are usually generic, and are not tailored to a particular distribution of downstream tasks. We explore the use of expert representations for transfer with a simple, yet effective, strategy. We train a diverse set of experts by exploiting existing label structures, and use cheap-to-compute performance proxies to select the relevant expert for each target task. This strategy scales the process of transferring to new tasks, since it does not revisit the pre-training data during transfer. Accordingly, it requires little extra compute per target task, and results in a speed-up of 2-3 orders of magnitude compared to competing approaches. Further, we provide an adapter-based architecture able to compress many experts into a single model. We evaluate our approach on two different data sources and demonstrate that it outperforms baselines on over 20 diverse vision tasks in both cases.



### Texture Memory-Augmented Deep Patch-Based Image Inpainting
- **Arxiv ID**: http://arxiv.org/abs/2009.13240v2
- **DOI**: 10.1109/TIP.2021.3122930
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13240v2)
- **Published**: 2020-09-28 12:09:08+00:00
- **Updated**: 2021-11-04 04:11:47+00:00
- **Authors**: Rui Xu, Minghao Guo, Jiaqi Wang, Xiaoxiao Li, Bolei Zhou, Chen Change Loy
- **Comment**: Published on TIP. Project Page: https://nbei.github.io/tmad.html
- **Journal**: None
- **Summary**: Patch-based methods and deep networks have been employed to tackle image inpainting problem, with their own strengths and weaknesses. Patch-based methods are capable of restoring a missing region with high-quality texture through searching nearest neighbor patches from the unmasked regions. However, these methods bring problematic contents when recovering large missing regions. Deep networks, on the other hand, show promising results in completing large regions. Nonetheless, the results often lack faithful and sharp details that resemble the surrounding area. By bringing together the best of both paradigms, we propose a new deep inpainting framework where texture generation is guided by a texture memory of patch samples extracted from unmasked regions. The framework has a novel design that allows texture memory retrieval to be trained end-to-end with the deep inpainting network. In addition, we introduce a patch distribution loss to encourage high-quality patch synthesis. The proposed method shows superior performance both qualitatively and quantitatively on three challenging image benchmarks, i.e., Places, CelebA-HQ, and Paris Street-View datasets.



### Driver Drowsiness Classification Based on Eye Blink and Head Movement Features Using the k-NN Algorithm
- **Arxiv ID**: http://arxiv.org/abs/2009.13276v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13276v1)
- **Published**: 2020-09-28 12:37:38+00:00
- **Updated**: 2020-09-28 12:37:38+00:00
- **Authors**: Mariella Dreissig, Mohamed Hedi Baccour, Tim Schaeck, Enkelejda Kasneci
- **Comment**: accepted paper at IEEE Symposium on Computational Intelligence in
  Feature Analysis, Selection and Learning in Image and Pattern Recognition as
  part of the 2020 IEEE Symposium Series on Computational Intelligence (SSCI)
- **Journal**: None
- **Summary**: Modern advanced driver-assistance systems analyze the driving performance to gather information about the driver's state. Such systems are able, for example, to detect signs of drowsiness by evaluating the steering or lane keeping behavior and to alert the driver when the drowsiness state reaches a critical level. However, these kinds of systems have no access to direct cues about the driver's state. Hence, the aim of this work is to extend the driver drowsiness detection in vehicles using signals of a driver monitoring camera. For this purpose, 35 features related to the driver's eye blinking behavior and head movements are extracted in driving simulator experiments. Based on that large dataset, we developed and evaluated a feature selection method based on the k-Nearest Neighbor algorithm for the driver's state classification. A concluding analysis of the best performing feature sets yields valuable insights about the influence of drowsiness on the driver's blink behavior and head movements. These findings will help in the future development of robust and reliable driver drowsiness monitoring systems to prevent fatigue-induced accidents.



### Learning to Adapt Multi-View Stereo by Self-Supervision
- **Arxiv ID**: http://arxiv.org/abs/2009.13278v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T45(Primary), I.4.0; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2009.13278v1)
- **Published**: 2020-09-28 12:42:36+00:00
- **Updated**: 2020-09-28 12:42:36+00:00
- **Authors**: Arijit Mallick, Jörg Stückler, Hendrik Lensch
- **Comment**: 19 pages, including supplementary, accepted and presented in BMVC
  2020
- **Journal**: None
- **Summary**: 3D scene reconstruction from multiple views is an important classical problem in computer vision. Deep learning based approaches have recently demonstrated impressive reconstruction results. When training such models, self-supervised methods are favourable since they do not rely on ground truth data which would be needed for supervised training and is often difficult to obtain. Moreover, learned multi-view stereo reconstruction is prone to environment changes and should robustly generalise to different domains. We propose an adaptive learning approach for multi-view stereo which trains a deep neural network for improved adaptability to new target domains. We use model-agnostic meta-learning (MAML) to train base parameters which, in turn, are adapted for multi-view stereo on new domains through self-supervised training. Our evaluations demonstrate that the proposed adaptation method is effective in learning self-supervised multi-view stereo reconstruction in new domains.



### Multi-scale Receptive Fields Graph Attention Network for Point Cloud Classification
- **Arxiv ID**: http://arxiv.org/abs/2009.13289v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13289v1)
- **Published**: 2020-09-28 13:01:28+00:00
- **Updated**: 2020-09-28 13:01:28+00:00
- **Authors**: Xi-An Li, Lei Zhang, Li-Yan Wang, Jian Lu
- **Comment**: 10 pages, 5 figures
- **Journal**: None
- **Summary**: Understanding the implication of point cloud is still challenging to achieve the goal of classification or segmentation due to the irregular and sparse structure of point cloud. As we have known, PointNet architecture as a ground-breaking work for point cloud which can learn efficiently shape features directly on unordered 3D point cloud and have achieved favorable performance. However, this model fail to consider the fine-grained semantic information of local structure for point cloud. Afterwards, many valuable works are proposed to enhance the performance of PointNet by means of semantic features of local patch for point cloud. In this paper, a multi-scale receptive fields graph attention network (named after MRFGAT) for point cloud classification is proposed. By focusing on the local fine features of point cloud and applying multi attention modules based on channel affinity, the learned feature map for our network can well capture the abundant features information of point cloud. The proposed MRFGAT architecture is tested on ModelNet10 and ModelNet40 datasets, and results show it achieves state-of-the-art performance in shape classification tasks.



### The Elements of End-to-end Deep Face Recognition: A Survey of Recent Advances
- **Arxiv ID**: http://arxiv.org/abs/2009.13290v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13290v4)
- **Published**: 2020-09-28 13:02:17+00:00
- **Updated**: 2021-12-27 05:55:08+00:00
- **Authors**: Hang Du, Hailin Shi, Dan Zeng, Xiao-Ping Zhang, Tao Mei
- **Comment**: Accepted for publication in ACM Computing Surveys
- **Journal**: None
- **Summary**: Face recognition is one of the most popular and long-standing topics in computer vision. With the recent development of deep learning techniques and large-scale datasets, deep face recognition has made remarkable progress and been widely used in many real-world applications. Given a natural image or video frame as input, an end-to-end deep face recognition system outputs the face feature for recognition. To achieve this, a typical end-to-end system is built with three key elements: face detection, face alignment, and face representation. The face detection locates faces in the image or frame. Then, the face alignment is proceeded to calibrate the faces to the canonical view and crop them with a normalized pixel size. Finally, in the stage of face representation, the discriminative features are extracted from the aligned face for recognition. Nowadays, all of the three elements are fulfilled by the technique of deep convolutional neural network. In this survey article, we present a comprehensive review about the recent advance of each element. To start with, we present an overview of the end-to-end deep face recognition. Then, we review the advance of each element, respectively, covering many aspects such as the to-date algorithm designs, evaluation metrics, datasets, performance comparison, existing challenges, and promising directions for future research. Also, we provide a detailed discussion about the effect of each element on its subsequent elements and the holistic system. Through this survey, we wish to bring contributions in two aspects: first, readers can conveniently identify the methods which are quite strong-baseline style in the subcategory for further exploration; second, one can also employ suitable methods for establishing a state-of-the-art end-to-end face recognition system from scratch.



### Cuid: A new study of perceived image quality and its subjective assessment
- **Arxiv ID**: http://arxiv.org/abs/2009.13304v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13304v1)
- **Published**: 2020-09-28 13:14:45+00:00
- **Updated**: 2020-09-28 13:14:45+00:00
- **Authors**: Lucie Lévêque, Ji Yang, Xiaohan Yang, Pengfei Guo, Kenneth Dasalla, Leida Li, Yingying Wu, Hantao Liu
- **Comment**: None
- **Journal**: 27th IEEE International Conference on Image Processing (ICIP), Oct
  2020, Abu Dhabi, United Arab Emirates
- **Summary**: Research on image quality assessment (IQA) remains limited mainly due to our incomplete knowledge about human visual perception. Existing IQA algorithms have been designed or trained with insufficient subjective data with a small degree of stimulus variability. This has led to challenges for those algorithms to handle complexity and diversity of real-world digital content. Perceptual evidence from human subjects serves as a grounding for the development of advanced IQA algorithms. It is thus critical to acquire reliable subjective data with controlled perception experiments that faithfully reflect human behavioural responses to distortions in visual signals. In this paper, we present a new study of image quality perception where subjective ratings were collected in a controlled lab environment. We investigate how quality perception is affected by a combination of different categories of images and different types and levels of distortions. The database will be made publicly available to facilitate calibration and validation of IQA algorithms.



### EvolGAN: Evolutionary Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2009.13311v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13311v1)
- **Published**: 2020-09-28 13:31:13+00:00
- **Updated**: 2020-09-28 13:31:13+00:00
- **Authors**: Baptiste Roziere, Fabien Teytaud, Vlad Hosu, Hanhe Lin, Jeremy Rapin, Mariia Zameshina, Olivier Teytaud
- **Comment**: accepted ACCV oral
- **Journal**: None
- **Summary**: We propose to use a quality estimator and evolutionary methods to search the latent space of generative adversarial networks trained on small, difficult datasets, or both. The new method leads to the generation of significantly higher quality images while preserving the original generator's diversity. Human raters preferred an image from the new version with frequency 83.7pc for Cats, 74pc for FashionGen, 70.4pc for Horses, and 69.2pc for Artworks, and minor improvements for the already excellent GANs for faces. This approach applies to any quality scorer and GAN generator.



### High-throughput molecular imaging via deep learning enabled Raman spectroscopy
- **Arxiv ID**: http://arxiv.org/abs/2009.13318v1
- **DOI**: 10.1021/acs.analchem.1c02178
- **Categories**: **eess.IV**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2009.13318v1)
- **Published**: 2020-09-28 13:40:14+00:00
- **Updated**: 2020-09-28 13:40:14+00:00
- **Authors**: Conor C. Horgan, Magnus Jensen, Anika Nagelkerke, Jean-Phillipe St-Pierre, Tom Vercauteren, Molly M. Stevens, Mads S. Bergholt
- **Comment**: None
- **Journal**: None
- **Summary**: Raman spectroscopy enables non-destructive, label-free imaging with unprecedented molecular contrast but is limited by slow data acquisition, largely preventing high-throughput imaging applications. Here, we present a comprehensive framework for higher-throughput molecular imaging via deep learning enabled Raman spectroscopy, termed DeepeR, trained on a large dataset of hyperspectral Raman images, with over 1.5 million spectra (400 hours of acquisition) in total. We firstly perform denoising and reconstruction of low signal-to-noise ratio Raman molecular signatures via deep learning, with a 9x improvement in mean squared error over state-of-the-art Raman filtering methods. Next, we develop a neural network for robust 2-4x super-resolution of hyperspectral Raman images that preserves molecular cellular information. Combining these approaches, we achieve Raman imaging speed-ups of up to 160x, enabling high resolution, high signal-to-noise ratio cellular imaging in under one minute. Finally, transfer learning is applied to extend DeepeR from cell to tissue-scale imaging. DeepeR provides a foundation that will enable a host of higher-throughput Raman spectroscopy and molecular imaging applications across biomedicine.



### AI Progress in Skin Lesion Analysis
- **Arxiv ID**: http://arxiv.org/abs/2009.13323v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13323v2)
- **Published**: 2020-09-28 13:44:50+00:00
- **Updated**: 2020-10-09 16:58:15+00:00
- **Authors**: Philippe M. Burlina, William Paul, Phil A. Mathew, Neil J. Joshi, Alison W. Rebman, John N. Aucott
- **Comment**: None
- **Journal**: None
- **Summary**: We examine progress in the use of AI for detecting skin lesions, with particular emphasis on the erythema migrans rash of acute Lyme disease, and other lesions, such as those from conditions like herpes zoster (shingles), tinea corporis, erythema multiforme, cellulitis, insect bites, or tick bites. We discuss important challenges for these applications, in particular the problems of AI bias regarding the lack of skin images in dark skinned individuals, being able to accurately detect, delineate, and segment lesions or regions of interest compared to normal skin in images, and low shot learning (addressing classification with a paucity of training images). Solving these problems ranges from being highly desirable requirements -- e.g. for delineation, which may be useful to disambiguate between similar types of lesions, and perform improved diagnostics -- or required, as is the case for AI de-biasing, to allow for the deployment of fair AI techniques in the clinic for skin lesion analysis. For the problem of low shot learning in particular, we report skin analysis algorithms that gracefully degrade and still perform well at low shots, when compared to baseline algorithms: when using a little as 10 training exemplars per class, the baseline DL algorithm performance significantly degrades, with accuracy of 56.41%, close to chance, whereas the best performing low shot algorithm yields an accuracy of 85.26%.



### Addressing Class Imbalance in Scene Graph Parsing by Learning to Contrast and Score
- **Arxiv ID**: http://arxiv.org/abs/2009.13331v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13331v2)
- **Published**: 2020-09-28 13:57:59+00:00
- **Updated**: 2020-10-05 13:06:45+00:00
- **Authors**: He Huang, Shunta Saito, Yuta Kikuchi, Eiichi Matsumoto, Wei Tang, Philip S. Yu
- **Comment**: ACCV 2020
- **Journal**: None
- **Summary**: Scene graph parsing aims to detect objects in an image scene and recognize their relations. Recent approaches have achieved high average scores on some popular benchmarks, but fail in detecting rare relations, as the highly long-tailed distribution of data biases the learning towards frequent labels. Motivated by the fact that detecting these rare relations can be critical in real-world applications, this paper introduces a novel integrated framework of classification and ranking to resolve the class imbalance problem in scene graph parsing. Specifically, we design a new Contrasting Cross-Entropy loss, which promotes the detection of rare relations by suppressing incorrect frequent ones. Furthermore, we propose a novel scoring module, termed as Scorer, which learns to rank the relations based on the image features and relation features to improve the recall of predictions. Our framework is simple and effective, and can be incorporated into current scene graph models. Experimental results show that the proposed approach improves the current state-of-the-art methods, with a clear advantage of detecting rare relations.



### Group Whitening: Balancing Learning Efficiency and Representational Capacity
- **Arxiv ID**: http://arxiv.org/abs/2009.13333v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.13333v4)
- **Published**: 2020-09-28 14:00:07+00:00
- **Updated**: 2021-04-06 04:17:27+00:00
- **Authors**: Lei Huang, Yi Zhou, Li Liu, Fan Zhu, Ling Shao
- **Comment**: V4: camera version of CVPR 2021. Code available at:
  https://github.com/huangleiBuaa/GroupWhitening
- **Journal**: None
- **Summary**: Batch normalization (BN) is an important technique commonly incorporated into deep learning models to perform standardization within mini-batches. The merits of BN in improving a model's learning efficiency can be further amplified by applying whitening, while its drawbacks in estimating population statistics for inference can be avoided through group normalization (GN). This paper proposes group whitening (GW), which exploits the advantages of the whitening operation and avoids the disadvantages of normalization within mini-batches. In addition, we analyze the constraints imposed on features by normalization, and show how the batch size (group number) affects the performance of batch (group) normalized networks, from the perspective of model's representational capacity. This analysis provides theoretical guidance for applying GW in practice. Finally, we apply the proposed GW to ResNet and ResNeXt architectures and conduct experiments on the ImageNet and COCO benchmarks. Results show that GW consistently improves the performance of different architectures, with absolute gains of $1.02\%$ $\sim$ $1.49\%$ in top-1 accuracy on ImageNet and $1.82\%$ $\sim$ $3.21\%$ in bounding box AP on COCO.



### Weakly Supervised Deep Functional Map for Shape Matching
- **Arxiv ID**: http://arxiv.org/abs/2009.13339v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13339v1)
- **Published**: 2020-09-28 14:06:46+00:00
- **Updated**: 2020-09-28 14:06:46+00:00
- **Authors**: Abhishek Sharma, Maks Ovsjanikov
- **Comment**: Accepted to appear in proceedings of Neurips 2020. Code available at:
  \url{https://github.com/Not-IITian/Weakly-supervised-Functional-map}
- **Journal**: None
- **Summary**: A variety of deep functional maps have been proposed recently, from fully supervised to totally unsupervised, with a range of loss functions as well as different regularization terms. However, it is still not clear what are minimum ingredients of a deep functional map pipeline and whether such ingredients unify or generalize all recent work on deep functional maps. We show empirically minimum components for obtaining state of the art results with different loss functions, supervised as well as unsupervised. Furthermore, we propose a novel framework designed for both full-to-full as well as partial to full shape matching that achieves state of the art results on several benchmark datasets outperforming even the fully supervised methods by a significant margin. Our code is publicly available at https://github.com/Not-IITian/Weakly-supervised-Functional-map



### Learning Category- and Instance-Aware Pixel Embedding for Fast Panoptic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2009.13342v2
- **DOI**: 10.1109/TIP.2021.3090522
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13342v2)
- **Published**: 2020-09-28 14:07:50+00:00
- **Updated**: 2021-06-16 01:13:09+00:00
- **Authors**: Naiyu Gao, Yanhu Shan, Xin Zhao, Kaiqi Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Panoptic segmentation (PS) is a complex scene understanding task that requires providing high-quality segmentation for both thing objects and stuff regions. Previous methods handle these two classes with semantic and instance segmentation modules separately, following with heuristic fusion or additional modules to resolve the conflicts between the two outputs. This work simplifies this pipeline of PS by consistently modeling the two classes with a novel PS framework, which extends a detection model with an extra module to predict category- and instance-aware pixel embedding (CIAE). CIAE is a novel pixel-wise embedding feature that encodes both semantic-classification and instance-distinction information. At the inference process, PS results are simply derived by assigning each pixel to a detected instance or a stuff class according to the learned embedding. Our method not only demonstrates fast inference speed but also the first one-stage method to achieve comparable performance to two-stage methods on the challenging COCO benchmark.



### RS-MetaNet: Deep meta metric learning for few-shot remote sensing scene classification
- **Arxiv ID**: http://arxiv.org/abs/2009.13364v1
- **DOI**: 10.1109/TGRS.2020.3027387
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13364v1)
- **Published**: 2020-09-28 14:34:15+00:00
- **Updated**: 2020-09-28 14:34:15+00:00
- **Authors**: Haifeng Li, Zhenqi Cui, Zhiqing Zhu, Li Chen, Jiawei Zhu, Haozhe Huang, Chao Tao
- **Comment**: 13 pages, 11 figures
- **Journal**: IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, 2020
- **Summary**: Training a modern deep neural network on massive labeled samples is the main paradigm in solving the scene classification problem for remote sensing, but learning from only a few data points remains a challenge. Existing methods for few-shot remote sensing scene classification are performed in a sample-level manner, resulting in easy overfitting of learned features to individual samples and inadequate generalization of learned category segmentation surfaces. To solve this problem, learning should be organized at the task level rather than the sample level. Learning on tasks sampled from a task family can help tune learning algorithms to perform well on new tasks sampled in that family. Therefore, we propose a simple but effective method, called RS-MetaNet, to resolve the issues related to few-shot remote sensing scene classification in the real world. On the one hand, RS-MetaNet raises the level of learning from the sample to the task by organizing training in a meta way, and it learns to learn a metric space that can well classify remote sensing scenes from a series of tasks. We also propose a new loss function, called Balance Loss, which maximizes the generalization ability of the model to new samples by maximizing the distance between different categories, providing the scenes in different categories with better linear segmentation planes while ensuring model fit. The experimental results on three open and challenging remote sensing datasets, UCMerced\_LandUse, NWPU-RESISC45, and Aerial Image Data, demonstrate that our proposed RS-MetaNet method achieves state-of-the-art results in cases where there are only 1-20 labeled samples.



### Fast Gravitational Approach for Rigid Point Set Registration with Ordinary Differential Equations
- **Arxiv ID**: http://arxiv.org/abs/2009.14005v2
- **DOI**: 10.1109/ACCESS.2021.3084505
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.14005v2)
- **Published**: 2020-09-28 15:05:39+00:00
- **Updated**: 2021-07-01 15:12:05+00:00
- **Authors**: Sk Aziz Ali, Kerem Kahraman, Christian Theobalt, Didier Stricker, Vladislav Golyanik
- **Comment**: 18 pages, 18 figures and two tables
- **Journal**: IEEE Access, vol. 9, pp. 79060-79079, 2021
- **Summary**: This article introduces a new physics-based method for rigid point set alignment called Fast Gravitational Approach (FGA). In FGA, the source and target point sets are interpreted as rigid particle swarms with masses interacting in a globally multiply-linked manner while moving in a simulated gravitational force field. The optimal alignment is obtained by explicit modeling of forces acting on the particles as well as their velocities and displacements with second-order ordinary differential equations of motion. Additional alignment cues (point-based or geometric features, and other boundary conditions) can be integrated into FGA through particle masses. We propose a smooth-particle mass function for point mass initialization, which improves robustness to noise and structural discontinuities. To avoid prohibitive quadratic complexity of all-to-all point interactions, we adapt a Barnes-Hut tree for accelerated force computation and achieve quasilinear computational complexity. We show that the new method class has characteristics not found in previous alignment methods such as efficient handling of partial overlaps, inhomogeneous point sampling densities, and coping with large point clouds with reduced runtime compared to the state of the art. Experiments show that our method performs on par with or outperforms all compared competing non-deep-learning-based and general-purpose techniques (which do not assume the availability of training data and a scene prior) in resolving transformations for LiDAR data and gains state-of-the-art accuracy and speed when coping with different types of data disturbances.



### CAT STREET: Chronicle Archive of Tokyo Street-fashion
- **Arxiv ID**: http://arxiv.org/abs/2009.13395v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.DB, cs.DL
- **Links**: [PDF](http://arxiv.org/pdf/2009.13395v2)
- **Published**: 2020-09-28 15:16:45+00:00
- **Updated**: 2021-04-29 13:54:35+00:00
- **Authors**: Satoshi Takahashi, Keiko Yamaguchi, Asuka Watanabe
- **Comment**: 19 pages, 17 figures
- **Journal**: None
- **Summary**: The analysis of daily-life fashion trends can provide us a profound understanding of our societies and cultures. However, no appropriate digital archive exists that includes images illustrating what people wore in their daily lives over an extended period. In this study, we propose a new fashion image archive, Chronicle Archive of Tokyo Street-fashion (CAT STREET), to shed light on daily-life fashion trends. CAT STREET includes images showing what people wore in their daily lives during 1970--2017, and these images contain timestamps and street location annotations. This novel database combined with machine learning enables us to observe daily-life fashion trends over a long term and analyze them quantitatively. To evaluate the potential of our proposed approach with the novel database, we corroborated the rules-of-thumb of two fashion trend phenomena that have been observed and discussed qualitatively in previous studies. Through these empirical analyses, we verified that our approach to quantify fashion trends can help in exploring unsolved research questions. We also demonstrate CAT STREET's potential to find new standpoints to promote the understanding of societies and cultures through fashion embedded in consumers' daily lives.



### A Study on Lip Localization Techniques used for Lip reading from a Video
- **Arxiv ID**: http://arxiv.org/abs/2009.13420v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, I.2.6; I.2.10; I.4.6; I.4.7; I.4.10; I.5
- **Links**: [PDF](http://arxiv.org/pdf/2009.13420v1)
- **Published**: 2020-09-28 15:36:35+00:00
- **Updated**: 2020-09-28 15:36:35+00:00
- **Authors**: S. D. Lalitha, K. K. Thyagharajan
- **Comment**: 6 pages, 1 figure
- **Journal**: None
- **Summary**: In this paper some of the different techniques used to localize the lips from the face are discussed and compared along with its processing steps. Lip localization is the basic step needed to read the lips for extracting visual information from the video input. The techniques could be applied on asymmetric lips and also on the mouth with visible teeth, tongue & mouth with moustache. In the process of Lip reading the following steps are generally used. They are, initially locating lips in the first frame of the video input, then tracking the lips in the following frames using the resulting pixel points of initial step and at last converting the tracked lip model to its corresponding matched letter to give the visual information. A new proposal is also initiated from the discussed techniques. The lip reading is useful in Automatic Speech Recognition when the audio is absent or present low with or without noise in the communication systems. Human Computer communication also will require speech recognition.



### Learning to Detect Objects with a 1 Megapixel Event Camera
- **Arxiv ID**: http://arxiv.org/abs/2009.13436v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13436v2)
- **Published**: 2020-09-28 16:03:59+00:00
- **Updated**: 2020-12-09 15:41:24+00:00
- **Authors**: Etienne Perot, Pierre de Tournemire, Davide Nitti, Jonathan Masci, Amos Sironi
- **Comment**: None
- **Journal**: None
- **Summary**: Event cameras encode visual information with high temporal precision, low data-rate, and high-dynamic range. Thanks to these characteristics, event cameras are particularly suited for scenarios with high motion, challenging lighting conditions and requiring low latency. However, due to the novelty of the field, the performance of event-based systems on many vision tasks is still lower compared to conventional frame-based solutions. The main reasons for this performance gap are: the lower spatial resolution of event sensors, compared to frame cameras; the lack of large-scale training datasets; the absence of well established deep learning architectures for event-based processing. In this paper, we address all these problems in the context of an event-based object detection task. First, we publicly release the first high-resolution large-scale dataset for object detection. The dataset contains more than 14 hours recordings of a 1 megapixel event camera, in automotive scenarios, together with 25M bounding boxes of cars, pedestrians, and two-wheelers, labeled at high frequency. Second, we introduce a novel recurrent architecture for event-based detection and a temporal consistency loss for better-behaved training. The ability to compactly represent the sequence of events into the internal memory of the model is essential to achieve high accuracy. Our model outperforms by a large margin feed-forward event-based architectures. Moreover, our method does not require any reconstruction of intensity images from events, showing that training directly from raw events is possible, more efficient, and more accurate than passing through an intermediate intensity image. Experiments on the dataset introduced in this work, for which events and gray level images are available, show performance on par with that of highly tuned and studied frame-based detectors.



### The Smart Parking Management System
- **Arxiv ID**: http://arxiv.org/abs/2009.13443v1
- **DOI**: 10.5121/ijcsit.2020.12405
- **Categories**: **cs.CY**, cs.AR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13443v1)
- **Published**: 2020-09-28 16:08:10+00:00
- **Updated**: 2020-09-28 16:08:10+00:00
- **Authors**: Amira. A. Elsonbaty, Mahmoud Shams
- **Comment**: 12 pages, 15 figures
- **Journal**: International Journal of Computer Science & Information Technology
  (IJCSIT) Vol 12, No 4, August 2020
- **Summary**: With growing, Car parking increases with the number of car users. With the increased use of smartphones and their applications, users prefer mobile phone-based solutions. This paper proposes the Smart Parking Management System (SPMS) that depends on Arduino parts, Android applications, and based on IoT. This gave the client the ability to check available parking spaces and reserve a parking spot. IR sensors are utilized to know if a car park space is allowed. Its area data are transmitted using the WI-FI module to the server and are recovered by the mobile application which offers many options attractively and with no cost to users and lets the user check reservation details. With IoT technology, the smart parking system can be connected wirelessly to easily track available locations.



### Arabic Handwritten Character Recognition based on Convolution Neural Networks and Support Vector Machine
- **Arxiv ID**: http://arxiv.org/abs/2009.13450v1
- **DOI**: 10.14569/IJACSA.2020.0110819
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13450v1)
- **Published**: 2020-09-28 16:18:52+00:00
- **Updated**: 2020-09-28 16:18:52+00:00
- **Authors**: Mahmoud Shams, Amira. A. Elsonbaty, Wael. Z. ElSawy
- **Comment**: 6 pages, 3 figures, 7 tables
- **Journal**: None
- **Summary**: Recognition of Arabic characters is essential for natural language processing and computer vision fields. The need to recognize and classify the handwritten Arabic letters and characters are essentially required. In this paper, we present an algorithm for recognizing Arabic letters and characters based on using deep convolution neural networks (DCNN) and support vector machine (SVM). This paper addresses the problem of recognizing the Arabic handwritten characters by determining the similarity between the input templates and the pre-stored templates using both fully connected DCNN and dropout SVM. Furthermore, this paper determines the correct classification rate (CRR) depends on the accuracy of the corrected classified templates, of the recognized handwritten Arabic characters. Moreover, we determine the error classification rate (ECR). The experimental results of this work indicate the ability of the proposed algorithm to recognize, identify, and verify the input handwritten Arabic characters. Furthermore, the proposed system determines similar Arabic characters using a clustering algorithm based on the K-means clustering approach to handle the problem of multi-stroke in Arabic characters. The comparative evaluation is stated and the system accuracy reached 95.07% CRR with 4.93% ECR compared with the state of the art.



### ConvSequential-SLAM: A Sequence-based, Training-less Visual Place Recognition Technique for Changing Environments
- **Arxiv ID**: http://arxiv.org/abs/2009.13454v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13454v1)
- **Published**: 2020-09-28 16:31:29+00:00
- **Updated**: 2020-09-28 16:31:29+00:00
- **Authors**: Mihnea-Alexandru Tomită, Mubariz Zaffar, Michael Milford, Klaus McDonald-Maier, Shoaib Ehsan
- **Comment**: 10 pages, currently under-review
- **Journal**: None
- **Summary**: Visual Place Recognition (VPR) is the ability to correctly recall a previously visited place under changing viewpoints and appearances. A large number of handcrafted and deep-learning-based VPR techniques exist, where the former suffer from appearance changes and the latter have significant computational needs. In this paper, we present a new handcrafted VPR technique that achieves state-of-the-art place matching performance under challenging conditions. Our technique combines the best of 2 existing trainingless VPR techniques, SeqSLAM and CoHOG, which are each robust to conditional and viewpoint changes, respectively. This blend, namely ConvSequential-SLAM, utilises sequential information and block-normalisation to handle appearance changes, while using regional-convolutional matching to achieve viewpoint-invariance. We analyse content-overlap in-between query frames to find a minimum sequence length, while also re-using the image entropy information for environment-based sequence length tuning. State-of-the-art performance is reported in contrast to 8 contemporary VPR techniques on 4 public datasets. Qualitative insights and an ablation study on sequence length are also provided.



### A complete character recognition and transliteration technique for Devanagari script
- **Arxiv ID**: http://arxiv.org/abs/2009.13460v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13460v1)
- **Published**: 2020-09-28 16:43:18+00:00
- **Updated**: 2020-09-28 16:43:18+00:00
- **Authors**: Jasmine Kaur, Vinay Kumar
- **Comment**: None
- **Journal**: None
- **Summary**: Transliteration involves transformation of one script to another based on phonetic similarities between the characters of two distinctive scripts. In this paper, we present a novel technique for automatic transliteration of Devanagari script using character recognition. One of the first tasks performed to isolate the constituent characters is segmentation. Line segmentation methodology in this manuscript discusses the case of overlapping lines. Character segmentation algorithm is designed to segment conjuncts and separate shadow characters. Presented shadow character segmentation scheme employs connected component method to isolate the character, keeping the constituent characters intact. Statistical features namely different order moments like area, variance, skewness and kurtosis along with structural features of characters are employed in two phase recognition process. After recognition, constituent Devanagari characters are mapped to corresponding roman alphabets in way that resulting roman alphabets have similar pronunciation to source characters.



### EIS -- a family of activation functions combining Exponential, ISRU, and Softplus
- **Arxiv ID**: http://arxiv.org/abs/2009.13501v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2009.13501v2)
- **Published**: 2020-09-28 17:48:24+00:00
- **Updated**: 2020-10-12 15:51:12+00:00
- **Authors**: Koushik Biswas, Sandeep Kumar, Shilpak Banerjee, Ashish Kumar Pandey
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Activation functions play a pivotal role in the function learning using neural networks. The non-linearity in the learned function is achieved by repeated use of the activation function. Over the years, numerous activation functions have been proposed to improve accuracy in several tasks. Basic functions like ReLU, Sigmoid, Tanh, or Softplus have been favorite among the deep learning community because of their simplicity. In recent years, several novel activation functions arising from these basic functions have been proposed, which have improved accuracy in some challenging datasets. We propose a five hyper-parameters family of activation functions, namely EIS, defined as, \[ \frac{x(\ln(1+e^x))^\alpha}{\sqrt{\beta+\gamma x^2}+\delta e^{-\theta x}}. \] We show examples of activation functions from the EIS family which outperform widely used activation functions on some well known datasets and models. For example, $\frac{x\ln(1+e^x)}{x+1.16e^{-x}}$ beats ReLU by 0.89\% in DenseNet-169, 0.24\% in Inception V3 in CIFAR100 dataset while 1.13\% in Inception V3, 0.13\% in DenseNet-169, 0.94\% in SimpleNet model in CIFAR10 dataset. Also, $\frac{x\ln(1+e^x)}{\sqrt{1+x^2}}$ beats ReLU by 1.68\% in DenseNet-169, 0.30\% in Inception V3 in CIFAR100 dataset while 1.0\% in Inception V3, 0.15\% in DenseNet-169, 1.13\% in SimpleNet model in CIFAR10 dataset.



### Information Obfuscation of Graph Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2009.13504v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.13504v5)
- **Published**: 2020-09-28 17:55:04+00:00
- **Updated**: 2021-06-13 05:35:04+00:00
- **Authors**: Peiyuan Liao, Han Zhao, Keyulu Xu, Tommi Jaakkola, Geoffrey Gordon, Stefanie Jegelka, Ruslan Salakhutdinov
- **Comment**: ICML 2021; Code is available at https://github.com/liaopeiyuan/GAL
- **Journal**: None
- **Summary**: While the advent of Graph Neural Networks (GNNs) has greatly improved node and graph representation learning in many applications, the neighborhood aggregation scheme exposes additional vulnerabilities to adversaries seeking to extract node-level information about sensitive attributes. In this paper, we study the problem of protecting sensitive attributes by information obfuscation when learning with graph structured data. We propose a framework to locally filter out pre-determined sensitive attributes via adversarial training with the total variation and the Wasserstein distance. Our method creates a strong defense against inference attacks, while only suffering small loss in task performance. Theoretically, we analyze the effectiveness of our framework against a worst-case adversary, and characterize an inherent trade-off between maximizing predictive accuracy and minimizing information leakage. Experiments across multiple datasets from recommender systems, knowledge graphs and quantum chemistry demonstrate that the proposed approach provides a robust defense across various graph structures and tasks, while producing competitive GNN encoders for downstream tasks.



### Afro-MNIST: Synthetic generation of MNIST-style datasets for low-resource languages
- **Arxiv ID**: http://arxiv.org/abs/2009.13509v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13509v1)
- **Published**: 2020-09-28 17:57:40+00:00
- **Updated**: 2020-09-28 17:57:40+00:00
- **Authors**: Daniel J Wu, Andrew C Yang, Vinay U Prabhu
- **Comment**: 10 pages, 11 figures, presented as a workshop paper at Practical
  Machine Learning for Developing Countries @ ICLR 2020
- **Journal**: None
- **Summary**: We present Afro-MNIST, a set of synthetic MNIST-style datasets for four orthographies used in Afro-Asiatic and Niger-Congo languages: Ge`ez (Ethiopic), Vai, Osmanya, and N'Ko. These datasets serve as "drop-in" replacements for MNIST. We also describe and open-source a method for synthetic MNIST-style dataset generation from single examples of each digit. These datasets can be found at https://github.com/Daniel-Wu/AfroMNIST. We hope that MNIST-style datasets will be developed for other numeral systems, and that these datasets vitalize machine learning education in underrepresented nations in the research community.



### Fully Automatic Intervertebral Disc Segmentation Using Multimodal 3D U-Net
- **Arxiv ID**: http://arxiv.org/abs/2009.13583v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13583v1)
- **Published**: 2020-09-28 18:58:24+00:00
- **Updated**: 2020-09-28 18:58:24+00:00
- **Authors**: Chuanbo Wang, Ye Guo, Wei Chen, Zeyun Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Intervertebral discs (IVDs), as small joints lying between adjacent vertebrae, have played an important role in pressure buffering and tissue protection. The fully-automatic localization and segmentation of IVDs have been discussed in the literature for many years since they are crucial to spine disease diagnosis and provide quantitative parameters in the treatment. Traditionally hand-crafted features are derived based on image intensities and shape priors to localize and segment IVDs. With the advance of deep learning, various neural network models have gained great success in image analysis including the recognition of intervertebral discs. Particularly, U-Net stands out among other approaches due to its outstanding performance on biomedical images with a relatively small set of training data. This paper proposes a novel convolutional framework based on 3D U-Net to segment IVDs from multi-modality MRI images. We first localize the centers of intervertebral discs in each spine sample and then train the network based on the cropped small volumes centered at the localized intervertebral discs. A detailed comprehensive analysis of the results using various combinations of multi-modalities is presented. Furthermore, experiments conducted on 2D and 3D U-Nets with augmented and non-augmented datasets are demonstrated and compared in terms of Dice coefficient and Hausdorff distance. Our method has proved to be effective with a mean segmentation Dice coefficient of 89.0% and a standard deviation of 1.4%.



### A Ranking-based, Balanced Loss Function Unifying Classification and Localisation in Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2009.13592v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13592v4)
- **Published**: 2020-09-28 19:24:51+00:00
- **Updated**: 2021-01-07 08:25:43+00:00
- **Authors**: Kemal Oksuz, Baris Can Cam, Emre Akbas, Sinan Kalkan
- **Comment**: NeurIPS 2020 spotlight paper
- **Journal**: None
- **Summary**: We propose average Localisation-Recall-Precision (aLRP), a unified, bounded, balanced and ranking-based loss function for both classification and localisation tasks in object detection. aLRP extends the Localisation-Recall-Precision (LRP) performance metric (Oksuz et al., 2018) inspired from how Average Precision (AP) Loss extends precision to a ranking-based loss function for classification (Chen et al., 2020). aLRP has the following distinct advantages: (i) aLRP is the first ranking-based loss function for both classification and localisation tasks. (ii) Thanks to using ranking for both tasks, aLRP naturally enforces high-quality localisation for high-precision classification. (iii) aLRP provides provable balance between positives and negatives. (iv) Compared to on average $\sim$6 hyperparameters in the loss functions of state-of-the-art detectors, aLRP Loss has only one hyperparameter, which we did not tune in practice. On the COCO dataset, aLRP Loss improves its ranking-based predecessor, AP Loss, up to around $5$ AP points, achieves $48.9$ AP without test time augmentation and outperforms all one-stage detectors. Code available at: https://github.com/kemaloksuz/aLRPLoss .



### Multi-focus Image Fusion for Visual Sensor Networks
- **Arxiv ID**: http://arxiv.org/abs/2009.13615v3
- **DOI**: 10.1109/IranianCEE.2016.7585790
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13615v3)
- **Published**: 2020-09-28 20:39:35+00:00
- **Updated**: 2020-10-02 18:04:32+00:00
- **Authors**: Milad Abdollahzadeh, Touba Malekzadeh, Hadi Seyedarabi
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Image fusion in visual sensor networks (VSNs) aims to combine information from multiple images of the same scene in order to transform a single image with more information. Image fusion methods based on discrete cosine transform (DCT) are less complex and time-saving in DCT based standards of image and video which makes them more suitable for VSN applications. In this paper, an efficient algorithm for the fusion of multi-focus images in the DCT domain is proposed. The Sum of modified laplacian (SML) of corresponding blocks of source images is used as a contrast criterion and blocks with the larger value of SML are absorbed to output images. The experimental results on several images show the improvement of the proposed algorithm in terms of both subjective and objective quality of fused image relative to other DCT based techniques.



### COVID-CT-MD: COVID-19 Computed Tomography (CT) Scan Dataset Applicable in Machine Learning and Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2009.14623v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.14623v1)
- **Published**: 2020-09-28 20:42:07+00:00
- **Updated**: 2020-09-28 20:42:07+00:00
- **Authors**: Parnian Afshar, Shahin Heidarian, Nastaran Enshaei, Farnoosh Naderkhani, Moezedin Javad Rafiee, Anastasia Oikonomou, Faranak Babaki Fard, Kaveh Samimi, Konstantinos N. Plataniotis, Arash Mohammadi
- **Comment**: None
- **Journal**: None
- **Summary**: Novel Coronavirus (COVID-19) has drastically overwhelmed more than 200 countries affecting millions and claiming almost 1 million lives, since its emergence in late 2019. This highly contagious disease can easily spread, and if not controlled in a timely fashion, can rapidly incapacitate healthcare systems. The current standard diagnosis method, the Reverse Transcription Polymerase Chain Reaction (RT- PCR), is time consuming, and subject to low sensitivity. Chest Radiograph (CXR), the first imaging modality to be used, is readily available and gives immediate results. However, it has notoriously lower sensitivity than Computed Tomography (CT), which can be used efficiently to complement other diagnostic methods. This paper introduces a new COVID-19 CT scan dataset, referred to as COVID-CT-MD, consisting of not only COVID-19 cases, but also healthy and subjects infected by Community Acquired Pneumonia (CAP). COVID-CT-MD dataset, which is accompanied with lobe-level, slice-level and patient-level labels, has the potential to facilitate the COVID-19 research, in particular COVID-CT-MD can assist in development of advanced Machine Learning (ML) and Deep Neural Network (DNN) based solutions.



### Fully Automated Left Atrium Segmentation from Anatomical Cine Long-axis MRI Sequences using Deep Convolutional Neural Network with Unscented Kalman Filter
- **Arxiv ID**: http://arxiv.org/abs/2009.13627v2
- **DOI**: 10.1016/j.media.2020.101916
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13627v2)
- **Published**: 2020-09-28 21:06:35+00:00
- **Updated**: 2020-11-22 18:47:25+00:00
- **Authors**: Xiaoran Zhang, Michelle Noga, David Glynn Martin, Kumaradevan Punithakumar
- **Comment**: Accepted by Medical Image Analysis 2020
- **Journal**: None
- **Summary**: This study proposes a fully automated approach for the left atrial segmentation from routine cine long-axis cardiac magnetic resonance image sequences using deep convolutional neural networks and Bayesian filtering. The proposed approach consists of a classification network that automatically detects the type of long-axis sequence and three different convolutional neural network models followed by unscented Kalman filtering (UKF) that delineates the left atrium. Instead of training and predicting all long-axis sequence types together, the proposed approach first identifies the image sequence type as to 2, 3 and 4 chamber views, and then performs prediction based on neural nets trained for that particular sequence type. The datasets were acquired retrospectively and ground truth manual segmentation was provided by an expert radiologist. In addition to neural net based classification and segmentation, another neural net is trained and utilized to select image sequences for further processing using UKF to impose temporal consistency over cardiac cycle. A cyclic dynamic model with time-varying angular frequency is introduced in UKF to characterize the variations in cardiac motion during image scanning. The proposed approach was trained and evaluated separately with varying amount of training data with images acquired from 20, 40, 60 and 80 patients. Evaluations over 1515 images with equal number of images from each chamber group acquired from an additional 20 patients demonstrated that the proposed model outperformed state-of-the-art and yielded a mean Dice coefficient value of 94.1%, 93.7% and 90.1% for 2, 3 and 4-chamber sequences, respectively, when trained with datasets from 80 patients.



### MPG-Net: Multi-Prediction Guided Network for Segmentation of Retinal Layers in OCT Images
- **Arxiv ID**: http://arxiv.org/abs/2009.13634v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13634v1)
- **Published**: 2020-09-28 21:22:22+00:00
- **Updated**: 2020-09-28 21:22:22+00:00
- **Authors**: Zeyu Fu, Yang Sun, Xiangyu Zhang, Scott Stainton, Shaun Barney, Jeffry Hogg, William Innes, Satnam Dlay
- **Comment**: EUSIPCO2020
- **Journal**: None
- **Summary**: Optical coherence tomography (OCT) is a commonly-used method of extracting high resolution retinal information. Moreover there is an increasing demand for the automated retinal layer segmentation which facilitates the retinal disease diagnosis. In this paper, we propose a novel multiprediction guided attention network (MPG-Net) for automated retinal layer segmentation in OCT images. The proposed method consists of two major steps to strengthen the discriminative power of a U-shape Fully convolutional network (FCN) for reliable automated segmentation. Firstly, the feature refinement module which adaptively re-weights the feature channels is exploited in the encoder to capture more informative features and discard information in irrelevant regions. Furthermore, we propose a multi-prediction guided attention mechanism which provides pixel-wise semantic prediction guidance to better recover the segmentation mask at each scale. This mechanism which transforms the deep supervision to supervised attention is able to guide feature aggregation with more semantic information between intermediate layers. Experiments on the publicly available Duke OCT dataset confirm the effectiveness of the proposed method as well as an improved performance over other state-of-the-art approaches.



### Cross-Task Representation Learning for Anatomical Landmark Detection
- **Arxiv ID**: http://arxiv.org/abs/2009.13635v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13635v1)
- **Published**: 2020-09-28 21:22:49+00:00
- **Updated**: 2020-09-28 21:22:49+00:00
- **Authors**: Zeyu Fu, Jianbo Jiao, Michael Suttie, J. Alison Noble
- **Comment**: MICCAI-MLMI 2020
- **Journal**: None
- **Summary**: Recently, there is an increasing demand for automatically detecting anatomical landmarks which provide rich structural information to facilitate subsequent medical image analysis. Current methods related to this task often leverage the power of deep neural networks, while a major challenge in fine tuning such models in medical applications arises from insufficient number of labeled samples. To address this, we propose to regularize the knowledge transfer across source and target tasks through cross-task representation learning. The proposed method is demonstrated for extracting facial anatomical landmarks which facilitate the diagnosis of fetal alcohol syndrome. The source and target tasks in this work are face recognition and landmark detection, respectively. The main idea of the proposed method is to retain the feature representations of the source model on the target task data, and to leverage them as an additional source of supervisory signals for regularizing the target model learning, thereby improving its performance under limited training samples. Concretely, we present two approaches for the proposed representation learning by constraining either final or intermediate model features on the target model. Experimental results on a clinical face image dataset demonstrate that the proposed approach works well with few labeled data, and outperforms other compared approaches.



### Conditional GAN for Prediction of Glaucoma Progression with Macular Optical Coherence Tomography
- **Arxiv ID**: http://arxiv.org/abs/2010.04552v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.04552v1)
- **Published**: 2020-09-28 22:24:46+00:00
- **Updated**: 2020-09-28 22:24:46+00:00
- **Authors**: Osama N. Hassan, Serhat Sahin, Vahid Mohammadzadeh, Xiaohe Yang, Navid Amini, Apoorva Mylavarapu, Jack Martinyan, Tae Hong, Golnoush Mahmoudinezhad, Daniel Rueckert, Kouros Nouri-Mahdavi, Fabien Scalzo
- **Comment**: None
- **Journal**: None
- **Summary**: The estimation of glaucoma progression is a challenging task as the rate of disease progression varies among individuals in addition to other factors such as measurement variability and the lack of standardization in defining progression. Structural tests, such as thickness measurements of the retinal nerve fiber layer or the macula with optical coherence tomography (OCT), are able to detect anatomical changes in glaucomatous eyes. Such changes may be observed before any functional damage. In this work, we built a generative deep learning model using the conditional GAN architecture to predict glaucoma progression over time. The patient's OCT scan is predicted from three or two prior measurements. The predicted images demonstrate high similarity with the ground truth images. In addition, our results suggest that OCT scans obtained from only two prior visits may actually be sufficient to predict the next OCT scan of the patient after six months.



### Breaking the Memory Wall for AI Chip with a New Dimension
- **Arxiv ID**: http://arxiv.org/abs/2009.13664v1
- **DOI**: None
- **Categories**: **cs.AR**, cs.AI, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.13664v1)
- **Published**: 2020-09-28 22:34:10+00:00
- **Updated**: 2020-09-28 22:34:10+00:00
- **Authors**: Eugene Tam, Shenfei Jiang, Paul Duan, Shawn Meng, Yue Pang, Cayden Huang, Yi Han, Jacke Xie, Yuanjun Cui, Jinsong Yu, Minggui Lu
- **Comment**: None
- **Journal**: None
- **Summary**: Recent advancements in deep learning have led to the widespread adoption of artificial intelligence (AI) in applications such as computer vision and natural language processing. As neural networks become deeper and larger, AI modeling demands outstrip the capabilities of conventional chip architectures. Memory bandwidth falls behind processing power. Energy consumption comes to dominate the total cost of ownership. Currently, memory capacity is insufficient to support the most advanced NLP models. In this work, we present a 3D AI chip, called Sunrise, with near-memory computing architecture to address these three challenges. This distributed, near-memory computing architecture allows us to tear down the performance-limiting memory wall with an abundance of data bandwidth. We achieve the same level of energy efficiency on 40nm technology as competing chips on 7nm technology. By moving to similar technologies as other AI chips, we project to achieve more than ten times the energy efficiency, seven times the performance of the current state-of-the-art chips, and twenty times of memory capacity as compared with the best chip in each benchmark.



### VIVO: Visual Vocabulary Pre-Training for Novel Object Captioning
- **Arxiv ID**: http://arxiv.org/abs/2009.13682v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.13682v2)
- **Published**: 2020-09-28 23:20:02+00:00
- **Updated**: 2021-03-04 20:01:10+00:00
- **Authors**: Xiaowei Hu, Xi Yin, Kevin Lin, Lijuan Wang, Lei Zhang, Jianfeng Gao, Zicheng Liu
- **Comment**: AAAI 2021
- **Journal**: None
- **Summary**: It is highly desirable yet challenging to generate image captions that can describe novel objects which are unseen in caption-labeled training data, a capability that is evaluated in the novel object captioning challenge (nocaps). In this challenge, no additional image-caption training data, other thanCOCO Captions, is allowed for model training. Thus, conventional Vision-Language Pre-training (VLP) methods cannot be applied. This paper presents VIsual VOcabulary pretraining (VIVO) that performs pre-training in the absence of caption annotations. By breaking the dependency of paired image-caption training data in VLP, VIVO can leverage large amounts of paired image-tag data to learn a visual vocabulary. This is done by pre-training a multi-layer Transformer model that learns to align image-level tags with their corresponding image region features. To address the unordered nature of image tags, VIVO uses a Hungarian matching loss with masked tag prediction to conduct pre-training. We validate the effectiveness of VIVO by fine-tuning the pre-trained model for image captioning. In addition, we perform an analysis of the visual-text alignment inferred by our model. The results show that our model can not only generate fluent image captions that describe novel objects, but also identify the locations of these objects. Our single model has achieved new state-of-the-art results on nocaps and surpassed the human CIDEr score.



### Detecting soccer balls with reduced neural networks: a comparison of multiple architectures under constrained hardware scenarios
- **Arxiv ID**: http://arxiv.org/abs/2009.13684v2
- **DOI**: 10.1007/s10846-021-01336-y
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.13684v2)
- **Published**: 2020-09-28 23:26:25+00:00
- **Updated**: 2021-02-21 12:15:09+00:00
- **Authors**: Douglas De Rizzo Meneghetti, Thiago Pedro Donadon Homem, Jonas Henrique Renolfi de Oliveira, Isaac Jesus da Silva, Danilo Hernani Perico, Reinaldo Augusto da Costa Bianchi
- **Comment**: 11-page version of a ~24-page version published in the Journal of
  Intelligent & Robotics Systems
- **Journal**: None
- **Summary**: Object detection techniques that achieve state-of-the-art detection accuracy employ convolutional neural networks, implemented to have optimal performance in graphics processing units. Some hardware systems, such as mobile robots, operate under constrained hardware situations, but still benefit from object detection capabilities. Multiple network models have been proposed, achieving comparable accuracy with reduced architectures and leaner operations. Motivated by the need to create an object detection system for a soccer team of mobile robots, this work provides a comparative study of recent proposals of neural networks targeted towards constrained hardware environments, in the specific task of soccer ball detection. We train multiple open implementations of MobileNetV2 and MobileNetV3 models with different underlying architectures, as well as YOLOv3, TinyYOLOv3, YOLOv4 and TinyYOLOv4 in an annotated image data set captured using a mobile robot. We then report their mean average precision on a test data set and their inference times in videos of different resolutions, under constrained and unconstrained hardware configurations. Results show that MobileNetV3 models have a good trade-off between mAP and inference time in constrained scenarios only, while MobileNetV2 with high width multipliers are appropriate for server-side inference. YOLO models in their official implementations are not suitable for inference in CPUs.



