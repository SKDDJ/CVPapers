# Arxiv Papers in cs.CV on 2020-09-09
### Unconstrained Text Detection in Manga: a New Dataset and Baseline
- **Arxiv ID**: http://arxiv.org/abs/2009.04042v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04042v1)
- **Published**: 2020-09-09 00:16:51+00:00
- **Updated**: 2020-09-09 00:16:51+00:00
- **Authors**: Juli√°n Del Gobbo, Rosana Matuk Herrera
- **Comment**: None
- **Journal**: None
- **Summary**: The detection and recognition of unconstrained text is an open problem in research. Text in comic books has unusual styles that raise many challenges for text detection. This work aims to binarize text in a comic genre with highly sophisticated text styles: Japanese manga. To overcome the lack of a manga dataset with text annotations at a pixel level, we create our own. To improve the evaluation and search of an optimal model, in addition to standard metrics in binarization, we implement other special metrics. Using these resources, we designed and evaluated a deep network model, outperforming current methods for text binarization in manga in most metrics.



### Improved Trainable Calibration Method for Neural Networks on Medical Imaging Classification
- **Arxiv ID**: http://arxiv.org/abs/2009.04057v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04057v1)
- **Published**: 2020-09-09 01:25:53+00:00
- **Updated**: 2020-09-09 01:25:53+00:00
- **Authors**: Gongbo Liang, Yu Zhang, Xiaoqin Wang, Nathan Jacobs
- **Comment**: Accepted to the 31th British Machine Vision Conference (BMVC 2020)
- **Journal**: None
- **Summary**: Recent works have shown that deep neural networks can achieve super-human performance in a wide range of image classification tasks in the medical imaging domain. However, these works have primarily focused on classification accuracy, ignoring the important role of uncertainty quantification. Empirically, neural networks are often miscalibrated and overconfident in their predictions. This miscalibration could be problematic in any automatic decision-making system, but we focus on the medical field in which neural network miscalibration has the potential to lead to significant treatment errors. We propose a novel calibration approach that maintains the overall classification accuracy while significantly improving model calibration. The proposed approach is based on expected calibration error, which is a common metric for quantifying miscalibration. Our approach can be easily integrated into any classification task as an auxiliary loss term, thus not requiring an explicit training round for calibration. We show that our approach reduces calibration error significantly across various architectures and datasets.



### View-consistent 4D Light Field Depth Estimation
- **Arxiv ID**: http://arxiv.org/abs/2009.04065v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04065v1)
- **Published**: 2020-09-09 01:47:34+00:00
- **Updated**: 2020-09-09 01:47:34+00:00
- **Authors**: Numair Khan, Min H. Kim, James Tompkin
- **Comment**: BMVC 2020
- **Journal**: None
- **Summary**: We propose a method to compute depth maps for every sub-aperture image in a light field in a view consistent way. Previous light field depth estimation methods typically estimate a depth map only for the central sub-aperture view, and struggle with view consistent estimation. Our method precisely defines depth edges via EPIs, then we diffuse these edges spatially within the central view. These depth estimates are then propagated to all other views in an occlusion-aware way. Finally, disoccluded regions are completed by diffusion in EPI space. Our method runs efficiently with respect to both other classical and deep learning-based approaches, and achieves competitive quantitative metrics and qualitative performance on both synthetic and real-world light fields



### Is Each Layer Non-trivial in CNN?
- **Arxiv ID**: http://arxiv.org/abs/2009.09938v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.09938v2)
- **Published**: 2020-09-09 02:17:49+00:00
- **Updated**: 2020-12-03 02:23:09+00:00
- **Authors**: Wei Wang, Yanjie Zhu, Zhuoxu Cui, Dong Liang
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural network (CNN) models have achieved great success in many fields. With the advent of ResNet, networks used in practice are getting deeper and wider. However, is each layer non-trivial in networks? To answer this question, we trained a network on the training set, then we replace the network convolution kernels with zeros and test the result models on the test set. We compared experimental results with baseline and showed that we can reach similar or even the same performances. Although convolution kernels are the cores of networks, we demonstrate that some of them are trivial and regular in ResNet.



### Generalizing Complex/Hyper-complex Convolutions to Vector Map Convolutions
- **Arxiv ID**: http://arxiv.org/abs/2009.04083v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04083v1)
- **Published**: 2020-09-09 03:00:03+00:00
- **Updated**: 2020-09-09 03:00:03+00:00
- **Authors**: Chase J Gaudet, Anthony S Maida
- **Comment**: None
- **Journal**: None
- **Summary**: We show that the core reasons that complex and hypercomplex valued neural networks offer improvements over their real-valued counterparts is the weight sharing mechanism and treating multidimensional data as a single entity. Their algebra linearly combines the dimensions, making each dimension related to the others. However, both are constrained to a set number of dimensions, two for complex and four for quaternions. Here we introduce novel vector map convolutions which capture both of these properties provided by complex/hypercomplex convolutions, while dropping the unnatural dimensionality constraints they impose. This is achieved by introducing a system that mimics the unique linear combination of input dimensions, such as the Hamilton product for quaternions. We perform three experiments to show that these novel vector map convolutions seem to capture all the benefits of complex and hyper-complex networks, such as their ability to capture internal latent relations, while avoiding the dimensionality restriction.



### Deep Metric Learning Meets Deep Clustering: An Novel Unsupervised Approach for Feature Embedding
- **Arxiv ID**: http://arxiv.org/abs/2009.04091v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04091v1)
- **Published**: 2020-09-09 04:02:04+00:00
- **Updated**: 2020-09-09 04:02:04+00:00
- **Authors**: Binh X. Nguyen, Binh D. Nguyen, Gustavo Carneiro, Erman Tjiputra, Quang D. Tran, Thanh-Toan Do
- **Comment**: Accepted in BMVC 2020
- **Journal**: None
- **Summary**: Unsupervised Deep Distance Metric Learning (UDML) aims to learn sample similarities in the embedding space from an unlabeled dataset. Traditional UDML methods usually use the triplet loss or pairwise loss which requires the mining of positive and negative samples w.r.t. anchor data points. This is, however, challenging in an unsupervised setting as the label information is not available. In this paper, we propose a new UDML method that overcomes that challenge. In particular, we propose to use a deep clustering loss to learn centroids, i.e., pseudo labels, that represent semantic classes. During learning, these centroids are also used to reconstruct the input samples. It hence ensures the representativeness of centroids - each centroid represents visually similar samples. Therefore, the centroids give information about positive (visually similar) and negative (visually dissimilar) samples. Based on pseudo labels, we propose a novel unsupervised metric loss which enforces the positive concentration and negative separation of samples in the embedding space. Experimental results on benchmarking datasets show that the proposed approach outperforms other UDML methods.



### Real-time Plant Health Assessment Via Implementing Cloud-based Scalable Transfer Learning On AWS DeepLens
- **Arxiv ID**: http://arxiv.org/abs/2009.04110v2
- **DOI**: 10.1371/journal.pone.0243243
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04110v2)
- **Published**: 2020-09-09 05:23:34+00:00
- **Updated**: 2020-09-10 16:58:20+00:00
- **Authors**: Asim Khan, Umair Nawaz, Anwaar Ulhaq, Randall W. Robinson
- **Comment**: 10 Pages, 12 Figures and 6 Tables
- **Journal**: None
- **Summary**: In the Agriculture sector, control of plant leaf diseases is crucial as it influences the quality and production of plant species with an impact on the economy of any country. Therefore, automated identification and classification of plant leaf disease at an early stage is essential to reduce economic loss and to conserve the specific species. Previously, to detect and classify plant leaf disease, various Machine Learning models have been proposed; however, they lack usability due to hardware incompatibility, limited scalability and inefficiency in practical usage. Our proposed DeepLens Classification and Detection Model (DCDM) approach deal with such limitations by introducing automated detection and classification of the leaf diseases in fruits (apple, grapes, peach and strawberry) and vegetables (potato and tomato) via scalable transfer learning on AWS SageMaker and importing it on AWS DeepLens for real-time practical usability. Cloud integration provides scalability and ubiquitous access to our approach. Our experiments on extensive image data set of healthy and unhealthy leaves of fruits and vegetables showed an accuracy of 98.78% with a real-time diagnosis of plant leaves diseases. We used forty thousand images for the training of deep learning model and then evaluated it on ten thousand images. The process of testing an image for disease diagnosis and classification using AWS DeepLens on average took 0.349s, providing disease information to the user in less than a second.



### Single Image Super-Resolution for Domain-Specific Ultra-Low Bandwidth Image Transmission
- **Arxiv ID**: http://arxiv.org/abs/2009.04127v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2009.04127v2)
- **Published**: 2020-09-09 06:44:30+00:00
- **Updated**: 2020-09-22 06:27:21+00:00
- **Authors**: Jesper Haahr Christensen, Lars Valdemar Mogensen, Ole Ravn
- **Comment**: None
- **Journal**: None
- **Summary**: Low-bandwidth communication, such as underwater acoustic communication, is limited by best-case data rates of 30--50 kbit/s. This renders such channels unusable or inefficient at best for single image, video, or other bandwidth-demanding sensor-data transmission. To combat data-transmission bottlenecks, we consider practical use-cases within the maritime domain and investigate the prospect of Single Image Super-Resolution methodologies. This is investigated on a large, diverse dataset obtained during years of trawl fishing where cameras have been placed in the fishing nets. We propose down-sampling images to a low-resolution low-size version of about 1 kB that satisfies underwater acoustic bandwidth requirements for even several frames per second. A neural network is then trained to perform up-sampling, trying to reconstruct the original image. We aim to investigate the quality of reconstructed images and prospects for such methods in practical use-cases in general. Our focus in this work is solely on learning to reconstruct the high-resolution images on "real-world" data. We show that our method achieves better perceptual quality and superior reconstruction than generic bicubic up-sampling and motivates further work in this area for underwater applications.



### One-shot Text Field Labeling using Attention and Belief Propagation for Structure Information Extraction
- **Arxiv ID**: http://arxiv.org/abs/2009.04153v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.04153v1)
- **Published**: 2020-09-09 08:11:34+00:00
- **Updated**: 2020-09-09 08:11:34+00:00
- **Authors**: Mengli Cheng, Minghui Qiu, Xing Shi, Jun Huang, Wei Lin
- **Comment**: 9 pages
- **Journal**: ACMMM 2020
- **Summary**: Structured information extraction from document images usually consists of three steps: text detection, text recognition, and text field labeling. While text detection and text recognition have been heavily studied and improved a lot in literature, text field labeling is less explored and still faces many challenges. Existing learning based methods for text labeling task usually require a large amount of labeled examples to train a specific model for each type of document. However, collecting large amounts of document images and labeling them is difficult and sometimes impossible due to privacy issues. Deploying separate models for each type of document also consumes a lot of resources. Facing these challenges, we explore one-shot learning for the text field labeling task. Existing one-shot learning methods for the task are mostly rule-based and have difficulty in labeling fields in crowded regions with few landmarks and fields consisting of multiple separate text regions. To alleviate these problems, we proposed a novel deep end-to-end trainable approach for one-shot text field labeling, which makes use of attention mechanism to transfer the layout information between document images. We further applied conditional random field on the transferred layout information for the refinement of field labeling. We collected and annotated a real-world one-shot field labeling dataset with a large variety of document types and conducted extensive experiments to examine the effectiveness of the proposed model. To stimulate research in this direction, the collected dataset and the one-shot model will be released1.



### Revealing Lung Affections from CTs. A Comparative Analysis of Various Deep Learning Approaches for Dealing with Volumetric Data
- **Arxiv ID**: http://arxiv.org/abs/2009.04160v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2009.04160v1)
- **Published**: 2020-09-09 08:34:18+00:00
- **Updated**: 2020-09-09 08:34:18+00:00
- **Authors**: Radu Miron, Cosmin Moisii, Mihaela Breaban
- **Comment**: ImageClef2020 Tuberculosis task
- **Journal**: Working Notes of CLEF 2020 - Conference and Labs of the Evaluation
  Forum Thessaloniki, Greece, September22-25, 2020
- **Summary**: The paper presents and comparatively analyses several deep learning approaches to automatically detect tuberculosis related lesions in lung CTs, in the context of the ImageClef 2020 Tuberculosis task. Three classes of methods, different with respect to the way the volumetric data is given as input to neural network-based classifiers are discussed and evaluated. All these come with a rich experimental analysis comprising a variety of neural network architectures, various segmentation algorithms and data augmentation schemes. The reported work belongs to the SenticLab.UAIC team, which obtained the best results in the competition.



### Diversified Mutual Learning for Deep Metric Learning
- **Arxiv ID**: http://arxiv.org/abs/2009.04170v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04170v1)
- **Published**: 2020-09-09 09:00:16+00:00
- **Updated**: 2020-09-09 09:00:16+00:00
- **Authors**: Wonpyo Park, Wonjae Kim, Kihyun You, Minsu Cho
- **Comment**: Accepted to ECCV Workshop 2020
- **Journal**: None
- **Summary**: Mutual learning is an ensemble training strategy to improve generalization by transferring individual knowledge to each other while simultaneously training multiple models. In this work, we propose an effective mutual learning method for deep metric learning, called Diversified Mutual Metric Learning, which enhances embedding models with diversified mutual learning. We transfer relational knowledge for deep metric learning by leveraging three kinds of diversities in mutual learning: (1) model diversity from different initializations of models, (2) temporal diversity from different frequencies of parameter update, and (3) view diversity from different augmentations of inputs. Our method is particularly adequate for inductive transfer learning at the lack of large-scale data, where the embedding model is initialized with a pretrained model and then fine-tuned on a target dataset. Extensive experiments show that our method significantly improves individual models as well as their ensemble. Finally, the proposed method with a conventional triplet loss achieves the state-of-the-art performance of Recall@1 on standard datasets: 69.9 on CUB-200-2011 and 89.1 on CARS-196.



### Relative Attribute Classification with Deep Rank SVM
- **Arxiv ID**: http://arxiv.org/abs/2009.07717v1
- **DOI**: 10.1007/978-3-030-68790-8_51
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.07717v1)
- **Published**: 2020-09-09 09:21:39+00:00
- **Updated**: 2020-09-09 09:21:39+00:00
- **Authors**: Sara Atito Ali Ahmed, Berrin Yanikoglu
- **Comment**: None
- **Journal**: None
- **Summary**: Relative attributes indicate the strength of a particular attribute between image pairs. We introduce a deep Siamese network with rank SVM loss function, called Deep Rank SVM (DRSVM), in order to decide which one of a pair of images has a stronger presence of a specific attribute. The network is trained in an end-to-end fashion to jointly learn the visual features and the ranking function. We demonstrate the effectiveness of our approach against the state-of-the-art methods on four image benchmark datasets: LFW-10, PubFig, UTZap50K-lexi and UTZap50K-2 datasets. DRSVM surpasses state-of-art in terms of the average accuracy across attributes, on three of the four image benchmark datasets.



### MU-GAN: Facial Attribute Editing based on Multi-attention Mechanism
- **Arxiv ID**: http://arxiv.org/abs/2009.04177v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2009.04177v1)
- **Published**: 2020-09-09 09:25:04+00:00
- **Updated**: 2020-09-09 09:25:04+00:00
- **Authors**: Ke Zhang, Yukun Su, Xiwang Guo, Liang Qi, Zhenbing Zhao
- **Comment**: 12 pages, 10 figures
- **Journal**: None
- **Summary**: Facial attribute editing has mainly two objectives: 1) translating image from a source domain to a target one, and 2) only changing the facial regions related to a target attribute and preserving the attribute-excluding details. In this work, we propose a Multi-attention U-Net-based Generative Adversarial Network (MU-GAN). First, we replace a classic convolutional encoder-decoder with a symmetric U-Net-like structure in a generator, and then apply an additive attention mechanism to build attention-based U-Net connections for adaptively transferring encoder representations to complement a decoder with attribute-excluding detail and enhance attribute editing ability. Second, a self-attention mechanism is incorporated into convolutional layers for modeling long-range and multi-level dependencies across image regions. experimental results indicate that our method is capable of balancing attribute editing ability and details preservation ability, and can decouple the correlation among attributes. It outperforms the state-of-the-art methods in terms of attribute manipulation accuracy and image quality.



### Temporal Attribute-Appearance Learning Network for Video-based Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2009.04181v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04181v1)
- **Published**: 2020-09-09 09:28:07+00:00
- **Updated**: 2020-09-09 09:28:07+00:00
- **Authors**: Jiawei Liu, Xierong Zhu, Zheng-Jun Zha
- **Comment**: None
- **Journal**: None
- **Summary**: Video-based person re-identification aims to match a specific pedestrian in surveillance videos across different time and locations. Human attributes and appearance are complementary to each other, both of them contribute to pedestrian matching. In this work, we propose a novel Temporal Attribute-Appearance Learning Network (TALNet) for video-based person re-identification. TALNet simultaneously exploits human attributes and appearance to learn comprehensive and effective pedestrian representations from videos. It explores hard visual attention and temporal-semantic context for attributes, and spatial-temporal dependencies among body parts for appearance, to boost the learning of them. Specifically, an attribute branch network is proposed with a spatial attention block and a temporal-semantic context block for learning robust attribute representation. The spatial attention block focuses the network on corresponding regions within video frames related to each attribute, the temporal-semantic context block learns both the temporal context for each attribute across video frames and the semantic context among attributes in each video frame. The appearance branch network is designed to learn effective appearance representation from both whole body and body parts with spatial-temporal dependencies among them. TALNet leverages the complementation between attribute and appearance representations, and jointly optimizes them by multi-task learning fashion. Moreover, we annotate ID-level attributes for each pedestrian in the two commonly used video datasets. Extensive experiments on these datasets, have verified the superiority of TALNet over state-of-the-art methods.



### Small-floating Target Detection in Sea Clutter via Visual Feature Classifying in the Time-Doppler Spectra
- **Arxiv ID**: http://arxiv.org/abs/2009.04185v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04185v1)
- **Published**: 2020-09-09 09:35:03+00:00
- **Updated**: 2020-09-09 09:35:03+00:00
- **Authors**: Yi Zhou, Yin Cui, Xiaoke Xu, Jidong Suo, Xiaoming Liu
- **Comment**: None
- **Journal**: None
- **Summary**: It is challenging to detect small-floating object in the sea clutter for a surface radar. In this paper, we have observed that the backscatters from the target brake the continuity of the underlying motion of the sea surface in the time-Doppler spectra (TDS) images. Following this visual clue, we exploit the local binary pattern (LBP) to measure the variations of texture in the TDS images. It is shown that the radar returns containing target and those only having clutter are separable in the feature space of LBP. An unsupervised one-class support vector machine (SVM) is then utilized to detect the deviation of the LBP histogram of the clutter. The outiler of the detector is classified as the target. In the real-life IPIX radar data sets, our visual feature based detector shows favorable detection rate compared to other three existing approaches.



### Semi-Supervised Active Learning for COVID-19 Lung Ultrasound Multi-symptom Classification
- **Arxiv ID**: http://arxiv.org/abs/2009.05436v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.05436v2)
- **Published**: 2020-09-09 10:45:34+00:00
- **Updated**: 2021-02-28 08:47:52+00:00
- **Authors**: Lei Liu, Wentao Lei, Yongfang Luo, Cheng Feng, Xiang Wan, Li Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Ultrasound (US) is a non-invasive yet effective medical diagnostic imaging technique for the COVID-19 global pandemic. However, due to complex feature behaviors and expensive annotations of US images, it is difficult to apply Artificial Intelligence (AI) assisting approaches for lung's multi-symptom (multi-label) classification. To overcome these difficulties, we propose a novel semi-supervised Two-Stream Active Learning (TSAL) method to model complicated features and reduce labeling costs in an iterative procedure. The core component of TSAL is the multi-label learning mechanism, in which label correlations information is used to design multi-label margin (MLM) strategy and confidence validation for automatically selecting informative samples and confident labels. On this basis, a multi-symptom multi-label (MSML) classification network is proposed to learn discriminative features of lung symptoms, and a human-machine interaction is exploited to confirm the final annotations that are used to fine-tune MSML with progressively labeled data. Moreover, a novel lung US dataset named COVID19-LUSMS is built, currently containing 71 clinical patients with 6,836 images sampled from 678 videos. Experimental evaluations show that TSAL using only 20% data can achieve superior performance to the baseline and the state-of-the-art. Qualitatively, visualization of both attention map and sample distribution confirms the good consistency with the clinic knowledge.



### ODIN: Automated Drift Detection and Recovery in Video Analytics
- **Arxiv ID**: http://arxiv.org/abs/2009.05440v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.SY, eess.SY
- **Links**: [PDF](http://arxiv.org/pdf/2009.05440v1)
- **Published**: 2020-09-09 12:13:40+00:00
- **Updated**: 2020-09-09 12:13:40+00:00
- **Authors**: Abhijit Suprem, Joy Arulraj, Calton Pu, Joao Ferreira
- **Comment**: None
- **Journal**: PVLDB, 13(11):2453-2465, 2020
- **Summary**: Recent advances in computer vision have led to a resurgence of interest in visual data analytics. Researchers are developing systems for effectively and efficiently analyzing visual data at scale. A significant challenge that these systems encounter lies in the drift in real-world visual data. For instance, a model for self-driving vehicles that is not trained on images containing snow does not work well when it encounters them in practice. This drift phenomenon limits the accuracy of models employed for visual data analytics. In this paper, we present a visual data analytics system, called ODIN, that automatically detects and recovers from drift. ODIN uses adversarial autoencoders to learn the distribution of high-dimensional images. We present an unsupervised algorithm for detecting drift by comparing the distributions of the given data against that of previously seen data. When ODIN detects drift, it invokes a drift recovery algorithm to deploy specialized models tailored towards the novel data points. These specialized models outperform their non-specialized counterpart on accuracy, performance, and memory footprint. Lastly, we present a model selection algorithm for picking an ensemble of best-fit specialized models to process a given input. We evaluate the efficacy and efficiency of ODIN on high-resolution dashboard camera videos captured under diverse environments from the Berkeley DeepDrive dataset. We demonstrate that ODIN's models deliver 6x higher throughput, 2x higher accuracy, and 6x smaller memory footprint compared to a baseline system without automated drift detection and recovery.



### Unsupervised Part Discovery by Unsupervised Disentanglement
- **Arxiv ID**: http://arxiv.org/abs/2009.04264v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04264v2)
- **Published**: 2020-09-09 12:34:37+00:00
- **Updated**: 2020-09-10 09:31:48+00:00
- **Authors**: Sandro Braun, Patrick Esser, Bj√∂rn Ommer
- **Comment**: GCPR 2020 (Oral)
- **Journal**: None
- **Summary**: We address the problem of discovering part segmentations of articulated objects without supervision. In contrast to keypoints, part segmentations provide information about part localizations on the level of individual pixels. Capturing both locations and semantics, they are an attractive target for supervised learning approaches. However, large annotation costs limit the scalability of supervised algorithms to other object categories than humans. Unsupervised approaches potentially allow to use much more data at a lower cost. Most existing unsupervised approaches focus on learning abstract representations to be refined with supervision into the final representation. Our approach leverages a generative model consisting of two disentangled representations for an object's shape and appearance and a latent variable for the part segmentation. From a single image, the trained model infers a semantic part segmentation map. In experiments, we compare our approach to previous state-of-the-art approaches and observe significant gains in segmentation accuracy and shape consistency. Our work demonstrates the feasibility to discover semantic part segmentations without supervision.



### Online trajectory recovery from offline handwritten Japanese kanji characters
- **Arxiv ID**: http://arxiv.org/abs/2009.04284v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2009.04284v1)
- **Published**: 2020-09-09 13:05:50+00:00
- **Updated**: 2020-09-09 13:05:50+00:00
- **Authors**: Hung Tuan Nguyen, Tsubasa Nakamura, Cuong Tuan Nguyen, Masaki Nakagawa
- **Comment**: 9 pages, ICPR2020 (reviewing)
- **Journal**: None
- **Summary**: In general, it is straightforward to render an offline handwriting image from an online handwriting pattern. However, it is challenging to reconstruct an online handwriting pattern given an offline handwriting image, especially for multiple-stroke character as Japanese kanji. The multiple-stroke character requires not only point coordinates but also stroke orders whose difficulty is exponential growth by the number of strokes. Besides, several crossed and touch points might increase the difficulty of the recovered task. We propose a deep neural network-based method to solve the recovered task using a large online handwriting database. Our proposed model has two main components: Convolutional Neural Network-based encoder and Long Short-Term Memory Network-based decoder with an attention layer. The encoder focuses on feature extraction while the decoder refers to the extracted features and generates the time-sequences of coordinates. We also demonstrate the effect of the attention layer to guide the decoder during the reconstruction. We evaluate the performance of the proposed method by both visual verification and handwritten character recognition. Although the visual verification reveals some problems, the recognition experiments demonstrate the effect of trajectory recovery in improving the accuracy of offline handwritten character recognition when online recognition for the recovered trajectories are combined.



### Enhancing and Learning Denoiser without Clean Reference
- **Arxiv ID**: http://arxiv.org/abs/2009.04286v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04286v2)
- **Published**: 2020-09-09 13:15:31+00:00
- **Updated**: 2021-03-28 13:13:17+00:00
- **Authors**: Rui Zhao, Daniel P. K. Lun, Kin-Man Lam
- **Comment**: None
- **Journal**: None
- **Summary**: Recent studies on learning-based image denoising have achieved promising performance on various noise reduction tasks. Most of these deep denoisers are trained either under the supervision of clean references, or unsupervised on synthetic noise. The assumption with the synthetic noise leads to poor generalization when facing real photographs. To address this issue, we propose a novel deep image-denoising method by regarding the noise reduction task as a special case of the noise transference task. Learning noise transference enables the network to acquire the denoising ability by observing the corrupted samples. The results on real-world denoising benchmarks demonstrate that our proposed method achieves promising performance on removing realistic noises, making it a potential solution to practical noise reduction problems.



### HSFM-$Œ£$nn: Combining a Feedforward Motion Prediction Network and Covariance Prediction
- **Arxiv ID**: http://arxiv.org/abs/2009.04299v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2009.04299v1)
- **Published**: 2020-09-09 13:46:35+00:00
- **Updated**: 2020-09-09 13:46:35+00:00
- **Authors**: A. Postnikov, A. Gamayunov, G. Ferrer
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new method for motion prediction: HSFM-$\Sigma$nn. Our proposed method combines two different approaches: a feedforward network whose layers are model-based transition functions using the HSFM and a Neural Network (NN), on each of these layers, for covariance prediction. We will compare our method with classical methods for covariance estimation showing their limitations. We will also compare with a learning-based approach, social-LSTM, showing that our method is more precise and efficient.



### Plant Diseases recognition on images using Convolutional Neural Networks: A Systematic Review
- **Arxiv ID**: http://arxiv.org/abs/2009.04365v1
- **DOI**: None
- **Categories**: **cs.CV**, 65D19, I.4.9
- **Links**: [PDF](http://arxiv.org/pdf/2009.04365v1)
- **Published**: 2020-09-09 15:36:04+00:00
- **Updated**: 2020-09-09 15:36:04+00:00
- **Authors**: Andre S. Abade, Paulo Afonso Ferreira, Flavio de Barros Vidal
- **Comment**: 47 pages, 11 figures
- **Journal**: None
- **Summary**: Plant diseases are considered one of the main factors influencing food production and minimize losses in production, and it is essential that crop diseases have fast detection and recognition. The recent expansion of deep learning methods has found its application in plant disease detection, offering a robust tool with highly accurate results. In this context, this work presents a systematic review of the literature that aims to identify the state of the art of the use of convolutional neural networks(CNN) in the process of identification and classification of plant diseases, delimiting trends, and indicating gaps. In this sense, we present 121 papers selected in the last ten years with different approaches to treat aspects related to disease detection, characteristics of the data set, the crops and pathogens investigated. From the results of the systematic review, it is possible to understand the innovative trends regarding the use of CNNs in the identification of plant diseases and to identify the gaps that need the attention of the research community.



### Cephalogram Synthesis and Landmark Detection in Dental Cone-Beam CT Systems
- **Arxiv ID**: http://arxiv.org/abs/2009.04420v2
- **DOI**: 10.1016/j.media.2021.102028
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04420v2)
- **Published**: 2020-09-09 17:06:54+00:00
- **Updated**: 2021-03-20 18:08:38+00:00
- **Authors**: Yixing Huang, Fuxin Fan, Christopher Syben, Philipp Roser, Leonid Mill, Andreas Maier
- **Comment**: None
- **Journal**: Medical Image Analysis 2021
- **Summary**: Due to the lack of standardized 3D cephalometric analytic methodology, 2D cephalograms synthesized from 3D cone-beam computed tomography (CBCT) volumes are widely used for cephalometric analysis in dental CBCT systems. However, compared with conventional X-ray film based cephalograms, such synthetic cephalograms lack image contrast and resolution. In addition, the radiation dose during the scan for 3D reconstruction causes potential health risks. In this work, we propose a sigmoid-based intensity transform that uses the nonlinear optical property of X-ray films to increase image contrast of synthetic cephalograms. To improve image resolution, super resolution deep learning techniques are investigated. For low dose purpose, the pixel-to-pixel generative adversarial network (pix2pixGAN) is proposed for 2D cephalogram synthesis directly from two CBCT projections. For landmark detection in the synthetic cephalograms, an efficient automatic landmark detection method using the combination of LeNet-5 and ResNet50 is proposed. Our experiments demonstrate the efficacy of pix2pixGAN in 2D cephalogram synthesis, achieving an average peak signal-to-noise ratio (PSNR) value of 33.8 with reference to the cephalograms synthesized from 3D CBCT volumes. Pix2pixGAN also achieves the best performance in super resolution, achieving an average PSNR value of 32.5 without the introduction of checkerboard or jagging artifacts. Our proposed automatic landmark detection method achieves 86.7% successful detection rate in the 2 mm clinical acceptable range on the ISBI Test1 data, which is comparable to the state-of-the-art methods. The method trained on conventional cephalograms can be directly applied to landmark detection in the synthetic cephalograms, achieving 93.0% and 80.7% successful detection rate in 4 mm precision range for synthetic cephalograms from 3D volumes and 2D projections respectively.



### not-so-BigGAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2009.04433v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.04433v2)
- **Published**: 2020-09-09 17:29:40+00:00
- **Updated**: 2020-10-25 18:41:09+00:00
- **Authors**: Seungwook Han, Akash Srivastava, Cole Hurwitz, Prasanna Sattigeri, David D. Cox
- **Comment**: None
- **Journal**: None
- **Summary**: State-of-the-art models for high-resolution image generation, such as BigGAN and VQVAE-2, require an incredible amount of compute resources and/or time (512 TPU-v3 cores) to train, putting them out of reach for the larger research community. On the other hand, GAN-based image super-resolution models, such as ESRGAN, can not only upscale images to high dimensions, but also are efficient to train. In this paper, we present not-so-big-GAN (nsb-GAN), a simple yet cost-effective two-step training framework for deep generative models (DGMs) of high-dimensional natural images. First, we generate images in low-frequency bands by training a sampler in the wavelet domain. Then, we super-resolve these images from the wavelet domain back to the pixel-space with our novel wavelet super-resolution decoder network. Wavelet-based down-sampling method preserves more structural information than pixel-based methods, leading to significantly better generative quality of the low-resolution sampler (e.g., 64x64). Since the sampler and decoder can be trained in parallel and operate on much lower dimensional spaces than end-to-end models, the training cost is substantially reduced. On ImageNet 512x512, our model achieves a Fr\'echet Inception Distance (FID) of 10.59 -- beating the baseline BigGAN model -- at half the compute (256 TPU-v3 cores).



### Semi-supervised Medical Image Segmentation through Dual-task Consistency
- **Arxiv ID**: http://arxiv.org/abs/2009.04448v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04448v3)
- **Published**: 2020-09-09 17:49:21+00:00
- **Updated**: 2023-05-06 06:36:37+00:00
- **Authors**: Xiangde Luo, Jieneng Chen, Tao Song, Yinan Chen, Guotai Wang, Shaoting Zhang
- **Comment**: AAAI2021; Code is available at https://github.com/HiLab-git/DTC
- **Journal**: None
- **Summary**: Deep learning-based semi-supervised learning (SSL) algorithms have led to promising results in medical images segmentation and can alleviate doctors' expensive annotations by leveraging unlabeled data. However, most of the existing SSL algorithms in literature tend to regularize the model training by perturbing networks and/or data. Observing that multi/dual-task learning attends to various levels of information which have inherent prediction perturbation, we ask the question in this work: can we explicitly build task-level regularization rather than implicitly constructing networks- and/or data-level perturbation-and-transformation for SSL? To answer this question, we propose a novel dual-task-consistency semi-supervised framework for the first time. Concretely, we use a dual-task deep network that jointly predicts a pixel-wise segmentation map and a geometry-aware level set representation of the target. The level set representation is converted to an approximated segmentation map through a differentiable task transform layer. Simultaneously, we introduce a dual-task consistency regularization between the level set-derived segmentation maps and directly predicted segmentation maps for both labeled and unlabeled data. Extensive experiments on two public datasets show that our method can largely improve the performance by incorporating the unlabeled data. Meanwhile, our framework outperforms the state-of-the-art semi-supervised medical image segmentation methods. Code is available at: https://github.com/Luoxd1996/DTC



### Map-Adaptive Goal-Based Trajectory Prediction
- **Arxiv ID**: http://arxiv.org/abs/2009.04450v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2009.04450v2)
- **Published**: 2020-09-09 17:57:01+00:00
- **Updated**: 2020-11-13 23:20:43+00:00
- **Authors**: Lingyao Zhang, Po-Hsun Su, Jerrick Hoang, Galen Clark Haynes, Micol Marchetti-Bowick
- **Comment**: Published at CoRL 2020
- **Journal**: Conference on Robot Learning (CoRL) 2020
- **Summary**: We present a new method for multi-modal, long-term vehicle trajectory prediction. Our approach relies on using lane centerlines captured in rich maps of the environment to generate a set of proposed goal paths for each vehicle. Using these paths -- which are generated at run time and therefore dynamically adapt to the scene -- as spatial anchors, we predict a set of goal-based trajectories along with a categorical distribution over the goals. This approach allows us to directly model the goal-directed behavior of traffic actors, which unlocks the potential for more accurate long-term prediction. Our experimental results on both a large-scale internal driving dataset and on the public nuScenes dataset show that our model outperforms state-of-the-art approaches for vehicle trajectory prediction over a 6-second horizon. We also empirically demonstrate that our model is better able to generalize to road scenes from a completely new city than existing methods.



### Segmentation-free Estimation of Aortic Diameters from MRI Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2009.04507v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04507v1)
- **Published**: 2020-09-09 18:28:00+00:00
- **Updated**: 2020-09-09 18:28:00+00:00
- **Authors**: Axel Aguerreberry, Ezequiel de la Rosa, Alain Lalande, Elmer Fernandez
- **Comment**: To be presented at the STACOM workshop at MICCAI 2020
- **Journal**: None
- **Summary**: Accurate and reproducible measurements of the aortic diameters are crucial for the diagnosis of cardiovascular diseases and for therapeutic decision making. Currently, these measurements are manually performed by healthcare professionals, being time consuming, highly variable, and suffering from lack of reproducibility. In this work we propose a supervised deep learning method for the direct estimation of aortic diameters. The approach is devised and tested over 100 magnetic resonance angiography scans without contrast agent. All data was expert-annotated at six aortic locations typically used in clinical practice. Our approach makes use of a 3D+2D convolutional neural network (CNN) that takes as input a 3D scan and outputs the aortic diameter at a given location. In a 5-fold cross-validation comparison against a fully 3D CNN and against a 3D multiresolution CNN, our approach was consistently superior in predicting the aortic diameters. Overall, the 3D+2D CNN achieved a mean absolute error between 2.2-2.4 mm depending on the considered aortic location. These errors are less than 1 mm higher than the inter-observer variability. Thus, suggesting that our method makes predictions almost reaching the expert's performance. We conclude that the work allows to further explore automatic algorithms for direct estimation of anatomical structures without the necessity of a segmentation step. It also opens possibilities for the automation of cardiovascular measurements in clinical settings.



### RoIFusion: 3D Object Detection from LiDAR and Vision
- **Arxiv ID**: http://arxiv.org/abs/2009.04554v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2009.04554v1)
- **Published**: 2020-09-09 20:23:27+00:00
- **Updated**: 2020-09-09 20:23:27+00:00
- **Authors**: Can Chen, Luca Zanotti Fragonara, Antonios Tsourdos
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: When localizing and detecting 3D objects for autonomous driving scenes, obtaining information from multiple sensor (e.g. camera, LIDAR) typically increases the robustness of 3D detectors. However, the efficient and effective fusion of different features captured from LIDAR and camera is still challenging, especially due to the sparsity and irregularity of point cloud distributions. This notwithstanding, point clouds offer useful complementary information. In this paper, we would like to leverage the advantages of LIDAR and camera sensors by proposing a deep neural network architecture for the fusion and the efficient detection of 3D objects by identifying their corresponding 3D bounding boxes with orientation. In order to achieve this task, instead of densely combining the point-wise feature of the point cloud and the related pixel features, we propose a novel fusion algorithm by projecting a set of 3D Region of Interests (RoIs) from the point clouds to the 2D RoIs of the corresponding the images. Finally, we demonstrate that our deep fusion approach achieves state-of-the-art performance on the KITTI 3D object detection challenging benchmark.



### Applying a random projection algorithm to optimize machine learning model for breast lesion classification
- **Arxiv ID**: http://arxiv.org/abs/2009.09937v1
- **DOI**: 10.1109/TBME.2021.3054248
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2009.09937v1)
- **Published**: 2020-09-09 21:27:27+00:00
- **Updated**: 2020-09-09 21:27:27+00:00
- **Authors**: Morteza Heidari, Sivaramakrishnan Lakshmivarahan, Seyedehnafiseh Mirniaharikandehei, Gopichandh Danala, Sai Kiran R. Maryada, Hong Liu, Bin Zheng
- **Comment**: 11 pages, 6 figures
- **Journal**: IEEE Transactions on Biomedical Engineering, 2021
- **Summary**: Machine learning is widely used in developing computer-aided diagnosis (CAD) schemes of medical images. However, CAD usually computes large number of image features from the targeted regions, which creates a challenge of how to identify a small and optimal feature vector to build robust machine learning models. In this study, we investigate feasibility of applying a random projection algorithm to build an optimal feature vector from the initially CAD-generated large feature pool and improve performance of machine learning model. We assemble a retrospective dataset involving 1,487 cases of mammograms in which 644 cases have confirmed malignant mass lesions and 843 have benign lesions. A CAD scheme is first applied to segment mass regions and initially compute 181 features. Then, support vector machine (SVM) models embedded with several feature dimensionality reduction methods are built to predict likelihood of lesions being malignant. All SVM models are trained and tested using a leave-one-case-out cross-validation method. SVM generates a likelihood score of each segmented mass region depicting on one-view mammogram. By fusion of two scores of the same mass depicting on two-view mammograms, a case-based likelihood score is also evaluated. Comparing with the principle component analyses, nonnegative matrix factorization, and Chi-squared methods, SVM embedded with the random projection algorithm yielded a significantly higher case-based lesion classification performance with the area under ROC curve of 0.84+0.01 (p<0.02). The study demonstrates that the random project algorithm is a promising method to generate optimal feature vectors to help improve performance of machine learning models of medical images.



### Blind Image Restoration with Flow Based Priors
- **Arxiv ID**: http://arxiv.org/abs/2009.04583v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2009.04583v1)
- **Published**: 2020-09-09 21:40:11+00:00
- **Updated**: 2020-09-09 21:40:11+00:00
- **Authors**: Leonhard Helminger, Michael Bernasconi, Abdelaziz Djelouah, Markus Gross, Christopher Schroers
- **Comment**: None
- **Journal**: None
- **Summary**: Image restoration has seen great progress in the last years thanks to the advances in deep neural networks. Most of these existing techniques are trained using full supervision with suitable image pairs to tackle a specific degradation. However, in a blind setting with unknown degradations this is not possible and a good prior remains crucial. Recently, neural network based approaches have been proposed to model such priors by leveraging either denoising autoencoders or the implicit regularization captured by the neural network structure itself. In contrast to this, we propose using normalizing flows to model the distribution of the target content and to use this as a prior in a maximum a posteriori (MAP) formulation. By expressing the MAP optimization process in the latent space through the learned bijective mapping, we are able to obtain solutions through gradient descent. To the best of our knowledge, this is the first work that explores normalizing flows as prior in image enhancement problems. Furthermore, we present experimental results for a number of different degradations on data sets varying in complexity and show competitive results when comparing with the deep image prior approach.



### Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On
- **Arxiv ID**: http://arxiv.org/abs/2009.04592v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2009.04592v1)
- **Published**: 2020-09-09 22:38:03+00:00
- **Updated**: 2020-09-09 22:38:03+00:00
- **Authors**: Raquel Vidaurre, Igor Santesteban, Elena Garces, Dan Casas
- **Comment**: Project website
  http://mslab.es/projects/FullyConvolutionalGraphVirtualTryOn . Accepted to
  ACM SIGGRAPH / Eurographics Symposium on Computer Animation, 2020
- **Journal**: None
- **Summary**: We present a learning-based approach for virtual try-on applications based on a fully convolutional graph neural network. In contrast to existing data-driven models, which are trained for a specific garment or mesh topology, our fully convolutional model can cope with a large family of garments, represented as parametric predefined 2D panels with arbitrary mesh topology, including long dresses, shirts, and tight tops. Under the hood, our novel geometric deep learning approach learns to drape 3D garments by decoupling the three different sources of deformations that condition the fit of clothing: garment type, target body shape, and material. Specifically, we first learn a regressor that predicts the 3D drape of the input parametric garment when worn by a mean body shape. Then, after a mesh topology optimization step where we generate a sufficient level of detail for the input garment type, we further deform the mesh to reproduce deformations caused by the target body shape. Finally, we predict fine-scale details such as wrinkles that depend mostly on the garment material. We qualitatively and quantitatively demonstrate that our fully convolutional approach outperforms existing methods in terms of generalization capabilities and memory requirements, and therefore it opens the door to more general learning-based models for virtual try-on applications.



