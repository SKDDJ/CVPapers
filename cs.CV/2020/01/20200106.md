# Arxiv Papers in cs.CV on 2020-01-06
### Learning and Memorizing Representative Prototypes for 3D Point Cloud Semantic and Instance Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2001.01349v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01349v1)
- **Published**: 2020-01-06 01:07:46+00:00
- **Updated**: 2020-01-06 01:07:46+00:00
- **Authors**: Tong He, Dong Gong, Zhi Tian, Chunhua Shen
- **Comment**: None
- **Journal**: None
- **Summary**: 3D point cloud semantic and instance segmentation is crucial and fundamental for 3D scene understanding. Due to the complex structure, point sets are distributed off balance and diversely, which appears as both category imbalance and pattern imbalance. As a result, deep networks can easily forget the non-dominant cases during the learning process, resulting in unsatisfactory performance. Although re-weighting can reduce the influence of the well-classified examples, they cannot handle the non-dominant patterns during the dynamic training. In this paper, we propose a memory-augmented network to learn and memorize the representative prototypes that cover diverse samples universally. Specifically, a memory module is introduced to alleviate the forgetting issue by recording the patterns seen in mini-batch training. The learned memory items consistently reflect the interpretable and meaningful information for both dominant and non-dominant categories and cases. The distorted observations and rare cases can thus be augmented by retrieving the stored prototypes, leading to better performances and generalization. Exhaustive experiments on the benchmarks, i.e. S3DIS and ScanNetV2, reflect the superiority of our method on both effectiveness and efficiency. Not only the overall accuracy but also nondominant classes have improved substantially.



### CAE-LO: LiDAR Odometry Leveraging Fully Unsupervised Convolutional Auto-Encoder for Interest Point Detection and Feature Description
- **Arxiv ID**: http://arxiv.org/abs/2001.01354v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01354v3)
- **Published**: 2020-01-06 01:26:28+00:00
- **Updated**: 2020-10-31 01:22:44+00:00
- **Authors**: Deyu Yin, Qian Zhang, Jingbin Liu, Xinlian Liang, Yunsheng Wang, Jyri Maanpää, Hao Ma, Juha Hyyppä, Ruizhi Chen
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: As an important technology in 3D mapping, autonomous driving, and robot navigation, LiDAR odometry is still a challenging task. Appropriate data structure and unsupervised deep learning are the keys to achieve an easy adjusted LiDAR odometry solution with high performance. Utilizing compact 2D structured spherical ring projection model and voxel model which preserves the original shape of input data, we propose a fully unsupervised Convolutional Auto-Encoder based LiDAR Odometry (CAE-LO) that detects interest points from spherical ring data using 2D CAE and extracts features from multi-resolution voxel model using 3D CAE. We make several key contributions: 1) experiments based on KITTI dataset show that our interest points can capture more local details to improve the matching success rate on unstructured scenarios and our features outperform state-of-the-art by more than 50% in matching inlier ratio; 2) besides, we also propose a keyframe selection method based on matching pairs transferring, an odometry refinement method for keyframes based on extended interest points from spherical rings, and a backward pose update method. The odometry refinement experiments verify the proposed ideas' feasibility and effectiveness.



### Identifying and Compensating for Feature Deviation in Imbalanced Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.01385v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.01385v4)
- **Published**: 2020-01-06 03:52:11+00:00
- **Updated**: 2022-07-11 01:09:36+00:00
- **Authors**: Han-Jia Ye, Hong-You Chen, De-Chuan Zhan, Wei-Lun Chao
- **Comment**: None
- **Journal**: None
- **Summary**: Classifiers trained with class-imbalanced data are known to perform poorly on test data of the "minor" classes, of which we have insufficient training data. In this paper, we investigate learning a ConvNet classifier under such a scenario. We found that a ConvNet significantly over-fits the minor classes, which is quite opposite to traditional machine learning algorithms that often under-fit minor classes. We conducted a series of analysis and discovered the feature deviation phenomenon -- the learned ConvNet generates deviated features between the training and test data of minor classes -- which explains how over-fitting happens. To compensate for the effect of feature deviation which pushes test data toward low decision value regions, we propose to incorporate class-dependent temperatures (CDT) in training a ConvNet. CDT simulates feature deviation in the training phase, forcing the ConvNet to enlarge the decision values for minor-class data so that it can overcome real feature deviation in the test phase. We validate our approach on benchmark datasets and achieve promising performance. We hope that our insights can inspire new ways of thinking in resolving class-imbalanced deep learning.



### AutoDNNchip: An Automated DNN Chip Predictor and Builder for Both FPGAs and ASICs
- **Arxiv ID**: http://arxiv.org/abs/2001.03535v4
- **DOI**: 10.1145/3373087.3375306
- **Categories**: **cs.DC**, cs.CV, eess.SP, 68T45 (Primary), 68M20 (Secondary), C.5.0; C.3
- **Links**: [PDF](http://arxiv.org/pdf/2001.03535v4)
- **Published**: 2020-01-06 05:32:15+00:00
- **Updated**: 2020-06-10 23:50:57+00:00
- **Authors**: Pengfei Xu, Xiaofan Zhang, Cong Hao, Yang Zhao, Yongan Zhang, Yue Wang, Chaojian Li, Zetong Guan, Deming Chen, Yingyan Lin
- **Comment**: Accepted by 28th ACM/SIGDA International Symposium on
  Field-Programmable Gate Arrays (FPGA'2020)
- **Journal**: None
- **Summary**: Recent breakthroughs in Deep Neural Networks (DNNs) have fueled a growing demand for DNN chips. However, designing DNN chips is non-trivial because: (1) mainstream DNNs have millions of parameters and operations; (2) the large design space due to the numerous design choices of dataflows, processing elements, memory hierarchy, etc.; and (3) an algorithm/hardware co-design is needed to allow the same DNN functionality to have a different decomposition, which would require different hardware IPs to meet the application specifications. Therefore, DNN chips take a long time to design and require cross-disciplinary experts. To enable fast and effective DNN chip design, we propose AutoDNNchip - a DNN chip generator that can automatically generate both FPGA- and ASIC-based DNN chip implementation given DNNs from machine learning frameworks (e.g., PyTorch) for a designated application and dataset. Specifically, AutoDNNchip consists of two integrated enablers: (1) a Chip Predictor, built on top of a graph-based accelerator representation, which can accurately and efficiently predict a DNN accelerator's energy, throughput, and area based on the DNN model parameters, hardware configuration, technology-based IPs, and platform constraints; and (2) a Chip Builder, which can automatically explore the design space of DNN chips (including IP selection, block configuration, resource balancing, etc.), optimize chip design via the Chip Predictor, and then generate optimized synthesizable RTL to achieve the target design metrics. Experimental results show that our Chip Predictor's predicted performance differs from real-measured ones by < 10% when validated using 15 DNN models and 4 platforms (edge-FPGA/TPU/GPU and ASIC). Furthermore, accelerators generated by our AutoDNNchip can achieve better (up to 3.86X improvement) performance than that of expert-crafted state-of-the-art accelerators.



### Classification of Large-Scale High-Resolution SAR Images with Deep Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.01425v1
- **DOI**: 10.1109/LGRS.2020.2965558
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01425v1)
- **Published**: 2020-01-06 07:22:28+00:00
- **Updated**: 2020-01-06 07:22:28+00:00
- **Authors**: Zhongling Huang, Corneliu Octavian Dumitru, Zongxu Pan, Bin Lei, Mihai Datcu
- **Comment**: None
- **Journal**: IEEE Geoscience and Remote Sensing Letters 2020
- **Summary**: The classification of large-scale high-resolution SAR land cover images acquired by satellites is a challenging task, facing several difficulties such as semantic annotation with expertise, changing data characteristics due to varying imaging parameters or regional target area differences, and complex scattering mechanisms being different from optical imaging. Given a large-scale SAR land cover dataset collected from TerraSAR-X images with a hierarchical three-level annotation of 150 categories and comprising more than 100,000 patches, three main challenges in automatically interpreting SAR images of highly imbalanced classes, geographic diversity, and label noise are addressed. In this letter, a deep transfer learning method is proposed based on a similarly annotated optical land cover dataset (NWPU-RESISC45). Besides, a top-2 smooth loss function with cost-sensitive parameters was introduced to tackle the label noise and imbalanced classes' problems. The proposed method shows high efficiency in transferring information from a similarly annotated remote sensing dataset, a robust performance on highly imbalanced classes, and is alleviating the over-fitting problem caused by label noise. What's more, the learned deep model has a good generalization for other SAR-specific tasks, such as MSTAR target recognition with a state-of-the-art classification accuracy of 99.46%.



### Deep Video Super-Resolution using HR Optical Flow Estimation
- **Arxiv ID**: http://arxiv.org/abs/2001.02129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.02129v1)
- **Published**: 2020-01-06 07:25:24+00:00
- **Updated**: 2020-01-06 07:25:24+00:00
- **Authors**: Longguang Wang, Yulan Guo, Li Liu, Zaiping Lin, Xinpu Deng, Wei An
- **Comment**: Accepted by IEEE TIP. arXiv admin note: text overlap with
  arXiv:1809.08573
- **Journal**: None
- **Summary**: Video super-resolution (SR) aims at generating a sequence of high-resolution (HR) frames with plausible and temporally consistent details from their low-resolution (LR) counterparts. The key challenge for video SR lies in the effective exploitation of temporal dependency between consecutive frames. Existing deep learning based methods commonly estimate optical flows between LR frames to provide temporal dependency. However, the resolution conflict between LR optical flows and HR outputs hinders the recovery of fine details. In this paper, we propose an end-to-end video SR network to super-resolve both optical flows and images. Optical flow SR from LR frames provides accurate temporal dependency and ultimately improves video SR performance. Specifically, we first propose an optical flow reconstruction network (OFRnet) to infer HR optical flows in a coarse-to-fine manner. Then, motion compensation is performed using HR optical flows to encode temporal dependency. Finally, compensated LR inputs are fed to a super-resolution network (SRnet) to generate SR results. Extensive experiments have been conducted to demonstrate the effectiveness of HR optical flows for SR performance improvement. Comparative results on the Vid4 and DAVIS-10 datasets show that our network achieves the state-of-the-art performance.



### Robust Semantic Segmentation of Brain Tumor Regions from 3D MRIs
- **Arxiv ID**: http://arxiv.org/abs/2001.02040v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.02040v1)
- **Published**: 2020-01-06 07:47:42+00:00
- **Updated**: 2020-01-06 07:47:42+00:00
- **Authors**: Andriy Myronenko, Ali Hatamizadeh
- **Comment**: Accepted to 2019 International MICCAI Brainlesion Workshop --
  Multimodal Brain Tumor Segmentation Challenge (BraTS) 2019. arXiv admin note:
  substantial text overlap with arXiv:1810.11654
- **Journal**: None
- **Summary**: Multimodal brain tumor segmentation challenge (BraTS) brings together researchers to improve automated methods for 3D MRI brain tumor segmentation. Tumor segmentation is one of the fundamental vision tasks necessary for diagnosis and treatment planning of the disease. Previous years winning methods were all deep-learning based, thanks to the advent of modern GPUs, which allow fast optimization of deep convolutional neural network architectures. In this work, we explore best practices of 3D semantic segmentation, including conventional encoder-decoder architecture, as well combined loss functions, in attempt to further improve the segmentation accuracy. We evaluate the method on BraTS 2019 challenge.



### Deeper Insights into Weight Sharing in Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2001.01431v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.01431v1)
- **Published**: 2020-01-06 07:50:08+00:00
- **Updated**: 2020-01-06 07:50:08+00:00
- **Authors**: Yuge Zhang, Zejun Lin, Junyang Jiang, Quanlu Zhang, Yujing Wang, Hui Xue, Chen Zhang, Yaming Yang
- **Comment**: None
- **Journal**: None
- **Summary**: With the success of deep neural networks, Neural Architecture Search (NAS) as a way of automatic model design has attracted wide attention. As training every child model from scratch is very time-consuming, recent works leverage weight-sharing to speed up the model evaluation procedure. These approaches greatly reduce computation by maintaining a single copy of weights on the super-net and share the weights among every child model. However, weight-sharing has no theoretical guarantee and its impact has not been well studied before. In this paper, we conduct comprehensive experiments to reveal the impact of weight-sharing: (1) The best-performing models from different runs or even from consecutive epochs within the same run have significant variance; (2) Even with high variance, we can extract valuable information from training the super-net with shared weights; (3) The interference between child models is a main factor that induces high variance; (4) Properly reducing the degree of weight sharing could effectively reduce variance and improve performance.



### Facial Emotions Recognition using Convolutional Neural Net
- **Arxiv ID**: http://arxiv.org/abs/2001.01456v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01456v2)
- **Published**: 2020-01-06 09:43:06+00:00
- **Updated**: 2022-09-23 16:44:07+00:00
- **Authors**: Faisal Ghaffar
- **Comment**: 6 pages, 11 figures
- **Journal**: None
- **Summary**: Facial expressions vary from person to person, and the brightness, contrast, and resolution of every random image are different. This is why recognizing facial expressions is very difficult. This article proposes an efficient system for facial emotion recognition for the seven basic human emotions (angry, disgust, fear, happy, sad, surprise, and neutral), using a convolution neural network (CNN), which predicts and assigns probabilities to each emotion. Since deep learning models learn from data, thus, our proposed system processes each image with various pre-processing steps for better prediction. Every image was first passed through the face detection algorithm to include in the training dataset. As CNN requires a large amount of data, we duplicated our data using various filters on each image. Pre-processed images of size 80*100 are passed as input to the first layer of CNN. Three convolutional layers were used, followed by a pooling layer and three dense layers. The dropout rate for the dense layer was 20%. The model was trained by combining two publicly available datasets, JAFFE and KDEF. 90% of the data was used for training, while 10% was used for testing. We achieved maximum accuracy of 78.1 % using the combined dataset. Moreover, we designed an application of the proposed system with a graphical user interface that classifies emotions in real-time.



### Express Wavenet -- a low parameter optical neural network with random shift wavelet pattern
- **Arxiv ID**: http://arxiv.org/abs/2001.01458v1
- **DOI**: 10.1016/j.optcom.2020.126709
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.01458v1)
- **Published**: 2020-01-06 09:45:20+00:00
- **Updated**: 2020-01-06 09:45:20+00:00
- **Authors**: Yingshi Chen
- **Comment**: 5 pages,4 figures
- **Journal**: None
- **Summary**: Express Wavenet is an improved optical diffractive neural network. At each layer, it uses wavelet-like pattern to modulate the phase of optical waves. For input image with n2 pixels, express wavenet reduce parameter number from O(n2) to O(n). Only need one percent of the parameters, and the accuracy is still very high. In the MNIST dataset, it only needs 1229 parameters to get accuracy of 92%, while the standard optical network needs 125440 parameters. The random shift wavelets show the characteristics of optical network more vividly. Especially the vanishing gradient phenomenon in the training process. We present a modified expressway structure for this problem. Experiments verified the effect of random shift wavelet and expressway structure. Our work shows optical diffractive network would use much fewer parameters than other neural networks. The source codes are available at https://github.com/closest-git/ONNet.



### TableNet: Deep Learning model for end-to-end Table detection and Tabular data extraction from Scanned Document Images
- **Arxiv ID**: http://arxiv.org/abs/2001.01469v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01469v1)
- **Published**: 2020-01-06 10:25:32+00:00
- **Updated**: 2020-01-06 10:25:32+00:00
- **Authors**: Shubham Paliwal, Vishwanath D, Rohit Rahul, Monika Sharma, Lovekesh Vig
- **Comment**: None
- **Journal**: None
- **Summary**: With the widespread use of mobile phones and scanners to photograph and upload documents, the need for extracting the information trapped in unstructured document images such as retail receipts, insurance claim forms and financial invoices is becoming more acute. A major hurdle to this objective is that these images often contain information in the form of tables and extracting data from tabular sub-images presents a unique set of challenges. This includes accurate detection of the tabular region within an image, and subsequently detecting and extracting information from the rows and columns of the detected table. While some progress has been made in table detection, extracting the table contents is still a challenge since this involves more fine grained table structure(rows & columns) recognition. Prior approaches have attempted to solve the table detection and structure recognition problems independently using two separate models. In this paper, we propose TableNet: a novel end-to-end deep learning model for both table detection and structure recognition. The model exploits the interdependence between the twin tasks of table detection and table structure recognition to segment out the table and column regions. This is followed by semantic rule-based row extraction from the identified tabular sub-regions. The proposed model and extraction approach was evaluated on the publicly available ICDAR 2013 and Marmot Table datasets obtaining state of the art results. Additionally, we demonstrate that feeding additional semantic features further improves model performance and that the model exhibits transfer learning across datasets. Another contribution of this paper is to provide additional table structure annotations for the Marmot data, which currently only has annotations for table detection.



### Deceiving Image-to-Image Translation Networks for Autonomous Driving with Adversarial Perturbations
- **Arxiv ID**: http://arxiv.org/abs/2001.01506v1
- **DOI**: 10.1109/LRA.2020.2967289
- **Categories**: **cs.CV**, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01506v1)
- **Published**: 2020-01-06 11:51:04+00:00
- **Updated**: 2020-01-06 11:51:04+00:00
- **Authors**: Lin Wang, Wonjune Cho, Kuk-Jin Yoon
- **Comment**: 8pages, Accepted on IEEE Robotics and Automation Letters (RAL)
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have achieved impressive performance on handling computer vision problems, however, it has been found that DNNs are vulnerable to adversarial examples. For such reason, adversarial perturbations have been recently studied in several respects. However, most previous works have focused on image classification tasks, and it has never been studied regarding adversarial perturbations on Image-to-image (Im2Im) translation tasks, showing great success in handling paired and/or unpaired mapping problems in the field of autonomous driving and robotics. This paper examines different types of adversarial perturbations that can fool Im2Im frameworks for autonomous driving purpose. We propose both quasi-physical and digital adversarial perturbations that can make Im2Im models yield unexpected results. We then empirically analyze these perturbations and show that they generalize well under both paired for image synthesis and unpaired settings for style transfer. We also validate that there exist some perturbation thresholds over which the Im2Im mapping is disrupted or impossible. The existence of these perturbations reveals that there exist crucial weaknesses in Im2Im models. Lastly, we show that our methods illustrate how perturbations affect the quality of outputs, pioneering the improvement of the robustness of current SOTA networks for autonomous driving.



### Mutual Mean-Teaching: Pseudo Label Refinery for Unsupervised Domain Adaptation on Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/2001.01526v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01526v2)
- **Published**: 2020-01-06 12:42:58+00:00
- **Updated**: 2020-01-30 06:37:43+00:00
- **Authors**: Yixiao Ge, Dapeng Chen, Hongsheng Li
- **Comment**: Accepted in International Conference on Learning Representations
  (ICLR 2020)
- **Journal**: None
- **Summary**: Person re-identification (re-ID) aims at identifying the same persons' images across different cameras. However, domain diversities between different datasets pose an evident challenge for adapting the re-ID model trained on one dataset to another one. State-of-the-art unsupervised domain adaptation methods for person re-ID transferred the learned knowledge from the source domain by optimizing with pseudo labels created by clustering algorithms on the target domain. Although they achieved state-of-the-art performances, the inevitable label noise caused by the clustering procedure was ignored. Such noisy pseudo labels substantially hinders the model's capability on further improving feature representations on the target domain. In order to mitigate the effects of noisy pseudo labels, we propose to softly refine the pseudo labels in the target domain by proposing an unsupervised framework, Mutual Mean-Teaching (MMT), to learn better features from the target domain via off-line refined hard pseudo labels and on-line refined soft pseudo labels in an alternative training manner. In addition, the common practice is to adopt both the classification loss and the triplet loss jointly for achieving optimal performances in person re-ID models. However, conventional triplet loss cannot work with softly refined labels. To solve this problem, a novel soft softmax-triplet loss is proposed to support learning with soft pseudo triplet labels for achieving the optimal domain adaptation performance. The proposed MMT framework achieves considerable improvements of 14.4%, 18.2%, 13.1% and 16.4% mAP on Market-to-Duke, Duke-to-Market, Market-to-MSMT and Duke-to-MSMT unsupervised domain adaptation tasks. Code is available at https://github.com/yxgeee/MMT.



### Learning From Multiple Experts: Self-paced Knowledge Distillation for Long-tailed Classification
- **Arxiv ID**: http://arxiv.org/abs/2001.01536v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.01536v3)
- **Published**: 2020-01-06 12:57:36+00:00
- **Updated**: 2020-09-21 02:44:16+00:00
- **Authors**: Liuyu Xiang, Guiguang Ding, Jungong Han
- **Comment**: ECCV 2020 Spotlight
- **Journal**: None
- **Summary**: In real-world scenarios, data tends to exhibit a long-tailed distribution, which increases the difficulty of training deep networks. In this paper, we propose a novel self-paced knowledge distillation framework, termed Learning From Multiple Experts (LFME). Our method is inspired by the observation that networks trained on less imbalanced subsets of the distribution often yield better performances than their jointly-trained counterparts. We refer to these models as 'Experts', and the proposed LFME framework aggregates the knowledge from multiple 'Experts' to learn a unified student model. Specifically, the proposed framework involves two levels of adaptive learning schedules: Self-paced Expert Selection and Curriculum Instance Selection, so that the knowledge is adaptively transferred to the 'Student'. We conduct extensive experiments and demonstrate that our method is able to achieve superior performances compared to state-of-the-art methods. We also show that our method can be easily plugged into state-of-the-art long-tailed classification algorithms for further improvements.



### Hyperspectral Super-Resolution via Coupled Tensor Ring Factorization
- **Arxiv ID**: http://arxiv.org/abs/2001.01547v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01547v1)
- **Published**: 2020-01-06 13:19:59+00:00
- **Updated**: 2020-01-06 13:19:59+00:00
- **Authors**: Wei He, Yong Chen, Naoto Yokoya, Chao Li, Qibin Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Hyperspectral super-resolution (HSR) fuses a low-resolution hyperspectral image (HSI) and a high-resolution multispectral image (MSI) to obtain a high-resolution HSI (HR-HSI). In this paper, we propose a new model, named coupled tensor ring factorization (CTRF), for HSR. The proposed CTRF approach simultaneously learns high spectral resolution core tensor from the HSI and high spatial resolution core tensors from the MSI, and reconstructs the HR-HSI via tensor ring (TR) representation (Figure~\ref{fig:framework}). The CTRF model can separately exploit the low-rank property of each class (Section \ref{sec:analysis}), which has been never explored in the previous coupled tensor model. Meanwhile, it inherits the simple representation of coupled matrix/CP factorization and flexible low-rank exploration of coupled Tucker factorization.   Guided by Theorem~\ref{th:1}, we further propose a spectral nuclear norm regularization to explore the global spectral low-rank property.   The experiments have demonstrated the advantage of the proposed nuclear norm regularized CTRF (NCTRF) as compared to previous matrix/tensor and deep learning methods.



### Multi-scale Domain-adversarial Multiple-instance CNN for Cancer Subtype Classification with Unannotated Histopathological Images
- **Arxiv ID**: http://arxiv.org/abs/2001.01599v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, I.2.1; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/2001.01599v2)
- **Published**: 2020-01-06 14:09:51+00:00
- **Updated**: 2020-04-02 08:03:24+00:00
- **Authors**: Noriaki Hashimoto, Daisuke Fukushima, Ryoichi Koga, Yusuke Takagi, Kaho Ko, Kei Kohno, Masato Nakaguro, Shigeo Nakamura, Hidekata Hontani, Ichiro Takeuchi
- **Comment**: Accepted to CVPR2020
- **Journal**: None
- **Summary**: We propose a new method for cancer subtype classification from histopathological images, which can automatically detect tumor-specific features in a given whole slide image (WSI). The cancer subtype should be classified by referring to a WSI, i.e., a large-sized image (typically 40,000x40,000 pixels) of an entire pathological tissue slide, which consists of cancer and non-cancer portions. One difficulty arises from the high cost associated with annotating tumor regions in WSIs. Furthermore, both global and local image features must be extracted from the WSI by changing the magnifications of the image. In addition, the image features should be stably detected against the differences of staining conditions among the hospitals/specimens. In this paper, we develop a new CNN-based cancer subtype classification method by effectively combining multiple-instance, domain adversarial, and multi-scale learning frameworks in order to overcome these practical difficulties. When the proposed method was applied to malignant lymphoma subtype classifications of 196 cases collected from multiple hospitals, the classification performance was significantly better than the standard CNN or other conventional methods, and the accuracy compared favorably with that of standard pathologists.



### Improving Few-shot Learning by Spatially-aware Matching and CrossTransformer
- **Arxiv ID**: http://arxiv.org/abs/2001.01600v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01600v2)
- **Published**: 2020-01-06 14:10:20+00:00
- **Updated**: 2022-10-08 12:16:49+00:00
- **Authors**: Hongguang Zhang, Philip H. S. Torr, Piotr Koniusz
- **Comment**: Asian Conference on Computer Vision 2022
- **Journal**: None
- **Summary**: Current few-shot learning models capture visual object relations in the so-called meta-learning setting under a fixed-resolution input. However, such models have a limited generalization ability under the scale and location mismatch between objects, as only few samples from target classes are provided. Therefore, the lack of a mechanism to match the scale and location between pairs of compared images leads to the performance degradation. The importance of image contents varies across coarse-to-fine scales depending on the object and its class label, e.g., generic objects and scenes rely on their global appearance while fine-grained objects rely more on their localized visual patterns. In this paper, we study the impact of scale and location mismatch in the few-shot learning scenario, and propose a novel Spatially-aware Matching (SM) scheme to effectively perform matching across multiple scales and locations, and learn image relations by giving the highest weights to the best matching pairs. The SM is trained to activate the most related locations and scales between support and query data. We apply and evaluate SM on various few-shot learning models and backbones for comprehensive evaluations. Furthermore, we leverage an auxiliary self-supervisory discriminator to train/predict the spatial- and scale-level index of feature vectors we use. Finally, we develop a novel transformer-based pipeline to exploit self- and cross-attention in a spatially-aware matching process. Our proposed design is orthogonal to the choice of backbone and/or comparator.



### Chained Representation Cycling: Learning to Estimate 3D Human Pose and Shape by Cycling Between Representations
- **Arxiv ID**: http://arxiv.org/abs/2001.01613v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.01613v1)
- **Published**: 2020-01-06 14:54:00+00:00
- **Updated**: 2020-01-06 14:54:00+00:00
- **Authors**: Nadine Rueegg, Christoph Lassner, Michael J. Black, Konrad Schindler
- **Comment**: To be published in proceedings of Thirty-Fourth AAAI Conference on
  Artificial Intelligence (AAAI-20)
- **Journal**: None
- **Summary**: The goal of many computer vision systems is to transform image pixels into 3D representations. Recent popular models use neural networks to regress directly from pixels to 3D object parameters. Such an approach works well when supervision is available, but in problems like human pose and shape estimation, it is difficult to obtain natural images with 3D ground truth. To go one step further, we propose a new architecture that facilitates unsupervised, or lightly supervised, learning. The idea is to break the problem into a series of transformations between increasingly abstract representations. Each step involves a cycle designed to be learnable without annotated training data, and the chain of cycles delivers the final solution. Specifically, we use 2D body part segments as an intermediate representation that contains enough information to be lifted to 3D, and at the same time is simple enough to be learned in an unsupervised way. We demonstrate the method by learning 3D human pose and shape from un-paired and un-annotated images. We also explore varying amounts of paired data and show that cycling greatly alleviates the need for paired data. While we present results for modeling humans, our formulation is general and can be applied to other vision problems.



### Deep Snake for Real-Time Instance Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2001.01629v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01629v3)
- **Published**: 2020-01-06 15:29:06+00:00
- **Updated**: 2020-04-01 15:01:53+00:00
- **Authors**: Sida Peng, Wen Jiang, Huaijin Pi, Xiuli Li, Hujun Bao, Xiaowei Zhou
- **Comment**: Accepted to CVPR 2020 as Oral. Add experiments on MS COCO
- **Journal**: None
- **Summary**: This paper introduces a novel contour-based approach named deep snake for real-time instance segmentation. Unlike some recent methods that directly regress the coordinates of the object boundary points from an image, deep snake uses a neural network to iteratively deform an initial contour to match the object boundary, which implements the classic idea of snake algorithms with a learning-based approach. For structured feature learning on the contour, we propose to use circular convolution in deep snake, which better exploits the cycle-graph structure of a contour compared against generic graph convolution. Based on deep snake, we develop a two-stage pipeline for instance segmentation: initial contour proposal and contour deformation, which can handle errors in object localization. Experiments show that the proposed approach achieves competitive performances on the Cityscapes, KINS, SBD and COCO datasets while being efficient for real-time applications with a speed of 32.3 fps for 512$\times$512 images on a 1080Ti GPU. The code is available at https://github.com/zju3dv/snake/.



### A Hybrid Approach to Temporal Pattern Matching
- **Arxiv ID**: http://arxiv.org/abs/2001.01661v2
- **DOI**: None
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01661v2)
- **Published**: 2020-01-06 16:52:44+00:00
- **Updated**: 2020-01-24 11:22:10+00:00
- **Authors**: Konstantinos Semertzidis, Evaggelia Pitoura
- **Comment**: 4 pages, 4 figures, 1 table
- **Journal**: None
- **Summary**: The primary objective of graph pattern matching is to find all appearances of an input graph pattern query in a large data graph. Such appearances are called matches. In this paper, we are interested in finding matches of interaction patterns in temporal graphs. To this end, we propose a hybrid approach that achieves effective filtering of potential matches based both on structure and time. Our approach exploits a graph representation where edges are ordered by time. We present experiments with real datasets that illustrate the efficiency of our approach.



### Meshlet Priors for 3D Mesh Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2001.01744v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01744v2)
- **Published**: 2020-01-06 19:13:40+00:00
- **Updated**: 2020-06-01 18:58:52+00:00
- **Authors**: Abhishek Badki, Orazio Gallo, Jan Kautz, Pradeep Sen
- **Comment**: To be presented at CVPR 2020
- **Journal**: None
- **Summary**: Estimating a mesh from an unordered set of sparse, noisy 3D points is a challenging problem that requires carefully selected priors. Existing hand-crafted priors, such as smoothness regularizers, impose an undesirable trade-off between attenuating noise and preserving local detail. Recent deep-learning approaches produce impressive results by learning priors directly from the data. However, the priors are learned at the object level, which makes these algorithms class-specific and even sensitive to the pose of the object. We introduce meshlets, small patches of mesh that we use to learn local shape priors. Meshlets act as a dictionary of local features and thus allow to use learned priors to reconstruct object meshes in any pose and from unseen classes, even when the noise is large and the samples sparse.



### Unpaired Multi-modal Segmentation via Knowledge Distillation
- **Arxiv ID**: http://arxiv.org/abs/2001.03111v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.03111v1)
- **Published**: 2020-01-06 20:03:17+00:00
- **Updated**: 2020-01-06 20:03:17+00:00
- **Authors**: Qi Dou, Quande Liu, Pheng Ann Heng, Ben Glocker
- **Comment**: IEEE TMI, code available
- **Journal**: None
- **Summary**: Multi-modal learning is typically performed with network architectures containing modality-specific layers and shared layers, utilizing co-registered images of different modalities. We propose a novel learning scheme for unpaired cross-modality image segmentation, with a highly compact architecture achieving superior segmentation accuracy. In our method, we heavily reuse network parameters, by sharing all convolutional kernels across CT and MRI, and only employ modality-specific internal normalization layers which compute respective statistics. To effectively train such a highly compact model, we introduce a novel loss term inspired by knowledge distillation, by explicitly constraining the KL-divergence of our derived prediction distributions between modalities. We have extensively validated our approach on two multi-class segmentation problems: i) cardiac structure segmentation, and ii) abdominal organ segmentation. Different network settings, i.e., 2D dilated network and 3D U-net, are utilized to investigate our method's general efficacy. Experimental results on both tasks demonstrate that our novel multi-modal learning scheme consistently outperforms single-modal training and previous multi-modal approaches.



### Plug-and-Play Rescaling Based Crowd Counting in Static Images
- **Arxiv ID**: http://arxiv.org/abs/2001.01786v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01786v1)
- **Published**: 2020-01-06 21:43:25+00:00
- **Updated**: 2020-01-06 21:43:25+00:00
- **Authors**: Usman Sajid, Guanghui Wang
- **Comment**: 10 pages, 6 figures, WACV conference
- **Journal**: None
- **Summary**: Crowd counting is a challenging problem especially in the presence of huge crowd diversity across images and complex cluttered crowd-like background regions, where most previous approaches do not generalize well and consequently produce either huge crowd underestimation or overestimation. To address these challenges, we propose a new image patch rescaling module (PRM) and three independent PRM employed crowd counting methods. The proposed frameworks use the PRM module to rescale the image regions (patches) that require special treatment, whereas the classification process helps in recognizing and discarding any cluttered crowd-like background regions which may result in overestimation. Experiments on three standard benchmarks and cross-dataset evaluation show that our approach outperforms the state-of-the-art models in the RMSE evaluation metric with an improvement up to 10.4%, and possesses superior generalization ability to new datasets.



### MCMLSD: A Probabilistic Algorithm and Evaluation Framework for Line Segment Detection
- **Arxiv ID**: http://arxiv.org/abs/2001.01788v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01788v1)
- **Published**: 2020-01-06 21:51:45+00:00
- **Updated**: 2020-01-06 21:51:45+00:00
- **Authors**: James H. Elder, Emilio J. Almazàn, Yiming Qian, Ron Tal
- **Comment**: None
- **Journal**: None
- **Summary**: Traditional approaches to line segment detection typically involve perceptual grouping in the image domain and/or global accumulation in the Hough domain. Here we propose a probabilistic algorithm that merges the advantages of both approaches. In a first stage lines are detected using a global probabilistic Hough approach. In the second stage each detected line is analyzed in the image domain to localize the line segments that generated the peak in the Hough map. By limiting search to a line, the distribution of segments over the sequence of points on the line can be modeled as a Markov chain, and a probabilistically optimal labelling can be computed exactly using a standard dynamic programming algorithm, in linear time. The Markov assumption also leads to an intuitive ranking method that uses the local marginal posterior probabilities to estimate the expected number of correctly labelled points on a segment. To assess the resulting Markov Chain Marginal Line Segment Detector (MCMLSD) we develop and apply a novel quantitative evaluation methodology that controls for under- and over-segmentation. Evaluation on the YorkUrbanDB and Wireframe datasets shows that the proposed MCMLSD method outperforms prior traditional approaches, as well as more recent deep learning methods.



### Implementation of the VBM3D Video Denoising Method and Some Variants
- **Arxiv ID**: http://arxiv.org/abs/2001.01802v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01802v1)
- **Published**: 2020-01-06 22:37:37+00:00
- **Updated**: 2020-01-06 22:37:37+00:00
- **Authors**: Thibaud Ehret, Pablo Arias
- **Comment**: 18 pages, 7 figures, 5 tables
- **Journal**: None
- **Summary**: VBM3D is an extension to video of the well known image denoising algorithm BM3D, which takes advantage of the sparse representation of stacks of similar patches in a transform domain. The extension is rather straightforward: the similar 2D patches are taken from a spatio-temporal neighborhood which includes neighboring frames. In spite of its simplicity, the algorithm offers a good trade-off between denoising performance and computational complexity. In this work we revisit this method, providing an open-source C++ implementation reproducing the results. A detailed description is given and the choice of parameters is thoroughly discussed. Furthermore, we discuss several extensions of the original algorithm: (1) a multi-scale implementation, (2) the use of 3D patches, (3) the use of optical flow to guide the patch search. These extensions allow to obtain results which are competitive with even the most recent state of the art.



### Advancing machine learning for MR image reconstruction with an open competition: Overview of the 2019 fastMRI challenge
- **Arxiv ID**: http://arxiv.org/abs/2001.02518v1
- **DOI**: 10.1002/mrm.28338
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.02518v1)
- **Published**: 2020-01-06 23:00:56+00:00
- **Updated**: 2020-01-06 23:00:56+00:00
- **Authors**: Florian Knoll, Tullie Murrell, Anuroop Sriram, Nafissa Yakubova, Jure Zbontar, Michael Rabbat, Aaron Defazio, Matthew J. Muckley, Daniel K. Sodickson, C. Lawrence Zitnick, Michael P. Recht
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose: To advance research in the field of machine learning for MR image reconstruction with an open challenge. Methods: We provided participants with a dataset of raw k-space data from 1,594 consecutive clinical exams of the knee. The goal of the challenge was to reconstruct images from these data. In order to strike a balance between realistic data and a shallow learning curve for those not already familiar with MR image reconstruction, we ran multiple tracks for multi-coil and single-coil data. We performed a two-stage evaluation based on quantitative image metrics followed by evaluation by a panel of radiologists. The challenge ran from June to December of 2019. Results: We received a total of 33 challenge submissions. All participants chose to submit results from supervised machine learning approaches. Conclusion: The challenge led to new developments in machine learning for image reconstruction, provided insight into the current state of the art in the field, and highlighted remaining hurdles for clinical adoption.



### Semi-supervised Anomaly Detection using AutoEncoders
- **Arxiv ID**: http://arxiv.org/abs/2001.03674v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.03674v1)
- **Published**: 2020-01-06 23:06:28+00:00
- **Updated**: 2020-01-06 23:06:28+00:00
- **Authors**: Manpreet Singh Minhas, John Zelek
- **Comment**: None
- **Journal**: JCVIS, vol. 5, no. 1, p. 3, Jan. 2020
- **Summary**: Anomaly detection refers to the task of finding unusual instances that stand out from the normal data. In several applications, these outliers or anomalous instances are of greater interest compared to the normal ones. Specifically in the case of industrial optical inspection and infrastructure asset management, finding these defects (anomalous regions) is of extreme importance. Traditionally and even today this process has been carried out manually. Humans rely on the saliency of the defects in comparison to the normal texture to detect the defects. However, manual inspection is slow, tedious, subjective and susceptible to human biases. Therefore, the automation of defect detection is desirable. But for defect detection lack of availability of a large number of anomalous instances and labelled data is a problem. In this paper, we present a convolutional auto-encoder architecture for anomaly detection that is trained only on the defect-free (normal) instances. For the test images, residual masks that are obtained by subtracting the original image from the auto-encoder output are thresholded to obtain the defect segmentation masks. The approach was tested on two data-sets and achieved an impressive average F1 score of 0.885. The network learnt to detect the actual shape of the defects even though no defected images were used during the training.



### Regression and Learning with Pixel-wise Attention for Retinal Fundus Glaucoma Segmentation and Detection
- **Arxiv ID**: http://arxiv.org/abs/2001.01815v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01815v1)
- **Published**: 2020-01-06 23:54:27+00:00
- **Updated**: 2020-01-06 23:54:27+00:00
- **Authors**: Peng Liu, Ruogu Fang
- **Comment**: MICCAI 2018 workshop challenge
- **Journal**: None
- **Summary**: Observing retinal fundus images by an ophthalmologist is a major diagnosis approach for glaucoma. However, it is still difficult to distinguish the features of the lesion solely through manual observations, especially, in glaucoma early phase. In this paper, we present two deep learning-based automated algorithms for glaucoma detection and optic disc and cup segmentation. We utilize the attention mechanism to learn pixel-wise features for accurate prediction. In particular, we present two convolutional neural networks that can focus on learning various pixel-wise level features. In addition, we develop several attention strategies to guide the networks to learn the important features that have a major impact on prediction accuracy. We evaluate our methods on the validation dataset and The proposed both tasks' solutions can achieve impressive results and outperform current state-of-the-art methods. \textit{The code is available at \url{https://github.com/cswin/RLPA}}.



### The Pedestrian Patterns Dataset
- **Arxiv ID**: http://arxiv.org/abs/2001.01816v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2001.01816v1)
- **Published**: 2020-01-06 23:58:39+00:00
- **Updated**: 2020-01-06 23:58:39+00:00
- **Authors**: Kasra Mokhtari, Alan R. Wagner
- **Comment**: Accepted in AAAI Fall Symposium 2019
- **Journal**: None
- **Summary**: We present the pedestrian patterns dataset for autonomous driving. The dataset was collected by repeatedly traversing the same three routes for one week starting at different specific timeslots. The purpose of the dataset is to capture the patterns of social and pedestrian behavior along the traversed routes at different times and to eventually use this information to make predictions about the risk associated with autonomously traveling along different routes. This dataset contains the Full HD videos and GPS data for each traversal. Fast R-CNN pedestrian detection method is applied to the captured videos to count the number of pedestrians at each video frame in order to assess the density of pedestrians along a route. By providing this large-scale dataset to researchers, we hope to accelerate autonomous driving research not only to estimate the risk, both to the public and to the autonomous vehicle but also accelerate research on long-term vision-based localization of mobile robots and autonomous vehicles of the future.



