# Arxiv Papers in cs.CV on 2020-01-05
### End-To-End Trainable Video Super-Resolution Based on a New Mechanism for Implicit Motion Estimation and Compensation
- **Arxiv ID**: http://arxiv.org/abs/2001.01162v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01162v1)
- **Published**: 2020-01-05 03:47:24+00:00
- **Updated**: 2020-01-05 03:47:24+00:00
- **Authors**: Xiaohong Liu, Lingshi Kong, Yang Zhou, Jiying Zhao, Jun Chen
- **Comment**: 10 pages, accepted in WACV2020
- **Journal**: None
- **Summary**: Video super-resolution aims at generating a high-resolution video from its low-resolution counterpart. With the rapid rise of deep learning, many recently proposed video super-resolution methods use convolutional neural networks in conjunction with explicit motion compensation to capitalize on statistical dependencies within and across low-resolution frames. Two common issues of such methods are noteworthy. Firstly, the quality of the final reconstructed HR video is often very sensitive to the accuracy of motion estimation. Secondly, the warp grid needed for motion compensation, which is specified by the two flow maps delineating pixel displacements in horizontal and vertical directions, tends to introduce additional errors and jeopardize the temporal consistency across video frames. To address these issues, we propose a novel dynamic local filter network to perform implicit motion estimation and compensation by employing, via locally connected layers, sample-specific and position-specific dynamic local filters that are tailored to the target pixels. We also propose a global refinement network based on ResBlock and autoencoder structures to exploit non-local correlations and enhance the spatial consistency of super-resolved frames. The experimental results demonstrate that the proposed method outperforms the state-of-the-art, and validate its strength in terms of local transformation handling, temporal consistency as well as edge sharpness.



### Facial Action Unit Detection via Adaptive Attention and Relation
- **Arxiv ID**: http://arxiv.org/abs/2001.01168v2
- **DOI**: 10.1109/TIP.2023.3277794
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01168v2)
- **Published**: 2020-01-05 05:14:03+00:00
- **Updated**: 2023-05-17 03:18:31+00:00
- **Authors**: Zhiwen Shao, Yong Zhou, Jianfei Cai, Hancheng Zhu, Rui Yao
- **Comment**: This paper has been accepted by IEEE Transactions on Image Processing
  (TIP)
- **Journal**: None
- **Summary**: Facial action unit (AU) detection is challenging due to the difficulty in capturing correlated information from subtle and dynamic AUs. Existing methods often resort to the localization of correlated regions of AUs, in which predefining local AU attentions by correlated facial landmarks often discards essential parts, or learning global attention maps often contains irrelevant areas. Furthermore, existing relational reasoning methods often employ common patterns for all AUs while ignoring the specific way of each AU. To tackle these limitations, we propose a novel adaptive attention and relation (AAR) framework for facial AU detection. Specifically, we propose an adaptive attention regression network to regress the global attention map of each AU under the constraint of attention predefinition and the guidance of AU detection, which is beneficial for capturing both specified dependencies by landmarks in strongly correlated regions and facial globally distributed dependencies in weakly correlated regions. Moreover, considering the diversity and dynamics of AUs, we propose an adaptive spatio-temporal graph convolutional network to simultaneously reason the independent pattern of each AU, the inter-dependencies among AUs, as well as the temporal dependencies. Extensive experiments show that our approach (i) achieves competitive performance on challenging benchmarks including BP4D, DISFA, and GFT in constrained scenarios and Aff-Wild2 in unconstrained scenarios, and (ii) can precisely learn the regional correlation distribution of each AU.



### The Human Visual System and Adversarial AI
- **Arxiv ID**: http://arxiv.org/abs/2001.01172v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01172v2)
- **Published**: 2020-01-05 05:47:48+00:00
- **Updated**: 2020-01-07 21:15:45+00:00
- **Authors**: Yaoshiang Ho, Samuel Wookey
- **Comment**: None
- **Journal**: None
- **Summary**: This paper applies theories about the Human Visual System to make Adversarial AI more effective. To date, Adversarial AI has modeled perceptual distances between clean and adversarial examples of images using Lp norms. These norms have the benefit of simple mathematical description and reasonable effectiveness in approximating perceptual distance. However, in prior decades, other areas of image processing have moved beyond simpler models like Mean Squared Error (MSE) towards more complex models that better approximate the Human Visual System (HVS). We demonstrate a proof of concept of incorporating HVS models into Adversarial AI.



### Informative Sample Mining Network for Multi-Domain Image-to-Image Translation
- **Arxiv ID**: http://arxiv.org/abs/2001.01173v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01173v4)
- **Published**: 2020-01-05 05:48:02+00:00
- **Updated**: 2020-09-20 09:56:53+00:00
- **Authors**: Jie Cao, Huaibo Huang, Yi Li, Ran He, Zhenan Sun
- **Comment**: None
- **Journal**: None
- **Summary**: The performance of multi-domain image-to-image translation has been significantly improved by recent progress in deep generative models. Existing approaches can use a unified model to achieve translations between all the visual domains. However, their outcomes are far from satisfying when there are large domain variations. In this paper, we reveal that improving the sample selection strategy is an effective solution. To select informative samples, we dynamically estimate sample importance during the training of Generative Adversarial Networks, presenting Informative Sample Mining Network. We theoretically analyze the relationship between the sample importance and the prediction of the global optimal discriminator. Then a practical importance estimation function for general conditions is derived. Furthermore, we propose a novel multi-stage sample training scheme to reduce sample hardness while preserving sample informativeness. Extensive experiments on a wide range of specific image-to-image translation tasks are conducted, and the results demonstrate our superiority over current state-of-the-art methods.



### Spatial-Scale Aligned Network for Fine-Grained Recognition
- **Arxiv ID**: http://arxiv.org/abs/2001.01211v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01211v1)
- **Published**: 2020-01-05 11:12:08+00:00
- **Updated**: 2020-01-05 11:12:08+00:00
- **Authors**: Lizhao Gao, Haihua Xu, Chong Sun, Junling Liu, Yu-Wing Tai
- **Comment**: None
- **Journal**: None
- **Summary**: Existing approaches for fine-grained visual recognition focus on learning marginal region-based representations while neglecting the spatial and scale misalignments, leading to inferior performance. In this paper, we propose the spatial-scale aligned network (SSANET) and implicitly address misalignments during the recognition process. Especially, SSANET consists of 1) a self-supervised proposal mining formula with Morphological Alignment Constraints; 2) a discriminative scale mining (DSM) module, which exploits the feature pyramid via a circulant matrix, and provides the Fourier solver for fast scale alignments; 3) an oriented pooling (OP) module, that performs the pooling operation in several pre-defined orientations. Each orientation defines one kind of spatial alignment, and the network automatically determines which is the optimal alignments through learning. With the proposed two modules, our algorithm can automatically determine the accurate local proposal regions and generate more robust target representations being invariant to various appearance variances. Extensive experiments verify that SSANET is competent at learning better spatial-scale invariant target representations, yielding superior performance on the fine-grained recognition task on several benchmarks.



### Fractional order graph neural network
- **Arxiv ID**: http://arxiv.org/abs/2001.04026v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/2001.04026v3)
- **Published**: 2020-01-05 11:55:55+00:00
- **Updated**: 2021-07-06 06:23:18+00:00
- **Authors**: Zijian Liu, Chunbo Luo, Shuai Li, Peng Ren, Geyong Min
- **Comment**: There are serious mistakes in the article and it needs to be
  retracted and corrected
- **Journal**: None
- **Summary**: This paper proposes fractional order graph neural networks (FGNNs), optimized by the approximation strategy to address the challenges of local optimum of classic and fractional graph neural networks which are specialised at aggregating information from the feature and adjacent matrices of connected nodes and their neighbours to solve learning tasks on non-Euclidean data such as graphs. Meanwhile the approximate calculation of fractional order gradients also overcomes the high computational complexity of fractional order derivations. We further prove that such an approximation is feasible and the FGNN is unbiased towards global optimization solution. Extensive experiments on citation networks show that FGNN achieves great advantage over baseline models when selected appropriate fractional order.



### EcoNAS: Finding Proxies for Economical Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2001.01233v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2001.01233v2)
- **Published**: 2020-01-05 13:29:02+00:00
- **Updated**: 2020-02-27 02:42:45+00:00
- **Authors**: Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi, Xuesen Zhang, Wanli Ouyang
- **Comment**: CVPR2020
- **Journal**: None
- **Summary**: Neural Architecture Search (NAS) achieves significant progress in many computer vision tasks. While many methods have been proposed to improve the efficiency of NAS, the search progress is still laborious because training and evaluating plausible architectures over large search space is time-consuming. Assessing network candidates under a proxy (i.e., computationally reduced setting) thus becomes inevitable. In this paper, we observe that most existing proxies exhibit different behaviors in maintaining the rank consistency among network candidates. In particular, some proxies can be more reliable -- the rank of candidates does not differ much comparing their reduced setting performance and final performance. In this paper, we systematically investigate some widely adopted reduction factors and report our observations. Inspired by these observations, we present a reliable proxy and further formulate a hierarchical proxy strategy. The strategy spends more computations on candidate networks that are potentially more accurate, while discards unpromising ones in early stage with a fast proxy. This leads to an economical evolutionary-based NAS (EcoNAS), which achieves an impressive 400x search time reduction in comparison to the evolutionary-based state of the art (8 vs. 3150 GPU days). Some new proxies led by our observations can also be applied to accelerate other NAS methods while still able to discover good candidate networks with performance matching those found by previous proxy strategies.



### Cooperative Initialization based Deep Neural Network Training
- **Arxiv ID**: http://arxiv.org/abs/2001.01240v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.01240v1)
- **Published**: 2020-01-05 14:08:46+00:00
- **Updated**: 2020-01-05 14:08:46+00:00
- **Authors**: Pravendra Singh, Munender Varshney, Vinay P. Namboodiri
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2020
- **Journal**: None
- **Summary**: Researchers have proposed various activation functions. These activation functions help the deep network to learn non-linear behavior with a significant effect on training dynamics and task performance. The performance of these activations also depends on the initial state of the weight parameters, i.e., different initial state leads to a difference in the performance of a network. In this paper, we have proposed a cooperative initialization for training the deep network using ReLU activation function to improve the network performance. Our approach uses multiple activation functions in the initial few epochs for the update of all sets of weight parameters while training the network. These activation functions cooperate to overcome their drawbacks in the update of weight parameters, which in effect learn better "feature representation" and boost the network performance later. Cooperative initialization based training also helps in reducing the overfitting problem and does not increase the number of parameters, inference (test) time in the final model while improving the performance. Experiments show that our approach outperforms various baselines and, at the same time, performs well over various tasks such as classification and detection. The Top-1 classification accuracy of the model trained using our approach improves by 2.8% for VGG-16 and 2.1% for ResNet-56 on CIFAR-100 dataset.



### Exploiting Event Cameras for Spatio-Temporal Prediction of Fast-Changing Trajectories
- **Arxiv ID**: http://arxiv.org/abs/2001.01248v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2001.01248v2)
- **Published**: 2020-01-05 14:37:28+00:00
- **Updated**: 2020-01-15 13:13:02+00:00
- **Authors**: Marco Monforte, Ander Arriandiaga, Arren Glover, Chiara Bartolozzi
- **Comment**: 5 pages, 5 figures, 1 table, paper accepted for presentation at the
  2nd IEEE International Conference on Artificial Intelligence Circuits and
  Systems (AICAS2020)
- **Journal**: None
- **Summary**: This paper investigates trajectory prediction for robotics, to improve the interaction of robots with moving targets, such as catching a bouncing ball. Unexpected, highly-non-linear trajectories cannot easily be predicted with regression-based fitting procedures, therefore we apply state of the art machine learning, specifically based on Long-Short Term Memory (LSTM) architectures. In addition, fast moving targets are better sensed using event cameras, which produce an asynchronous output triggered by spatial change, rather than at fixed temporal intervals as with traditional cameras. We investigate how LSTM models can be adapted for event camera data, and in particular look at the benefit of using asynchronously sampled data.



### The troublesome kernel -- On hallucinations, no free lunches and the accuracy-stability trade-off in inverse problems
- **Arxiv ID**: http://arxiv.org/abs/2001.01258v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, 65R32, 94A08, 68T05, 65M12
- **Links**: [PDF](http://arxiv.org/pdf/2001.01258v2)
- **Published**: 2020-01-05 15:30:23+00:00
- **Updated**: 2023-01-10 14:09:43+00:00
- **Authors**: Nina M. Gottschling, Vegard Antun, Anders C. Hansen, Ben Adcock
- **Comment**: None
- **Journal**: None
- **Summary**: Methods inspired by Artificial Intelligence (AI) are starting to fundamentally change computational science and engineering through breakthrough performances on challenging problems. However, reliability and trustworthiness of such techniques is becoming a major concern. In inverse problems in imaging, the focus of this paper, there is increasing empirical evidence that methods may suffer from hallucinations, i.e., false, but realistic-looking artifacts; instability, i.e., sensitivity to perturbations in the data; and unpredictable generalization, i.e., excellent performance on some images, but significant deterioration on others. This paper presents a theoretical foundation for these phenomena. We give a mathematical framework describing how and when such effects arise in arbitrary reconstruction methods, not just AI-inspired techniques. Several of our results take the form of 'no free lunch' theorems. Specifically, we show that (i) methods that overperform on a single image can wrongly transfer details from one image to another, creating a hallucination, (ii) methods that overperform on two or more images can hallucinate or be unstable, (iii) optimizing the accuracy-stability trade-off is generally difficult, (iv) hallucinations and instabilities, if they occur, are not rare events, and may be encouraged by standard training, (v) it may be impossible to construct optimal reconstruction maps for certain problems, (vi) standard methods to improve reliability (e.g., regularization or adversarial training) may themselves lead to unstable problems. Our results trace these effects to the kernel of the forwards operator. They assert that such effects can be avoided only if information about the kernel is encoded into the reconstruction procedure. Based on this, this work aims to spur research into new ways to develop robust and reliable AI-inspired methods for inverse problems in imaging.



### A Robust Pose Transformational GAN for Pose Guided Person Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2001.01259v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01259v1)
- **Published**: 2020-01-05 15:32:35+00:00
- **Updated**: 2020-01-05 15:32:35+00:00
- **Authors**: Arnab Karmakar, Deepak Mishra
- **Comment**: Accepted in 7th National Conference on Computer Vision, Pattern
  Recognition, Image Processing and Graphics (NCVPRIPG 2019)
- **Journal**: None
- **Summary**: Generating photorealistic images of human subjects in any unseen pose have crucial applications in generating a complete appearance model of the subject. However, from a computer vision perspective, this task becomes significantly challenging due to the inability of modelling the data distribution conditioned on pose. Existing works use a complicated pose transformation model with various additional features such as foreground segmentation, human body parsing etc. to achieve robustness that leads to computational overhead. In this work, we propose a simple yet effective pose transformation GAN by utilizing the Residual Learning method without any additional feature learning to generate a given human image in any arbitrary pose. Using effective data augmentation techniques and cleverly tuning the model, we achieve robustness in terms of illumination, occlusion, distortion and scale. We present a detailed study, both qualitative and quantitative, to demonstrate the superiority of our model over the existing methods on two large datasets.



### FDFtNet: Facing Off Fake Images using Fake Detection Fine-tuning Network
- **Arxiv ID**: http://arxiv.org/abs/2001.01265v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01265v2)
- **Published**: 2020-01-05 16:04:17+00:00
- **Updated**: 2020-08-10 06:08:29+00:00
- **Authors**: Hyeonseong Jeon, Youngoh Bang, Simon S. Woo
- **Comment**: IFIP-Sec 2020
- **Journal**: None
- **Summary**: Creating fake images and videos such as "Deepfake" has become much easier these days due to the advancement in Generative Adversarial Networks (GANs). Moreover, recent research such as the few-shot learning can create highly realistic personalized fake images with only a few images. Therefore, the threat of Deepfake to be used for a variety of malicious intents such as propagating fake images and videos becomes prevalent. And detecting these machine-generated fake images has been quite challenging than ever. In this work, we propose a light-weight robust fine-tuning neural network-based classifier architecture called Fake Detection Fine-tuning Network (FDFtNet), which is capable of detecting many of the new fake face image generation models, and can be easily combined with existing image classification networks and finetuned on a few datasets. In contrast to many existing methods, our approach aims to reuse popular pre-trained models with only a few images for fine-tuning to effectively detect fake images. The core of our approach is to introduce an image-based self-attention module called Fine-Tune Transformer that uses only the attention module and the down-sampling layer. This module is added to the pre-trained model and fine-tuned on a few data to search for new sets of feature space to detect fake images. We experiment with our FDFtNet on the GANsbased dataset (Progressive Growing GAN) and Deepfake-based dataset (Deepfake and Face2Face) with a small input image resolution of 64x64 that complicates detection. Our FDFtNet achieves an overall accuracy of 90.29% in detecting fake images generated from the GANs-based dataset, outperforming the state-of-the-art.



### Self-Orthogonality Module: A Network Architecture Plug-in for Learning Orthogonal Filters
- **Arxiv ID**: http://arxiv.org/abs/2001.01275v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01275v2)
- **Published**: 2020-01-05 17:31:07+00:00
- **Updated**: 2020-01-17 18:10:58+00:00
- **Authors**: Ziming Zhang, Wenchi Ma, Yuanwei Wu, Guanghui Wang
- **Comment**: This version fixed the controversial expression in Section 2.2
- **Journal**: None
- **Summary**: In this paper, we investigate the empirical impact of orthogonality regularization (OR) in deep learning, either solo or collaboratively. Recent works on OR showed some promising results on the accuracy. In our ablation study, however, we do not observe such significant improvement from existing OR techniques compared with the conventional training based on weight decay, dropout, and batch normalization. To identify the real gain from OR, inspired by the locality sensitive hashing (LSH) in angle estimation, we propose to introduce an implicit self-regularization into OR to push the mean and variance of filter angles in a network towards 90 and 0 simultaneously to achieve (near) orthogonality among the filters, without using any other explicit regularization. Our regularization can be implemented as an architectural plug-in and integrated with an arbitrary network. We reveal that OR helps stabilize the training process and leads to faster convergence and better generalization.



### Automated Segmentation of Vertebrae on Lateral Chest Radiography Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.01277v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01277v1)
- **Published**: 2020-01-05 17:35:04+00:00
- **Updated**: 2020-01-05 17:35:04+00:00
- **Authors**: Sanket Badhe, Varun Singh, Joy Li, Paras Lakhani
- **Comment**: 10 pages, Accepted Poster presentation at Conference on Machine
  Intelligence in Medical Imaging 2018
- **Journal**: None
- **Summary**: The purpose of this study is to develop an automated algorithm for thoracic vertebral segmentation on chest radiography using deep learning. 124 de-identified lateral chest radiographs on unique patients were obtained. Segmentations of visible vertebrae were manually performed by a medical student and verified by a board-certified radiologist. 74 images were used for training, 10 for validation, and 40 were held out for testing. A U-Net deep convolutional neural network was employed for segmentation, using the sum of dice coefficient and binary cross-entropy as the loss function. On the test set, the algorithm demonstrated an average dice coefficient value of 90.5 and an average intersection-over-union (IoU) of 81.75. Deep learning demonstrates promise in the segmentation of vertebrae on lateral chest radiography.



### Deep Transfer Convolutional Neural Network and Extreme Learning Machine for Lung Nodule Diagnosis on CT images
- **Arxiv ID**: http://arxiv.org/abs/2001.01279v2
- **DOI**: 10.1016/j.knosys.2020.106230.
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.01279v2)
- **Published**: 2020-01-05 17:49:38+00:00
- **Updated**: 2020-04-28 10:36:35+00:00
- **Authors**: Xufeng Huang, Qiang Lei, Tingli Xie, Yahui Zhang, Zhen Hu, Qi Zhou
- **Comment**: Some content of the article needs to be kept secret
- **Journal**: Knowledge-Based Systems (2020) 106230
- **Summary**: Some content of the article needs to be kept secret



### Learning Global and Local Consistent Representations for Unsupervised Image Retrieval via Deep Graph Diffusion Networks
- **Arxiv ID**: http://arxiv.org/abs/2001.01284v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01284v2)
- **Published**: 2020-01-05 18:24:28+00:00
- **Updated**: 2020-06-11 19:53:53+00:00
- **Authors**: Zhiyong Dou, Haotian Cui, Lin Zhang, Bo Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Diffusion has shown great success in improving accuracy of unsupervised image retrieval systems by utilizing high-order structures of image manifold. However, existing diffusion methods suffer from three major limitations: 1) they usually rely on local structures without considering global manifold information; 2) they focus on improving pair-wise similarities within existing images input output transductively while lacking flexibility to learn representations for novel unseen instances inductively; 3) they fail to scale to large datasets due to prohibitive memory consumption and computational burden due to intrinsic high-order operations on the whole graph. In this paper, to address these limitations, we propose a novel method, Graph Diffusion Networks (GRAD-Net), that adopts graph neural networks (GNNs), a novel variant of deep learning algorithms on irregular graphs. GRAD-Net learns semantic representations by exploiting both local and global structures of image manifold in an unsupervised fashion. By utilizing sparse coding techniques, GRAD-Net not only preserves global information on the image manifold, but also enables scalable training and efficient querying. Experiments on several large benchmark datasets demonstrate effectiveness of our method over state-of-the-art diffusion algorithms for unsupervised image retrieval.



### General Partial Label Learning via Dual Bipartite Graph Autoencoder
- **Arxiv ID**: http://arxiv.org/abs/2001.01290v2
- **DOI**: 10.1609/aaai.v34i07.6621
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01290v2)
- **Published**: 2020-01-05 19:00:41+00:00
- **Updated**: 2021-09-09 14:40:19+00:00
- **Authors**: Brian Chen, Bo Wu, Alireza Zareian, Hanwang Zhang, Shih-Fu Chang
- **Comment**: 8 pages
- **Journal**: AAAI, vol. 34, no. 07, pp. 10502-10509, Apr. 2020
- **Summary**: We formulate a practical yet challenging problem: General Partial Label Learning (GPLL). Compared to the traditional Partial Label Learning (PLL) problem, GPLL relaxes the supervision assumption from instance-level -- a label set partially labels an instance -- to group-level: 1) a label set partially labels a group of instances, where the within-group instance-label link annotations are missing, and 2) cross-group links are allowed -- instances in a group may be partially linked to the label set from another group. Such ambiguous group-level supervision is more practical in real-world scenarios as additional annotation on the instance-level is no longer required, e.g., face-naming in videos where the group consists of faces in a frame, labeled by a name set in the corresponding caption. In this paper, we propose a novel graph convolutional network (GCN) called Dual Bipartite Graph Autoencoder (DB-GAE) to tackle the label ambiguity challenge of GPLL. First, we exploit the cross-group correlations to represent the instance groups as dual bipartite graphs: within-group and cross-group, which reciprocally complements each other to resolve the linking ambiguities. Second, we design a GCN autoencoder to encode and decode them, where the decodings are considered as the refined results. It is worth noting that DB-GAE is self-supervised and transductive, as it only uses the group-level supervision without a separate offline training stage. Extensive experiments on two real-world datasets demonstrate that DB-GAE significantly outperforms the best baseline over absolute 0.159 F1-score and 24.8% accuracy. We further offer analysis on various levels of label ambiguities.



### Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging
- **Arxiv ID**: http://arxiv.org/abs/2001.01293v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.01293v2)
- **Published**: 2020-01-05 19:17:32+00:00
- **Updated**: 2021-09-13 05:30:05+00:00
- **Authors**: Samet Akcay, Toby Breckon
- **Comment**: Published in Pattern Recognition
- **Journal**: None
- **Summary**: X-ray security screening is widely used to maintain aviation/transport security, and its significance poses a particular interest in automated screening systems. This paper aims to review computerised X-ray security imaging algorithms by taxonomising the field into conventional machine learning and contemporary deep learning applications. The first part briefly discusses the classical machine learning approaches utilised within X-ray security imaging, while the latter part thoroughly investigates the use of modern deep learning algorithms. The proposed taxonomy sub-categorises the use of deep learning approaches into supervised, semi-supervised and unsupervised learning, with a particular focus on object classification, detection, segmentation and anomaly detection tasks. The paper further explores well-established X-ray datasets and provides a performance benchmark. Based on the current and future trends in deep learning, the paper finally presents a discussion and future directions for X-ray security imagery.



### Agriculture-Vision: A Large Aerial Image Database for Agricultural Pattern Analysis
- **Arxiv ID**: http://arxiv.org/abs/2001.01306v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01306v2)
- **Published**: 2020-01-05 20:19:33+00:00
- **Updated**: 2020-03-19 04:13:08+00:00
- **Authors**: Mang Tik Chiu, Xingqian Xu, Yunchao Wei, Zilong Huang, Alexander Schwing, Robert Brunner, Hrant Khachatrian, Hovnatan Karapetyan, Ivan Dozier, Greg Rose, David Wilson, Adrian Tudor, Naira Hovakimyan, Thomas S. Huang, Honghui Shi
- **Comment**: CVPR 2020
- **Journal**: None
- **Summary**: The success of deep learning in visual recognition tasks has driven advancements in multiple fields of research. Particularly, increasing attention has been drawn towards its application in agriculture. Nevertheless, while visual pattern recognition on farmlands carries enormous economic values, little progress has been made to merge computer vision and crop sciences due to the lack of suitable agricultural image datasets. Meanwhile, problems in agriculture also pose new challenges in computer vision. For example, semantic segmentation of aerial farmland images requires inference over extremely large-size images with extreme annotation sparsity. These challenges are not present in most of the common object datasets, and we show that they are more challenging than many other aerial image datasets. To encourage research in computer vision for agriculture, we present Agriculture-Vision: a large-scale aerial farmland image dataset for semantic segmentation of agricultural patterns. We collected 94,986 high-quality aerial images from 3,432 farmlands across the US, where each image consists of RGB and Near-infrared (NIR) channels with resolution as high as 10 cm per pixel. We annotate nine types of field anomaly patterns that are most important to farmers. As a pilot study of aerial agricultural semantic segmentation, we perform comprehensive experiments using popular semantic segmentation models; we also propose an effective model designed for aerial agricultural pattern recognition. Our experiments demonstrate several challenges Agriculture-Vision poses to both the computer vision and agriculture communities. Future versions of this dataset will include even more aerial images, anomaly patterns and image channels. More information at https://www.agriculture-vision.com.



### Covering the News with (AI) Style
- **Arxiv ID**: http://arxiv.org/abs/2002.02369v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.02369v1)
- **Published**: 2020-01-05 22:57:51+00:00
- **Updated**: 2020-01-05 22:57:51+00:00
- **Authors**: Michele Merler, Cicero Nogueira dos Santos, Mauro Martino, Alfio M. Gliozzo, John R. Smith
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a multi-modal discriminative and generative frame-work capable of assisting humans in producing visual content re-lated to a given theme, starting from a collection of documents(textual, visual, or both). This framework can be used by edit or to generate images for articles, as well as books or music album covers. Motivated by a request from the The New York Times (NYT) seeking help to use AI to create art for their special section on Artificial Intelligence, we demonstrated the application of our system in producing such image.



### Convolutional Neural Networks with Intermediate Loss for 3D Super-Resolution of CT and MRI Scans
- **Arxiv ID**: http://arxiv.org/abs/2001.01330v4
- **DOI**: 10.1109/ACCESS.2020.2980266
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.01330v4)
- **Published**: 2020-01-05 23:21:40+00:00
- **Updated**: 2023-04-06 09:01:41+00:00
- **Authors**: Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae Verga
- **Comment**: Accepted in IEEE Access
- **Journal**: None
- **Summary**: CT scanners that are commonly-used in hospitals nowadays produce low-resolution images, up to 512 pixels in size. One pixel in the image corresponds to a one millimeter piece of tissue. In order to accurately segment tumors and make treatment plans, doctors need CT scans of higher resolution. The same problem appears in MRI. In this paper, we propose an approach for the single-image super-resolution of 3D CT or MRI scans. Our method is based on deep convolutional neural networks (CNNs) composed of 10 convolutional layers and an intermediate upscaling layer that is placed after the first 6 convolutional layers. Our first CNN, which increases the resolution on two axes (width and height), is followed by a second CNN, which increases the resolution on the third axis (depth). Different from other methods, we compute the loss with respect to the ground-truth high-resolution output right after the upscaling layer, in addition to computing the loss after the last convolutional layer. The intermediate loss forces our network to produce a better output, closer to the ground-truth. A widely-used approach to obtain sharp results is to add Gaussian blur using a fixed standard deviation. In order to avoid overfitting to a fixed standard deviation, we apply Gaussian smoothing with various standard deviations, unlike other approaches. We evaluate our method in the context of 2D and 3D super-resolution of CT and MRI scans from two databases, comparing it to relevant related works from the literature and baselines based on various interpolation schemes, using 2x and 4x scaling factors. The empirical results show that our approach attains superior results to all other methods. Moreover, our human annotation study reveals that both doctors and regular annotators chose our method in favor of Lanczos interpolation in 97.55% cases for 2x upscaling factor and in 96.69% cases for 4x upscaling factor.



