# Arxiv Papers in cs.CV on 2020-01-23
### Investigating naturalistic hand movements by behavior mining in long-term video and neural recordings
- **Arxiv ID**: http://arxiv.org/abs/2001.08349v2
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08349v2)
- **Published**: 2020-01-23 02:41:35+00:00
- **Updated**: 2020-06-19 22:52:49+00:00
- **Authors**: Satpreet H. Singh, Steven M. Peterson, Rajesh P. N. Rao, Bingni W. Brunton
- **Comment**: None
- **Journal**: None
- **Summary**: Recent technological advances in brain recording and artificial intelligence are propelling a new paradigm in neuroscience beyond the traditional controlled experiment. Rather than focusing on cued, repeated trials, naturalistic neuroscience studies neural processes underlying spontaneous behaviors performed in unconstrained settings. However, analyzing such unstructured data lacking a priori experimental design remains a significant challenge, especially when the data is multi-modal and long-term. Here we describe an automated approach for analyzing simultaneously recorded long-term, naturalistic electrocorticography (ECoG) and naturalistic behavior video data. We take a behavior-first approach to analyzing the long-term recordings. Using a combination of computer vision, discrete latent-variable modeling, and string pattern-matching on the behavioral video data, we find and annotate spontaneous human upper-limb movement events. We show results from our approach applied to data collected for 12 human subjects over 7--9 days for each subject. Our pipeline discovers and annotates over 40,000 instances of naturalistic human upper-limb movement events in the behavioral videos. Analysis of the simultaneously recorded brain data reveals neural signatures of movement that corroborate prior findings from traditional controlled experiments. We also prototype a decoder for a movement initiation detection task to demonstrate the efficacy of our pipeline as a source of training data for brain-computer interfacing applications. Our work addresses the unique data analysis challenges in studying naturalistic human behaviors, and contributes methods that may generalize to other neural recording modalities beyond ECoG. We publicly release our curated dataset, providing a resource to study naturalistic neural and behavioral variability at a scale not previously available.



### BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted Regularization Method
- **Arxiv ID**: http://arxiv.org/abs/2001.08357v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08357v2)
- **Published**: 2020-01-23 03:30:56+00:00
- **Updated**: 2020-02-22 03:00:10+00:00
- **Authors**: Xiaolong Ma, Zhengang Li, Yifan Gong, Tianyun Zhang, Wei Niu, Zheng Zhan, Pu Zhao, Jian Tang, Xue Lin, Bin Ren, Yanzhi Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Accelerating DNN execution on various resource-limited computing platforms has been a long-standing problem. Prior works utilize l1-based group lasso or dynamic regularization such as ADMM to perform structured pruning on DNN models to leverage the parallel computing architectures. However, both of the pruning dimensions and pruning methods lack universality, which leads to degraded performance and limited applicability. To solve the problem, we propose a new block-based pruning framework that comprises a general and flexible structured pruning dimension as well as a powerful and efficient reweighted regularization method. Our framework is universal, which can be applied to both CNNs and RNNs, implying complete support for the two major kinds of computation-intensive layers (i.e., CONV and FC layers). To complete all aspects of the pruning-for-acceleration task, we also integrate compiler-based code optimization into our framework that can perform DNN inference in a real-time manner. To the best of our knowledge, it is the first time that the weight pruning framework achieves universal coverage for both CNNs and RNNs with real-time mobile acceleration and no accuracy compromise.



### Continual Local Replacement for Few-shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08366v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08366v2)
- **Published**: 2020-01-23 04:26:21+00:00
- **Updated**: 2020-03-10 13:21:57+00:00
- **Authors**: Canyu Le, Zhonggui Chen, Xihan Wei, Biao Wang, Lei Zhang
- **Comment**: Update experiment results and reorganize paper writting
- **Journal**: None
- **Summary**: The goal of few-shot learning is to learn a model that can recognize novel classes based on one or few training data. It is challenging mainly due to two aspects: (1) it lacks good feature representation of novel classes; (2) a few of labeled data could not accurately represent the true data distribution and thus it's hard to learn a good decision function for classification. In this work, we use a sophisticated network architecture to learn better feature representation and focus on the second issue. A novel continual local replacement strategy is proposed to address the data deficiency problem. It takes advantage of the content in unlabeled images to continually enhance labeled ones. Specifically, a pseudo labeling method is adopted to constantly select semantically similar images on the fly. Original labeled images will be locally replaced by the selected images for the next epoch training. In this way, the model can directly learn new semantic information from unlabeled images and the capacity of supervised signals in the embedding space can be significantly enlarged. This allows the model to improve generalization and learn a better decision boundary for classification. Our method is conceptually simple and easy to implement. Extensive experiments demonstrate that it can achieve state-of-the-art results on various few-shot image recognition benchmarks.



### Text Extraction and Restoration of Old Handwritten Documents
- **Arxiv ID**: http://arxiv.org/abs/2001.08742v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08742v1)
- **Published**: 2020-01-23 05:42:39+00:00
- **Updated**: 2020-01-23 05:42:39+00:00
- **Authors**: Mayank Wadhwani, Debapriya Kundu, Deepayan Chakraborty, Bhabatosh Chanda
- **Comment**: None
- **Journal**: None
- **Summary**: Image restoration is very crucial computer vision task. This paper describes two novel methods for the restoration of old degraded handwritten documents using deep neural network. In addition to that, a small-scale dataset of 26 heritage letters images is introduced. The ground truth data to train the desired network is generated semi automatically involving a pragmatic combination of color transformation, Gaussian mixture model based segmentation and shape correction by using mathematical morphological operators. In the first approach, a deep neural network has been used for text extraction from the document image and later background reconstruction has been done using Gaussian mixture modeling. But Gaussian mixture modelling requires to set parameters manually, to alleviate this we propose a second approach where the background reconstruction and foreground extraction (which which includes extracting text with its original colour) both has been done using deep neural network. Experiments demonstrate that the proposed systems perform well on handwritten document images with severe degradations, even when trained with small dataset. Hence, the proposed methods are ideally suited for digital heritage preservation repositories. It is worth mentioning that, these methods can be extended easily for printed degraded documents.



### Adaptation of a deep learning malignancy model from full-field digital mammography to digital breast tomosynthesis
- **Arxiv ID**: http://arxiv.org/abs/2001.08381v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08381v1)
- **Published**: 2020-01-23 05:44:11+00:00
- **Updated**: 2020-01-23 05:44:11+00:00
- **Authors**: Sadanand Singh, Thomas Paul Matthews, Meet Shah, Brent Mombourquette, Trevor Tsue, Aaron Long, Ranya Almohsen, Stefano Pedemonte, Jason Su
- **Comment**: SPIE Medical Imaging 2020
- **Journal**: None
- **Summary**: Mammography-based screening has helped reduce the breast cancer mortality rate, but has also been associated with potential harms due to low specificity, leading to unnecessary exams or procedures, and low sensitivity. Digital breast tomosynthesis (DBT) improves on conventional mammography by increasing both sensitivity and specificity and is becoming common in clinical settings. However, deep learning (DL) models have been developed mainly on conventional 2D full-field digital mammography (FFDM) or scanned film images. Due to a lack of large annotated DBT datasets, it is difficult to train a model on DBT from scratch. In this work, we present methods to generalize a model trained on FFDM images to DBT images. In particular, we use average histogram matching (HM) and DL fine-tuning methods to generalize a FFDM model to the 2D maximum intensity projection (MIP) of DBT images. In the proposed approach, the differences between the FFDM and DBT domains are reduced via HM and then the base model, which was trained on abundant FFDM images, is fine-tuned. When evaluating on image patches extracted around identified findings, we are able to achieve similar areas under the receiver operating characteristic curve (ROC AUC) of $\sim 0.9$ for FFDM and $\sim 0.85$ for MIP images, as compared to a ROC AUC of $\sim 0.75$ when tested directly on MIP images.



### A Hypersensitive Breast Cancer Detector
- **Arxiv ID**: http://arxiv.org/abs/2001.08382v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08382v1)
- **Published**: 2020-01-23 05:44:39+00:00
- **Updated**: 2020-01-23 05:44:39+00:00
- **Authors**: Stefano Pedemonte, Brent Mombourquette, Alexis Goh, Trevor Tsue, Aaron Long, Sadanand Singh, Thomas Paul Matthews, Meet Shah, Jason Su
- **Comment**: SPIE Medical Imaging 2020
- **Journal**: None
- **Summary**: Early detection of breast cancer through screening mammography yields a 20-35% increase in survival rate; however, there are not enough radiologists to serve the growing population of women seeking screening mammography. Although commercial computer aided detection (CADe) software has been available to radiologists for decades, it has failed to improve the interpretation of full-field digital mammography (FFDM) images due to its low sensitivity over the spectrum of findings. In this work, we leverage a large set of FFDM images with loose bounding boxes of mammographically significant findings to train a deep learning detector with extreme sensitivity. Building upon work from the Hourglass architecture, we train a model that produces segmentation-like images with high spatial resolution, with the aim of producing 2D Gaussian blobs centered on ground-truth boxes. We replace the pixel-wise $L_2$ norm with a weak-supervision loss designed to achieve high sensitivity, asymmetrically penalizing false positives and false negatives while softening the noise of the loose bounding boxes by permitting a tolerance in misaligned predictions. The resulting system achieves a sensitivity for malignant findings of 0.99 with only 4.8 false positive markers per image. When utilized in a CADe system, this model could enable a novel workflow where radiologists can focus their attention with trust on only the locations proposed by the model, expediting the interpretation process and bringing attention to potential findings that could otherwise have been missed. Due to its nearly perfect sensitivity, the proposed detector can also be used as a high-performance proposal generator in two-stage detection systems.



### A Multi-site Study of a Breast Density Deep Learning Model for Full-field Digital Mammography Images and Synthetic Mammography Images
- **Arxiv ID**: http://arxiv.org/abs/2001.08383v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, 68T45, I.5.4; J.3; I.2.10; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/2001.08383v2)
- **Published**: 2020-01-23 05:51:27+00:00
- **Updated**: 2020-10-02 20:07:03+00:00
- **Authors**: Thomas P. Matthews, Sadanand Singh, Brent Mombourquette, Jason Su, Meet P. Shah, Stefano Pedemonte, Aaron Long, David Maffit, Jenny Gurney, Rodrigo Morales Hoil, Nikita Ghare, Douglas Smith, Stephen M. Moore, Susan C. Marks, Richard L. Wahl
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose: To develop a Breast Imaging Reporting and Data System (BI-RADS) breast density deep learning (DL) model in a multi-site setting for synthetic two-dimensional mammography (SM) images derived from digital breast tomosynthesis exams using full-field digital mammography (FFDM) images and limited SM data.   Materials and Methods: A DL model was trained to predict BI-RADS breast density using FFDM images acquired from 2008 to 2017 (Site 1: 57492 patients, 187627 exams, 750752 images) for this retrospective study. The FFDM model was evaluated using SM datasets from two institutions (Site 1: 3842 patients, 3866 exams, 14472 images, acquired from 2016 to 2017; Site 2: 7557 patients, 16283 exams, 63973 images, 2015 to 2019). Each of the three datasets were then split into training, validation, and test datasets. Adaptation methods were investigated to improve performance on the SM datasets and the effect of dataset size on each adaptation method is considered. Statistical significance was assessed using confidence intervals (CI), estimated by bootstrapping.   Results: Without adaptation, the model demonstrated substantial agreement with the original reporting radiologists for all three datasets (Site 1 FFDM: linearly-weighted $\kappa_w$ = 0.75 [95% CI: 0.74, 0.76]; Site 1 SM: $\kappa_w$ = 0.71 [95% CI: 0.64, 0.78]; Site 2 SM: $\kappa_w$ = 0.72 [95% CI: 0.70, 0.75]). With adaptation, performance improved for Site 2 (Site 1: $\kappa_w$ = 0.72 [95% CI: 0.66, 0.79], 0.71 vs 0.72, P = .80; Site 2: $\kappa_w$ = 0.79 [95% CI: 0.76, 0.81], 0.72 vs 0.79, P $<$ .001) using only 500 SM images from that site.   Conclusion: A BI-RADS breast density DL model demonstrated strong performance on FFDM and SM images from two institutions without training on SM images and improved using few SM images.



### Dense Residual Network: Enhancing Global Dense Feature Flow for Character Recognition
- **Arxiv ID**: http://arxiv.org/abs/2001.09021v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.09021v4)
- **Published**: 2020-01-23 06:55:08+00:00
- **Updated**: 2021-02-09 02:35:30+00:00
- **Authors**: Zhao Zhang, Zemin Tang, Yang Wang, Zheng Zhang, Choujun Zhan, Zhengjun Zha, Meng Wang
- **Comment**: Please cite this work as: Zhao Zhang, Zemin Tang, Yang Wang, Zheng
  Zhang, Choujun Zhan, Zhengjun Zha and Meng Wang, "Dense Residual Network:
  Enhancing Global Dense Feature Flow for Character Recognition," Neural
  Networks (NN), Feb 2021. arXiv admin note: text overlap with arXiv:1912.07016
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (CNNs), such as Dense Convolutional Networks (DenseNet), have achieved great success for image representation by discovering deep hierarchical information. However, most existing networks simply stacks the convolutional layers and hence failing to fully discover local and global feature information among layers. In this paper, we mainly explore how to enhance the local and global dense feature flow by exploiting hierarchical features fully from all the convolution layers. Technically, we propose an efficient and effective CNN framework, i.e., Fast Dense Residual Network (FDRN), for text recognition. To construct FDRN, we propose a new fast residual dense block (f-RDB) to retain the ability of local feature fusion and local residual learning of original RDB, which can reduce the computing efforts at the same time. After fully learning local residual dense features, we utilize the sum operation and several f-RDBs to define a new block termed global dense block (GDB) by imitating the construction of dense blocks to learn global dense residual features adaptively in a holistic way. Finally, we use two convolution layers to construct a down-sampling block to reduce the global feature size and extract deeper features. Extensive simulations show that FDRN obtains the enhanced recognition results, compared with other related models.



### Semi-DerainGAN: A New Semi-supervised Single Image Deraining Network
- **Arxiv ID**: http://arxiv.org/abs/2001.08388v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08388v3)
- **Published**: 2020-01-23 07:01:30+00:00
- **Updated**: 2021-04-07 08:27:50+00:00
- **Authors**: Yanyan Wei, Zhao Zhang, Yang Wang, Haijun Zhang, Mingbo Zhao, Mingliang Xu, Meng Wang
- **Comment**: Please cite this work as: Yanyan Wei, Zhao Zhang, Yang Wang, Haijun
  Zhang, Mingbo Zhao, Mingliang Xu and Meng Wang, "Semi-DerainGAN: A New
  Semi-supervised Single Image Deraining Network," In: Proceedings of the IEEE
  International Conference on Multimedia and Expo (ICME), July 2021
- **Journal**: None
- **Summary**: Removing the rain streaks from single image is still a challenging task, since the shapes and directions of rain streaks in the synthetic datasets are very different from real images. Although supervised deep deraining networks have obtained impressive results on synthetic datasets, they still cannot obtain satisfactory results on real images due to weak generalization of rain removal capacity, i.e., the pre-trained models usually cannot handle new shapes and directions that may lead to over-derained/under-derained results. In this paper, we propose a new semi-supervised GAN-based deraining network termed Semi-DerainGAN, which can use both synthetic and real rainy images in a uniform network using two supervised and unsupervised processes. Specifically, a semi-supervised rain streak learner termed SSRML sharing the same parameters of both processes is derived, which makes the real images contribute more rain streak information. To deliver better deraining results, we design a paired discriminator for distinguishing the real pairs from fake pairs. Note that we also contribute a new real-world rainy image dataset Real200 to alleviate the difference between the synthetic and real image do-mains. Extensive results on public datasets show that our model can obtain competitive performance, especially on real images.



### A One-Shot Learning Framework for Assessment of Fibrillar Collagen from Second Harmonic Generation Images of an Infarcted Myocardium
- **Arxiv ID**: http://arxiv.org/abs/2001.08395v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2001.08395v2)
- **Published**: 2020-01-23 07:35:56+00:00
- **Updated**: 2020-01-30 04:49:13+00:00
- **Authors**: Qun Liu, Supratik Mukhopadhyay, Maria Ximena Bastidas Rodriguez, Xing Fu, Sushant Sahu, David Burk, Manas Gartia
- **Comment**: Paper was accepted at the IEEE International Symposium on Biomedical
  Imaging (ISBI 2020)
- **Journal**: None
- **Summary**: Myocardial infarction (MI) is a scientific term that refers to heart attack. In this study, we infer highly relevant second harmonic generation (SHG) cues from collagen fibers exhibiting highly non-centrosymmetric assembly together with two-photon excited cellular autofluorescence in infarcted mouse heart to quantitatively probe fibrosis, especially targeted at an early stage after MI. We present a robust one-shot machine learning algorithm that enables determination of 2D assembly of collagen with high spatial resolution along with its structural arrangement in heart tissues post-MI with spectral specificity and sensitivity. Detection, evaluation, and precise quantification of fibrosis extent at early stage would guide one to develop treatment therapies that may prevent further progression and determine heart transplant needs for patient survival.



### Fast, Compact and Highly Scalable Visual Place Recognition through Sequence-based Matching of Overloaded Representations
- **Arxiv ID**: http://arxiv.org/abs/2001.08434v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.08434v2)
- **Published**: 2020-01-23 10:31:28+00:00
- **Updated**: 2020-03-12 12:51:41+00:00
- **Authors**: Sourav Garg, Michael Milford
- **Comment**: 8 pages, 4 figures, Accepted for oral presentation at the 2020 IEEE
  International Conference on Robotics and Automation
- **Journal**: None
- **Summary**: Visual place recognition algorithms trade off three key characteristics: their storage footprint, their computational requirements, and their resultant performance, often expressed in terms of recall rate. Significant prior work has investigated highly compact place representations, sub-linear computational scaling and sub-linear storage scaling techniques, but have always involved a significant compromise in one or more of these regards, and have only been demonstrated on relatively small datasets. In this paper we present a novel place recognition system which enables for the first time the combination of ultra-compact place representations, near sub-linear storage scaling and extremely lightweight compute requirements. Our approach exploits the inherently sequential nature of much spatial data in the robotics domain and inverts the typical target criteria, through intentionally coarse scalar quantization-based hashing that leads to more collisions but is resolved by sequence-based matching. For the first time, we show how effective place recognition rates can be achieved on a new very large 10 million place dataset, requiring only 8 bytes of storage per place and 37K unitary operations to achieve over 50% recall for matching a sequence of 100 frames, where a conventional state-of-the-art approach both consumes 1300 times more compute and fails catastrophically. We present analysis investigating the effectiveness of our hashing overload approach under varying sizes of quantized vector length, comparison of near miss matches with the actual match selections and characterise the effect of variance re-scaling of data on quantization.



### Ada-LISTA: Learned Solvers Adaptive to Varying Models
- **Arxiv ID**: http://arxiv.org/abs/2001.08456v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08456v2)
- **Published**: 2020-01-23 11:34:03+00:00
- **Updated**: 2020-02-19 14:28:35+00:00
- **Authors**: Aviad Aberdam, Alona Golts, Michael Elad
- **Comment**: None
- **Journal**: None
- **Summary**: Neural networks that are based on unfolding of an iterative solver, such as LISTA (learned iterative soft threshold algorithm), are widely used due to their accelerated performance. Nevertheless, as opposed to non-learned solvers, these networks are trained on a certain dictionary, and therefore they are inapplicable for varying model scenarios. This work introduces an adaptive learned solver, termed Ada-LISTA, which receives pairs of signals and their corresponding dictionaries as inputs, and learns a universal architecture to serve them all. We prove that this scheme is guaranteed to solve sparse coding in linear rate for varying models, including dictionary perturbations and permutations. We also provide an extensive numerical study demonstrating its practical adaptation capabilities. Finally, we deploy Ada-LISTA to natural image inpainting, where the patch-masks vary spatially, thus requiring such an adaptation.



### Segmentation of Retinal Low-Cost Optical Coherence Tomography Images using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08480v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08480v1)
- **Published**: 2020-01-23 12:55:53+00:00
- **Updated**: 2020-01-23 12:55:53+00:00
- **Authors**: Timo Kepp, Helge Sudkamp, Claus von der Burchard, Hendrik Schenke, Peter Koch, Gereon Hüttmann, Johann Roider, Mattias P. Heinrich, Heinz Handels
- **Comment**: Accepted for SPIE Medical Imaging 2020: Computer-Aided Diagnosis
- **Journal**: None
- **Summary**: The treatment of age-related macular degeneration (AMD) requires continuous eye exams using optical coherence tomography (OCT). The need for treatment is determined by the presence or change of disease-specific OCT-based biomarkers. Therefore, the monitoring frequency has a significant influence on the success of AMD therapy. However, the monitoring frequency of current treatment schemes is not individually adapted to the patient and therefore often insufficient. While a higher monitoring frequency would have a positive effect on the success of treatment, in practice it can only be achieved with a home monitoring solution. One of the key requirements of a home monitoring OCT system is a computer-aided diagnosis to automatically detect and quantify pathological changes using specific OCT-based biomarkers. In this paper, for the first time, retinal scans of a novel self-examination low-cost full-field OCT (SELF-OCT) are segmented using a deep learning-based approach. A convolutional neural network (CNN) is utilized to segment the total retina as well as pigment epithelial detachments (PED). It is shown that the CNN-based approach can segment the retina with high accuracy, whereas the segmentation of the PED proves to be challenging. In addition, a convolutional denoising autoencoder (CDAE) refines the CNN prediction, which has previously learned retinal shape information. It is shown that the CDAE refinement can correct segmentation errors caused by artifacts in the OCT image.



### Learning Object Placements For Relational Instructions by Hallucinating Scene Representations
- **Arxiv ID**: http://arxiv.org/abs/2001.08481v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08481v2)
- **Published**: 2020-01-23 12:58:50+00:00
- **Updated**: 2020-02-21 18:14:11+00:00
- **Authors**: Oier Mees, Alp Emek, Johan Vertens, Wolfram Burgard
- **Comment**: Accepted at the 2020 IEEE International Conference on Robotics and
  Automation (ICRA). Video at https://www.youtube.com/watch?v=zaZkHTWFMKM
- **Journal**: None
- **Summary**: Robots coexisting with humans in their environment and performing services for them need the ability to interact with them. One particular requirement for such robots is that they are able to understand spatial relations and can place objects in accordance with the spatial relations expressed by their user. In this work, we present a convolutional neural network for estimating pixelwise object placement probabilities for a set of spatial relations from a single input image. During training, our network receives the learning signal by classifying hallucinated high-level scene representations as an auxiliary task. Unlike previous approaches, our method does not require ground truth data for the pixelwise relational probabilities or 3D models of the objects, which significantly expands the applicability in practical applications. Our results obtained using real-world data and human-robot experiments demonstrate the effectiveness of our method in reasoning about the best way to place objects to reproduce a spatial relation. Videos of our experiments can be found at https://youtu.be/zaZkHTWFMKM



### A Large Scale Event-based Detection Dataset for Automotive
- **Arxiv ID**: http://arxiv.org/abs/2001.08499v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08499v3)
- **Published**: 2020-01-23 13:40:51+00:00
- **Updated**: 2020-01-31 13:35:45+00:00
- **Authors**: Pierre de Tournemire, Davide Nitti, Etienne Perot, Davide Migliore, Amos Sironi
- **Comment**: 8 pages, 29 images
- **Journal**: None
- **Summary**: We introduce the first very large detection dataset for event cameras. The dataset is composed of more than 39 hours of automotive recordings acquired with a 304x240 ATIS sensor. It contains open roads and very diverse driving scenarios, ranging from urban, highway, suburbs and countryside scenes, as well as different weather and illumination conditions. Manual bounding box annotations of cars and pedestrians contained in the recordings are also provided at a frequency between 1 and 4Hz, yielding more than 255,000 labels in total. We believe that the availability of a labeled dataset of this size will contribute to major advances in event-based vision tasks such as object detection and classification. We also expect benefits in other tasks such as optical flow, structure from motion and tracking, where for example, the large amount of data can be leveraged by self-supervised learning methods.



### Filter Sketch for Network Pruning
- **Arxiv ID**: http://arxiv.org/abs/2001.08514v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08514v4)
- **Published**: 2020-01-23 13:57:08+00:00
- **Updated**: 2021-05-25 03:12:53+00:00
- **Authors**: Mingbao Lin, Liujuan Cao, Shaojie Li, Qixiang Ye, Yonghong Tian, Jianzhuang Liu, Qi Tian, Rongrong Ji
- **Comment**: Accepted by IEEE Transactions on Neural Networks and Learning Systems
  (IEEE TNNLS)
- **Journal**: None
- **Summary**: We propose a novel network pruning approach by information preserving of pre-trained network weights (filters). Network pruning with the information preserving is formulated as a matrix sketch problem, which is efficiently solved by the off-the-shelf Frequent Direction method. Our approach, referred to as FilterSketch, encodes the second-order information of pre-trained weights, which enables the representation capacity of pruned networks to be recovered with a simple fine-tuning procedure. FilterSketch requires neither training from scratch nor data-driven iterative optimization, leading to a several-orders-of-magnitude reduction of time cost in the optimization of pruning. Experiments on CIFAR-10 show that FilterSketch reduces 63.3% of FLOPs and prunes 59.9% of network parameters with negligible accuracy cost for ResNet-110. On ILSVRC-2012, it reduces 45.5% of FLOPs and removes 43.0% of parameters with only 0.69% accuracy drop for ResNet-50. Our code and pruned models can be found at https://github.com/lmbxmu/FilterSketch.



### DCT-Conv: Coding filters in convolutional networks with Discrete Cosine Transform
- **Arxiv ID**: http://arxiv.org/abs/2001.08517v4
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08517v4)
- **Published**: 2020-01-23 13:58:17+00:00
- **Updated**: 2020-04-07 10:59:07+00:00
- **Authors**: Karol Chęciński, Paweł Wawrzyński
- **Comment**: 6 pages, 2 figures, submitted for IJCNN 2020
- **Journal**: None
- **Summary**: Convolutional neural networks are based on a huge number of trained weights. Consequently, they are often data-greedy, sensitive to overtraining, and learn slowly. We follow the line of research in which filters of convolutional neural layers are determined on the basis of a smaller number of trained parameters. In this paper, the trained parameters define a frequency spectrum which is transformed into convolutional filters with Inverse Discrete Cosine Transform (IDCT, the same is applied in decompression from JPEG). We analyze how switching off selected components of the spectra, thereby reducing the number of trained weights of the network, affects its performance. Our experiments show that coding the filters with trained DCT parameters leads to improvement over traditional convolution. Also, the performance of the networks modified this way decreases very slowly with the increasing extent of switching off these parameters. In some experiments, a good performance is observed when even 99.9% of these parameters are switched off.



### Information Compensation for Deep Conditional Generative Networks
- **Arxiv ID**: http://arxiv.org/abs/2001.08559v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08559v3)
- **Published**: 2020-01-23 14:39:53+00:00
- **Updated**: 2022-03-06 07:28:58+00:00
- **Authors**: Zehao Wang, Kaili Wang, Tinne Tuytelaars, Jose Oramas
- **Comment**: I think my previous work during master study is too naive
- **Journal**: None
- **Summary**: In recent years, unsupervised/weakly-supervised conditional generative adversarial networks (GANs) have achieved many successes on the task of modeling and generating data. However, one of their weaknesses lies in their poor ability to separate, or disentangle, the different factors that characterize the representation encoded in their latent space. To address this issue, we propose a novel structure for unsupervised conditional GANs powered by a novel Information Compensation Connection (IC-Connection). The proposed IC-Connection enables GANs to compensate for information loss incurred during deconvolution operations. In addition, to quantify the degree of disentanglement on both discrete and continuous latent variables, we design a novel evaluation procedure. Our empirical results suggest that our method achieves better disentanglement compared to the state-of-the-art GANs in a conditional generation setting.



### Channel Pruning via Automatic Structure Search
- **Arxiv ID**: http://arxiv.org/abs/2001.08565v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08565v3)
- **Published**: 2020-01-23 14:51:19+00:00
- **Updated**: 2020-06-29 01:52:28+00:00
- **Authors**: Mingbao Lin, Rongrong Ji, Yuxin Zhang, Baochang Zhang, Yongjian Wu, Yonghong Tian
- **Comment**: Accepted by IJCAI2020. SOLO copyright holder is IJCAI (International
  Joint Conferences on Artificial Intelligence)
- **Journal**: None
- **Summary**: Channel pruning is among the predominant approaches to compress deep neural networks. To this end, most existing pruning methods focus on selecting channels (filters) by importance/optimization or regularization based on rule-of-thumb designs, which defects in sub-optimal pruning. In this paper, we propose a new channel pruning method based on artificial bee colony algorithm (ABC), dubbed as ABCPruner, which aims to efficiently find optimal pruned structure, i.e., channel number in each layer, rather than selecting "important" channels as previous works did. To solve the intractably huge combinations of pruned structure for deep networks, we first propose to shrink the combinations where the preserved channels are limited to a specific space, thus the combinations of pruned structure can be significantly reduced. And then, we formulate the search of optimal pruned structure as an optimization problem and integrate the ABC algorithm to solve it in an automatic manner to lessen human interference. ABCPruner has been demonstrated to be more effective, which also enables the fine-tuning to be conducted efficiently in an end-to-end manner. The source codes can be available at https://github.com/lmbxmu/ABCPruner.



### Observer variation-aware medical image segmentation by combining deep learning and surrogate-assisted genetic algorithms
- **Arxiv ID**: http://arxiv.org/abs/2001.08552v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08552v1)
- **Published**: 2020-01-23 14:51:40+00:00
- **Updated**: 2020-01-23 14:51:40+00:00
- **Authors**: Arkadiy Dushatskiy, Adriënne M. Mendrik, Peter A. N. Bosman, Tanja Alderliesten
- **Comment**: 11 pages, 5 figures, SPIE Medical Imaging Conference - 2020
- **Journal**: None
- **Summary**: There has recently been great progress in automatic segmentation of medical images with deep learning algorithms. In most works observer variation is acknowledged to be a problem as it makes training data heterogeneous but so far no attempts have been made to explicitly capture this variation. Here, we propose an approach capable of mimicking different styles of segmentation, which potentially can improve quality and clinical acceptance of automatic segmentation methods. In this work, instead of training one neural network on all available data, we train several neural networks on subgroups of data belonging to different segmentation variations separately. Because a priori it may be unclear what styles of segmentation exist in the data and because different styles do not necessarily map one-on-one to different observers, the subgroups should be automatically determined. We achieve this by searching for the best data partition with a genetic algorithm. Therefore, each network can learn a specific style of segmentation from grouped training data. We provide proof of principle results for open-sourced prostate segmentation MRI data with simulated observer variations. Our approach provides an improvement of up to 23% (depending on simulated variations) in terms of Dice and surface Dice coefficients compared to one network trained on all data.



### Detecting Deficient Coverage in Colonoscopies
- **Arxiv ID**: http://arxiv.org/abs/2001.08589v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08589v3)
- **Published**: 2020-01-23 15:12:33+00:00
- **Updated**: 2020-03-29 09:42:05+00:00
- **Authors**: Daniel Freedman, Yochai Blau, Liran Katzir, Amit Aides, Ilan Shimshoni, Danny Veikherman, Tomer Golany, Ariel Gordon, Greg Corrado, Yossi Matias, Ehud Rivlin
- **Comment**: None
- **Journal**: None
- **Summary**: Colonoscopy is the tool of choice for preventing Colorectal Cancer, by detecting and removing polyps before they become cancerous. However, colonoscopy is hampered by the fact that endoscopists routinely miss 22-28% of polyps. While some of these missed polyps appear in the endoscopist's field of view, others are missed simply because of substandard coverage of the procedure, i.e. not all of the colon is seen. This paper attempts to rectify the problem of substandard coverage in colonoscopy through the introduction of the C2D2 (Colonoscopy Coverage Deficiency via Depth) algorithm which detects deficient coverage, and can thereby alert the endoscopist to revisit a given area. More specifically, C2D2 consists of two separate algorithms: the first performs depth estimation of the colon given an ordinary RGB video stream; while the second computes coverage given these depth estimates. Rather than compute coverage for the entire colon, our algorithm computes coverage locally, on a segment-by-segment basis; C2D2 can then indicate in real-time whether a particular area of the colon has suffered from deficient coverage, and if so the endoscopist can return to that area. Our coverage algorithm is the first such algorithm to be evaluated in a large-scale way; while our depth estimation technique is the first calibration-free unsupervised method applied to colonoscopies. The C2D2 algorithm achieves state of the art results in the detection of deficient coverage. On synthetic sequences with ground truth, it is 2.4 times more accurate than human experts; while on real sequences, C2D2 achieves a 93.0% agreement with experts.



### Weakly-Supervised Lesion Segmentation on CT Scans using Co-Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2001.08590v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08590v1)
- **Published**: 2020-01-23 15:15:53+00:00
- **Updated**: 2020-01-23 15:15:53+00:00
- **Authors**: Vatsal Agarwal, Youbao Tang, Jing Xiao, Ronald M. Summers
- **Comment**: None
- **Journal**: None
- **Summary**: Lesion segmentation on computed tomography (CT) scans is an important step for precisely monitoring changes in lesion/tumor growth. This task, however, is very challenging since manual segmentation is prohibitively time-consuming, expensive, and requires professional knowledge. Current practices rely on an imprecise substitute called response evaluation criteria in solid tumors (RECIST). Although these markers lack detailed information about the lesion regions, they are commonly found in hospitals' picture archiving and communication systems (PACS). Thus, these markers have the potential to serve as a powerful source of weak-supervision for 2D lesion segmentation. To approach this problem, this paper proposes a convolutional neural network (CNN) based weakly-supervised lesion segmentation method, which first generates the initial lesion masks from the RECIST measurements and then utilizes co-segmentation to leverage lesion similarities and refine the initial masks. In this work, an attention-based co-segmentation model is adopted due to its ability to learn more discriminative features from a pair of images. Experimental results on the NIH DeepLesion dataset demonstrate that the proposed co-segmentation approach significantly improves lesion segmentation performance, e.g the Dice score increases about 4.0% (from 85.8% to 89.8%).



### CNN-CASS: CNN for Classification of Coronary Artery Stenosis Score in MPR Images
- **Arxiv ID**: http://arxiv.org/abs/2001.08593v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08593v1)
- **Published**: 2020-01-23 15:20:22+00:00
- **Updated**: 2020-01-23 15:20:22+00:00
- **Authors**: Mariia Dobko, Bohdan Petryshak, Oles Dobosevych
- **Comment**: To be published in CVWW 2020 proceedings
- **Journal**: 25th Computer Vision Winter Workshop, 2020
- **Summary**: To decrease patient waiting time for diagnosis of the Coronary Artery Disease, automatic methods are applied to identify its severity using Coronary Computed Tomography Angiography scans or extracted Multiplanar Reconstruction (MPR) images, giving doctors a second-opinion on the priority of each case. The main disadvantage of previous studies is the lack of large set of data that could guarantee their reliability. Another limitation is the usage of handcrafted features requiring manual preprocessing, such as centerline extraction. We overcome both limitations by applying a different automated approach based on ShuffleNet V2 network architecture and testing it on the proposed collected dataset of MPR images, which is bigger than any other used in this field before. We also omit centerline extraction step and train and test our model using whole curved MPR images of 708 and 105 patients, respectively. The model predicts one of three classes: 'no stenosis' for normal, 'non-significant' - 1-50% of stenosis detected, 'significant' - more than 50% of stenosis. We demonstrate model's interpretability through visualization of the most important features selected by the network. For stenosis score classification, the method shows improved performance comparing to previous works, achieving 80% accuracy on the patient level. Our code is publicly available.



### Deformation-aware Unpaired Image Translation for Pose Estimation on Laboratory Animals
- **Arxiv ID**: http://arxiv.org/abs/2001.08601v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08601v1)
- **Published**: 2020-01-23 15:34:11+00:00
- **Updated**: 2020-01-23 15:34:11+00:00
- **Authors**: Siyuan Li, Semih Günel, Mirela Ostrek, Pavan Ramdya, Pascal Fua, Helge Rhodin
- **Comment**: None
- **Journal**: None
- **Summary**: Our goal is to capture the pose of neuroscience model organisms, without using any manual supervision, to be able to study how neural circuits orchestrate behaviour. Human pose estimation attains remarkable accuracy when trained on real or simulated datasets consisting of millions of frames. However, for many applications simulated models are unrealistic and real training datasets with comprehensive annotations do not exist. We address this problem with a new sim2real domain transfer method. Our key contribution is the explicit and independent modeling of appearance, shape and poses in an unpaired image translation framework. Our model lets us train a pose estimator on the target domain by transferring readily available body keypoint locations from the source domain to generated target images. We compare our approach with existing domain transfer methods and demonstrate improved pose estimation accuracy on Drosophila melanogaster (fruit fly), Caenorhabditis elegans (worm) and Danio rerio (zebrafish), without requiring any manual annotation on the target domain and despite using simplistic off-the-shelf animal characters for simulation, or simple geometric shapes as models. Our new datasets, code, and trained models will be published to support future neuroscientific studies.



### SPACE: Structured Compression and Sharing of Representational Space for Continual Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08650v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08650v4)
- **Published**: 2020-01-23 16:40:56+00:00
- **Updated**: 2021-02-03 06:23:33+00:00
- **Authors**: Gobinda Saha, Isha Garg, Aayush Ankit, Kaushik Roy
- **Comment**: The first two authors contributed equally to this paper
- **Journal**: None
- **Summary**: Humans learn adaptively and efficiently throughout their lives. However, incrementally learning tasks causes artificial neural networks to overwrite relevant information learned about older tasks, resulting in 'Catastrophic Forgetting'. Efforts to overcome this phenomenon often utilize resources poorly, for instance, by growing the network architecture or needing to save parametric importance scores, or violate data privacy between tasks. To tackle this, we propose SPACE, an algorithm that enables a network to learn continually and efficiently by partitioning the learnt space into a Core space, that serves as the condensed knowledge base over previously learned tasks, and a Residual space, which is akin to a scratch space for learning the current task. After learning each task, the Residual is analyzed for redundancy, both within itself and with the learnt Core space. A minimal number of extra dimensions required to explain the current task are added to the Core space and the remaining Residual is freed up for learning the next task. We evaluate our algorithm on P-MNIST, CIFAR and a sequence of 8 different datasets, and achieve comparable accuracy to the state-of-the-art methods while overcoming catastrophic forgetting. Additionally, our algorithm is well suited for practical use. The partitioning algorithm analyzes all layers in one shot, ensuring scalability to deeper networks. Moreover, the analysis of dimensions translates to filter-level sparsity, and the structured nature of the resulting architecture gives us up to 5x improvement in energy efficiency during task inference over the current state-of-the-art.



### Tensor-Based Grading: A Novel Patch-Based Grading Approach for the Analysis of Deformation Fields in Huntington's Disease
- **Arxiv ID**: http://arxiv.org/abs/2001.08651v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08651v1)
- **Published**: 2020-01-23 16:42:24+00:00
- **Updated**: 2020-01-23 16:42:24+00:00
- **Authors**: Kilian Hett, Hans Johnson, Pierrick Coupé, Jane Paulsen, Jeffrey Long, Ipek Oguz
- **Comment**: None
- **Journal**: IEEE ISBI 2020: International Symposium on Biomedical Imaging, Apr
  2020, Iowa City, United States
- **Summary**: The improvements in magnetic resonance imaging have led to the development of numerous techniques to better detect structural alterations caused by neurodegenerative diseases. Among these, the patch-based grading framework has been proposed to model local patterns of anatomical changes. This approach is attractive because of its low computational cost and its competitive performance. Other studies have proposed to analyze the deformations of brain structures using tensor-based morphometry, which is a highly interpretable approach. In this work, we propose to combine the advantages of these two approaches by extending the patch-based grading framework with a new tensor-based grading method that enables us to model patterns of local deformation using a log-Euclidean metric. We evaluate our new method in a study of the putamen for the classification of patients with pre-manifest Huntington's disease and healthy controls. Our experiments show a substantial increase in classification accuracy (87.5 $\pm$ 0.5 vs. 81.3 $\pm$ 0.6) compared to the existing patch-based grading methods, and a good complement to putamen volume, which is a primary imaging-based marker for the study of Huntington's disease.



### Compressive MRI quantification using convex spatiotemporal priors and deep auto-encoders
- **Arxiv ID**: http://arxiv.org/abs/2001.08746v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2001.08746v2)
- **Published**: 2020-01-23 17:15:42+00:00
- **Updated**: 2020-04-21 20:09:21+00:00
- **Authors**: Mohammad Golbabaee, Guido Buonincontri, Carolin Pirkl, Marion Menzel, Bjoern Menze, Mike Davies, Pedro Gomez
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a dictionary-matching-free pipeline for multi-parametric quantitative MRI image computing. Our approach has two stages based on compressed sensing reconstruction and deep learned quantitative inference. The reconstruction phase is convex and incorporates efficient spatiotemporal regularisations within an accelerated iterative shrinkage algorithm. This minimises the under-sampling (aliasing) artefacts from aggressively short scan times. The learned quantitative inference phase is purely trained on physical simulations (Bloch equations) that are flexible for producing rich training samples. We propose a deep and compact auto-encoder network with residual blocks in order to embed Bloch manifold projections through multiscale piecewise affine approximations, and to replace the nonscalable dictionary-matching baseline. Tested on a number of datasets we demonstrate effectiveness of the proposed scheme for recovering accurate and consistent quantitative information from novel and aggressively subsampled 2D/3D quantitative MRI acquisition protocols.



### Rethinking the Distribution Gap of Person Re-identification with Camera-based Batch Normalization
- **Arxiv ID**: http://arxiv.org/abs/2001.08680v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08680v3)
- **Published**: 2020-01-23 17:22:34+00:00
- **Updated**: 2020-07-18 15:37:06+00:00
- **Authors**: Zijie Zhuang, Longhui Wei, Lingxi Xie, Tianyu Zhang, Hengheng Zhang, Haozhe Wu, Haizhou Ai, Qi Tian
- **Comment**: None
- **Journal**: None
- **Summary**: The fundamental difficulty in person re-identification (ReID) lies in learning the correspondence among individual cameras. It strongly demands costly inter-camera annotations, yet the trained models are not guaranteed to transfer well to previously unseen cameras. These problems significantly limit the application of ReID. This paper rethinks the working mechanism of conventional ReID approaches and puts forward a new solution. With an effective operator named Camera-based Batch Normalization (CBN), we force the image data of all cameras to fall onto the same subspace, so that the distribution gap between any camera pair is largely shrunk. This alignment brings two benefits. First, the trained model enjoys better abilities to generalize across scenarios with unseen cameras as well as transfer across multiple training sets. Second, we can rely on intra-camera annotations, which have been undervalued before due to the lack of cross-camera information, to achieve competitive ReID performance. Experiments on a wide range of ReID tasks demonstrate the effectiveness of our approach. The code is available at https://github.com/automan000/Camera-based-Person-ReID.



### MRI Banding Removal via Adversarial Training
- **Arxiv ID**: http://arxiv.org/abs/2001.08699v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08699v3)
- **Published**: 2020-01-23 17:46:14+00:00
- **Updated**: 2020-10-08 15:54:45+00:00
- **Authors**: Aaron Defazio, Tullie Murrell, Michael P. Recht
- **Comment**: None
- **Journal**: None
- **Summary**: MRI images reconstructed from sub-sampled Cartesian data using deep learning techniques often show a characteristic banding (sometimes described as streaking), which is particularly strong in low signal-to-noise regions of the reconstructed image. In this work, we propose the use of an adversarial loss that penalizes banding structures without requiring any human annotation. Our technique greatly reduces the appearance of banding, without requiring any additional computation or post-processing at reconstruction time. We report the results of a blind comparison against a strong baseline by a group of expert evaluators (board-certified radiologists), where our approach is ranked superior at banding removal with no statistically significant loss of detail.



### Lipreading using Temporal Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/2001.08702v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.SD, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2001.08702v1)
- **Published**: 2020-01-23 17:49:35+00:00
- **Updated**: 2020-01-23 17:49:35+00:00
- **Authors**: Brais Martinez, Pingchuan Ma, Stavros Petridis, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: Lip-reading has attracted a lot of research attention lately thanks to advances in deep learning. The current state-of-the-art model for recognition of isolated words in-the-wild consists of a residual network and Bidirectional Gated Recurrent Unit (BGRU) layers. In this work, we address the limitations of this model and we propose changes which further improve its performance. Firstly, the BGRU layers are replaced with Temporal Convolutional Networks (TCN). Secondly, we greatly simplify the training procedure, which allows us to train the model in one single stage. Thirdly, we show that the current state-of-the-art methodology produces models that do not generalize well to variations on the sequence length, and we addresses this issue by proposing a variable-length augmentation. We present results on the largest publicly-available datasets for isolated word recognition in English and Mandarin, LRW and LRW1000, respectively. Our proposed model results in an absolute improvement of 1.2% and 3.2%, respectively, in these datasets which is the new state-of-the-art performance.



### Ternary Feature Masks: zero-forgetting for task-incremental learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08714v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08714v2)
- **Published**: 2020-01-23 18:08:37+00:00
- **Updated**: 2021-04-21 10:34:21+00:00
- **Authors**: Marc Masana, Tinne Tuytelaars, Joost van de Weijer
- **Comment**: To appear in the IEEE Conference on Computer Vision and Pattern
  Recognition Workshop (CVPR-W) on Continual Learning in Computer Vision
  (CLVision) 2021
- **Journal**: None
- **Summary**: We propose an approach without any forgetting to continual learning for the task-aware regime, where at inference the task-label is known. By using ternary masks we can upgrade a model to new tasks, reusing knowledge from previous tasks while not forgetting anything about them. Using masks prevents both catastrophic forgetting and backward transfer. We argue -- and show experimentally -- that avoiding the former largely compensates for the lack of the latter, which is rarely observed in practice. In contrast to earlier works, our masks are applied to the features (activations) of each layer instead of the weights. This considerably reduces the number of mask parameters for each new task; with more than three orders of magnitude for most networks. The encoding of the ternary masks into two bits per feature creates very little overhead to the network, avoiding scalability issues. To allow already learned features to adapt to the current task without changing the behavior of these features for previous tasks, we introduce task-specific feature normalization. Extensive experiments on several finegrained datasets and ImageNet show that our method outperforms current state-of-the-art while reducing memory overhead in comparison to weight-based approaches.



### Interpretable End-to-end Urban Autonomous Driving with Latent Deep Reinforcement Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08726v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.08726v3)
- **Published**: 2020-01-23 18:36:35+00:00
- **Updated**: 2020-07-07 06:23:50+00:00
- **Authors**: Jianyu Chen, Shengbo Eben Li, Masayoshi Tomizuka
- **Comment**: None
- **Journal**: None
- **Summary**: Unlike popular modularized framework, end-to-end autonomous driving seeks to solve the perception, decision and control problems in an integrated way, which can be more adapting to new scenarios and easier to generalize at scale. However, existing end-to-end approaches are often lack of interpretability, and can only deal with simple driving tasks like lane keeping. In this paper, we propose an interpretable deep reinforcement learning method for end-to-end autonomous driving, which is able to handle complex urban scenarios. A sequential latent environment model is introduced and learned jointly with the reinforcement learning process. With this latent model, a semantic birdeye mask can be generated, which is enforced to connect with a certain intermediate property in today's modularized framework for the purpose of explaining the behaviors of learned policy. The latent space also significantly reduces the sample complexity of reinforcement learning. Comparison tests with a simulated autonomous car in CARLA show that the performance of our method in urban scenarios with crowded surrounding vehicles dominates many baselines including DQN, DDPG, TD3 and SAC. Moreover, through masked outputs, the learned policy is able to provide a better explanation of how the car reasons about the driving environment. The codes and videos of this work are available at our github repo and project website.



### Reducing the Representation Error of GAN Image Priors Using the Deep Decoder
- **Arxiv ID**: http://arxiv.org/abs/2001.08747v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08747v1)
- **Published**: 2020-01-23 18:37:24+00:00
- **Updated**: 2020-01-23 18:37:24+00:00
- **Authors**: Max Daniels, Paul Hand, Reinhard Heckel
- **Comment**: None
- **Journal**: None
- **Summary**: Generative models, such as GANs, learn an explicit low-dimensional representation of a particular class of images, and so they may be used as natural image priors for solving inverse problems such as image restoration and compressive sensing. GAN priors have demonstrated impressive performance on these tasks, but they can exhibit substantial representation error for both in-distribution and out-of-distribution images, because of the mismatch between the learned, approximate image distribution and the data generating distribution. In this paper, we demonstrate a method for reducing the representation error of GAN priors by modeling images as the linear combination of a GAN prior with a Deep Decoder. The deep decoder is an underparameterized and most importantly unlearned natural signal model similar to the Deep Image Prior. No knowledge of the specific inverse problem is needed in the training of the GAN underlying our method. For compressive sensing and image superresolution, our hybrid model exhibits consistently higher PSNRs than both the GAN priors and Deep Decoder separately, both on in-distribution and out-of-distribution images. This model provides a method for extensibly and cheaply leveraging both the benefits of learned and unlearned image recovery priors in inverse problems.



### Robust Explanations for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2001.08730v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2001.08730v1)
- **Published**: 2020-01-23 18:43:34+00:00
- **Updated**: 2020-01-23 18:43:34+00:00
- **Authors**: Badri N. Patro, Shivansh Pate, Vinay P. Namboodiri
- **Comment**: WACV-2020 (Accepted)
- **Journal**: None
- **Summary**: In this paper, we propose a method to obtain robust explanations for visual question answering(VQA) that correlate well with the answers. Our model explains the answers obtained through a VQA model by providing visual and textual explanations. The main challenges that we address are i) Answers and textual explanations obtained by current methods are not well correlated and ii) Current methods for visual explanation do not focus on the right location for explaining the answer. We address both these challenges by using a collaborative correlated module which ensures that even if we do not train for noise based attacks, the enhanced correlation ensures that the right explanation and answer can be generated. We further show that this also aids in improving the generated visual and textual explanations. The use of the correlated module can be thought of as a robust method to verify if the answer and explanations are coherent. We evaluate this model using VQA-X dataset. We observe that the proposed method yields better textual and visual justification that supports the decision. We showcase the robustness of the model against a noise-based perturbation attack using corresponding visual and textual explanations. A detailed empirical analysis is shown. Here we provide source code link for our model \url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.



### Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation
- **Arxiv ID**: http://arxiv.org/abs/2001.08735v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.08735v3)
- **Published**: 2020-01-23 18:55:43+00:00
- **Updated**: 2020-03-09 08:58:10+00:00
- **Authors**: Hung-Yu Tseng, Hsin-Ying Lee, Jia-Bin Huang, Ming-Hsuan Yang
- **Comment**: ICLR 2020 (Spotlight). Project page:
  http://vllab.ucmerced.edu/ym41608/projects/CrossDomainFewShot Code:
  https://github.com/hytseng0509/CrossDomainFewShot
- **Journal**: None
- **Summary**: Few-shot classification aims to recognize novel categories with only few labeled images in each class. Existing metric-based few-shot classification algorithms predict categories by comparing the feature embeddings of query images with those from a few labeled images (support examples) using a learned metric function. While promising performance has been demonstrated, these methods often fail to generalize to unseen domains due to large discrepancy of the feature distribution across domains. In this work, we address the problem of few-shot classification under domain shifts for metric-based methods. Our core idea is to use feature-wise transformation layers for augmenting the image features using affine transforms to simulate various feature distributions under different domains in the training stage. To capture variations of the feature distributions under different domains, we further apply a learning-to-learn approach to search for the hyper-parameters of the feature-wise transformation layers. We conduct extensive experiments and ablation studies under the domain generalization setting using five few-shot classification datasets: mini-ImageNet, CUB, Cars, Places, and Plantae. Experimental results demonstrate that the proposed feature-wise transformation layer is applicable to various metric-based models, and provides consistent improvements on the few-shot classification performance under domain shift.



### Audiovisual SlowFast Networks for Video Recognition
- **Arxiv ID**: http://arxiv.org/abs/2001.08740v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2001.08740v2)
- **Published**: 2020-01-23 18:59:46+00:00
- **Updated**: 2020-03-09 00:50:19+00:00
- **Authors**: Fanyi Xiao, Yong Jae Lee, Kristen Grauman, Jitendra Malik, Christoph Feichtenhofer
- **Comment**: Technical report
- **Journal**: None
- **Summary**: We present Audiovisual SlowFast Networks, an architecture for integrated audiovisual perception. AVSlowFast has Slow and Fast visual pathways that are deeply integrated with a Faster Audio pathway to model vision and sound in a unified representation. We fuse audio and visual features at multiple layers, enabling audio to contribute to the formation of hierarchical audiovisual concepts. To overcome training difficulties that arise from different learning dynamics for audio and visual modalities, we introduce DropPathway, which randomly drops the Audio pathway during training as an effective regularization technique. Inspired by prior studies in neuroscience, we perform hierarchical audiovisual synchronization to learn joint audiovisual features. We report state-of-the-art results on six video action classification and detection datasets, perform detailed ablation studies, and show the generalization of AVSlowFast to learn self-supervised audiovisual features. Code will be made available at: https://github.com/facebookresearch/SlowFast.



### Cloud and Cloud Shadow Segmentation for Remote Sensing Imagery via Filtered Jaccard Loss Function and Parametric Augmentation
- **Arxiv ID**: http://arxiv.org/abs/2001.08768v2
- **DOI**: 10.1109/JSTARS.2021.3070786
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.08768v2)
- **Published**: 2020-01-23 19:13:00+00:00
- **Updated**: 2021-04-23 22:01:36+00:00
- **Authors**: Sorour Mohajerani, Parvaneh Saeedi
- **Comment**: 12 pages. This version is a bit different from the one published in
  IEEE JSTARS
- **Journal**: IEEE Journal of Selected Topics in Applied Earth Observations and
  Remote Sensing (JSTARS), 2021
- **Summary**: Cloud and cloud shadow segmentation are fundamental processes in optical remote sensing image analysis. Current methods for cloud/shadow identification in geospatial imagery are not as accurate as they should, especially in the presence of snow and haze. This paper presents a deep learning-based framework for the detection of cloud/shadow in Landsat 8 images. Our method benefits from a convolutional neural network, Cloud-Net+ (a modification of our previously proposed Cloud-Net \cite{myigarss}) that is trained with a novel loss function (Filtered Jaccard Loss). The proposed loss function is more sensitive to the absence of foreground objects in an image and penalizes/rewards the predicted mask more accurately than other common loss functions. In addition, a sunlight direction-aware data augmentation technique is developed for the task of cloud shadow detection to extend the generalization ability of the proposed model by expanding existing training sets. The combination of Cloud-Net+, Filtered Jaccard Loss function, and the proposed augmentation algorithm delivers superior results on four public cloud/shadow detection datasets. Our experiments on Pascal VOC dataset exemplifies the applicability and quality of our proposed network and loss function in other computer vision applications.



### Deep Bayesian Network for Visual Question Generation
- **Arxiv ID**: http://arxiv.org/abs/2001.08779v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2001.08779v1)
- **Published**: 2020-01-23 19:37:20+00:00
- **Updated**: 2020-01-23 19:37:20+00:00
- **Authors**: Badri N. Patro, Vinod K. Kurmi, Sandeep Kumar, Vinay P. Namboodiri
- **Comment**: WACV-2020 (Accepted)
- **Journal**: None
- **Summary**: Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues experts for generating probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. We observe that with the addition of more cues and by minimizing uncertainty among the cues, the Bayesian framework becomes more confident. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion of cues is preferred. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE, and CIDEr). Here we provide project link for Deep Bayesian VQG \url{https://delta-lab-iitk.github.io/BVQG/}



### Uncertainty based Class Activation Maps for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2002.10309v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.10309v1)
- **Published**: 2020-01-23 19:54:19+00:00
- **Updated**: 2020-01-23 19:54:19+00:00
- **Authors**: Badri N. Patro, Mayank Lunayach, Vinay P. Namboodiri
- **Comment**: This work is an extension of our ICCV-2019 work. arXiv admin note:
  text overlap with arXiv:1908.06306
- **Journal**: None
- **Summary**: Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanations for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.



### Localization of Critical Findings in Chest X-Ray without Local Annotations Using Multi-Instance Learning
- **Arxiv ID**: http://arxiv.org/abs/2001.08817v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.08817v1)
- **Published**: 2020-01-23 21:29:14+00:00
- **Updated**: 2020-01-23 21:29:14+00:00
- **Authors**: Evan Schwab, André Gooßen, Hrishikesh Deshpande, Axel Saalbach
- **Comment**: Accepted to International Symposium of Biomedical Imaging (ISBI) 2020
- **Journal**: None
- **Summary**: The automatic detection of critical findings in chest X-rays (CXR), such as pneumothorax, is important for assisting radiologists in their clinical workflow like triaging time-sensitive cases and screening for incidental findings. While deep learning (DL) models has become a promising predictive technology with near-human accuracy, they commonly suffer from a lack of explainability, which is an important aspect for clinical deployment of DL models in the highly regulated healthcare industry. For example, localizing critical findings in an image is useful for explaining the predictions of DL classification algorithms. While there have been a host of joint classification and localization methods for computer vision, the state-of-the-art DL models require locally annotated training data in the form of pixel level labels or bounding box coordinates. In the medical domain, this requires an expensive amount of manual annotation by medical experts for each critical finding. This requirement becomes a major barrier for training models that can rapidly scale to various findings. In this work, we address these shortcomings with an interpretable DL algorithm based on multi-instance learning that jointly classifies and localizes critical findings in CXR without the need for local annotations. We show competitive classification results on three different critical findings (pneumothorax, pneumonia, and pulmonary edema) from three different CXR datasets.



### SS-Auto: A Single-Shot, Automatic Structured Weight Pruning Framework of DNNs with Ultra-High Efficiency
- **Arxiv ID**: http://arxiv.org/abs/2001.08839v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2001.08839v1)
- **Published**: 2020-01-23 22:45:02+00:00
- **Updated**: 2020-01-23 22:45:02+00:00
- **Authors**: Zhengang Li, Yifan Gong, Xiaolong Ma, Sijia Liu, Mengshu Sun, Zheng Zhan, Zhenglun Kong, Geng Yuan, Yanzhi Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Structured weight pruning is a representative model compression technique of DNNs for hardware efficiency and inference accelerations. Previous works in this area leave great space for improvement since sparse structures with combinations of different structured pruning schemes are not exploited fully and efficiently. To mitigate the limitations, we propose SS-Auto, a single-shot, automatic structured pruning framework that can achieve row pruning and column pruning simultaneously. We adopt soft constraint-based formulation to alleviate the strong non-convexity of l0-norm constraints used in state-of-the-art ADMM-based methods for faster convergence and fewer hyperparameters. Instead of solving the problem directly, a Primal-Proximal solution is proposed to avoid the pitfall of penalizing all weights equally, thereby enhancing the accuracy. Extensive experiments on CIFAR-10 and CIFAR-100 datasets demonstrate that the proposed framework can achieve ultra-high pruning rates while maintaining accuracy. Furthermore, significant inference speedup has been observed from the proposed framework through actual measurements on the smartphone.



### Brain Tumor Classification Using Deep Learning Technique -- A Comparison between Cropped, Uncropped, and Segmented Lesion Images with Different Sizes
- **Arxiv ID**: http://arxiv.org/abs/2001.08844v1
- **DOI**: 10.30534/ijatcse/2019/155862019
- **Categories**: **eess.IV**, cs.CV, cs.LG, 68Txx (Primary), 30F20 (Secondary), I.2; I.4; I.5
- **Links**: [PDF](http://arxiv.org/pdf/2001.08844v1)
- **Published**: 2020-01-23 23:05:19+00:00
- **Updated**: 2020-01-23 23:05:19+00:00
- **Authors**: Ali Mohammad Alqudah, Hiam Alquraan, Isam Abu Qasmieh, Amin Alqudah, Wafaa Al-Sharu
- **Comment**: None
- **Journal**: IJATCSE, 8(6), pp.3684-3691 (2019)
- **Summary**: Deep Learning is the newest and the current trend of the machine learning field that paid a lot of the researchers' attention in the recent few years. As a proven powerful machine learning tool, deep learning was widely used in several applications for solving various complex problems that require extremely high accuracy and sensitivity, particularly in the medical field. In general, brain tumor is one of the most common and aggressive malignant tumor diseases which is leading to a very short expected life if it is diagnosed at higher grade. Based on that, brain tumor grading is a very critical step after detecting the tumor in order to achieve an effective treating plan. In this paper, we used Convolutional Neural Network (CNN) which is one of the most widely used deep learning architectures for classifying a dataset of 3064 T1 weighted contrast-enhanced brain MR images for grading (classifying) the brain tumors into three classes (Glioma, Meningioma, and Pituitary Tumor). The proposed CNN classifier is a powerful tool and its overall performance with accuracy of 98.93% and sensitivity of 98.18% for the cropped lesions, while the results for the uncropped lesions are 99% accuracy and 98.52% sensitivity and the results for segmented lesion images are 97.62% for accuracy and 97.40% sensitivity.



