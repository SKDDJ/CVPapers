# Arxiv Papers in cs.CV on 2020-10-25
### Smartphone-Based Test and Predictive Models for Rapid, Non-Invasive, and Point-of-Care Monitoring of Ocular and Cardiovascular Complications Related to Diabetes
- **Arxiv ID**: http://arxiv.org/abs/2011.08068v1
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2011.08068v1)
- **Published**: 2020-10-25 00:57:35+00:00
- **Updated**: 2020-10-25 00:57:35+00:00
- **Authors**: Kasyap Chakravadhanula
- **Comment**: 25 Pages, 12 Figures
- **Journal**: None
- **Summary**: Among the most impactful diabetic complications are diabetic retinopathy, the leading cause of blindness among working class adults, and cardiovascular disease, the leading cause of death worldwide. This study describes the development of improved machine learning based screening of these conditions. First, a random forest model was developed by retrospectively analyzing the influence of various risk factors (obtained quickly and non-invasively) on cardiovascular risk. Next, a deep-learning model was developed for prediction of diabetic retinopathy from retinal fundus images by a modified and re-trained InceptionV3 image classification model. The input was simplified by automatically segmenting the blood vessels in the retinal image. The technique of transfer learning enables the model to capitalize on existing infrastructure on the target device, meaning more versatile deployment, especially helpful in low-resource settings. The models were integrated into a smartphone-based device, combined with an inexpensive 3D-printed retinal imaging attachment. Accuracy scores, as well as the receiver operating characteristic curve, the learning curve, and other gauges, were promising. This test is much cheaper and faster, enabling continuous monitoring for two damaging complications of diabetes. It has the potential to replace the manual methods of diagnosing both diabetic retinopathy and cardiovascular risk, which are time consuming and costly processes only done by medical professionals away from the point of care, and to prevent irreversible blindness and heart-related complications through faster, cheaper, and safer monitoring of diabetic complications. As well, tracking of cardiovascular and ocular complications of diabetes can enable improved detection of other diabetic complications, leading to earlier and more efficient treatment on a global scale.



### APB2FaceV2: Real-Time Audio-Guided Multi-Face Reenactment
- **Arxiv ID**: http://arxiv.org/abs/2010.13017v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13017v1)
- **Published**: 2020-10-25 02:30:09+00:00
- **Updated**: 2020-10-25 02:30:09+00:00
- **Authors**: Jiangning Zhang, Xianfang Zeng, Chao Xu, Jun Chen, Yong Liu, Yunliang Jiang
- **Comment**: ICASSP'21
- **Journal**: None
- **Summary**: Audio-guided face reenactment aims to generate a photorealistic face that has matched facial expression with the input audio. However, current methods can only reenact a special person once the model is trained or need extra operations such as 3D rendering and image post-fusion on the premise of generating vivid faces. To solve the above challenge, we propose a novel \emph{R}eal-time \emph{A}udio-guided \emph{M}ulti-face reenactment approach named \emph{APB2FaceV2}, which can reenact different target faces among multiple persons with corresponding reference face and drive audio signal as inputs. Enabling the model to be trained end-to-end and have a faster speed, we design a novel module named Adaptive Convolution (AdaConv) to infuse audio information into the network, as well as adopt a lightweight network as our backbone so that the network can run in real time on CPU and GPU. Comparison experiments prove the superiority of our approach than existing state-of-the-art methods, and further experiments demonstrate that our method is efficient and flexible for practical applications https://github.com/zhangzjn/APB2FaceV2



### CLRGaze: Contrastive Learning of Representations for Eye Movement Signals
- **Arxiv ID**: http://arxiv.org/abs/2010.13046v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13046v2)
- **Published**: 2020-10-25 06:12:06+00:00
- **Updated**: 2021-05-30 14:14:23+00:00
- **Authors**: Louise Gillian C. Bautista, Prospero C. Naval Jr
- **Comment**: Accepted to 29th European Signal Processing Conference (EUSIPCO 2021)
- **Journal**: None
- **Summary**: Eye movements are intricate and dynamic biosignals that contain a wealth of cognitive information about the subject. However, these are ambiguous signals and therefore require meticulous feature engineering to be used by machine learning algorithms. We instead propose to learn feature vectors of eye movements in a self-supervised manner. We adopt a contrastive learning approach and propose a set of data transformations that encourage a deep neural network to discern salient and granular gaze patterns. This paper presents a novel experiment utilizing six eye-tracking data sets despite different data specifications and experimental conditions. We assess the learned features on biometric tasks with only a linear classifier, achieving 84.6% accuracy on a mixed dataset, and up to 97.3% accuracy on a single dataset. Our work advances the state of machine learning for eye movements and provides insights into a general representation learning method not only for eye movements but also for similar biosignals.



### Applying convolutional neural networks to extremely sparse image datasets using an image subdivision approach
- **Arxiv ID**: http://arxiv.org/abs/2010.13054v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2010.13054v1)
- **Published**: 2020-10-25 07:43:20+00:00
- **Updated**: 2020-10-25 07:43:20+00:00
- **Authors**: Johan P. Boetker
- **Comment**: 10 pages, 4 figures
- **Journal**: None
- **Summary**: Purpose: The aim of this work is to demonstrate that convolutional neural networks (CNN) can be applied to extremely sparse image libraries by subdivision of the original image datasets. Methods: Image datasets from a conventional digital camera was created and scanning electron microscopy (SEM) measurements were obtained from the literature. The image datasets were subdivided and CNN models were trained on parts of the subdivided datasets. Results: The CNN models were capable of analyzing extremely sparse image datasets by utilizing the proposed method of image subdivision. It was furthermore possible to provide a direct assessment of the various regions where a given API or appearance was predominant.



### Dynamic Adversarial Patch for Evading Object Detection Models
- **Arxiv ID**: http://arxiv.org/abs/2010.13070v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.13070v1)
- **Published**: 2020-10-25 08:55:40+00:00
- **Updated**: 2020-10-25 08:55:40+00:00
- **Authors**: Shahar Hoory, Tzvika Shapira, Asaf Shabtai, Yuval Elovici
- **Comment**: None
- **Journal**: None
- **Summary**: Recent research shows that neural networks models used for computer vision (e.g., YOLO and Fast R-CNN) are vulnerable to adversarial evasion attacks. Most of the existing real-world adversarial attacks against object detectors use an adversarial patch which is attached to the target object (e.g., a carefully crafted sticker placed on a stop sign). This method may not be robust to changes in the camera's location relative to the target object; in addition, it may not work well when applied to nonplanar objects such as cars. In this study, we present an innovative attack method against object detectors applied in a real-world setup that addresses some of the limitations of existing attacks. Our method uses dynamic adversarial patches which are placed at multiple predetermined locations on a target object. An adversarial learning algorithm is applied in order to generate the patches used. The dynamic attack is implemented by switching between optimized patches dynamically, according to the camera's position (i.e., the object detection system's position). In order to demonstrate our attack in a real-world setup, we implemented the patches by attaching flat screens to the target object; the screens are used to present the patches and switch between them, depending on the current camera location. Thus, the attack is dynamic and adjusts itself to the situation to achieve optimal results. We evaluated our dynamic patch approach by attacking the YOLOv2 object detector with a car as the target object and succeeded in misleading it in up to 90% of the video frames when filming the car from a wide viewing angle range. We improved the attack by generating patches that consider the semantic distance between the target object and its classification. We also examined the attack's transferability among different car models and were able to mislead the detector 71% of the time.



### Fast and Accurate Light Field Saliency Detection through Deep Encoding
- **Arxiv ID**: http://arxiv.org/abs/2010.13073v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.SP, I.4; I.5
- **Links**: [PDF](http://arxiv.org/pdf/2010.13073v2)
- **Published**: 2020-10-25 09:15:08+00:00
- **Updated**: 2021-12-13 17:12:56+00:00
- **Authors**: Sahan Hemachandra, Ranga Rodrigo, Chamira Edussooriya
- **Comment**: None
- **Journal**: None
- **Summary**: Light field saliency detection -- important due to utility in many vision tasks -- still lacks speed and can improve in accuracy. Due to the formulation of the saliency detection problem in light fields as a segmentation task or a memorizing task, existing approaches consume unnecessarily large amounts of computational resources for training, and have longer execution times for testing. We solve this by aggressively reducing the large light field images to a much smaller three-channel feature map appropriate for saliency detection using an RGB image saliency detector with attention mechanisms. We achieve this by introducing a novel convolutional neural network based features extraction and encoding module. Our saliency detector takes $0.4$ s to process a light field of size $9\times9\times512\times375$ in a CPU and is significantly faster than state-of-the-art light field saliency detectors, with better or comparable accuracy. Furthermore, model size of our architecture is significantly lower compared to state-of-the-art light field saliency detectors. Our work shows that extracting features from light fields through aggressive size reduction and the attention mechanism results in a faster and accurate light field saliency detector leading to near real-time light field processing.



### Context Aware 3D UNet for Brain Tumor Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2010.13082v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13082v2)
- **Published**: 2020-10-25 10:32:25+00:00
- **Updated**: 2020-11-27 13:57:26+00:00
- **Authors**: Parvez Ahmad, Saqib Qamar, Linlin Shen, Adnan Saeed
- **Comment**: Accepted for MICCAI 2020 Brain Lesions (BrainLes) Workshop
- **Journal**: None
- **Summary**: Deep convolutional neural network (CNN) achieves remarkable performance for medical image analysis. UNet is the primary source in the performance of 3D CNN architectures for medical imaging tasks, including brain tumor segmentation. The skip connection in the UNet architecture concatenates features from both encoder and decoder paths to extract multi-contextual information from image data. The multi-scaled features play an essential role in brain tumor segmentation. However, the limited use of features can degrade the performance of the UNet approach for segmentation. In this paper, we propose a modified UNet architecture for brain tumor segmentation. In the proposed architecture, we used densely connected blocks in both encoder and decoder paths to extract multi-contextual information from the concept of feature reusability. In addition, residual-inception blocks (RIB) are used to extract the local and global information by merging features of different kernel sizes. We validate the proposed architecture on the multi-modal brain tumor segmentation challenge (BRATS) 2020 testing dataset. The dice (DSC) scores of the whole tumor (WT), tumor core (TC), and enhancing tumor (ET) are 89.12%, 84.74%, and 79.12%, respectively.



### Coherent Loss: A Generic Framework for Stable Video Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2010.13085v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13085v1)
- **Published**: 2020-10-25 10:48:28+00:00
- **Updated**: 2020-10-25 10:48:28+00:00
- **Authors**: Mingyang Qian, Yi Fu, Xiao Tan, Yingying Li, Jinqing Qi, Huchuan Lu, Shilei Wen, Errui Ding
- **Comment**: 10 pages, 6 figures, 4 tables
- **Journal**: None
- **Summary**: Video segmentation approaches are of great importance for numerous vision tasks especially in video manipulation for entertainment. Due to the challenges associated with acquiring high-quality per-frame segmentation annotations and large video datasets with different environments at scale, learning approaches shows overall higher accuracy on test dataset but lack strict temporal constraints to self-correct jittering artifacts in most practical applications. We investigate how this jittering artifact degrades the visual quality of video segmentation results and proposed a metric of temporal stability to numerically evaluate it. In particular, we propose a Coherent Loss with a generic framework to enhance the performance of a neural network against jittering artifacts, which combines with high accuracy and high consistency. Equipped with our method, existing video object/semantic segmentation approaches achieve a significant improvement in term of more satisfactory visual quality on video human dataset, which we provide for further research in this field, and also on DAVIS and Cityscape.



### Scribble-based Weakly Supervised Deep Learning for Road Surface Extraction from Remote Sensing Images
- **Arxiv ID**: http://arxiv.org/abs/2010.13106v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13106v1)
- **Published**: 2020-10-25 12:40:30+00:00
- **Updated**: 2020-10-25 12:40:30+00:00
- **Authors**: Yao Wei, Shunping Ji
- **Comment**: 12 pages, 8 figures, submitted to IEEE Transactions on Geoscience and
  Remote Sensing
- **Journal**: None
- **Summary**: Road surface extraction from remote sensing images using deep learning methods has achieved good performance, while most of the existing methods are based on fully supervised learning, which requires a large amount of training data with laborious per-pixel annotation. In this paper, we propose a scribble-based weakly supervised road surface extraction method named ScRoadExtractor, which learns from easily accessible scribbles such as centerlines instead of densely annotated road surface ground-truths. To propagate semantic information from sparse scribbles to unlabeled pixels, we introduce a road label propagation algorithm which considers both the buffer-based properties of road networks and the color and spatial information of super-pixels. The proposal masks generated from the road label propagation algorithm are utilized to train a dual-branch encoder-decoder network we designed, which consists of a semantic segmentation branch and an auxiliary boundary detection branch. We perform experiments on three diverse road datasets that are comprised of highresolution remote sensing satellite and aerial images across the world. The results demonstrate that ScRoadExtractor exceed the classic scribble-supervised segmentation method by 20% for the intersection over union (IoU) indicator and outperform the state-of-the-art scribble-based weakly supervised methods at least 4%.



### Empowering Knowledge Distillation via Open Set Recognition for Robust 3D Point Cloud Classification
- **Arxiv ID**: http://arxiv.org/abs/2010.13114v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13114v1)
- **Published**: 2020-10-25 13:26:48+00:00
- **Updated**: 2020-10-25 13:26:48+00:00
- **Authors**: Ayush Bhardwaj, Sakshee Pimpale, Saurabh Kumar, Biplab Banerjee
- **Comment**: Preprint. Under consideration at Pattern Recognition Letters
- **Journal**: None
- **Summary**: Real-world scenarios pose several challenges to deep learning based computer vision techniques despite their tremendous success in research. Deeper models provide better performance, but are challenging to deploy and knowledge distillation allows us to train smaller models with minimal loss in performance. The model also has to deal with open set samples from classes outside the ones it was trained on and should be able to identify them as unknown samples while classifying the known ones correctly. Finally, most existing image recognition research focuses only on using two-dimensional snapshots of the real world three-dimensional objects. In this work, we aim to bridge these three research fields, which have been developed independently until now, despite being deeply interrelated. We propose a joint Knowledge Distillation and Open Set recognition training methodology for three-dimensional object recognition. We demonstrate the effectiveness of the proposed method via various experiments on how it allows us to obtain a much smaller model, which takes a minimal hit in performance while being capable of open set recognition for 3D point cloud data.



### Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model
- **Arxiv ID**: http://arxiv.org/abs/2010.13118v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.13118v4)
- **Published**: 2020-10-25 13:40:10+00:00
- **Updated**: 2021-07-07 07:43:54+00:00
- **Authors**: Julian Lienen, Eyke Hüllermeier, Ralph Ewerth, Nils Nommensen
- **Comment**: 15 pages, 5 figures, 7 tables, IEEE/CVF Conference on Computer Vision
  and Pattern Recognition (CVPR) 2021
- **Journal**: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR), 2021, pp. 14595-14604
- **Summary**: In many real-world applications, the relative depth of objects in an image is crucial for scene understanding. Recent approaches mainly tackle the problem of depth prediction in monocular images by treating the problem as a regression task. Yet, being interested in an order relation in the first place, ranking methods suggest themselves as a natural alternative to regression, and indeed, ranking approaches leveraging pairwise comparisons as training information ("object A is closer to the camera than B") have shown promising performance on this problem. In this paper, we elaborate on the use of so-called listwise ranking as a generalization of the pairwise approach. Our method is based on the Plackett-Luce (PL) model, a probability distribution on rankings, which we combine with a state-of-the-art neural network architecture and a simple sampling strategy to reduce training complexity. Moreover, taking advantage of the representation of PL as a random utility model, the proposed predictor offers a natural way to recover (shift-invariant) metric depth information from ranking-only data provided at training time. An empirical evaluation on several benchmark datasets in a "zero-shot" setting demonstrates the effectiveness of our approach compared to existing ranking and regression methods.



### Correspondence Learning via Linearly-invariant Embedding
- **Arxiv ID**: http://arxiv.org/abs/2010.13136v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.13136v1)
- **Published**: 2020-10-25 15:31:53+00:00
- **Updated**: 2020-10-25 15:31:53+00:00
- **Authors**: Riccardo Marin, Marie-Julie Rakotosaona, Simone Melzi, Maks Ovsjanikov
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a fully differentiable pipeline for estimating accurate dense correspondences between 3D point clouds. The proposed pipeline is an extension and a generalization of the functional maps framework. However, instead of using the Laplace-Beltrami eigenfunctions as done in virtually all previous works in this domain, we demonstrate that learning the basis from data can both improve robustness and lead to better accuracy in challenging settings. We interpret the basis as a learned embedding into a higher dimensional space. Following the functional map paradigm the optimal transformation in this embedding space must be linear and we propose a separate architecture aimed at estimating the transformation by learning optimal descriptor functions. This leads to the first end-to-end trainable functional map-based correspondence approach in which both the basis and the descriptors are learned from data. Interestingly, we also observe that learning a \emph{canonical} embedding leads to worse results, suggesting that leaving an extra linear degree of freedom to the embedding network gives it more robustness, thereby also shedding light onto the success of previous methods. Finally, we demonstrate that our approach achieves state-of-the-art results in challenging non-rigid 3D point cloud correspondence applications.



### Neuron Merging: Compensating for Pruned Neurons
- **Arxiv ID**: http://arxiv.org/abs/2010.13160v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2010.13160v1)
- **Published**: 2020-10-25 16:50:26+00:00
- **Updated**: 2020-10-25 16:50:26+00:00
- **Authors**: Woojeong Kim, Suhyun Kim, Mincheol Park, Geonseok Jeon
- **Comment**: NeurIPS 2020
- **Journal**: None
- **Summary**: Network pruning is widely used to lighten and accelerate neural network models. Structured network pruning discards the whole neuron or filter, leading to accuracy loss. In this work, we propose a novel concept of neuron merging applicable to both fully connected layers and convolution layers, which compensates for the information loss due to the pruned neurons/filters. Neuron merging starts with decomposing the original weights into two matrices/tensors. One of them becomes the new weights for the current layer, and the other is what we name a scaling matrix, guiding the combination of neurons. If the activation function is ReLU, the scaling matrix can be absorbed into the next layer under certain conditions, compensating for the removed neurons. We also propose a data-free and inexpensive method to decompose the weights by utilizing the cosine similarity between neurons. Compared to the pruned model with the same topology, our merged model better preserves the output feature map of the original model; thus, it maintains the accuracy after pruning without fine-tuning. We demonstrate the effectiveness of our approach over network pruning for various model architectures and datasets. As an example, for VGG-16 on CIFAR-10, we achieve an accuracy of 93.16% while reducing 64% of total parameters, without any fine-tuning. The code can be found here: https://github.com/friendshipkim/neuron-merging



### Unsupervised Super-Resolution: Creating High-Resolution Medical Images from Low-Resolution Anisotropic Examples
- **Arxiv ID**: http://arxiv.org/abs/2010.13172v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13172v1)
- **Published**: 2020-10-25 17:41:54+00:00
- **Updated**: 2020-10-25 17:41:54+00:00
- **Authors**: Jörg Sander, Bob D. de Vos, Ivana Išgum
- **Comment**: accepted at the SPIE Medical Imaging 2021 conference
- **Journal**: None
- **Summary**: Although high resolution isotropic 3D medical images are desired in clinical practice, their acquisition is not always feasible. Instead, lower resolution images are upsampled to higher resolution using conventional interpolation methods. Sophisticated learning-based super-resolution approaches are frequently unavailable in clinical setting, because such methods require training with high-resolution isotropic examples. To address this issue, we propose a learning-based super-resolution approach that can be trained using solely anisotropic images, i.e. without high-resolution ground truth data. The method exploits the latent space, generated by autoencoders trained on anisotropic images, to increase spatial resolution in low-resolution images. The method was trained and evaluated using 100 publicly available cardiac cine MR scans from the Automated Cardiac Diagnosis Challenge (ACDC). The quantitative results show that the proposed method performs better than conventional interpolation methods. Furthermore, the qualitative results indicate that especially finer cardiac structures are synthesized with high quality. The method has the potential to be applied to other anatomies and modalities and can be easily applied to any 3D anisotropic medical image dataset.



### Amodal Segmentation through Out-of-Task and Out-of-Distribution Generalization with a Bayesian Model
- **Arxiv ID**: http://arxiv.org/abs/2010.13175v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13175v4)
- **Published**: 2020-10-25 18:01:26+00:00
- **Updated**: 2022-07-09 04:42:39+00:00
- **Authors**: Yihong Sun, Adam Kortylewski, Alan Yuille
- **Comment**: CVPR 2022
- **Journal**: None
- **Summary**: Amodal completion is a visual task that humans perform easily but which is difficult for computer vision algorithms. The aim is to segment those object boundaries which are occluded and hence invisible. This task is particularly challenging for deep neural networks because data is difficult to obtain and annotate. Therefore, we formulate amodal segmentation as an out-of-task and out-of-distribution generalization problem. Specifically, we replace the fully connected classifier in neural networks with a Bayesian generative model of the neural network features. The model is trained from non-occluded images using bounding box annotations and class labels only, but is applied to generalize out-of-task to object segmentation and to generalize out-of-distribution to segment occluded objects. We demonstrate how such Bayesian models can naturally generalize beyond the training task labels when they learn a prior that models the object's background context and shape. Moreover, by leveraging an outlier process, Bayesian models can further generalize out-of-distribution to segment partially occluded objects and to predict their amodal object boundaries. Our algorithm outperforms alternative methods that use the same supervision by a large margin, and even outperforms methods where annotated amodal segmentations are used during training, when the amount of occlusion is large. Code is publicly available at https://github.com/YihongSun/Bayesian-Amodal.



### Improving the Reconstruction of Disentangled Representation Learners via Multi-Stage Modelling
- **Arxiv ID**: http://arxiv.org/abs/2010.13187v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.13187v1)
- **Published**: 2020-10-25 18:51:15+00:00
- **Updated**: 2020-10-25 18:51:15+00:00
- **Authors**: Akash Srivastava, Yamini Bansal, Yukun Ding, Cole Hurwitz, Kai Xu, Bernhard Egger, Prasanna Sattigeri, Josh Tenenbaum, David D. Cox, Dan Gutfreund
- **Comment**: None
- **Journal**: None
- **Summary**: Current autoencoder-based disentangled representation learning methods achieve disentanglement by penalizing the (aggregate) posterior to encourage statistical independence of the latent factors. This approach introduces a trade-off between disentangled representation learning and reconstruction quality since the model does not have enough capacity to learn correlated latent variables that capture detail information present in most image data. To overcome this trade-off, we present a novel multi-stage modelling approach where the disentangled factors are first learned using a preexisting disentangled representation learning method (such as $\beta$-TCVAE); then, the low-quality reconstruction is improved with another deep generative model that is trained to model the missing correlated latent variables, adding detail information while maintaining conditioning on the previously learned disentangled factors. Taken together, our multi-stage modelling approach results in a single, coherent probabilistic model that is theoretically justified by the principal of D-separation and can be realized with a variety of model classes including likelihood-based models such as variational autoencoders, implicit models such as generative adversarial networks, and tractable models like normalizing flows or mixtures of Gaussians. We demonstrate that our multi-stage model has much higher reconstruction quality than current state-of-the-art methods with equivalent disentanglement performance across multiple standard benchmarks.



### Gestop : Customizable Gesture Control of Computer Systems
- **Arxiv ID**: http://arxiv.org/abs/2010.13197v1
- **DOI**: 10.1145/3430984.3430993
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13197v1)
- **Published**: 2020-10-25 19:13:01+00:00
- **Updated**: 2020-10-25 19:13:01+00:00
- **Authors**: Sriram Krishna, Nishant Sinha
- **Comment**: 5 pages, 5 figures, to appear in the proceedings of the 8th ACM IKDD
  CODS and 26th COMAD (CODS-COMAD '21)
- **Journal**: None
- **Summary**: The established way of interfacing with most computer systems is a mouse and keyboard. Hand gestures are an intuitive and effective touchless way to interact with computer systems. However, hand gesture based systems have seen low adoption among end-users primarily due to numerous technical hurdles in detecting in-air gestures accurately. This paper presents Gestop, a framework developed to bridge this gap. The framework learns to detect gestures from demonstrations, is customizable by end-users and enables users to interact in real-time with computers having only RGB cameras, using gestures.



### SUREMap: Predicting Uncertainty in CNN-based Image Reconstruction Using Stein's Unbiased Risk Estimate
- **Arxiv ID**: http://arxiv.org/abs/2010.13214v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13214v2)
- **Published**: 2020-10-25 20:29:41+00:00
- **Updated**: 2021-04-20 03:01:14+00:00
- **Authors**: Ruangrawee Kitichotkul, Christopher A. Metzler, Frank Ong, Gordon Wetzstein
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNN) have emerged as a powerful tool for solving computational imaging reconstruction problems. However, CNNs are generally difficult-to-understand black-boxes. Accordingly, it is challenging to know when they will work and, more importantly, when they will fail. This limitation is a major barrier to their use in safety-critical applications like medical imaging: Is that blob in the reconstruction an artifact or a tumor?   In this work we use Stein's unbiased risk estimate (SURE) to develop per-pixel confidence intervals, in the form of heatmaps, for compressive sensing reconstruction using the approximate message passing (AMP) framework with CNN-based denoisers. These heatmaps tell end-users how much to trust an image formed by a CNN, which could greatly improve the utility of CNNs in various computational imaging applications.



### Human or Machine? It Is Not What You Write, But How You Write It
- **Arxiv ID**: http://arxiv.org/abs/2010.13231v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.13231v1)
- **Published**: 2020-10-25 22:01:48+00:00
- **Updated**: 2020-10-25 22:01:48+00:00
- **Authors**: Luis A. Leiva, Moises Diaz, Miguel A. Ferrer, Réjean Plamondon
- **Comment**: None
- **Journal**: Proceedings of the 25th Intl. Conf. on Pattern Recognition (ICPR),
  2020
- **Summary**: Online fraud often involves identity theft. Since most security measures are weak or can be spoofed, we investigate a more nuanced and less explored avenue: behavioral biometrics via handwriting movements. This kind of data can be used to verify whether a user is operating a device or a computer application, so it is important to distinguish between human and machine-generated movements reliably. For this purpose, we study handwritten symbols (isolated characters, digits, gestures, and signatures) produced by humans and machines, and compare and contrast several deep learning models. We find that if symbols are presented as static images, they can fool state-of-the-art classifiers (near 75% accuracy in the best case) but can be distinguished with remarkable accuracy if they are presented as temporal sequences (95% accuracy in the average case). We conclude that an accurate detection of fake movements has more to do with how users write, rather than what they write. Our work has implications for computerized systems that need to authenticate or verify legitimate human users, and provides an additional layer of security to keep attackers at bay.



### Self-Supervised Training For Low Dose CT Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2010.13232v2
- **DOI**: 10.1109/ISBI48211.2021.9433944
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13232v2)
- **Published**: 2020-10-25 22:02:14+00:00
- **Updated**: 2021-04-17 18:58:01+00:00
- **Authors**: Mehmet Ozan Unal, Metin Ertas, Isa Yildirim
- **Comment**: None
- **Journal**: 2021 IEEE 18th International Symposium on Biomedical Imaging
  (ISBI)
- **Summary**: Ionizing radiation has been the biggest concern in CT imaging. To reduce the dose level without compromising the image quality, low-dose CT reconstruction has been offered with the availability of compressed sensing based reconstruction methods. Recently, data-driven methods got attention with the rise of deep learning, the availability of high computational power, and big datasets. Deep learning based methods have also been used in low-dose CT reconstruction problem in different manners. Usually, the success of these methods depends on labeled data. However, recent studies showed that training can be achieved successfully with noisy datasets. In this study, we defined a training scheme to use low-dose sinograms as their own training targets. We applied the self-supervision principle in the projection domain where the noise is element-wise independent which is a requirement for self-supervised training methods. Using the self-supervised training, the filtering part of the FBP method and the parameters of a denoiser neural network are optimized. We demonstrate that our method outperforms both conventional and compressed sensing based iterative reconstruction methods qualitatively and quantitatively in the reconstruction of analytic CT phantoms and real-world CT images in low-dose CT reconstruction task.



### Co-embedding of Nodes and Edges with Graph Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2010.13242v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.13242v1)
- **Published**: 2020-10-25 22:39:31+00:00
- **Updated**: 2020-10-25 22:39:31+00:00
- **Authors**: Xiaodong Jiang, Ronghang Zhu, Pengsheng Ji, Sheng Li
- **Comment**: This manuscript has been accepted by the IEEE Transactions on Pattern
  Analysis and Machine Intelligence
- **Journal**: None
- **Summary**: Graph, as an important data representation, is ubiquitous in many real world applications ranging from social network analysis to biology. How to correctly and effectively learn and extract information from graph is essential for a large number of machine learning tasks. Graph embedding is a way to transform and encode the data structure in high dimensional and non-Euclidean feature space to a low dimensional and structural space, which is easily exploited by other machine learning algorithms. We have witnessed a huge surge of such embedding methods, from statistical approaches to recent deep learning methods such as the graph convolutional networks (GCN). Deep learning approaches usually outperform the traditional methods in most graph learning benchmarks by building an end-to-end learning framework to optimize the loss function directly. However, most of the existing GCN methods can only perform convolution operations with node features, while ignoring the handy information in edge features, such as relations in knowledge graphs. To address this problem, we present CensNet, Convolution with Edge-Node Switching graph neural network, for learning tasks in graph-structured data with both node and edge features. CensNet is a general graph embedding framework, which embeds both nodes and edges to a latent feature space. By using line graph of the original undirected graph, the role of nodes and edges are switched, and two novel graph convolution operations are proposed for feature propagation. Experimental results on real-world academic citation networks and quantum chemistry graphs show that our approach achieves or matches the state-of-the-art performance in four graph learning tasks, including semi-supervised node classification, multi-task graph classification, graph regression, and link prediction.



### Generalized Iris Presentation Attack Detection Algorithm under Cross-Database Settings
- **Arxiv ID**: http://arxiv.org/abs/2010.13244v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2010.13244v1)
- **Published**: 2020-10-25 22:42:27+00:00
- **Updated**: 2020-10-25 22:42:27+00:00
- **Authors**: Mehak Gupta, Vishal Singh, Akshay Agarwal, Mayank Vatsa, Richa Singh
- **Comment**: ICPR 2020, 8 pages, 7 figures, 4 tables
- **Journal**: None
- **Summary**: Presentation attacks are posing major challenges to most of the biometric modalities. Iris recognition, which is considered as one of the most accurate biometric modality for person identification, has also been shown to be vulnerable to advanced presentation attacks such as 3D contact lenses and textured lens. While in the literature, several presentation attack detection (PAD) algorithms are presented; a significant limitation is the generalizability against an unseen database, unseen sensor, and different imaging environment. To address this challenge, we propose a generalized deep learning-based PAD network, MVANet, which utilizes multiple representation layers. It is inspired by the simplicity and success of hybrid algorithm or fusion of multiple detection networks. The computational complexity is an essential factor in training deep neural networks; therefore, to reduce the computational complexity while learning multiple feature representation layers, a fixed base model has been used. The performance of the proposed network is demonstrated on multiple databases such as IIITD-WVU MUIPA and IIITD-CLI databases under cross-database training-testing settings, to assess the generalizability of the proposed algorithm.



### MixNet for Generalized Face Presentation Attack Detection
- **Arxiv ID**: http://arxiv.org/abs/2010.13246v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2010.13246v1)
- **Published**: 2020-10-25 23:01:13+00:00
- **Updated**: 2020-10-25 23:01:13+00:00
- **Authors**: Nilay Sanghvi, Sushant Kumar Singh, Akshay Agarwal, Mayank Vatsa, Richa Singh
- **Comment**: ICPR 2020, 8 pages, 6 figures, 7 tables
- **Journal**: None
- **Summary**: The non-intrusive nature and high accuracy of face recognition algorithms have led to their successful deployment across multiple applications ranging from border access to mobile unlocking and digital payments. However, their vulnerability against sophisticated and cost-effective presentation attack mediums raises essential questions regarding its reliability. In the literature, several presentation attack detection algorithms are presented; however, they are still far behind from reality. The major problem with existing work is the generalizability against multiple attacks both in the seen and unseen setting. The algorithms which are useful for one kind of attack (such as print) perform unsatisfactorily for another type of attack (such as silicone masks). In this research, we have proposed a deep learning-based network termed as \textit{MixNet} to detect presentation attacks in cross-database and unseen attack settings. The proposed algorithm utilizes state-of-the-art convolutional neural network architectures and learns the feature mapping for each attack category. Experiments are performed using multiple challenging face presentation attack databases such as SMAD and Spoof In the Wild (SiW-M) databases. Extensive experiments and comparison with existing state of the art algorithms show the effectiveness of the proposed algorithm.



### Attack Agnostic Adversarial Defense via Visual Imperceptible Bound
- **Arxiv ID**: http://arxiv.org/abs/2010.13247v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2010.13247v1)
- **Published**: 2020-10-25 23:14:26+00:00
- **Updated**: 2020-10-25 23:14:26+00:00
- **Authors**: Saheb Chhabra, Akshay Agarwal, Richa Singh, Mayank Vatsa
- **Comment**: ICPR 2020, 8 pages, 5 figures, 7 tables
- **Journal**: None
- **Summary**: The high susceptibility of deep learning algorithms against structured and unstructured perturbations has motivated the development of efficient adversarial defense algorithms. However, the lack of generalizability of existing defense algorithms and the high variability in the performance of the attack algorithms for different databases raises several questions on the effectiveness of the defense algorithms. In this research, we aim to design a defense model that is robust within a certain bound against both seen and unseen adversarial attacks. This bound is related to the visual appearance of an image, and we termed it as \textit{Visual Imperceptible Bound (VIB)}. To compute this bound, we propose a novel method that uses the database characteristics. The VIB is further used to measure the effectiveness of attack algorithms. The performance of the proposed defense model is evaluated on the MNIST, CIFAR-10, and Tiny ImageNet databases on multiple attacks that include C\&W ($l_2$) and DeepFool. The proposed defense model is not only able to increase the robustness against several attacks but also retain or improve the classification accuracy on an original clean test set. The proposed algorithm is attack agnostic, i.e. it does not require any knowledge of the attack algorithm.



