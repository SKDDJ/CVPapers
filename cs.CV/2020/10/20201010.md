# Arxiv Papers in cs.CV on 2020-10-10
### Training Binary Neural Networks through Learning with Noisy Supervision
- **Arxiv ID**: http://arxiv.org/abs/2010.04871v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.04871v1)
- **Published**: 2020-10-10 01:59:39+00:00
- **Updated**: 2020-10-10 01:59:39+00:00
- **Authors**: Kai Han, Yunhe Wang, Yixing Xu, Chunjing Xu, Enhua Wu, Chang Xu
- **Comment**: ICML 2020
- **Journal**: None
- **Summary**: This paper formalizes the binarization operations over neural networks from a learning perspective. In contrast to classical hand crafted rules (\eg hard thresholding) to binarize full-precision neurons, we propose to learn a mapping from full-precision neurons to the target binary ones. Each individual weight entry will not be binarized independently. Instead, they are taken as a whole to accomplish the binarization, just as they work together in generating convolution features. To help the training of the binarization mapping, the full-precision neurons after taking sign operations is regarded as some auxiliary supervision signal, which is noisy but still has valuable guidance. An unbiased estimator is therefore introduced to mitigate the influence of the supervision noise. Experimental results on benchmark datasets indicate that the proposed binarization technique attains consistent improvements over baselines.



### Unveiling Class-Labeling Structure for Universal Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2010.04873v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.04873v1)
- **Published**: 2020-10-10 02:13:02+00:00
- **Updated**: 2020-10-10 02:13:02+00:00
- **Authors**: Yueming Yin, Zhen Yang, Xiaofu Wu, Haifeng Hu
- **Comment**: None
- **Journal**: None
- **Summary**: As a more practical setting for unsupervised domain adaptation, Universal Domain Adaptation (UDA) is recently introduced, where the target label set is unknown. One of the big challenges in UDA is how to determine the common label set shared by source and target domains, as there is simply no labeling available in the target domain. In this paper, we employ a probabilistic approach for locating the common label set, where each source class may come from the common label set with a probability. In particular, we propose a novel approach for evaluating the probability of each source class from the common label set, where this probability is computed by the prediction margin accumulated over the whole target domain. Then, we propose a simple universal adaptation network (S-UAN) by incorporating the probabilistic structure for the common label set. Finally, we analyse the generalization bound focusing on the common label set and explore the properties on the target risk for UDA. Extensive experiments indicate that S-UAN works well in different UDA settings and outperforms the state-of-the-art methods by large margins.



### Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework
- **Arxiv ID**: http://arxiv.org/abs/2010.04879v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.04879v3)
- **Published**: 2020-10-10 02:30:47+00:00
- **Updated**: 2021-06-15 13:02:09+00:00
- **Authors**: Wenxiao Wang, Minghao Chen, Shuai Zhao, Long Chen, Jinming Hu, Haifeng Liu, Deng Cai, Xiaofei He, Wei Liu
- **Comment**: 11 pages, 5 figures. Accepted by ICML 2021
- **Journal**: None
- **Summary**: Most neural network pruning methods, such as filter-level and layer-level prunings, prune the network model along one dimension (depth, width, or resolution) solely to meet a computational budget. However, such a pruning policy often leads to excessive reduction of that dimension, thus inducing a huge accuracy loss. To alleviate this issue, we argue that pruning should be conducted along three dimensions comprehensively. For this purpose, our pruning framework formulates pruning as an optimization problem. Specifically, it first casts the relationships between a certain model's accuracy and depth/width/resolution into a polynomial regression and then maximizes the polynomial to acquire the optimal values for the three dimensions. Finally, the model is pruned along the three optimal dimensions accordingly. In this framework, since collecting too much data for training the regression is very time-costly, we propose two approaches to lower the cost: 1) specializing the polynomial to ensure an accurate regression even with less training data; 2) employing iterative pruning and fine-tuning to collect the data faster. Extensive experiments show that our proposed algorithm surpasses state-of-the-art pruning algorithms and even neural architecture search-based algorithms.



### Deep Active Learning for Joint Classification & Segmentation with Weak Annotator
- **Arxiv ID**: http://arxiv.org/abs/2010.04889v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.04889v2)
- **Published**: 2020-10-10 03:25:54+00:00
- **Updated**: 2020-11-14 04:09:55+00:00
- **Authors**: Soufiane Belharbi, Ismail Ben Ayed, Luke McCaffrey, Eric Granger
- **Comment**: 20 pages, 12 figures, WACV 2021
- **Journal**: None
- **Summary**: CNN visualization and interpretation methods, like class-activation maps (CAMs), are typically used to highlight the image regions linked to class predictions. These models allow to simultaneously classify images and extract class-dependent saliency maps, without the need for costly pixel-level annotations. However, they typically yield segmentations with high false-positive rates and, therefore, coarse visualisations, more so when processing challenging images, as encountered in histology. To mitigate this issue, we propose an active learning (AL) framework, which progressively integrates pixel-level annotations during training. Given training data with global image-level labels, our deep weakly-supervised learning model jointly performs supervised image-level classification and active learning for segmentation, integrating pixel annotations by an oracle. Unlike standard AL methods that focus on sample selection, we also leverage large numbers of unlabeled images via pseudo-segmentations (i.e., self-learning at the pixel level), and integrate them with the oracle-annotated samples during training. We report extensive experiments over two challenging benchmarks -- high-resolution medical images (histology GlaS data for colon cancer) and natural images (CUB-200-2011 for bird species). Our results indicate that, by simply using random sample selection, the proposed approach can significantly outperform state-of the-art CAMs and AL methods, with an identical oracle-supervision budget. Our code is publicly available.



### Online Anomaly Detection in Surveillance Videos with Asymptotic Bounds on False Alarm Rate
- **Arxiv ID**: http://arxiv.org/abs/2010.07110v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2010.07110v1)
- **Published**: 2020-10-10 04:46:16+00:00
- **Updated**: 2020-10-10 04:46:16+00:00
- **Authors**: Keval Doshi, Yasin Yilmaz
- **Comment**: Submitted to Pattern Recognition. arXiv admin note: substantial text
  overlap with arXiv:2004.07941
- **Journal**: None
- **Summary**: Anomaly detection in surveillance videos is attracting an increasing amount of attention. Despite the competitive performance of recent methods, they lack theoretical performance analysis, particularly due to the complex deep neural network architectures used in decision making. Additionally, online decision making is an important but mostly neglected factor in this domain. Much of the existing methods that claim to be online, depend on batch or offline processing in practice. Motivated by these research gaps, we propose an online anomaly detection method in surveillance videos with asymptotic bounds on the false alarm rate, which in turn provides a clear procedure for selecting a proper decision threshold that satisfies the desired false alarm rate. Our proposed algorithm consists of a multi-objective deep learning module along with a statistical anomaly detection module, and its effectiveness is demonstrated on several publicly available data sets where we outperform the state-of-the-art algorithms. All codes are available at https://github.com/kevaldoshi17/Prediction-based-Video-Anomaly-Detection-.



### Multi-path Neural Networks for On-device Multi-domain Visual Classification
- **Arxiv ID**: http://arxiv.org/abs/2010.04904v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.04904v2)
- **Published**: 2020-10-10 05:13:49+00:00
- **Updated**: 2021-01-08 08:02:15+00:00
- **Authors**: Qifei Wang, Junjie Ke, Joshua Greaves, Grace Chu, Gabriel Bender, Luciano Sbaiz, Alec Go, Andrew Howard, Feng Yang, Ming-Hsuan Yang, Jeff Gilbert, Peyman Milanfar
- **Comment**: WACV 2021
- **Journal**: None
- **Summary**: Learning multiple domains/tasks with a single model is important for improving data efficiency and lowering inference cost for numerous vision tasks, especially on resource-constrained mobile devices. However, hand-crafting a multi-domain/task model can be both tedious and challenging. This paper proposes a novel approach to automatically learn a multi-path network for multi-domain visual classification on mobile devices. The proposed multi-path network is learned from neural architecture search by applying one reinforcement learning controller for each domain to select the best path in the super-network created from a MobileNetV3-like search space. An adaptive balanced domain prioritization algorithm is proposed to balance optimizing the joint model on multiple domains simultaneously. The determined multi-path model selectively shares parameters across domains in shared nodes while keeping domain-specific parameters within non-shared nodes in individual domain paths. This approach effectively reduces the total number of parameters and FLOPS, encouraging positive knowledge transfer while mitigating negative interference across domains. Extensive evaluations on the Visual Decathlon dataset demonstrate that the proposed multi-path model achieves state-of-the-art performance in terms of accuracy, model size, and FLOPS against other approaches using MobileNetV3-like architectures. Furthermore, the proposed method improves average accuracy over learning single-domain models individually, and reduces the total number of parameters and FLOPS by 78% and 32% respectively, compared to the approach that simply bundles single-domain models for multi-domain learning.



### Interpretable Neural Computation for Real-World Compositional Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/2010.04913v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.04913v1)
- **Published**: 2020-10-10 05:46:22+00:00
- **Updated**: 2020-10-10 05:46:22+00:00
- **Authors**: Ruixue Tang, Chao Ma
- **Comment**: PRCV 2020
- **Journal**: None
- **Summary**: There are two main lines of research on visual question answering (VQA): compositional model with explicit multi-hop reasoning, and monolithic network with implicit reasoning in the latent feature space. The former excels in interpretability and compositionality but fails on real-world images, while the latter usually achieves better performance due to model flexibility and parameter efficiency. We aim to combine the two to build an interpretable framework for real-world compositional VQA. In our framework, images and questions are disentangled into scene graphs and programs, and a symbolic program executor runs on them with full transparency to select the attention regions, which are then iteratively passed to a visual-linguistic pre-trained encoder to predict answers. Experiments conducted on the GQA benchmark demonstrate that our framework outperforms the compositional prior arts and achieves competitive accuracy among monolithic ones. With respect to the validity, plausibility and distribution metrics, our framework surpasses others by a considerable margin.



### Selective Information Passing for MR/CT Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2010.04920v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.04920v1)
- **Published**: 2020-10-10 06:47:53+00:00
- **Updated**: 2020-10-10 06:47:53+00:00
- **Authors**: Qikui Zhu, Liang Li, Jiangnan Hao, Yunfei Zha, Yan Zhang, Yanxiang Cheng, Fei Liao, Pingxiang Li
- **Comment**: None
- **Journal**: None
- **Summary**: Automated medical image segmentation plays an important role in many clinical applications, which however is a very challenging task, due to complex background texture, lack of clear boundary and significant shape and texture variation between images. Many researchers proposed an encoder-decoder architecture with skip connections to combine low-level feature maps from the encoder path with high-level feature maps from the decoder path for automatically segmenting medical images. The skip connections have been shown to be effective in recovering fine-grained details of the target objects and may facilitate the gradient back-propagation. However, not all the feature maps transmitted by those connections contribute positively to the network performance. In this paper, to adaptively select useful information to pass through those skip connections, we propose a novel 3D network with self-supervised function, named selective information passing network (SIP-Net). We evaluate our proposed model on the MICCAI Prostate MR Image Segmentation 2012 Grant Challenge dataset, TCIA Pancreas CT-82 and MICCAI 2017 Liver Tumor Segmentation (LiTS) Challenge dataset. The experimental results across these data sets show that our model achieved improved segmentation results and outperformed other state-of-the-art methods. The source code of this work is available at https://github.com/ahukui/SIPNet.



### Contrastive Rendering for Ultrasound Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2010.04928v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.04928v1)
- **Published**: 2020-10-10 07:14:03+00:00
- **Updated**: 2020-10-10 07:14:03+00:00
- **Authors**: Haoming Li, Xin Yang, Jiamin Liang, Wenlong Shi, Chaoyu Chen, Haoran Dou, Rui Li, Rui Gao, Guangquan Zhou, Jinghui Fang, Xiaowen Liang, Ruobing Huang, Alejandro Frangi, Zhiyi Chen, Dong Ni
- **Comment**: 10 pages, 5 figures, 2 tables, 13 references
- **Journal**: None
- **Summary**: Ultrasound (US) image segmentation embraced its significant improvement in deep learning era. However, the lack of sharp boundaries in US images still remains an inherent challenge for segmentation. Previous methods often resort to global context, multi-scale cues or auxiliary guidance to estimate the boundaries. It is hard for these methods to approach pixel-level learning for fine-grained boundary generating. In this paper, we propose a novel and effective framework to improve boundary estimation in US images. Our work has three highlights. First, we propose to formulate the boundary estimation as a rendering task, which can recognize ambiguous points (pixels/voxels) and calibrate the boundary prediction via enriched feature representation learning. Second, we introduce point-wise contrastive learning to enhance the similarity of points from the same class and contrastively decrease the similarity of points from different classes. Boundary ambiguities are therefore further addressed. Third, both rendering and contrastive learning tasks contribute to consistent improvement while reducing network parameters. As a proof-of-concept, we performed validation experiments on a challenging dataset of 86 ovarian US volumes. Results show that our proposed method outperforms state-of-the-art methods and has the potential to be used in clinical practice.



### An Empirical Study on Detecting COVID-19 in Chest X-ray Images Using Deep Learning Based Methods
- **Arxiv ID**: http://arxiv.org/abs/2010.04936v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2010.04936v1)
- **Published**: 2020-10-10 08:07:19+00:00
- **Updated**: 2020-10-10 08:07:19+00:00
- **Authors**: Ramtin Babaeipour, Elham Azizi, Hassan Khotanlou
- **Comment**: This paper is submitted to the The IKT 2020 conference
- **Journal**: None
- **Summary**: Spreading of COVID-19 virus has increased the efforts to provide testing kits. Not only the preparation of these kits had been hard, rare, and expensive but also using them is another issue. Results have shown that these kits take some crucial time to recognize the virus, in addition to the fact that they encounter with 30% loss. In this paper, we have studied the usage of x-ray pictures which are ubiquitous, for the classification of COVID-19 chest Xray images, by the existing convolutional neural networks (CNNs). We intend to train chest x-rays of infected and not infected ones with different CNNs architectures including VGG19, Densnet-121, and Xception. Training these architectures resulted in different accuracies which were much faster and more precise than usual ways of testing.



### Double Forward Propagation for Memorized Batch Normalization
- **Arxiv ID**: http://arxiv.org/abs/2010.04947v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.04947v1)
- **Published**: 2020-10-10 08:48:41+00:00
- **Updated**: 2020-10-10 08:48:41+00:00
- **Authors**: Yong Guo, Qingyao Wu, Chaorui Deng, Jian Chen, Mingkui Tan
- **Comment**: AAAI2018, 8 pages, 3 figures
- **Journal**: None
- **Summary**: Batch Normalization (BN) has been a standard component in designing deep neural networks (DNNs). Although the standard BN can significantly accelerate the training of DNNs and improve the generalization performance, it has several underlying limitations which may hamper the performance in both training and inference. In the training stage, BN relies on estimating the mean and variance of data using a single minibatch. Consequently, BN can be unstable when the batch size is very small or the data is poorly sampled. In the inference stage, BN often uses the so called moving mean and moving variance instead of batch statistics, i.e., the training and inference rules in BN are not consistent. Regarding these issues, we propose a memorized batch normalization (MBN), which considers multiple recent batches to obtain more accurate and robust statistics. Note that after the SGD update for each batch, the model parameters will change, and the features will change accordingly, leading to the Distribution Shift before and after the update for the considered batch. To alleviate this issue, we present a simple Double-Forward scheme in MBN which can further improve the performance. Compared to related methods, the proposed MBN exhibits consistent behaviors in both training and inference. Empirical results show that the MBN based models trained with the Double-Forward scheme greatly reduce the sensitivity of data and significantly improve the generalization performance.



### HCNet: Hierarchical Context Network for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2010.04962v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.04962v2)
- **Published**: 2020-10-10 09:51:17+00:00
- **Updated**: 2020-10-20 03:06:36+00:00
- **Authors**: Yanwen Chong, Congchong Nie, Yulong Tao, Xiaoshu Chen, Shaoming Pan
- **Comment**: None
- **Journal**: None
- **Summary**: Global context information is vital in visual understanding problems, especially in pixel-level semantic segmentation. The mainstream methods adopt the self-attention mechanism to model global context information. However, pixels belonging to different classes usually have weak feature correlation. Modeling the global pixel-level correlation matrix indiscriminately is extremely redundant in the self-attention mechanism. In order to solve the above problem, we propose a hierarchical context network to differentially model homogeneous pixels with strong correlations and heterogeneous pixels with weak correlations. Specifically, we first propose a multi-scale guided pre-segmentation module to divide the entire feature map into different classed-based homogeneous regions. Within each homogeneous region, we design the pixel context module to capture pixel-level correlations. Subsequently, different from the self-attention mechanism that still models weak heterogeneous correlations in a dense pixel-level manner, the region context module is proposed to model sparse region-level dependencies using a unified representation of each region. Through aggregating fine-grained pixel context features and coarse-grained region context features, our proposed network can not only hierarchically model global context information but also harvest multi-granularity representations to more robustly identify multi-scale objects. We evaluate our approach on Cityscapes and the ISPRS Vaihingen dataset. Without Bells or Whistles, our approach realizes a mean IoU of 82.8% and overall accuracy of 91.4% on Cityscapes and ISPRS Vaihingen test set, achieving state-of-the-art results.



### Light Field Salient Object Detection: A Review and Benchmark
- **Arxiv ID**: http://arxiv.org/abs/2010.04968v4
- **DOI**: 10.1007/s41095-021-0256-2
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.04968v4)
- **Published**: 2020-10-10 10:30:40+00:00
- **Updated**: 2021-07-24 14:23:26+00:00
- **Authors**: Keren Fu, Yao Jiang, Ge-Peng Ji, Tao Zhou, Qijun Zhao, Deng-Ping Fan
- **Comment**: None
- **Journal**: Computational Visual Media, 2022, Vol. 8, No. 4, Pages: 509-534
- **Summary**: Salient object detection (SOD) is a long-standing research topic in computer vision and has drawn an increasing amount of research interest in the past decade. This paper provides the first comprehensive review and benchmark for light field SOD, which has long been lacking in the saliency community. Firstly, we introduce preliminary knowledge on light fields, including theory and data forms, and then review existing studies on light field SOD, covering ten traditional models, seven deep learning-based models, one comparative study, and one brief review. Existing datasets for light field SOD are also summarized with detailed information and statistical analyses. Secondly, we benchmark nine representative light field SOD models together with several cutting-edge RGB-D SOD models on four widely used light field datasets, from which insightful discussions and analyses, including a comparison between light field SOD and RGB-D SOD models, are achieved. Besides, due to the inconsistency of datasets in their current forms, we further generate complete data and supplement focal stacks, depth maps and multi-view images for the inconsistent datasets, making them consistent and unified. Our supplemental data makes a universal benchmark possible. Lastly, because light field SOD is quite a special problem attributed to its diverse data representations and high dependency on acquisition hardware, making it differ greatly from other saliency detection tasks, we provide nine hints into the challenges and future directions, and outline several open issues. We hope our review and benchmarking could help advance research in this field. All the materials including collected models, datasets, benchmarking results, and supplemented light field datasets will be publicly available on our project site https://github.com/kerenfu/LFSOD-Survey.



### A Termination Criterion for Probabilistic PointClouds Registration
- **Arxiv ID**: http://arxiv.org/abs/2010.04979v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.04979v1)
- **Published**: 2020-10-10 12:02:18+00:00
- **Updated**: 2020-10-10 12:02:18+00:00
- **Authors**: Simone Fontana, Domenico G. Sorrenti
- **Comment**: None
- **Journal**: None
- **Summary**: Probabilistic Point Clouds Registration (PPCR) is an algorithm that, in its multi-iteration version, outperformed state of the art algorithms for local point clouds registration. However, its performances have been tested using a fixed high number of iterations. To be of practical usefulness, we think that the algorithm should decide by itself when to stop, to avoid an excessive number of iterations and, therefore, wasting computational time. With this work, we compare different termination criterion on several datasets and prove that the chosen one produce very good results that are comparable to those obtained using a very high number of iterations while saving computational time.



### Category-Learning with Context-Augmented Autoencoder
- **Arxiv ID**: http://arxiv.org/abs/2010.05007v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2010.05007v1)
- **Published**: 2020-10-10 14:04:44+00:00
- **Updated**: 2020-10-10 14:04:44+00:00
- **Authors**: Denis Kuzminykh, Laida Kushnareva, Timofey Grigoryev, Alexander Zatolokin
- **Comment**: 11 pages, 12 figures
- **Journal**: Information Technologies and Computing Systems 3/2020, pp. 30-39
- **Summary**: Finding an interpretable non-redundant representation of real-world data is one of the key problems in Machine Learning. Biological neural networks are known to solve this problem quite well in unsupervised manner, yet unsupervised artificial neural networks either struggle to do it or require fine tuning for each task individually. We associate this with the fact that a biological brain learns in the context of the relationships between observations, while an artificial network does not. We also notice that, though a naive data augmentation technique can be very useful for supervised learning problems, autoencoders typically fail to generalize transformations from data augmentations. Thus, we believe that providing additional knowledge about relationships between data samples will improve model's capability of finding useful inner data representation. More formally, we consider a dataset not as a manifold, but as a category, where the examples are objects. Two these objects are connected by a morphism, if they actually represent different transformations of the same entity. Following this formalism, we propose a novel method of using data augmentations when training autoencoders. We train a Variational Autoencoder in such a way, that it makes transformation outcome predictable by auxiliary network in terms of the hidden representation. We believe that the classification accuracy of a linear classifier on the learned representation is a good metric to measure its interpretability. In our experiments, present approach outperforms $\beta$-VAE and is comparable with Gaussian-mixture VAE.



### An Encoder-Decoder CNN for Hair Removal in Dermoscopic Images
- **Arxiv ID**: http://arxiv.org/abs/2010.05013v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2010.05013v1)
- **Published**: 2020-10-10 14:28:10+00:00
- **Updated**: 2020-10-10 14:28:10+00:00
- **Authors**: Lidia Talavera-Martínez, Pedro Bibiloni, Manuel González-Hidalgo
- **Comment**: None
- **Journal**: None
- **Summary**: The process of removing occluding hair has a relevant role in the early and accurate diagnosis of skin cancer. It consists of detecting hairs and restore the texture below them, which is sporadically occluded. In this work, we present a model based on convolutional neural networks for hair removal in dermoscopic images. During the network's training, we use a combined loss function to improve the restoration ability of the proposed model. In order to train the CNN and to quantitatively validate their performance, we simulate the presence of skin hair in hairless images extracted from publicly known datasets such as the PH2, dermquest, dermis, EDRA2002, and the ISIC Data Archive. As far as we know, there is no other hair removal method based on deep learning. Thus, we compare our results with six state-of-the-art algorithms based on traditional computer vision techniques by means of similarity measures that compare the reference hairless image and the one with hair simulated. Finally, a statistical test is used to compare the methods. Both qualitative and quantitative results demonstrate the effectiveness of our network.



### Boosted EfficientNet: Detection of Lymph Node Metastases in Breast Cancer Using Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2010.05027v1
- **DOI**: 10.3390/cancers13040661
- **Categories**: **cs.CV**, I.4; J.3
- **Links**: [PDF](http://arxiv.org/pdf/2010.05027v1)
- **Published**: 2020-10-10 15:18:56+00:00
- **Updated**: 2020-10-10 15:18:56+00:00
- **Authors**: Jun Wang, Qianying Liu, Haotian Xie, Zhaogang Yang, Hefeng Zhou
- **Comment**: 17 pages, 7 figures, 2 tables, journal
- **Journal**: None
- **Summary**: In recent years, advances in the development of whole-slide images have laid a foundation for the utilization of digital images in pathology. With the assistance of computer images analysis that automatically identifies tissue or cell types, they have greatly improved the histopathologic interpretation and diagnosis accuracy. In this paper, the Convolutional Neutral Network (CNN) has been adapted to predict and classify lymph node metastasis in breast cancer. Unlike traditional image cropping methods that are only suitable for large resolution images, we propose a novel data augmentation method named Random Center Cropping (RCC) to facilitate small resolution images. RCC enriches the datasets while retaining the image resolution and the center area of images. In addition, we reduce the downsampling scale of the network to further facilitate small resolution images better. Moreover, Attention and Feature Fusion (FF) mechanisms are employed to improve the semantic information of images. Experiments demonstrate that our methods boost performances of basic CNN architectures. And the best-performed method achieves an accuracy of 97.96% and an AUC of 99.68% on RPCam datasets, respectively.



### Interpreting Multivariate Shapley Interactions in DNNs
- **Arxiv ID**: http://arxiv.org/abs/2010.05045v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2010.05045v4)
- **Published**: 2020-10-10 17:02:51+00:00
- **Updated**: 2021-02-03 09:12:47+00:00
- **Authors**: Hao Zhang, Yichen Xie, Longjie Zheng, Die Zhang, Quanshi Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper aims to explain deep neural networks (DNNs) from the perspective of multivariate interactions. In this paper, we define and quantify the significance of interactions among multiple input variables of the DNN. Input variables with strong interactions usually form a coalition and reflect prototype features, which are memorized and used by the DNN for inference. We define the significance of interactions based on the Shapley value, which is designed to assign the attribution value of each input variable to the inference. We have conducted experiments with various DNNs. Experimental results have demonstrated the effectiveness of the proposed method.



### Adaptive Aggregation Networks for Class-Incremental Learning
- **Arxiv ID**: http://arxiv.org/abs/2010.05063v3
- **DOI**: 10.1109/CVPR46437.2021.00257
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2010.05063v3)
- **Published**: 2020-10-10 18:24:24+00:00
- **Updated**: 2021-03-29 22:09:07+00:00
- **Authors**: Yaoyao Liu, Bernt Schiele, Qianru Sun
- **Comment**: Accepted to CVPR 2021. Code:
  https://github.com/yaoyao-liu/class-incremental-learning
- **Journal**: None
- **Summary**: Class-Incremental Learning (CIL) aims to learn a classification model with the number of classes increasing phase-by-phase. An inherent problem in CIL is the stability-plasticity dilemma between the learning of old and new classes, i.e., high-plasticity models easily forget old classes, but high-stability models are weak to learn new classes. We alleviate this issue by proposing a novel network architecture called Adaptive Aggregation Networks (AANets), in which we explicitly build two types of residual blocks at each residual level (taking ResNet as the baseline architecture): a stable block and a plastic block. We aggregate the output feature maps from these two blocks and then feed the results to the next-level blocks. We adapt the aggregation weights in order to balance these two types of blocks, i.e., to balance stability and plasticity, dynamically. We conduct extensive experiments on three CIL benchmarks: CIFAR-100, ImageNet-Subset, and ImageNet, and show that many existing CIL methods can be straightforwardly incorporated into the architecture of AANets to boost their performances.



### Hybrid-S2S: Video Object Segmentation with Recurrent Networks and Correspondence Matching
- **Arxiv ID**: http://arxiv.org/abs/2010.05069v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.05069v2)
- **Published**: 2020-10-10 19:00:43+00:00
- **Updated**: 2020-11-07 09:33:51+00:00
- **Authors**: Fatemeh Azimi, Stanislav Frolov, Federico Raue, Joern Hees, Andreas Dengel
- **Comment**: None
- **Journal**: None
- **Summary**: One-shot Video Object Segmentation~(VOS) is the task of pixel-wise tracking an object of interest within a video sequence, where the segmentation mask of the first frame is given at inference time. In recent years, Recurrent Neural Networks~(RNNs) have been widely used for VOS tasks, but they often suffer from limitations such as drift and error propagation. In this work, we study an RNN-based architecture and address some of these issues by proposing a hybrid sequence-to-sequence architecture named HS2S, utilizing a dual mask propagation strategy that allows incorporating the information obtained from correspondence matching. Our experiments show that augmenting the RNN with correspondence matching is a highly effective solution to reduce the drift problem. The additional information helps the model to predict more accurate masks and makes it robust against error propagation. We evaluate our HS2S model on the DAVIS2017 dataset as well as Youtube-VOS. On the latter, we achieve an improvement of 11.2pp in the overall segmentation accuracy over RNN-based state-of-the-art methods in VOS. We analyze our model's behavior in challenging cases such as occlusion and long sequences and show that our hybrid architecture significantly enhances the segmentation quality in these difficult scenarios.



### Diagnosing and Preventing Instabilities in Recurrent Video Processing
- **Arxiv ID**: http://arxiv.org/abs/2010.05099v3
- **DOI**: 10.1109/TPAMI.2022.3160350
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2010.05099v3)
- **Published**: 2020-10-10 21:39:28+00:00
- **Updated**: 2023-03-11 16:59:38+00:00
- **Authors**: Thomas Tanay, Aivar Sootla, Matteo Maggioni, Puneet K. Dokania, Philip Torr, Ales Leonardis, Gregory Slabaugh
- **Comment**: None
- **Journal**: in IEEE Transactions on Pattern Analysis and Machine Intelligence,
  vol. 45, no. 2, pp. 1594-1605, 1 Feb. 2023
- **Summary**: Recurrent models are a popular choice for video enhancement tasks such as video denoising or super-resolution. In this work, we focus on their stability as dynamical systems and show that they tend to fail catastrophically at inference time on long video sequences. To address this issue, we (1) introduce a diagnostic tool which produces input sequences optimized to trigger instabilities and that can be interpreted as visualizations of temporal receptive fields, and (2) propose two approaches to enforce the stability of a model during training: constraining the spectral norm or constraining the stable rank of its convolutional layers. We then introduce Stable Rank Normalization for Convolutional layers (SRN-C), a new algorithm that enforces these constraints. Our experimental results suggest that SRN-C successfully enforces stability in recurrent video processing models without a significant performance loss.



### Anomaly Detection based on Zero-Shot Outlier Synthesis and Hierarchical Feature Distillation
- **Arxiv ID**: http://arxiv.org/abs/2010.05119v1
- **DOI**: 10.1109/TNNLS.2020.3027667
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2010.05119v1)
- **Published**: 2020-10-10 23:34:02+00:00
- **Updated**: 2020-10-10 23:34:02+00:00
- **Authors**: Adín Ramírez Rivera, Adil Khan, Imad E. I. Bekkouch, Taimoor S. Sheikh
- **Comment**: To appear in IEEE Trans. on Neural Networks and Learning Systems
- **Journal**: None
- **Summary**: Anomaly detection suffers from unbalanced data since anomalies are quite rare. Synthetically generated anomalies are a solution to such ill or not fully defined data. However, synthesis requires an expressive representation to guarantee the quality of the generated data. In this paper, we propose a two-level hierarchical latent space representation that distills inliers' feature-descriptors (through autoencoders) into more robust representations based on a variational family of distributions (through a variational autoencoder) for zero-shot anomaly generation. From the learned latent distributions, we select those that lie on the outskirts of the training data as synthetic-outlier generators. And, we synthesize from them, i.e., generate negative samples without seen them before, to train binary classifiers. We found that the use of the proposed hierarchical structure for feature distillation and fusion creates robust and general representations that allow us to synthesize pseudo outlier samples. And in turn, train robust binary classifiers for true outlier detection (without the need for actual outliers during training). We demonstrate the performance of our proposal on several benchmarks for anomaly detection.



