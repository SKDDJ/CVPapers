# Arxiv Papers in cs.CV on 2020-02-27
### Analysis of diversity-accuracy tradeoff in image captioning
- **Arxiv ID**: http://arxiv.org/abs/2002.11848v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11848v1)
- **Published**: 2020-02-27 00:09:25+00:00
- **Updated**: 2020-02-27 00:09:25+00:00
- **Authors**: Ruotian Luo, Gregory Shakhnarovich
- **Comment**: None
- **Journal**: None
- **Summary**: We investigate the effect of different model architectures, training objectives, hyperparameter settings and decoding procedures on the diversity of automatically generated image captions. Our results show that 1) simple decoding by naive sampling, coupled with low temperature is a competitive and fast method to produce diverse and accurate caption sets; 2) training with CIDEr-based reward using Reinforcement learning harms the diversity properties of the resulting generator, which cannot be mitigated by manipulating decoding parameters. In addition, we propose a new metric AllSPICE for evaluating both accuracy and diversity of a set of captions by a single value.



### Comparison of Multi-Class and Binary Classification Machine Learning Models in Identifying Strong Gravitational Lenses
- **Arxiv ID**: http://arxiv.org/abs/2002.11849v1
- **DOI**: 10.1088/1538-3873/ab747b
- **Categories**: **astro-ph.GA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11849v1)
- **Published**: 2020-02-27 00:11:31+00:00
- **Updated**: 2020-02-27 00:11:31+00:00
- **Authors**: Hossen Teimoorinia, Robert D. Toyonaga, Sebastien Fabbro, Connor Bottrell
- **Comment**: PASP accepted, 14 pages, 10 figures, 4 tables
- **Journal**: None
- **Summary**: Typically, binary classification lens-finding schemes are used to discriminate between lens candidates and non-lenses. However, these models often suffer from substantial false-positive classifications. Such false positives frequently occur due to images containing objects such as crowded sources, galaxies with arms, and also images with a central source and smaller surrounding sources. Therefore, a model might confuse the stated circumstances with an Einstein ring. It has been proposed that by allowing such commonly misclassified image types to constitute their own classes, machine learning models will more easily be able to learn the difference between images that contain real lenses, and images that contain lens imposters. Using Hubble Space Telescope (HST) images, in the F814W filter, we compare the usage of binary and multi-class classification models applied to the lens finding task. From our findings, we conclude there is not a significant benefit to using the multi-class model over a binary model. We will also present the results of a simple lens search using a multi-class machine learning model, and potential new lens candidates.



### GATCluster: Self-Supervised Gaussian-Attention Network for Image Clustering
- **Arxiv ID**: http://arxiv.org/abs/2002.11863v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11863v2)
- **Published**: 2020-02-27 00:57:18+00:00
- **Updated**: 2020-06-06 20:09:39+00:00
- **Authors**: Chuang Niu, Jun Zhang, Ge Wang, Jimin Liang
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a self-supervised Gaussian ATtention network for image Clustering (GATCluster). Rather than extracting intermediate features first and then performing the traditional clustering algorithm, GATCluster directly outputs semantic cluster labels without further post-processing. Theoretically, we give a Label Feature Theorem to guarantee the learned features are one-hot encoded vectors, and the trivial solutions are avoided. To train the GATCluster in a completely unsupervised manner, we design four self-learning tasks with the constraints of transformation invariance, separability maximization, entropy analysis, and attention mapping. Specifically, the transformation invariance and separability maximization tasks learn the relationships between sample pairs. The entropy analysis task aims to avoid trivial solutions. To capture the object-oriented semantics, we design a self-supervised attention mechanism that includes a parameterized attention module and a soft-attention loss. All the guiding signals for clustering are self-generated during the training process. Moreover, we develop a two-step learning algorithm that is memory-efficient for clustering large-size images. Extensive experiments demonstrate the superiority of our proposed method in comparison with the state-of-the-art image clustering benchmarks. Our code has been made publicly available at https://github.com/niuchuangnn/GATCluster.



### Defense-PointNet: Protecting PointNet Against Adversarial Attacks
- **Arxiv ID**: http://arxiv.org/abs/2002.11881v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11881v1)
- **Published**: 2020-02-27 02:35:08+00:00
- **Updated**: 2020-02-27 02:35:08+00:00
- **Authors**: Yu Zhang, Gongbo Liang, Tawfiq Salem, Nathan Jacobs
- **Comment**: Accepted by IEEE International Conference on Big Data (BigData)
  Workshop: The Next Frontier of Big Data From LiDAR, 2019
- **Journal**: None
- **Summary**: Despite remarkable performance across a broad range of tasks, neural networks have been shown to be vulnerable to adversarial attacks. Many works focus on adversarial attacks and defenses on 2D images, but few focus on 3D point clouds. In this paper, our goal is to enhance the adversarial robustness of PointNet, which is one of the most widely used models for 3D point clouds. We apply the fast gradient sign attack method (FGSM) on 3D point clouds and find that FGSM can be used to generate not only adversarial images but also adversarial point clouds. To minimize the vulnerability of PointNet to adversarial attacks, we propose Defense-PointNet. We compare our model with two baseline approaches and show that Defense-PointNet significantly improves the robustness of the network against adversarial samples.



### Kernel Bi-Linear Modeling for Reconstructing Data on Manifolds: The Dynamic-MRI Case
- **Arxiv ID**: http://arxiv.org/abs/2002.11885v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.11885v1)
- **Published**: 2020-02-27 02:42:08+00:00
- **Updated**: 2020-02-27 02:42:08+00:00
- **Authors**: Gaurav N. Shetty, Konstantinos Slavakis, Ukash Nakarmi, Gesualdo Scutari, Leslie Ying
- **Comment**: None
- **Journal**: None
- **Summary**: This paper establishes a kernel-based framework for reconstructing data on manifolds, tailored to fit the dynamic-(d)MRI-data recovery problem. The proposed methodology exploits simple tangent-space geometries of manifolds in reproducing kernel Hilbert spaces and follows classical kernel-approximation arguments to form the data-recovery task as a bi-linear inverse problem. Departing from mainstream approaches, the proposed methodology uses no training data, employs no graph Laplacian matrix to penalize the optimization task, uses no costly (kernel) pre-imaging step to map feature points back to the input space, and utilizes complex-valued kernel functions to account for k-space data. The framework is validated on synthetically generated dMRI data, where comparisons against state-of-the-art schemes highlight the rich potential of the proposed approach in data-recovery problems.



### Hierarchical Memory Decoding for Video Captioning
- **Arxiv ID**: http://arxiv.org/abs/2002.11886v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.11886v1)
- **Published**: 2020-02-27 02:48:10+00:00
- **Updated**: 2020-02-27 02:48:10+00:00
- **Authors**: Aming Wu, Yahong Han
- **Comment**: None
- **Journal**: None
- **Summary**: Recent advances of video captioning often employ a recurrent neural network (RNN) as the decoder. However, RNN is prone to diluting long-term information. Recent works have demonstrated memory network (MemNet) has the advantage of storing long-term information. However, as the decoder, it has not been well exploited for video captioning. The reason partially comes from the difficulty of sequence decoding with MemNet. Instead of the common practice, i.e., sequence decoding with RNN, in this paper, we devise a novel memory decoder for video captioning. Concretely, after obtaining representation of each frame through a pre-trained network, we first fuse the visual and lexical information. Then, at each time step, we construct a multi-layer MemNet-based decoder, i.e., in each layer, we employ a memory set to store previous information and an attention mechanism to select the information related to the current input. Thus, this decoder avoids the dilution of long-term information. And the multi-layer architecture is helpful for capturing dependencies between frames and word sequences. Experimental results show that even without the encoding network, our decoder still could obtain competitive performance and outperform the performance of RNN decoder. Furthermore, compared with one-layer RNN decoder, our decoder has fewer parameters.



### BBAND Index: A No-Reference Banding Artifact Predictor
- **Arxiv ID**: http://arxiv.org/abs/2002.11891v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2002.11891v1)
- **Published**: 2020-02-27 03:05:26+00:00
- **Updated**: 2020-02-27 03:05:26+00:00
- **Authors**: Zhengzhong Tu, Jessie Lin, Yilin Wang, Balu Adsumilli, Alan C. Bovik
- **Comment**: Accepted by ICASSP 2020
- **Journal**: None
- **Summary**: Banding artifact, or false contouring, is a common video compression impairment that tends to appear on large flat regions in encoded videos. These staircase-shaped color bands can be very noticeable in high-definition videos. Here we study this artifact, and propose a new distortion-specific no-reference video quality model for predicting banding artifacts, called the Blind BANding Detector (BBAND index). BBAND is inspired by human visual models. The proposed detector can generate a pixel-wise banding visibility map and output a banding severity score at both the frame and video levels. Experimental results show that our proposed method outperforms state-of-the-art banding detection algorithms and delivers better consistency with subjective evaluations.



### Unshuffling Data for Improved Generalization
- **Arxiv ID**: http://arxiv.org/abs/2002.11894v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.11894v3)
- **Published**: 2020-02-27 03:07:41+00:00
- **Updated**: 2020-11-20 23:14:33+00:00
- **Authors**: Damien Teney, Ehsan Abbasnejad, Anton van den Hengel
- **Comment**: None
- **Journal**: None
- **Summary**: Generalization beyond the training distribution is a core challenge in machine learning. The common practice of mixing and shuffling examples when training neural networks may not be optimal in this regard. We show that partitioning the data into well-chosen, non-i.i.d. subsets treated as multiple training environments can guide the learning of models with better out-of-distribution generalization. We describe a training procedure to capture the patterns that are stable across environments while discarding spurious ones. The method makes a step beyond correlation-based learning: the choice of the partitioning allows injecting information about the task that cannot be otherwise recovered from the joint distribution of the training data. We demonstrate multiple use cases with the task of visual question answering, which is notorious for dataset biases. We obtain significant improvements on VQA-CP, using environments built from prior knowledge, existing meta data, or unsupervised clustering. We also get improvements on GQA using annotations of "equivalent questions", and on multi-dataset training (VQA v2 / Visual Genome) by treating them as distinct environments.



### Gradient Boosted Normalizing Flows
- **Arxiv ID**: http://arxiv.org/abs/2002.11896v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.11896v4)
- **Published**: 2020-02-27 03:12:08+00:00
- **Updated**: 2020-10-17 20:09:27+00:00
- **Authors**: Robert Giaquinto, Arindam Banerjee
- **Comment**: Appearing in the 34th Conference on Neural Information Processing
  Systems (NeurIPS 2020), Vancouver, Canada
- **Journal**: None
- **Summary**: By chaining a sequence of differentiable invertible transformations, normalizing flows (NF) provide an expressive method of posterior approximation, exact density evaluation, and sampling. The trend in normalizing flow literature has been to devise deeper, more complex transformations to achieve greater flexibility. We propose an alternative: Gradient Boosted Normalizing Flows (GBNF) model a density by successively adding new NF components with gradient boosting. Under the boosting framework, each new NF component optimizes a sample weighted likelihood objective, resulting in new components that are fit to the residuals of the previously trained components. The GBNF formulation results in a mixture model structure, whose flexibility increases as more components are added. Moreover, GBNFs offer a wider, as opposed to strictly deeper, approach that improves existing NFs at the cost of additional training---not more complex transformations. We demonstrate the effectiveness of this technique for density estimation and, by coupling GBNF with a variational autoencoder, generative modeling of images. Our results show that GBNFs outperform their non-boosted analog, and, in some cases, produce better results with smaller, simpler flows.



### A Neuromorphic Proto-Object Based Dynamic Visual Saliency Model with an FPGA Implementation
- **Arxiv ID**: http://arxiv.org/abs/2002.11898v3
- **DOI**: 10.1109/TBCAS.2021.3089622
- **Categories**: **cs.NE**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11898v3)
- **Published**: 2020-02-27 03:31:56+00:00
- **Updated**: 2020-04-12 02:04:47+00:00
- **Authors**: Jamal Lottier Molin, Chetan Singh Thakur, Ralph Etienne-Cummings, Ernst Niebur
- **Comment**: 15 pages, 6 figures, 6 tables, journal
- **Journal**: None
- **Summary**: The ability to attend to salient regions of a visual scene is an innate and necessary preprocessing step for both biological and engineered systems performing high-level visual tasks (e.g. object detection, tracking, and classification). Computational efficiency, in regard to processing bandwidth and speed, is improved by only devoting computational resources to salient regions of the visual stimuli. In this paper, we first present a neuromorphic, bottom-up, dynamic visual saliency model based on the notion of proto-objects. This is achieved by incorporating the temporal characteristics of the visual stimulus into the model, similarly to the manner in which early stages of the human visual system extracts temporal information. This neuromorphic model outperforms state-of-the-art dynamic visual saliency models in predicting human eye fixations on a commonly used video dataset with associated eye tracking data. Secondly, for this model to have practical applications, it must be capable of performing its computations in real-time under low-power, small-size, and lightweight constraints. To address this, we introduce a Field-Programmable Gate Array implementation of the model on an Opal Kelly 7350 Kintex-7 board. This novel hardware implementation allows for processing of up to 23.35 frames per second running on a 100 MHz clock - better than 26x speedup from the software implementation.



### Segmentation-based Method combined with Dynamic Programming for Brain Midline Delineation
- **Arxiv ID**: http://arxiv.org/abs/2002.11918v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11918v1)
- **Published**: 2020-02-27 05:12:18+00:00
- **Updated**: 2020-02-27 05:12:18+00:00
- **Authors**: Shen Wang, Kongming Liang, Chengwei Pan, Chuyang Ye, Xiuli Li, Feng Liu, Yizhou Yu, Yizhou Wang
- **Comment**: None
- **Journal**: None
- **Summary**: The midline related pathological image features are crucial for evaluating the severity of brain compression caused by stroke or traumatic brain injury (TBI). The automated midline delineation not only improves the assessment and clinical decision making for patients with stroke symptoms or head trauma but also reduces the time of diagnosis. Nevertheless, most of the previous methods model the midline by localizing the anatomical points, which are hard to detect or even missing in severe cases. In this paper, we formulate the brain midline delineation as a segmentation task and propose a three-stage framework. The proposed framework firstly aligns an input CT image into the standard space. Then, the aligned image is processed by a midline detection network (MD-Net) integrated with the CoordConv Layer and Cascade AtrousCconv Module to obtain the probability map. Finally, we formulate the optimal midline selection as a pathfinding problem to solve the problem of the discontinuity of midline delineation. Experimental results show that our proposed framework can achieve superior performance on one in-house dataset and one public dataset.



### RNNPool: Efficient Non-linear Pooling for RAM Constrained Inference
- **Arxiv ID**: http://arxiv.org/abs/2002.11921v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.11921v2)
- **Published**: 2020-02-27 05:22:44+00:00
- **Updated**: 2020-10-22 21:05:24+00:00
- **Authors**: Oindrila Saha, Aditya Kusupati, Harsha Vardhan Simhadri, Manik Varma, Prateek Jain
- **Comment**: 25 pages, 8 figures. Published at Advances in Neural Information
  Processing Systems (NeurIPS) 2020
- **Journal**: None
- **Summary**: Standard Convolutional Neural Networks (CNNs) designed for computer vision tasks tend to have large intermediate activation maps. These require large working memory and are thus unsuitable for deployment on resource-constrained devices typically used for inference on the edge. Aggressively downsampling the images via pooling or strided convolutions can address the problem but leads to a significant decrease in accuracy due to gross aggregation of the feature map by standard pooling operators. In this paper, we introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efficiently aggregates features over large patches of an image and rapidly downsamples activation maps. Empirical evaluation indicates that an RNNPool layer can effectively replace multiple blocks in a variety of architectures such as MobileNets, DenseNet when applied to standard vision tasks like image classification and face detection. That is, RNNPool can significantly decrease computational complexity and peak memory usage for inference while retaining comparable accuracy. We use RNNPool with the standard S3FD architecture to construct a face detection method that achieves state-of-the-art MAP for tiny ARM Cortex-M4 class microcontrollers with under 256 KB of RAM. Code is released at https://github.com/Microsoft/EdgeML.



### Set-Constrained Viterbi for Set-Supervised Action Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2002.11925v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.11925v2)
- **Published**: 2020-02-27 05:32:52+00:00
- **Updated**: 2020-03-27 23:00:12+00:00
- **Authors**: Jun Li, Sinisa Todorovic
- **Comment**: CVPR 2020 conference paper
- **Journal**: None
- **Summary**: This paper is about weakly supervised action segmentation, where the ground truth specifies only a set of actions present in a training video, but not their true temporal ordering. Prior work typically uses a classifier that independently labels video frames for generating the pseudo ground truth, and multiple instance learning for training the classifier. We extend this framework by specifying an HMM, which accounts for co-occurrences of action classes and their temporal lengths, and by explicitly training the HMM on a Viterbi-based loss. Our first contribution is the formulation of a new set-constrained Viterbi algorithm (SCV). Given a video, the SCV generates the MAP action segmentation that satisfies the ground truth. This prediction is used as a framewise pseudo ground truth in our HMM training. Our second contribution in training is a new regularization of feature affinities between training videos that share the same action classes. Evaluation on action segmentation and alignment on the Breakfast, MPII Cooking2, Hollywood Extended datasets demonstrates our significant performance improvement for the two tasks over prior work.



### Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction
- **Arxiv ID**: http://arxiv.org/abs/2002.11927v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.11927v3)
- **Published**: 2020-02-27 05:40:23+00:00
- **Updated**: 2020-03-24 06:07:03+00:00
- **Authors**: Abduallah Mohamed, Kun Qian, Mohamed Elhoseiny, Christian Claudel
- **Comment**: Accepted by CVPR 2020
- **Journal**: The IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR), 2020, pp. 14424-14432
- **Summary**: Better machine understanding of pedestrian behaviors enables faster progress in modeling interactions between agents such as autonomous vehicles and humans. Pedestrian trajectories are not only influenced by the pedestrian itself but also by interaction with surrounding objects. Previous methods modeled these interactions by using a variety of aggregation methods that integrate different learned pedestrians states. We propose the Social Spatio-Temporal Graph Convolutional Neural Network (Social-STGCNN), which substitutes the need of aggregation methods by modeling the interactions as a graph. Our results show an improvement over the state of art by 20% on the Final Displacement Error (FDE) and an improvement on the Average Displacement Error (ADE) with 8.5 times less parameters and up to 48 times faster inference speed than previously reported methods. In addition, our model is data efficient, and exceeds previous state of the art on the ADE metric with only 20% of the training data. We propose a kernel function to embed the social interactions between pedestrians within the adjacency matrix. Through qualitative analysis, we show that our model inherited social behaviors that can be expected between pedestrians trajectories. Code is available at https://github.com/abduallahmohamed/Social-STGCNN.



### Auto-Encoding Twin-Bottleneck Hashing
- **Arxiv ID**: http://arxiv.org/abs/2002.11930v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.11930v2)
- **Published**: 2020-02-27 05:58:12+00:00
- **Updated**: 2020-03-16 09:14:58+00:00
- **Authors**: Yuming Shen, Jie Qin, Jiaxin Chen, Mengyang Yu, Li Liu, Fan Zhu, Fumin Shen, Ling Shao
- **Comment**: CVPR 2020 Accepted, Code at https://github.com/ymcidence/TBH
- **Journal**: None
- **Summary**: Conventional unsupervised hashing methods usually take advantage of similarity graphs, which are either pre-computed in the high-dimensional space or obtained from random anchor points. On the one hand, existing methods uncouple the procedures of hash function learning and graph construction. On the other hand, graphs empirically built upon original data could introduce biased prior knowledge of data relevance, leading to sub-optimal retrieval performance. In this paper, we tackle the above problems by proposing an efficient and adaptive code-driven graph, which is updated by decoding in the context of an auto-encoder. Specifically, we introduce into our framework twin bottlenecks (i.e., latent variables) that exchange crucial information collaboratively. One bottleneck (i.e., binary codes) conveys the high-level intrinsic data structure captured by the code-driven graph to the other (i.e., continuous variables for low-level detail information), which in turn propagates the updated network feedback for the encoder to learn more discriminative binary codes. The auto-encoding learning objective literally rewards the code-driven graph to learn an optimal encoder. Moreover, the proposed model can be simply optimized by gradient descent without violating the binary constraints. Experiments on benchmarked datasets clearly show the superiority of our framework over the state-of-the-art hashing methods. Our source code can be found at https://github.com/ymcidence/TBH.



### Supervised Dimensionality Reduction and Visualization using Centroid-encoder
- **Arxiv ID**: http://arxiv.org/abs/2002.11934v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.11934v2)
- **Published**: 2020-02-27 06:08:22+00:00
- **Updated**: 2020-02-28 23:22:24+00:00
- **Authors**: Tomojit Ghosh, Michael Kirby
- **Comment**: 25 pages (including 3 reference pages), 12 figures. I am planning to
  submit the paper to JMLR very soon. Centroid-encoder was applied on a
  biological pathway data
  (https://www.sciencedirect.com/science/article/pii/S1046202317300439). In
  this paper we throughly analyzed the algorithm and compared it with
  state-of-the art techniques on a 8 data sets including MNIST, USPS
- **Journal**: None
- **Summary**: Visualizing high-dimensional data is an essential task in Data Science and Machine Learning. The Centroid-Encoder (CE) method is similar to the autoencoder but incorporates label information to keep objects of a class close together in the reduced visualization space. CE exploits nonlinearity and labels to encode high variance in low dimensions while capturing the global structure of the data. We present a detailed analysis of the method using a wide variety of data sets and compare it with other supervised dimension reduction techniques, including NCA, nonlinear NCA, t-distributed NCA, t-distributed MCML, supervised UMAP, supervised PCA, Colored Maximum Variance Unfolding, supervised Isomap, Parametric Embedding, supervised Neighbor Retrieval Visualizer, and Multiple Relational Embedding. We empirically show that centroid-encoder outperforms most of these techniques. We also show that when the data variance is spread across multiple modalities, centroid-encoder extracts a significant amount of information from the data in low dimensional space. This key feature establishes its value to use it as a tool for data visualization.



### Weakly supervised discriminative feature learning with state information for person identification
- **Arxiv ID**: http://arxiv.org/abs/2002.11939v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.11939v1)
- **Published**: 2020-02-27 06:33:56+00:00
- **Updated**: 2020-02-27 06:33:56+00:00
- **Authors**: Hong-Xing Yu, Wei-Shi Zheng
- **Comment**: To appear at CVPR20
- **Journal**: None
- **Summary**: Unsupervised learning of identity-discriminative visual feature is appealing in real-world tasks where manual labelling is costly. However, the images of an identity can be visually discrepant when images are taken under different states, e.g. different camera views and poses. This visual discrepancy leads to great difficulty in unsupervised discriminative learning. Fortunately, in real-world tasks we could often know the states without human annotation, e.g. we can easily have the camera view labels in person re-identification and facial pose labels in face recognition. In this work we propose utilizing the state information as weak supervision to address the visual discrepancy caused by different states. We formulate a simple pseudo label model and utilize the state information in an attempt to refine the assigned pseudo labels by the weakly supervised decision boundary rectification and weakly supervised feature drift regularization. We evaluate our model on unsupervised person re-identification and pose-invariant face recognition. Despite the simplicity of our method, it could outperform the state-of-the-art results on Duke-reID, MultiPIE and CFP datasets with a standard ResNet-50 backbone. We also find our model could perform comparably with the standard supervised fine-tuning results on the three datasets. Code is available at https://github.com/KovenYu/state-information



### Features for Ground Texture Based Localization -- A Survey
- **Arxiv ID**: http://arxiv.org/abs/2002.11948v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2002.11948v2)
- **Published**: 2020-02-27 07:25:41+00:00
- **Updated**: 2020-03-03 09:58:42+00:00
- **Authors**: Jan Fabian Schmid, Stephan F. Simon, Rudolf Mester
- **Comment**: Published at the 30th British Machine Vision Conference (BMVC 2019)
- **Journal**: None
- **Summary**: Ground texture based vehicle localization using feature-based methods is a promising approach to achieve infrastructure-free high-accuracy localization. In this paper, we provide the first extensive evaluation of available feature extraction methods for this task, using separately taken image pairs as well as synthetic transformations. We identify AKAZE, SURF and CenSurE as best performing keypoint detectors, and find pairings of CenSurE with the ORB, BRIEF and LATCH feature descriptors to achieve greatest success rates for incremental localization, while SIFT stands out when considering severe synthetic transformations as they might occur during absolute localization.



### Unbiased Scene Graph Generation from Biased Training
- **Arxiv ID**: http://arxiv.org/abs/2002.11949v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.11949v3)
- **Published**: 2020-02-27 07:29:53+00:00
- **Updated**: 2020-03-11 07:55:13+00:00
- **Authors**: Kaihua Tang, Yulei Niu, Jianqiang Huang, Jiaxin Shi, Hanwang Zhang
- **Comment**: This paper is accepted by CVPR 2020. The code is publicly available
  on GitHub: https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch
- **Journal**: None
- **Summary**: Today's scene graph generation (SGG) task is still far from practical, mainly due to the severe training bias, e.g., collapsing diverse "human walk on / sit on / lay on beach" into "human on beach". Given such SGG, the down-stream tasks such as VQA can hardly infer better scene structures than merely a bag of objects. However, debiasing in SGG is not trivial because traditional debiasing methods cannot distinguish between the good and bad bias, e.g., good context prior (e.g., "person read book" rather than "eat") and bad long-tailed bias (e.g., "near" dominating "behind / in front of"). In this paper, we present a novel SGG framework based on causal inference but not the conventional likelihood. We first build a causal graph for SGG, and perform traditional biased training with the graph. Then, we propose to draw the counterfactual causality from the trained graph to infer the effect from the bad bias, which should be removed. In particular, we use Total Direct Effect (TDE) as the proposed final predicate score for unbiased SGG. Note that our framework is agnostic to any SGG model and thus can be widely applied in the community who seeks unbiased predictions. By using the proposed Scene Graph Diagnosis toolkit on the SGG benchmark Visual Genome and several prevailing models, we observed significant improvements over the previous state-of-the-art methods.



### Face Verification Using 60~GHz 802.11 waveforms
- **Arxiv ID**: http://arxiv.org/abs/2002.11965v2
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11965v2)
- **Published**: 2020-02-27 08:34:51+00:00
- **Updated**: 2020-06-01 06:52:11+00:00
- **Authors**: Eran Hof, Amichai Sanderovich, Evyatar Hemo
- **Comment**: None
- **Journal**: None
- **Summary**: Verification of an identity based on the human face radar signature in mmwave is studied. The chipset for 802.11ad/y networking that is cable of operating in a radar mode is used. A dataset with faces of 200 different persons was collected for the testing. Our preliminary study shows promising results for the application of autoencoder for the setup at hand.



### NeurIPS 2019 Disentanglement Challenge: Improved Disentanglement through Learned Aggregation of Convolutional Feature Maps
- **Arxiv ID**: http://arxiv.org/abs/2002.12356v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12356v2)
- **Published**: 2020-02-27 08:46:17+00:00
- **Updated**: 2020-11-17 15:16:35+00:00
- **Authors**: Maximilian Seitzer, Andreas Foltyn, Felix P. Kemeth
- **Comment**: Disentanglement Challenge - 33rd Conference on Neural Information
  Processing Systems (NeurIPS) - NeurIPS 2019. arXiv admin note: text overlap
  with arXiv:2002.10003. Acknowledgements added
- **Journal**: None
- **Summary**: This report to our stage 2 submission to the NeurIPS 2019 disentanglement challenge presents a simple image preprocessing method for learning disentangled latent factors. We propose to train a variational autoencoder on regionally aggregated feature maps obtained from networks pretrained on the ImageNet database, utilizing the implicit inductive bias contained in those features for disentanglement. This bias can be further enhanced by explicitly fine-tuning the feature maps on auxiliary tasks useful for the challenge, such as angle, position estimation, or color classification. Our approach achieved the 2nd place in stage 2 of the challenge. Code is available at https://github.com/mseitzer/neurips2019-disentanglement-challenge.



### Multiple Discrimination and Pairwise CNN for View-based 3D Object Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2002.11977v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.11977v1)
- **Published**: 2020-02-27 09:11:23+00:00
- **Updated**: 2020-02-27 09:11:23+00:00
- **Authors**: Z. Gao, K. X Xue, S. H Wan
- **Comment**: None
- **Journal**: None
- **Summary**: With the rapid development and wide application of computer, camera device, network and hardware technology, 3D object (or model) retrieval has attracted widespread attention and it has become a hot research topic in the computer vision domain. Deep learning features already available in 3D object retrieval have been proven to be better than the retrieval performance of hand-crafted features. However, most existing networks do not take into account the impact of multi-view image selection on network training, and the use of contrastive loss alone only forcing the same-class samples to be as close as possible. In this work, a novel solution named Multi-view Discrimination and Pairwise CNN (MDPCNN) for 3D object retrieval is proposed to tackle these issues. It can simultaneously input of multiple batches and multiple views by adding the Slice layer and the Concat layer. Furthermore, a highly discriminative network is obtained by training samples that are not easy to be classified by clustering. Lastly, we deploy the contrastive-center loss and contrastive loss as the optimization objective that has better intra-class compactness and inter-class separability. Large-scale experiments show that the proposed MDPCNN can achieve a significant performance over the state-of-the-art algorithms in 3D object retrieval.



### Deep Learning on Radar Centric 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2003.00851v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, Artificial intelligence
- **Links**: [PDF](http://arxiv.org/pdf/2003.00851v1)
- **Published**: 2020-02-27 10:16:46+00:00
- **Updated**: 2020-02-27 10:16:46+00:00
- **Authors**: Seungjun Lee
- **Comment**: 4 pages
- **Journal**: None
- **Summary**: Even though many existing 3D object detection algorithms rely mostly on camera and LiDAR, camera and LiDAR are prone to be affected by harsh weather and lighting conditions. On the other hand, radar is resistant to such conditions. However, research has found only recently to apply deep neural networks on radar data. In this paper, we introduce a deep learning approach to 3D object detection with radar only. To the best of our knowledge, we are the first ones to demonstrate a deep learning-based 3D object detection model with radar only that was trained on the public radar dataset. To overcome the lack of radar labeled data, we propose a novel way of making use of abundant LiDAR data by transforming it into radar-like point cloud data and aggressive radar augmentation techniques.



### Meta-Learned Confidence for Few-shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2002.12017v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12017v2)
- **Published**: 2020-02-27 10:22:17+00:00
- **Updated**: 2020-06-24 14:13:47+00:00
- **Authors**: Seong Min Kye, Hae Beom Lee, Hoirin Kim, Sung Ju Hwang
- **Comment**: None
- **Journal**: None
- **Summary**: Transductive inference is an effective means of tackling the data deficiency problem in few-shot learning settings. A popular transductive inference technique for few-shot metric-based approaches, is to update the prototype of each class with the mean of the most confident query examples, or confidence-weighted average of all the query samples. However, a caveat here is that the model confidence may be unreliable, which may lead to incorrect predictions. To tackle this issue, we propose to meta-learn the confidence for each query sample, to assign optimal weights to unlabeled queries such that they improve the model's transductive inference performance on unseen tasks. We achieve this by meta-learning an input-adaptive distance metric over a task distribution under various model and data perturbations, which will enforce consistency on the model predictions under diverse uncertainties for unseen tasks. Moreover, we additionally suggest a regularization which explicitly enforces the consistency on the predictions across the different dimensions of a high-dimensional embedding vector. We validate our few-shot learning model with meta-learned confidence on four benchmark datasets, on which it largely outperforms strong recent baselines and obtains new state-of-the-art results. Further application on semi-supervised few-shot learning tasks also yields significant performance improvements over the baselines. The source code of our algorithm is available at https://github.com/seongmin-kye/MCT.



### Attention-guided Chained Context Aggregation for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2002.12041v4
- **DOI**: 10.1016/j.imavis.2021.104309
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12041v4)
- **Published**: 2020-02-27 11:26:56+00:00
- **Updated**: 2021-05-21 03:25:20+00:00
- **Authors**: Quan Tang, Fagui Liu, Tong Zhang, Jun Jiang, Yu Zhang
- **Comment**: Wrong numbers in Table 7 of version v3 have been corrected
- **Journal**: Image and Vision Computing 2021
- **Summary**: The way features propagate in Fully Convolutional Networks is of momentous importance to capture multi-scale contexts for obtaining precise segmentation masks. This paper proposes a novel series-parallel hybrid paradigm called the Chained Context Aggregation Module (CAM) to diversify feature propagation. CAM gains features of various spatial scales through chain-connected ladder-style information flows and fuses them in a two-stage process, namely pre-fusion and re-fusion. The serial flow continuously increases receptive fields of output neurons and those in parallel encode different region-based contexts. Each information flow is a shallow encoder-decoder with appropriate down-sampling scales to sufficiently capture contextual information. We further adopt an attention model in CAM to guide feature re-fusion. Based on these developments, we construct the Chained Context Aggregation Network (CANet), which employs an asymmetric decoder to recover precise spatial details of prediction maps. We conduct extensive experiments on six challenging datasets, including Pascal VOC 2012, Pascal Context, Cityscapes, CamVid, SUN-RGBD and GATECH. Results evidence that CANet achieves state-of-the-art performance.



### XSepConv: Extremely Separated Convolution
- **Arxiv ID**: http://arxiv.org/abs/2002.12046v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12046v1)
- **Published**: 2020-02-27 11:46:17+00:00
- **Updated**: 2020-02-27 11:46:17+00:00
- **Authors**: Jiarong Chen, Zongqing Lu, Jing-Hao Xue, Qingmin Liao
- **Comment**: None
- **Journal**: None
- **Summary**: Depthwise convolution has gradually become an indispensable operation for modern efficient neural networks and larger kernel sizes ($\ge5$) have been applied to it recently. In this paper, we propose a novel extremely separated convolutional block (XSepConv), which fuses spatially separable convolutions into depthwise convolution to further reduce both the computational cost and parameter size of large kernels. Furthermore, an extra $2\times2$ depthwise convolution coupled with improved symmetric padding strategy is employed to compensate for the side effect brought by spatially separable convolutions. XSepConv is designed to be an efficient alternative to vanilla depthwise convolution with large kernel sizes. To verify this, we use XSepConv for the state-of-the-art architecture MobileNetV3-Small and carry out extensive experiments on four highly competitive benchmark datasets (CIFAR-10, CIFAR-100, SVHN and Tiny-ImageNet) to demonstrate that XSepConv can indeed strike a better trade-off between accuracy and efficiency.



### FMix: Enhancing Mixed Sample Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/2002.12047v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.IT, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12047v3)
- **Published**: 2020-02-27 11:46:33+00:00
- **Updated**: 2021-02-28 14:47:36+00:00
- **Authors**: Ethan Harris, Antonia Marcu, Matthew Painter, Mahesan Niranjan, Adam Prügel-Bennett, Jonathon Hare
- **Comment**: Code available at https://github.com/ecs-vlc/FMix
- **Journal**: None
- **Summary**: Mixed Sample Data Augmentation (MSDA) has received increasing attention in recent years, with many successful variants such as MixUp and CutMix. By studying the mutual information between the function learned by a VAE on the original data and on the augmented data we show that MixUp distorts learned functions in a way that CutMix does not. We further demonstrate this by showing that MixUp acts as a form of adversarial training, increasing robustness to attacks such as Deep Fool and Uniform Noise which produce examples similar to those generated by MixUp. We argue that this distortion prevents models from learning about sample specific features in the data, aiding generalisation performance. In contrast, we suggest that CutMix works more like a traditional augmentation, improving performance by preventing memorisation without distorting the data distribution. However, we argue that an MSDA which builds on CutMix to include masks of arbitrary shape, rather than just square, could further prevent memorisation whilst preserving the data distribution in the same way. To this end, we propose FMix, an MSDA that uses random binary masks obtained by applying a threshold to low frequency images sampled from Fourier space. These random masks can take on a wide range of shapes and can be generated for use with one, two, and three dimensional data. FMix improves performance over MixUp and CutMix, without an increase in training time, for a number of models across a range of data sets and problem settings, obtaining a new single model state-of-the-art result on CIFAR-10 without external data. Finally, we show that a consequence of the difference between interpolating MSDA such as MixUp and masking MSDA such as FMix is that the two can be combined to improve performance even further. Code for all experiments is provided at https://github.com/ecs-vlc/FMix .



### Two-stage multi-scale breast mass segmentation for full mammogram analysis without user intervention
- **Arxiv ID**: http://arxiv.org/abs/2002.12079v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12079v2)
- **Published**: 2020-02-27 13:16:22+00:00
- **Updated**: 2020-12-08 09:50:41+00:00
- **Authors**: Yutong Yan, Pierre-Henri Conze, Gwenolé Quellec, Mathieu Lamard, Béatrice Cochener, Gouenou Coatrieux
- **Comment**: None
- **Journal**: None
- **Summary**: Mammography is the primary imaging modality used for early detection and diagnosis of breast cancer. X-ray mammogram analysis mainly refers to the localization of suspicious regions of interest followed by segmentation, towards further lesion classification into benign versus malignant. Among diverse types of breast abnormalities, masses are the most important clinical findings of breast carcinomas. However, manually segmenting breast masses from native mammograms is time-consuming and error-prone. Therefore, an integrated computer-aided diagnosis system is required to assist clinicians for automatic and precise breast mass delineation. In this work, we present a two-stage multi-scale pipeline that provides accurate mass contours from high-resolution full mammograms. First, we propose an extended deep detector integrating a multi-scale fusion strategy for automated mass localization. Second, a convolutional encoder-decoder network using nested and dense skip connections is employed to fine-delineate candidate masses. Unlike most previous studies based on segmentation from regions, our framework handles mass segmentation from native full mammograms without any user intervention. Trained on INbreast and DDSM-CBIS public datasets, the pipeline achieves an overall average Dice of 80.44% on INbreast test images, outperforming state-of-the-art. Our system shows promising accuracy as an automatic full-image mass segmentation system. Extensive experiments reveals robustness against the diversity of size, shape and appearance of breast masses, towards better interaction-free computer-aided diagnosis.



### Reducing Geographic Performance Differential for Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/2002.12093v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12093v1)
- **Published**: 2020-02-27 13:56:09+00:00
- **Updated**: 2020-02-27 13:56:09+00:00
- **Authors**: Martins Bruveris, Jochem Gietema, Pouria Mortazavian, Mohan Mahadevan
- **Comment**: Demographic Variation in the Performance of Biometric Systems
  workshop at WACV 2020
- **Journal**: None
- **Summary**: As face recognition algorithms become more accurate and get deployed more widely, it becomes increasingly important to ensure that the algorithms work equally well for everyone. We study the geographic performance differentials-differences in false acceptance and false rejection rates across different countries-when comparing selfies against photos from ID documents. We show how to mitigate geographic performance differentials using sampling strategies despite large imbalances in the dataset. Using vanilla domain adaptation strategies to fine-tune a face recognition CNN on domain-specific doc-selfie data improves the performance of the model on such data, but, in the presence of imbalanced training data, also significantly increases the demographic bias. We then show how to mitigate this effect by employing sampling strategies to balance the training procedure.



### Action Quality Assessment using Siamese Network-Based Deep Metric Learning
- **Arxiv ID**: http://arxiv.org/abs/2002.12096v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12096v1)
- **Published**: 2020-02-27 14:00:05+00:00
- **Updated**: 2020-02-27 14:00:05+00:00
- **Authors**: Hiteshi Jain, Gaurav Harit, Avinash Sharma
- **Comment**: 12 pages, 5 Figures, 8 tables
- **Journal**: None
- **Summary**: Automated vision-based score estimation models can be used as an alternate opinion to avoid judgment bias. In the past works the score estimation models were learned by regressing the video representations to the ground truth score provided by the judges. However such regression-based solutions lack interpretability in terms of giving reasons for the awarded score. One solution to make the scores more explicable is to compare the given action video with a reference video. This would capture the temporal variations w.r.t. the reference video and map those variations to the final score. In this work, we propose a new action scoring system as a two-phase system: (1) A Deep Metric Learning Module that learns similarity between any two action videos based on their ground truth scores given by the judges; (2) A Score Estimation Module that uses the first module to find the resemblance of a video to a reference video in order to give the assessment score. The proposed scoring model has been tested for Olympics Diving and Gymnastic vaults and the model outperforms the existing state-of-the-art scoring models.



### Deep Slow Motion Video Reconstruction with Hybrid Imaging System
- **Arxiv ID**: http://arxiv.org/abs/2002.12106v2
- **DOI**: 10.1109/TPAMI.2020.2987316
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2002.12106v2)
- **Published**: 2020-02-27 14:18:12+00:00
- **Updated**: 2020-04-21 11:05:44+00:00
- **Authors**: Avinash Paliwal, Nima Khademi Kalantari
- **Comment**: IEEE TPAMI and ICCP 2020. Project page containing code and video at
  http://faculty.cs.tamu.edu/nimak/Papers/ICCP2020_Slomo
- **Journal**: None
- **Summary**: Slow motion videos are becoming increasingly popular, but capturing high-resolution videos at extremely high frame rates requires professional high-speed cameras. To mitigate this problem, current techniques increase the frame rate of standard videos through frame interpolation by assuming linear object motion which is not valid in challenging cases. In this paper, we address this problem using two video streams as input; an auxiliary video with high frame rate and low spatial resolution, providing temporal information, in addition to the standard main video with low frame rate and high spatial resolution. We propose a two-stage deep learning system consisting of alignment and appearance estimation that reconstructs high resolution slow motion video from the hybrid video input. For alignment, we propose to compute flows between the missing frame and two existing frames of the main video by utilizing the content of the auxiliary video frames. For appearance estimation, we propose to combine the warped and auxiliary frames using a context and occlusion aware network. We train our model on synthetically generated hybrid videos and show high-quality results on a variety of test scenes. To demonstrate practicality, we show the performance of our system on two real dual camera setups with small baseline.



### Domain Decluttering: Simplifying Images to Mitigate Synthetic-Real Domain Shift and Improve Depth Estimation
- **Arxiv ID**: http://arxiv.org/abs/2002.12114v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12114v2)
- **Published**: 2020-02-27 14:28:56+00:00
- **Updated**: 2020-06-25 07:37:13+00:00
- **Authors**: Yunhan Zhao, Shu Kong, Daeyun Shin, Charless Fowlkes
- **Comment**: camera-ready version, CVPR2020
- **Journal**: None
- **Summary**: Leveraging synthetically rendered data offers great potential to improve monocular depth estimation and other geometric estimation tasks, but closing the synthetic-real domain gap is a non-trivial and important task. While much recent work has focused on unsupervised domain adaptation, we consider a more realistic scenario where a large amount of synthetic training data is supplemented by a small set of real images with ground-truth. In this setting, we find that existing domain translation approaches are difficult to train and offer little advantage over simple baselines that use a mix of real and synthetic data. A key failure mode is that real-world images contain novel objects and clutter not present in synthetic training. This high-level domain shift isn't handled by existing image translation models.   Based on these observations, we develop an attention module that learns to identify and remove difficult out-of-domain regions in real images in order to improve depth prediction for a model trained primarily on synthetic data. We carry out extensive experiments to validate our attend-remove-complete approach (ARC) and find that it significantly outperforms state-of-the-art domain adaptation methods for depth prediction. Visualizing the removed regions provides interpretable insights into the synthetic-real domain gap.



### Multi-Cycle-Consistent Adversarial Networks for CT Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/2002.12130v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12130v1)
- **Published**: 2020-02-27 14:44:45+00:00
- **Updated**: 2020-02-27 14:44:45+00:00
- **Authors**: Jinglan Liu, Yukun Ding, Jinjun Xiong, Qianjun Jia, Meiping Huang, Jian Zhuang, Bike Xie, Chun-Chen Liu, Yiyu Shi
- **Comment**: Accepted in ISBI 2020. 5 pages, 4 figures
- **Journal**: None
- **Summary**: CT image denoising can be treated as an image-to-image translation task where the goal is to learn the transform between a source domain $X$ (noisy images) and a target domain $Y$ (clean images). Recently, cycle-consistent adversarial denoising network (CCADN) has achieved state-of-the-art results by enforcing cycle-consistent loss without the need of paired training data. Our detailed analysis of CCADN raises a number of interesting questions. For example, if the noise is large leading to significant difference between domain $X$ and domain $Y$, can we bridge $X$ and $Y$ with an intermediate domain $Z$ such that both the denoising process between $X$ and $Z$ and that between $Z$ and $Y$ are easier to learn? As such intermediate domains lead to multiple cycles, how do we best enforce cycle-consistency? Driven by these questions, we propose a multi-cycle-consistent adversarial network (MCCAN) that builds intermediate domains and enforces both local and global cycle-consistency. The global cycle-consistency couples all generators together to model the whole denoising process, while the local cycle-consistency imposes effective supervision on the process between adjacent domains. Experiments show that both local and global cycle-consistency are important for the success of MCCAN, which outperforms the state-of-the-art.



### The Data Representativeness Criterion: Predicting the Performance of Supervised Classification Based on Data Set Similarity
- **Arxiv ID**: http://arxiv.org/abs/2002.12105v1
- **DOI**: 10.1371/journal.pone.0237009
- **Categories**: **cs.CV**, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/2002.12105v1)
- **Published**: 2020-02-27 15:08:13+00:00
- **Updated**: 2020-02-27 15:08:13+00:00
- **Authors**: Evelien Schat, Rens van de Schoot, Wouter M. Kouw, Duco Veen, Adriënne M. Mendrik
- **Comment**: 12 pages, 6 figures
- **Journal**: PLoS ONE 15(8): e0237009, 2020, pp. 1-16
- **Summary**: In a broad range of fields it may be desirable to reuse a supervised classification algorithm and apply it to a new data set. However, generalization of such an algorithm and thus achieving a similar classification performance is only possible when the training data used to build the algorithm is similar to new unseen data one wishes to apply it to. It is often unknown in advance how an algorithm will perform on new unseen data, being a crucial reason for not deploying an algorithm at all. Therefore, tools are needed to measure the similarity of data sets. In this paper, we propose the Data Representativeness Criterion (DRC) to determine how representative a training data set is of a new unseen data set. We present a proof of principle, to see whether the DRC can quantify the similarity of data sets and whether the DRC relates to the performance of a supervised classification algorithm. We compared a number of magnetic resonance imaging (MRI) data sets, ranging from subtle to severe difference is acquisition parameters. Results indicate that, based on the similarity of data sets, the DRC is able to give an indication as to when the performance of a supervised classifier decreases. The strictness of the DRC can be set by the user, depending on what one considers to be an acceptable underperformance.



### MLography: An Automated Quantitative Metallography Model for Impurities Anomaly Detection using Novel Data Mining and Deep Learning Approach
- **Arxiv ID**: http://arxiv.org/abs/2003.04226v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2003.04226v1)
- **Published**: 2020-02-27 15:17:03+00:00
- **Updated**: 2020-02-27 15:17:03+00:00
- **Authors**: Matan Rusanovsky, Gal Oren, Sigalit Ifergane, Ofer Beeri
- **Comment**: 9 pages, 8 figures, 3 algorithms, 1 table
- **Journal**: None
- **Summary**: The micro-structure of most of the engineering alloys contains some inclusions and precipitates, which may affect their properties, therefore it is crucial to characterize them. In this work we focus on the development of a state-of-the-art artificial intelligence model for Anomaly Detection named MLography to automatically quantify the degree of anomaly of impurities in alloys. For this purpose, we introduce several anomaly detection measures: Spatial, Shape and Area anomaly, that successfully detect the most anomalous objects based on their objective, given that the impurities were already labeled. The first two measures quantify the degree of anomaly of each object by how each object is distant and big compared to its neighborhood, and by the abnormally of its own shape respectively. The last measure, combines the former two and highlights the most anomalous regions among all input images, for later (physical) examination. The performance of the model is presented and analyzed based on few representative cases. We stress that although the models presented here were developed for metallography analysis, most of them can be generalized to a wider set of problems in which anomaly detection of geometrical objects is desired. All models as well as the data-set that was created for this work, are publicly available at: https://github.com/matanr/MLography.



### University-1652: A Multi-view Multi-source Benchmark for Drone-based Geo-localization
- **Arxiv ID**: http://arxiv.org/abs/2002.12186v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12186v2)
- **Published**: 2020-02-27 15:24:15+00:00
- **Updated**: 2020-08-16 00:07:39+00:00
- **Authors**: Zhedong Zheng, Yunchao Wei, Yi Yang
- **Comment**: accepted by ACM Multimedia 2020
- **Journal**: None
- **Summary**: We consider the problem of cross-view geo-localization. The primary challenge of this task is to learn the robust feature against large viewpoint changes. Existing benchmarks can help, but are limited in the number of viewpoints. Image pairs, containing two viewpoints, e.g., satellite and ground, are usually provided, which may compromise the feature learning. Besides phone cameras and satellites, in this paper, we argue that drones could serve as the third platform to deal with the geo-localization problem. In contrast to the traditional ground-view images, drone-view images meet fewer obstacles, e.g., trees, and could provide a comprehensive view when flying around the target place. To verify the effectiveness of the drone platform, we introduce a new multi-view multi-source benchmark for drone-based geo-localization, named University-1652. University-1652 contains data from three platforms, i.e., synthetic drones, satellites and ground cameras of 1,652 university buildings around the world. To our knowledge, University-1652 is the first drone-based geo-localization dataset and enables two new tasks, i.e., drone-view target localization and drone navigation. As the name implies, drone-view target localization intends to predict the location of the target place via drone-view images. On the other hand, given a satellite-view query image, drone navigation is to drive the drone to the area of interest in the query. We use this dataset to analyze a variety of off-the-shelf CNN features and propose a strong CNN baseline on this challenging dataset. The experiments show that University-1652 helps the model to learn the viewpoint-invariant features and also has good generalization ability in the real-world scenario.



### Visual Commonsense R-CNN
- **Arxiv ID**: http://arxiv.org/abs/2002.12204v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12204v3)
- **Published**: 2020-02-27 15:51:19+00:00
- **Updated**: 2020-04-27 04:29:49+00:00
- **Authors**: Tan Wang, Jianqiang Huang, Hanwang Zhang, Qianru Sun
- **Comment**: Accepted by CVPR 2020
- **Journal**: None
- **Summary**: We present a novel unsupervised feature representation learning method, Visual Commonsense Region-based Convolutional Neural Network (VC R-CNN), to serve as an improved visual region encoder for high-level tasks such as captioning and VQA. Given a set of detected object regions in an image (e.g., using Faster R-CNN), like any other unsupervised feature learning methods (e.g., word2vec), the proxy training objective of VC R-CNN is to predict the contextual objects of a region. However, they are fundamentally different: the prediction of VC R-CNN is by using causal intervention: P(Y|do(X)), while others are by using the conventional likelihood: P(Y|X). This is also the core reason why VC R-CNN can learn "sense-making" knowledge like chair can be sat -- while not just "common" co-occurrences such as chair is likely to exist if table is observed. We extensively apply VC R-CNN features in prevailing models of three popular tasks: Image Captioning, VQA, and VCR, and observe consistent performance boosts across them, achieving many new state-of-the-arts. Code and feature are available at https://github.com/Wangt-CN/VC-R-CNN.



### Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image
- **Arxiv ID**: http://arxiv.org/abs/2002.12212v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12212v1)
- **Published**: 2020-02-27 16:00:52+00:00
- **Updated**: 2020-02-27 16:00:52+00:00
- **Authors**: Yinyu Nie, Xiaoguang Han, Shihui Guo, Yujian Zheng, Jian Chang, Jian Jun Zhang
- **Comment**: Accepted by CVPR 2020
- **Journal**: None
- **Summary**: Semantic reconstruction of indoor scenes refers to both scene understanding and object reconstruction. Existing works either address one part of this problem or focus on independent objects. In this paper, we bridge the gap between understanding and reconstruction, and propose an end-to-end solution to jointly reconstruct room layout, object bounding boxes and meshes from a single image. Instead of separately resolving scene understanding and object reconstruction, our method builds upon a holistic scene context and proposes a coarse-to-fine hierarchy with three components: 1. room layout with camera pose; 2. 3D object bounding boxes; 3. object meshes. We argue that understanding the context of each component can assist the task of parsing the others, which enables joint understanding and reconstruction. The experiments on the SUN RGB-D and Pix3D datasets demonstrate that our method consistently outperforms existing methods in indoor layout estimation, 3D object detection and mesh reconstruction.



### Meta-Transfer Learning for Zero-Shot Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/2002.12213v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12213v1)
- **Published**: 2020-02-27 16:01:11+00:00
- **Updated**: 2020-02-27 16:01:11+00:00
- **Authors**: Jae Woong Soh, Sunwoo Cho, Nam Ik Cho
- **Comment**: Will be presented in CVPR 2020
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have shown dramatic improvements in single image super-resolution (SISR) by using large-scale external samples. Despite their remarkable performance based on the external dataset, they cannot exploit internal information within a specific image. Another problem is that they are applicable only to the specific condition of data that they are supervised. For instance, the low-resolution (LR) image should be a "bicubic" downsampled noise-free image from a high-resolution (HR) one. To address both issues, zero-shot super-resolution (ZSSR) has been proposed for flexible internal learning. However, they require thousands of gradient updates, i.e., long inference time. In this paper, we present Meta-Transfer Learning for Zero-Shot Super-Resolution (MZSR), which leverages ZSSR. Precisely, it is based on finding a generic initial parameter that is suitable for internal learning. Thus, we can exploit both external and internal information, where one single gradient update can yield quite considerable results. (See Figure 1). With our method, the network can quickly adapt to a given image condition. In this respect, our method can be applied to a large spectrum of image conditions within a fast adaptation process.



### Optimization of Graph Total Variation via Active-Set-based Combinatorial Reconditioning
- **Arxiv ID**: http://arxiv.org/abs/2002.12236v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12236v1)
- **Published**: 2020-02-27 16:33:09+00:00
- **Updated**: 2020-02-27 16:33:09+00:00
- **Authors**: Zhenzhang Ye, Thomas Möllenhoff, Tao Wu, Daniel Cremers
- **Comment**: Presented at the 23 rd International Conference on Artificial
  Intelligence and Statistics (AISTATS) 2020. Code:
  https://github.com/zhenzhangye/graph_TV_recond
- **Journal**: None
- **Summary**: Structured convex optimization on weighted graphs finds numerous applications in machine learning and computer vision. In this work, we propose a novel adaptive preconditioning strategy for proximal algorithms on this problem class. Our preconditioner is driven by a sharp analysis of the local linear convergence rate depending on the "active set" at the current iterate. We show that nested-forest decomposition of the inactive edges yields a guaranteed local linear convergence rate. Further, we propose a practical greedy heuristic which realizes such nested decompositions and show in several numerical experiments that our reconditioning strategy, when applied to proximal gradient or primal-dual hybrid gradient algorithm, achieves competitive performances. Our results suggest that local convergence analysis can serve as a guideline for selecting variable metrics in proximal algorithms.



### Learning Representations by Predicting Bags of Visual Words
- **Arxiv ID**: http://arxiv.org/abs/2002.12247v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12247v1)
- **Published**: 2020-02-27 16:45:25+00:00
- **Updated**: 2020-02-27 16:45:25+00:00
- **Authors**: Spyros Gidaris, Andrei Bursuc, Nikos Komodakis, Patrick Pérez, Matthieu Cord
- **Comment**: Accepted to CVPR2020
- **Journal**: None
- **Summary**: Self-supervised representation learning targets to learn convnet-based image representations from unlabeled data. Inspired by the success of NLP methods in this area, in this work we propose a self-supervised approach based on spatially dense image descriptions that encode discrete visual concepts, here called visual words. To build such discrete representations, we quantize the feature maps of a first pre-trained self-supervised convnet, over a k-means based vocabulary. Then, as a self-supervised task, we train another convnet to predict the histogram of visual words of an image (i.e., its Bag-of-Words representation) given as input a perturbed version of that image. The proposed task forces the convnet to learn perturbation-invariant and context-aware image features, useful for downstream image understanding tasks. We extensively evaluate our method and demonstrate very strong empirical results, e.g., our pre-trained self-supervised representations transfer better on detection task and similarly on classification over classes "unseen" during pre-training, when compared to the supervised case.   This also shows that the process of image discretization into visual words can provide the basis for very powerful self-supervised approaches in the image domain, thus allowing further connections to be made to related methods from the NLP domain that have been extremely successful so far.



### ZoomCount: A Zooming Mechanism for Crowd Counting in Static Images
- **Arxiv ID**: http://arxiv.org/abs/2002.12256v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12256v1)
- **Published**: 2020-02-27 16:57:04+00:00
- **Updated**: 2020-02-27 16:57:04+00:00
- **Authors**: Usman Sajid, Hasan Sajid, Hongcheng Wang, Guanghui Wang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a novel approach for crowd counting in low to high density scenarios in static images. Current approaches cannot handle huge crowd diversity well and thus perform poorly in extreme cases, where the crowd density in different regions of an image is either too low or too high, leading to crowd underestimation or overestimation. The proposed solution is based on the observation that detecting and handling such extreme cases in a specialized way leads to better crowd estimation. Additionally, existing methods find it hard to differentiate between the actual crowd and the cluttered background regions, resulting in further count overestimation. To address these issues, we propose a simple yet effective modular approach, where an input image is first subdivided into fixed-size patches and then fed to a four-way classification module labeling each image patch as low, medium, high-dense or no-crowd. This module also provides a count for each label, which is then analyzed via a specifically devised novel decision module to decide whether the image belongs to any of the two extreme cases (very low or very high density) or a normal case. Images, specified as high- or low-density extreme or a normal case, pass through dedicated zooming or normal patch-making blocks respectively before routing to the regressor in the form of fixed-size patches for crowd estimate. Extensive experimental evaluations demonstrate that the proposed approach outperforms the state-of-the-art methods on four benchmarks under most of the evaluation criteria.



### The Mertens Unrolled Network (MU-Net): A High Dynamic Range Fusion Neural Network for Through the Windshield Driver Recognition
- **Arxiv ID**: http://arxiv.org/abs/2002.12257v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12257v1)
- **Published**: 2020-02-27 16:57:36+00:00
- **Updated**: 2020-02-27 16:57:36+00:00
- **Authors**: Max Ruby, David S. Bolme, Joel Brogan, David Cornett III, Baldemar Delgado, Gavin Jager, Christi Johnson, Jose Martinez-Mendoza, Hector Santos-Villalobos, Nisha Srinivas
- **Comment**: Accepted to SPEI Autonomous Systems: Sensors, Processing and Security
  for Vehicles & Infrastructure 2020
- **Journal**: None
- **Summary**: Face recognition of vehicle occupants through windshields in unconstrained environments poses a number of unique challenges ranging from glare, poor illumination, driver pose and motion blur. In this paper, we further develop the hardware and software components of a custom vehicle imaging system to better overcome these challenges. After the build out of a physical prototype system that performs High Dynamic Range (HDR) imaging, we collect a small dataset of through-windshield image captures of known drivers. We then re-formulate the classical Mertens-Kautz-Van Reeth HDR fusion algorithm as a pre-initialized neural network, which we name the Mertens Unrolled Network (MU-Net), for the purpose of fine-tuning the HDR output of through-windshield images. Reconstructed faces from this novel HDR method are then evaluated and compared against other traditional and experimental HDR methods in a pre-trained state-of-the-art (SOTA) facial recognition pipeline, verifying the efficacy of our approach.



### Blurry Video Frame Interpolation
- **Arxiv ID**: http://arxiv.org/abs/2002.12259v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12259v1)
- **Published**: 2020-02-27 17:00:26+00:00
- **Updated**: 2020-02-27 17:00:26+00:00
- **Authors**: Wang Shen, Wenbo Bao, Guangtao Zhai, Li Chen, Xiongkuo Min, Zhiyong Gao
- **Comment**: This work is accepted in CVPR 2020
- **Journal**: None
- **Summary**: Existing works reduce motion blur and up-convert frame rate through two separate ways, including frame deblurring and frame interpolation. However, few studies have approached the joint video enhancement problem, namely synthesizing high-frame-rate clear results from low-frame-rate blurry inputs. In this paper, we propose a blurry video frame interpolation method to reduce motion blur and up-convert frame rate simultaneously. Specifically, we develop a pyramid module to cyclically synthesize clear intermediate frames. The pyramid module features adjustable spatial receptive field and temporal scope, thus contributing to controllable computational complexity and restoration ability. Besides, we propose an inter-pyramid recurrent module to connect sequential models to exploit the temporal relationship. The pyramid module integrates a recurrent module, thus can iteratively synthesize temporally smooth results without significantly increasing the model size. Extensive experimental results demonstrate that our method performs favorably against state-of-the-art methods.



### Opportunities of a Machine Learning-based Decision Support System for Stroke Rehabilitation Assessment
- **Arxiv ID**: http://arxiv.org/abs/2002.12261v2
- **DOI**: None
- **Categories**: **cs.HC**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12261v2)
- **Published**: 2020-02-27 17:04:07+00:00
- **Updated**: 2020-03-02 17:22:42+00:00
- **Authors**: Min Hun Lee, Daniel P. Siewiorek, Asim Smailagic, Alexandre Bernardino, Sergi Bermúdez i Badia
- **Comment**: None
- **Journal**: None
- **Summary**: Rehabilitation assessment is critical to determine an adequate intervention for a patient. However, the current practices of assessment mainly rely on therapist's experience, and assessment is infrequently executed due to the limited availability of a therapist. In this paper, we identified the needs of therapists to assess patient's functional abilities (e.g. alternative perspective on assessment with quantitative information on patient's exercise motions). As a result, we developed an intelligent decision support system that can identify salient features of assessment using reinforcement learning to assess the quality of motion and summarize patient specific analysis. We evaluated this system with seven therapists using the dataset from 15 patient performing three exercises. The evaluation demonstrates that our system is preferred over a traditional system without analysis while presenting more useful information and significantly increasing the agreement over therapists' evaluation from 0.6600 to 0.7108 F1-scores ($p <0.05$). We discuss the importance of presenting contextually relevant and salient information and adaptation to develop a human and machine collaborative decision making system.



### Coronary Wall Segmentation in CCTA Scans via a Hybrid Net with Contours Regularization
- **Arxiv ID**: http://arxiv.org/abs/2002.12263v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12263v1)
- **Published**: 2020-02-27 17:06:58+00:00
- **Updated**: 2020-02-27 17:06:58+00:00
- **Authors**: Kaikai Huang, Antonio Tejero-de-Pablos, Hiroaki Yamane, Yusuke Kurose, Junichi Iho, Youji Tokunaga, Makoto Horie, Keisuke Nishizawa, Yusaku Hayashi, Yasushi Koyama, Tatsuya Harada
- **Comment**: 5 pages, 2 figures, accepted by ISBI 2020
- **Journal**: None
- **Summary**: Providing closed and well-connected boundaries of coronary artery is essential to assist cardiologists in the diagnosis of coronary artery disease (CAD). Recently, several deep learning-based methods have been proposed for boundary detection and segmentation in a medical image. However, when applied to coronary wall detection, they tend to produce disconnected and inaccurate boundaries. In this paper, we propose a novel boundary detection method for coronary arteries that focuses on the continuity and connectivity of the boundaries. In order to model the spatial continuity of consecutive images, our hybrid architecture takes a volume (i.e., a segment of the coronary artery) as input and detects the boundary of the target slice (i.e., the central slice of the segment). Then, to ensure closed boundaries, we propose a contour-constrained weighted Hausdorff distance loss. We evaluate our method on a dataset of 34 patients of coronary CT angiography scans with curved planar reconstruction (CCTA-CPR) of the arteries (i.e., cross-sections). Experiment results show that our method can produce smooth closed boundaries outperforming the state-of-the-art accuracy.



### 2D Convolutional Neural Networks for 3D Digital Breast Tomosynthesis Classification
- **Arxiv ID**: http://arxiv.org/abs/2002.12314v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2002.12314v1)
- **Published**: 2020-02-27 18:32:52+00:00
- **Updated**: 2020-02-27 18:32:52+00:00
- **Authors**: Yu Zhang, Xiaoqin Wang, Hunter Blanton, Gongbo Liang, Xin Xing, Nathan Jacobs
- **Comment**: Accepted by IEEE International Conference of Bioinformatics and
  Biomedicine (BIBM), 2019
- **Journal**: None
- **Summary**: Automated methods for breast cancer detection have focused on 2D mammography and have largely ignored 3D digital breast tomosynthesis (DBT), which is frequently used in clinical practice. The two key challenges in developing automated methods for DBT classification are handling the variable number of slices and retaining slice-to-slice changes. We propose a novel deep 2D convolutional neural network (CNN) architecture for DBT classification that simultaneously overcomes both challenges. Our approach operates on the full volume, regardless of the number of slices, and allows the use of pre-trained 2D CNNs for feature extraction, which is important given the limited amount of annotated training data. In an extensive evaluation on a real-world clinical dataset, our approach achieves 0.854 auROC, which is 28.80% higher than approaches based on 3D CNNs. We also find that these improvements are stable across a range of model configurations.



### Semantically-Guided Representation Learning for Self-Supervised Monocular Depth
- **Arxiv ID**: http://arxiv.org/abs/2002.12319v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12319v1)
- **Published**: 2020-02-27 18:40:10+00:00
- **Updated**: 2020-02-27 18:40:10+00:00
- **Authors**: Vitor Guizilini, Rui Hou, Jie Li, Rares Ambrus, Adrien Gaidon
- **Comment**: Proceedings of the Eighth International Conference on Learning
  Representations (ICLR 2020)
- **Journal**: None
- **Summary**: Self-supervised learning is showing great promise for monocular depth estimation, using geometry as the only source of supervision. Depth networks are indeed capable of learning representations that relate visual appearance to 3D properties by implicitly leveraging category-level patterns. In this work we investigate how to leverage more directly this semantic structure to guide geometric representation learning, while remaining in the self-supervised regime. Instead of using semantic labels and proxy losses in a multi-task approach, we propose a new architecture leveraging fixed pretrained semantic segmentation networks to guide self-supervised representation learning via pixel-adaptive convolutions. Furthermore, we propose a two-stage training process to overcome a common semantic bias on dynamic objects via resampling. Our method improves upon the state of the art for self-supervised monocular depth prediction over all pixels, fine-grained details, and per semantic categories.



### Visual Camera Re-Localization from RGB and RGB-D Images Using DSAC
- **Arxiv ID**: http://arxiv.org/abs/2002.12324v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12324v4)
- **Published**: 2020-02-27 18:45:21+00:00
- **Updated**: 2020-10-09 15:03:02+00:00
- **Authors**: Eric Brachmann, Carsten Rother
- **Comment**: None
- **Journal**: None
- **Summary**: We describe a learning-based system that estimates the camera position and orientation from a single input image relative to a known environment. The system is flexible w.r.t. the amount of information available at test and at training time, catering to different applications. Input images can be RGB-D or RGB, and a 3D model of the environment can be utilized for training but is not necessary. In the minimal case, our system requires only RGB images and ground truth poses at training time, and it requires only a single RGB image at test time. The framework consists of a deep neural network and fully differentiable pose optimization. The neural network predicts so called scene coordinates, i.e. dense correspondences between the input image and 3D scene space of the environment. The pose optimization implements robust fitting of pose parameters using differentiable RANSAC (DSAC) to facilitate end-to-end training. The system, an extension of DSAC++ and referred to as DSAC*, achieves state-of-the-art accuracy an various public datasets for RGB-based re-localization, and competitive accuracy for RGB-D-based re-localization.



### Hallucinative Topological Memory for Zero-Shot Visual Planning
- **Arxiv ID**: http://arxiv.org/abs/2002.12336v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG, cs.NE, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2002.12336v1)
- **Published**: 2020-02-27 18:54:42+00:00
- **Updated**: 2020-02-27 18:54:42+00:00
- **Authors**: Kara Liu, Thanard Kurutach, Christine Tung, Pieter Abbeel, Aviv Tamar
- **Comment**: None
- **Journal**: None
- **Summary**: In visual planning (VP), an agent learns to plan goal-directed behavior from observations of a dynamical system obtained offline, e.g., images obtained from self-supervised robot interaction. Most previous works on VP approached the problem by planning in a learned latent space, resulting in low-quality visual plans, and difficult training algorithms. Here, instead, we propose a simple VP method that plans directly in image space and displays competitive performance. We build on the semi-parametric topological memory (SPTM) method: image samples are treated as nodes in a graph, the graph connectivity is learned from image sequence data, and planning can be performed using conventional graph search methods. We propose two modifications on SPTM. First, we train an energy-based graph connectivity function using contrastive predictive coding that admits stable training. Second, to allow zero-shot planning in new domains, we learn a conditional VAE model that generates images given a context of the domain, and use these hallucinated samples for building the connectivity graph and planning. We show that this simple approach significantly outperform the state-of-the-art VP methods, in terms of both plan interpretability and success rate when using the plan to guide a trajectory-following controller. Interestingly, our method can pick up non-trivial visual properties of objects, such as their geometry, and account for it in the plans.



### A Novel Measure to Evaluate Generative Adversarial Networks Based on Direct Analysis of Generated Images
- **Arxiv ID**: http://arxiv.org/abs/2002.12345v4
- **DOI**: 10.1007/s00521-021-06031-5
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12345v4)
- **Published**: 2020-02-27 18:59:22+00:00
- **Updated**: 2021-04-07 05:18:25+00:00
- **Authors**: Shuyue Guan, Murray Loew
- **Comment**: 16 pages, 11 figures. Accepted by the Neural Computing and
  Applications journal
- **Journal**: Neural Comput & Applic 33, 13921-13936 (2021)
- **Summary**: The Generative Adversarial Network (GAN) is a state-of-the-art technique in the field of deep learning. A number of recent papers address the theory and applications of GANs in various fields of image processing. Fewer studies, however, have directly evaluated GAN outputs. Those that have been conducted focused on using classification performance, e.g., Inception Score (IS) and statistical metrics, e.g., Fr\'echet Inception Distance (FID). Here, we consider a fundamental way to evaluate GANs by directly analyzing the images they generate, instead of using them as inputs to other classifiers. We characterize the performance of a GAN as an image generator according to three aspects: 1) Creativity: non-duplication of the real images. 2) Inheritance: generated images should have the same style, which retains key features of the real images. 3) Diversity: generated images are different from each other. A GAN should not generate a few different images repeatedly. Based on the three aspects of ideal GANs, we have designed the Likeness Score (LS) to evaluate GAN performance, and have applied it to evaluate several typical GANs. We compared our proposed measure with two commonly used GAN evaluation methods: IS and FID, and four additional measures. Furthermore, we discuss how these evaluations could help us deepen our understanding of GANs and improve their performance.



### Joint 2D-3D Breast Cancer Classification
- **Arxiv ID**: http://arxiv.org/abs/2002.12392v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2002.12392v1)
- **Published**: 2020-02-27 19:08:16+00:00
- **Updated**: 2020-02-27 19:08:16+00:00
- **Authors**: Gongbo Liang, Xiaoqin Wang, Yu Zhang, Xin Xing, Hunter Blanton, Tawfiq Salem, Nathan Jacobs
- **Comment**: Accepted by IEEE International Conference of Bioinformatics and
  Biomedicine (BIBM), 2019
- **Journal**: None
- **Summary**: Breast cancer is the malignant tumor that causes the highest number of cancer deaths in females. Digital mammograms (DM or 2D mammogram) and digital breast tomosynthesis (DBT or 3D mammogram) are the two types of mammography imagery that are used in clinical practice for breast cancer detection and diagnosis. Radiologists usually read both imaging modalities in combination; however, existing computer-aided diagnosis tools are designed using only one imaging modality. Inspired by clinical practice, we propose an innovative convolutional neural network (CNN) architecture for breast cancer classification, which uses both 2D and 3D mammograms, simultaneously. Our experiment shows that the proposed method significantly improves the performance of breast cancer classification. By assembling three CNN classifiers, the proposed model achieves 0.97 AUC, which is 34.72% higher than the methods using only one imaging modality.



### Affinity guided Geometric Semi-Supervised Metric Learning
- **Arxiv ID**: http://arxiv.org/abs/2002.12394v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12394v2)
- **Published**: 2020-02-27 19:10:21+00:00
- **Updated**: 2020-11-06 17:49:32+00:00
- **Authors**: Ujjal Kr Dutta, Mehrtash Harandi, Chellu Chandra Sekhar
- **Comment**: Paper accepted in NeurIPS 2020 workshop on Differential Geometry
  meets Deep Learning
- **Journal**: None
- **Summary**: In this paper, we revamp the forgotten classical Semi-Supervised Distance Metric Learning (SSDML) problem from a Riemannian geometric lens, to leverage stochastic optimization within a end-to-end deep framework. The motivation comes from the fact that apart from a few classical SSDML approaches learning a linear Mahalanobis metric, deep SSDML has not been studied. We first extend existing SSDML methods to their deep counterparts and then propose a new method to overcome their limitations. Due to the nature of constraints on our metric parameters, we leverage Riemannian optimization. Our deep SSDML method with a novel affinity propagation based triplet mining strategy outperforms its competitors.



### TSS: Transformation-Specific Smoothing for Robustness Certification
- **Arxiv ID**: http://arxiv.org/abs/2002.12398v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12398v5)
- **Published**: 2020-02-27 19:19:32+00:00
- **Updated**: 2021-11-16 10:11:15+00:00
- **Authors**: Linyi Li, Maurice Weber, Xiaojun Xu, Luka Rimanic, Bhavya Kailkhura, Tao Xie, Ce Zhang, Bo Li
- **Comment**: 2021 ACM SIGSAC Conference on Computer and Communications Security
  (CCS '21)
- **Journal**: None
- **Summary**: As machine learning (ML) systems become pervasive, safeguarding their security is critical. However, recently it has been demonstrated that motivated adversaries are able to mislead ML systems by perturbing test data using semantic transformations. While there exists a rich body of research providing provable robustness guarantees for ML models against $\ell_p$ norm bounded adversarial perturbations, guarantees against semantic perturbations remain largely underexplored. In this paper, we provide TSS -- a unified framework for certifying ML robustness against general adversarial semantic transformations. First, depending on the properties of each transformation, we divide common transformations into two categories, namely resolvable (e.g., Gaussian blur) and differentially resolvable (e.g., rotation) transformations. For the former, we propose transformation-specific randomized smoothing strategies and obtain strong robustness certification. The latter category covers transformations that involve interpolation errors, and we propose a novel approach based on stratified sampling to certify the robustness. Our framework TSS leverages these certification strategies and combines with consistency-enhanced training to provide rigorous certification of robustness. We conduct extensive experiments on over ten types of challenging semantic transformations and show that TSS significantly outperforms the state of the art. Moreover, to the best of our knowledge, TSS is the first approach that achieves nontrivial certified robustness on the large-scale ImageNet dataset. For instance, our framework achieves 30.4% certified robust accuracy against rotation attack (within $\pm 30^\circ$) on ImageNet. Moreover, to consider a broader range of transformations, we show TSS is also robust against adaptive attacks and unforeseen image corruptions such as CIFAR-10-C and ImageNet-C.



### Cognitively-Inspired Model for Incremental Learning Using a Few Examples
- **Arxiv ID**: http://arxiv.org/abs/2002.12411v3
- **DOI**: 10.1109/CVPRW50498.2020.00119
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12411v3)
- **Published**: 2020-02-27 19:52:42+00:00
- **Updated**: 2020-07-30 06:55:06+00:00
- **Authors**: Ali Ayub, Alan Wagner
- **Comment**: Added link to the code in the paper
- **Journal**: The IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR) Workshops, 2020
- **Summary**: Incremental learning attempts to develop a classifier which learns continuously from a stream of data segregated into different classes. Deep learning approaches suffer from catastrophic forgetting when learning classes incrementally, while most incremental learning approaches require a large amount of training data per class. We examine the problem of incremental learning using only a few training examples, referred to as Few-Shot Incremental Learning (FSIL). To solve this problem, we propose a novel approach inspired by the concept learning model of the hippocampus and the neocortex that represents each image class as centroids and does not suffer from catastrophic forgetting. We evaluate our approach on three class-incremental learning benchmarks: Caltech-101, CUBS-200-2011 and CIFAR-100 for incremental and few-shot incremental learning and show that our approach achieves state-of-the-art results in terms of classification accuracy over all learned classes.



### SilhoNet-Fisheye: Adaptation of A ROI Based Object Pose Estimation Network to Monocular Fisheye Images
- **Arxiv ID**: http://arxiv.org/abs/2002.12415v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12415v1)
- **Published**: 2020-02-27 19:57:33+00:00
- **Updated**: 2020-02-27 19:57:33+00:00
- **Authors**: Gideon Billings, Matthew Johnson-Roberson
- **Comment**: Submitted to IEEE RAL/IROS 2020
- **Journal**: None
- **Summary**: There has been much recent interest in deep learning methods for monocular image based object pose estimation. While object pose estimation is an important problem for autonomous robot interaction with the physical world, and the application space for monocular-based methods is expansive, there has been little work on applying these methods with fisheye imaging systems. Also, little exists in the way of annotated fisheye image datasets on which these methods can be developed and tested. The research landscape is even more sparse for object detection methods applied in the underwater domain, fisheye image based or otherwise. In this work, we present a novel framework for adapting a ROI-based 6D object pose estimation method to work on full fisheye images. The method incorporates the gnomic projection of regions of interest from an intermediate spherical image representation to correct for the fisheye distortions. Further, we contribute a fisheye image dataset, called UWHandles, collected in natural underwater environments, with 6D object pose and 2D bounding box annotations.



### Learning in the Frequency Domain
- **Arxiv ID**: http://arxiv.org/abs/2002.12416v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12416v4)
- **Published**: 2020-02-27 19:57:55+00:00
- **Updated**: 2020-03-31 23:40:51+00:00
- **Authors**: Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-Kuang Chen, Fengbo Ren
- **Comment**: Accepted to CVPR 2020; https://github.com/calmevtime/DCTNet
- **Journal**: None
- **Summary**: Deep neural networks have achieved remarkable success in computer vision tasks. Existing neural networks mainly operate in the spatial domain with fixed input sizes. For practical applications, images are usually large and have to be downsampled to the predetermined input size of neural networks. Even though the downsampling operations reduce computation and the required communication bandwidth, it removes both redundant and salient information obliviously, which results in accuracy degradation. Inspired by digital signal processing theories, we analyze the spectral bias from the frequency perspective and propose a learning-based frequency selection method to identify the trivial frequency components which can be removed without accuracy loss. The proposed method of learning in the frequency domain leverages identical structures of the well-known neural networks, such as ResNet-50, MobileNetV2, and Mask R-CNN, while accepting the frequency-domain information as the input. Experiment results show that learning in the frequency domain with static channel selection can achieve higher accuracy than the conventional spatial downsampling approach and meanwhile further reduce the input data size. Specifically for ImageNet classification with the same input size, the proposed method achieves 1.41% and 0.66% top-1 accuracy improvements on ResNet-50 and MobileNetV2, respectively. Even with half input size, the proposed method still improves the top-1 accuracy on ResNet-50 by 1%. In addition, we observe a 0.8% average precision improvement on Mask R-CNN for instance segmentation on the COCO dataset.



### MNN: A Universal and Efficient Inference Engine
- **Arxiv ID**: http://arxiv.org/abs/2002.12418v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.12418v1)
- **Published**: 2020-02-27 20:03:16+00:00
- **Updated**: 2020-02-27 20:03:16+00:00
- **Authors**: Xiaotang Jiang, Huan Wang, Yiliu Chen, Ziqi Wu, Lichuan Wang, Bin Zou, Yafeng Yang, Zongyang Cui, Yu Cai, Tianhang Yu, Chengfei Lv, Zhihua Wu
- **Comment**: Accepted by MLSys 2020
- **Journal**: None
- **Summary**: Deploying deep learning models on mobile devices draws more and more attention recently. However, designing an efficient inference engine on devices is under the great challenges of model compatibility, device diversity, and resource limitation. To deal with these challenges, we propose Mobile Neural Network (MNN), a universal and efficient inference engine tailored to mobile applications. In this paper, the contributions of MNN include: (1) presenting a mechanism called pre-inference that manages to conduct runtime optimization; (2)deliveringthorough kernel optimization on operators to achieve optimal computation performance; (3) introducing backend abstraction module which enables hybrid scheduling and keeps the engine lightweight. Extensive benchmark experiments demonstrate that MNN performs favorably against other popular lightweight deep learning frameworks. MNN is available to public at: https://github.com/alibaba/MNN.



### Triangle-Net: Towards Robustness in Point Cloud Learning
- **Arxiv ID**: http://arxiv.org/abs/2003.00856v2
- **DOI**: 10.1109/WACV48630.2021.00087
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2003.00856v2)
- **Published**: 2020-02-27 20:42:32+00:00
- **Updated**: 2021-08-24 02:07:06+00:00
- **Authors**: Chenxi Xiao, Juan Wachs
- **Comment**: WACV 2021
- **Journal**: Proceedings of the IEEE/CVF Winter Conference on Applications of
  Computer Vision (WACV), 2021, pp. 826-835
- **Summary**: Three dimensional (3D) object recognition is becoming a key desired capability for many computer vision systems such as autonomous vehicles, service robots and surveillance drones to operate more effectively in unstructured environments. These real-time systems require effective classification methods that are robust to various sampling resolutions, noisy measurements, and unconstrained pose configurations. Previous research has shown that points' sparsity, rotation and positional inherent variance can lead to a significant drop in the performance of point cloud based classification techniques. However, neither of them is sufficiently robust to multifactorial variance and significant sparsity. In this regard, we propose a novel approach for 3D classification that can simultaneously achieve invariance towards rotation, positional shift, scaling, and is robust to point sparsity. To this end, we introduce a new feature that utilizes graph structure of point clouds, which can be learned end-to-end with our proposed neural network to acquire a robust latent representation of the 3D object. We show that such latent representations can significantly improve the performance of object classification and retrieval tasks when points are sparse. Further, we show that our approach outperforms PointNet and 3DmFV by 35.0% and 28.1% respectively in ModelNet 40 classification tasks using sparse point clouds of only 16 points under arbitrary SO(3) rotation.



### TGGLines: A Robust Topological Graph Guided Line Segment Detector for Low Quality Binary Images
- **Arxiv ID**: http://arxiv.org/abs/2002.12428v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.12428v1)
- **Published**: 2020-02-27 20:47:18+00:00
- **Updated**: 2020-02-27 20:47:18+00:00
- **Authors**: Ming Gong, Liping Yang, Catherine Potts, Vijayan K. Asari, Diane Oyen, Brendt Wohlberg
- **Comment**: None
- **Journal**: None
- **Summary**: Line segment detection is an essential task in computer vision and image analysis, as it is the critical foundation for advanced tasks such as shape modeling and road lane line detection for autonomous driving. We present a robust topological graph guided approach for line segment detection in low quality binary images (hence, we call it TGGLines). Due to the graph-guided approach, TGGLines not only detects line segments, but also organizes the segments with a line segment connectivity graph, which means the topological relationships (e.g., intersection, an isolated line segment) of the detected line segments are captured and stored; whereas other line detectors only retain a collection of loose line segments. Our empirical results show that the TGGLines detector visually and quantitatively outperforms state-of-the-art line segment detection methods. In addition, our TGGLines approach has the following two competitive advantages: (1) our method only requires one parameter and it is adaptive, whereas almost all other line segment detection methods require multiple (non-adaptive) parameters, and (2) the line segments detected by TGGLines are organized by a line segment connectivity graph.



### Deep Meditations: Controlled navigation of latent space
- **Arxiv ID**: http://arxiv.org/abs/2003.00910v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2003.00910v1)
- **Published**: 2020-02-27 21:19:44+00:00
- **Updated**: 2020-02-27 21:19:44+00:00
- **Authors**: Memo Akten, Rebecca Fiebrink, Mick Grierson
- **Comment**: Presented at the 2nd Workshop on Machine Learning for Creativity and
  Design at the Neural Information Processing Systems (NeurIPS) 2018 conference
  in Montreal
- **Journal**: None
- **Summary**: We introduce a method which allows users to creatively explore and navigate the vast latent spaces of deep generative models. Specifically, our method enables users to \textit{discover} and \textit{design} \textit{trajectories} in these high dimensional spaces, to construct stories, and produce time-based media such as videos---\textit{with meaningful control over narrative}. Our goal is to encourage and aid the use of deep generative models as a medium for creative expression and story telling with meaningful human control. Our method is analogous to traditional video production pipelines in that we use a conventional non-linear video editor with proxy clips, and conform with arrays of latent space vectors. Examples can be seen at \url{http://deepmeditations.ai}.



### Is the Meta-Learning Idea Able to Improve the Generalization of Deep Neural Networks on the Standard Supervised Learning?
- **Arxiv ID**: http://arxiv.org/abs/2002.12455v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12455v1)
- **Published**: 2020-02-27 21:29:54+00:00
- **Updated**: 2020-02-27 21:29:54+00:00
- **Authors**: Xiang Deng, Zhongfei Zhang
- **Comment**: None
- **Journal**: ICPR 2020
- **Summary**: Substantial efforts have been made on improving the generalization abilities of deep neural networks (DNNs) in order to obtain better performances without introducing more parameters. On the other hand, meta-learning approaches exhibit powerful generalization on new tasks in few-shot learning. Intuitively, few-shot learning is more challenging than the standard supervised learning as each target class only has a very few or no training samples. The natural question that arises is whether the meta-learning idea can be used for improving the generalization of DNNs on the standard supervised learning. In this paper, we propose a novel meta-learning based training procedure (MLTP) for DNNs and demonstrate that the meta-learning idea can indeed improve the generalization abilities of DNNs. MLTP simulates the meta-training process by considering a batch of training samples as a task. The key idea is that the gradient descent step for improving the current task performance should also improve a new task performance, which is ignored by the current standard procedure for training neural networks. MLTP also benefits from all the existing training techniques such as dropout, weight decay, and batch normalization. We evaluate MLTP by training a variety of small and large neural networks on three benchmark datasets, i.e., CIFAR-10, CIFAR-100, and Tiny ImageNet. The experimental results show a consistently improved generalization performance on all the DNNs with different sizes, which verifies the promise of MLTP and demonstrates that the meta-learning idea is indeed able to improve the generalization of DNNs on the standard supervised learning.



### Learning Fast and Robust Target Models for Video Object Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2003.00908v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2003.00908v2)
- **Published**: 2020-02-27 21:58:06+00:00
- **Updated**: 2020-03-31 09:58:00+00:00
- **Authors**: Andreas Robinson, Felix Järemo Lawin, Martin Danelljan, Fahad Shahbaz Khan, Michael Felsberg
- **Comment**: CVPR 2020. arXiv admin note: substantial text overlap with
  arXiv:1904.08630
- **Journal**: None
- **Summary**: Video object segmentation (VOS) is a highly challenging problem since the initial mask, defining the target object, is only given at test-time. The main difficulty is to effectively handle appearance changes and similar background objects, while maintaining accurate segmentation. Most previous approaches fine-tune segmentation networks on the first frame, resulting in impractical frame-rates and risk of overfitting. More recent methods integrate generative target appearance models, but either achieve limited robustness or require large amounts of training data.   We propose a novel VOS architecture consisting of two network components. The target appearance model consists of a light-weight module, which is learned during the inference stage using fast optimization techniques to predict a coarse but robust target segmentation. The segmentation model is exclusively trained offline, designed to process the coarse scores into high quality segmentation masks. Our method is fast, easily trainable and remains highly effective in cases of limited training data. We perform extensive experiments on the challenging YouTube-VOS and DAVIS datasets. Our network achieves favorable performance, while operating at higher frame-rates compared to state-of-the-art. Code and trained models are available at https://github.com/andr345/frtm-vos.



### Target Detection, Tracking and Avoidance System for Low-cost UAVs using AI-Based Approaches
- **Arxiv ID**: http://arxiv.org/abs/2002.12461v1
- **DOI**: 10.1109/REDUAS47371.2019.8999683
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2002.12461v1)
- **Published**: 2020-02-27 21:58:54+00:00
- **Updated**: 2020-02-27 21:58:54+00:00
- **Authors**: Vinorth Varatharasan, Alice Shuang Shuang Rao, Eric Toutounji, Ju-Hyeon Hong, Hyo-Sang Shin
- **Comment**: IEEE RED-UAS 2019 Conference
- **Journal**: None
- **Summary**: An onboard target detection, tracking and avoidance system has been developed in this paper, for low-cost UAV flight controllers using AI-Based approaches. The aim of the proposed system is that an ally UAV can either avoid or track an unexpected enemy UAV with a net to protect itself. In this point of view, a simple and robust target detection, tracking and avoidance system is designed. Two open-source tools were used for the aim: a state-of-the-art object detection technique called SSD and an API for MAVLink compatible systems called MAVSDK. The MAVSDK performs velocity control when a UAV is detected so that the manoeuvre is done simply and efficiently. The proposed system was verified with Software in the loop (SITL) and Hardware in the loop (HITL) simulators. The simplicity of this algorithm makes it innovative, and therefore it should be used in future applications needing robust performances with low-cost hardware such as delivery drone applications.



### LEEP: A New Measure to Evaluate Transferability of Learned Representations
- **Arxiv ID**: http://arxiv.org/abs/2002.12462v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.12462v2)
- **Published**: 2020-02-27 22:02:20+00:00
- **Updated**: 2020-08-14 02:33:25+00:00
- **Authors**: Cuong V. Nguyen, Tal Hassner, Matthias Seeger, Cedric Archambeau
- **Comment**: Published at the International Conference on Machine Learning (ICML)
  2020
- **Journal**: None
- **Summary**: We introduce a new measure to evaluate the transferability of representations learned by classifiers. Our measure, the Log Expected Empirical Prediction (LEEP), is simple and easy to compute: when given a classifier trained on a source data set, it only requires running the target data set through this classifier once. We analyze the properties of LEEP theoretically and demonstrate its effectiveness empirically. Our analysis shows that LEEP can predict the performance and convergence speed of both transfer and meta-transfer learning methods, even for small or imbalanced data. Moreover, LEEP outperforms recently proposed transferability measures such as negative conditional entropy and H scores. Notably, when transferring from ImageNet to CIFAR100, LEEP can achieve up to 30% improvement compared to the best competing method in terms of the correlations with actual transfer accuracy.



### Improving Learning Effectiveness For Object Detection and Classification in Cluttered Backgrounds
- **Arxiv ID**: http://arxiv.org/abs/2002.12467v1
- **DOI**: 10.1109/REDUAS47371.2019.8999695
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12467v1)
- **Published**: 2020-02-27 22:28:48+00:00
- **Updated**: 2020-02-27 22:28:48+00:00
- **Authors**: Vinorth Varatharasan, Hyo-Sang Shin, Antonios Tsourdos, Nick Colosimo
- **Comment**: IEEE RED-UAS 2019 Conference
- **Journal**: None
- **Summary**: Usually, Neural Networks models are trained with a large dataset of images in homogeneous backgrounds. The issue is that the performance of the network models trained could be significantly degraded in a complex and heterogeneous environment. To mitigate the issue, this paper develops a framework that permits to autonomously generate a training dataset in heterogeneous cluttered backgrounds. It is clear that the learning effectiveness of the proposed framework should be improved in complex and heterogeneous environments, compared with the ones with the typical dataset. In our framework, a state-of-the-art image segmentation technique called DeepLab is used to extract objects of interest from a picture and Chroma-key technique is then used to merge the extracted objects of interest into specific heterogeneous backgrounds. The performance of the proposed framework is investigated through empirical tests and compared with that of the model trained with the COCO dataset. The results show that the proposed framework outperforms the model compared. This implies that the learning effectiveness of the framework developed is superior to the models with the typical dataset.



### RSANet: Recurrent Slice-wise Attention Network for Multiple Sclerosis Lesion Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2002.12470v1
- **DOI**: 10.1007/978-3-030-32248-9_46
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.12470v1)
- **Published**: 2020-02-27 22:46:10+00:00
- **Updated**: 2020-02-27 22:46:10+00:00
- **Authors**: Hang Zhang, Jinwei Zhang, Qihao Zhang, Jeremy Kim, Shun Zhang, Susan A. Gauthier, Pascal Spincemaille, Thanh D. Nguyen, Mert R. Sabuncu, Yi Wang
- **Comment**: Accepted for publication in MICCAI 2019
- **Journal**: None
- **Summary**: Brain lesion volume measured on T2 weighted MRI images is a clinically important disease marker in multiple sclerosis (MS). Manual delineation of MS lesions is a time-consuming and highly operator-dependent task, which is influenced by lesion size, shape and conspicuity. Recently, automated lesion segmentation algorithms based on deep neural networks have been developed with promising results. In this paper, we propose a novel recurrent slice-wise attention network (RSANet), which models 3D MRI images as sequences of slices and captures long-range dependencies through a recurrent manner to utilize contextual information of MS lesions. Experiments on a dataset with 43 patients show that the proposed method outperforms the state-of-the-art approaches. Our implementation is available online at https://github.com/tinymilky/RSANet.



