# Arxiv Papers in cs.CV on 2020-02-11
### Reconstructing the Noise Manifold for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/2002.04147v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04147v2)
- **Published**: 2020-02-11 00:31:31+00:00
- **Updated**: 2020-03-07 01:00:00+00:00
- **Authors**: Ioannis Marras, Grigorios G. Chrysos, Ioannis Alexiou, Gregory Slabaugh, Stefanos Zafeiriou
- **Comment**: 18 pages, 8 figures
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (CNNs) have been successfully used in many low-level vision problems like image denoising. Although the conditional image generation techniques have led to large improvements in this task, there has been little effort in providing conditional generative adversarial networks (cGAN)[42] with an explicit way of understanding the image noise for object-independent denoising reliable for real-world applications. The task of leveraging structures in the target space is unstable due to the complexity of patterns in natural scenes, so the presence of unnatural artifacts or over-smoothed image areas cannot be avoided. To fill the gap, in this work we introduce the idea of a cGAN which explicitly leverages structure in the image noise space. By learning directly a low dimensional manifold of the image noise, the generator promotes the removal from the noisy image only that information which spans this manifold. This idea brings many advantages while it can be appended at the end of any denoiser to significantly improve its performance. Based on our experiments, our model substantially outperforms existing state-of-the-art architectures, resulting in denoised images with less oversmoothing and better detail.



### Sperm Detection and Tracking in Phase-Contrast Microscopy Image Sequences using Deep Learning and Modified CSR-DCF
- **Arxiv ID**: http://arxiv.org/abs/2002.04034v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04034v4)
- **Published**: 2020-02-11 00:38:47+00:00
- **Updated**: 2020-04-04 06:21:26+00:00
- **Authors**: Mohammad reza Mohammadi, Mohammad Rahimzadeh, Abolfazl Attar
- **Comment**: None
- **Journal**: None
- **Summary**: Nowadays, computer-aided sperm analysis (CASA) systems have made a big leap in extracting the characteristics of spermatozoa for studies or measuring human fertility. The first step in sperm characteristics analysis is sperm detection in the frames of the video sample. In this article, we used RetinaNet, a deep fully convolutional neural network as the object detector. Sperms are small objects with few attributes, that makes the detection more difficult in high-density samples and especially when there are other particles in semen, which could be like sperm heads. One of the main attributes of sperms is their movement, but this attribute cannot be extracted when only one frame would be fed to the network. To improve the performance of the sperm detection network, we concatenated some consecutive frames to use as the input of the network. With this method, the motility attribute has also been extracted, and then with the help of the deep convolutional network, we have achieved high accuracy in sperm detection. The second step is tracking the sperms, for extracting the motility parameters that are essential for indicating fertility and other studies on sperms. In the tracking phase, we modify the CSR-DCF algorithm. This method also has shown excellent results in sperm tracking even in high-density sperm samples, occlusions, sperm colliding, and when sperms exit from a frame and re-enter in the next frames. The average precision of the detection phase is 99.1%, and the F1 score of the tracking method evaluation is 96.61%. These results can be a great help in studies investigating sperm behavior and analyzing fertility possibility.



### Incremental Meta-Learning via Indirect Discriminant Alignment
- **Arxiv ID**: http://arxiv.org/abs/2002.04162v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04162v2)
- **Published**: 2020-02-11 01:39:12+00:00
- **Updated**: 2020-04-21 18:19:18+00:00
- **Authors**: Qing Liu, Orchid Majumder, Alessandro Achille, Avinash Ravichandran, Rahul Bhotika, Stefano Soatto
- **Comment**: None
- **Journal**: None
- **Summary**: Majority of the modern meta-learning methods for few-shot classification tasks operate in two phases: a meta-training phase where the meta-learner learns a generic representation by solving multiple few-shot tasks sampled from a large dataset and a testing phase, where the meta-learner leverages its learnt internal representation for a specific few-shot task involving classes which were not seen during the meta-training phase. To the best of our knowledge, all such meta-learning methods use a single base dataset for meta-training to sample tasks from and do not adapt the algorithm after meta-training. This strategy may not scale to real-world use-cases where the meta-learner does not potentially have access to the full meta-training dataset from the very beginning and we need to update the meta-learner in an incremental fashion when additional training data becomes available. Through our experimental setup, we develop a notion of incremental learning during the meta-training phase of meta-learning and propose a method which can be used with multiple existing metric-based meta-learning algorithms. Experimental results on benchmark dataset show that our approach performs favorably at test time as compared to training a model with the full meta-training set and incurs negligible amount of catastrophic forgetting



### Learning to Incorporate Structure Knowledge for Image Inpainting
- **Arxiv ID**: http://arxiv.org/abs/2002.04170v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04170v2)
- **Published**: 2020-02-11 02:22:38+00:00
- **Updated**: 2020-02-12 03:12:04+00:00
- **Authors**: Jie Yang, Zhiquan Qi, Yong Shi
- **Comment**: Accepted by AAAI 2020
- **Journal**: None
- **Summary**: This paper develops a multi-task learning framework that attempts to incorporate the image structure knowledge to assist image inpainting, which is not well explored in previous works. The primary idea is to train a shared generator to simultaneously complete the corrupted image and corresponding structures --- edge and gradient, thus implicitly encouraging the generator to exploit relevant structure knowledge while inpainting. In the meantime, we also introduce a structure embedding scheme to explicitly embed the learned structure features into the inpainting process, thus to provide possible preconditions for image completion. Specifically, a novel pyramid structure loss is proposed to supervise structure learning and embedding. Moreover, an attention mechanism is developed to further exploit the recurrent structures and patterns in the image to refine the generated structures and contents. Through multi-task learning, structure embedding besides with attention, our framework takes advantage of the structure knowledge and outperforms several state-of-the-art methods on benchmark datasets quantitatively and qualitatively.



### Optimal Transfer Learning Model for Binary Classification of Funduscopic Images through Simple Heuristics
- **Arxiv ID**: http://arxiv.org/abs/2002.04189v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04189v3)
- **Published**: 2020-02-11 03:49:14+00:00
- **Updated**: 2020-02-20 21:41:36+00:00
- **Authors**: Rohit Jammula, Vishnu Rajan Tejus, Shreya Shankar
- **Comment**: 5 pages. 4 tables. Accepted to present in Machine Learning in
  Computational Biology (MLCB) 2019 conference
- **Journal**: None
- **Summary**: Deep learning models have the capacity to fundamentally revolutionize medical imaging analysis, and they have particularly interesting applications in computer-aided diagnosis. We attempt to use deep learning neural networks to diagnose funduscopic images, visual representations of the interior of the eye. Recently, a few robust deep learning approaches have performed binary classification to infer the presence of a specific ocular disease, such as glaucoma or diabetic retinopathy. In an effort to broaden the applications of computer-aided ocular disease diagnosis, we propose a unifying model for disease classification: low-cost inference of a fundus image to determine whether it is healthy or diseased. To achieve this, we use transfer learning techniques, which retain the more overarching capabilities of a pre-trained base architecture but can adapt to another dataset. For comparisons, we then develop a custom heuristic equation and evaluation metric ranking system to determine the optimal base architecture and hyperparameters. The Xception base architecture, Adam optimizer, and mean squared error loss function perform best, achieving 90% accuracy, 94% sensitivity, and 86% specificity. For additional ease of use, we contain the model in a web interface whose file chooser can access the local filesystem, allowing for use on any internet-connected device: mobile, PC, or otherwise.



### From IC Layout to Die Photo: A CNN-Based Data-Driven Approach
- **Arxiv ID**: http://arxiv.org/abs/2002.04967v2
- **DOI**: 10.1109/TCAD.2020.3015469
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04967v2)
- **Published**: 2020-02-11 04:02:04+00:00
- **Updated**: 2020-08-06 13:16:34+00:00
- **Authors**: Hao-Chiang Shao, Chao-Yi Peng, Jun-Rei Wu, Chia-Wen Lin, Shao-Yun Fang, Pin-Yen Tsai, Yan-Hsiu Liu
- **Comment**: 14 pages, 16 figures
- **Journal**: None
- **Summary**: We propose a deep learning-based data-driven framework consisting of two convolutional neural networks: i) LithoNet that predicts the shape deformations on a circuit due to IC fabrication, and ii) OPCNet that suggests IC layout corrections to compensate for such shape deformations. By learning the shape correspondences between pairs of layout design patterns and their scanning electron microscope (SEM) images of the product wafer thereof, given an IC layout pattern, LithoNet can mimic the fabrication process to predict its fabricated circuit shape. Furthermore, LithoNet can take the wafer fabrication parameters as a latent vector to model the parametric product variations that can be inspected on SEM images. Besides, traditional optical proximity correction (OPC) methods used to suggest a correction on a lithographic photomask is computationally expensive. Our proposed OPCNet mimics the OPC procedure and efficiently generates a corrected photomask by collaborating with LithoNet to examine if the shape of a fabricated circuit optimally matches its original layout design. As a result, the proposed LithoNet-OPCNet framework can not only predict the shape of a fabricated IC from its layout pattern, but also suggests a layout correction according to the consistency between the predicted shape and the given layout. Experimental results with several benchmark layout patterns demonstrate the effectiveness of the proposed method.



### Fine-grained Uncertainty Modeling in Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2002.04205v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04205v1)
- **Published**: 2020-02-11 05:06:25+00:00
- **Updated**: 2020-02-11 05:06:25+00:00
- **Authors**: Rahul Soni, Naresh Shah, Jimmy D. Moore
- **Comment**: None
- **Journal**: None
- **Summary**: Existing uncertainty modeling approaches try to detect an out-of-distribution point from the in-distribution dataset. We extend this argument to detect finer-grained uncertainty that distinguishes between (a). certain points, (b). uncertain points but within the data distribution, and (c). out-of-distribution points. Our method corrects overconfident NN decisions, detects outlier points and learns to say ``I don't know'' when uncertain about a critical point between the top two predictions. In addition, we provide a mechanism to quantify class distributions overlap in the decision manifold and investigate its implications in model interpretability.   Our method is two-step: in the first step, the proposed method builds a class distribution using Kernel Activation Vectors (kav) extracted from the Network. In the second step, the algorithm determines the confidence of a test point by a hierarchical decision rule based on the chi-squared distribution of squared Mahalanobis distances.   Our method sits on top of a given Neural Network, requires a single scan of training data to estimate class distribution statistics, and is highly scalable to deep networks and wider pre-softmax layer. As a positive side effect, our method helps to prevent adversarial attacks without requiring any additional training. It is directly achieved when the Softmax layer is substituted by our robust uncertainty layer at the evaluation phase.



### Dual-Triplet Metric Learning for Unsupervised Domain Adaptation in Video-Based Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/2002.04206v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04206v1)
- **Published**: 2020-02-11 05:06:30+00:00
- **Updated**: 2020-02-11 05:06:30+00:00
- **Authors**: George Ekladious, Hugo Lemoine, Eric Granger, Kaveh Kamali, Salim Moudache
- **Comment**: Submitted too IJCNN2020
- **Journal**: None
- **Summary**: The scalability and complexity of deep learning models remains a key issue in many of visual recognition applications like, e.g., video surveillance, where fine tuning with labeled image data from each new camera is required to reduce the domain shift between videos captured from the source domain, e.g., a laboratory setting, and the target domain, i.e, an operational environment. In many video surveillance applications, like face recognition (FR) and person re-identification, a pair-wise matcher is used to assign a query image captured using a video camera to the corresponding reference images in a gallery. The different configurations and operational conditions of video cameras can introduce significant shifts in the pair-wise distance distributions, resulting in degraded recognition performance for new cameras. In this paper, a new deep domain adaptation (DA) method is proposed to adapt the CNN embedding of a Siamese network using unlabeled tracklets captured with a new video cameras. To this end, a dual-triplet loss is introduced for metric learning, where two triplets are constructed using video data from a source camera, and a new target camera. In order to constitute the dual triplets, a mutual-supervised learning approach is introduced where the source camera acts as a teacher, providing the target camera with an initial embedding. Then, the student relies on the teacher to iteratively label the positive and negative pairs collected during, e.g., initial camera calibration. Both source and target embeddings continue to simultaneously learn such that their pair-wise distance distributions become aligned. For validation, the proposed metric learning technique is used to train deep Siamese networks under different training scenarios, and is compared to state-of-the-art techniques for still-to-video FR on the COX-S2V and a private video-based FR dataset.



### Edge-Gated CNNs for Volumetric Semantic Segmentation of Medical Images
- **Arxiv ID**: http://arxiv.org/abs/2002.04207v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04207v1)
- **Published**: 2020-02-11 05:08:21+00:00
- **Updated**: 2020-02-11 05:08:21+00:00
- **Authors**: Ali Hatamizadeh, Demetri Terzopoulos, Andriy Myronenko
- **Comment**: None
- **Journal**: None
- **Summary**: Textures and edges contribute different information to image recognition. Edges and boundaries encode shape information, while textures manifest the appearance of regions. Despite the success of Convolutional Neural Networks (CNNs) in computer vision and medical image analysis applications, predominantly only texture abstractions are learned, which often leads to imprecise boundary delineations. In medical imaging, expert manual segmentation often relies on organ boundaries; for example, to manually segment a liver, a medical practitioner usually identifies edges first and subsequently fills in the segmentation mask. Motivated by these observations, we propose a plug-and-play module, dubbed Edge-Gated CNNs (EG-CNNs), that can be used with existing encoder-decoder architectures to process both edge and texture information. The EG-CNN learns to emphasize the edges in the encoder, to predict crisp boundaries by an auxiliary edge supervision, and to fuse its output with the original CNN output. We evaluate the effectiveness of the EG-CNN with various mainstream CNNs on two publicly available datasets, BraTS 19 and KiTS 19 for brain tumor and kidney semantic segmentation. We demonstrate how the addition of EG-CNN consistently improves segmentation accuracy and generalization performance.



### Hyperspectral Classification Based on 3D Asymmetric Inception Network with Data Fusion Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/2002.04227v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04227v1)
- **Published**: 2020-02-11 06:37:34+00:00
- **Updated**: 2020-02-11 06:37:34+00:00
- **Authors**: Haokui Zhang, Yu Liu, Bei Fang, Ying Li, Lingqiao Liu, Ian Reid
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: Hyperspectral image(HSI) classification has been improved with convolutional neural network(CNN) in very recent years. Being different from the RGB datasets, different HSI datasets are generally captured by various remote sensors and have different spectral configurations. Moreover, each HSI dataset only contains very limited training samples and thus it is prone to overfitting when using deep CNNs. In this paper, we first deliver a 3D asymmetric inception network, AINet, to overcome the overfitting problem. With the emphasis on spectral signatures over spatial contexts of HSI data, AINet can convey and classify the features effectively. In addition, the proposed data fusion transfer learning strategy is beneficial in boosting the classification performance. Extensive experiments show that the proposed approach beat all of the state-of-art methods on several HSI benchmarks, including Pavia University, Indian Pines and Kennedy Space Center(KSC). Code can be found at: https://github.com/UniLauX/AINet.



### Improving the affordability of robustness training for DNNs
- **Arxiv ID**: http://arxiv.org/abs/2002.04237v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04237v2)
- **Published**: 2020-02-11 07:29:45+00:00
- **Updated**: 2020-04-30 04:17:09+00:00
- **Authors**: Sidharth Gupta, Parijat Dube, Ashish Verma
- **Comment**: None
- **Journal**: None
- **Summary**: Projected Gradient Descent (PGD) based adversarial training has become one of the most prominent methods for building robust deep neural network models. However, the computational complexity associated with this approach, due to the maximization of the loss function when finding adversaries, is a longstanding problem and may be prohibitive when using larger and more complex models. In this paper we show that the initial phase of adversarial training is redundant and can be replaced with natural training which significantly improves the computational efficiency. We demonstrate that this efficiency gain can be achieved without any loss in accuracy on natural and adversarial test samples. We support our argument with insights on the nature of the adversaries and their relative strength during the training process. We show that our proposed method can reduce the training time by a factor of up to 2.5 with comparable or better model test accuracy and generalization on various strengths of adversarial attacks.



### AI Online Filters to Real World Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/2002.08242v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2002.08242v1)
- **Published**: 2020-02-11 08:23:14+00:00
- **Updated**: 2020-02-11 08:23:14+00:00
- **Authors**: Hai Xiao, Jin Shang, Mengyuan Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep artificial neural networks, trained with labeled data sets are widely used in numerous vision and robotics applications today. In terms of AI, these are called reflex models, referring to the fact that they do not self-evolve or actively adapt to environmental changes. As demand for intelligent robot control expands to many high level tasks, reinforcement learning and state based models play an increasingly important role. Herein, in computer vision and robotics domain, we study a novel approach to add reinforcement controls onto the image recognition reflex models to attain better overall performance, specifically to a wider environment range beyond what is expected of the task reflex models. Follow a common infrastructure with environment sensing and AI based modeling of self-adaptive agents, we implement multiple types of AI control agents. To the end, we provide comparative results of these agents with baseline, and an insightful analysis of their benefit to improve overall image recognition performance in real world.



### 2.75D: Boosting Learning Efficiency and Capability by Representing 3D Features in 2D
- **Arxiv ID**: http://arxiv.org/abs/2002.04251v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04251v2)
- **Published**: 2020-02-11 08:24:19+00:00
- **Updated**: 2020-11-25 19:44:20+00:00
- **Authors**: Ruisheng Su, Weiyi Xie, Tao Tan
- **Comment**: None
- **Journal**: None
- **Summary**: In medical imaging, 3D convolutional neural networks (CNNs) have shown superior performance to 2D CNN in numerous deep learning tasks with high dimensional input, proving the added value of 3D spatial information in feature representation. However, 3D CNN requires more training samples to converge, and more computational resources and execution time for both training and inference. Meanwhile, applying transfer learning on 3D CNN is challenging due to a lack of publicly available pre-trained 3D networks. To tackle with these issues, we propose a novel 2D strategical representation of volumetric data, namely 2.75D approach. In our method, the spatial information of 3D images was captured in a single 2D view by a spiral-spinning technique. Therefore, our CNN is intrinsically a 2D network, which can fully leverage pre-trained 2D CNNs for downstream vision problems. We evaluated the proposed method on LUNA16 nodule detection challenge, by comparing the proposed 2.75D method with 2D, 2.5D, 3D counterparts in the nodule false positive reduction. Results show that the proposed method outperforms other counterparts when all methods were trained from scratch. Such performance gain is more pronounced when introducing transfer learning or when training data is limited. In addition, our method achieves a substantial reduce in time consumption of training and inference comparing with the 3D method. Our code will be publicly available.



### Hi-Net: Hybrid-fusion Network for Multi-modal MR Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2002.05000v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.05000v1)
- **Published**: 2020-02-11 08:26:42+00:00
- **Updated**: 2020-02-11 08:26:42+00:00
- **Authors**: Tao Zhou, Huazhu Fu, Geng Chen, Jianbing Shen, Ling Shao
- **Comment**: has been accepted by IEEE TMI
- **Journal**: None
- **Summary**: Magnetic resonance imaging (MRI) is a widely used neuroimaging technique that can provide images of different contrasts (i.e., modalities). Fusing this multi-modal data has proven particularly effective for boosting model performance in many tasks. However, due to poor data quality and frequent patient dropout, collecting all modalities for every patient remains a challenge. Medical image synthesis has been proposed as an effective solution to this, where any missing modalities are synthesized from the existing ones. In this paper, we propose a novel Hybrid-fusion Network (Hi-Net) for multi-modal MR image synthesis, which learns a mapping from multi-modal source images (i.e., existing modalities) to target images (i.e., missing modalities). In our Hi-Net, a modality-specific network is utilized to learn representations for each individual modality, and a fusion network is employed to learn the common latent representation of multi-modal data. Then, a multi-modal synthesis network is designed to densely combine the latent representation with hierarchical features from each modality, acting as a generator to synthesize the target images. Moreover, a layer-wise multi-modal fusion strategy is presented to effectively exploit the correlations among multiple modalities, in which a Mixed Fusion Block (MFB) is proposed to adaptively weight different fusion strategies (i.e., element-wise summation, product, and maximization). Extensive experiments demonstrate that the proposed model outperforms other state-of-the-art medical image synthesis methods.



### The Devil is in the Channels: Mutual-Channel Loss for Fine-Grained Image Classification
- **Arxiv ID**: http://arxiv.org/abs/2002.04264v3
- **DOI**: 10.1109/TIP.2020.2973812
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04264v3)
- **Published**: 2020-02-11 09:12:45+00:00
- **Updated**: 2021-08-10 04:23:56+00:00
- **Authors**: Dongliang Chang, Yifeng Ding, Jiyang Xie, Ayan Kumar Bhunia, Xiaoxu Li, Zhanyu Ma, Ming Wu, Jun Guo, Yi-Zhe Song
- **Comment**: TIP2020. Code available at
  https://github.com/dongliangchang/Mutual-Channel-Loss
- **Journal**: None
- **Summary**: Key for solving fine-grained image categorization is finding discriminate and local regions that correspond to subtle visual traits. Great strides have been made, with complex networks designed specifically to learn part-level discriminate feature representations. In this paper, we show it is possible to cultivate subtle details without the need for overly complicated network designs or training mechanisms -- a single loss is all it takes. The main trick lies with how we delve into individual feature channels early on, as opposed to the convention of starting from a consolidated feature map. The proposed loss function, termed as mutual-channel loss (MC-Loss), consists of two channel-specific components: a discriminality component and a diversity component. The discriminality component forces all feature channels belonging to the same class to be discriminative, through a novel channel-wise attention mechanism. The diversity component additionally constraints channels so that they become mutually exclusive on spatial-wise. The end result is therefore a set of feature channels that each reflects different locally discriminative regions for a specific class. The MC-Loss can be trained end-to-end, without the need for any bounding-box/part annotations, and yields highly discriminative regions during inference. Experimental results show our MC-Loss when implemented on top of common base networks can achieve state-of-the-art performance on all four fine-grained categorization datasets (CUB-Birds, FGVC-Aircraft, Flowers-102, and Stanford-Cars). Ablative studies further demonstrate the superiority of MC-Loss when compared with other recently proposed general-purpose losses for visual classification, on two different base networks. Code available at https://github.com/dongliangchang/Mutual-Channel-Loss



### To Share or Not To Share: A Comprehensive Appraisal of Weight-Sharing
- **Arxiv ID**: http://arxiv.org/abs/2002.04289v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04289v2)
- **Published**: 2020-02-11 10:29:31+00:00
- **Updated**: 2020-05-18 09:11:20+00:00
- **Authors**: Aloïs Pourchot, Alexis Ducarouge, Olivier Sigaud
- **Comment**: None
- **Journal**: None
- **Summary**: Weight-sharing (WS) has recently emerged as a paradigm to accelerate the automated search for efficient neural architectures, a process dubbed Neural Architecture Search (NAS). Although very appealing, this framework is not without drawbacks and several works have started to question its capabilities on small hand-crafted benchmarks. In this paper, we take advantage of the \nasbench dataset to challenge the efficiency of WS on a representative search space. By comparing a SOTA WS approach to a plain random search we show that, despite decent correlations between evaluations using weight-sharing and standalone ones, WS is only rarely significantly helpful to NAS. In particular we highlight the impact of the search space itself on the benefits.



### Improved prediction of soil properties with Multi-target Stacked Generalisation on EDXRF spectra
- **Arxiv ID**: http://arxiv.org/abs/2002.04312v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/2002.04312v1)
- **Published**: 2020-02-11 11:05:03+00:00
- **Updated**: 2020-02-11 11:05:03+00:00
- **Authors**: Everton Jose Santana, Felipe Rodrigues dos Santos, Saulo Martiello Mastelini, Fabio Luiz Melquiades, Sylvio Barbon Jr
- **Comment**: 20 pages, 5 figures
- **Journal**: None
- **Summary**: Machine Learning (ML) algorithms have been used for assessing soil quality parameters along with non-destructive methodologies. Among spectroscopic analytical methodologies, energy dispersive X-ray fluorescence (EDXRF) is one of the more quick, environmentally friendly and less expensive when compared to conventional methods. However, some challenges in EDXRF spectral data analysis still demand more efficient methods capable of providing accurate outcomes. Using Multi-target Regression (MTR) methods, multiple parameters can be predicted, and also taking advantage of inter-correlated parameters the overall predictive performance can be improved. In this study, we proposed the Multi-target Stacked Generalisation (MTSG), a novel MTR method relying on learning from different regressors arranged in stacking structure for a boosted outcome. We compared MTSG and 5 MTR methods for predicting 10 parameters of soil fertility. Random Forest and Support Vector Machine (with linear and radial kernels) were used as learning algorithms embedded into each MTR method. Results showed the superiority of MTR methods over the Single-target Regression (the traditional ML method), reducing the predictive error for 5 parameters. Particularly, MTSG obtained the lowest error for phosphorus, total organic carbon and cation exchange capacity. When observing the relative performance of Support Vector Machine with a radial kernel, the prediction of base saturation percentage was improved in 19%. Finally, the proposed method was able to reduce the average error from 0.67 (single-target) to 0.64 analysing all targets, representing a global improvement of 4.48%.



### Symplectic Geometric Methods for Matrix Differential Equations Arising from Inertial Navigation Problems
- **Arxiv ID**: http://arxiv.org/abs/2002.04315v1
- **DOI**: None
- **Categories**: **math.DS**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2002.04315v1)
- **Published**: 2020-02-11 11:08:52+00:00
- **Updated**: 2020-02-11 11:08:52+00:00
- **Authors**: Xin-Long Luo, Geng Sun
- **Comment**: None
- **Journal**: None
- **Summary**: This article explores some geometric and algebraic properties of the dynamical system which is represented by matrix differential equations arising from inertial navigation problems, such as the symplecticity and the orthogonality. Furthermore, it extends the applicable fields of symplectic geometric algorithms from the even dimensional Hamiltonian system to the odd dimensional dynamical system. Finally, some numerical experiments are presented and illustrate the theoretical results of this paper.



### A Machine Learning Framework for Data Ingestion in Document Images
- **Arxiv ID**: http://arxiv.org/abs/2003.00838v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2003.00838v1)
- **Published**: 2020-02-11 12:02:47+00:00
- **Updated**: 2020-02-11 12:02:47+00:00
- **Authors**: Han Fu, Yunyu Bai, Zhuo Li, Jun Shen, Jianling Sun
- **Comment**: None
- **Journal**: None
- **Summary**: Paper documents are widely used as an irreplaceable channel of information in many fields, especially in financial industry, fostering a great amount of demand for systems which can convert document images into structured data representations. In this paper, we present a machine learning framework for data ingestion in document images, which processes the images uploaded by users and return fine-grained data in JSON format. Details of model architectures, design strategies, distinctions with existing solutions and lessons learned during development are elaborated. We conduct abundant experiments on both synthetic and real-world data in State Street. The experimental results indicate the effectiveness and efficiency of our methods.



### Vision-based Fight Detection from Surveillance Cameras
- **Arxiv ID**: http://arxiv.org/abs/2002.04355v1
- **DOI**: 10.1109/IPTA.2019.8936070
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04355v1)
- **Published**: 2020-02-11 12:56:29+00:00
- **Updated**: 2020-02-11 12:56:29+00:00
- **Authors**: Şeymanur Aktı, Gözde Ayşe Tataroğlu, Hazım Kemal Ekenel
- **Comment**: 6 pages, 5 figures, 4 tables, International Conference on Image
  Processing Theory, Tools and Applications, IPTA 2019
- **Journal**: None
- **Summary**: Vision-based action recognition is one of the most challenging research topics of computer vision and pattern recognition. A specific application of it, namely, detecting fights from surveillance cameras in public areas, prisons, etc., is desired to quickly get under control these violent incidents. This paper addresses this research problem and explores LSTM-based approaches to solve it. Moreover, the attention layer is also utilized. Besides, a new dataset is collected, which consists of fight scenes from surveillance camera videos available at YouTube. This dataset is made publicly available. From the extensive experiments conducted on Hockey Fight, Peliculas, and the newly collected fight datasets, it is observed that the proposed approach, which integrates Xception model, Bi-LSTM, and attention, improves the state-of-the-art accuracy for fight scene classification.



### Firearm Detection and Segmentation Using an Ensemble of Semantic Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2003.00805v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T01, I.2.6; I.2.10; J.7
- **Links**: [PDF](http://arxiv.org/pdf/2003.00805v1)
- **Published**: 2020-02-11 13:58:16+00:00
- **Updated**: 2020-02-11 13:58:16+00:00
- **Authors**: Alexander Egiazarov, Vasileios Mavroeidis, Fabio Massimo Zennaro, Kamer Vishi
- **Comment**: 8 pages, 8 figures, 2 tables, 2019 European Intelligence and Security
  Informatics Conference (EISIC)
- **Journal**: None
- **Summary**: In recent years we have seen an upsurge in terror attacks around the world. Such attacks usually happen in public places with large crowds to cause the most damage possible and get the most attention. Even though surveillance cameras are assumed to be a powerful tool, their effect in preventing crime is far from clear due to either limitation in the ability of humans to vigilantly monitor video surveillance or for the simple reason that they are operating passively. In this paper, we present a weapon detection system based on an ensemble of semantic Convolutional Neural Networks that decomposes the problem of detecting and locating a weapon into a set of smaller problems concerned with the individual component parts of a weapon. This approach has computational and practical advantages: a set of simpler neural networks dedicated to specific tasks requires less computational resources and can be trained in parallel; the overall output of the system given by the aggregation of the outputs of individual networks can be tuned by a user to trade-off false positives and false negatives; finally, according to ensemble theory, the output of the overall system will be robust and reliable even in the presence of weak individual models. We evaluated our system running simulations aimed at assessing the accuracy of individual networks and the whole system. The results on synthetic data and real-world data are promising, and they suggest that our approach may have advantages compared to the monolithic approach based on a single deep convolutional neural network.



### Saliency Enhancement using Gradient Domain Edges Merging
- **Arxiv ID**: http://arxiv.org/abs/2002.04380v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04380v1)
- **Published**: 2020-02-11 14:04:56+00:00
- **Updated**: 2020-02-11 14:04:56+00:00
- **Authors**: Dominique Beaini, Sofiane Achiche, Alexandre Duperre, Maxime Raison
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, there has been a rapid progress in solving the binary problems in computer vision, such as edge detection which finds the boundaries of an image and salient object detection which finds the important object in an image. This progress happened thanks to the rise of deep-learning and convolutional neural networks (CNN) which allow to extract complex and abstract features. However, edge detection and saliency are still two different fields and do not interact together, although it is intuitive for a human to detect salient objects based on its boundaries. Those features are not well merged in a CNN because edges and surfaces do not intersect since one feature represents a region while the other represents boundaries between different regions. In the current work, the main objective is to develop a method to merge the edges with the saliency maps to improve the performance of the saliency. Hence, we developed the gradient-domain merging (GDM) which can be used to quickly combine the image-domain information of salient object detection with the gradient-domain information of the edge detection. This leads to our proposed saliency enhancement using edges (SEE) with an average improvement of the F-measure of at least 3.4 times higher on the DUT-OMRON dataset and 6.6 times higher on the ECSSD dataset, when compared to competing algorithm such as denseCRF and BGOF. The SEE algorithm is split into 2 parts, SEE-Pre for preprocessing and SEE-Post pour postprocessing.



### Toward Improving the Evaluation of Visual Attention Models: a Crowdsourcing Approach
- **Arxiv ID**: http://arxiv.org/abs/2002.04407v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.04407v2)
- **Published**: 2020-02-11 14:27:47+00:00
- **Updated**: 2020-05-07 13:34:36+00:00
- **Authors**: Dario Zanca, Stefano Melacci, Marco Gori
- **Comment**: None
- **Journal**: None
- **Summary**: Human visual attention is a complex phenomenon. A computational modeling of this phenomenon must take into account where people look in order to evaluate which are the salient locations (spatial distribution of the fixations), when they look in those locations to understand the temporal development of the exploration (temporal order of the fixations), and how they move from one location to another with respect to the dynamics of the scene and the mechanics of the eyes (dynamics). State-of-the-art models focus on learning saliency maps from human data, a process that only takes into account the spatial component of the phenomenon and ignore its temporal and dynamical counterparts. In this work we focus on the evaluation methodology of models of human visual attention. We underline the limits of the current metrics for saliency prediction and scanpath similarity, and we introduce a statistical measure for the evaluation of the dynamics of the simulated eye movements. While deep learning models achieve astonishing performance in saliency prediction, our analysis shows their limitations in capturing the dynamics of the process. We find that unsupervised gravitational models, despite of their simplicity, outperform all competitors. Finally, exploiting a crowd-sourcing platform, we present a study aimed at evaluating how strongly the scanpaths generated with the unsupervised gravitational models appear plausible to naive and expert human observers.



### Background Matting
- **Arxiv ID**: http://arxiv.org/abs/2002.04433v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04433v1)
- **Published**: 2020-02-11 14:46:57+00:00
- **Updated**: 2020-02-11 14:46:57+00:00
- **Authors**: Hossein Javidnia, François Pitié
- **Comment**: None
- **Journal**: None
- **Summary**: The current state of the art alpha matting methods mainly rely on the trimap as the secondary and only guidance to estimate alpha. This paper investigates the effects of utilising the background information as well as trimap in the process of alpha calculation. To achieve this goal, a state of the art method, AlphaGan is adopted and modified to process the background information as an extra input channel. Extensive experiments are performed to analyse the effect of the background information in image and video matting such as training with mildly and heavily distorted backgrounds. Based on the quantitative evaluations performed on Adobe Composition-1k dataset, the proposed pipeline significantly outperforms the state of the art methods using AlphaMatting benchmark metrics.



### Folding-based compression of point cloud attributes
- **Arxiv ID**: http://arxiv.org/abs/2002.04439v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.GR, cs.LG, eess.SP, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04439v3)
- **Published**: 2020-02-11 14:55:58+00:00
- **Updated**: 2020-06-22 07:17:57+00:00
- **Authors**: Maurice Quach, Giuseppe Valenzise, Frederic Dufaux
- **Comment**: Published in ICIP 2020. The source code can be found at
  https://github.com/mauriceqch/pcc_attr_folding
- **Journal**: None
- **Summary**: Existing techniques to compress point cloud attributes leverage either geometric or video-based compression tools. We explore a radically different approach inspired by recent advances in point cloud representation learning. Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we fold a 2D grid onto a point cloud and we map attributes from the point cloud onto the folded 2D grid using a novel optimized mapping method. This mapping results in an image, which opens a way to apply existing image processing techniques on point cloud attributes. However, as this mapping process is lossy in nature, we propose several strategies to refine it so that attributes can be mapped to the 2D grid with minimal distortion. Moreover, this approach can be flexibly applied to point cloud patches in order to better adapt to local geometric complexity. In this work, we consider point cloud attribute compression; thus, we compress this image with a conventional 2D image codec. Our preliminary results show that the proposed folding-based coding scheme can already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC) codec.



### On Parameter Tuning in Meta-learning for Computer Vision
- **Arxiv ID**: http://arxiv.org/abs/2003.00837v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2003.00837v1)
- **Published**: 2020-02-11 15:07:30+00:00
- **Updated**: 2020-02-11 15:07:30+00:00
- **Authors**: Farid Ghareh Mohammadi, M. Hadi Amini, Hamid R. Arabnia
- **Comment**: 6 pages, 2 algorithms, 3 figures
- **Journal**: None
- **Summary**: Learning to learn plays a pivotal role in meta-learning (MTL) to obtain an optimal learning model. In this paper, we investigate mage recognition for unseen categories of a given dataset with limited training information. We deploy a zero-shot learning (ZSL) algorithm to achieve this goal. We also explore the effect of parameter tuning on performance of semantic auto-encoder (SAE). We further address the parameter tuning problem for meta-learning, especially focusing on zero-shot learning. By combining different embedded parameters, we improved the accuracy of tuned-SAE. Advantages and disadvantages of parameter tuning and its application in image classification are also explored.



### HRINet: Alternative Supervision Network for High-resolution CT image Interpolation
- **Arxiv ID**: http://arxiv.org/abs/2002.04455v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04455v2)
- **Published**: 2020-02-11 15:09:42+00:00
- **Updated**: 2020-06-07 19:13:08+00:00
- **Authors**: Jiawei Li, Jae Chul Koh, Won-Sook Lee
- **Comment**: None
- **Journal**: None
- **Summary**: Image interpolation in medical area is of high importance as most 3D biomedical volume images are sampled where the distance between consecutive slices significantly greater than the in-plane pixel size due to radiation dose or scanning time. Image interpolation creates a number of new slices between known slices in order to obtain an isotropic volume image. The results can be used for the higher quality of 3D reconstruction and visualization of human body structures. Semantic interpolation on the manifold has been proved to be very useful for smoothing image interpolation. Nevertheless, all previous methods focused on low-resolution image interpolation, and most of them work poorly on high-resolution image. We propose a novel network, High Resolution Interpolation Network (HRINet), aiming at producing high-resolution CT image interpolations. We combine the idea of ACAI and GANs, and propose a novel idea of alternative supervision method by applying supervised and unsupervised training alternatively to raise the accuracy of human organ structures in CT while keeping high quality. We compare an MSE based and a perceptual based loss optimizing methods for high quality interpolation, and show the tradeoff between the structural correctness and sharpness. Our experiments show the great improvement on 256 2 and 5122 images quantitatively and qualitatively.



### Self-Supervised Object-in-Gripper Segmentation from Robotic Motions
- **Arxiv ID**: http://arxiv.org/abs/2002.04487v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2002.04487v3)
- **Published**: 2020-02-11 15:44:46+00:00
- **Updated**: 2020-11-06 10:31:16+00:00
- **Authors**: Wout Boerdijk, Martin Sundermeyer, Maximilian Durner, Rudolph Triebel
- **Comment**: 15 pages, 11 figures. Video:
  https://www.youtube.com/watch?v=srEwuuIIgzI
- **Journal**: None
- **Summary**: Accurate object segmentation is a crucial task in the context of robotic manipulation. However, creating sufficient annotated training data for neural networks is particularly time consuming and often requires manual labeling. To this end, we propose a simple, yet robust solution for learning to segment unknown objects grasped by a robot. Specifically, we exploit motion and temporal cues in RGB video sequences. Using optical flow estimation we first learn to predict segmentation masks of our given manipulator. Then, these annotations are used in combination with motion cues to automatically distinguish between background, manipulator and unknown, grasped object. In contrast to existing systems our approach is fully self-supervised and independent of precise camera calibration, 3D models or potentially imperfect depth data. We perform a thorough comparison with alternative baselines and approaches from literature. The object masks and views are shown to be suitable training data for segmentation networks that generalize to novel environments and also allow for watertight 3D reconstruction.



### A Novel and Efficient Tumor Detection Framework for Pancreatic Cancer via CT Images
- **Arxiv ID**: http://arxiv.org/abs/2002.04493v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04493v1)
- **Published**: 2020-02-11 15:48:22+00:00
- **Updated**: 2020-02-11 15:48:22+00:00
- **Authors**: Zhengdong Zhang, Shuai Li, Ziyang Wang, Yun Lu
- **Comment**: 5 pages, 5 figures
- **Journal**: None
- **Summary**: As Deep Convolutional Neural Networks (DCNNs) have shown robust performance and results in medical image analysis, a number of deep-learning-based tumor detection methods were developed in recent years. Nowadays, the automatic detection of pancreatic tumors using contrast-enhanced Computed Tomography (CT) is widely applied for the diagnosis and staging of pancreatic cancer. Traditional hand-crafted methods only extract low-level features. Normal convolutional neural networks, however, fail to make full use of effective context information, which causes inferior detection results. In this paper, a novel and efficient pancreatic tumor detection framework aiming at fully exploiting the context information at multiple scales is designed. More specifically, the contribution of the proposed method mainly consists of three components: Augmented Feature Pyramid networks, Self-adaptive Feature Fusion and a Dependencies Computation (DC) Module. A bottom-up path augmentation to fully extract and propagate low-level accurate localization information is established firstly. Then, the Self-adaptive Feature Fusion can encode much richer context information at multiple scales based on the proposed regions. Finally, the DC Module is specifically designed to capture the interaction information between proposals and surrounding tissues. Experimental results achieve competitive performance in detection with the AUC of 0.9455, which outperforms other state-of-the-art methods to our best of knowledge, demonstrating the proposed framework can detect the tumor of pancreatic cancer efficiently and accurately.



### Artificial Intelligence Assistance Significantly Improves Gleason Grading of Prostate Biopsies by Pathologists
- **Arxiv ID**: http://arxiv.org/abs/2002.04500v1
- **DOI**: 10.1038/s41379-020-0640-y
- **Categories**: **eess.IV**, cs.CV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/2002.04500v1)
- **Published**: 2020-02-11 16:00:31+00:00
- **Updated**: 2020-02-11 16:00:31+00:00
- **Authors**: Wouter Bulten, Maschenka Balkenhol, Jean-Joël Awoumou Belinga, Américo Brilhante, Aslı Çakır, Xavier Farré, Katerina Geronatsiou, Vincent Molinié, Guilherme Pereira, Paromita Roy, Günter Saile, Paulo Salles, Ewout Schaafsma, Joëlle Tschui, Anne-Marie Vos, Hester van Boven, Robert Vink, Jeroen van der Laak, Christina Hulsbergen-van de Kaa, Geert Litjens
- **Comment**: 21 pages, 5 figures
- **Journal**: Modern Pathology, Available online 5 August 2020
- **Summary**: While the Gleason score is the most important prognostic marker for prostate cancer patients, it suffers from significant observer variability. Artificial Intelligence (AI) systems, based on deep learning, have proven to achieve pathologist-level performance at Gleason grading. However, the performance of such systems can degrade in the presence of artifacts, foreign tissue, or other anomalies. Pathologists integrating their expertise with feedback from an AI system could result in a synergy that outperforms both the individual pathologist and the system. Despite the hype around AI assistance, existing literature on this topic within the pathology domain is limited. We investigated the value of AI assistance for grading prostate biopsies. A panel of fourteen observers graded 160 biopsies with and without AI assistance. Using AI, the agreement of the panel with an expert reference standard significantly increased (quadratically weighted Cohen's kappa, 0.799 vs 0.872; p=0.018). Our results show the added value of AI systems for Gleason grading, but more importantly, show the benefits of pathologist-AI synergy.



### A Survey On 3D Inner Structure Prediction from its Outer Shape
- **Arxiv ID**: http://arxiv.org/abs/2002.04571v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2002.04571v1)
- **Published**: 2020-02-11 17:56:38+00:00
- **Updated**: 2020-02-11 17:56:38+00:00
- **Authors**: Mohamed Mejri, Antoine Richard, Cédric Pradalier
- **Comment**: None
- **Journal**: None
- **Summary**: The analysis of the internal structure of trees is highly important for both forest experts, biological scientists, and the wood industry. Traditionally, CT-scanners are considered as the most efficient way to get an accurate inner representation of the tree. However, this method requires an important investment and reduces the cost-effectiveness of this operation. Our goal is to design neural-network-based methods to predict the internal density of the tree from its external bark shape. This paper compares different image-to-image(2D), volume-to-volume(3D) and Convolutional Long Short Term Memory based neural network architectures in the context of the prediction of the defect distribution inside trees from their external bark shape. Those models are trained on a synthetic dataset of 1800 CT-scanned look-like volumetric structures of the internal density of the trees and their corresponding external surface.



### Fundamental Tradeoffs between Invariance and Sensitivity to Adversarial Perturbations
- **Arxiv ID**: http://arxiv.org/abs/2002.04599v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04599v2)
- **Published**: 2020-02-11 18:50:23+00:00
- **Updated**: 2020-08-04 16:53:43+00:00
- **Authors**: Florian Tramèr, Jens Behrmann, Nicholas Carlini, Nicolas Papernot, Jörn-Henrik Jacobsen
- **Comment**: ICML 2020 (Supersedes the workshop paper "Exploiting Excessive
  Invariance caused by Norm-Bounded Adversarial Robustness", arXiv:1903.10484)
- **Journal**: None
- **Summary**: Adversarial examples are malicious inputs crafted to induce misclassification. Commonly studied sensitivity-based adversarial examples introduce semantically-small changes to an input that result in a different model prediction. This paper studies a complementary failure mode, invariance-based adversarial examples, that introduce minimal semantic changes that modify an input's true label yet preserve the model's prediction. We demonstrate fundamental tradeoffs between these two types of adversarial examples.   We show that defenses against sensitivity-based attacks actively harm a model's accuracy on invariance-based attacks, and that new approaches are needed to resist both attack types. In particular, we break state-of-the-art adversarially-trained and certifiably-robust models by generating small perturbations that the models are (provably) robust to, yet that change an input's class according to human labelers. Finally, we formally show that the existence of excessively invariant classifiers arises from the presence of overly-robust predictive features in standard datasets.



### Building Footprint Generation by IntegratingConvolution Neural Network with Feature PairwiseConditional Random Field (FPCRF)
- **Arxiv ID**: http://arxiv.org/abs/2002.04600v1
- **DOI**: 10.1109/TGRS.2020.2973720
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04600v1)
- **Published**: 2020-02-11 18:51:19+00:00
- **Updated**: 2020-02-11 18:51:19+00:00
- **Authors**: Qingyu Li, Yilei Shi, Xin Huang, Xiao Xiang Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Building footprint maps are vital to many remote sensing applications, such as 3D building modeling, urban planning, and disaster management. Due to the complexity of buildings, the accurate and reliable generation of the building footprint from remote sensing imagery is still a challenging task. In this work, an end-to-end building footprint generation approach that integrates convolution neural network (CNN) and graph model is proposed. CNN serves as the feature extractor, while the graph model can take spatial correlation into consideration. Moreover, we propose to implement the feature pairwise conditional random field (FPCRF) as a graph model to preserve sharp boundaries and fine-grained segmentation. Experiments are conducted on four different datasets: (1) Planetscope satellite imagery of the cities of Munich, Paris, Rome, and Zurich; (2) ISPRS benchmark data from the city of Potsdam, (3) Dstl Kaggle dataset; and (4) Inria Aerial Image Labeling data of Austin, Chicago, Kitsap County, Western Tyrol, and Vienna. It is found that the proposed end-to-end building footprint generation framework with the FPCRF as the graph model can further improve the accuracy of building footprint generation by using only CNN, which is the current state-of-the-art.



### Finding novelty with uncertainty
- **Arxiv ID**: http://arxiv.org/abs/2002.04626v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.04626v1)
- **Published**: 2020-02-11 19:00:22+00:00
- **Updated**: 2020-02-11 19:00:22+00:00
- **Authors**: Jacob C. Reinhold, Yufan He, Shizhong Han, Yunqiang Chen, Dashan Gao, Junghoon Lee, Jerry L. Prince, Aaron Carass
- **Comment**: SPIE Medical Imaging 2020
- **Journal**: None
- **Summary**: Medical images are often used to detect and characterize pathology and disease; however, automatically identifying and segmenting pathology in medical images is challenging because the appearance of pathology across diseases varies widely. To address this challenge, we propose a Bayesian deep learning method that learns to translate healthy computed tomography images to magnetic resonance images and simultaneously calculates voxel-wise uncertainty. Since high uncertainty occurs in pathological regions of the image, this uncertainty can be used for unsupervised anomaly segmentation. We show encouraging experimental results on an unsupervised anomaly segmentation task by combining two types of uncertainty into a novel quantity we call scibilic uncertainty.



### Neuroevolution of Neural Network Architectures Using CoDeepNEAT and Keras
- **Arxiv ID**: http://arxiv.org/abs/2002.04634v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, 68T20, 68T05, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2002.04634v1)
- **Published**: 2020-02-11 19:03:34+00:00
- **Updated**: 2020-02-11 19:03:34+00:00
- **Authors**: Jonas da Silveira Bohrer, Bruno Iochins Grisci, Marcio Dorn
- **Comment**: The original work was presented by Jonas da Silveira Bohrer in
  partial fulfillment of the requirements for the degree of Bachelor in
  Computer Engineering at the Institute of Informatics of the Federal
  University of Rio Grande do Sul (UFRGS), Brazil, with Marcio Dorn as advisor
  and Bruno Iochins Grisci as co-advisor. The original text is available at
  Lume: https://lume.ufrgs.br/
- **Journal**: None
- **Summary**: Machine learning is a huge field of study in computer science and statistics dedicated to the execution of computational tasks through algorithms that do not require explicit instructions but instead rely on learning patterns from data samples to automate inferences. A large portion of the work involved in a machine learning project is to define the best type of algorithm to solve a given problem. Neural networks - especially deep neural networks - are the predominant type of solution in the field. However, the networks themselves can produce very different results according to the architectural choices made for them. Finding the optimal network topology and configurations for a given problem is a challenge that requires domain knowledge and testing efforts due to a large number of parameters that need to be considered. The purpose of this work is to propose an adapted implementation of a well-established evolutionary technique from the neuroevolution field that manages to automate the tasks of topology and hyperparameter selection. It uses a popular and accessible machine learning framework - Keras - as the back-end, presenting results and proposed changes concerning the original algorithm. The implementation is available at GitHub (https://github.com/sbcblab/Keras-CoDeepNEAT) with documentation and examples to reproduce the experiments performed for this work.



### Validating uncertainty in medical image translation
- **Arxiv ID**: http://arxiv.org/abs/2002.04639v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.04639v1)
- **Published**: 2020-02-11 19:06:54+00:00
- **Updated**: 2020-02-11 19:06:54+00:00
- **Authors**: Jacob C. Reinhold, Yufan He, Shizhong Han, Yunqiang Chen, Dashan Gao, Junghoon Lee, Jerry L. Prince, Aaron Carass
- **Comment**: IEEE ISBI 2020
- **Journal**: None
- **Summary**: Medical images are increasingly used as input to deep neural networks to produce quantitative values that aid researchers and clinicians. However, standard deep neural networks do not provide a reliable measure of uncertainty in those quantitative values. Recent work has shown that using dropout during training and testing can provide estimates of uncertainty. In this work, we investigate using dropout to estimate epistemic and aleatoric uncertainty in a CT-to-MR image translation task. We show that both types of uncertainty are captured, as defined, providing confidence in the output uncertainty estimates.



### A Non-Intrusive Correction Algorithm for Classification Problems with Corrupted Data
- **Arxiv ID**: http://arxiv.org/abs/2002.04658v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04658v1)
- **Published**: 2020-02-11 20:07:05+00:00
- **Updated**: 2020-02-11 20:07:05+00:00
- **Authors**: Jun Hou, Tong Qin, Kailiang Wu, Dongbin Xiu
- **Comment**: None
- **Journal**: None
- **Summary**: A novel correction algorithm is proposed for multi-class classification problems with corrupted training data. The algorithm is non-intrusive, in the sense that it post-processes a trained classification model by adding a correction procedure to the model prediction. The correction procedure can be coupled with any approximators, such as logistic regression, neural networks of various architectures, etc. When training dataset is sufficiently large, we prove that the corrected models deliver correct classification results as if there is no corruption in the training data. For datasets of finite size, the corrected models produce significantly better recovery results, compared to the models without the correction algorithm. All of the theoretical findings in the paper are verified by our numerical examples.



### Object Detection as a Positive-Unlabeled Problem
- **Arxiv ID**: http://arxiv.org/abs/2002.04672v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04672v2)
- **Published**: 2020-02-11 20:49:34+00:00
- **Updated**: 2020-11-01 18:25:47+00:00
- **Authors**: Yuewei Yang, Kevin J Liang, Lawrence Carin
- **Comment**: Published as a conference paper in the British Machine Vision
  Conference (BMVC) 2020
- **Journal**: None
- **Summary**: As with other deep learning methods, label quality is important for learning modern convolutional object detectors. However, the potentially large number and wide diversity of object instances that can be found in complex image scenes makes constituting complete annotations a challenging task; objects missing annotations can be observed in a variety of popular object detection datasets. These missing annotations can be problematic, as the standard cross-entropy loss employed to train object detection models treats classification as a positive-negative (PN) problem: unlabeled regions are implicitly assumed to be background. As such, any object missing a bounding box results in a confusing learning signal, the effects of which we observe empirically. To remedy this, we propose treating object detection as a positive-unlabeled (PU) problem, which removes the assumption that unlabeled regions must be negative. We demonstrate that our proposed PU classification loss outperforms the standard PN loss on PASCAL VOC and MS COCO across a range of label missingness, as well as on Visual Genome and DeepLesion with full labels.



### Learning spatio-temporal representations with temporal squeeze pooling
- **Arxiv ID**: http://arxiv.org/abs/2002.04685v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2002.04685v2)
- **Published**: 2020-02-11 21:13:12+00:00
- **Updated**: 2022-01-13 00:47:40+00:00
- **Authors**: Guoxi Huang, Adrian G. Bors
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new video representation learning method, named Temporal Squeeze (TS) pooling, which can extract the essential movement information from a long sequence of video frames and map it into a set of few images, named Squeezed Images. By embedding the Temporal Squeeze pooling as a layer into off-the-shelf Convolution Neural Networks (CNN), we design a new video classification model, named Temporal Squeeze Network (TeSNet). The resulting Squeezed Images contain the essential movement information from the video frames, corresponding to the optimization of the video classification task. We evaluate our architecture on two video classification benchmarks, and the results achieved are compared to the state-of-the-art.



### fastai: A Layered API for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2002.04688v2
- **DOI**: 10.3390/info11020108
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2002.04688v2)
- **Published**: 2020-02-11 21:16:48+00:00
- **Updated**: 2020-02-16 18:17:51+00:00
- **Authors**: Jeremy Howard, Sylvain Gugger
- **Comment**: None
- **Journal**: Information 2020, 11(2), 108
- **Summary**: fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes: a new type dispatch system for Python along with a semantic type hierarchy for tensors; a GPU-optimized computer vision library which can be extended in pure Python; an optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 4-5 lines of code; a novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training; a new data block API; and much more. We have used this library to successfully create a complete deep learning course, which we were able to write more quickly than using previous approaches, and the code was more clear. The library is already in wide use in research, industry, and teaching. NB: This paper covers fastai v2, which is currently in pre-release at http://dev.fast.ai/



### Improving Place Recognition Using Dynamic Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2002.04698v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO, eess.IV, I.4.9; I.2; J.7
- **Links**: [PDF](http://arxiv.org/pdf/2002.04698v2)
- **Published**: 2020-02-11 21:39:24+00:00
- **Updated**: 2020-06-12 04:58:38+00:00
- **Authors**: Juan Pablo Munoz, Scott Dexter
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel approach to place recognition well-suited to environments with many dynamic objects--objects that may or may not be present in an agent's subsequent visits. By incorporating an object-detecting preprocessing step, our approach yields high-quality place representations that incorporate object information. Not only does this result in significantly improved place recognition in dynamic environments, it also significantly reduces memory/storage requirements, which may increase the effectiveness of mobile agents with limited resources.



### A Single RGB Camera Based Gait Analysis with a Mobile Tele-Robot for Healthcare
- **Arxiv ID**: http://arxiv.org/abs/2002.04700v4
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.HC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2002.04700v4)
- **Published**: 2020-02-11 21:42:22+00:00
- **Updated**: 2020-03-15 03:27:52+00:00
- **Authors**: Ziyang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: With the increasing awareness of high-quality life, there is a growing need for health monitoring devices running robust algorithms in home environment. Health monitoring technologies enable real-time analysis of users' health status, offering long-term healthcare support and reducing hospitalization time. The purpose of this work is twofold, the software focuses on the analysis of gait, which is widely adopted for joint correction and assessing any lower limb or spinal problem. On the hardware side, we design a novel marker-less gait analysis device using a low-cost RGB camera mounted on a mobile tele-robot. As gait analysis with a single camera is much more challenging compared to previous works utilizing multi-cameras, a RGB-D camera or wearable sensors, we propose using vision-based human pose estimation approaches. More specifically, based on the output of two state-of-the-art human pose estimation models (Openpose and VNect), we devise measurements for four bespoke gait parameters: inversion/eversion, dorsiflexion/plantarflexion, ankle and foot progression angles. We thereby classify walking patterns into normal, supination, pronation and limp. We also illustrate how to run the purposed machine learning models in low-resource environments such as a single entry-level CPU. Experiments show that our single RGB camera method achieves competitive performance compared to state-of-the-art methods based on depth cameras or multi-camera motion capture system, at smaller hardware costs.



### Marine life through You Only Look Once's perspective
- **Arxiv ID**: http://arxiv.org/abs/2003.00836v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2003.00836v1)
- **Published**: 2020-02-11 22:47:45+00:00
- **Updated**: 2020-02-11 22:47:45+00:00
- **Authors**: Herman Stavelin, Adil Rasheed, Omer San, Arne Johan Hestnes
- **Comment**: None
- **Journal**: None
- **Summary**: With the rise of focus on man made changes to our planet and wildlife therein, more and more emphasis is put on sustainable and responsible gathering of resources. In an effort to preserve maritime wildlife the Norwegian government has decided that it is necessary to create an overview over the presence and abundance of various species of wildlife in the Norwegian fjords and oceans. In this paper we apply and analyze an object detection scheme that detects fish in camera images. The data is sampled from a submerged data station at Fulehuk in Norway. We implement You Only Look Once (YOLO) version 3 and create a dataset consisting of 99,961 images with a mAP of $\sim 0.88$. We also investigate intermediate results within YOLO, gaining insight into how it performs object detection.



