# Arxiv Papers in cs.CV on 2020-06-18
### UV-Net: Learning from Boundary Representations
- **Arxiv ID**: http://arxiv.org/abs/2006.10211v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T07, 68T10, I.5.1; I.3.5
- **Links**: [PDF](http://arxiv.org/pdf/2006.10211v2)
- **Published**: 2020-06-18 00:12:52+00:00
- **Updated**: 2021-04-26 03:27:44+00:00
- **Authors**: Pradeep Kumar Jayaraman, Aditya Sanghi, Joseph G. Lambourne, Karl D. D. Willis, Thomas Davies, Hooman Shayani, Nigel Morris
- **Comment**: CVPR 2021
- **Journal**: None
- **Summary**: We introduce UV-Net, a novel neural network architecture and representation designed to operate directly on Boundary representation (B-rep) data from 3D CAD models. The B-rep format is widely used in the design, simulation and manufacturing industries to enable sophisticated and precise CAD modeling operations. However, B-rep data presents some unique challenges when used with modern machine learning due to the complexity of the data structure and its support for both continuous non-Euclidean geometric entities and discrete topological entities. In this paper, we propose a unified representation for B-rep data that exploits the U and V parameter domain of curves and surfaces to model geometry, and an adjacency graph to explicitly model topology. This leads to a unique and efficient network architecture, UV-Net, that couples image and graph convolutional neural networks in a compute and memory-efficient manner. To aid in future research we present a synthetic labelled B-rep dataset, SolidLetters, derived from human designed fonts with variations in both geometry and topology. Finally we demonstrate that UV-Net can generalize to supervised and unsupervised tasks on five datasets, while outperforming alternate 3D shape representations such as point clouds, voxels, and meshes.



### MediaPipe Hands: On-device Real-time Hand Tracking
- **Arxiv ID**: http://arxiv.org/abs/2006.10214v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10214v1)
- **Published**: 2020-06-18 00:19:13+00:00
- **Updated**: 2020-06-18 00:19:13+00:00
- **Authors**: Fan Zhang, Valentin Bazarevsky, Andrey Vakunov, Andrei Tkachenka, George Sung, Chuo-Ling Chang, Matthias Grundmann
- **Comment**: 5 pages, 7 figures; CVPR Workshop on Computer Vision for Augmented
  and Virtual Reality, Seattle, WA, USA, 2020
- **Journal**: None
- **Summary**: We present a real-time on-device hand tracking pipeline that predicts hand skeleton from single RGB camera for AR/VR applications. The pipeline consists of two models: 1) a palm detector, 2) a hand landmark model. It's implemented via MediaPipe, a framework for building cross-platform ML solutions. The proposed model and pipeline architecture demonstrates real-time inference speed on mobile GPUs and high prediction quality. MediaPipe Hands is open sourced at https://mediapipe.dev.



### Generating Fundus Fluorescence Angiography Images from Structure Fundus Images Using Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2006.10216v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10216v1)
- **Published**: 2020-06-18 00:27:20+00:00
- **Updated**: 2020-06-18 00:27:20+00:00
- **Authors**: Wanyue Li, Wen Kong, Yiwei Chen, Jing Wang, Yi He, Guohua Shi, Guohua Deng
- **Comment**: 16 pages, 6 figures, accepted by Medical Imaging on Deep Learning
- **Journal**: None
- **Summary**: Fluorescein angiography can provide a map of retinal vascular structure and function, which is commonly used in ophthalmology diagnosis, however, this imaging modality may pose risks of harm to the patients. To help physicians reduce the potential risks of diagnosis, an image translation method is adopted. In this work, we proposed a conditional generative adversarial network(GAN) - based method to directly learn the mapping relationship between structure fundus images and fundus fluorescence angiography images. Moreover, local saliency maps, which define each pixel's importance, are used to define a novel saliency loss in the GAN cost function. This facilitates more accurate learning of small-vessel and fluorescein leakage features.



### Sequential Graph Convolutional Network for Active Learning
- **Arxiv ID**: http://arxiv.org/abs/2006.10219v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10219v3)
- **Published**: 2020-06-18 00:55:10+00:00
- **Updated**: 2021-04-01 16:18:44+00:00
- **Authors**: Razvan Caramalau, Binod Bhattarai, Tae-Kyun Kim
- **Comment**: Accepted as Poster at CVPR 2021
- **Journal**: None
- **Summary**: We propose a novel pool-based Active Learning framework constructed on a sequential Graph Convolution Network (GCN). Each image's feature from a pool of data represents a node in the graph and the edges encode their similarities. With a small number of randomly sampled images as seed labelled examples, we learn the parameters of the graph to distinguish labelled vs unlabelled nodes by minimising the binary cross-entropy loss. GCN performs message-passing operations between the nodes, and hence, induces similar representations of the strongly associated nodes. We exploit these characteristics of GCN to select the unlabelled examples which are sufficiently different from labelled ones. To this end, we utilise the graph node embeddings and their confidence scores and adapt sampling techniques such as CoreSet and uncertainty-based methods to query the nodes. We flip the label of newly queried nodes from unlabelled to labelled, re-train the learner to optimise the downstream task and the graph to minimise its modified objective. We continue this process within a fixed budget. We evaluate our method on 6 different benchmarks:4 real image classification, 1 depth-based hand pose estimation and 1 synthetic RGB image classification datasets. Our method outperforms several competitive baselines such as VAAL, Learning Loss, CoreSet and attains the new state-of-the-art performance on multiple applications The implementations can be found here: https://github.com/razvancaramalau/Sequential-GCN-for-Active-Learning



### Progressively Unfreezing Perceptual GAN
- **Arxiv ID**: http://arxiv.org/abs/2006.10250v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10250v1)
- **Published**: 2020-06-18 03:12:41+00:00
- **Updated**: 2020-06-18 03:12:41+00:00
- **Authors**: Jinxuan Sun, Yang Chen, Junyu Dong, Guoqiang Zhong
- **Comment**: None
- **Journal**: None
- **Summary**: Generative adversarial networks (GANs) are widely used in image generation tasks, yet the generated images are usually lack of texture details. In this paper, we propose a general framework, called Progressively Unfreezing Perceptual GAN (PUPGAN), which can generate images with fine texture details. Particularly, we propose an adaptive perceptual discriminator with a pre-trained perceptual feature extractor, which can efficiently measure the discrepancy between multi-level features of the generated and real images. In addition, we propose a progressively unfreezing scheme for the adaptive perceptual discriminator, which ensures a smooth transfer process from a large scale classification task to a specified image generation task. The qualitative and quantitative experiments with comparison to the classical baselines on three image generation tasks, i.e. single image super-resolution, paired image-to-image translation and unpaired image-to-image translation demonstrate the superiority of PUPGAN over the compared approaches.



### Video Moment Localization using Object Evidence and Reverse Captioning
- **Arxiv ID**: http://arxiv.org/abs/2006.10260v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2006.10260v1)
- **Published**: 2020-06-18 03:45:49+00:00
- **Updated**: 2020-06-18 03:45:49+00:00
- **Authors**: Madhawa Vidanapathirana, Supriya Pandhre, Sonia Raychaudhuri, Anjali Khurana
- **Comment**: 7 pages. 6 figures. For source code, refer
  https://github.com/madhawav/MML
- **Journal**: None
- **Summary**: We address the problem of language-based temporal localization of moments in untrimmed videos. Compared to temporal localization with fixed categories, this problem is more challenging as the language-based queries have no predefined activity classes and may also contain complex descriptions. Current state-of-the-art model MAC addresses it by mining activity concepts from both video and language modalities. This method encodes the semantic activity concepts from the verb/object pair in a language query and leverages visual activity concepts from video activity classification prediction scores. We propose "Multi-faceted VideoMoment Localizer" (MML), an extension of MAC model by the introduction of visual object evidence via object segmentation masks and video understanding features via video captioning. Furthermore, we improve language modelling in sentence embedding. We experimented on Charades-STA dataset and identified that MML outperforms MAC baseline by 4.93% and 1.70% on R@1 and R@5metrics respectively. Our code and pre-trained model are publicly available at https://github.com/madhawav/MML.



### Joint Contrastive Learning for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2006.10297v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10297v1)
- **Published**: 2020-06-18 06:25:34+00:00
- **Updated**: 2020-06-18 06:25:34+00:00
- **Authors**: Changhwa Park, Jonghyun Lee, Jaeyoon Yoo, Minhoe Hur, Sungroh Yoon
- **Comment**: 16 pages, 1 figure, 4 tables
- **Journal**: None
- **Summary**: Enhancing feature transferability by matching marginal distributions has led to improvements in domain adaptation, although this is at the expense of feature discrimination. In particular, the ideal joint hypothesis error in the target error upper bound, which was previously considered to be minute, has been found to be significant, impairing its theoretical guarantee. In this paper, we propose an alternative upper bound on the target error that explicitly considers the joint error to render it more manageable. With the theoretical analysis, we suggest a joint optimization framework that combines the source and target domains. Further, we introduce Joint Contrastive Learning (JCL) to find class-level discriminative features, which is essential for minimizing the joint error. With a solid theoretical framework, JCL employs contrastive loss to maximize the mutual information between a feature and its label, which is equivalent to maximizing the Jensen-Shannon divergence between conditional distributions. Experiments on two real-world datasets demonstrate that JCL outperforms the state-of-the-art methods.



### Automatic Speech Recognition Benchmark for Air-Traffic Communications
- **Arxiv ID**: http://arxiv.org/abs/2006.10304v2
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG, cs.SD, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2006.10304v2)
- **Published**: 2020-06-18 06:49:22+00:00
- **Updated**: 2020-08-13 06:46:34+00:00
- **Authors**: Juan Zuluaga-Gomez, Petr Motlicek, Qingran Zhan, Karel Vesely, Rudolf Braun
- **Comment**: Accepted to: 21st INTERSPEECH conference (Shanghai, October 25-29)
- **Journal**: None
- **Summary**: Advances in Automatic Speech Recognition (ASR) over the last decade opened new areas of speech-based automation such as in Air-Traffic Control (ATC) environment. Currently, voice communication and data links communications are the only way of contact between pilots and Air-Traffic Controllers (ATCo), where the former is the most widely used and the latter is a non-spoken method mandatory for oceanic messages and limited for some domestic issues. ASR systems on ATCo environments inherit increasing complexity due to accents from non-English speakers, cockpit noise, speaker-dependent biases, and small in-domain ATC databases for training. Hereby, we introduce CleanSky EC-H2020 ATCO2, a project that aims to develop an ASR-based platform to collect, organize and automatically pre-process ATCo speech-data from air space. This paper conveys an exploratory benchmark of several state-of-the-art ASR models trained on more than 170 hours of ATCo speech-data. We demonstrate that the cross-accent flaws due to speakers' accents are minimized due to the amount of data, making the system feasible for ATC environments. The developed ASR system achieves an averaged word error rate (WER) of 7.75% across four databases. An additional 35% relative improvement in WER is achieved on one test set when training a TDNNF system with byte-pair encoding.



### Cascaded Regression Tracking: Towards Online Hard Distractor Discrimination
- **Arxiv ID**: http://arxiv.org/abs/2006.10336v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10336v1)
- **Published**: 2020-06-18 07:48:01+00:00
- **Updated**: 2020-06-18 07:48:01+00:00
- **Authors**: Ning Wang, Wengang Zhou, Qi Tian, Houqiang Li
- **Comment**: Accepted by IEEE TCSVT
- **Journal**: None
- **Summary**: Visual tracking can be easily disturbed by similar surrounding objects. Such objects as hard distractors, even though being the minority among negative samples, increase the risk of target drift and model corruption, which deserve additional attention in online tracking and model update. To enhance the tracking robustness, in this paper, we propose a cascaded regression tracker with two sequential stages. In the first stage, we filter out abundant easily-identified negative candidates via an efficient convolutional regression. In the second stage, a discrete sampling based ridge regression is designed to double-check the remaining ambiguous hard samples, which serves as an alternative of fully-connected layers and benefits from the closed-form solver for efficient learning. Extensive experiments are conducted on 11 challenging tracking benchmarks including OTB-2013, OTB-2015, VOT2018, VOT2019, UAV123, Temple-Color, NfS, TrackingNet, LaSOT, UAV20L, and OxUvA. The proposed method achieves state-of-the-art performance on prevalent benchmarks, while running in a real-time speed.



### Automated Radiological Report Generation For Chest X-Rays With Weakly-Supervised End-to-End Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2006.10347v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10347v1)
- **Published**: 2020-06-18 08:12:54+00:00
- **Updated**: 2020-06-18 08:12:54+00:00
- **Authors**: Shuai Zhang, Xiaoyan Xin, Yang Wang, Yachong Guo, Qiuqiao Hao, Xianfeng Yang, Jun Wang, Jian Zhang, Bing Zhang, Wei Wang
- **Comment**: None
- **Journal**: None
- **Summary**: The chest X-Ray (CXR) is the one of the most common clinical exam used to diagnose thoracic diseases and abnormalities. The volume of CXR scans generated daily in hospitals is huge. Therefore, an automated diagnosis system able to save the effort of doctors is of great value. At present, the applications of artificial intelligence in CXR diagnosis usually use pattern recognition to classify the scans. However, such methods rely on labeled databases, which are costly and usually have large error rates. In this work, we built a database containing more than 12,000 CXR scans and radiological reports, and developed a model based on deep convolutional neural network and recurrent network with attention mechanism. The model learns features from the CXR scans and the associated raw radiological reports directly; no additional labeling of the scans are needed. The model provides automated recognition of given scans and generation of reports. The quality of the generated reports was evaluated with both the CIDEr scores and by radiologists as well. The CIDEr scores are found to be around 5.8 on average for the testing dataset. Further blind evaluation suggested a comparable performance against human radiologist.



### DrNAS: Dirichlet Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2006.10355v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10355v4)
- **Published**: 2020-06-18 08:23:02+00:00
- **Updated**: 2021-03-16 02:32:55+00:00
- **Authors**: Xiangning Chen, Ruochen Wang, Minhao Cheng, Xiaocheng Tang, Cho-Jui Hsieh
- **Comment**: ICLR 2021, code is available at
  https://github.com/xiangning-chen/DrNAS
- **Journal**: None
- **Summary**: This paper proposes a novel differentiable architecture search method by formulating it into a distribution learning problem. We treat the continuously relaxed architecture mixing weight as random variables, modeled by Dirichlet distribution. With recently developed pathwise derivatives, the Dirichlet parameters can be easily optimized with gradient-based optimizer in an end-to-end manner. This formulation improves the generalization ability and induces stochasticity that naturally encourages exploration in the search space. Furthermore, to alleviate the large memory consumption of differentiable NAS, we propose a simple yet effective progressive learning scheme that enables searching directly on large-scale tasks, eliminating the gap between search and evaluation phases. Extensive experiments demonstrate the effectiveness of our method. Specifically, we obtain a test error of 2.46% for CIFAR-10, 23.7% for ImageNet under the mobile setting. On NAS-Bench-201, we also achieve state-of-the-art results on all three datasets and provide insights for the effective design of neural architecture search algorithms.



### On the Robustness of Active Learning
- **Arxiv ID**: http://arxiv.org/abs/2006.10370v1
- **DOI**: 10.29007/thws
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10370v1)
- **Published**: 2020-06-18 09:07:23+00:00
- **Updated**: 2020-06-18 09:07:23+00:00
- **Authors**: Lukas Hahn, Lutz Roese-Koerner, Peet Cremer, Urs Zimmermann, Ori Maoz, Anton Kummert
- **Comment**: 11 pages, 6 figures, 1 table; as published in the proceedings of the
  5th Global Conference on Artificial Intelligence (GCAI), EPiC Series in
  Computing, Volume 65, pages 152-162, https://doi.org/10.29007/thws, 2019
- **Journal**: Proceedings of the 5th Global Conference on Artificial
  Intelligence (GCAI), EPiC Series in Computing, Volume 65, pages 152-162, 2019
- **Summary**: Active Learning is concerned with the question of how to identify the most useful samples for a Machine Learning algorithm to be trained with. When applied correctly, it can be a very powerful tool to counteract the immense data requirements of Artificial Neural Networks. However, we find that it is often applied with not enough care and domain knowledge. As a consequence, unrealistic hopes are raised and transfer of the experimental results from one dataset to another becomes unnecessarily hard.   In this work we analyse the robustness of different Active Learning methods with respect to classifier capacity, exchangeability and type, as well as hyperparameters and falsely labelled data. Experiments reveal possible biases towards the architecture used for sample selection, resulting in suboptimal performance for other classifiers. We further propose the new "Sum of Squared Logits" method based on the Simpson diversity index and investigate the effect of using the confusion matrix for balancing in sample selection.



### Video Semantic Segmentation with Distortion-Aware Feature Correction
- **Arxiv ID**: http://arxiv.org/abs/2006.10380v2
- **DOI**: 10.1109/TCSVT.2020.3037234
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10380v2)
- **Published**: 2020-06-18 09:30:00+00:00
- **Updated**: 2020-11-12 09:12:50+00:00
- **Authors**: Jiafan Zhuang, Zilei Wang, Bingke Wang
- **Comment**: 12 pages, 16 figures. The paper has been accepted by IEEE
  Transactions on Circuits and Systems for Video Technology(TCSVT) 2020
- **Journal**: None
- **Summary**: Video semantic segmentation is active in recent years benefited from the great progress of image semantic segmentation. For such a task, the per-frame image segmentation is generally unacceptable in practice due to high computation cost. To tackle this issue, many works use the flow-based feature propagation to reuse the features of previous frames. However, the optical flow estimation inevitably suffers inaccuracy and then causes the propagated features distorted. In this paper, we propose distortion-aware feature correction to alleviate the issue, which improves video segmentation performance by correcting distorted propagated features. To be specific, we firstly propose to transfer distortion patterns from feature into image space and conduct effective distortion map prediction. Benefited from the guidance of distortion maps, we proposed Feature Correction Module (FCM) to rectify propagated features in the distorted areas. Our proposed method can significantly boost the accuracy of video semantic segmentation at a low price. The extensive experimental results on Cityscapes and CamVid show that our method outperforms the recent state-of-the-art methods.



### 3D Pipe Network Reconstruction Based on Structure from Motion with Incremental Conic Shape Detection and Cylindrical Constraint
- **Arxiv ID**: http://arxiv.org/abs/2006.10383v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10383v2)
- **Published**: 2020-06-18 09:37:00+00:00
- **Updated**: 2020-07-03 04:52:21+00:00
- **Authors**: Sho kagami, Hajime Taira, Naoyuki Miyashita, Akihiko Torii, Masatoshi Okutomi
- **Comment**: This manuscript was accepted and presented in the 29th IEEE
  International Symposium on Industrial Electronics (ISIE2020)
- **Journal**: None
- **Summary**: Pipe inspection is a critical task for many industries and infrastructure of a city. The 3D information of a pipe can be used for revealing the deformation of the pipe surface and position of the camera during the inspection. In this paper, we propose a 3D pipe reconstruction system using sequential images captured by a monocular endoscopic camera. Our work extends a state-of-the-art incremental Structure-from-Motion (SfM) method to incorporate prior constraints given by the target shape into bundle adjustment (BA). Using this constraint, we can minimize the scale-drift that is the general problem in SfM. Moreover, our method can reconstruct a pipe network composed of multiple parts including straight pipes, elbows, and tees. In the experiments, we show that the proposed system enables more accurate and robust pipe mapping from a monocular camera in comparison with existing state-of-the-art methods.



### SceneAdapt: Scene-based domain adaptation for semantic segmentation using adversarial learning
- **Arxiv ID**: http://arxiv.org/abs/2006.10386v1
- **DOI**: 10.1016/j.patrec.2020.06.002
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10386v1)
- **Published**: 2020-06-18 09:43:31+00:00
- **Updated**: 2020-06-18 09:43:31+00:00
- **Authors**: Daniele Di Mauro, Antonino Furnari, Giuseppe Patanè, Sebastiano Battiato, Giovanni Maria Farinella
- **Comment**: None
- **Journal**: Pattern Recognition Letters, Volume 136, August 2020, Pages
  175-182
- **Summary**: Semantic segmentation methods have achieved outstanding performance thanks to deep learning. Nevertheless, when such algorithms are deployed to new contexts not seen during training, it is necessary to collect and label scene-specific data in order to adapt them to the new domain using fine-tuning. This process is required whenever an already installed camera is moved or a new camera is introduced in a camera network due to the different scene layouts induced by the different viewpoints. To limit the amount of additional training data to be collected, it would be ideal to train a semantic segmentation method using labeled data already available and only unlabeled data coming from the new camera. We formalize this problem as a domain adaptation task and introduce a novel dataset of urban scenes with the related semantic labels. As a first approach to address this challenging task, we propose SceneAdapt, a method for scene adaptation of semantic segmentation algorithms based on adversarial learning. Experiments and comparisons with state-of-the-art approaches to domain adaptation highlight that promising performance can be achieved using adversarial learning both when the two scenes have different but points of view, and when they comprise images of completely different scenes. To encourage research on this topic, we made our code available at our web page: https://iplab.dmi.unict.it/ParkSmartSceneAdaptation/.



### Fourth-Order Anisotropic Diffusion for Inpainting and Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2006.10406v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.2; I.4.4
- **Links**: [PDF](http://arxiv.org/pdf/2006.10406v1)
- **Published**: 2020-06-18 10:13:31+00:00
- **Updated**: 2020-06-18 10:13:31+00:00
- **Authors**: Ikram Jumakulyyev, Thomas Schultz
- **Comment**: Accepted for publication in Springer book "Anisotropy Across Fields
  and Scales"
- **Journal**: None
- **Summary**: Edge-enhancing diffusion (EED) can reconstruct a close approximation of an original image from a small subset of its pixels. This makes it an attractive foundation for PDE based image compression. In this work, we generalize second-order EED to a fourth-order counterpart. It involves a fourth-order diffusion tensor that is constructed from the regularized image gradient in a similar way as in traditional second-order EED, permitting diffusion along edges, while applying a non-linear diffusivity function across them. We show that our fourth-order diffusion tensor formalism provides a unifying framework for all previous anisotropic fourth-order diffusion based methods, and that it provides additional flexibility. We achieve an efficient implementation using a fast semi-iterative scheme. Experimental results on natural and medical images suggest that our novel fourth-order method produces more accurate reconstructions compared to the existing second-order EED.



### Overcoming Classifier Imbalance for Long-tail Object Detection with Balanced Group Softmax
- **Arxiv ID**: http://arxiv.org/abs/2006.10408v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10408v1)
- **Published**: 2020-06-18 10:24:26+00:00
- **Updated**: 2020-06-18 10:24:26+00:00
- **Authors**: Yu Li, Tao Wang, Bingyi Kang, Sheng Tang, Chunfeng Wang, Jintao Li, Jiashi Feng
- **Comment**: CVPR 2020 (Oral). Code is available at
  https://github.com/FishYuLi/BalancedGroupSoftmax
- **Journal**: None
- **Summary**: Solving long-tail large vocabulary object detection with deep learning based models is a challenging and demanding task, which is however under-explored.In this work, we provide the first systematic analysis on the underperformance of state-of-the-art models in front of long-tail distribution. We find existing detection methods are unable to model few-shot classes when the dataset is extremely skewed, which can result in classifier imbalance in terms of parameter magnitude. Directly adapting long-tail classification models to detection frameworks can not solve this problem due to the intrinsic difference between detection and classification.In this work, we propose a novel balanced group softmax (BAGS) module for balancing the classifiers within the detection frameworks through group-wise training. It implicitly modulates the training process for the head and tail classes and ensures they are both sufficiently trained, without requiring any extra sampling for the instances from the tail classes.Extensive experiments on the very recent long-tail large vocabulary object recognition benchmark LVIS show that our proposed BAGS significantly improves the performance of detectors with various backbones and frameworks on both object detection and instance segmentation. It beats all state-of-the-art methods transferred from long-tail image classification and establishes new state-of-the-art.Code is available at https://github.com/FishYuLi/BalancedGroupSoftmax.



### Frost filtered scale-invariant feature extraction and multilayer perceptron for hyperspectral image classification
- **Arxiv ID**: http://arxiv.org/abs/2006.12556v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12556v1)
- **Published**: 2020-06-18 10:51:04+00:00
- **Updated**: 2020-06-18 10:51:04+00:00
- **Authors**: G. Kalaiarasi, S. Maheswari
- **Comment**: None
- **Journal**: None
- **Summary**: Hyperspectral image (HSI) classification plays a significant in the field of remote sensing due to its ability to provide spatial and spectral information. Due to the rapid development and increasing of hyperspectral remote sensing technology, many methods have been developed for HSI classification but still a lack of achieving the better performance. A Frost Filtered Scale-Invariant Feature Transformation based MultiLayer Perceptron Classification (FFSIFT-MLPC) technique is introduced for classifying the hyperspectral image with higher accuracy and minimum time consumption. The FFSIFT-MLPC technique performs three major processes, namely preprocessing, feature extraction and classification using multiple layers. Initially, the hyperspectral image is divided into number of spectral bands. These bands are given as input in the input layer of perceptron. Then the Frost filter is used in FFSIFT-MLPC technique for preprocessing the input bands which helps to remove the noise from hyper-spectral image at the first hidden layer. After preprocessing task, texture, color and object features of hyper-spectral image are extracted at second hidden layer using Gaussian distributive scale-invariant feature transform. At the third hidden layer, Euclidean distance is measured between the extracted features and testing features. Finally, feature matching is carried out at the output layer for hyper-spectral image classification. The classified outputs are resulted in terms of spectral bands (i.e., different colors). Experimental analysis is performed with PSNR, classification accuracy, false positive rate and classification time with number of spectral bands. The results evident that presented FFSIFT-MLPC technique improves the hyperspectral image classification accuracy, PSNR and minimizes false positive rate as well as classification time than the state-of-the-art methods.



### Learning High-Resolution Domain-Specific Representations with a GAN Generator
- **Arxiv ID**: http://arxiv.org/abs/2006.10451v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10451v1)
- **Published**: 2020-06-18 11:57:18+00:00
- **Updated**: 2020-06-18 11:57:18+00:00
- **Authors**: Danil Galeev, Konstantin Sofiiuk, Danila Rukhovich, Mikhail Romanov, Olga Barinova, Anton Konushin
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years generative models of visual data have made a great progress, and now they are able to produce images of high quality and diversity. In this work we study representations learnt by a GAN generator. First, we show that these representations can be easily projected onto semantic segmentation map using a lightweight decoder. We find that such semantic projection can be learnt from just a few annotated images. Based on this finding, we propose LayerMatch scheme for approximating the representation of a GAN generator that can be used for unsupervised domain-specific pretraining. We consider the semi-supervised learning scenario when a small amount of labeled data is available along with a large unlabeled dataset from the same domain. We find that the use of LayerMatch-pretrained backbone leads to superior accuracy compared to standard supervised pretraining on ImageNet. Moreover, this simple approach also outperforms recent semi-supervised semantic segmentation methods that use both labeled and unlabeled data during training. Source code for reproducing our experiments will be available at the time of publication.



### Language Guided Networks for Cross-modal Moment Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2006.10457v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2006.10457v2)
- **Published**: 2020-06-18 12:08:40+00:00
- **Updated**: 2020-09-09 05:19:24+00:00
- **Authors**: Kun Liu, Huadong Ma, Chuang Gan
- **Comment**: None
- **Journal**: None
- **Summary**: We address the challenging task of cross-modal moment retrieval, which aims to localize a temporal segment from an untrimmed video described by a natural language query. It poses great challenges over the proper semantic alignment between vision and linguistic domains. Existing methods independently extract the features of videos and sentences and purely utilize the sentence embedding in the multi-modal fusion stage, which do not make full use of the potential of language. In this paper, we present Language Guided Networks (LGN), a new framework that leverages the sentence embedding to guide the whole process of moment retrieval. In the first feature extraction stage, we propose to jointly learn visual and language features to capture the powerful visual information which can cover the complex semantics in the sentence query. Specifically, the early modulation unit is designed to modulate the visual feature extractor's feature maps by a linguistic embedding. Then we adopt a multi-modal fusion module in the second fusion stage. Finally, to get a precise localizer, the sentence information is utilized to guide the process of predicting temporal positions. Specifically, the late guidance module is developed to linearly transform the output of localization networks via the channel attention mechanism. The experimental results on two popular datasets demonstrate the superior performance of our proposed method on moment retrieval (improving by 5.8\% in terms of Rank1@IoU0.5 on Charades-STA and 5.2\% on TACoS). The source code for the complete system will be publicly available.



### Auxiliary-task learning for geographic data with autoregressive embeddings
- **Arxiv ID**: http://arxiv.org/abs/2006.10461v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10461v3)
- **Published**: 2020-06-18 12:16:08+00:00
- **Updated**: 2021-08-19 10:22:48+00:00
- **Authors**: Konstantin Klemmer, Daniel B. Neill
- **Comment**: SIGSPATIAL 2021
- **Journal**: None
- **Summary**: Machine learning is gaining popularity in a broad range of areas working with geographic data, such as ecology or atmospheric sciences. Here, data often exhibit spatial effects, which can be difficult to learn for neural networks. In this study, we propose SXL, a method for embedding information on the autoregressive nature of spatial data directly into the learning process using auxiliary tasks. We utilize the local Moran's I, a popular measure of local spatial autocorrelation, to "nudge" the model to learn the direction and magnitude of local spatial effects, complementing the learning of the primary task. We further introduce a novel expansion of Moran's I to multiple resolutions, thus capturing spatial interactions over longer and shorter distances simultaneously. The novel multi-resolution Moran's I can be constructed easily and as a multi-dimensional tensor offers seamless integration into existing machine learning frameworks. Throughout a range of experiments using real-world data, we highlight how our method consistently improves the training of neural networks in unsupervised and supervised learning tasks. In generative spatial modeling experiments, we propose a novel loss for auxiliary task GANs utilizing task uncertainty weights. Our proposed method outperforms domain-specific spatial interpolation benchmarks, highlighting its potential for downstream applications. This study bridges expertise from geographic information science and machine learning, showing how this integration of disciplines can help to address domain-specific challenges. The code for our experiments is available on Github: https://github.com/konstantinklemmer/sxl.



### Structure and Design of HoloGen
- **Arxiv ID**: http://arxiv.org/abs/2006.10509v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10509v1)
- **Published**: 2020-06-18 13:29:46+00:00
- **Updated**: 2020-06-18 13:29:46+00:00
- **Authors**: Peter J. Christopher, Timothy D. Wilkinson
- **Comment**: None
- **Journal**: None
- **Summary**: Increasing popularity of augmented and mixed reality systems has seen a similar increase of interest in 2D and 3D computer generated holography (CGH). Unlike stereoscopic approaches, CGH can fully represent a light field including depth of focus, accommodation and vergence. Along with existing telecommunications, imaging, projection, lithography, beam shaping and optical tweezing applications, CGH is an exciting technique applicable to a wide array of photonic problems including full 3D representation. Traditionally, the primary roadblock to acceptance has been the significant numerical processing required to generate holograms requiring both significant expertise and significant computational power. This article discusses the structure and design of HoloGen. HoloGen is an MIT licensed application that may be used to generate holograms using a wide array of algorithms without expert guidance. HoloGen uses a Cuda C and C++ backend with a C# and Windows Presentation Framework graphical user interface. The article begins by introducing HoloGen before providing an in-depth discussion of its design and structure. Particular focus is given to the communication, data transfer and algorithmic aspects.



### Contrastive learning of global and local features for medical image segmentation with limited annotations
- **Arxiv ID**: http://arxiv.org/abs/2006.10511v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10511v2)
- **Published**: 2020-06-18 13:31:26+00:00
- **Updated**: 2020-10-30 14:45:25+00:00
- **Authors**: Krishna Chaitanya, Ertunc Erdil, Neerav Karani, Ender Konukoglu
- **Comment**: 18 pages, 2 figures, 10 tables. This article has been accepted as
  Oral Presentation at NeurIPS 2020 (34th Conference on Neural Information
  Processing Systems)
- **Journal**: None
- **Summary**: A key requirement for the success of supervised deep learning is a large labeled dataset - a condition that is difficult to meet in medical image analysis. Self-supervised learning (SSL) can help in this regard by providing a strategy to pre-train a neural network with unlabeled data, followed by fine-tuning for a downstream task with limited annotations. Contrastive learning, a particular variant of SSL, is a powerful technique for learning image-level representations. In this work, we propose strategies for extending the contrastive learning framework for segmentation of volumetric medical images in the semi-supervised setting with limited annotations, by leveraging domain-specific and problem-specific cues. Specifically, we propose (1) novel contrasting strategies that leverage structural similarity across volumetric medical images (domain-specific cue) and (2) a local version of the contrastive loss to learn distinctive representations of local regions that are useful for per-pixel segmentation (problem-specific cue). We carry out an extensive evaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited annotation setting, the proposed method yields substantial improvements compared to other self-supervision and semi-supervised learning techniques. When combined with a simple data augmentation technique, the proposed method reaches within 8% of benchmark performance using only two labeled MRI volumes for training, corresponding to only 4% (for ACDC) of the training data used to train the benchmark. The code is made public at https://github.com/krishnabits001/domain_specific_cl.



### Computer Vision with Deep Learning for Plant Phenotyping in Agriculture: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2006.11391v1
- **DOI**: 10.34048/ACC.2020.1.F1
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11391v1)
- **Published**: 2020-06-18 14:21:19+00:00
- **Updated**: 2020-06-18 14:21:19+00:00
- **Authors**: Akshay L Chandra, Sai Vikas Desai, Wei Guo, Vineeth N Balasubramanian
- **Comment**: Featured as an article at Journal of Advanced Computing and
  Communications, April 2020. arXiv admin note: text overlap with
  arXiv:1805.00881 by other authors
- **Journal**: None
- **Summary**: In light of growing challenges in agriculture with ever growing food demand across the world, efficient crop management techniques are necessary to increase crop yield. Precision agriculture techniques allow the stakeholders to make effective and customized crop management decisions based on data gathered from monitoring crop environments. Plant phenotyping techniques play a major role in accurate crop monitoring. Advancements in deep learning have made previously difficult phenotyping tasks possible. This survey aims to introduce the reader to the state of the art research in deep plant phenotyping.



### Towards a Neural Graphics Pipeline for Controllable Image Generation
- **Arxiv ID**: http://arxiv.org/abs/2006.10569v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10569v2)
- **Published**: 2020-06-18 14:22:54+00:00
- **Updated**: 2021-02-22 09:18:55+00:00
- **Authors**: Xuelin Chen, Daniel Cohen-Or, Baoquan Chen, Niloy J. Mitra
- **Comment**: Eurographics 2021
- **Journal**: None
- **Summary**: In this paper, we leverage advances in neural networks towards forming a neural rendering for controllable image generation, and thereby bypassing the need for detailed modeling in conventional graphics pipeline. To this end, we present Neural Graphics Pipeline (NGP), a hybrid generative model that brings together neural and traditional image formation models. NGP decomposes the image into a set of interpretable appearance feature maps, uncovering direct control handles for controllable image generation. To form an image, NGP generates coarse 3D models that are fed into neural rendering modules to produce view-specific interpretable 2D maps, which are then composited into the final output image using a traditional image formation model. Our approach offers control over image generation by providing direct handles controlling illumination and camera parameters, in addition to control over shape and appearance variations. The key challenge is to learn these controls through unsupervised training that links generated coarse 3D models with unpaired real images via neural and traditional (e.g., Blinn- Phong) rendering functions, without establishing an explicit correspondence between them. We demonstrate the effectiveness of our approach on controllable image generation of single-object scenes. We evaluate our hybrid modeling framework, compare with neural-only generation methods (namely, DCGAN, LSGAN, WGAN-GP, VON, and SRNs), report improvement in FID scores against real images, and demonstrate that NGP supports direct controls common in traditional forward rendering. Code is available at http://geometry.cs.ucl.ac.uk/projects/2021/ngp.



### A Review of 1D Convolutional Neural Networks toward Unknown Substance Identification in Portable Raman Spectrometer
- **Arxiv ID**: http://arxiv.org/abs/2006.10575v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10575v1)
- **Published**: 2020-06-18 14:28:00+00:00
- **Updated**: 2020-06-18 14:28:00+00:00
- **Authors**: M. Hamed Mozaffari, Li-Lin Tay
- **Comment**: 19 pages, 1 figure, 5 tables
- **Journal**: None
- **Summary**: Raman spectroscopy is a powerful analytical tool with applications ranging from quality control to cutting edge biomedical research. One particular area which has seen tremendous advances in the past decade is the development of powerful handheld Raman spectrometers. They have been adopted widely by first responders and law enforcement agencies for the field analysis of unknown substances. Field detection and identification of unknown substances with Raman spectroscopy rely heavily on the spectral matching capability of the devices on hand. Conventional spectral matching algorithms (such as correlation, dot product, etc.) have been used in identifying unknown Raman spectrum by comparing the unknown to a large reference database. This is typically achieved through brute-force summation of pixel-by-pixel differences between the reference and the unknown spectrum. Conventional algorithms have noticeable drawbacks. For example, they tend to work well with identifying pure compounds but less so for mixture compounds. For instance, limited reference spectra inaccessible databases with a large number of classes relative to the number of samples have been a setback for the widespread usage of Raman spectroscopy for field analysis applications. State-of-the-art deep learning methods (specifically convolutional neural networks CNNs), as an alternative approach, presents a number of advantages over conventional spectral comparison algorism. With optimization, they are ideal to be deployed in handheld spectrometers for field detection of unknown substances. In this study, we present a comprehensive survey in the use of one-dimensional CNNs for Raman spectrum identification. Specifically, we highlight the use of this powerful deep learning technique for handheld Raman spectrometers taking into consideration the potential limit in power consumption and computation ability of handheld systems.



### Neural Parameter Allocation Search
- **Arxiv ID**: http://arxiv.org/abs/2006.10598v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10598v4)
- **Published**: 2020-06-18 15:01:00+00:00
- **Updated**: 2022-03-16 03:29:34+00:00
- **Authors**: Bryan A. Plummer, Nikoli Dryden, Julius Frost, Torsten Hoefler, Kate Saenko
- **Comment**: Accepted at ICLR 2022
- **Journal**: None
- **Summary**: Training neural networks requires increasing amounts of memory. Parameter sharing can reduce memory and communication costs, but existing methods assume networks have many identical layers and utilize hand-crafted sharing strategies that fail to generalize. We introduce Neural Parameter Allocation Search (NPAS), a novel task where the goal is to train a neural network given an arbitrary, fixed parameter budget. NPAS covers both low-budget regimes, which produce compact networks, as well as a novel high-budget regime, where additional capacity can be added to boost performance without increasing inference FLOPs. To address NPAS, we introduce Shapeshifter Networks (SSNs), which automatically learn where and how to share parameters in a network to support any parameter budget without requiring any changes to the architecture or loss function. NPAS and SSNs provide a complete framework for addressing generalized parameter sharing, and can also be combined with prior work for additional performance gains. We demonstrate the effectiveness of our approach using nine network architectures across four diverse tasks, including ImageNet classification and transformers.



### On the Predictability of Pruning Across Scales
- **Arxiv ID**: http://arxiv.org/abs/2006.10621v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10621v3)
- **Published**: 2020-06-18 15:41:46+00:00
- **Updated**: 2021-07-04 02:51:24+00:00
- **Authors**: Jonathan S. Rosenfeld, Jonathan Frankle, Michael Carbin, Nir Shavit
- **Comment**: None
- **Journal**: None
- **Summary**: We show that the error of iteratively magnitude-pruned networks empirically follows a scaling law with interpretable coefficients that depend on the architecture and task. We functionally approximate the error of the pruned networks, showing it is predictable in terms of an invariant tying width, depth, and pruning level, such that networks of vastly different pruned densities are interchangeable. We demonstrate the accuracy of this approximation over orders of magnitude in depth, width, dataset size, and density. We show that the functional form holds (generalizes) for large scale data (e.g., ImageNet) and architectures (e.g., ResNets). As neural networks become ever larger and costlier to train, our findings suggest a framework for reasoning conceptually and analytically about a standard method for unstructured pruning.



### SatImNet: Structured and Harmonised Training Data for Enhanced Satellite Imagery Classification
- **Arxiv ID**: http://arxiv.org/abs/2006.10623v2
- **DOI**: 10.3390/rs12203358
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10623v2)
- **Published**: 2020-06-18 15:46:24+00:00
- **Updated**: 2020-11-03 22:44:00+00:00
- **Authors**: Vasileios Syrris, Ondrej Pesek, Pierre Soille
- **Comment**: 22 pages, 10 figures
- **Journal**: Remote Sensing 12(20) (2020) 3358
- **Summary**: Automatic supervised classification with complex modelling such as deep neural networks requires the availability of representative training data sets. While there exists a plethora of data sets that can be used for this purpose, they are usually very heterogeneous and not interoperable. In this context, the present work has a twofold objective: i) to describe procedures of open-source training data management, integration, and data retrieval, and ii) to demonstrate the practical use of varying source training data for remote sensing image classification. For the former, we propose SatImNet, a collection of open training data, structured and harmonized according to specific rules. For the latter, two modelling approaches based on convolutional neural networks have been designed and configured to deal with satellite image classification and segmentation.



### Use of in-the-wild images for anomaly detection in face anti-spoofing
- **Arxiv ID**: http://arxiv.org/abs/2006.10626v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, I.5.4; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/2006.10626v1)
- **Published**: 2020-06-18 15:49:36+00:00
- **Updated**: 2020-06-18 15:49:36+00:00
- **Authors**: Latifah Abduh, Ioannis Ivrissimtzis
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: The traditional approach to face anti-spoofing sees it as a binary classification problem, and binary classifiers are trained and validated on specialized anti-spoofing databases. One of the drawbacks of this approach is that, due to the variability of face spoofing attacks, environmental factors, and the typically small sample size, such classifiers do not generalize well to previously unseen databases. Anomaly detection, which approaches face anti-spoofing as a one-class classification problem, is emerging as an increasingly popular alternative approach. Nevertheless, in all existing work on anomaly detection for face anti-spoofing, the proposed training protocols utilize images from specialized anti-spoofing databases only, even though only common images of real faces are needed. Here, we explore the use of in-the-wild images, and images from non-specialized face databases, to train one-class classifiers for face anti-spoofing. Employing a well-established technique, we train a convolutional autoencoder on real faces and compare the reconstruction error of the input against a threshold to classify a face image accordingly as either client or imposter.   Our results show that the inclusion in the training set of in-the-wild images increases the discriminating power of the classifier significantly on an unseen database, as evidenced by a large increase in the value of the Area Under the Curve. In a limitation of our approach, we note that the problem of finding a suitable operating point on the unseen database remains a challenge, as evidenced by the values of the Half Total Error Rate.



### Online Deep Clustering for Unsupervised Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2006.10645v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10645v1)
- **Published**: 2020-06-18 16:15:46+00:00
- **Updated**: 2020-06-18 16:15:46+00:00
- **Authors**: Xiaohang Zhan, Jiahao Xie, Ziwei Liu, Yew Soon Ong, Chen Change Loy
- **Comment**: Accepted by CVPR 2020. Code:
  https://github.com/open-mmlab/OpenSelfSup
- **Journal**: None
- **Summary**: Joint clustering and feature learning methods have shown remarkable performance in unsupervised representation learning. However, the training schedule alternating between feature clustering and network parameters update leads to unstable learning of visual representations. To overcome this challenge, we propose Online Deep Clustering (ODC) that performs clustering and network update simultaneously rather than alternatingly. Our key insight is that the cluster centroids should evolve steadily in keeping the classifier stably updated. Specifically, we design and maintain two dynamic memory modules, i.e., samples memory to store samples labels and features, and centroids memory for centroids evolution. We break down the abrupt global clustering into steady memory update and batch-wise label re-assignment. The process is integrated into network update iterations. In this way, labels and the network evolve shoulder-to-shoulder rather than alternatingly. Extensive experiments demonstrate that ODC stabilizes the training process and boosts the performance effectively. Code: https://github.com/open-mmlab/OpenSelfSup.



### Multi-Density Sketch-to-Image Translation Network
- **Arxiv ID**: http://arxiv.org/abs/2006.10649v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10649v1)
- **Published**: 2020-06-18 16:21:04+00:00
- **Updated**: 2020-06-18 16:21:04+00:00
- **Authors**: Jialu Huang, Jing Liao, Zhifeng Tan, Sam Kwong
- **Comment**: 2020 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other uses, in any current or future
  media, including reprinting/republishing this material for advertising or
  promotional purposes, creating new collective works, for resale or
  redistribution to servers or lists, or reuse of any copyrighted component of
  this work in other works
- **Journal**: None
- **Summary**: Sketch-to-image (S2I) translation plays an important role in image synthesis and manipulation tasks, such as photo editing and colorization. Some specific S2I translation including sketch-to-photo and sketch-to-painting can be used as powerful tools in the art design industry. However, previous methods only support S2I translation with a single level of density, which gives less flexibility to users for controlling the input sketches. In this work, we propose the first multi-level density sketch-to-image translation framework, which allows the input sketch to cover a wide range from rough object outlines to micro structures. Moreover, to tackle the problem of noncontinuous representation of multi-level density input sketches, we project the density level into a continuous latent space, which can then be linearly controlled by a parameter. This allows users to conveniently control the densities of input sketches and generation of images. Moreover, our method has been successfully verified on various datasets for different applications including face editing, multi-modal sketch-to-photo translation, and anime colorization, providing coarse-to-fine levels of controls to these applications.



### REGroup: Rank-aggregating Ensemble of Generative Classifiers for Robust Predictions
- **Arxiv ID**: http://arxiv.org/abs/2006.10679v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10679v2)
- **Published**: 2020-06-18 17:07:19+00:00
- **Updated**: 2021-11-24 11:00:57+00:00
- **Authors**: Lokender Tiwari, Anish Madan, Saket Anand, Subhashis Banerjee
- **Comment**: WACV,2022. Project Page : https://lokender.github.io/REGroup.html
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) are often criticized for being susceptible to adversarial attacks. Most successful defense strategies adopt adversarial training or random input transformations that typically require retraining or fine-tuning the model to achieve reasonable performance. In this work, our investigations of intermediate representations of a pre-trained DNN lead to an interesting discovery pointing to intrinsic robustness to adversarial attacks. We find that we can learn a generative classifier by statistically characterizing the neural response of an intermediate layer to clean training samples. The predictions of multiple such intermediate-layer based classifiers, when aggregated, show unexpected robustness to adversarial attacks. Specifically, we devise an ensemble of these generative classifiers that rank-aggregates their predictions via a Borda count-based consensus. Our proposed approach uses a subset of the clean training data and a pre-trained model, and yet is agnostic to network architectures or the adversarial attack generation method. We show extensive experiments to establish that our defense strategy achieves state-of-the-art performance on the ImageNet validation set.



### Semi-Supervised Recognition under a Noisy and Fine-grained Dataset
- **Arxiv ID**: http://arxiv.org/abs/2006.10702v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10702v1)
- **Published**: 2020-06-18 17:37:13+00:00
- **Updated**: 2020-06-18 17:37:13+00:00
- **Authors**: Cheng Cui, Zhi Ye, Yangxi Li, Xinjian Li, Min Yang, Kai Wei, Bing Dai, Yanmei Zhao, Zhongji Liu, Rong Pang
- **Comment**: 5 pages, 3 figures, 3 tables
- **Journal**: None
- **Summary**: Simi-Supervised Recognition Challenge-FGVC7 is a challenging fine-grained recognition competition. One of the difficulties of this competition is how to use unlabeled data. We adopted pseudo-tag data mining to increase the amount of training data. The other one is how to identify similar birds with a very small difference, especially those have a relatively tiny main-body in examples. We combined generic image recognition and fine-grained image recognition method to solve the problem. All generic image recognition models were training using PaddleClas . Using the combination of two different ways of deep recognition models, we finally won the third place in the competition.



### Latent Video Transformer
- **Arxiv ID**: http://arxiv.org/abs/2006.10704v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10704v1)
- **Published**: 2020-06-18 17:38:38+00:00
- **Updated**: 2020-06-18 17:38:38+00:00
- **Authors**: Ruslan Rakhimov, Denis Volkhonskiy, Alexey Artemov, Denis Zorin, Evgeny Burnaev
- **Comment**: None
- **Journal**: None
- **Summary**: The video generation task can be formulated as a prediction of future video frames given some past frames. Recent generative models for videos face the problem of high computational requirements. Some models require up to 512 Tensor Processing Units for parallel training. In this work, we address this problem via modeling the dynamics in a latent space. After the transformation of frames into the latent space, our model predicts latent representation for the next frames in an autoregressive manner. We demonstrate the performance of our approach on BAIR Robot Pushing and Kinetics-600 datasets. The approach tends to reduce requirements to 8 Graphical Processing Units for training the models while maintaining comparable generation quality.



### Set Distribution Networks: a Generative Model for Sets of Images
- **Arxiv ID**: http://arxiv.org/abs/2006.10705v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10705v1)
- **Published**: 2020-06-18 17:38:56+00:00
- **Updated**: 2020-06-18 17:38:56+00:00
- **Authors**: Shuangfei Zhai, Walter Talbott, Miguel Angel Bautista, Carlos Guestrin, Josh M. Susskind
- **Comment**: None
- **Journal**: None
- **Summary**: Images with shared characteristics naturally form sets. For example, in a face verification benchmark, images of the same identity form sets. For generative models, the standard way of dealing with sets is to represent each as a one hot vector, and learn a conditional generative model $p(\mathbf{x}|\mathbf{y})$. This representation assumes that the number of sets is limited and known, such that the distribution over sets reduces to a simple multinomial distribution. In contrast, we study a more generic problem where the number of sets is large and unknown. We introduce Set Distribution Networks (SDNs), a novel framework that learns to autoencode and freely generate sets. We achieve this by jointly learning a set encoder, set discriminator, set generator, and set prior. We show that SDNs are able to reconstruct image sets that preserve salient attributes of the inputs in our benchmark datasets, and are also able to generate novel objects/identities. We examine the sets generated by SDN with a pre-trained 3D reconstruction network and a face verification network, respectively, as a novel way to evaluate the quality of generated sets of images.



### Task-agnostic Out-of-Distribution Detection Using Kernel Density Estimation
- **Arxiv ID**: http://arxiv.org/abs/2006.10712v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10712v4)
- **Published**: 2020-06-18 17:46:06+00:00
- **Updated**: 2021-03-30 21:55:47+00:00
- **Authors**: Ertunc Erdil, Krishna Chaitanya, Neerav Karani, Ender Konukoglu
- **Comment**: None
- **Journal**: None
- **Summary**: In the recent years, researchers proposed a number of successful methods to perform out-of-distribution (OOD) detection in deep neural networks (DNNs). So far the scope of the highly accurate methods has been limited to image level classification tasks. However, attempts for generally applicable methods beyond classification did not attain similar performance. In this paper, we address this limitation by proposing a simple yet effective task-agnostic OOD detection method. We estimate the probability density functions (pdfs) of intermediate features of a pre-trained DNN by performing kernel density estimation (KDE) on the training dataset. As direct application of KDE to feature maps is hindered by their high dimensionality, we use a set of lower-dimensional marginalized KDE models instead of a single high-dimensional one. At test time, we evaluate the pdfs on a test sample and produce a confidence score that indicates the sample is OOD. The use of KDE eliminates the need for making simplifying assumptions about the underlying feature pdfs and makes the proposed method task-agnostic. We perform extensive experiments on classification tasks using benchmark datasets for OOD detection. Additionally, we perform experiments on medical image segmentation tasks using brain MRI datasets. The results demonstrate that the proposed method consistently achieves high OOD detection performance in both classification and segmentation tasks and improves state-of-the-art in almost all cases. Code is available at \url{https://github.com/eerdil/task_agnostic_ood}



### Zero-Shot Learning with Common Sense Knowledge Graphs
- **Arxiv ID**: http://arxiv.org/abs/2006.10713v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10713v4)
- **Published**: 2020-06-18 17:46:17+00:00
- **Updated**: 2022-08-25 19:27:00+00:00
- **Authors**: Nihal V. Nayak, Stephen H. Bach
- **Comment**: Paper published in TMLR
- **Journal**: None
- **Summary**: Zero-shot learning relies on semantic class representations such as hand-engineered attributes or learned embeddings to predict classes without any labeled examples. We propose to learn class representations by embedding nodes from common sense knowledge graphs in a vector space. Common sense knowledge graphs are an untapped source of explicit high-level knowledge that requires little human effort to apply to a range of tasks. To capture the knowledge in the graph, we introduce ZSL-KG, a general-purpose framework with a novel transformer graph convolutional network (TrGCN) for generating class representations. Our proposed TrGCN architecture computes non-linear combinations of node neighbourhoods. Our results show that ZSL-KG improves over existing WordNet-based methods on five out of six zero-shot benchmark datasets in language and vision.



### Ocean: Object-aware Anchor-free Tracking
- **Arxiv ID**: http://arxiv.org/abs/2006.10721v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10721v2)
- **Published**: 2020-06-18 17:51:39+00:00
- **Updated**: 2020-07-09 17:00:21+00:00
- **Authors**: Zhipeng Zhang, Houwen Peng, Jianlong Fu, Bing Li, Weiming Hu
- **Comment**: Accepted by ECCV2020
- **Journal**: ECCV2020
- **Summary**: Anchor-based Siamese trackers have achieved remarkable advancements in accuracy, yet the further improvement is restricted by the lagged tracking robustness. We find the underlying reason is that the regression network in anchor-based methods is only trained on the positive anchor boxes (i.e., $IoU \geq0.6$). This mechanism makes it difficult to refine the anchors whose overlap with the target objects are small. In this paper, we propose a novel object-aware anchor-free network to address this issue. First, instead of refining the reference anchor boxes, we directly predict the position and scale of target objects in an anchor-free fashion. Since each pixel in groundtruth boxes is well trained, the tracker is capable of rectifying inexact predictions of target objects during inference. Second, we introduce a feature alignment module to learn an object-aware feature from predicted bounding boxes. The object-aware feature can further contribute to the classification of target objects and background. Moreover, we present a novel tracking framework based on the anchor-free model. The experiments show that our anchor-free tracker achieves state-of-the-art performance on five benchmarks, including VOT-2018, VOT-2019, OTB-100, GOT-10k and LaSOT. The source code is available at https://github.com/researchmm/TracKit.



### Cyclic Differentiable Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2006.10724v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10724v4)
- **Published**: 2020-06-18 17:55:19+00:00
- **Updated**: 2022-04-25 06:20:19+00:00
- **Authors**: Hongyuan Yu, Houwen Peng, Yan Huang, Jianlong Fu, Hao Du, Liang Wang, Haibin Ling
- **Comment**: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)
- **Journal**: None
- **Summary**: Differentiable ARchiTecture Search, i.e., DARTS, has drawn great attention in neural architecture search. It tries to find the optimal architecture in a shallow search network and then measures its performance in a deep evaluation network. The independent optimization of the search and evaluation networks, however, leaves room for potential improvement by allowing interaction between the two networks. To address the problematic optimization issue, we propose new joint optimization objectives and a novel Cyclic Differentiable ARchiTecture Search framework, dubbed CDARTS. Considering the structure difference, CDARTS builds a cyclic feedback mechanism between the search and evaluation networks with introspective distillation. First, the search network generates an initial architecture for evaluation, and the weights of the evaluation network are optimized. Second, the architecture weights in the search network are further optimized by the label supervision in classification, as well as the regularization from the evaluation network through feature distillation. Repeating the above cycle results in joint optimization of the search and evaluation networks and thus enables the evolution of the architecture to fit the final evaluation network. The experiments and analysis on CIFAR, ImageNet and NAS-Bench-201 demonstrate the effectiveness of the proposed approach over the state-of-the-art ones. Specifically, in the DARTS search space, we achieve 97.52% top-1 accuracy on CIFAR10 and 76.3% top-1 accuracy on ImageNet. In the chain-structured search space, we achieve 78.2% top-1 accuracy on ImageNet, which is 1.1% higher than EfficientNet-B0. Our code and models are publicly available at https://github.com/microsoft/Cream.



### Tent: Fully Test-time Adaptation by Entropy Minimization
- **Arxiv ID**: http://arxiv.org/abs/2006.10726v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10726v3)
- **Published**: 2020-06-18 17:55:28+00:00
- **Updated**: 2021-03-18 17:58:01+00:00
- **Authors**: Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, Trevor Darrell
- **Comment**: ICLR 2021 Spotlight
- **Journal**: None
- **Summary**: A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent): we optimize the model for confidence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training.



### Diverse Image Generation via Self-Conditioned GANs
- **Arxiv ID**: http://arxiv.org/abs/2006.10728v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10728v2)
- **Published**: 2020-06-18 17:56:03+00:00
- **Updated**: 2022-02-10 01:57:02+00:00
- **Authors**: Steven Liu, Tongzhou Wang, David Bau, Jun-Yan Zhu, Antonio Torralba
- **Comment**: CVPR 2020. Code: https://github.com/stevliu/self-conditioned-gan.
  Webpage: http://selfcondgan.csail.mit.edu/
- **Journal**: None
- **Summary**: We introduce a simple but effective unsupervised method for generating realistic and diverse images. We train a class-conditional GAN model without using manually annotated class labels. Instead, our model is conditional on labels automatically derived from clustering in the discriminator's feature space. Our clustering step automatically discovers diverse modes, and explicitly requires the generator to cover them. Experiments on standard mode collapse benchmarks show that our method outperforms several competing methods when addressing mode collapse. Our method also performs well on large-scale datasets such as ImageNet and Places365, improving both image diversity and standard quality metrics, compared to previous methods.



### Spin-Weighted Spherical CNNs
- **Arxiv ID**: http://arxiv.org/abs/2006.10731v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10731v2)
- **Published**: 2020-06-18 17:57:21+00:00
- **Updated**: 2020-10-26 17:38:17+00:00
- **Authors**: Carlos Esteves, Ameesh Makadia, Kostas Daniilidis
- **Comment**: Accepted to NeurIPS'20
- **Journal**: None
- **Summary**: Learning equivariant representations is a promising way to reduce sample and model complexity and improve the generalization performance of deep neural networks. The spherical CNNs are successful examples, producing SO(3)-equivariant representations of spherical inputs. There are two main types of spherical CNNs. The first type lifts the inputs to functions on the rotation group SO(3) and applies convolutions on the group, which are computationally expensive since SO(3) has one extra dimension. The second type applies convolutions directly on the sphere, which are limited to zonal (isotropic) filters, and thus have limited expressivity. In this paper, we present a new type of spherical CNN that allows anisotropic filters in an efficient way, without ever leaving the spherical domain. The key idea is to consider spin-weighted spherical functions, which were introduced in physics in the study of gravitational waves. These are complex-valued functions on the sphere whose phases change upon rotation. We define a convolution between spin-weighted functions and build a CNN based on it. The spin-weighted functions can also be interpreted as spherical vector fields, allowing applications to tasks where the inputs or outputs are vector fields. Experiments show that our method outperforms previous methods on tasks like classification of spherical images, classification of 3D shapes and semantic segmentation of spherical panoramas.



### Forward Prediction for Physical Reasoning
- **Arxiv ID**: http://arxiv.org/abs/2006.10734v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10734v2)
- **Published**: 2020-06-18 17:57:42+00:00
- **Updated**: 2021-03-29 19:41:24+00:00
- **Authors**: Rohit Girdhar, Laura Gustafson, Aaron Adcock, Laurens van der Maaten
- **Comment**: Webpage/code/models: https://facebookresearch.github.io/phyre-fwd/
- **Journal**: None
- **Summary**: Physical reasoning requires forward prediction: the ability to forecast what will happen next given some initial world state. We study the performance of state-of-the-art forward-prediction models in the complex physical-reasoning tasks of the PHYRE benchmark. We do so by incorporating models that operate on object or pixel-based representations of the world into simple physical-reasoning agents. We find that forward-prediction models can improve physical-reasoning performance, particularly on complex tasks that involve many objects. However, we also find that these improvements are contingent on the test tasks being small variations of train tasks, and that generalization to completely new task templates is challenging. Surprisingly, we observe that forward predictors with better pixel accuracy do not necessarily lead to better physical-reasoning performance.Nevertheless, our best models set a new state-of-the-art on the PHYRE benchmark.



### Differentiable Augmentation for Data-Efficient GAN Training
- **Arxiv ID**: http://arxiv.org/abs/2006.10738v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10738v4)
- **Published**: 2020-06-18 17:59:01+00:00
- **Updated**: 2020-12-07 05:51:53+00:00
- **Authors**: Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, Song Han
- **Comment**: NeurIPS 2020. Project: https://data-efficient-gans.mit.edu/ Code:
  https://github.com/mit-han-lab/data-efficient-gans
- **Journal**: None
- **Summary**: The performance of generative adversarial networks (GANs) heavily deteriorates given a limited amount of training data. This is mainly because the discriminator is memorizing the exact training set. To combat it, we propose Differentiable Augmentation (DiffAugment), a simple method that improves the data efficiency of GANs by imposing various types of differentiable augmentations on both real and fake samples. Previous attempts to directly augment the training data manipulate the distribution of real images, yielding little benefit; DiffAugment enables us to adopt the differentiable augmentation for the generated samples, effectively stabilizes training, and leads to better convergence. Experiments demonstrate consistent gains of our method over a variety of GAN architectures and loss functions for both unconditional and class-conditional generation. With DiffAugment, we achieve a state-of-the-art FID of 6.80 with an IS of 100.8 on ImageNet 128x128 and 2-4x reductions of FID given 1,000 images on FFHQ and LSUN. Furthermore, with only 20% training data, we can match the top performance on CIFAR-10 and CIFAR-100. Finally, our method can generate high-fidelity images using only 100 images without pre-training, while being on par with existing transfer learning algorithms. Code is available at https://github.com/mit-han-lab/data-efficient-gans.



### Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains
- **Arxiv ID**: http://arxiv.org/abs/2006.10739v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10739v1)
- **Published**: 2020-06-18 17:59:11+00:00
- **Updated**: 2020-06-18 17:59:11+00:00
- **Authors**: Matthew Tancik, Pratul P. Srinivasan, Ben Mildenhall, Sara Fridovich-Keil, Nithin Raghavan, Utkarsh Singhal, Ravi Ramamoorthi, Jonathan T. Barron, Ren Ng
- **Comment**: Project page: https://people.eecs.berkeley.edu/~bmild/fourfeat/
- **Journal**: None
- **Summary**: We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.



### Bootstrapping Complete The Look at Pinterest
- **Arxiv ID**: http://arxiv.org/abs/2006.10792v2
- **DOI**: 10.1145/3394486.3403382
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10792v2)
- **Published**: 2020-06-18 18:20:19+00:00
- **Updated**: 2020-06-29 18:24:47+00:00
- **Authors**: Eileen Li, Eric Kim, Andrew Zhai, Josh Beal, Kunlong Gu
- **Comment**: 9 pages, 12 figures, To be published in KDD '20
- **Journal**: None
- **Summary**: Putting together an ideal outfit is a process that involves creativity and style intuition. This makes it a particularly difficult task to automate. Existing styling products generally involve human specialists and a highly curated set of fashion items. In this paper, we will describe how we bootstrapped the Complete The Look (CTL) system at Pinterest. This is a technology that aims to learn the subjective task of "style compatibility" in order to recommend complementary items that complete an outfit. In particular, we want to show recommendations from other categories that are compatible with an item of interest. For example, what are some heels that go well with this cocktail dress? We will introduce our outfit dataset of over 1 million outfits and 4 million objects, a subset of which we will make available to the research community, and describe the pipeline used to obtain and refresh this dataset. Furthermore, we will describe how we evaluate this subjective task and compare model performance across multiple training methods. Lastly, we will share our lessons going from experimentation to working prototype, and how to mitigate failure modes in the production environment. Our work represents one of the first examples of an industrial-scale solution for compatibility-based fashion recommendation.



### DS6, Deformation-aware Semi-supervised Learning: Application to Small Vessel Segmentation with Noisy Training Data
- **Arxiv ID**: http://arxiv.org/abs/2006.10802v3
- **DOI**: 10.3390/jimaging8100259
- **Categories**: **eess.IV**, cs.CV, cs.LG, 68T07 (Primary) 68T45 (Secondary), I.2.6; I.4.6
- **Links**: [PDF](http://arxiv.org/pdf/2006.10802v3)
- **Published**: 2020-06-18 18:42:57+00:00
- **Updated**: 2022-09-25 08:40:58+00:00
- **Authors**: Soumick Chatterjee, Kartik Prabhu, Mahantesh Pattadkal, Gerda Bortsova, Chompunuch Sarasaen, Florian Dubost, Hendrik Mattern, Marleen de Bruijne, Oliver Speck, Andreas Nürnberger
- **Comment**: None
- **Journal**: Journal of Imaging. 2022; 8(10):259
- **Summary**: Blood vessels of the brain provide the human brain with the required nutrients and oxygen. As a vulnerable part of the cerebral blood supply, pathology of small vessels can cause serious problems such as Cerebral Small Vessel Diseases (CSVD). It has also been shown that CSVD is related to neurodegeneration, such as Alzheimer's disease. With the advancement of 7 Tesla MRI systems, higher spatial image resolution can be achieved, enabling the depiction of very small vessels in the brain. Non-Deep Learning-based approaches for vessel segmentation, e.g., Frangi's vessel enhancement with subsequent thresholding, are capable of segmenting medium to large vessels but often fail to segment small vessels. The sensitivity of these methods to small vessels can be increased by extensive parameter tuning or by manual corrections, albeit making them time-consuming, laborious, and not feasible for larger datasets. This paper proposes a deep learning architecture to automatically segment small vessels in 7 Tesla 3D Time-of-Flight (ToF) Magnetic Resonance Angiography (MRA) data. The algorithm was trained and evaluated on a small imperfect semi-automatically segmented dataset of only 11 subjects; using six for training, two for validation, and three for testing. The deep learning model based on U-Net Multi-Scale Supervision was trained using the training subset and was made equivariant to elastic deformations in a self-supervised manner using deformation-aware learning to improve the generalisation performance. The proposed technique was evaluated quantitatively and qualitatively against the test set and achieved a Dice score of 80.44 $\pm$ 0.83. Furthermore, the result of the proposed method was compared against a selected manually segmented region (62.07 resultant Dice) and has shown a considerable improvement (18.98\%) with deformation-aware learning.



### Supervision Accelerates Pre-training in Contrastive Semi-Supervised Learning of Visual Representations
- **Arxiv ID**: http://arxiv.org/abs/2006.10803v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.10803v2)
- **Published**: 2020-06-18 18:44:13+00:00
- **Updated**: 2020-12-01 19:39:24+00:00
- **Authors**: Mahmoud Assran, Nicolas Ballas, Lluis Castrejon, Michael Rabbat
- **Comment**: None
- **Journal**: None
- **Summary**: We investigate a strategy for improving the efficiency of contrastive learning of visual representations by leveraging a small amount of supervised information during pre-training. We propose a semi-supervised loss, SuNCEt, based on noise-contrastive estimation and neighbourhood component analysis, that aims to distinguish examples of different classes in addition to the self-supervised instance-wise pretext tasks. On ImageNet, we find that SuNCEt can be used to match the semi-supervised learning accuracy of previous contrastive approaches while using less than half the amount of pre-training and compute. Our main insight is that leveraging even a small amount of labeled data during pre-training, and not only during fine-tuning, provides an important signal that can significantly accelerate contrastive learning of visual representations. Our code is available online at github.com/facebookresearch/suncet.



### Learning non-rigid surface reconstruction from spatio-temporal image patches
- **Arxiv ID**: http://arxiv.org/abs/2006.10841v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10841v1)
- **Published**: 2020-06-18 20:25:15+00:00
- **Updated**: 2020-06-18 20:25:15+00:00
- **Authors**: Matteo Pedone, Abdelrahman Mostafa, Janne heikkilä
- **Comment**: None
- **Journal**: None
- **Summary**: We present a method to reconstruct a dense spatio-temporal depth map of a non-rigidly deformable object directly from a video sequence. The estimation of depth is performed locally on spatio-temporal patches of the video, and then the full depth video of the entire shape is recovered by combining them together. Since the geometric complexity of a local spatio-temporal patch of a deforming non-rigid object is often simple enough to be faithfully represented with a parametric model, we artificially generate a database of small deforming rectangular meshes rendered with different material properties and light conditions, along with their corresponding depth videos, and use such data to train a convolutional neural network. We tested our method on both synthetic and Kinect data and experimentally observed that the reconstruction error is significantly lower than the one obtained using other approaches like conventional non-rigid structure from motion.



### Understanding Anomaly Detection with Deep Invertible Networks through Hierarchies of Distributions and Features
- **Arxiv ID**: http://arxiv.org/abs/2006.10848v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2006.10848v3)
- **Published**: 2020-06-18 20:56:14+00:00
- **Updated**: 2020-11-02 17:27:25+00:00
- **Authors**: Robin Tibor Schirrmeister, Yuxuan Zhou, Tonio Ball, Dan Zhang
- **Comment**: Published at NeurIPS 2020. Code can be found at
  https://github.com/boschresearch/hierarchical_anomaly_detection
- **Journal**: None
- **Summary**: Deep generative networks trained via maximum likelihood on a natural image dataset like CIFAR10 often assign high likelihoods to images from datasets with different objects (e.g., SVHN). We refine previous investigations of this failure at anomaly detection for invertible generative networks and provide a clear explanation of it as a combination of model bias and domain prior: Convolutional networks learn similar low-level feature distributions when trained on any natural image dataset and these low-level features dominate the likelihood. Hence, when the discriminative features between inliers and outliers are on a high-level, e.g., object shapes, anomaly detection becomes particularly challenging. To remove the negative impact of model bias and domain prior on detecting high-level differences, we propose two methods, first, using the log likelihood ratios of two identical models, one trained on the in-distribution data (e.g., CIFAR10) and the other one on a more general distribution of images (e.g., 80 Million Tiny Images). We also derive a novel outlier loss for the in-distribution network on samples from the more general distribution to further improve the performance. Secondly, using a multi-scale model like Glow, we show that low-level features are mainly captured at early scales. Therefore, using only the likelihood contribution of the final scale performs remarkably well for detecting high-level feature differences of the out-of-distribution and the in-distribution. This method is especially useful if one does not have access to a suitable general distribution. Overall, our methods achieve strong anomaly detection performance in the unsupervised setting, and only slightly underperform state-of-the-art classifier-based methods in the supervised setting. Code can be found at https://github.com/boschresearch/hierarchical_anomaly_detection.



### Deep Image Translation for Enhancing Simulated Ultrasound Images
- **Arxiv ID**: http://arxiv.org/abs/2006.10850v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10850v1)
- **Published**: 2020-06-18 21:05:27+00:00
- **Updated**: 2020-06-18 21:05:27+00:00
- **Authors**: Lin Zhang, Tiziano Portenier, Christoph Paulus, Orcun Goksel
- **Comment**: None
- **Journal**: None
- **Summary**: Ultrasound simulation based on ray tracing enables the synthesis of highly realistic images. It can provide an interactive environment for training sonographers as an educational tool. However, due to high computational demand, there is a trade-off between image quality and interactivity, potentially leading to sub-optimal results at interactive rates. In this work we introduce a deep learning approach based on adversarial training that mitigates this trade-off by improving the quality of simulated images with constant computation time. An image-to-image translation framework is utilized to translate low quality images into high quality versions. To incorporate anatomical information potentially lost in low quality images, we additionally provide segmentation maps to image translation. Furthermore, we propose to leverage information from acoustic attenuation maps to better preserve acoustic shadows and directional artifacts, an invaluable feature for ultrasound image interpretation. The proposed method yields an improvement of 7.2% in Fr\'{e}chet Inception Distance and 8.9% in patch-based Kullback-Leibler divergence.



### Image classification in frequency domain with 2SReLU: a second harmonics superposition activation function
- **Arxiv ID**: http://arxiv.org/abs/2006.10853v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10853v1)
- **Published**: 2020-06-18 21:11:43+00:00
- **Updated**: 2020-06-18 21:11:43+00:00
- **Authors**: Thomio Watanabe, Denis F. Wolf
- **Comment**: 12 pages, 9 figures
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks are able to identify complex patterns and perform tasks with super-human capabilities. However, besides the exceptional results, they are not completely understood and it is still impractical to hand-engineer similar solutions. In this work, an image classification Convolutional Neural Network and its building blocks are described from a frequency domain perspective. Some network layers have established counterparts in the frequency domain like the convolutional and pooling layers. We propose the 2SReLU layer, a novel non-linear activation function that preserves high frequency components in deep networks. It is demonstrated that in the frequency domain it is possible to achieve competitive results without using the computationally costly convolution operation. A source code implementation in PyTorch is provided at: https://gitlab.com/thomio/2srelu



### Shop The Look: Building a Large Scale Visual Shopping System at Pinterest
- **Arxiv ID**: http://arxiv.org/abs/2006.10866v1
- **DOI**: 10.1145/3394486.3403372
- **Categories**: **cs.CV**, I.2.10; I.4.8; I.4.9; I.4.10; I.5.4; K.4.4
- **Links**: [PDF](http://arxiv.org/pdf/2006.10866v1)
- **Published**: 2020-06-18 21:38:07+00:00
- **Updated**: 2020-06-18 21:38:07+00:00
- **Authors**: Raymond Shiau, Hao-Yu Wu, Eric Kim, Yue Li Du, Anqi Guo, Zhiyuan Zhang, Eileen Li, Kunlong Gu, Charles Rosenberg, Andrew Zhai
- **Comment**: 10 pages, 7 figures, Accepted to KDD'20
- **Journal**: None
- **Summary**: As online content becomes ever more visual, the demand for searching by visual queries grows correspondingly stronger. Shop The Look is an online shopping discovery service at Pinterest, leveraging visual search to enable users to find and buy products within an image. In this work, we provide a holistic view of how we built Shop The Look, a shopping oriented visual search system, along with lessons learned from addressing shopping needs. We discuss topics including core technology across object detection and visual embeddings, serving infrastructure for realtime inference, and data labeling methodology for training/evaluation data collection and human evaluation. The user-facing impacts of our system design choices are measured through offline evaluations, human relevance judgements, and online A/B experiments. The collective improvements amount to cumulative relative gains of over 160% in end-to-end human relevance judgements and over 80% in engagement. Shop The Look is deployed in production at Pinterest.



### Model-Aware Regularization For Learning Approaches To Inverse Problems
- **Arxiv ID**: http://arxiv.org/abs/2006.10869v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10869v1)
- **Published**: 2020-06-18 21:59:03+00:00
- **Updated**: 2020-06-18 21:59:03+00:00
- **Authors**: Jaweria Amjad, Zhaoyan Lyu, Miguel R. D. Rodrigues
- **Comment**: None
- **Journal**: None
- **Summary**: There are various inverse problems -- including reconstruction problems arising in medical imaging -- where one is often aware of the forward operator that maps variables of interest to the observations. It is therefore natural to ask whether such knowledge of the forward operator can be exploited in deep learning approaches increasingly used to solve inverse problems.   In this paper, we provide one such way via an analysis of the generalisation error of deep learning methods applicable to inverse problems. In particular, by building on the algorithmic robustness framework, we offer a generalisation error bound that encapsulates key ingredients associated with the learning problem such as the complexity of the data space, the size of the training set, the Jacobian of the deep neural network and the Jacobian of the composition of the forward operator with the neural network. We then propose a 'plug-and-play' regulariser that leverages the knowledge of the forward map to improve the generalization of the network. We likewise also propose a new method allowing us to tightly upper bound the Lipschitz constants of the relevant functions that is much more computational efficient than existing ones. We demonstrate the efficacy of our model-aware regularised deep learning algorithms against other state-of-the-art approaches on inverse problems involving various sub-sampling operators such as those used in classical compressed sensing setup and accelerated Magnetic Resonance Imaging (MRI).



### Generative Patch Priors for Practical Compressive Image Recovery
- **Arxiv ID**: http://arxiv.org/abs/2006.10873v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10873v2)
- **Published**: 2020-06-18 22:24:46+00:00
- **Updated**: 2020-10-05 16:51:14+00:00
- **Authors**: Rushil Anirudh, Suhas Lohit, Pavan Turaga
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose the generative patch prior (GPP) that defines a generative prior for compressive image recovery, based on patch-manifold models. Unlike learned, image-level priors that are restricted to the range space of a pre-trained generator, GPP can recover a wide variety of natural images using a pre-trained patch generator. Additionally, GPP retains the benefits of generative priors like high reconstruction quality at extremely low sensing rates, while also being much more generally applicable. We show that GPP outperforms several unsupervised and supervised techniques on three different sensing models -- linear compressive sensing with known, and unknown calibration settings, and the non-linear phase retrieval problem. Finally, we propose an alternating optimization strategy using GPP for joint calibration-and-reconstruction which performs favorably against several baselines on a real world, un-calibrated compressive sensing dataset.



