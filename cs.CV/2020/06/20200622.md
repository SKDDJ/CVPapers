# Arxiv Papers in cs.CV on 2020-06-22
### Emerging Biometrics: Deep Inference and Other Computational Intelligence
- **Arxiv ID**: http://arxiv.org/abs/2006.11971v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2006.11971v1)
- **Published**: 2020-06-22 02:35:00+00:00
- **Updated**: 2020-06-22 02:35:00+00:00
- **Authors**: Svetlana Yanushkevich, Shawn Eastwood, Kenneth Lai, Vlad Shmerko
- **Comment**: Survey paper
- **Journal**: None
- **Summary**: This paper aims at identifying emerging computational intelligence trends for the design and modeling of complex biometric-enabled infrastructure and systems. Biometric-enabled systems are evolving towards deep learning and deep inference using the principles of adaptive computing, - the front tides of the modern computational intelligence domain. Therefore, we focus on intelligent inference engines widely deployed in biometrics. Computational intelligence applications that cover a wide spectrum of biometric tasks using physiological and behavioral traits are chosen for illustration. We highlight the technology gaps that must be addressed in future generations of biometric systems. The reported approaches and results primarily address the researchers who work towards developing the next generation of intelligent biometric-enabled systems.



### ELF: An Early-Exiting Framework for Long-Tailed Classification
- **Arxiv ID**: http://arxiv.org/abs/2006.11979v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11979v2)
- **Published**: 2020-06-22 02:54:26+00:00
- **Updated**: 2020-09-13 17:12:03+00:00
- **Authors**: Rahul Duggal, Scott Freitas, Sunny Dhamnani, Duen Horng Chau, Jimeng Sun
- **Comment**: None
- **Journal**: None
- **Summary**: The natural world often follows a long-tailed data distribution where only a few classes account for most of the examples. This long-tail causes classifiers to overfit to the majority class. To mitigate this, prior solutions commonly adopt class rebalancing strategies such as data resampling and loss reshaping. However, by treating each example within a class equally, these methods fail to account for the important notion of example hardness, i.e., within each class some examples are easier to classify than others. To incorporate this notion of hardness into the learning process, we propose the EarLy-exiting Framework(ELF). During training, ELF learns to early-exit easy examples through auxiliary branches attached to a backbone network. This offers a dual benefit-(1) the neural network increasingly focuses on hard examples, since they contribute more to the overall network loss; and (2) it frees up additional model capacity to distinguish difficult examples. Experimental results on two large-scale datasets, ImageNet LT and iNaturalist'18, demonstrate that ELF can improve state-of-the-art accuracy by more than 3 percent. This comes with the additional benefit of reducing up to 20 percent of inference time FLOPS. ELF is complementary to prior work and can naturally integrate with a variety of existing methods to tackle the challenge of long-tailed distributions.



### COVID-19 Image Data Collection: Prospective Predictions Are the Future
- **Arxiv ID**: http://arxiv.org/abs/2006.11988v3
- **DOI**: 10.59275/j.melba.2020-48g7
- **Categories**: **q-bio.QM**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11988v3)
- **Published**: 2020-06-22 03:20:36+00:00
- **Updated**: 2020-12-14 18:52:43+00:00
- **Authors**: Joseph Paul Cohen, Paul Morrison, Lan Dao, Karsten Roth, Tim Q Duong, Marzyeh Ghassemi
- **Comment**: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org. Code for baseline
  experiments can be found here: https://github.com/mlmed/covid-baselines
- **Journal**: None
- **Summary**: Across the world's coronavirus disease 2019 (COVID-19) hot spots, the need to streamline patient diagnosis and management has become more pressing than ever. As one of the main imaging tools, chest X-rays (CXRs) are common, fast, non-invasive, relatively cheap, and potentially bedside to monitor the progression of the disease. This paper describes the first public COVID-19 image data collection as well as a preliminary exploration of possible use cases for the data. This dataset currently contains hundreds of frontal view X-rays and is the largest public resource for COVID-19 image and prognostic data, making it a necessary resource to develop and evaluate tools to aid in the treatment of COVID-19. It was manually aggregated from publication figures as well as various web based repositories into a machine learning (ML) friendly format with accompanying dataloader code. We collected frontal and lateral view imagery and metadata such as the time since first symptoms, intensive care unit (ICU) status, survival status, intubation status, or hospital location. We present multiple possible use cases for the data such as predicting the need for the ICU, predicting patient survival, and understanding a patient's trajectory during treatment. Data can be accessed here: https://github.com/ieee8023/covid-chestxray-dataset



### Global Image Sentiment Transfer
- **Arxiv ID**: http://arxiv.org/abs/2006.11989v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11989v1)
- **Published**: 2020-06-22 03:22:25+00:00
- **Updated**: 2020-06-22 03:22:25+00:00
- **Authors**: Jie An, Tianlang Chen, Songyang Zhang, Jiebo Luo
- **Comment**: None
- **Journal**: None
- **Summary**: Transferring the sentiment of an image is an unexplored research topic in the area of computer vision. This work proposes a novel framework consisting of a reference image retrieval step and a global sentiment transfer step to transfer sentiments of images according to a given sentiment tag. The proposed image retrieval algorithm is based on the SSIM index. The retrieved reference images by the proposed algorithm are more content-related against the algorithm based on the perceptual loss. Therefore can lead to a better image sentiment transfer result. In addition, we propose a global sentiment transfer step, which employs an optimization algorithm to iteratively transfer sentiment of images based on feature maps produced by the Densenet121 architecture. The proposed sentiment transfer algorithm can transfer the sentiment of images while ensuring the content structure of the input image intact. The qualitative and quantitative experiments demonstrate that the proposed sentiment transfer framework outperforms existing artistic and photorealistic style transfer algorithms in making reliable sentiment transfer results with rich and exact details.



### Computational Enhancement of Molecularly Targeted Contrast-Enhanced Ultrasound: Application to Human Breast Tumor Imaging
- **Arxiv ID**: http://arxiv.org/abs/2006.11993v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11993v1)
- **Published**: 2020-06-22 03:45:52+00:00
- **Updated**: 2020-06-22 03:45:52+00:00
- **Authors**: Andrew A. Berlin, Mon Young, Ahmed El Kaffas, Sam Gambhir, Amelie Lutz, Maria Luigia Storto, Juergen Willmann
- **Comment**: None
- **Journal**: None
- **Summary**: Molecularly targeted contrast enhanced ultrasound (mCEUS) is a clinically promising approach for early cancer detection through targeted imaging of VEGFR2 (KDR) receptors. We have developed computational enhancement techniques for mCEUS tailored to address the unique challenges of imaging contrast accumulation in humans. These techniques utilize dynamic analysis to distinguish molecularly bound contrast agent from other contrast-mode signal sources, enabling analysis of contrast agent accumulation to be performed during contrast bolus arrival when the signal due to molecular binding is strongest.   Applied to the 18 human patient examinations of the first-in-human molecular ultrasound breast lesion study, computational enhancement improved the ability to differentiate between pathology-proven lesion and pathology-proven normal tissue in real-world human examination conditions that involved both patient and probe motion, with improvements in contrast ratio between lesion and normal tissue that in most cases exceed an order of magnitude (10x). Notably, computational enhancement eliminated a false positive result in which tissue leakage signal was misinterpreted by radiologists to be contrast agent accumulation.



### Modeling Lost Information in Lossy Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2006.11999v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11999v3)
- **Published**: 2020-06-22 04:04:56+00:00
- **Updated**: 2020-07-08 01:55:56+00:00
- **Authors**: Yaolong Wang, Mingqing Xiao, Chang Liu, Shuxin Zheng, Tie-Yan Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Lossy image compression is one of the most commonly used operators for digital images. Most recently proposed deep-learning-based image compression methods leverage the auto-encoder structure, and reach a series of promising results in this field. The images are encoded into low dimensional latent features first, and entropy coded subsequently by exploiting the statistical redundancy. However, the information lost during encoding is unfortunately inevitable, which poses a significant challenge to the decoder to reconstruct the original images. In this work, we propose a novel invertible framework called Invertible Lossy Compression (ILC) to largely mitigate the information loss problem. Specifically, ILC introduces an invertible encoding module to replace the encoder-decoder structure to produce the low dimensional informative latent representation, meanwhile, transform the lost information into an auxiliary latent variable that won't be further coded or stored. The latent representation is quantized and encoded into bit-stream, and the latent variable is forced to follow a specified distribution, i.e. isotropic Gaussian distribution. In this way, recovering the original image is made tractable by easily drawing a surrogate latent variable and applying the inverse pass of the module with the sampled variable and decoded latent features. Experimental results demonstrate that with a new component replacing the auto-encoder in image compression methods, ILC can significantly outperform the baseline method on extensive benchmark datasets by combining with the existing compression algorithms.



### MaskIt: Masking for efficient utilization of incomplete public datasets for training deep learning models
- **Arxiv ID**: http://arxiv.org/abs/2006.12004v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12004v1)
- **Published**: 2020-06-22 04:49:41+00:00
- **Updated**: 2020-06-22 04:49:41+00:00
- **Authors**: Ankit Kariryaa
- **Comment**: 5 pages, 3 figures
- **Journal**: None
- **Summary**: A major challenge in training deep learning models is the lack of high quality and complete datasets. In the paper, we present a masking approach for training deep learning models from a publicly available but incomplete dataset. For example, city of Hamburg, Germany maintains a list of trees along the roads, but this dataset does not contain any information about trees in private homes and parks. To train a deep learning model on such a dataset, we mask the street trees and aerial images with the road network. Road network used for creating the mask is downloaded from OpenStreetMap, and it marks the area where the training data is available. The mask is passed to the model as one of the inputs and it also coats the output. Our model learns to successfully predict trees only in the masked region with 78.4% accuracy.



### Feature Alignment and Restoration for Domain Generalization and Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2006.12009v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12009v1)
- **Published**: 2020-06-22 05:08:13+00:00
- **Updated**: 2020-06-22 05:08:13+00:00
- **Authors**: Xin Jin, Cuiling Lan, Wenjun Zeng, Zhibo Chen
- **Comment**: None
- **Journal**: None
- **Summary**: For domain generalization (DG) and unsupervised domain adaptation (UDA), cross domain feature alignment has been widely explored to pull the feature distributions of different domains in order to learn domain-invariant representations. However, the feature alignment is in general task-ignorant and could result in degradation of the discrimination power of the feature representation and thus hinders the high performance. In this paper, we propose a unified framework termed Feature Alignment and Restoration (FAR) to simultaneously ensure high generalization and discrimination power of the networks for effective DG and UDA. Specifically, we perform feature alignment (FA) across domains by aligning the moments of the distributions of attentively selected features to reduce their discrepancy. To ensure high discrimination, we propose a Feature Restoration (FR) operation to distill task-relevant features from the residual information and use them to compensate for the aligned features. For better disentanglement, we enforce a dual ranking entropy loss constraint in the FR step to encourage the separation of task-relevant and task-irrelevant features. Extensive experiments on multiple classification benchmarks demonstrate the high performance and strong generalization of our FAR framework for both domain generalization and unsupervised domain adaptation.



### Towards Better Performance and More Explainable Uncertainty for 3D Object Detection of Autonomous Vehicles
- **Arxiv ID**: http://arxiv.org/abs/2006.12015v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2006.12015v2)
- **Published**: 2020-06-22 05:49:58+00:00
- **Updated**: 2020-08-17 21:37:14+00:00
- **Authors**: Hujie Pan, Zining Wang, Wei Zhan, Masayoshi Tomizuka
- **Comment**: ITSC2020
- **Journal**: None
- **Summary**: In this paper, we propose a novel form of the loss function to increase the performance of LiDAR-based 3d object detection and obtain more explainable and convincing uncertainty for the prediction. The loss function was designed using corner transformation and uncertainty modeling. With the new loss function, the performance of our method on the val split of KITTI dataset shows up to a 15% increase in terms of Average Precision (AP) comparing with the baseline using simple L1 Loss. In the study of the characteristics of predicted uncertainties, we find that generally more accurate prediction of the bounding box is usually accompanied by lower uncertainty. The distribution of corner uncertainties agrees on the distribution of the point cloud in the bounding box, which means the corner with denser observed points has lower uncertainty. Moreover, our method also learns the constraint from the cuboid geometry of the bounding box in uncertainty prediction. Finally, we propose an efficient Bayesian updating method to recover the uncertainty for the original parameters of the bounding boxes which can help to provide probabilistic results for the planning module.



### DO-Conv: Depthwise Over-parameterized Convolutional Layer
- **Arxiv ID**: http://arxiv.org/abs/2006.12030v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12030v1)
- **Published**: 2020-06-22 06:57:10+00:00
- **Updated**: 2020-06-22 06:57:10+00:00
- **Authors**: Jinming Cao, Yangyan Li, Mingchao Sun, Ying Chen, Dani Lischinski, Daniel Cohen-Or, Baoquan Chen, Changhe Tu
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional layers are the core building blocks of Convolutional Neural Networks (CNNs). In this paper, we propose to augment a convolutional layer with an additional depthwise convolution, where each input channel is convolved with a different 2D kernel. The composition of the two convolutions constitutes an over-parameterization, since it adds learnable parameters, while the resulting linear operation can be expressed by a single convolution layer. We refer to this depthwise over-parameterized convolutional layer as DO-Conv. We show with extensive experiments that the mere replacement of conventional convolutional layers with DO-Conv layers boosts the performance of CNNs on many classical vision tasks, such as image classification, detection, and segmentation. Moreover, in the inference phase, the depthwise convolution is folded into the conventional convolution, reducing the computation to be exactly equivalent to that of a convolutional layer without over-parameterization. As DO-Conv introduces performance gains without incurring any computational complexity increase for inference, we advocate it as an alternative to the conventional convolutional layer. We open-source a reference implementation of DO-Conv in Tensorflow, PyTorch and GluonCV at https://github.com/yangyanli/DO-Conv.



### Characterizing Hirability via Personality and Behavior
- **Arxiv ID**: http://arxiv.org/abs/2006.12041v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12041v1)
- **Published**: 2020-06-22 07:24:22+00:00
- **Updated**: 2020-06-22 07:24:22+00:00
- **Authors**: Harshit Malik, Hersh Dhillon, Roland Goecke, Ramanathan Subramanian
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: While personality traits have been extensively modeled as behavioral constructs, we model \textbf{\textit{job hirability}} as a \emph{personality construct}. On the {\emph{First Impressions Candidate Screening}} (FICS) dataset, we examine relationships among personality and hirability measures. Modeling hirability as a discrete/continuous variable with the \emph{big-five} personality traits as predictors, we utilize (a) apparent personality annotations, and (b) personality estimates obtained via audio, visual and textual cues for hirability prediction (HP). We also examine the efficacy of a two-step HP process involving (1) personality estimation from multimodal behavioral cues, followed by (2) HP from personality estimates.   Interesting results from experiments performed on $\approx$~5000 FICS videos are as follows. (1) For each of the \emph{text}, \emph{audio} and \emph{visual} modalities, HP via the above two-step process is more effective than directly predicting from behavioral cues. Superior results are achieved when hirability is modeled as a continuous vis-\'a-vis categorical variable. (2) Among visual cues, eye and bodily information achieve performance comparable to face cues for predicting personality and hirability. (3) Explanatory analyses reveal the impact of multimodal behavior on personality impressions; \eg, Conscientiousness impressions are impacted by the use of \emph{cuss words} (verbal behavior), and \emph{eye movements} (non-verbal behavior), confirming prior observations.



### Few-shot 3D Point Cloud Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.12052v2
- **DOI**: None
- **Categories**: **cs.CV**, I.2.10; I.4.6
- **Links**: [PDF](http://arxiv.org/pdf/2006.12052v2)
- **Published**: 2020-06-22 08:05:25+00:00
- **Updated**: 2021-03-29 05:55:06+00:00
- **Authors**: Na Zhao, Tat-Seng Chua, Gim Hee Lee
- **Comment**: CVPR 2021
- **Journal**: None
- **Summary**: Many existing approaches for 3D point cloud semantic segmentation are fully supervised. These fully supervised approaches heavily rely on large amounts of labeled training data that are difficult to obtain and cannot segment new classes after training. To mitigate these limitations, we propose a novel attention-aware multi-prototype transductive few-shot point cloud semantic segmentation method to segment new classes given a few labeled examples. Specifically, each class is represented by multiple prototypes to model the complex data distribution of labeled points. Subsequently, we employ a transductive label propagation method to exploit the affinities between labeled multi-prototypes and unlabeled points, and among the unlabeled points. Furthermore, we design an attention-aware multi-level feature learning network to learn the discriminative features that capture the geometric dependencies and semantic correlations between points. Our proposed method shows significant and consistent improvements compared to baselines in different few-shot point cloud semantic segmentation settings (i.e., 2/3-way 1/5-shot) on two benchmark datasets. Our code is available at https://github.com/Na-Z/attMPTI.



### Differentiable Rendering: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2006.12057v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2006.12057v2)
- **Published**: 2020-06-22 08:14:52+00:00
- **Updated**: 2020-07-31 00:01:27+00:00
- **Authors**: Hiroharu Kato, Deniz Beker, Mihai Morariu, Takahiro Ando, Toru Matsuoka, Wadim Kehl, Adrien Gaidon
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have shown remarkable performance improvements on vision-related tasks such as object detection or image segmentation. Despite their success, they generally lack the understanding of 3D objects which form the image, as it is not always possible to collect 3D information about the scene or to easily annotate it. Differentiable rendering is a novel field which allows the gradients of 3D objects to be calculated and propagated through images. It also reduces the requirement of 3D data collection and annotation, while enabling higher success rate in various applications. This paper reviews existing literature and discusses the current state of differentiable rendering, its applications and open research problems.



### Object Tracking through Residual and Dense LSTMs
- **Arxiv ID**: http://arxiv.org/abs/2006.12061v1
- **DOI**: 10.1007/978-3-030-50516-5_9
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12061v1)
- **Published**: 2020-06-22 08:20:17+00:00
- **Updated**: 2020-06-22 08:20:17+00:00
- **Authors**: Fabio Garcea, Alessandro Cucco, Lia Morra, Fabrizio Lamberti
- **Comment**: None
- **Journal**: Proceedings of 17th International Conference On Image Analysis and
  Recognition (ICIAR 2020)
- **Summary**: Visual object tracking task is constantly gaining importance in several fields of application as traffic monitoring, robotics, and surveillance, to name a few. Dealing with changes in the appearance of the tracked object is paramount to achieve high tracking accuracy, and is usually achieved by continually learning features. Recently, deep learning-based trackers based on LSTMs (Long Short-Term Memory) recurrent neural networks have emerged as a powerful alternative, bypassing the need to retrain the feature extraction in an online fashion. Inspired by the success of residual and dense networks in image recognition, we propose here to enhance the capabilities of hybrid trackers using residual and/or dense LSTMs. By introducing skip connections, it is possible to increase the depth of the architecture while ensuring a fast convergence. Experimental results on the Re3 tracker show that DenseLSTMs outperform Residual and regular LSTM, and offer a higher resilience to nuisances such as occlusions and out-of-view objects. Our case study supports the adoption of residual-based RNNs for enhancing the robustness of other trackers.



### MotioNet: 3D Human Motion Reconstruction from Monocular Video with Skeleton Consistency
- **Arxiv ID**: http://arxiv.org/abs/2006.12075v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, I.4.5
- **Links**: [PDF](http://arxiv.org/pdf/2006.12075v1)
- **Published**: 2020-06-22 08:50:09+00:00
- **Updated**: 2020-06-22 08:50:09+00:00
- **Authors**: Mingyi Shi, Kfir Aberman, Andreas Aristidou, Taku Komura, Dani Lischinski, Daniel Cohen-Or, Baoquan Chen
- **Comment**: Accepted to Transactions on Graphics (ToG) 2020. Project page:
  {https://rubbly.cn/publications/motioNet} Video:
  {https://youtu.be/8YubchlzvFA}
- **Journal**: None
- **Summary**: We introduce MotioNet, a deep neural network that directly reconstructs the motion of a 3D human skeleton from monocular video.While previous methods rely on either rigging or inverse kinematics (IK) to associate a consistent skeleton with temporally coherent joint rotations, our method is the first data-driven approach that directly outputs a kinematic skeleton, which is a complete, commonly used, motion representation. At the crux of our approach lies a deep neural network with embedded kinematic priors, which decomposes sequences of 2D joint positions into two separate attributes: a single, symmetric, skeleton, encoded by bone lengths, and a sequence of 3D joint rotations associated with global root positions and foot contact labels. These attributes are fed into an integrated forward kinematics (FK) layer that outputs 3D positions, which are compared to a ground truth. In addition, an adversarial loss is applied to the velocities of the recovered rotations, to ensure that they lie on the manifold of natural joint rotations. The key advantage of our approach is that it learns to infer natural joint rotations directly from the training data, rather than assuming an underlying model, or inferring them from joint positions using a data-agnostic IK solver. We show that enforcing a single consistent skeleton along with temporally coherent joint rotations constrains the solution space, leading to a more robust handling of self-occlusions and depth ambiguities.



### Split to Be Slim: An Overlooked Redundancy in Vanilla Convolution
- **Arxiv ID**: http://arxiv.org/abs/2006.12085v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12085v1)
- **Published**: 2020-06-22 09:08:51+00:00
- **Updated**: 2020-06-22 09:08:51+00:00
- **Authors**: Qiulin Zhang, Zhuqing Jiang, Qishuo Lu, Jia'nan Han, Zhengxin Zeng, Shang-hua Gao, Aidong Men
- **Comment**: Preprint version. The final version has been accepted to appear at
  IJCAI20
- **Journal**: None
- **Summary**: Many effective solutions have been proposed to reduce the redundancy of models for inference acceleration. Nevertheless, common approaches mostly focus on eliminating less important filters or constructing efficient operations, while ignoring the pattern redundancy in feature maps. We reveal that many feature maps within a layer share similar but not identical patterns. However, it is difficult to identify if features with similar patterns are redundant or contain essential details. Therefore, instead of directly removing uncertain redundant features, we propose a \textbf{sp}lit based \textbf{conv}olutional operation, namely SPConv, to tolerate features with similar patterns but require less computation. Specifically, we split input feature maps into the representative part and the uncertain redundant part, where intrinsic information is extracted from the representative part through relatively heavy computation while tiny hidden details in the uncertain redundant part are processed with some light-weight operation. To recalibrate and fuse these two groups of processed features, we propose a parameters-free feature fusion module. Moreover, our SPConv is formulated to replace the vanilla convolution in a plug-and-play way. Without any bells and whistles, experimental results on benchmarks demonstrate SPConv-equipped networks consistently outperform state-of-the-art baselines in both accuracy and inference time on GPU, with FLOPs and parameters dropped sharply.



### Progressive Graph Learning for Open-Set Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2006.12087v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12087v2)
- **Published**: 2020-06-22 09:10:34+00:00
- **Updated**: 2020-06-30 00:44:21+00:00
- **Authors**: Yadan Luo, Zijian Wang, Zi Huang, Mahsa Baktashmotlagh
- **Comment**: None
- **Journal**: International Conference on Machine Learning (ICML 2020)
- **Summary**: Domain shift is a fundamental problem in visual recognition which typically arises when the source and target data follow different distributions. The existing domain adaptation approaches which tackle this problem work in the closed-set setting with the assumption that the source and the target data share exactly the same classes of objects. In this paper, we tackle a more realistic problem of open-set domain shift where the target data contains additional classes that are not present in the source data. More specifically, we introduce an end-to-end Progressive Graph Learning (PGL) framework where a graph neural network with episodic training is integrated to suppress underlying conditional shift and adversarial learning is adopted to close the gap between the source and target distributions. Compared to the existing open-set adaptation approaches, our approach guarantees to achieve a tighter upper bound of the target error. Extensive experiments on three standard open-set benchmarks evidence that our approach significantly outperforms the state-of-the-arts in open-set domain adaptation.



### Deep Low-rank Prior in Dynamic MR Imaging
- **Arxiv ID**: http://arxiv.org/abs/2006.12090v4
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12090v4)
- **Published**: 2020-06-22 09:26:10+00:00
- **Updated**: 2020-07-28 09:26:49+00:00
- **Authors**: Ziwen Ke, Wenqi Huang, Jing Cheng, Zhuoxu Cui, Sen Jia, Haifeng Wang, Xin Liu, Hairong Zheng, Leslie Ying, Yanjie Zhu, Dong Liang
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: The deep learning methods have achieved attractive performance in dynamic MR cine imaging. However, all of these methods are only driven by the sparse prior of MR images, while the important low-rank (LR) prior of dynamic MR cine images is not explored, which limits the further improvements on dynamic MR reconstruction. In this paper, a learned singular value thresholding (Learned-SVT) operation is proposed to explore deep low-rank prior in dynamic MR imaging for obtaining improved reconstruction results. In particular, we come up with two novel and distinct schemes to introduce the learnable low-rank prior into deep network architectures in an unrolling manner and a plug-and-play manner respectively. In the unrolling manner, we put forward a model-based unrolling sparse and low-rank network for dynamic MR imaging, dubbed SLR-Net. The SLR-Net is defined over a deep network flow graph, which is unrolled from the iterative procedures in the Iterative Shrinkage-Thresholding Algorithm (ISTA) for optimizing a sparse and low-rank based dynamic MRI model. In the plug-and-play manner, we present a plug-and-play LR network module that can be easily embedded into any other dynamic MR neural networks without changing the network paradigm. Experimental results show that both schemes can further improve the state-of-the-art CS methods, such as k-t SLR, and sparsity-driven deep learning-based methods, such as DC-CNN and CRNN, both qualitatively and quantitatively.



### The color out of space: learning self-supervised representations for Earth Observation imagery
- **Arxiv ID**: http://arxiv.org/abs/2006.12119v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T07, I.4
- **Links**: [PDF](http://arxiv.org/pdf/2006.12119v1)
- **Published**: 2020-06-22 10:21:36+00:00
- **Updated**: 2020-06-22 10:21:36+00:00
- **Authors**: Stefano Vincenzi, Angelo Porrello, Pietro Buzzega, Marco Cipriano, Pietro Fronte, Roberto Cuccu, Carla Ippoliti, Annamaria Conte, Simone Calderara
- **Comment**: 8 pages, 2 figures. Accepted in the 25th International Conference on
  PATTERN RECOGNITION (ICPR 2020), Milan, Italy
- **Journal**: None
- **Summary**: The recent growth in the number of satellite images fosters the development of effective deep-learning techniques for Remote Sensing (RS). However, their full potential is untapped due to the lack of large annotated datasets. Such a problem is usually countered by fine-tuning a feature extractor that is previously trained on the ImageNet dataset. Unfortunately, the domain of natural images differs from the RS one, which hinders the final performance. In this work, we propose to learn meaningful representations from satellite imagery, leveraging its high-dimensionality spectral bands to reconstruct the visible colors. We conduct experiments on land cover classification (BigEarthNet) and West Nile Virus detection, showing that colorization is a solid pretext task for training a feature extractor. Furthermore, we qualitatively observe that guesses based on natural images and colorization rely on different parts of the input. This paves the way to an ensemble model that eventually outperforms both the above-mentioned techniques.



### Automated machine vision enabled detection of movement disorders from hand drawn spirals
- **Arxiv ID**: http://arxiv.org/abs/2006.12121v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12121v1)
- **Published**: 2020-06-22 10:21:51+00:00
- **Updated**: 2020-06-22 10:21:51+00:00
- **Authors**: Nabeel Seedat, Vered Aharonson, Ilana Schlesinger
- **Comment**: Accepted IEEE International Conference on Healthcare Informatics 2020
  (ICHI 2020), Upcoming Dec 2020, Copyright IEEE - 978-1-5386-5541-2/18/$31.00
  Copyright, 2020 IEEE
- **Journal**: None
- **Summary**: A widely used test for the diagnosis of Parkinson's disease (PD) and Essential tremor (ET) is hand-drawn shapes,where the analysis is observationally performed by the examining neurologist. This method is subjective and is prone to bias amongst different physicians. Due to the similarities in the symptoms of the two diseases, they are often misdiagnosed.Studies which attempt to automate the process typically use digitized input, where the tablet or specialized equipment are not affordable in many clinical settings. This study uses a dataset of scanned pen and paper drawings and a convolutional neural network (CNN) to perform classification between PD, ET and control subjects. The discrimination accuracy of PD from controls was 98.2%. The discrimination accuracy of PD from ET and from controls was 92%. An ablation study was conducted and indicated that correct hyper parameter optimization can increases the accuracy up to 4.33%. Finally, the study indicates the viability of using a CNN-enabled machine vision system to provide robust and accurate detection of movement disorders from hand drawn spirals.



### Supervised dimensionality reduction by a Linear Discriminant Analysis on pre-trained CNN features
- **Arxiv ID**: http://arxiv.org/abs/2006.12127v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12127v1)
- **Published**: 2020-06-22 10:31:04+00:00
- **Updated**: 2020-06-22 10:31:04+00:00
- **Authors**: Francisco J. H. Heras, Gonzalo G. de Polavieja
- **Comment**: None
- **Journal**: None
- **Summary**: We explore the application of linear discriminant analysis (LDA) to the features obtained in different layers of pretrained deep convolutional neural networks (CNNs). The advantage of LDA compared to other techniques in dimensionality reduction is that it reduces dimensions while preserving the global structure of data, so distances in the low-dimensional structure found are meaningful. The LDA applied to the CNN features finds that the centroids of classes corresponding to the similar data lay closer than classes corresponding to different data. We applied the method to a modification of the MNIST dataset with ten additional classes, each new class with half of the images from one of the standard ten classes. The method finds the new classes close to the corresponding standard classes we took the data form. We also applied the method to a dataset of images of butterflies to find that related subspecies are found to be close. For both datasets, we find a performance similar to state-of-the-art methods.



### Learning to Generate Noise for Multi-Attack Robustness
- **Arxiv ID**: http://arxiv.org/abs/2006.12135v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12135v4)
- **Published**: 2020-06-22 10:44:05+00:00
- **Updated**: 2021-06-24 18:41:57+00:00
- **Authors**: Divyam Madaan, Jinwoo Shin, Sung Ju Hwang
- **Comment**: Accepted to ICML 2021. Code available at
  https://github.com/divyam3897/MNG_AC
- **Journal**: None
- **Summary**: Adversarial learning has emerged as one of the successful techniques to circumvent the susceptibility of existing methods against adversarial perturbations. However, the majority of existing defense methods are tailored to defend against a single category of adversarial perturbation (e.g. $\ell_\infty$-attack). In safety-critical applications, this makes these methods extraneous as the attacker can adopt diverse adversaries to deceive the system. Moreover, training on multiple perturbations simultaneously significantly increases the computational overhead during training. To address these challenges, we propose a novel meta-learning framework that explicitly learns to generate noise to improve the model's robustness against multiple types of attacks. Its key component is Meta Noise Generator (MNG) that outputs optimal noise to stochastically perturb a given sample, such that it helps lower the error on diverse adversarial perturbations. By utilizing samples generated by MNG, we train a model by enforcing the label consistency across multiple perturbations. We validate the robustness of models trained by our scheme on various datasets and against a wide variety of perturbations, demonstrating that it significantly outperforms the baselines across multiple perturbations with a marginal computational cost.



### High-Precision Digital Traffic Recording with Multi-LiDAR Infrastructure Sensor Setups
- **Arxiv ID**: http://arxiv.org/abs/2006.12140v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12140v1)
- **Published**: 2020-06-22 10:57:52+00:00
- **Updated**: 2020-06-22 10:57:52+00:00
- **Authors**: Laurent Kloeker, Christian Geller, Amarin Kloeker, Lutz Eckstein
- **Comment**: Accepted to be published as part of the 23rd IEEE International
  Conference on Intelligent Transportation Systems (ITSC), Rhodes, Greece,
  September 20-23, 2020
- **Journal**: None
- **Summary**: Large driving datasets are a key component in the current development and safeguarding of automated driving functions. Various methods can be used to collect such driving data records. In addition to the use of sensor equipped research vehicles or unmanned aerial vehicles (UAVs), the use of infrastructure sensor technology offers another alternative. To minimize object occlusion during data collection, it is crucial to record the traffic situation from several perspectives in parallel. A fusion of all raw sensor data might create better conditions for multi-object detection and tracking (MODT) compared to the use of individual raw sensor data. So far, no sufficient studies have been conducted to sufficiently confirm this approach. In our work we investigate the impact of fused LiDAR point clouds compared to single LiDAR point clouds. We model different urban traffic scenarios with up to eight 64-layer LiDARs in simulation and in reality. We then analyze the properties of the resulting point clouds and perform MODT for all emerging traffic participants. The evaluation of the extracted trajectories shows that a fused infrastructure approach significantly increases the tracking results and reaches accuracies within a few centimeters.



### Generating Annotated High-Fidelity Images Containing Multiple Coherent Objects
- **Arxiv ID**: http://arxiv.org/abs/2006.12150v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12150v3)
- **Published**: 2020-06-22 11:33:55+00:00
- **Updated**: 2021-07-15 21:42:29+00:00
- **Authors**: Bryan G. Cardenas, Devanshu Arya, Deepak K. Gupta
- **Comment**: 21 pages, 5 tables, 21 figures
- **Journal**: None
- **Summary**: Recent developments related to generative models have made it possible to generate diverse high-fidelity images. In particular, layout-to-image generation models have gained significant attention due to their capability to generate realistic complex images containing distinct objects. These models are generally conditioned on either semantic layouts or textual descriptions. However, unlike natural images, providing auxiliary information can be extremely hard in domains such as biomedical imaging and remote sensing. In this work, we propose a multi-object generation framework that can synthesize images with multiple objects without explicitly requiring their contextual information during the generation process. Based on a vector-quantized variational autoencoder (VQ-VAE) backbone, our model learns to preserve spatial coherency within an image as well as semantic coherency between the objects and the background through two powerful autoregressive priors: PixelSNAIL and LayoutPixelSNAIL. While the PixelSNAIL learns the distribution of the latent encodings of the VQ-VAE, the LayoutPixelSNAIL is used to specifically learn the semantic distribution of the objects. An implicit advantage of our approach is that the generated samples are accompanied by object-level annotations. We demonstrate how coherency and fidelity are preserved with our method through experiments on the Multi-MNIST and CLEVR datasets; thereby outperforming state-of-the-art multi-object generative methods. The efficacy of our approach is demonstrated through application on medical imaging datasets, where we show that augmenting the training set with generated samples using our approach improves the performance of existing models.



### Neural Cellular Automata Manifold
- **Arxiv ID**: http://arxiv.org/abs/2006.12155v3
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12155v3)
- **Published**: 2020-06-22 11:41:57+00:00
- **Updated**: 2021-03-02 10:38:43+00:00
- **Authors**: Alejandro Hernandez Ruiz, Armand Vilalta, Francesc Moreno-Noguer
- **Comment**: None
- **Journal**: None
- **Summary**: Very recently, the Neural Cellular Automata (NCA) has been proposed to simulate the morphogenesis process with deep networks. NCA learns to grow an image starting from a fixed single pixel. In this work, we show that the neural network (NN) architecture of the NCA can be encapsulated in a larger NN. This allows us to propose a new model that encodes a manifold of NCA, each of them capable of generating a distinct image. Therefore, we are effectively learning an embedding space of CA, which shows generalization capabilities. We accomplish this by introducing dynamic convolutions inside an Auto-Encoder architecture, for the first time used to join two different sources of information, the encoding and cells environment information. In biological terms, our approach would play the role of the transcription factors, modulating the mapping of genes into specific proteins that drive cellular differentiation, which occurs right before the morphogenesis. We thoroughly evaluate our approach in a dataset of synthetic emojis and also in real images of CIFAR10. Our model introduces a general-purpose network, which can be used in a broad range of problems beyond image generation.



### Neural networks adapting to datasets: learning network size and topology
- **Arxiv ID**: http://arxiv.org/abs/2006.12195v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12195v2)
- **Published**: 2020-06-22 12:46:44+00:00
- **Updated**: 2020-07-15 10:00:07+00:00
- **Authors**: Romuald A. Janik, Aleksandra Nowak
- **Comment**: Fixed blank page
- **Journal**: None
- **Summary**: We introduce a flexible setup allowing for a neural network to learn both its size and topology during the course of a standard gradient-based training. The resulting network has the structure of a graph tailored to the particular learning task and dataset. The obtained networks can also be trained from scratch and achieve virtually identical performance. We explore the properties of the network architectures for a number of datasets of varying difficulty observing systematic regularities. The obtained graphs can be therefore understood as encoding nontrivial characteristics of the particular classification tasks.



### Text Recognition in Real Scenarios with a Few Labeled Samples
- **Arxiv ID**: http://arxiv.org/abs/2006.12209v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12209v1)
- **Published**: 2020-06-22 13:03:01+00:00
- **Updated**: 2020-06-22 13:03:01+00:00
- **Authors**: Jinghuang Lin, Zhanzhan Cheng, Fan Bai, Yi Niu, Shiliang Pu, Shuigeng Zhou
- **Comment**: 8 pages, 6 figures
- **Journal**: None
- **Summary**: Scene text recognition (STR) is still a hot research topic in computer vision field due to its various applications. Existing works mainly focus on learning a general model with a huge number of synthetic text images to recognize unconstrained scene texts, and have achieved substantial progress. However, these methods are not quite applicable in many real-world scenarios where 1) high recognition accuracy is required, while 2) labeled samples are lacked. To tackle this challenging problem, this paper proposes a few-shot adversarial sequence domain adaptation (FASDA) approach to build sequence adaptation between the synthetic source domain (with many synthetic labeled samples) and a specific target domain (with only some or a few real labeled samples). This is done by simultaneously learning each character's feature representation with an attention mechanism and establishing the corresponding character-level latent subspace with adversarial learning. Our approach can maximize the character-level confusion between the source domain and the target domain, thus achieves the sequence-level adaptation with even a small number of labeled samples in the target domain. Extensive experiments on various datasets show that our method significantly outperforms the finetuning scheme, and obtains comparable performance to the state-of-the-art STR methods.



### Facial Expression Editing with Continuous Emotion Labels
- **Arxiv ID**: http://arxiv.org/abs/2006.12210v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12210v1)
- **Published**: 2020-06-22 13:03:02+00:00
- **Updated**: 2020-06-22 13:03:02+00:00
- **Authors**: Alexandra Lindt, Pablo Barros, Henrique Siqueira, Stefan Wermter
- **Comment**: 8 pages, 5 figures. 14th IEEE International Conference on Automatic
  Face and Gesture Recognition (FG 2019), May 2019
- **Journal**: None
- **Summary**: Recently deep generative models have achieved impressive results in the field of automated facial expression editing. However, the approaches presented so far presume a discrete representation of human emotions and are therefore limited in the modelling of non-discrete emotional expressions. To overcome this limitation, we explore how continuous emotion representations can be used to control automated expression editing. We propose a deep generative model that can be used to manipulate facial expressions in facial images according to continuous two-dimensional emotion labels. One dimension represents an emotion's valence, the other represents its degree of arousal. We demonstrate the functionality of our model with a quantitative analysis using classifier networks as well as with a qualitative analysis.



### Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample
- **Arxiv ID**: http://arxiv.org/abs/2006.12226v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12226v3)
- **Published**: 2020-06-22 13:24:25+00:00
- **Updated**: 2020-10-22 11:38:19+00:00
- **Authors**: Shir Gur, Sagie Benaim, Lior Wolf
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the task of generating diverse and novel videos from a single video sample. Recently, new hierarchical patch-GAN based approaches were proposed for generating diverse images, given only a single sample at training time. Moving to videos, these approaches fail to generate diverse samples, and often collapse into generating samples similar to the training video. We introduce a novel patch-based variational autoencoder (VAE) which allows for a much greater diversity in generation. Using this tool, a new hierarchical video generation scheme is constructed: at coarse scales, our patch-VAE is employed, ensuring samples are of high diversity. Subsequently, at finer scales, a patch-GAN renders the fine details, resulting in high quality videos. Our experiments show that the proposed method produces diverse samples in both the image domain, and the more challenging video domain.



### HookNet: multi-resolution convolutional neural networks for semantic segmentation in histopathology whole-slide images
- **Arxiv ID**: http://arxiv.org/abs/2006.12230v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12230v1)
- **Published**: 2020-06-22 13:26:37+00:00
- **Updated**: 2020-06-22 13:26:37+00:00
- **Authors**: Mart van Rijthoven, Maschenka Balkenhol, Karina Siliņa, Jeroen van der Laak, Francesco Ciompi
- **Comment**: None
- **Journal**: None
- **Summary**: We propose HookNet, a semantic segmentation model for histopathology whole-slide images, which combines context and details via multiple branches of encoder-decoder convolutional neural networks. Concentricpatches at multiple resolutions with different fields of view are used to feed different branches of HookNet, and intermediate representations are combined via a hooking mechanism. We describe a framework to design and train HookNet for achieving high-resolution semantic segmentation and introduce constraints to guarantee pixel-wise alignment in feature maps during hooking. We show the advantages of using HookNet in two histopathology image segmentation tasks where tissue type prediction accuracy strongly depends on contextual information, namely (1) multi-class tissue segmentation in breast cancer and, (2) segmentation of tertiary lymphoid structures and germinal centers in lung cancer. Weshow the superiority of HookNet when compared with single-resolution U-Net models working at different resolutions as well as with a recently published multi-resolution model for histopathology image segmentation



### ResFPN: Residual Skip Connections in Multi-Resolution Feature Pyramid Networks for Accurate Dense Pixel Matching
- **Arxiv ID**: http://arxiv.org/abs/2006.12235v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12235v1)
- **Published**: 2020-06-22 13:31:31+00:00
- **Updated**: 2020-06-22 13:31:31+00:00
- **Authors**: Rishav, René Schuster, Ramy Battrawy, Oliver Wasenmüller, Didier Stricker
- **Comment**: Accepted at ICPR 2020
- **Journal**: None
- **Summary**: Dense pixel matching is required for many computer vision algorithms such as disparity, optical flow or scene flow estimation. Feature Pyramid Networks (FPN) have proven to be a suitable feature extractor for CNN-based dense matching tasks. FPN generates well localized and semantically strong features at multiple scales. However, the generic FPN is not utilizing its full potential, due to its reasonable but limited localization accuracy. Thus, we present ResFPN -- a multi-resolution feature pyramid network with multiple residual skip connections, where at any scale, we leverage the information from higher resolution maps for stronger and better localized features. In our ablation study, we demonstrate the effectiveness of our novel architecture with clearly higher accuracy than FPN. In addition, we verify the superior accuracy of ResFPN in many different pixel matching applications on established datasets like KITTI, Sintel, and FlyingThings3D.



### Pix2Vox++: Multi-scale Context-aware 3D Object Reconstruction from Single and Multiple Images
- **Arxiv ID**: http://arxiv.org/abs/2006.12250v2
- **DOI**: 10.1007/s11263-020-01347-6
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12250v2)
- **Published**: 2020-06-22 13:48:09+00:00
- **Updated**: 2020-07-07 09:30:13+00:00
- **Authors**: Haozhe Xie, Hongxun Yao, Shengping Zhang, Shangchen Zhou, Wenxiu Sun
- **Comment**: International Journal of Computer Vision (IJCV). arXiv admin note:
  text overlap with arXiv:1901.11153
- **Journal**: International Journal of Computer Vision, 128(12): 2919-2935, 2020
- **Summary**: Recovering the 3D shape of an object from single or multiple images with deep neural networks has been attracting increasing attention in the past few years. Mainstream works (e.g. 3D-R2N2) use recurrent neural networks (RNNs) to sequentially fuse feature maps of input images. However, RNN-based approaches are unable to produce consistent reconstruction results when given the same input images with different orders. Moreover, RNNs may forget important features from early input images due to long-term memory loss. To address these issues, we propose a novel framework for single-view and multi-view 3D object reconstruction, named Pix2Vox++. By using a well-designed encoder-decoder, it generates a coarse 3D volume from each input image. A multi-scale context-aware fusion module is then introduced to adaptively select high-quality reconstructions for different parts from all coarse 3D volumes to obtain a fused 3D volume. To further correct the wrongly recovered parts in the fused 3D volume, a refiner is adopted to generate the final output. Experimental results on the ShapeNet, Pix3D, and Things3D benchmarks show that Pix2Vox++ performs favorably against state-of-the-art methods in terms of both accuracy and efficiency.



### FDFlowNet: Fast Optical Flow Estimation using a Deep Lightweight Network
- **Arxiv ID**: http://arxiv.org/abs/2006.12263v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12263v1)
- **Published**: 2020-06-22 14:01:01+00:00
- **Updated**: 2020-06-22 14:01:01+00:00
- **Authors**: Lingtong Kong, Jie Yang
- **Comment**: Accepted by ICIP 2020
- **Journal**: None
- **Summary**: Significant progress has been made for estimating optical flow using deep neural networks. Advanced deep models achieve accurate flow estimation often with a considerable computation complexity and time-consuming training processes. In this work, we present a lightweight yet effective model for real-time optical flow estimation, termed FDFlowNet (fast deep flownet). We achieve better or similar accuracy on the challenging KITTI and Sintel benchmarks while being about 2 times faster than PWC-Net. This is achieved by a carefully-designed structure and newly proposed components. We first introduce an U-shape network for constructing multi-scale feature which benefits upper levels with global receptive field compared with pyramid network. In each scale, a partial fully connected structure with dilated convolution is proposed for flow estimation that obtains a good balance among speed, accuracy and number of parameters compared with sequential connected and dense connected structures. Experiments demonstrate that our model achieves state-of-the-art performance while being fast and lightweight.



### On the Ability of a CNN to Realize Image-to-Image Language Conversion
- **Arxiv ID**: http://arxiv.org/abs/2006.12316v1
- **DOI**: 10.1109/ICDAR.2019.00078
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12316v1)
- **Published**: 2020-06-22 14:54:42+00:00
- **Updated**: 2020-06-22 14:54:42+00:00
- **Authors**: Kohei Baba, Seiichi Uchida, Brian Kenji Iwana
- **Comment**: Published at ICDAR 2019
- **Journal**: None
- **Summary**: The purpose of this paper is to reveal the ability that Convolutional Neural Networks (CNN) have on the novel task of image-to-image language conversion. We propose a new network to tackle this task by converting images of Korean Hangul characters directly into images of the phonetic Latin character equivalent. The conversion rules between Hangul and the phonetic symbols are not explicitly provided. The results of the proposed network show that it is possible to perform image-to-image language conversion. Moreover, it shows that it can grasp the structural features of Hangul even from limited learning data. In addition, it introduces a new network to use when the input and output have significantly different features.



### Automatic Recall Machines: Internal Replay, Continual Learning and the Brain
- **Arxiv ID**: http://arxiv.org/abs/2006.12323v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, q-bio.NC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12323v3)
- **Published**: 2020-06-22 15:07:06+00:00
- **Updated**: 2020-12-12 17:58:30+00:00
- **Authors**: Xu Ji, Joao Henriques, Tinne Tuytelaars, Andrea Vedaldi
- **Comment**: NeurIPS 2020 Workshop on BabyMind
- **Journal**: None
- **Summary**: Replay in neural networks involves training on sequential data with memorized samples, which counteracts forgetting of previous behavior caused by non-stationarity. We present a method where these auxiliary samples are generated on the fly, given only the model that is being trained for the assessed objective, without extraneous buffers or generator networks. Instead the implicit memory of learned samples within the assessed model itself is exploited. Furthermore, whereas existing work focuses on reinforcing the full seen data distribution, we show that optimizing for not forgetting calls for the generation of samples that are specialized to each real training batch, which is more efficient and scalable. We consider high-level parallels with the brain, notably the use of a single model for inference and recall, the dependency of recalled samples on the current environment batch, top-down modulation of activations and learning, abstract recall, and the dependency between the degree to which a task is learned and the degree to which it is recalled. These characteristics emerge naturally from the method without being controlled for.



### Generative Sparse Detection Networks for 3D Single-shot Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2006.12356v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12356v1)
- **Published**: 2020-06-22 15:54:24+00:00
- **Updated**: 2020-06-22 15:54:24+00:00
- **Authors**: JunYoung Gwak, Christopher Choy, Silvio Savarese
- **Comment**: None
- **Journal**: None
- **Summary**: 3D object detection has been widely studied due to its potential applicability to many promising areas such as robotics and augmented reality. Yet, the sparse nature of the 3D data poses unique challenges to this task. Most notably, the observable surface of the 3D point clouds is disjoint from the center of the instance to ground the bounding box prediction on. To this end, we propose Generative Sparse Detection Network (GSDN), a fully-convolutional single-shot sparse detection network that efficiently generates the support for object proposals. The key component of our model is a generative sparse tensor decoder, which uses a series of transposed convolutions and pruning layers to expand the support of sparse tensors while discarding unlikely object centers to maintain minimal runtime and memory footprint. GSDN can process unprecedentedly large-scale inputs with a single fully-convolutional feed-forward pass, thus does not require the heuristic post-processing stage that stitches results from sliding windows as other previous methods have. We validate our approach on three 3D indoor datasets including the large-scale 3D indoor reconstruction dataset where our method outperforms the state-of-the-art methods by a relative improvement of 7.14% while being 3.78 times faster than the best prior work.



### Learning Physical Graph Representations from Visual Scenes
- **Arxiv ID**: http://arxiv.org/abs/2006.12373v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.4.8; I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2006.12373v2)
- **Published**: 2020-06-22 16:10:26+00:00
- **Updated**: 2020-06-24 17:33:35+00:00
- **Authors**: Daniel M. Bear, Chaofei Fan, Damian Mrowca, Yunzhu Li, Seth Alter, Aran Nayebi, Jeremy Schwartz, Li Fei-Fei, Jiajun Wu, Joshua B. Tenenbaum, Daniel L. K. Yamins
- **Comment**: 23 pages; corrected affiliations and acknowledgments
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) have proved exceptional at learning representations for visual object categorization. However, CNNs do not explicitly encode objects, parts, and their physical properties, which has limited CNNs' success on tasks that require structured understanding of visual scenes. To overcome these limitations, we introduce the idea of Physical Scene Graphs (PSGs), which represent scenes as hierarchical graphs, with nodes in the hierarchy corresponding intuitively to object parts at different scales, and edges to physical connections between parts. Bound to each node is a vector of latent attributes that intuitively represent object properties such as surface shape and texture. We also describe PSGNet, a network architecture that learns to extract PSGs by reconstructing scenes through a PSG-structured bottleneck. PSGNet augments standard CNNs by including: recurrent feedback connections to combine low and high-level image information; graph pooling and vectorization operations that convert spatially-uniform feature maps into object-centric graph structures; and perceptual grouping principles to encourage the identification of meaningful scene elements. We show that PSGNet outperforms alternative self-supervised scene representation algorithms at scene segmentation tasks, especially on complex real-world images, and generalizes well to unseen object types and scene arrangements. PSGNet is also able learn from physical motion, enhancing scene estimates even for static images. We present a series of ablation studies illustrating the importance of each component of the PSGNet architecture, analyses showing that learned latent attributes capture intuitive scene properties, and illustrate the use of PSGs for compositional scene inference.



### Deep Negative Volume Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.12430v1
- **DOI**: 10.1038/s41598-021-95526-1
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12430v1)
- **Published**: 2020-06-22 16:55:23+00:00
- **Updated**: 2020-06-22 16:55:23+00:00
- **Authors**: Kristina Belikova, Oleg Rogov, Aleksandr Rybakov, Maxim V. Maslov, Dmitry V. Dylov
- **Comment**: 20 pages, 5 main figures, 3 tables, 11 supplemental figures,
  supplementary material
- **Journal**: Sci Rep 11, 16292 (2021)
- **Summary**: Clinical examination of three-dimensional image data of compound anatomical objects, such as complex joints, remains a tedious process, demanding the time and the expertise of physicians. For instance, automation of the segmentation task of the TMJ (temporomandibular joint) has been hindered by its compound three-dimensional shape, multiple overlaid textures, an abundance of surrounding irregularities in the skull, and a virtually omnidirectional range of the jaw's motion - all of which extend the manual annotation process to more than an hour per patient. To address the challenge, we invent a new angle to the 3D segmentation task: namely, we propose to segment empty spaces between all the tissues surrounding the object - the so-called negative volume segmentation. Our approach is an end-to-end pipeline that comprises a V-Net for bone segmentation, a 3D volume construction by inflation of the reconstructed bone head in all directions along the normal vector to its mesh faces. Eventually confined within the skull bones, the inflated surface occupies the entire "negative" space in the joint, effectively providing a geometrical/topological metric of the joint's health. We validate the idea on the CT scans in a 50-patient dataset, annotated by experts in maxillofacial medicine, quantitatively compare the asymmetry given the left and the right negative volumes, and automate the entire framework for clinical adoption.



### Cardiac Segmentation on Late Gadolinium Enhancement MRI: A Benchmark Study from Multi-Sequence Cardiac MR Segmentation Challenge
- **Arxiv ID**: http://arxiv.org/abs/2006.12434v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12434v2)
- **Published**: 2020-06-22 17:04:38+00:00
- **Updated**: 2021-07-17 13:55:30+00:00
- **Authors**: Xiahai Zhuang, Jiahang Xu, Xinzhe Luo, Chen Chen, Cheng Ouyang, Daniel Rueckert, Victor M. Campello, Karim Lekadir, Sulaiman Vesal, Nishant RaviKumar, Yashu Liu, Gongning Luo, Jingkun Chen, Hongwei Li, Buntheng Ly, Maxime Sermesant, Holger Roth, Wentao Zhu, Jiexiang Wang, Xinghao Ding, Xinyue Wang, Sen Yang, Lei Li
- **Comment**: 14 pages
- **Journal**: None
- **Summary**: Accurate computing, analysis and modeling of the ventricles and myocardium from medical images are important, especially in the diagnosis and treatment management for patients suffering from myocardial infarction (MI). Late gadolinium enhancement (LGE) cardiac magnetic resonance (CMR) provides an important protocol to visualize MI. However, automated segmentation of LGE CMR is still challenging, due to the indistinguishable boundaries, heterogeneous intensity distribution and complex enhancement patterns of pathological myocardium from LGE CMR. Furthermore, compared with the other sequences LGE CMR images with gold standard labels are particularly limited, which represents another obstacle for developing novel algorithms for automatic segmentation of LGE CMR. This paper presents the selective results from the Multi-Sequence Cardiac MR (MS-CMR) Segmentation challenge, in conjunction with MICCAI 2019. The challenge offered a data set of paired MS-CMR images, including auxiliary CMR sequences as well as LGE CMR, from 45 patients who underwent cardiomyopathy. It was aimed to develop new algorithms, as well as benchmark existing ones for LGE CMR segmentation and compare them objectively. In addition, the paired MS-CMR images could enable algorithms to combine the complementary information from the other sequences for the segmentation of LGE CMR. Nine representative works were selected for evaluation and comparisons, among which three methods are unsupervised methods and the other six are supervised. The results showed that the average performance of the nine methods was comparable to the inter-observer variations. The success of these methods was mainly attributed to the inclusion of the auxiliary sequences from the MS-CMR images, which provide important label information for the training of deep neural networks.



### A Baseline Approach for AutoImplant: the MICCAI 2020 Cranial Implant Design Challenge
- **Arxiv ID**: http://arxiv.org/abs/2006.12449v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12449v2)
- **Published**: 2020-06-22 17:27:56+00:00
- **Updated**: 2020-06-24 11:22:39+00:00
- **Authors**: Jianning Li, Antonio Pepe, Christina Gsaxner, Gord von Campe, Jan Egger
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: In this study, we present a baseline approach for AutoImplant (https://autoimplant.grand-challenge.org/) - the cranial implant design challenge, which, as suggested by the organizers, can be formulated as a volumetric shape learning task. In this task, the defective skull, the complete skull and the cranial implant are represented as binary voxel grids. To accomplish this task, the implant can be either reconstructed directly from the defective skull or obtained by taking the difference between a defective skull and a complete skull. In the latter case, a complete skull has to be reconstructed given a defective skull, which defines a volumetric shape completion problem. Our baseline approach for this task is based on the former formulation, i.e., a deep neural network is trained to predict the implants directly from the defective skulls. The approach generates high-quality implants in two steps: First, an encoder-decoder network learns a coarse representation of the implant from down-sampled, defective skulls; The coarse implant is only used to generate the bounding box of the defected region in the original high-resolution skull. Second, another encoder-decoder network is trained to generate a fine implant from the bounded area. On the test set, the proposed approach achieves an average dice similarity score (DSC) of 0.8555 and Hausdorff distance (HD) of 5.1825 mm. The code is publicly available at https://github.com/Jianningli/autoimplant.



### Effective Version Space Reduction for Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2006.12456v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML, I.2.6; G.3; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/2006.12456v1)
- **Published**: 2020-06-22 17:40:03+00:00
- **Updated**: 2020-06-22 17:40:03+00:00
- **Authors**: Jiayu Liu, Ioannis Chiotellis, Rudolph Triebel, Daniel Cremers
- **Comment**: 22 pages, 8 figures, to be published in the Proceedings of the
  European Conference on Machine Learning and Principles and Practice of
  Knowledge Discovery in Databases (ECML PKDD) 2020
- **Journal**: None
- **Summary**: In active learning, sampling bias could pose a serious inconsistency problem and hinder the algorithm from finding the optimal hypothesis. However, many methods for neural networks are hypothesis space agnostic and do not address this problem. We examine active learning with convolutional neural networks through the principled lens of version space reduction. We identify the connection between two approaches---prior mass reduction and diameter reduction---and propose a new diameter-based querying method---the minimum Gibbs-vote disagreement. By estimating version space diameter and bias, we illustrate how version space of neural networks evolves and examine the realizability assumption. With experiments on MNIST, Fashion-MNIST, SVHN and STL-10 datasets, we demonstrate that diameter reduction methods reduce the version space more effectively and perform better than prior mass reduction and other baselines, and that the Gibbs vote disagreement is on par with the best query method.



### Slimming Neural Networks using Adaptive Connectivity Scores
- **Arxiv ID**: http://arxiv.org/abs/2006.12463v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, cs.LG, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/2006.12463v3)
- **Published**: 2020-06-22 17:45:16+00:00
- **Updated**: 2021-12-17 21:44:23+00:00
- **Authors**: Madan Ravi Ganesh, Dawsin Blanchard, Jason J. Corso, Salimeh Yasaei Sekeh
- **Comment**: 18 pages
- **Journal**: None
- **Summary**: In general, deep neural network (DNN) pruning methods fall into two categories: 1) Weight-based deterministic constraints, and 2) Probabilistic frameworks. While each approach has its merits and limitations there are a set of common practical issues such as, trial-and-error to analyze sensitivity and hyper-parameters to prune DNNs, which plague them both. In this work, we propose a new single-shot, fully automated pruning algorithm called Slimming Neural networks using Adaptive Connectivity Scores (SNACS). Our proposed approach combines a probabilistic pruning framework with constraints on the underlying weight matrices, via a novel connectivity measure, at multiple levels to capitalize on the strengths of both approaches while solving their deficiencies. In \alg{}, we propose a fast hash-based estimator of Adaptive Conditional Mutual Information (ACMI), that uses a weight-based scaling criterion, to evaluate the connectivity between filters and prune unimportant ones. To automatically determine the limit up to which a layer can be pruned, we propose a set of operating constraints that jointly define the upper pruning percentage limits across all the layers in a deep network. Finally, we define a novel sensitivity criterion for filters that measures the strength of their contributions to the succeeding layer and highlights critical filters that need to be completely protected from pruning. Through our experimental validation we show that SNACS is faster by over 17x the nearest comparable method and is the state of the art single-shot pruning method across three standard Dataset-DNN pruning benchmarks: CIFAR10-VGG16, CIFAR10-ResNet56 and ILSVRC2012-ResNet50.



### Stacked Convolutional Neural Network for Diagnosis of COVID-19 Disease from X-ray Images
- **Arxiv ID**: http://arxiv.org/abs/2006.13817v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.13817v1)
- **Published**: 2020-06-22 17:55:16+00:00
- **Updated**: 2020-06-22 17:55:16+00:00
- **Authors**: Mahesh Gour, Sweta Jain
- **Comment**: 6 tables, 4 figures
- **Journal**: None
- **Summary**: Automatic and rapid screening of COVID-19 from the chest X-ray images has become an urgent need in this pandemic situation of SARS-CoV-2 worldwide in 2020. However, accurate and reliable screening of patients is a massive challenge due to the discrepancy between COVID-19 and other viral pneumonia in X-ray images. In this paper, we design a new stacked convolutional neural network model for the automatic diagnosis of COVID-19 disease from the chest X-ray images. We obtain different sub-models from the VGG19 and developed a 30-layered CNN model (named as CovNet30) during the training, and obtained sub-models are stacked together using logistic regression. The proposed CNN model combines the discriminating power of the different CNN`s sub-models and classifies chest X-ray images into COVID-19, Normal, and Pneumonia classes. In addition, we generate X-ray images dataset referred to as COVID19CXr, which includes 2764 chest x-ray images of 1768 patients from the three publicly available data repositories. The proposed stacked CNN achieves an accuracy of 92.74%, the sensitivity of 93.33%, PPV of 92.13%, and F1-score of 0.93 for the classification of X-ray images. Our proposed approach shows its superiority over the existing methods for the diagnosis of the COVID-19 from the X-ray images.



### Self-supervised Video Object Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.12480v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.12480v1)
- **Published**: 2020-06-22 17:55:59+00:00
- **Updated**: 2020-06-22 17:55:59+00:00
- **Authors**: Fangrui Zhu, Li Zhang, Yanwei Fu, Guodong Guo, Weidi Xie
- **Comment**: None
- **Journal**: None
- **Summary**: The objective of this paper is self-supervised representation learning, with the goal of solving semi-supervised video object segmentation (a.k.a. dense tracking). We make the following contributions: (i) we propose to improve the existing self-supervised approach, with a simple, yet more effective memory mechanism for long-term correspondence matching, which resolves the challenge caused by the dis-appearance and reappearance of objects; (ii) by augmenting the self-supervised approach with an online adaptation module, our method successfully alleviates tracker drifts caused by spatial-temporal discontinuity, e.g. occlusions or dis-occlusions, fast motions; (iii) we explore the efficiency of self-supervised representation learning for dense tracking, surprisingly, we show that a powerful tracking model can be trained with as few as 100 raw video clips (equivalent to a duration of 11mins), indicating that low-level statistics have already been effective for tracking tasks; (iv) we demonstrate state-of-the-art results among the self-supervised approaches on DAVIS-2017 and YouTube-VOS, as well as surpassing most of methods trained with millions of manual segmentation annotations, further bridging the gap between self-supervised and supervised learning. Codes are released to foster any further research (https://github.com/fangruizhu/self_sup_semiVOS).



### On Creating Benchmark Dataset for Aerial Image Interpretation: Reviews, Guidances and Million-AID
- **Arxiv ID**: http://arxiv.org/abs/2006.12485v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12485v2)
- **Published**: 2020-06-22 17:59:00+00:00
- **Updated**: 2021-03-30 10:53:03+00:00
- **Authors**: Yang Long, Gui-Song Xia, Shengyang Li, Wen Yang, Michael Ying Yang, Xiao Xiang Zhu, Liangpei Zhang, Deren Li
- **Comment**: None
- **Journal**: None
- **Summary**: The past years have witnessed great progress on remote sensing (RS) image interpretation and its wide applications. With RS images becoming more accessible than ever before, there is an increasing demand for the automatic interpretation of these images. In this context, the benchmark datasets serve as essential prerequisites for developing and testing intelligent interpretation algorithms. After reviewing existing benchmark datasets in the research community of RS image interpretation, this article discusses the problem of how to efficiently prepare a suitable benchmark dataset for RS image interpretation. Specifically, we first analyze the current challenges of developing intelligent algorithms for RS image interpretation with bibliometric investigations. We then present the general guidances on creating benchmark datasets in efficient manners. Following the presented guidances, we also provide an example on building RS image dataset, i.e., Million-AID, a new large-scale benchmark dataset containing a million instances for RS image scene classification. Several challenges and perspectives in RS image annotation are finally discussed to facilitate the research in benchmark dataset construction. We do hope this paper will provide the RS community an overall perspective on constructing large-scale and practical image datasets for further research, especially data-driven ones.



### Locally Masked Convolution for Autoregressive Models
- **Arxiv ID**: http://arxiv.org/abs/2006.12486v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12486v3)
- **Published**: 2020-06-22 17:59:07+00:00
- **Updated**: 2020-06-27 04:53:14+00:00
- **Authors**: Ajay Jain, Pieter Abbeel, Deepak Pathak
- **Comment**: Published at Conference on Uncertainty in AI (UAI) 2020
- **Journal**: None
- **Summary**: High-dimensional generative models have many applications including image compression, multimedia generation, anomaly detection and data completion. State-of-the-art estimators for natural images are autoregressive, decomposing the joint distribution over pixels into a product of conditionals parameterized by a deep neural network, e.g. a convolutional neural network such as the PixelCNN. However, PixelCNNs only model a single decomposition of the joint, and only a single generation order is efficient. For tasks such as image completion, these models are unable to use much of the observed context. To generate data in arbitrary orders, we introduce LMConv: a simple modification to the standard 2D convolution that allows arbitrary masks to be applied to the weights at each location in the image. Using LMConv, we learn an ensemble of distribution estimators that share parameters but differ in generation order, achieving improved performance on whole-image density estimation (2.89 bpd on unconditional CIFAR10), as well as globally coherent image completions. Our code is available at https://ajayjain.github.io/lmconv.



### Just How Toxic is Data Poisoning? A Unified Benchmark for Backdoor and Data Poisoning Attacks
- **Arxiv ID**: http://arxiv.org/abs/2006.12557v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, cs.CY, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12557v3)
- **Published**: 2020-06-22 18:34:08+00:00
- **Updated**: 2021-06-17 14:10:57+00:00
- **Authors**: Avi Schwarzschild, Micah Goldblum, Arjun Gupta, John P Dickerson, Tom Goldstein
- **Comment**: 19 pages, 4 figures
- **Journal**: None
- **Summary**: Data poisoning and backdoor attacks manipulate training data in order to cause models to fail during inference. A recent survey of industry practitioners found that data poisoning is the number one concern among threats ranging from model stealing to adversarial attacks. However, it remains unclear exactly how dangerous poisoning methods are and which ones are more effective considering that these methods, even ones with identical objectives, have not been tested in consistent or realistic settings. We observe that data poisoning and backdoor attacks are highly sensitive to variations in the testing setup. Moreover, we find that existing methods may not generalize to realistic settings. While these existing works serve as valuable prototypes for data poisoning, we apply rigorous tests to determine the extent to which we should fear them. In order to promote fair comparison in future work, we develop standardized benchmarks for data poisoning and backdoor attacks.



### A Survey on Deep Learning for Localization and Mapping: Towards the Age of Spatial Machine Intelligence
- **Arxiv ID**: http://arxiv.org/abs/2006.12567v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12567v2)
- **Published**: 2020-06-22 19:01:21+00:00
- **Updated**: 2020-06-29 18:58:07+00:00
- **Authors**: Changhao Chen, Bing Wang, Chris Xiaoxuan Lu, Niki Trigoni, Andrew Markham
- **Comment**: 26 pages, 10 figures. Project website:
  https://github.com/changhao-chen/deep-learning-localization-mapping
- **Journal**: None
- **Summary**: Deep learning based localization and mapping has recently attracted significant attention. Instead of creating hand-designed algorithms through exploitation of physical models or geometric theories, deep learning based solutions provide an alternative to solve the problem in a data-driven way. Benefiting from ever-increasing volumes of data and computational power, these methods are fast evolving into a new area that offers accurate and robust systems to track motion and estimate scenes and their structure for real-world applications. In this work, we provide a comprehensive survey, and propose a new taxonomy for localization and mapping using deep learning. We also discuss the limitations of current models, and indicate possible future directions. A wide range of topics are covered, from learning odometry estimation, mapping, to global localization and simultaneous localization and mapping (SLAM). We revisit the problem of perceiving self-motion and scene understanding with on-board sensors, and show how to solve it by integrating these modules into a prospective spatial machine intelligence system (SMIS). It is our hope that this work can connect emerging works from robotics, computer vision and machine learning communities, and serve as a guide for future researchers to apply deep learning to tackle localization and mapping problems.



### LAMP: Large Deep Nets with Automated Model Parallelism for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.12575v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12575v3)
- **Published**: 2020-06-22 19:20:35+00:00
- **Updated**: 2020-09-15 17:51:41+00:00
- **Authors**: Wentao Zhu, Can Zhao, Wenqi Li, Holger Roth, Ziyue Xu, Daguang Xu
- **Comment**: MICCAI 2020 Early Accepted paper. Code is
  available\footnote{https://monai.io/research/lamp-automated-model-parallelism}
- **Journal**: None
- **Summary**: Deep Learning (DL) models are becoming larger, because the increase in model size might offer significant accuracy gain. To enable the training of large deep networks, data parallelism and model parallelism are two well-known approaches for parallel training. However, data parallelism does not help reduce memory footprint per device. In this work, we introduce Large deep 3D ConvNets with Automated Model Parallelism (LAMP) and investigate the impact of both input's and deep 3D ConvNets' size on segmentation accuracy. Through automated model parallelism, it is feasible to train large deep 3D ConvNets with a large input patch, even the whole image. Extensive experiments demonstrate that, facilitated by the automated model parallelism, the segmentation accuracy can be improved through increasing model size and input context size, and large input yields significant inference speedup compared with sliding window of small patches in the inference. Code is available\footnote{https://monai.io/research/lamp-automated-model-parallelism}.



### Auxiliary Learning by Implicit Differentiation
- **Arxiv ID**: http://arxiv.org/abs/2007.02693v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.02693v3)
- **Published**: 2020-06-22 19:35:07+00:00
- **Updated**: 2021-05-11 06:52:59+00:00
- **Authors**: Aviv Navon, Idan Achituve, Haggai Maron, Gal Chechik, Ethan Fetaya
- **Comment**: Published at ICLR 2021
- **Journal**: None
- **Summary**: Training neural networks with auxiliary tasks is a common practice for improving the performance on a main task of interest. Two main challenges arise in this multi-task learning setting: (i) designing useful auxiliary tasks; and (ii) combining auxiliary tasks into a single coherent loss. Here, we propose a novel framework, AuxiLearn, that targets both challenges based on implicit differentiation. First, when useful auxiliaries are known, we propose learning a network that combines all losses into a single coherent objective function. This network can learn non-linear interactions between tasks. Second, when no useful auxiliary task is known, we describe how to learn a network that generates a meaningful, novel auxiliary task. We evaluate AuxiLearn in a series of tasks and domains, including image segmentation and learning with attributes in the low data regime, and find that it consistently outperforms competing methods.



### Laplacian Mixture Model Point Based Registration
- **Arxiv ID**: http://arxiv.org/abs/2006.12582v1
- **DOI**: 10.1109/IranianMVIP.2015.7397504
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12582v1)
- **Published**: 2020-06-22 19:46:41+00:00
- **Updated**: 2020-06-22 19:46:41+00:00
- **Authors**: Mohammad Sadegh Majdi, Emad Fatemizadeh
- **Comment**: None
- **Journal**: 2015 9th Iranian Conference on Machine Vision and Image Processing
  (MVIP), Tehran, 2015, pp. 57-60
- **Summary**: Point base registration is an important part in many machine VISIOn applications, medical diagnostics, agricultural studies etc. The goal of point set registration is to find correspondences between different data sets and estimate the appropriate transformation that can map one set to another. Here we introduce a novel method for matching of different data sets based on Laplacian distribution. We consider the alignment of two point sets as probability density estimation problem. By using maximum likelihood methods we try to fit the Laplacian mixture model (LMM) centroids (source point set) to the data point set.



### Semantic Features Aided Multi-Scale Reconstruction of Inter-Modality Magnetic Resonance Images
- **Arxiv ID**: http://arxiv.org/abs/2006.12585v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.12585v1)
- **Published**: 2020-06-22 19:53:50+00:00
- **Updated**: 2020-06-22 19:53:50+00:00
- **Authors**: Preethi Srinivasan, Prabhjot Kaur, Aditya Nigam, Arnav Bhavsar
- **Comment**: Accepted in IEEE CMBS 2020
- **Journal**: None
- **Summary**: Long acquisition time (AQT) due to series acquisition of multi-modality MR images (especially T2 weighted images (T2WI) with longer AQT), though beneficial for disease diagnosis, is practically undesirable. We propose a novel deep network based solution to reconstruct T2W images from T1W images (T1WI) using an encoder-decoder architecture. The proposed learning is aided with semantic features by using multi-channel input with intensity values and gradient of image in two orthogonal directions. A reconstruction module (RM) augmenting the network along with a domain adaptation module (DAM) which is an encoder-decoder model built-in with sharp bottleneck module (SBM) is trained via modular training. The proposed network significantly reduces the total AQT with negligible qualitative artifacts and quantitative loss (reconstructs one volume in approximately 1 second). The testing is done on publicly available dataset with real MR images, and the proposed network shows (approximately 1dB) increase in PSNR over SOTA.



### Drive-Net: Convolutional Network for Driver Distraction Detection
- **Arxiv ID**: http://arxiv.org/abs/2006.12586v1
- **DOI**: 10.1109/SSIAI.2018.8470309
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12586v1)
- **Published**: 2020-06-22 19:54:53+00:00
- **Updated**: 2020-06-22 19:54:53+00:00
- **Authors**: Mohammed S. Majdi, Sundaresh Ram, Jonathan T. Gill, Jeffery J. Rodriguez
- **Comment**: None
- **Journal**: 2018 IEEE Southwest Symposium on Image Analysis and Interpretation
  (SSIAI), Las Vegas, NV, 2018, pp. 1-4,
- **Summary**: To help prevent motor vehicle accidents, there has been significant interest in finding an automated method to recognize signs of driver distraction, such as talking to passengers, fixing hair and makeup, eating and drinking, and using a mobile phone. In this paper, we present an automated supervised learning method called Drive-Net for driver distraction detection. Drive-Net uses a combination of a convolutional neural network (CNN) and a random decision forest for classifying images of a driver. We compare the performance of our proposed Drive-Net to two other popular machine-learning approaches: a recurrent neural network (RNN), and a multi-layer perceptron (MLP). We test the methods on a publicly available database of images acquired under a controlled environment containing about 22425 images manually annotated by an expert. Results show that Drive-Net achieves a detection accuracy of 95%, which is 2% more than the best results obtained on the same database using other methods



### RP2K: A Large-Scale Retail Product Dataset for Fine-Grained Image Classification
- **Arxiv ID**: http://arxiv.org/abs/2006.12634v7
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.12634v7)
- **Published**: 2020-06-22 21:39:56+00:00
- **Updated**: 2021-09-01 16:21:13+00:00
- **Authors**: Jingtian Peng, Chang Xiao, Yifan Li
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce RP2K, a new large-scale retail product dataset for fine-grained image classification. Unlike previous datasets focusing on relatively few products, we collect more than 500,000 images of retail products on shelves belonging to 2000 different products. Our dataset aims to advance the research in retail object recognition, which has massive applications such as automatic shelf auditing and image-based product information retrieval. Our dataset enjoys following properties: (1) It is by far the largest scale dataset in terms of product categories. (2) All images are captured manually in physical retail stores with natural lightings, matching the scenario of real applications. (3) We provide rich annotations to each object, including the sizes, shapes and flavors/scents. We believe our dataset could benefit both computer vision research and retail industry. Our dataset is publicly available at https://www.pinlandata.com/rp2k_dataset.



### Microstructure Generation via Generative Adversarial Network for Heterogeneous, Topologically Complex 3D Materials
- **Arxiv ID**: http://arxiv.org/abs/2006.13886v1
- **DOI**: None
- **Categories**: **eess.IV**, cond-mat.mtrl-sci, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.13886v1)
- **Published**: 2020-06-22 21:52:01+00:00
- **Updated**: 2020-06-22 21:52:01+00:00
- **Authors**: Tim Hsu, William K. Epting, Hokon Kim, Harry W. Abernathy, Gregory A. Hackett, Anthony D. Rollett, Paul A. Salvador, Elizabeth A. Holm
- **Comment**: submitted to JOM
- **Journal**: None
- **Summary**: Using a large-scale, experimentally captured 3D microstructure dataset, we implement the generative adversarial network (GAN) framework to learn and generate 3D microstructures of solid oxide fuel cell electrodes. The generated microstructures are visually, statistically, and topologically realistic, with distributions of microstructural parameters, including volume fraction, particle size, surface area, tortuosity, and triple phase boundary density, being highly similar to those of the original microstructure. These results are compared and contrasted with those from an established, grain-based generation algorithm (DREAM.3D). Importantly, simulations of electrochemical performance, using a locally resolved finite element model, demonstrate that the GAN generated microstructures closely match the performance distribution of the original, while DREAM.3D leads to significant differences. The ability of the generative machine learning model to recreate microstructures with high fidelity suggests that the essence of complex microstructures may be captured and represented in a compact and manipulatable form.



### Mental representations of objects reflect the ways in which we interact with them
- **Arxiv ID**: http://arxiv.org/abs/2007.04245v2
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG, q-bio.NC, 68U15, J.4; I.5.4; I.2.7
- **Links**: [PDF](http://arxiv.org/pdf/2007.04245v2)
- **Published**: 2020-06-22 22:05:56+00:00
- **Updated**: 2021-05-11 13:06:41+00:00
- **Authors**: Ka Chun Lam, Francisco Pereira, Maryam Vaziri-Pashkam, Kristin Woodard, Emalie McMahon
- **Comment**: 17 pages, 13 figures, 6 tables
- **Journal**: None
- **Summary**: In order to interact with objects in our environment, humans rely on an understanding of the actions that can be performed on them, as well as their properties. When considering concrete motor actions, this knowledge has been called the object affordance. Can this notion be generalized to any type of interaction that one can have with an object? In this paper we introduce a method to represent objects in a space where each dimension corresponds to a broad mode of interaction, based on verb selectional preferences in text corpora. This object embedding makes it possible to predict human judgments of verb applicability to objects better than a variety of alternative approaches. Furthermore, we show that the dimensions in this space can be used to predict categorical and functional dimensions in a state-of-the-art mental representation of objects, derived solely from human judgements of object similarity. These results suggest that interaction knowledge accounts for a large part of mental representations of objects.



### Artist-Guided Semiautomatic Animation Colorization
- **Arxiv ID**: http://arxiv.org/abs/2006.13717v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.13717v2)
- **Published**: 2020-06-22 22:30:39+00:00
- **Updated**: 2020-06-25 00:50:09+00:00
- **Authors**: Harrish Thasarathan, Mehran Ebrahimi
- **Comment**: This article supersedes our previous work arXiv:1904.09527
- **Journal**: The IEEE International Conference on Computer Vision (ICCV)
  Workshops, 2019
- **Summary**: There is a delicate balance between automating repetitive work in creative domains while staying true to an artist's vision. The animation industry regularly outsources large animation workloads to foreign countries where labor is inexpensive and long hours are common. Automating part of this process can be incredibly useful for reducing costs and creating manageable workloads for major animation studios and outsourced artists. We present a method for automating line art colorization by keeping artists in the loop to successfully reduce this workload while staying true to an artist's vision. By incorporating color hints and temporal information to an adversarial image-to-image framework, we show that it is possible to meet the balance between automation and authenticity through artist's input to generate colored frames with temporal consistency.



### Perceptual Adversarial Robustness: Defense Against Unseen Threat Models
- **Arxiv ID**: http://arxiv.org/abs/2006.12655v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.12655v4)
- **Published**: 2020-06-22 22:40:46+00:00
- **Updated**: 2021-07-04 19:34:05+00:00
- **Authors**: Cassidy Laidlaw, Sahil Singla, Soheil Feizi
- **Comment**: Published in ICLR 2021. Code and data are available at
  https://github.com/cassidylaidlaw/perceptual-advex
- **Journal**: None
- **Summary**: A key challenge in adversarial robustness is the lack of a precise mathematical characterization of human perception, used in the very definition of adversarial attacks that are imperceptible to human eyes. Most current attacks and defenses try to avoid this issue by considering restrictive adversarial threat models such as those bounded by $L_2$ or $L_\infty$ distance, spatial perturbations, etc. However, models that are robust against any of these restrictive threat models are still fragile against other threat models. To resolve this issue, we propose adversarial training against the set of all imperceptible adversarial examples, approximated using deep neural networks. We call this threat model the neural perceptual threat model (NPTM); it includes adversarial examples with a bounded neural perceptual distance (a neural network-based approximation of the true perceptual distance) to natural images. Through an extensive perceptual study, we show that the neural perceptual distance correlates well with human judgements of perceptibility of adversarial examples, validating our threat model.   Under the NPTM, we develop novel perceptual adversarial attacks and defenses. Because the NPTM is very broad, we find that Perceptual Adversarial Training (PAT) against a perceptual attack gives robustness against many other types of adversarial attacks. We test PAT on CIFAR-10 and ImageNet-100 against five diverse adversarial attacks. We find that PAT achieves state-of-the-art robustness against the union of these five attacks, more than doubling the accuracy over the next best model, without training against any of them. That is, PAT generalizes well to unforeseen perturbation types. This is vital in sensitive applications where a particular threat model cannot be assumed, and to the best of our knowledge, PAT is the first adversarial training defense with this property.



