# Arxiv Papers in cs.CV on 2020-06-19
### Hyperparameter Analysis for Image Captioning
- **Arxiv ID**: http://arxiv.org/abs/2006.10923v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10923v1)
- **Published**: 2020-06-19 01:49:37+00:00
- **Updated**: 2020-06-19 01:49:37+00:00
- **Authors**: Amish Patel, Aravind Varier
- **Comment**: 10 pages, 9 figures, and 7 tables
- **Journal**: None
- **Summary**: In this paper, we perform a thorough sensitivity analysis on state-of-the-art image captioning approaches using two different architectures: CNN+LSTM and CNN+Transformer. Experiments were carried out using the Flickr8k dataset. The biggest takeaway from the experiments is that fine-tuning the CNN encoder outperforms the baseline and all other experiments carried out for both architectures.



### COVIDLite: A depth-wise separable deep neural network with white balance and CLAHE for detection of COVID-19
- **Arxiv ID**: http://arxiv.org/abs/2006.13873v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, I.4.9; I.4.3
- **Links**: [PDF](http://arxiv.org/pdf/2006.13873v1)
- **Published**: 2020-06-19 02:30:34+00:00
- **Updated**: 2020-06-19 02:30:34+00:00
- **Authors**: Manu Siddhartha, Avik Santra
- **Comment**: None
- **Journal**: None
- **Summary**: Background and Objective:Currently, the whole world is facing a pandemic disease, novel Coronavirus also known as COVID-19, which spread in more than 200 countries with around 3.3 million active cases and 4.4 lakh deaths approximately. Due to rapid increase in number of cases and limited supply of testing kits, availability of alternative diagnostic method is necessary for containing the spread of COVID-19 cases at an early stage and reducing the death count. For making available an alternative diagnostic method, we proposed a deep neural network based diagnostic method which can be easily integrated with mobile devices for detection of COVID-19 and viral pneumonia using Chest X-rays (CXR) images. Methods:In this study, we have proposed a method named COVIDLite, which is a combination of white balance followed by Contrast Limited Adaptive Histogram Equalization (CLAHE) and depth-wise separable convolutional neural network (DSCNN). In this method, white balance followed by CLAHE is used as an image preprocessing step for enhancing the visibility of CXR images and DSCNN trained using sparse cross entropy is used for image classification with lesser parameters and significantly lighter in size, i.e., 8.4 MB without quantization. Results:The proposed COVIDLite method resulted in improved performance in comparison to vanilla DSCNN with no pre-processing. The proposed method achieved higher accuracy of 99.58% for binary classification, whereas 96.43% for multiclass classification and out-performed various state-of-the-art methods. Conclusion:Our proposed method, COVIDLite achieved exceptional results on various performance metrics. With detailed model interpretations, COVIDLite can assist radiologists in detecting COVID-19 patients from CXR images and can reduce the diagnosis time significantly.



### Melanoma Diagnosis with Spatio-Temporal Feature Learning on Sequential Dermoscopic Images
- **Arxiv ID**: http://arxiv.org/abs/2006.10950v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10950v1)
- **Published**: 2020-06-19 04:08:22+00:00
- **Updated**: 2020-06-19 04:08:22+00:00
- **Authors**: Zhen Yu, Jennifer Nguyen, Xiaojun Chang, John Kelly, Catriona Mclean, Lei Zhang, Victoria Mar, Zongyuan Ge
- **Comment**: submission of miccai 2020
- **Journal**: None
- **Summary**: Existing studies for automated melanoma diagnosis are based on single-time point images of lesions. However, melanocytic lesions de facto are progressively evolving and, moreover, benign lesions can progress into malignant melanoma. Ignoring cross-time morphological changes of lesions thus may lead to misdiagnosis in borderline cases. Based on the fact that dermatologists diagnose ambiguous skin lesions by evaluating the dermoscopic changes over time via follow-up examination, in this study, we propose an automated framework for melanoma diagnosis using sequential dermoscopic images. To capture the spatio-temporal characterization of dermoscopic evolution, we construct our model in a two-stream network architecture which capable of simultaneously learning appearance representations of individual lesions while performing temporal reasoning on both raw pixels difference and abstract features difference. We collect 184 cases of serial dermoscopic image data, which consists of histologically confirmed 92 benign lesions and 92 melanoma lesions, to evaluate the effectiveness of the proposed method. Our model achieved AUC of 74.34%, which is ~8% higher than that of only using single images and ~6% higher than the widely used sequence learning model based on LSTM.



### Keep Your AI-es on the Road: Tackling Distracted Driver Detection with Convolutional Neural Networks and Targeted Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.10955v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.10955v2)
- **Published**: 2020-06-19 04:56:08+00:00
- **Updated**: 2020-06-24 01:05:55+00:00
- **Authors**: Nikka Mofid, Jasmine Bayrooti, Shreya Ravi
- **Comment**: 10 pages, 11 figures
- **Journal**: None
- **Summary**: According to the World Health Organization, distracted driving is one of the leading cause of motor accidents and deaths in the world. In our study, we tackle the problem of distracted driving by aiming to build a robust multi-class classifier to detect and identify different forms of driver inattention using the State Farm Distracted Driving Dataset. We utilize combinations of pretrained image classification models, classical data augmentation, OpenCV based image preprocessing and skin segmentation augmentation approaches. Our best performing model combines several augmentation techniques, including skin segmentation, facial blurring, and classical augmentation techniques. This model achieves an approximately 15% increase in F1 score over the baseline, thus showing the promise in these techniques in enhancing the power of neural networks for the task of distracted driver detection.



### Attention Mesh: High-fidelity Face Mesh Prediction in Real-time
- **Arxiv ID**: http://arxiv.org/abs/2006.10962v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.10962v1)
- **Published**: 2020-06-19 05:07:38+00:00
- **Updated**: 2020-06-19 05:07:38+00:00
- **Authors**: Ivan Grishchenko, Artsiom Ablavatski, Yury Kartynnik, Karthik Raveendran, Matthias Grundmann
- **Comment**: 4 pages, 5 figures; CVPR Workshop on Computer Vision for Augmented
  and Virtual Reality, Seattle, WA, USA, 2020
- **Journal**: None
- **Summary**: We present Attention Mesh, a lightweight architecture for 3D face mesh prediction that uses attention to semantically meaningful regions. Our neural network is designed for real-time on-device inference and runs at over 50 FPS on a Pixel 2 phone. Our solution enables applications like AR makeup, eye tracking and AR puppeteering that rely on highly accurate landmarks for eye and lips regions. Our main contribution is a unified network architecture that achieves the same accuracy on facial landmarks as a multi-stage cascaded approach, while being 30 percent faster.



### Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms
- **Arxiv ID**: http://arxiv.org/abs/2007.04234v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.04234v1)
- **Published**: 2020-06-19 05:21:00+00:00
- **Updated**: 2020-06-19 05:21:00+00:00
- **Authors**: Xingyi Yang, Xuehai He, Yuxiao Liang, Yue Yang, Shanghang Zhang, Pengtao Xie
- **Comment**: None
- **Journal**: None
- **Summary**: Pretraining has become a standard technique in computer vision and natural language processing, which usually helps to improve performance substantially. Previously, the most dominant pretraining method is transfer learning (TL), which uses labeled data to learn a good representation network. Recently, a new pretraining approach -- self-supervised learning (SSL) -- has demonstrated promising results on a wide range of applications. SSL does not require annotated labels. It is purely conducted on input data by solving auxiliary tasks defined on the input data examples. The current reported results show that in certain applications, SSL outperforms TL and the other way around in other applications. There has not been a clear understanding on what properties of data and tasks render one approach outperforms the other. Without an informed guideline, ML researchers have to try both methods to find out which one is better empirically. It is usually time-consuming to do so. In this work, we aim to address this problem. We perform a comprehensive comparative study between SSL and TL regarding which one works better under different properties of data and tasks, including domain difference between source and target tasks, the amount of pretraining data, class imbalance in source data, and usage of target data for additional pretraining, etc. The insights distilled from our comparative studies can help ML researchers decide which method to use based on the properties of their applications.



### Cross-denoising Network against Corrupted Labels in Medical Image Segmentation with Domain Shift
- **Arxiv ID**: http://arxiv.org/abs/2006.10990v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.10990v1)
- **Published**: 2020-06-19 07:35:25+00:00
- **Updated**: 2020-06-19 07:35:25+00:00
- **Authors**: Qinming Zhang, Luyan Liu, Kai Ma, Cheng Zhuo, Yefeng Zheng
- **Comment**: Accepted by IJCAI 2020
- **Journal**: None
- **Summary**: Deep convolutional neural networks (DCNNs) have contributed many breakthroughs in segmentation tasks, especially in the field of medical imaging. However, \textit{domain shift} and \textit{corrupted annotations}, which are two common problems in medical imaging, dramatically degrade the performance of DCNNs in practice. In this paper, we propose a novel robust cross-denoising framework using two peer networks to address domain shift and corrupted label problems with a peer-review strategy. Specifically, each network performs as a mentor, mutually supervised to learn from reliable samples selected by the peer network to combat with corrupted labels. In addition, a noise-tolerant loss is proposed to encourage the network to capture the key location and filter the discrepancy under various noise-contaminant labels. To further reduce the accumulated error, we introduce a class-imbalanced cross learning using most confident predictions at the class-level. Experimental results on REFUGE and Drishti-GS datasets for optic disc (OD) and optic cup (OC) segmentation demonstrate the superior performance of our proposed approach to the state-of-the-art methods.



### Wave Propagation of Visual Stimuli in Focus of Attention
- **Arxiv ID**: http://arxiv.org/abs/2006.11035v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2006.11035v1)
- **Published**: 2020-06-19 09:33:21+00:00
- **Updated**: 2020-06-19 09:33:21+00:00
- **Authors**: Lapo Faggi, Alessandro Betti, Dario Zanca, Stefano Melacci, Marco Gori
- **Comment**: None
- **Journal**: None
- **Summary**: Fast reactions to changes in the surrounding visual environment require efficient attention mechanisms to reallocate computational resources to most relevant locations in the visual field. While current computational models keep improving their predictive ability thanks to the increasing availability of data, they still struggle approximating the effectiveness and efficiency exhibited by foveated animals. In this paper, we present a biologically-plausible computational model of focus of attention that exhibits spatiotemporal locality and that is very well-suited for parallel and distributed implementations. Attention emerges as a wave propagation process originated by visual stimuli corresponding to details and motion information. The resulting field obeys the principle of "inhibition of return" so as not to get stuck in potential holes. An accurate experimentation of the model shows that it achieves top level performance in scanpath prediction tasks. This can easily be understood at the light of a theoretical result that we establish in the paper, where we prove that as the velocity of wave propagation goes to infinity, the proposed model reduces to recently proposed state of the art gravitational models of focus of attention.



### Deep Learning-based Single Image Face Depth Data Enhancement
- **Arxiv ID**: http://arxiv.org/abs/2006.11091v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11091v3)
- **Published**: 2020-06-19 11:52:38+00:00
- **Updated**: 2021-07-27 09:09:50+00:00
- **Authors**: Torsten Schlett, Christian Rathgeb, Christoph Busch
- **Comment**: None
- **Journal**: None
- **Summary**: Face recognition can benefit from the utilization of depth data captured using low-cost cameras, in particular for presentation attack detection purposes. Depth video output from these capture devices can however contain defects such as holes or general depth inaccuracies. This work proposes a deep learning face depth enhancement method in this context of facial biometrics, which adds a security aspect to the topic. U-Net-like architectures are utilized, and the networks are compared against hand-crafted enhancer types, as well as a similar depth enhancer network from related work trained for an adjacent application scenario. All tested enhancer types exclusively use depth data as input, which differs from methods that enhance depth based on additional input data such as visible light color images. Synthetic face depth ground truth images and degraded forms thereof are created with help of PRNet, to train multiple deep learning enhancer models with different network sizes and training configurations. Evaluations are carried out on the synthetic data, on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435 images. These evaluations include an assessment of the falsification for occluded face depth input, which is relevant to biometric security. The proposed deep learning enhancers yield noticeably better results than the tested preexisting enhancers, without overly falsifying depth data when non-face input is provided, and are shown to reduce the error of a simple landmark-based PAD method.



### A machine learning-based method for estimating the number and orientations of major fascicles in diffusion-weighted magnetic resonance imaging
- **Arxiv ID**: http://arxiv.org/abs/2006.11117v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11117v1)
- **Published**: 2020-06-19 13:07:45+00:00
- **Updated**: 2020-06-19 13:07:45+00:00
- **Authors**: Davood Karimi, Lana Vasung, Camilo Jaimes, Fedel Machado-Rivas, Shadab Khan, Simon K. Warfield, Ali Gholipour
- **Comment**: None
- **Journal**: None
- **Summary**: Multi-compartment modeling of diffusion-weighted magnetic resonance imaging measurements is necessary for accurate brain connectivity analysis. Existing methods for estimating the number and orientations of fascicles in an imaging voxel either depend on non-convex optimization techniques that are sensitive to initialization and measurement noise, or are prone to predicting spurious fascicles. In this paper, we propose a machine learning-based technique that can accurately estimate the number and orientations of fascicles in a voxel. Our method can be trained with either simulated or real diffusion-weighted imaging data. Our method estimates the angle to the closest fascicle for each direction in a set of discrete directions uniformly spread on the unit sphere. This information is then processed to extract the number and orientations of fascicles in a voxel. On realistic simulated phantom data with known ground truth, our method predicts the number and orientations of crossing fascicles more accurately than several existing methods. It also leads to more accurate tractography. On real data, our method is better than or compares favorably with standard methods in terms of robustness to measurement down-sampling and also in terms of expert quality assessment of tractography results.



### From Discrete to Continuous Convolution Layers
- **Arxiv ID**: http://arxiv.org/abs/2006.11120v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11120v1)
- **Published**: 2020-06-19 13:16:06+00:00
- **Updated**: 2020-06-19 13:16:06+00:00
- **Authors**: Assaf Shocher, Ben Feinstein, Niv Haim, Michal Irani
- **Comment**: None
- **Journal**: None
- **Summary**: A basic operation in Convolutional Neural Networks (CNNs) is spatial resizing of feature maps. This is done either by strided convolution (donwscaling) or transposed convolution (upscaling). Such operations are limited to a fixed filter moving at predetermined integer steps (strides). Spatial sizes of consecutive layers are related by integer scale factors, predetermined at architectural design, and remain fixed throughout training and inference time. We propose a generalization of the common Conv-layer, from a discrete layer to a Continuous Convolution (CC) Layer. CC Layers naturally extend Conv-layers by representing the filter as a learned continuous function over sub-pixel coordinates. This allows learnable and principled resizing of feature maps, to any size, dynamically and consistently across scales. Once trained, the CC layer can be used to output any scale/size chosen at inference time. The scale can be non-integer and differ between the axes. CC gives rise to new freedoms for architectural design, such as dynamic layer shapes at inference time, or gradual architectures where the size changes by a small factor at each layer. This gives rise to many desired CNN properties, new architectural design capabilities, and useful applications. We further show that current Conv-layers suffer from inherent misalignments, which are ameliorated by CC layers.



### A Generative Model for Texture Synthesis based on Optimal Transport between Feature Distributions
- **Arxiv ID**: http://arxiv.org/abs/2007.03408v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2007.03408v2)
- **Published**: 2020-06-19 13:32:55+00:00
- **Updated**: 2021-10-18 15:08:04+00:00
- **Authors**: Antoine Houdard, Arthur Leclaire, Nicolas Papadakis, Julien Rabin
- **Comment**: None
- **Journal**: None
- **Summary**: We propose GOTEX, a general framework for texture synthesis by optimization that constrains the statistical distribution of local features. While our model encompasses several existing texture models, we focus on the case where the comparison between feature distributions relies on optimal transport distances. We show that the semi-dual formulation of optimal transport allows to control the distribution of various possible features, even if these features live in a high-dimensional space. We then study the resulting minimax optimization problem, which corresponds to a Wasserstein generative model, for which the inner concave maximization problem can be solved with standard stochastic gradient methods. The alternate optimization algorithm is shown to be versatile in terms of applications, features and architecture; in particular it allows to produce high-quality synthesized textures with different sets of features. We analyze the results obtained by constraining the distribution of patches or the distribution of responses to a pre-learned VGG neural network. We show that the patch representation can retrieve the desired textural aspect in a more precise manner. We also provide a detailed comparison with state-of-the-art texture synthesis methods. The GOTEX model based on patch features is also adapted to texture inpainting and texture interpolation. Finally, we show how to use our framework to learn a feed-forward neural network that can synthesize on-the-fly new textures of arbitrary size in a very fast manner. Experimental results and comparisons with the mainstream methods from the literature illustrate the relevance of the generative models learned with GOTEX.



### Deep Transformation-Invariant Clustering
- **Arxiv ID**: http://arxiv.org/abs/2006.11132v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11132v2)
- **Published**: 2020-06-19 13:43:08+00:00
- **Updated**: 2020-10-27 18:08:13+00:00
- **Authors**: Tom Monnier, Thibault Groueix, Mathieu Aubry
- **Comment**: Accepted at NeurIPS 2020 (oral). Project webpage:
  http://imagine.enpc.fr/~monniert/DTIClustering/
- **Journal**: None
- **Summary**: Recent advances in image clustering typically focus on learning better deep representations. In contrast, we present an orthogonal approach that does not rely on abstract features but instead learns to predict image transformations and performs clustering directly in image space. This learning process naturally fits in the gradient-based training of K-means and Gaussian mixture model, without requiring any additional loss or hyper-parameters. It leads us to two new deep transformation-invariant clustering frameworks, which jointly learn prototypes and transformations. More specifically, we use deep learning modules that enable us to resolve invariance to spatial, color and morphological transformations. Our approach is conceptually simple and comes with several advantages, including the possibility to easily adapt the desired invariance to the task and a strong interpretability of both cluster centers and assignments to clusters. We demonstrate that our novel approach yields competitive and highly promising results on standard image clustering benchmarks. Finally, we showcase its robustness and the advantages of its improved interpretability by visualizing clustering results over real photograph collections.



### Pupil Center Detection Approaches: A comparative analysis
- **Arxiv ID**: http://arxiv.org/abs/2006.11147v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11147v1)
- **Published**: 2020-06-19 14:19:07+00:00
- **Updated**: 2020-06-19 14:19:07+00:00
- **Authors**: Talía Vázquez Romaguera, Liset Vázquez Romaguera, David Castro Piñol, Carlos Román Vázquez Seisdedos
- **Comment**: 15 pages, 9 figures, submitted to the journal "Computaci\'on y
  Sistemas"
- **Journal**: None
- **Summary**: In the last decade, the development of technologies and tools for eye tracking has been a constantly growing area. Detecting the center of the pupil, using image processing techniques, has been an essential step in this process. A large number of techniques have been proposed for pupil center detection using both traditional image processing and machine learning-based methods. Despite the large number of methods proposed, no comparative work on their performance was found, using the same images and performance metrics. In this work, we aim at comparing four of the most frequently cited traditional methods for pupil center detection in terms of accuracy, robustness, and computational cost. These methods are based on the circular Hough transform, ellipse fitting, Daugman's integro-differential operator and radial symmetry transform. The comparative analysis was performed with 800 infrared images from the CASIA-IrisV3 and CASIA-IrisV4 databases containing various types of disturbances. The best performance was obtained by the method based on the radial symmetry transform with an accuracy and average robustness higher than 94%. The shortest processing time, obtained with the ellipse fitting method, was 0.06 s.



### Compositional Learning of Image-Text Query for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2006.11149v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/2006.11149v3)
- **Published**: 2020-06-19 14:21:41+00:00
- **Updated**: 2021-05-31 21:35:55+00:00
- **Authors**: Muhammad Umer Anwaar, Egor Labintcev, Martin Kleinsteuber
- **Comment**: Published at IEEE WACV 2021
- **Journal**: None
- **Summary**: In this paper, we investigate the problem of retrieving images from a database based on a multi-modal (image-text) query. Specifically, the query text prompts some modification in the query image and the task is to retrieve images with the desired modifications. For instance, a user of an E-Commerce platform is interested in buying a dress, which should look similar to her friend's dress, but the dress should be of white color with a ribbon sash. In this case, we would like the algorithm to retrieve some dresses with desired modifications in the query dress. We propose an autoencoder based model, ComposeAE, to learn the composition of image and text query for retrieving images. We adopt a deep metric learning approach and learn a metric that pushes composition of source image and text query closer to the target images. We also propose a rotational symmetry constraint on the optimization problem. Our approach is able to outperform the state-of-the-art method TIRG \cite{TIRG} on three benchmark datasets, namely: MIT-States, Fashion200k and Fashion IQ. In order to ensure fair comparison, we introduce strong baselines by enhancing TIRG method. To ensure reproducibility of the results, we publish our code here: \url{https://github.com/ecom-research/ComposeAE}.



### Concatenated Attention Neural Network for Image Restoration
- **Arxiv ID**: http://arxiv.org/abs/2006.11162v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11162v1)
- **Published**: 2020-06-19 14:49:25+00:00
- **Updated**: 2020-06-19 14:49:25+00:00
- **Authors**: Tian YingJie, Wang YiQi, Yang LinRui, Qi ZhiQuan
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a general framework for low-level vision tasks including image compression artifacts reduction and image denoising. Under this framework, a novel concatenated attention neural network (CANet) is specifically designed for image restoration. The main contributions of this paper are as follows: First, by applying concise but effective concatenation and feature selection mechanism, we establish a novel connection mechanism which connect different modules in the modules stacking network. Second, both pixel-wise and channel-wise attention mechanisms are used in each module convolution layer, which promotes further extraction of more essential information in images. Lastly, we demonstrate that CANet achieves better results than previous state-of-the-art approaches with sufficient experiments in compression artifacts removing and image denoising.



### Emotion Recognition on large video dataset based on Convolutional Feature Extractor and Recurrent Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2006.11168v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11168v1)
- **Published**: 2020-06-19 14:54:13+00:00
- **Updated**: 2020-06-19 14:54:13+00:00
- **Authors**: Denis Rangulov, Muhammad Fahim
- **Comment**: 6 pages, 7 figures, Face and Gesture 2020 Workshop Paper (ABAW2020
  competition)
- **Journal**: None
- **Summary**: For many years, the emotion recognition task has remained one of the most interesting and important problems in the field of human-computer interaction. In this study, we consider the emotion recognition task as a classification as well as a regression task by processing encoded emotions in different datasets using deep learning models. Our model combines convolutional neural network (CNN) with recurrent neural network (RNN) to predict dimensional emotions on video data. At the first step, CNN extracts feature vectors from video frames. In the second step, we fed these feature vectors to train RNN for exploiting the temporal dynamics of video. Furthermore, we analyzed how each neural network contributes to the system's overall performance. The experiments are performed on publicly available datasets including the largest modern Aff-Wild2 database. It contains over sixty hours of video data. We discovered the problem of overfitting of the model on an unbalanced dataset with an illustrative example using confusion matrices. The problem is solved by downsampling technique to balance the dataset. By significantly decreasing training data, we balance the dataset, thereby, the overall performance of the model is improved. Hence, the study qualitatively describes the abilities of deep learning models exploring enough amount of data to predict facial emotions. Our proposed method is implemented using Tensorflow Keras.



### Evaluation Of Hidden Markov Models Using Deep CNN Features In Isolated Sign Recognition
- **Arxiv ID**: http://arxiv.org/abs/2006.11183v2
- **DOI**: 10.1007/s11042-021-10593-w
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11183v2)
- **Published**: 2020-06-19 15:18:03+00:00
- **Updated**: 2021-05-10 13:24:33+00:00
- **Authors**: Anil Osman Tur, Hacer Yalim Keles
- **Comment**: This paper is the preprint of the accepted manuscript at Multimedia
  Tools and Applications Journal. It contains 16 pages, 5 figure, 8 tables
- **Journal**: None
- **Summary**: Isolated sign recognition from video streams is a challenging problem due to the multi-modal nature of the signs, where both local and global hand features and face gestures needs to be attended simultaneously. This problem has recently been studied widely using deep Convolutional Neural Network (CNN) based features and Long Short-Term Memory (LSTM) based deep sequence models. However, the current literature is lack of providing empirical analysis using Hidden Markov Models (HMMs) with deep features. In this study, we provide a framework that is composed of three modules to solve isolated sign recognition problem using different sequence models. The dimensions of deep features are usually too large to work with HMM models. To solve this problem, we propose two alternative CNN based architectures as the second module in our framework, to reduce deep feature dimensions effectively. After extensive experiments, we show that using pretrained Resnet50 features and one of our CNN based dimension reduction models, HMMs can classify isolated signs with 90.15% accuracy in Montalbano dataset using RGB and Skeletal data. This performance is comparable with the current LSTM based models. HMMs have fewer parameters and can be trained and run on commodity computers fast, without requiring GPUs. Therefore, our analysis with deep features show that HMMs could also be utilized as well as deep sequence models in challenging isolated sign recognition problem.



### Poisson Learning: Graph Based Semi-Supervised Learning At Very Low Label Rates
- **Arxiv ID**: http://arxiv.org/abs/2006.11184v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NA, math.AP, math.NA, stat.ML, 35J08, 35J15, 05C81, 68T05, 35R02, I.2.6; G.1.8; G.2.2; I.5.3; I.4.0
- **Links**: [PDF](http://arxiv.org/pdf/2006.11184v2)
- **Published**: 2020-06-19 15:21:04+00:00
- **Updated**: 2020-08-14 14:46:56+00:00
- **Authors**: Jeff Calder, Brendan Cook, Matthew Thorpe, Dejan Slepcev
- **Comment**: Proceedings of the 37th International Conference on Machine Learning,
  Online, PMLR 119, 2020
- **Journal**: None
- **Summary**: We propose a new framework, called Poisson learning, for graph based semi-supervised learning at very low label rates. Poisson learning is motivated by the need to address the degeneracy of Laplacian semi-supervised learning in this regime. The method replaces the assignment of label values at training points with the placement of sources and sinks, and solves the resulting Poisson equation on the graph. The outcomes are provably more stable and informative than those of Laplacian learning. Poisson learning is efficient and simple to implement, and we present numerical experiments showing the method is superior to other recent approaches to semi-supervised learning at low label rates on MNIST, FashionMNIST, and Cifar-10. We also propose a graph-cut enhancement of Poisson learning, called Poisson MBO, that gives higher accuracy and can incorporate prior knowledge of relative class sizes.



### Adaptive feature recombination and recalibration for semantic segmentation with Fully Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/2006.11193v1
- **DOI**: 10.1109/TMI.2019.2918096
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11193v1)
- **Published**: 2020-06-19 15:45:03+00:00
- **Updated**: 2020-06-19 15:45:03+00:00
- **Authors**: Sergio Pereira, Adriano Pinto, Joana Amorim, Alexandrine Ribeiro, Victor Alves, Carlos A. Silva
- **Comment**: Published in IEEE Transactions on Medical Imaging (TMI)
- **Journal**: IEEE Transactions on Medical Imaging, vol. 38, no. 12, pp.
  2914-2925, Dec. 2019
- **Summary**: Fully Convolutional Networks have been achieving remarkable results in image semantic segmentation, while being efficient. Such efficiency results from the capability of segmenting several voxels in a single forward pass. So, there is a direct spatial correspondence between a unit in a feature map and the voxel in the same location. In a convolutional layer, the kernel spans over all channels and extracts information from them. We observe that linear recombination of feature maps by increasing the number of channels followed by compression may enhance their discriminative power. Moreover, not all feature maps have the same relevance for the classes being predicted. In order to learn the inter-channel relationships and recalibrate the channels to suppress the less relevant ones, Squeeze and Excitation blocks were proposed in the context of image classification with Convolutional Neural Networks. However, this is not well adapted for segmentation with Fully Convolutional Networks since they segment several objects simultaneously, hence a feature map may contain relevant information only in some locations. In this paper, we propose recombination of features and a spatially adaptive recalibration block that is adapted for semantic segmentation with Fully Convolutional Networks - the SegSE block. Feature maps are recalibrated by considering the cross-channel information together with spatial relevance. Experimental results indicate that Recombination and Recalibration improve the results of a competitive baseline, and generalize across three different problems: brain tumor segmentation, stroke penumbra estimation, and ischemic stroke lesion outcome prediction. The obtained results are competitive or outperform the state of the art in the three applications.



### Embedded Encoder-Decoder in Convolutional Networks Towards Explainable AI
- **Arxiv ID**: http://arxiv.org/abs/2007.06712v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2007.06712v1)
- **Published**: 2020-06-19 15:49:39+00:00
- **Updated**: 2020-06-19 15:49:39+00:00
- **Authors**: Amirhossein Tavanaei
- **Comment**: None
- **Journal**: None
- **Summary**: Understanding intermediate layers of a deep learning model and discovering the driving features of stimuli have attracted much interest, recently. Explainable artificial intelligence (XAI) provides a new way to open an AI black box and makes a transparent and interpretable decision. This paper proposes a new explainable convolutional neural network (XCNN) which represents important and driving visual features of stimuli in an end-to-end model architecture. This network employs encoder-decoder neural networks in a CNN architecture to represent regions of interest in an image based on its category. The proposed model is trained without localization labels and generates a heat-map as part of the network architecture without extra post-processing steps. The experimental results on the CIFAR-10, Tiny ImageNet, and MNIST datasets showed the success of our algorithm (XCNN) to make CNNs explainable. Based on visual assessment, the proposed model outperforms the current algorithms in class-specific feature representation and interpretable heatmap generation while providing a simple and flexible network architecture. The initial success of this approach warrants further study to enhance weakly supervised localization and semantic segmentation in explainable frameworks.



### Frustratingly Simple Domain Generalization via Image Stylization
- **Arxiv ID**: http://arxiv.org/abs/2006.11207v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11207v2)
- **Published**: 2020-06-19 16:20:40+00:00
- **Updated**: 2020-07-10 15:13:11+00:00
- **Authors**: Nathan Somavarapu, Chih-Yao Ma, Zsolt Kira
- **Comment**: Code: https://github.com/GT-RIPL/DomainGeneralization-Stylization
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) show impressive performance in the standard classification setting where training and testing data are drawn i.i.d. from a given domain. However, CNNs do not readily generalize to new domains with different statistics, a setting that is simple for humans. In this work, we address the Domain Generalization problem, where the classifier must generalize to an unknown target domain. Inspired by recent works that have shown a difference in biases between CNNs and humans, we demonstrate an extremely simple yet effective method, namely correcting this bias by augmenting the dataset with stylized images. In contrast with existing stylization works, which use external data sources such as art, we further introduce a method that is entirely in-domain using no such extra sources of data. We provide a detailed analysis as to the mechanism by which the method works, verifying our claim that it changes the shape/texture bias, and demonstrate results surpassing or comparable to the state of the arts that utilize much more complex methods.



### Unified Representation Learning for Efficient Medical Image Analysis
- **Arxiv ID**: http://arxiv.org/abs/2006.11223v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11223v2)
- **Published**: 2020-06-19 16:52:16+00:00
- **Updated**: 2021-06-08 00:04:34+00:00
- **Authors**: Ghada Zamzmi, Sivaramakrishnan Rajaraman, Sameer Antani
- **Comment**: None
- **Journal**: Under Review 2020
- **Summary**: Medical image analysis typically includes several tasks such as enhancement, segmentation, and classification. Traditionally, these tasks are implemented using separate deep learning models for separate tasks, which is not efficient because it involves unnecessary training repetitions, demands greater computational resources, and requires a relatively large amount of labeled data. In this paper, we propose a multi-task training approach for medical image analysis, where individual tasks are fine-tuned simultaneously through relevant knowledge transfer using a unified modality-specific feature representation (UMS-Rep). We explore different fine-tuning strategies to demonstrate the impact of the strategy on the performance of target medical image tasks. We experiment with different visual tasks (e.g., image denoising, segmentation, and classification) to highlight the advantages offered with our approach for two imaging modalities, chest X-ray and Doppler echocardiography. Our results demonstrate that the proposed approach reduces the overall demand for computational resources and improves target task generalization and performance. Further, our results prove that the performance of target tasks in medical images is highly influenced by the utilized fine-tuning strategy.



### Lookahead Adversarial Learning for Near Real-Time Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.11227v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11227v3)
- **Published**: 2020-06-19 17:04:38+00:00
- **Updated**: 2021-01-21 15:00:09+00:00
- **Authors**: Hadi Jamali-Rad, Attila Szabo
- **Comment**: 25 pages
- **Journal**: None
- **Summary**: Semantic segmentation is one of the most fundamental problems in computer vision with significant impact on a wide variety of applications. Adversarial learning is shown to be an effective approach for improving semantic segmentation quality by enforcing higher-level pixel correlations and structural information. However, state-of-the-art semantic segmentation models cannot be easily plugged into an adversarial setting because they are not designed to accommodate convergence and stability issues in adversarial networks. We bridge this gap by building a conditional adversarial network with a state-of-the-art segmentation model (DeepLabv3+) at its core. To battle the stability issues, we introduce a novel lookahead adversarial learning (LoAd) approach with an embedded label map aggregation module. We focus on semantic segmentation models that run fast at inference for near real-time field applications. Through extensive experimentation, we demonstrate that the proposed solution can alleviate divergence issues in an adversarial semantic segmentation setting and results in considerable performance improvements (+5% in some classes) on the baseline for three standard datasets.



### Consistency Guided Scene Flow Estimation
- **Arxiv ID**: http://arxiv.org/abs/2006.11242v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11242v2)
- **Published**: 2020-06-19 17:28:07+00:00
- **Updated**: 2020-08-17 09:58:47+00:00
- **Authors**: Yuhua Chen, Luc Van Gool, Cordelia Schmid, Cristian Sminchisescu
- **Comment**: None
- **Journal**: None
- **Summary**: Consistency Guided Scene Flow Estimation (CGSF) is a self-supervised framework for the joint reconstruction of 3D scene structure and motion from stereo video. The model takes two temporal stereo pairs as input, and predicts disparity and scene flow. The model self-adapts at test time by iteratively refining its predictions. The refinement process is guided by a consistency loss, which combines stereo and temporal photo-consistency with a geometric term that couples disparity and 3D motion. To handle inherent modeling error in the consistency loss (e.g. Lambertian assumptions) and for better generalization, we further introduce a learned, output refinement network, which takes the initial predictions, the loss, and the gradient as input, and efficiently predicts a correlated output update. In multiple experiments, including ablation studies, we show that the proposed model can reliably predict disparity and scene flow in challenging imagery, achieves better generalization than the state-of-the-art, and adapts quickly and robustly to unseen domains.



### Center-based 3D Object Detection and Tracking
- **Arxiv ID**: http://arxiv.org/abs/2006.11275v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11275v2)
- **Published**: 2020-06-19 17:59:39+00:00
- **Updated**: 2021-01-06 18:56:03+00:00
- **Authors**: Tianwei Yin, Xingyi Zhou, Philipp Krähenbühl
- **Comment**: update nuScenes and Waymo results
- **Journal**: Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR) 2021
- **Summary**: Three-dimensional objects are commonly represented as 3D boxes in a point-cloud. This representation mimics the well-studied image-based 2D bounding-box detection but comes with additional challenges. Objects in a 3D world do not follow any particular orientation, and box-based detectors have difficulties enumerating all orientations or fitting an axis-aligned bounding box to rotated objects. In this paper, we instead propose to represent, detect, and track 3D objects as points. Our framework, CenterPoint, first detects centers of objects using a keypoint detector and regresses to other attributes, including 3D size, 3D orientation, and velocity. In a second stage, it refines these estimates using additional point features on the object. In CenterPoint, 3D object tracking simplifies to greedy closest-point matching. The resulting detection and tracking algorithm is simple, efficient, and effective. CenterPoint achieved state-of-the-art performance on the nuScenes benchmark for both 3D detection and tracking, with 65.5 NDS and 63.8 AMOTA for a single model. On the Waymo Open Dataset, CenterPoint outperforms all previous single model method by a large margin and ranks first among all Lidar-only submissions. The code and pretrained models are available at https://github.com/tianweiy/CenterPoint.



### SqueezeBERT: What can computer vision teach NLP about efficient neural networks?
- **Arxiv ID**: http://arxiv.org/abs/2006.11316v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2006.11316v1)
- **Published**: 2020-06-19 18:40:29+00:00
- **Updated**: 2020-06-19 18:40:29+00:00
- **Authors**: Forrest N. Iandola, Albert E. Shaw, Ravi Krishna, Kurt W. Keutzer
- **Comment**: 9 pages + appendix
- **Journal**: None
- **Summary**: Humans read and write hundreds of billions of messages every day. Further, due to the availability of large datasets, large computing systems, and better neural network models, natural language processing (NLP) technology has made significant strides in understanding, proofreading, and organizing these messages. Thus, there is a significant opportunity to deploy NLP in myriad applications to help web users, social networks, and businesses. In particular, we consider smartphones and other mobile devices as crucial platforms for deploying NLP models at scale. However, today's highly-accurate NLP neural network models such as BERT and RoBERTa are extremely computationally expensive, with BERT-base taking 1.7 seconds to classify a text snippet on a Pixel 3 smartphone. In this work, we observe that methods such as grouped convolutions have yielded significant speedups for computer vision networks, but many of these techniques have not been adopted by NLP neural network designers. We demonstrate how to replace several operations in self-attention layers with grouped convolutions, and we use this technique in a novel network architecture called SqueezeBERT, which runs 4.3x faster than BERT-base on the Pixel 3 while achieving competitive accuracy on the GLUE test set. The SqueezeBERT code will be released.



### Self-Supervised Prototypical Transfer Learning for Few-Shot Classification
- **Arxiv ID**: http://arxiv.org/abs/2006.11325v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11325v1)
- **Published**: 2020-06-19 19:00:11+00:00
- **Updated**: 2020-06-19 19:00:11+00:00
- **Authors**: Carlos Medina, Arnout Devos, Matthias Grossglauser
- **Comment**: Extended version of work presented at the 7th ICML Workshop on
  Automated Machine Learning (2020). Code available at
  https://github.com/indy-lab/ProtoTransfer ; 17 pages, 3 figures, 12 tables
- **Journal**: None
- **Summary**: Most approaches in few-shot learning rely on costly annotated data related to the goal task domain during (pre-)training. Recently, unsupervised meta-learning methods have exchanged the annotation requirement for a reduction in few-shot classification performance. Simultaneously, in settings with realistic domain shift, common transfer learning has been shown to outperform supervised meta-learning. Building on these insights and on advances in self-supervised learning, we propose a transfer learning approach which constructs a metric embedding that clusters unlabeled prototypical samples and their augmentations closely together. This pre-trained embedding is a starting point for few-shot classification by summarizing class clusters and fine-tuning. We demonstrate that our self-supervised prototypical transfer learning approach ProtoTransfer outperforms state-of-the-art unsupervised meta-learning methods on few-shot tasks from the mini-ImageNet dataset. In few-shot experiments with domain shift, our approach even has comparable performance to supervised methods, but requires orders of magnitude fewer labels.



### Class Normalization for (Continual)? Generalized Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2006.11328v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11328v2)
- **Published**: 2020-06-19 19:05:24+00:00
- **Updated**: 2021-04-14 16:12:34+00:00
- **Authors**: Ivan Skorokhodov, Mohamed Elhoseiny
- **Comment**: 22 pages, 7 figures, 7 tables
- **Journal**: None
- **Summary**: Normalization techniques have proved to be a crucial ingredient of successful training in a traditional supervised learning regime. However, in the zero-shot learning (ZSL) world, these ideas have received only marginal attention. This work studies normalization in ZSL scenario from both theoretical and practical perspectives. First, we give a theoretical explanation to two popular tricks used in zero-shot learning: normalize+scale and attributes normalization and show that they help training by preserving variance during a forward pass. Next, we demonstrate that they are insufficient to normalize a deep ZSL model and propose Class Normalization (CN): a normalization scheme, which alleviates this issue both provably and in practice. Third, we show that ZSL models typically have more irregular loss surface compared to traditional classifiers and that the proposed method partially remedies this problem. Then, we test our approach on 4 standard ZSL datasets and outperform sophisticated modern SotA with a simple MLP optimized without any bells and whistles and having ~50 times faster training speed. Finally, we generalize ZSL to a broader problem -- continual ZSL, and introduce some principled metrics and rigorous baselines for this new setup. The project page is located at https://universome.github.io/class-norm.



### Image Sentiment Transfer
- **Arxiv ID**: http://arxiv.org/abs/2006.11337v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11337v1)
- **Published**: 2020-06-19 19:28:08+00:00
- **Updated**: 2020-06-19 19:28:08+00:00
- **Authors**: Tianlang Chen, Wei Xiong, Haitian Zheng, Jiebo Luo
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we introduce an important but still unexplored research task -- image sentiment transfer. Compared with other related tasks that have been well-studied, such as image-to-image translation and image style transfer, transferring the sentiment of an image is more challenging. Given an input image, the rule to transfer the sentiment of each contained object can be completely different, making existing approaches that perform global image transfer by a single reference image inadequate to achieve satisfactory performance. In this paper, we propose an effective and flexible framework that performs image sentiment transfer at the object level. It first detects the objects and extracts their pixel-level masks, and then performs object-level sentiment transfer guided by multiple reference images for the corresponding objects. For the core object-level sentiment transfer, we propose a novel Sentiment-aware GAN (SentiGAN). Both global image-level and local object-level supervisions are imposed to train SentiGAN. More importantly, an effective content disentanglement loss cooperating with a content alignment step is applied to better disentangle the residual sentiment-related information of the input image. Extensive quantitative and qualitative experiments are performed on the object-oriented VSO dataset we create, demonstrating the effectiveness of the proposed framework.



### Video Panoptic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2006.11339v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11339v1)
- **Published**: 2020-06-19 19:35:47+00:00
- **Updated**: 2020-06-19 19:35:47+00:00
- **Authors**: Dahun Kim, Sanghyun Woo, Joon-Young Lee, In So Kweon
- **Comment**: CVPR 2020 Oral. Code: see https://github.com/mcahny/vps
- **Journal**: None
- **Summary**: Panoptic segmentation has become a new standard of visual recognition task by unifying previous semantic segmentation and instance segmentation tasks in concert. In this paper, we propose and explore a new video extension of this task, called video panoptic segmentation. The task requires generating consistent panoptic segmentation as well as an association of instance ids across video frames. To invigorate research on this new task, we present two types of video panoptic datasets. The first is a re-organization of the synthetic VIPER dataset into the video panoptic format to exploit its large-scale pixel annotations. The second is a temporal extension on the Cityscapes val. set, by providing new video panoptic annotations (Cityscapes-VPS). Moreover, we propose a novel video panoptic segmentation network (VPSNet) which jointly predicts object classes, bounding boxes, masks, instance id tracking, and semantic segmentation in video frames. To provide appropriate metrics for this task, we propose a video panoptic quality (VPQ) metric and evaluate our method and several other baselines. Experimental results demonstrate the effectiveness of the presented two datasets. We achieve state-of-the-art results in image PQ on Cityscapes and also in VPQ on Cityscapes-VPS and VIPER datasets. The datasets and code are made publicly available.



### Real-time Pupil Tracking from Monocular Video for Digital Puppetry
- **Arxiv ID**: http://arxiv.org/abs/2006.11341v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11341v1)
- **Published**: 2020-06-19 19:39:32+00:00
- **Updated**: 2020-06-19 19:39:32+00:00
- **Authors**: Artsiom Ablavatski, Andrey Vakunov, Ivan Grishchenko, Karthik Raveendran, Matsvei Zhdanovich
- **Comment**: None
- **Journal**: None
- **Summary**: We present a simple, real-time approach for pupil tracking from live video on mobile devices. Our method extends a state-of-the-art face mesh detector with two new components: a tiny neural network that predicts positions of the pupils in 2D, and a displacement-based estimation of the pupil blend shape coefficients. Our technique can be used to accurately control the pupil movements of a virtual puppet, and lends liveliness and energy to it. The proposed approach runs at over 50 FPS on modern phones, and enables its usage in any real-time puppeteering pipeline.



### Manifolds for Unsupervised Visual Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/2006.11364v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2006.11364v1)
- **Published**: 2020-06-19 20:41:58+00:00
- **Updated**: 2020-06-19 20:41:58+00:00
- **Authors**: Louise Naud, Alexander Lavin
- **Comment**: None
- **Journal**: None
- **Summary**: Anomalies are by definition rare, thus labeled examples are very limited or nonexistent, and likely do not cover unforeseen scenarios. Unsupervised learning methods that don't necessarily encounter anomalies in training would be immensely useful. Generative vision models can be useful in this regard but do not sufficiently represent normal and abnormal data distributions. To this end, we propose constant curvature manifolds for embedding data distributions in unsupervised visual anomaly detection. Through theoretical and empirical explorations of manifold shapes, we develop a novel hyperspherical Variational Auto-Encoder (VAE) via stereographic projections with a gyroplane layer - a complete equivalent to the Poincar\'e VAE. This approach with manifold projections is beneficial in terms of model generalization and can yield more interpretable representations. We present state-of-the-art results on visual anomaly benchmarks in precision manufacturing and inspection, demonstrating real-world utility in industrial AI scenarios. We further demonstrate the approach on the challenging problem of histopathology: our unsupervised approach effectively detects cancerous brain tissue from noisy whole-slide images, learning a smooth, latent organization of tissue types that provides an interpretable decisions tool for medical professionals.



### A survey of face recognition techniques under occlusion
- **Arxiv ID**: http://arxiv.org/abs/2006.11366v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11366v1)
- **Published**: 2020-06-19 20:44:02+00:00
- **Updated**: 2020-06-19 20:44:02+00:00
- **Authors**: Dan Zeng, Raymond Veldhuis, Luuk Spreeuwers
- **Comment**: None
- **Journal**: None
- **Summary**: The limited capacity to recognize faces under occlusions is a long-standing problem that presents a unique challenge for face recognition systems and even for humans. The problem regarding occlusion is less covered by research when compared to other challenges such as pose variation, different expressions, etc. Nevertheless, occluded face recognition is imperative to exploit the full potential of face recognition for real-world applications. In this paper, we restrict the scope to occluded face recognition. First, we explore what the occlusion problem is and what inherent difficulties can arise. As a part of this review, we introduce face detection under occlusion, a preliminary step in face recognition. Second, we present how existing face recognition methods cope with the occlusion problem and classify them into three categories, which are 1) occlusion robust feature extraction approaches, 2) occlusion aware face recognition approaches, and 3) occlusion recovery based face recognition approaches. Furthermore, we analyze the motivations, innovations, pros and cons, and the performance of representative approaches for comparison. Finally, future challenges and method trends of occluded face recognition are thoroughly discussed.



### Quantile-Quantile Embedding for Distribution Transformation and Manifold Embedding with Ability to Choose the Embedding Distribution
- **Arxiv ID**: http://arxiv.org/abs/2006.11385v2
- **DOI**: 10.1016/j.mlwa.2021.100088
- **Categories**: **stat.ML**, cs.CV, cs.LG, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/2006.11385v2)
- **Published**: 2020-06-19 21:09:09+00:00
- **Updated**: 2021-07-09 03:06:05+00:00
- **Authors**: Benyamin Ghojogh, Fakhri Karray, Mark Crowley
- **Comment**: Published in Machine Learning with Applications, Elsevier, Volume 6,
  Pages 100088, 2021
- **Journal**: Machine Learning with Applications, Elsevier, Volume 6, Pages
  100088, 2021
- **Summary**: We propose a new embedding method, named Quantile-Quantile Embedding (QQE), for distribution transformation and manifold embedding with the ability to choose the embedding distribution. QQE, which uses the concept of quantile-quantile plot from visual statistical tests, can transform the distribution of data to any theoretical desired distribution or empirical reference sample. Moreover, QQE gives the user a choice of embedding distribution in embedding the manifold of data into the low dimensional embedding space. It can also be used for modifying the embedding distribution of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric learning, for better representation or visualization of data. We propose QQE in both unsupervised and supervised forms. QQE can also transform a distribution to either an exact reference distribution or its shape. We show that QQE allows for better discrimination of classes in some cases. Our experiments on different synthetic and image datasets show the effectiveness of the proposed embedding method.



### A Symbolic Temporal Pooling method for Video-based Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/2006.11416v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11416v1)
- **Published**: 2020-06-19 21:52:33+00:00
- **Updated**: 2020-06-19 21:52:33+00:00
- **Authors**: S V Aruna Kumar, Ehsan Yaghoubi, Hugo Proença
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: In video-based person re-identification, both the spatial and temporal features are known to provide orthogonal cues to effective representations. Such representations are currently typically obtained by aggregating the frame-level features using max/avg pooling, at different points of the models. However, such operations also decrease the amount of discriminating information available, which is particularly hazardous in case of poor separability between the different classes. To alleviate this problem, this paper introduces a symbolic temporal pooling method, where frame-level features are represented in the distribution valued symbolic form, yielding from fitting an Empirical Cumulative Distribution Function (ECDF) to each feature. Also, considering that the original triplet loss formulation cannot be applied directly to this kind of representations, we introduce a symbolic triplet loss function that infers the similarity between two symbolic objects. Having carried out an extensive empirical evaluation of the proposed solution against the state-of-the-art, in four well known data sets (MARS, iLIDS-VID, PRID2011 and P-DESTRE), the observed results point for consistent improvements in performance over the previous best performing techniques.



### A Multiparametric Class of Low-complexity Transforms for Image and Video Coding
- **Arxiv ID**: http://arxiv.org/abs/2006.11418v1
- **DOI**: 10.1016/j.sigpro.2020.107685
- **Categories**: **eess.SP**, cs.CV, cs.MM, eess.IV, stat.ME, 94A08, MSC 33F05
- **Links**: [PDF](http://arxiv.org/pdf/2006.11418v1)
- **Published**: 2020-06-19 21:56:58+00:00
- **Updated**: 2020-06-19 21:56:58+00:00
- **Authors**: D. R. Canterle, T. L. T. da Silveira, F. M. Bayer, R. J. Cintra
- **Comment**: Fixed Figure 1 and typos in the reference list
- **Journal**: Signal Processing, Volume 176, November 2020
- **Summary**: Discrete transforms play an important role in many signal processing applications, and low-complexity alternatives for classical transforms became popular in recent years. Particularly, the discrete cosine transform (DCT) has proven to be convenient for data compression, being employed in well-known image and video coding standards such as JPEG, H.264, and the recent high efficiency video coding (HEVC). In this paper, we introduce a new class of low-complexity 8-point DCT approximations based on a series of works published by Bouguezel, Ahmed and Swamy. Also, a multiparametric fast algorithm that encompasses both known and novel transforms is derived. We select the best-performing DCT approximations after solving a multicriteria optimization problem, and submit them to a scaling method for obtaining larger size transforms. We assess these DCT approximations in both JPEG-like image compression and video coding experiments. We show that the optimal DCT approximations present compelling results in terms of coding efficiency and image quality metrics, and require only few addition or bit-shifting operations, being suitable for low-complexity and low-power systems.



### Capturing Video Frame Rate Variations via Entropic Differencing
- **Arxiv ID**: http://arxiv.org/abs/2006.11424v2
- **DOI**: 10.1109/LSP.2020.3028687
- **Categories**: **cs.MM**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2006.11424v2)
- **Published**: 2020-06-19 22:16:52+00:00
- **Updated**: 2020-10-21 01:02:00+00:00
- **Authors**: Pavan C. Madhusudana, Neil Birkbeck, Yilin Wang, Balu Adsumilli, Alan C. Bovik
- **Comment**: None
- **Journal**: IEEE Signal Processing Letters. 27 (2020) 1809-1813
- **Summary**: High frame rate videos are increasingly getting popular in recent years, driven by the strong requirements of the entertainment and streaming industries to provide high quality of experiences to consumers. To achieve the best trade-offs between the bandwidth requirements and video quality in terms of frame rate adaptation, it is imperative to understand the effects of frame rate on video quality. In this direction, we devise a novel statistical entropic differencing method based on a Generalized Gaussian Distribution model expressed in the spatial and temporal band-pass domains, which measures the difference in quality between reference and distorted videos. The proposed design is highly generalizable and can be employed when the reference and distorted sequences have different frame rates. Our proposed model correlates very well with subjective scores in the recently proposed LIVE-YT-HFR database and achieves state of the art performance when compared with existing methodologies.



### BEV-Seg: Bird's Eye View Semantic Segmentation Using Geometry and Semantic Point Cloud
- **Arxiv ID**: http://arxiv.org/abs/2006.11436v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2006.11436v2)
- **Published**: 2020-06-19 23:30:11+00:00
- **Updated**: 2020-06-23 16:45:07+00:00
- **Authors**: Mong H. Ng, Kaahan Radia, Jianfei Chen, Dequan Wang, Ionel Gog, Joseph E. Gonzalez
- **Comment**: Accepted into CVPR 2020 Workshop Scalability in Autonomous Driving by
  Waymo
- **Journal**: None
- **Summary**: Bird's-eye-view (BEV) is a powerful and widely adopted representation for road scenes that captures surrounding objects and their spatial locations, along with overall context in the scene. In this work, we focus on bird's eye semantic segmentation, a task that predicts pixel-wise semantic segmentation in BEV from side RGB images. This task is made possible by simulators such as Carla, which allow for cheap data collection, arbitrary camera placements, and supervision in ways otherwise not possible in the real world. There are two main challenges to this task: the view transformation from side view to bird's eye view, as well as transfer learning to unseen domains. Existing work transforms between views through fully connected layers and transfer learns via GANs. This suffers from a lack of depth reasoning and performance degradation across domains. Our novel 2-staged perception pipeline explicitly predicts pixel depths and combines them with pixel semantics in an efficient manner, allowing the model to leverage depth information to infer objects' spatial locations in the BEV. In addition, we transfer learning by abstracting high-level geometric features and predicting an intermediate representation that is common across different domains. We publish a new dataset called BEVSEG-Carla and show that our approach improves state-of-the-art by 24% mIoU and performs well when transferred to a new domain.



