# Arxiv Papers in cs.CV on 2018-08-15
### Holographic Visualisation of Radiology Data and Automated Machine Learning-based Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1808.04929v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1808.04929v1)
- **Published**: 2018-08-15 00:20:35+00:00
- **Updated**: 2018-08-15 00:20:35+00:00
- **Authors**: Lucian Trestioreanu
- **Comment**: None
- **Journal**: None
- **Summary**: Within this thesis we propose a platform for combining Augmented Reality (AR) hardware with machine learning in a user-oriented pipeline, offering to the medical staff an intuitive 3D visualization of volumetric Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) medical image segmentations inside the AR headset, that does not need human intervention for loading, processing and segmentation of medical images. The AR visualization, based on Microsoft HoloLens, employs a modular and thus scalable frontend-backend architecture for real-time visualizations on multiple AR headsets. As Convolutional Neural Networks (CNNs) have lastly demonstrated superior performance for the machine learning task of image semantic segmentation, the pipeline also includes a fully automated CNN algorithm for the segmentation of the liver from CT scans. The model is based on the Deep Retinal Image Understanding (DRIU) model which is a Fully Convolutional Network with side outputs from feature maps with different resolution, extracted at different stages of the network. The algorithm is 2.5D which means that the input is a set of consecutive scan slices. The experiments have been performed on the Liver Tumor Segmentation Challenge (LiTS) dataset for liver segmentation and demonstrated good results and flexibility. While multiple approaches exist in the domain, only few of them have focused on overcoming the practical aspects which still largely hold this technology away from the operating rooms. In line with this, we also are next planning an evaluation from medical doctors and radiologists in a real-world environment.



### PFCNN: Convolutional Neural Networks on 3D Surfaces Using Parallel Frames
- **Arxiv ID**: http://arxiv.org/abs/1808.04952v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1808.04952v2)
- **Published**: 2018-08-15 02:39:35+00:00
- **Updated**: 2020-06-12 05:58:56+00:00
- **Authors**: Yuqi Yang, Shilin Liu, Hao Pan, Yang Liu, Xin Tong
- **Comment**: 15 pages, 18 figures. CVPR 2020. Project page:
  https://haopan.github.io/surfacecnn.html
- **Journal**: The IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR), 2020, pp. 13578-13587
- **Summary**: Surface meshes are widely used shape representations and capture finer geometry data than point clouds or volumetric grids, but are challenging to apply CNNs directly due to their non-Euclidean structure. We use parallel frames on surface to define PFCNNs that enable effective feature learning on surface meshes by mimicking standard convolutions faithfully. In particular, the convolution of PFCNN not only maps local surface patches onto flat tangent planes, but also aligns the tangent planes such that they locally form a flat Euclidean structure, thus enabling recovery of standard convolutions. The alignment is achieved by the tool of locally flat connections borrowed from discrete differential geometry, which can be efficiently encoded and computed by parallel frame fields. In addition, the lack of canonical axis on surface is handled by sampling with the frame directions. Experiments show that for tasks including classification, segmentation and registration on deformable geometric domains, as well as semantic scene segmentation on rigid domains, PFCNNs achieve robust and superior performances without using sophisticated input features than state-of-the-art surface based CNNs.



### SAN: Learning Relationship between Convolutional Features for Multi-Scale Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1808.04974v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.04974v1)
- **Published**: 2018-08-15 05:35:44+00:00
- **Updated**: 2018-08-15 05:35:44+00:00
- **Authors**: Yonghyun Kim, Bong-Nam Kang, Daijin Kim
- **Comment**: None
- **Journal**: None
- **Summary**: Most of the recent successful methods in accurate object detection build on the convolutional neural networks (CNN). However, due to the lack of scale normalization in CNN-based detection methods, the activated channels in the feature space can be completely different according to a scale and this difference makes it hard for the classifier to learn samples. We propose a Scale Aware Network (SAN) that maps the convolutional features from the different scales onto a scale-invariant subspace to make CNN-based detection methods more robust to the scale variation, and also construct a unique learning method which considers purely the relationship between channels without the spatial information for the efficient learning of SAN. To show the validity of our method, we visualize how convolutional features change according to the scale through a channel activation matrix and experimentally show that SAN reduces the feature differences in the scale space. We evaluate our method on VOC PASCAL and MS COCO dataset. We demonstrate SAN by conducting several experiments on structures and parameters. The proposed SAN can be generally applied to many CNN-based detection methods to enhance the detection accuracy with a slight increase in the computing time.



### Pairwise Relational Networks for Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1808.04976v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.04976v1)
- **Published**: 2018-08-15 05:52:31+00:00
- **Updated**: 2018-08-15 05:52:31+00:00
- **Authors**: Bong-Nam Kang, Yonghyun Kim, Daijin Kim
- **Comment**: to appear in ECCV 2018
- **Journal**: None
- **Summary**: Existing face recognition using deep neural networks is difficult to know what kind of features are used to discriminate the identities of face images clearly. To investigate the effective features for face recognition, we propose a novel face recognition method, called a pairwise relational network (PRN), that obtains local appearance patches around landmark points on the feature map, and captures the pairwise relation between a pair of local appearance patches. The PRN is trained to capture unique and discriminative pairwise relations among different identities. Because the existence and meaning of pairwise relations should be identity dependent, we add a face identity state feature, which obtains from the long short-term memory (LSTM) units network with the sequential local appearance patches on the feature maps, to the PRN. To further improve accuracy of face recognition, we combined the global appearance representation with the pairwise relational feature. Experimental results on the LFW show that the PRN using only pairwise relations achieved 99.65% accuracy and the PRN using both pairwise relations and face identity state feature achieved 99.76% accuracy. On the YTF, both the PRN using only pairwise relations and the PRN using pairwise relations and the face identity state feature achieved the state-of-the-art (95.7% and 96.3%). The PRN also achieved comparable results to the state-of-the-art for both face verification and face identification tasks on the IJB-A, and the state-of-the-art on the IJB-B.



### Scene Coordinate Regression with Angle-Based Reprojection Loss for Camera Relocalization
- **Arxiv ID**: http://arxiv.org/abs/1808.04999v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.04999v2)
- **Published**: 2018-08-15 08:25:15+00:00
- **Updated**: 2018-09-30 22:34:22+00:00
- **Authors**: Xiaotian Li, Juha Ylioinas, Jakob Verbeek, Juho Kannala
- **Comment**: ECCV 2018 Workshop (Geometry Meets Deep Learning)
- **Journal**: None
- **Summary**: Image-based camera relocalization is an important problem in computer vision and robotics. Recent works utilize convolutional neural networks (CNNs) to regress for pixels in a query image their corresponding 3D world coordinates in the scene. The final pose is then solved via a RANSAC-based optimization scheme using the predicted coordinates. Usually, the CNN is trained with ground truth scene coordinates, but it has also been shown that the network can discover 3D scene geometry automatically by minimizing single-view reprojection loss. However, due to the deficiencies of the reprojection loss, the network needs to be carefully initialized. In this paper, we present a new angle-based reprojection loss, which resolves the issues of the original reprojection loss. With this new loss function, the network can be trained without careful initialization, and the system achieves more accurate results. The new loss also enables us to utilize available multi-view constraints, which further improve performance.



### A Dense-Depth Representation for VLAD descriptors in Content-Based Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1808.05022v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05022v1)
- **Published**: 2018-08-15 10:01:33+00:00
- **Updated**: 2018-08-15 10:01:33+00:00
- **Authors**: Federico Magliani, Tomaso Fontanini, Andrea Prati
- **Comment**: None
- **Journal**: None
- **Summary**: The recent advances brought by deep learning allowed to improve the performance in image retrieval tasks. Through the many convolutional layers, available in a Convolutional Neural Network (CNN), it is possible to obtain a hierarchy of features from the evaluated image. At every step, the patches extracted are smaller than the previous levels and more representative. Following this idea, this paper introduces a new detector applied on the feature maps extracted from pre-trained CNN. Specifically, this approach lets to increase the number of features in order to increase the performance of the aggregation algorithms like the most famous and used VLAD embedding. The proposed approach is tested on different public datasets: Holidays, Oxford5k, Paris6k and UKB.



### Ensemble of Convolutional Neural Networks for Dermoscopic Images Classification
- **Arxiv ID**: http://arxiv.org/abs/1808.05071v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05071v1)
- **Published**: 2018-08-15 13:36:41+00:00
- **Updated**: 2018-08-15 13:36:41+00:00
- **Authors**: Tomáš Majtner, Buda Bajić, Sule Yildirim, Jon Yngve Hardeberg, Joakim Lindblad, Nataša Sladoje
- **Comment**: 5 pages, 2 figures
- **Journal**: None
- **Summary**: In this report, we are presenting our automated prediction system for disease classification within dermoscopic images. The proposed solution is based on deep learning, where we employed transfer learning strategy on VGG16 and GoogLeNet architectures. The key feature of our solution is preprocessing based primarily on image augmentation and colour normalization. The solution was evaluated on Task 3: Lesion Diagnosis of the ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection.



### Multi-feature Fusion for Image Retrieval Using Constrained Dominant Sets
- **Arxiv ID**: http://arxiv.org/abs/1808.05075v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05075v1)
- **Published**: 2018-08-15 13:41:22+00:00
- **Updated**: 2018-08-15 13:41:22+00:00
- **Authors**: Leulseged Tesfaye Alemu, Marcello Pelillo
- **Comment**: None
- **Journal**: None
- **Summary**: Aggregating different image features for image retrieval has recently shown its effectiveness. While highly effective, though, the question of how to uplift the impact of the best features for a specific query image persists as an open computer vision problem. In this paper, we propose a computationally efficient approach to fuse several hand-crafted and deep features, based on the probabilistic distribution of a given membership score of a constrained cluster in an unsupervised manner. First, we introduce an incremental nearest neighbor (NN) selection method, whereby we dynamically select k-NN to the query. We then build several graphs from the obtained NN sets and employ constrained dominant sets (CDS) on each graph G to assign edge weights which consider the intrinsic manifold structure of the graph, and detect false matches to the query. Finally, we elaborate the computation of feature positive-impact weight (PIW) based on the dispersive degree of the characteristics vector. To this end, we exploit the entropy of a cluster membership-score distribution. In addition, the final NN set bypasses a heuristic voting scheme. Experiments on several retrieval benchmark datasets show that our method can improve the state-of-the-art result.



### Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos
- **Arxiv ID**: http://arxiv.org/abs/1808.05085v1
- **DOI**: 10.1145/3240508.3240534
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05085v1)
- **Published**: 2018-08-15 13:59:00+00:00
- **Updated**: 2018-08-15 13:59:00+00:00
- **Authors**: Zhaoyang Zhang, Zhanghui Kuang, Ping Luo, Litong Feng, Wei Zhang
- **Comment**: Accepted by ACM Multimedia
- **Journal**: None
- **Summary**: Video Analytics Software as a Service (VA SaaS) has been rapidly growing in recent years. VA SaaS is typically accessed by users using a lightweight client. Because the transmission bandwidth between the client and cloud is usually limited and expensive, it brings great benefits to design cloud video analysis algorithms with a limited data transmission requirement. Although considerable research has been devoted to video analysis, to our best knowledge, little of them has paid attention to the transmission bandwidth limitation in SaaS. As the first attempt in this direction, this work introduces a problem of few-frame action recognition, which aims at maintaining high recognition accuracy, when accessing only a few frames during both training and test. Unlike previous work that processed dense frames, we present Temporal Sequence Distillation (TSD), which distills a long video sequence into a very short one for transmission. By end-to-end training with 3D CNNs for video action recognition, TSD learns a compact and discriminative temporal and spatial representation of video frames. On Kinetics dataset, TSD+I3D typically requires only 50\% of the number of frames compared to I3D, a state-of-the-art video action recognition algorithm, to achieve almost the same accuracies. The proposed TSD has three appealing advantages. Firstly, TSD has a lightweight architecture and can be deployed in the client, eg. mobile devices, to produce compressed representative frames to save transmission bandwidth. Secondly, TSD significantly reduces the computations to run video action recognition with compressed frames on the cloud, while maintaining high recognition accuracies. Thirdly, TSD can be plugged in as a preprocessing module of any existing 3D CNNs. Extensive experiments show the effectiveness and characteristics of TSD.



### Dual approach for object tracking based on optical flow and swarm intelligence
- **Arxiv ID**: http://arxiv.org/abs/1808.08186v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1808.08186v2)
- **Published**: 2018-08-15 14:17:45+00:00
- **Updated**: 2021-08-01 06:52:15+00:00
- **Authors**: Rajesh Misra, Kumar S. Ray
- **Comment**: None
- **Journal**: None
- **Summary**: In Computer Vision,object tracking is a very old and complex problem.Though there are several existing algorithms for object tracking, still there are several challenges remain to be solved. For instance, variation of illumination of light, noise, occlusion, sudden start and stop of moving object, shading etc,make the object tracking a complex problem not only for dynamic background but also for static background. In this paper we propose a dual approach for object tracking based on optical flow and swarm Intelligence.The optical flow based KLT(Kanade-Lucas-Tomasi) tracker, tracks the dominant points of the target object from first frame to last frame of a video sequence;whereas swarm Intelligence based PSO (Particle Swarm Optimization) tracker simultaneously tracks the boundary information of the target object from second frame to last frame of the same video sequence.This dual function of tracking makes the trackers very much robust with respect to the above stated problems. The flexibility of our approach is that it can be successfully applicable in variable background as well as static background.We compare the performance of the proposed dual tracking algorithm with several benchmark datasets and obtain very competitive results in general and in most of the cases we obtained superior results using dual tracking algorithm. We also compare the performance of the proposed dual tracker with some existing PSO based algorithms for tracking and achieved better results.



### Deep Learning using K-space Based Data Augmentation for Automated Cardiac MR Motion Artefact Detection
- **Arxiv ID**: http://arxiv.org/abs/1808.05130v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05130v2)
- **Published**: 2018-08-15 15:22:21+00:00
- **Updated**: 2018-08-31 09:14:46+00:00
- **Authors**: Ilkay Oksuz, Bram Ruijsink, Esther Puyol-Anton, Aurelien Bustin, Gastao Cruz, Claudia Prieto, Daniel Rueckert, Julia A. Schnabel, Andrew P. King
- **Comment**: Accepted for MICCAI2018 Conference
- **Journal**: None
- **Summary**: Quality assessment of medical images is essential for complete automation of image processing pipelines. For large population studies such as the UK Biobank, artefacts such as those caused by heart motion are problematic and manual identification is tedious and time-consuming. Therefore, there is an urgent need for automatic image quality assessment techniques. In this paper, we propose a method to automatically detect the presence of motion-related artefacts in cardiac magnetic resonance (CMR) images. As this is a highly imbalanced classification problem (due to the high number of good quality images compared to the low number of images with motion artefacts), we propose a novel k-space based training data augmentation approach in order to address this problem. Our method is based on 3D spatio-temporal Convolutional Neural Networks, and is able to detect 2D+time short axis images with motion artefacts in less than 1ms. We test our algorithm on a subset of the UK Biobank dataset consisting of 3465 CMR images and achieve not only high accuracy in detection of motion artefacts, but also high precision and recall. We compare our approach to a range of state-of-the-art quality assessment methods.



### CBinfer: Exploiting Frame-to-Frame Locality for Faster Convolutional Network Inference on Video Streams
- **Arxiv ID**: http://arxiv.org/abs/1808.05488v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1808.05488v2)
- **Published**: 2018-08-15 15:27:29+00:00
- **Updated**: 2019-03-04 17:07:31+00:00
- **Authors**: Lukas Cavigelli, Luca Benini
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1704.04313
- **Journal**: None
- **Summary**: The last few years have brought advances in computer vision at an amazing pace, grounded on new findings in deep neural network construction and training as well as the availability of large labeled datasets. Applying these networks to images demands a high computational effort and pushes the use of state-of-the-art networks on real-time video data out of reach of embedded platforms. Many recent works focus on reducing network complexity for real-time inference on embedded computing platforms. We adopt an orthogonal viewpoint and propose a novel algorithm exploiting the spatio-temporal sparsity of pixel changes. This optimized inference procedure resulted in an average speed-up of 9.1x over cuDNN on the Tegra X2 platform at a negligible accuracy loss of <0.1% and no retraining of the network for a semantic segmentation application. Similarly, an average speed-up of 7.0x has been achieved for a pose detection DNN and a reduction of 5x of the number of arithmetic operations to be performed for object detection on static camera video surveillance data. These throughput gains combined with a lower power consumption result in an energy efficiency of 511 GOp/s/W compared to 70 GOp/s/W for the baseline.



### Recycle-GAN: Unsupervised Video Retargeting
- **Arxiv ID**: http://arxiv.org/abs/1808.05174v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1808.05174v1)
- **Published**: 2018-08-15 16:34:08+00:00
- **Updated**: 2018-08-15 16:34:08+00:00
- **Authors**: Aayush Bansal, Shugao Ma, Deva Ramanan, Yaser Sheikh
- **Comment**: ECCV 2018; Please refer to project webpage for videos -
  http://www.cs.cmu.edu/~aayushb/Recycle-GAN
- **Journal**: None
- **Summary**: We introduce a data-driven approach for unsupervised video retargeting that translates content from one domain to another while preserving the style native to a domain, i.e., if contents of John Oliver's speech were to be transferred to Stephen Colbert, then the generated content/speech should be in Stephen Colbert's style. Our approach combines both spatial and temporal information along with adversarial losses for content translation and style preservation. In this work, we first study the advantages of using spatiotemporal constraints over spatial constraints for effective retargeting. We then demonstrate the proposed approach for the problems where information in both space and time matters such as face-to-face translation, flower-to-flower, wind and cloud synthesis, sunrise and sunset.



### Building medical image classifiers with very limited data using segmentation networks
- **Arxiv ID**: http://arxiv.org/abs/1808.05205v1
- **DOI**: 10.1016/j.media.2018.07.010
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05205v1)
- **Published**: 2018-08-15 17:52:09+00:00
- **Updated**: 2018-08-15 17:52:09+00:00
- **Authors**: Ken C. L. Wong, Tanveer Syeda-Mahmood, Mehdi Moradi
- **Comment**: This paper was accepted by Medical Image Analysis
- **Journal**: Medical Image Analysis 49 (2018) 105-116
- **Summary**: Deep learning has shown promising results in medical image analysis, however, the lack of very large annotated datasets confines its full potential. Although transfer learning with ImageNet pre-trained classification models can alleviate the problem, constrained image sizes and model complexities can lead to unnecessary increase in computational cost and decrease in performance. As many common morphological features are usually shared by different classification tasks of an organ, it is greatly beneficial if we can extract such features to improve classification with limited samples. Therefore, inspired by the idea of curriculum learning, we propose a strategy for building medical image classifiers using features from segmentation networks. By using a segmentation network pre-trained on similar data as the classification task, the machine can first learn the simpler shape and structural concepts before tackling the actual classification problem which usually involves more complicated concepts. Using our proposed framework on a 3D three-class brain tumor type classification problem, we achieved 82% accuracy on 191 testing samples with 91 training samples. When applying to a 2D nine-class cardiac semantic level classification problem, we achieved 86% accuracy on 263 testing samples with 108 training samples. Comparisons with ImageNet pre-trained classifiers and classifiers trained from scratch are presented.



### AnatomyNet: Deep Learning for Fast and Fully Automated Whole-volume Segmentation of Head and Neck Anatomy
- **Arxiv ID**: http://arxiv.org/abs/1808.05238v2
- **DOI**: 10.1002/mp.13300
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1808.05238v2)
- **Published**: 2018-08-15 18:03:12+00:00
- **Updated**: 2018-11-09 00:23:48+00:00
- **Authors**: Wentao Zhu, Yufang Huang, Liang Zeng, Xuming Chen, Yong Liu, Zhen Qian, Nan Du, Wei Fan, Xiaohui Xie
- **Comment**: 6 figures, 4 videos in GitHub and YouTube. Accepted by Medical
  Physics. Code and videos are available on GitHub. Video:
  https://www.youtube.com/watch?v=_PpIUIm4XLU
- **Journal**: None
- **Summary**: Methods: Our deep learning model, called AnatomyNet, segments OARs from head and neck CT images in an end-to-end fashion, receiving whole-volume HaN CT images as input and generating masks of all OARs of interest in one shot. AnatomyNet is built upon the popular 3D U-net architecture, but extends it in three important ways: 1) a new encoding scheme to allow auto-segmentation on whole-volume CT images instead of local patches or subsets of slices, 2) incorporating 3D squeeze-and-excitation residual blocks in encoding layers for better feature representation, and 3) a new loss function combining Dice scores and focal loss to facilitate the training of the neural model. These features are designed to address two main challenges in deep-learning-based HaN segmentation: a) segmenting small anatomies (i.e., optic chiasm and optic nerves) occupying only a few slices, and b) training with inconsistent data annotations with missing ground truth for some anatomical structures.   Results: We collected 261 HaN CT images to train AnatomyNet, and used MICCAI Head and Neck Auto Segmentation Challenge 2015 as a benchmark dataset to evaluate the performance of AnatomyNet. The objective is to segment nine anatomies: brain stem, chiasm, mandible, optic nerve left, optic nerve right, parotid gland left, parotid gland right, submandibular gland left, and submandibular gland right. Compared to previous state-of-the-art results from the MICCAI 2015 competition, AnatomyNet increases Dice similarity coefficient by 3.3% on average. AnatomyNet takes about 0.12 seconds to fully segment a head and neck CT image of dimension 178 x 302 x 225, significantly faster than previous methods. In addition, the model is able to process whole-volume CT images and delineate all OARs in one pass, requiring little pre- or post-processing. https://github.com/wentaozhu/AnatomyNet-for-anatomical-segmentation.git.



### Blended Coarse Gradient Descent for Full Quantization of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1808.05240v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1808.05240v4)
- **Published**: 2018-08-15 18:13:12+00:00
- **Updated**: 2019-01-06 06:00:43+00:00
- **Authors**: Penghang Yin, Shuai Zhang, Jiancheng Lyu, Stanley Osher, Yingyong Qi, Jack Xin
- **Comment**: None
- **Journal**: None
- **Summary**: Quantized deep neural networks (QDNNs) are attractive due to their much lower memory storage and faster inference speed than their regular full precision counterparts. To maintain the same performance level especially at low bit-widths, QDNNs must be retrained. Their training involves piecewise constant activation functions and discrete weights, hence mathematical challenges arise. We introduce the notion of coarse gradient and propose the blended coarse gradient descent (BCGD) algorithm, for training fully quantized neural networks. Coarse gradient is generally not a gradient of any function but an artificial ascent direction. The weight update of BCGD goes by coarse gradient correction of a weighted average of the full precision weights and their quantization (the so-called blending), which yields sufficient descent in the objective value and thus accelerates the training. Our experiments demonstrate that this simple blending technique is very effective for quantization at extremely low bit-width such as binarization. In full quantization of ResNet-18 for ImageNet classification task, BCGD gives 64.36\% top-1 accuracy with binary weights across all layers and 4-bit adaptive activation. If the weights in the first and last layers are kept in full precision, this number increases to 65.46\%. As theoretical justification, we show convergence analysis of coarse gradient descent for a two-linear-layer neural network model with Gaussian input data, and prove that the expected coarse gradient correlates positively with the underlying true gradient.



### Measuring Human Assessed Complexity in Synthetic Aperture Sonar Imagery Using the Elo Rating System
- **Arxiv ID**: http://arxiv.org/abs/1808.05279v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05279v1)
- **Published**: 2018-08-15 20:06:38+00:00
- **Updated**: 2018-08-15 20:06:38+00:00
- **Authors**: Brian Reinhardt, Isaac Gerg, Daniel Brown, Joonho Park
- **Comment**: Accepted for the Institute of Acoustics 4th International Conference
  on Synthetic Apertures Sonar and Radar Sept 2018
- **Journal**: None
- **Summary**: Performance of automatic target recognition from synthetic aperture sonar data is heavily dependent on the complexity of the beamformed imagery. Several mechanisms can contribute to this, including unwanted vehicle dynamics, the bathymetry of the scene, and the presence of natural and manmade clutter. To understand the impact of the environmental complexity on image perception, researchers have taken approaches rooted in information theory, or heuristics. Despite these efforts, a quantitative measure for complexity has not been related to the phenomenology from which it is derived.   By using subject matter experts (SMEs) we derive a complexity metric for a set of imagery which accounts for the underlying phenomenology. The goal of this work is to develop an understanding of how several common information theoretic and heuristic measures are related to the SME perceived complexity in synthetic aperture sonar imagery. To achieve this, an ensemble of 10-meter x 10-meter images were cropped from a high-frequency SAS data set that spans multiple environments. The SME's were presented pairs of images from which they could rate the relative image complexity. These comparisons were then converted into the desired sequential ranking using a method first developed by A. Elo for establishing rankings of chess players.   The Elo method produced a plausible rank ordering across the broad dataset. The heuristic and information theoretical metrics were then compared to the image rank from which they were derived. The metrics with the highest degree of correlation were those relating to spatial information, e.g. variations in pixel intensity, with an R-squared value of approximately 0.9. However, this agreement was dependent on the scale from which the spatial variation was measured. Results will also be presented for many other measures including lacunarity, image compression, and entropy.



### DNN Feature Map Compression using Learned Representation over GF(2)
- **Arxiv ID**: http://arxiv.org/abs/1808.05285v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1808.05285v1)
- **Published**: 2018-08-15 21:13:06+00:00
- **Updated**: 2018-08-15 21:13:06+00:00
- **Authors**: Denis A. Gudovskiy, Alec Hodgkinson, Luca Rigazio
- **Comment**: CEFRL2018
- **Journal**: None
- **Summary**: In this paper, we introduce a method to compress intermediate feature maps of deep neural networks (DNNs) to decrease memory storage and bandwidth requirements during inference. Unlike previous works, the proposed method is based on converting fixed-point activations into vectors over the smallest GF(2) finite field followed by nonlinear dimensionality reduction (NDR) layers embedded into a DNN. Such an end-to-end learned representation finds more compact feature maps by exploiting quantization redundancies within the fixed-point activations along the channel or spatial dimensions. We apply the proposed network architectures derived from modified SqueezeNet and MobileNetV2 to the tasks of ImageNet classification and PASCAL VOC object detection. Compared to prior approaches, the conducted experiments show a factor of 2 decrease in memory requirements with minor degradation in accuracy while adding only bitwise computations.



