# Arxiv Papers in cs.CV on 2018-07-01
### Fast Fourier-Based Generation of the Compression Matrix for Deterministic Compressed Sensing
- **Arxiv ID**: http://arxiv.org/abs/1807.01238v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1807.01238v1)
- **Published**: 2018-07-01 04:51:35+00:00
- **Updated**: 2018-07-01 04:51:35+00:00
- **Authors**: Sai Charan Jajimi
- **Comment**: None
- **Journal**: None
- **Summary**: The primary goal of this work is to review the importance of data compression and present a fast Fourier-based method for generating the deterministic compression matrix in the area of deterministic compressed sensing. The principle concepts of data compression such as general process of data compression, sparse signals, coherence matrix and Restricted Isometry Property (RIP) have been defined. We have introduced two methods of sparse data compression. The first method is formed by utilizing a stochastic matrix which is a common approach, and the second method is created by utilizing a deterministic matrix which is proposed more recently. The main goal of this work is to improve the execution time of the deterministic matrix generation. The execution time is related to the generation method of the deterministic matrix. Furthermore, we have implemented a software which makes it possible to compare different methods of reconstructing data compression. To make this comparison, it is necessary to draw and compare certain graphs, e.g. phase transition, the ratio of output signal to noise and input signal to noise, signal to noise output and also the ratio of percentage of accurate reconstructing and order of sparse signals for various reconstructing methods. To facilitate this process, the user would be able to draw his/her favorite graphs in GUI environment.



### Photorealistic Style Transfer for Videos
- **Arxiv ID**: http://arxiv.org/abs/1807.00273v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1807.00273v1)
- **Published**: 2018-07-01 05:28:27+00:00
- **Updated**: 2018-07-01 05:28:27+00:00
- **Authors**: Michael Honke, Rahul Iyer, Dishant Mittal
- **Comment**: None
- **Journal**: None
- **Summary**: Photorealistic style transfer is a technique which transfers colour from one reference domain to another domain by using deep learning and optimization techniques. Here, we present a technique which we use to transfer style and colour from a reference image to a video.



### Self-supervised Sparse-to-Dense: Self-supervised Depth Completion from LiDAR and Monocular Camera
- **Arxiv ID**: http://arxiv.org/abs/1807.00275v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1807.00275v2)
- **Published**: 2018-07-01 06:02:48+00:00
- **Updated**: 2018-07-03 00:47:09+00:00
- **Authors**: Fangchang Ma, Guilherme Venturelli Cavalheiro, Sertac Karaman
- **Comment**: Software:
  https://github.com/fangchangma/self-supervised-depth-completion . Video:
  https://youtu.be/bGXfvF261pc . 12 pages, 6 figures, 3 tables
- **Journal**: None
- **Summary**: Depth completion, the technique of estimating a dense depth image from sparse depth measurements, has a variety of applications in robotics and autonomous driving. However, depth completion faces 3 main challenges: the irregularly spaced pattern in the sparse depth input, the difficulty in handling multiple sensor modalities (when color images are available), as well as the lack of dense, pixel-level ground truth depth labels. In this work, we address all these challenges. Specifically, we develop a deep regression model to learn a direct mapping from sparse depth (and color images) to dense depth. We also propose a self-supervised training framework that requires only sequences of color and sparse depth images, without the need for dense depth labels. Our experiments demonstrate that our network, when trained with semi-dense annotations, attains state-of-the- art accuracy and is the winning approach on the KITTI depth completion benchmark at the time of submission. Furthermore, the self-supervised framework outperforms a number of existing solutions trained with semi- dense annotations.



### Autonomous Deep Learning: A Genetic DCNN Designer for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1807.00284v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1807.00284v1)
- **Published**: 2018-07-01 07:11:54+00:00
- **Updated**: 2018-07-01 07:11:54+00:00
- **Authors**: Benteng Ma, Yong Xia
- **Comment**: None
- **Journal**: None
- **Summary**: Recent years have witnessed the breakthrough success of deep convolutional neural networks (DCNNs) in image classification and other vision applications. Although freeing users from the troublesome handcrafted feature extraction by providing a uniform feature extraction-classification framework, DCNNs still require a handcrafted design of their architectures. In this paper, we propose the genetic DCNN designer, an autonomous learning algorithm can generate a DCNN architecture automatically based on the data available for a specific image classification problem. We first partition a DCNN into multiple stacked meta convolutional blocks and fully connected blocks, each containing the operations of convolution, pooling, fully connection, batch normalization, activation and drop out, and thus convert the architecture into an integer vector. Then, we use refined evolutionary operations, including selection, mutation and crossover to evolve a population of DCNN architectures. Our results on the MNIST, Fashion-MNIST, EMNISTDigit, EMNIST-Letter, CIFAR10 and CIFAR100 datasets suggest that the proposed genetic DCNN designer is able to produce automatically DCNN architectures, whose performance is comparable to, if not better than, that of stateof- the-art DCNN models



### SYQ: Learning Symmetric Quantization For Efficient Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1807.00301v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1807.00301v1)
- **Published**: 2018-07-01 09:29:19+00:00
- **Updated**: 2018-07-01 09:29:19+00:00
- **Authors**: Julian Faraone, Nicholas Fraser, Michaela Blott, Philip H. W. Leong
- **Comment**: Published as a conference paper at the 2018 IEEE Conference on
  Computer Vision and Pattern Recognition (CVPR)
- **Journal**: None
- **Summary**: Inference for state-of-the-art deep neural networks is computationally expensive, making them difficult to deploy on constrained hardware environments. An efficient way to reduce this complexity is to quantize the weight parameters and/or activations during training by approximating their distributions with a limited entry codebook. For very low-precisions, such as binary or ternary networks with 1-8-bit activations, the information loss from quantization leads to significant accuracy degradation due to large gradient mismatches between the forward and backward functions. In this paper, we introduce a quantization method to reduce this loss by learning a symmetric codebook for particular weight subgroups. These subgroups are determined based on their locality in the weight matrix, such that the hardware simplicity of the low-precision representations is preserved. Empirically, we show that symmetric quantization can substantially improve accuracy for networks with extremely low-precision weights and activations. We also demonstrate that this representation imposes minimal or no hardware implications to more coarse-grained approaches. Source code is available at https://www.github.com/julianfaraone/SYQ.



### Towards Adversarial Training with Moderate Performance Improvement for Neural Network Classification
- **Arxiv ID**: http://arxiv.org/abs/1807.00340v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1807.00340v1)
- **Published**: 2018-07-01 15:08:52+00:00
- **Updated**: 2018-07-01 15:08:52+00:00
- **Authors**: Xinhan Di, Pengqian Yu, Meng Tian
- **Comment**: Accepted for publication in Uncertainty in Deep Learning Workshop at
  Uncertainty in Artificial Intelligence (UAI) 2018
- **Journal**: None
- **Summary**: It has been demonstrated that deep neural networks are prone to noisy examples particular adversarial samples during inference process. The gap between robust deep learning systems in real world applications and vulnerable neural networks is still large. Current adversarial training strategies improve the robustness against adversarial samples. However, these methods lead to accuracy reduction when the input examples are clean thus hinders the practicability. In this paper, we investigate an approach that protects the neural network classification from the adversarial samples and improves its accuracy when the input examples are clean. We demonstrate the versatility and effectiveness of our proposed approach on a variety of different networks and datasets.



### cilantro: A Lean, Versatile, and Efficient Library for Point Cloud Data Processing
- **Arxiv ID**: http://arxiv.org/abs/1807.00399v3
- **DOI**: 10.1145/3240508.3243655
- **Categories**: **cs.CV**, cs.CG, cs.GR, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1807.00399v3)
- **Published**: 2018-07-01 21:47:51+00:00
- **Updated**: 2018-11-16 17:30:17+00:00
- **Authors**: Konstantinos Zampogiannis, Cornelia Fermuller, Yiannis Aloimonos
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce cilantro, an open-source C++ library for geometric and general-purpose point cloud data processing. The library provides functionality that covers low-level point cloud operations, spatial reasoning, various methods for point cloud segmentation and generic data clustering, flexible algorithms for robust or local geometric alignment, model fitting, as well as powerful visualization tools. To accommodate all kinds of workflows, cilantro is almost fully templated, and most of its generic algorithms operate in arbitrary data dimension. At the same time, the library is easy to use and highly expressive, promoting a clean and concise coding style. cilantro is highly optimized, has a minimal set of external dependencies, and supports rapid development of performant point cloud processing software in a wide variety of contexts.



