# Arxiv Papers in cs.CV on 2018-10-31
### Scalable Laplacian K-modes
- **Arxiv ID**: http://arxiv.org/abs/1810.13044v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.13044v2)
- **Published**: 2018-10-31 00:01:31+00:00
- **Updated**: 2018-11-20 19:30:18+00:00
- **Authors**: Imtiaz Masud Ziko, Eric Granger, Ismail Ben Ayed
- **Comment**: 13 pages, 11 figures. Accepted in NIPS 2018
- **Journal**: None
- **Summary**: We advocate Laplacian K-modes for joint clustering and density mode finding, and propose a concave-convex relaxation of the problem, which yields a parallel algorithm that scales up to large datasets and high dimensions. We optimize a tight bound (auxiliary function) of our relaxation, which, at each iteration, amounts to computing an independent update for each cluster-assignment variable, with guaranteed convergence. Therefore, our bound optimizer can be trivially distributed for large-scale data sets. Furthermore, we show that the density modes can be obtained as byproducts of the assignment variables via simple maximum-value operations whose additional computational cost is linear in the number of data points. Our formulation does not need storing a full affinity matrix and computing its eigenvalue decomposition, neither does it perform expensive projection steps and Lagrangian-dual inner iterates for the simplex constraints of each point. Furthermore, unlike mean-shift, our density-mode estimation does not require inner-loop gradient-ascent iterates. It has a complexity independent of feature-space dimension, yields modes that are valid data points in the input set and is applicable to discrete domains as well as arbitrary kernels. We report comprehensive experiments over various data sets, which show that our algorithm yields very competitive performances in term of optimization quality (i.e., the value of the discrete-variable objective at convergence) and clustering accuracy.



### Cooperative Holistic Scene Understanding: Unifying 3D Object, Layout, and Camera Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1810.13049v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13049v2)
- **Published**: 2018-10-31 00:30:08+00:00
- **Updated**: 2019-02-21 02:17:57+00:00
- **Authors**: Siyuan Huang, Siyuan Qi, Yinxue Xiao, Yixin Zhu, Ying Nian Wu, Song-Chun Zhu
- **Comment**: Accepted by NeurIPS 2018
- **Journal**: None
- **Summary**: Holistic 3D indoor scene understanding refers to jointly recovering the i) object bounding boxes, ii) room layout, and iii) camera pose, all in 3D. The existing methods either are ineffective or only tackle the problem partially. In this paper, we propose an end-to-end model that simultaneously solves all three tasks in real-time given only a single RGB image. The essence of the proposed method is to improve the prediction by i) parametrizing the targets (e.g., 3D boxes) instead of directly estimating the targets, and ii) cooperative training across different modules in contrast to training these modules individually. Specifically, we parametrize the 3D object bounding boxes by the predictions from several modules, i.e., 3D camera pose and object attributes. The proposed method provides two major advantages: i) The parametrization helps maintain the consistency between the 2D image and the 3D world, thus largely reducing the prediction variances in 3D coordinates. ii) Constraints can be imposed on the parametrization to train different modules simultaneously. We call these constraints "cooperative losses" as they enable the joint training and inference. We employ three cooperative losses for 3D bounding boxes, 2D projections, and physical constraints to estimate a geometrically consistent and physically plausible 3D scene. Experiments on the SUN RGB-D dataset shows that the proposed method significantly outperforms prior approaches on 3D object detection, 3D layout estimation, 3D camera pose estimation, and holistic scene understanding.



### User Constrained Thumbnail Generation using Adaptive Convolutions
- **Arxiv ID**: http://arxiv.org/abs/1810.13054v3
- **DOI**: 10.1109/ICASSP.2019.8683761
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13054v3)
- **Published**: 2018-10-31 00:57:13+00:00
- **Updated**: 2019-04-19 02:23:39+00:00
- **Authors**: Perla Sai Raj Kishore, Ayan Kumar Bhunia, Shuvozit Ghose, Partha Pratim Roy
- **Comment**: International Conference on Acoustics, Speech, and Signal
  Processing(ICASSP), 2019
- **Journal**: None
- **Summary**: Thumbnails are widely used all over the world as a preview for digital images. In this work we propose a deep neural framework to generate thumbnails of any size and aspect ratio, even for unseen values during training, with high accuracy and precision. We use Global Context Aggregation (GCA) and a modified Region Proposal Network (RPN) with adaptive convolutions to generate thumbnails in real time. GCA is used to selectively attend and aggregate the global context information from the entire image while the RPN is used to predict candidate bounding boxes for the thumbnail image. Adaptive convolution eliminates the problem of generating thumbnails of various aspect ratios by using filter weights dynamically generated from the aspect ratio information. The experimental results indicate the superior performance of the proposed model over existing state-of-the-art techniques.



### Visual Attention Network for Low Dose CT
- **Arxiv ID**: http://arxiv.org/abs/1810.13059v2
- **DOI**: 10.1109/LSP.2019.2922851
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.13059v2)
- **Published**: 2018-10-31 01:12:03+00:00
- **Updated**: 2019-06-14 01:34:47+00:00
- **Authors**: Wenchao Du, Hu Chen, Peixi Liao, Hongyu Yang, Ge Wang, Yi Zhang
- **Comment**: 5 pages, 6 figures. To appear on IEEE Signal Processing Letters
- **Journal**: None
- **Summary**: Noise and artifacts are intrinsic to low dose CT (LDCT) data acquisition, and will significantly affect the imaging performance. Perfect noise removal and image restoration is intractable in the context of LDCT due to the statistical and technical uncertainties. In this paper, we apply the generative adversarial network (GAN) framework with a visual attention mechanism to deal with this problem in a data-driven/machine learning fashion. Our main idea is to inject visual attention knowledge into the learning process of GAN to provide a powerful prior of the noise distribution. By doing this, both the generator and discriminator networks are empowered with visual attention information so they will not only pay special attention to noisy regions and surrounding structures but also explicitly assess the local consistency of the recovered regions. Our experiments qualitatively and quantitatively demonstrate the effectiveness of the proposed method with clinic CT images.



### Query Adaptive Late Fusion for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1810.13103v1
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.13103v1)
- **Published**: 2018-10-31 04:51:16+00:00
- **Updated**: 2018-10-31 04:51:16+00:00
- **Authors**: Zhongdao Wang, Liang Zheng, Shengjin Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Feature fusion is a commonly used strategy in image retrieval tasks, which aggregates the matching responses of multiple visual features. Feasible sets of features can be either descriptors (SIFT, HSV) for an entire image or the same descriptor for different local parts (face, body). Ideally, the to-be-fused heterogeneous features are pre-assumed to be discriminative and complementary to each other. However, the effectiveness of different features varies dramatically according to different queries. That is to say, for some queries, a feature may be neither discriminative nor complementary to existing ones, while for other queries, the feature suffices. As a result, it is important to estimate the effectiveness of features in a query-adaptive manner. To this end, this article proposes a new late fusion scheme at the score level. We base our method on the observation that the sorted score curves contain patterns that describe their effectiveness. For example, an "L"-shaped curve indicates that the feature is discriminative while a gradually descending curve suggests a bad feature. As such, this paper introduces a query-adaptive late fusion pipeline. In the hand-crafted version, it can be an unsupervised approach to tasks like particular object retrieval. In the learning version, it can also be applied to supervised tasks like person recognition and pedestrian retrieval, based on a trainable neural module. Extensive experiments are conducted on two object retrieval datasets and one person recognition dataset. We show that our method is able to highlight the good features and suppress the bad ones, is resilient to distractor features, and achieves very competitive retrieval accuracy compared with the state of the art. In an additional person re-identification dataset, the application scope and limitation of the proposed method are studied.



### Compact Generalized Non-local Network
- **Arxiv ID**: http://arxiv.org/abs/1810.13125v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13125v2)
- **Published**: 2018-10-31 06:43:14+00:00
- **Updated**: 2018-11-01 03:24:51+00:00
- **Authors**: Kaiyu Yue, Ming Sun, Yuchen Yuan, Feng Zhou, Errui Ding, Fuxin Xu
- **Comment**: Technical report; To appear at NIPS 2018; Code is available at
  https://github.com/KaiyuYue/cgnl-network.pytorch
- **Journal**: None
- **Summary**: The non-local module is designed for capturing long-range spatio-temporal dependencies in images and videos. Although having shown excellent performance, it lacks the mechanism to model the interactions between positions across channels, which are of vital importance in recognizing fine-grained objects and actions. To address this limitation, we generalize the non-local module and take the correlations between the positions of any two channels into account. This extension utilizes the compact representation for multiple kernel functions with Taylor expansion that makes the generalized non-local module in a fast and low-complexity computation flow. Moreover, we implement our generalized non-local method within channel groups to ease the optimization. Experimental results illustrate the clear-cut improvements and practical applicability of the generalized non-local module on both fine-grained object recognition and video classification. Code is available at: https://github.com/KaiyuYue/cgnl-network.pytorch.



### The Effect of Learning Strategy versus Inherent Architecture Properties on the Ability of Convolutional Neural Networks to Develop Transformation Invariance
- **Arxiv ID**: http://arxiv.org/abs/1810.13128v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13128v1)
- **Published**: 2018-10-31 06:48:15+00:00
- **Updated**: 2018-10-31 06:48:15+00:00
- **Authors**: Megha Srivastava, Kalanit Grill-Spector
- **Comment**: 11 pages, 17 figures
- **Journal**: None
- **Summary**: As object recognition becomes an increasingly common ML task, and recent research demonstrating CNNs vulnerability to attacks and small image perturbations necessitate fully understanding the foundations of object recognition. We focus on understanding the mechanisms behind how neural networks generalize to spatial transformations of complex objects. While humans excel at discriminating between objects shown at new positions, orientations, and scales, past results demonstrate that this may be limited to familiar objects - humans demonstrate low tolerance of spatial-variances for purposefully constructed novel objects. Because training artificial neural networks from scratch is similar to showing novel objects to humans, we seek to understand the factors influencing the tolerance of CNNs to spatial transformations. We conduct a thorough empirical examination of seven Convolutional Neural Network (CNN) architectures. By training on a controlled face image dataset, we measure model accuracy across different degrees of 5 transformations: position, size, rotation, Gaussian blur, and resolution transformation due to resampling. We also examine how learning strategy affects generalizability by examining how different amounts of pre-training have on model robustness. Overall, we find that the most significant contributor to transformation invariance is pre-training on a large, diverse image dataset. Moreover, while AlexNet tends to be the least robust network, VGG and ResNet architectures demonstrate higher robustness for different transformations. Along with kernel visualizations and qualitative analyses, we examine differences between learning strategy and inherent architectural properties in contributing to invariance of transformations, providing valuable information towards understanding how to achieve greater robustness to transformations in CNNs.



### Don't forget, there is more than forgetting: new metrics for Continual Learning
- **Arxiv ID**: http://arxiv.org/abs/1810.13166v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG, cs.NE, 68T05, cs.LG, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.13166v1)
- **Published**: 2018-10-31 09:15:02+00:00
- **Updated**: 2018-10-31 09:15:02+00:00
- **Authors**: Natalia Díaz-Rodríguez, Vincenzo Lomonaco, David Filliat, Davide Maltoni
- **Comment**: None
- **Journal**: None
- **Summary**: Continual learning consists of algorithms that learn from a stream of data/tasks continuously and adaptively thought time, enabling the incremental development of ever more complex knowledge and skills. The lack of consensus in evaluating continual learning algorithms and the almost exclusive focus on forgetting motivate us to propose a more comprehensive set of implementation independent metrics accounting for several factors we believe have practical implications worth considering in the deployment of real AI systems that learn continually: accuracy or performance over time, backward and forward knowledge transfer, memory overhead as well as computational efficiency. Drawing inspiration from the standard Multi-Attribute Value Theory (MAVT) we further propose to fuse these metrics into a single score for ranking purposes and we evaluate our proposal with five continual learning strategies on the iCIFAR-100 continual learning benchmark.



### Inception-Residual Block based Neural Network for Thermal Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1810.13169v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13169v2)
- **Published**: 2018-10-31 09:18:55+00:00
- **Updated**: 2018-11-19 05:02:24+00:00
- **Authors**: Seongmin Hwang, Gwanghyun Yu, Huy Toan Nguyen, Nazeer Shahid, Doseong Sin, Jinyoung Kim, Seungyou Na
- **Comment**: 7 pages
- **Journal**: None
- **Summary**: Thermal cameras show noisy images due to their limited thermal resolution, especially for the scenes of a low temperature difference. In order to deal with a noise problem, this paper proposes a novel neural network architecture with repeatable denoising inception-residual blocks(DnIRB) for noise learning. Each DnIRB has two sub-blocks with difference receptive fields and one shortcut connection to prevent a vanishing gradient problem. The proposed approach is tested for thermal images. The experimental results indicate that the proposed approach shows the best SQNR performance and reasonable processing time compared with state-of-the-art denoising methods.



### Face Presentation Attack Detection in Learned Color-liked Space
- **Arxiv ID**: http://arxiv.org/abs/1810.13170v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13170v2)
- **Published**: 2018-10-31 09:20:06+00:00
- **Updated**: 2018-11-12 06:03:19+00:00
- **Authors**: Lei Li, Zhaoqiang Xia, Xiaoyue Jiang, Fabio Roli, Xiaoyi Feng
- **Comment**: None
- **Journal**: None
- **Summary**: Face presentation attack detection (PAD) has become a thorny problem for biometric systems and numerous countermeasures have been proposed to address it. However, majority of them directly extract feature descriptors and distinguish fake faces from the real ones in existing color spaces (e.g. RGB, HSV and YCbCr). Unfortunately, it is unknown for us which color space is the best or how to combine different spaces together. To make matters worse, the real and fake faces are overlapped in existing color spaces. So, in this paper, a learned distinguishable color-liked space is generated to deal with the problem of face PAD. More specifically, we present an end-to-end deep learning network that can map existing color spaces to a new learned color-liked space. Inspired by the generator of generative adversarial network (GAN), the proposed network consists of a space generator and a feature extractor. When training the color-liked space, a new triplet combination mechanism of points-to-center is explored to maximize interclass distance and minimize intraclass distance, and also keep a safe margin between the real and presented fake faces. Extensive experiments on two standard face PAD databases, i.e., Relay-Attack and OULU-NPU, indicate that our proposed color-liked space analysis based countermeasure significantly outperforms the state-of-the-art methods and show excellent generalization capability.



### The Many Moods of Emotion
- **Arxiv ID**: http://arxiv.org/abs/1810.13197v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.13197v1)
- **Published**: 2018-10-31 10:24:08+00:00
- **Updated**: 2018-10-31 10:24:08+00:00
- **Authors**: Valentin Vielzeuf, Corentin Kervadec, Stéphane Pateux, Frédéric Jurie
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a novel approach to the facial expression generation problem. Building upon the assumption of the psychological community that emotion is intrinsically continuous, we first design our own continuous emotion representation with a 3-dimensional latent space issued from a neural network trained on discrete emotion classification. The so-obtained representation can be used to annotate large in the wild datasets and later used to trained a Generative Adversarial Network. We first show that our model is able to map back to discrete emotion classes with a objectively and subjectively better quality of the images than usual discrete approaches. But also that we are able to pave the larger space of possible facial expressions, generating the many moods of emotion. Moreover, two axis in this space may be found to generate similar expression changes as in traditional continuous representations such as arousal-valence. Finally we show from visual interpretation, that the third remaining dimension is highly related to the well-known dominance dimension from psychology.



### Compressive Single-pixel Fourier Transform Imaging using Structured Illumination
- **Arxiv ID**: http://arxiv.org/abs/1810.13200v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13200v2)
- **Published**: 2018-10-31 10:29:07+00:00
- **Updated**: 2019-02-18 11:30:23+00:00
- **Authors**: Amirafshar Moshtaghpour, José M. Bioucas-Dias, Laurent Jacques
- **Comment**: 9 pages, 4 figures
- **Journal**: None
- **Summary**: Single Pixel (SP) imaging is now a reality in many applications, e.g., biomedical ultrathin endoscope and fluorescent spectroscopy. In this context, many schemes exist to improve the light throughput of these device, e.g., using structured illumination driven by compressive sensing theory. In this work, we consider the combination of SP imaging with Fourier Transform Interferometry (SP-FTI) to reach high-resolution HyperSpectral (HS) imaging, as desirable, e.g., in fluorescent spectroscopy. While this association is not new, we here focus on optimizing the spatial illumination, structured as Hadamard patterns, during the optical path progression. We follow a variable density sampling strategy for space-time coding of the light illumination, and show theoretically and numerically that this scheme allows us to reduce the number of measurements and light-exposure of the observed object compared to conventional compressive SP-FTI.



### Multi-Task Learning for Left Atrial Segmentation on GE-MRI
- **Arxiv ID**: http://arxiv.org/abs/1810.13205v1
- **DOI**: 10.1007/978-3-030-12029-0_32
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.13205v1)
- **Published**: 2018-10-31 10:47:06+00:00
- **Updated**: 2018-10-31 10:47:06+00:00
- **Authors**: Chen Chen, Wenjia Bai, Daniel Rueckert
- **Comment**: STACOM 2018 Workshop, MICCAI 2018
- **Journal**: Statistical Atlases and Computational Models of the Heart. Atrial
  Segmentation and LV Quantification Challenges, 9th International Workshop,
  STACOM 2018, pp.292-301
- **Summary**: Segmentation of the left atrium (LA) is crucial for assessing its anatomy in both pre-operative atrial fibrillation (AF) ablation planning and post-operative follow-up studies. In this paper, we present a fully automated framework for left atrial segmentation in gadolinium-enhanced magnetic resonance images (GE-MRI) based on deep learning. We propose a fully convolutional neural network and explore the benefits of multi-task learning for performing both atrial segmentation and pre/post ablation classification. Our results show that, by sharing features between related tasks, the network can gain additional anatomical information and achieve more accurate atrial segmentation, leading to a mean Dice score of 0.901 on a test set of 20 3D MRI images. Code of our proposed algorithm is available at https://github.com/cherise215/atria_segmentation_2018/.



### Quaternion Convolutional Neural Networks for Heterogeneous Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1811.02656v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.02656v1)
- **Published**: 2018-10-31 11:22:54+00:00
- **Updated**: 2018-10-31 11:22:54+00:00
- **Authors**: Titouan Parcollet, Mohamed Morchid, Georges Linarès
- **Comment**: Submitted at ICASSP 2019
- **Journal**: None
- **Summary**: Convolutional neural networks (CNN) have recently achieved state-of-the-art results in various applications. In the case of image recognition, an ideal model has to learn independently of the training data, both local dependencies between the three components (R,G,B) of a pixel, and the global relations describing edges or shapes, making it efficient with small or heterogeneous datasets. Quaternion-valued convolutional neural networks (QCNN) solved this problematic by introducing multidimensional algebra to CNN. This paper proposes to explore the fundamental reason of the success of QCNN over CNN, by investigating the impact of the Hamilton product on a color image reconstruction task performed from a gray-scale only training. By learning independently both internal and external relations and with less parameters than real valued convolutional encoder-decoder (CAE), quaternion convolutional encoder-decoders (QCAE) perfectly reconstructed unseen color images while CAE produced worst and gray-scale versions.



### Methods for Segmentation and Classification of Digital Microscopy Tissue Images
- **Arxiv ID**: http://arxiv.org/abs/1810.13230v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13230v2)
- **Published**: 2018-10-31 12:03:27+00:00
- **Updated**: 2018-11-16 19:08:17+00:00
- **Authors**: Quoc Dang Vu, Simon Graham, Minh Nguyen Nhat To, Muhammad Shaban, Talha Qaiser, Navid Alemi Koohbanani, Syed Ali Khurram, Tahsin Kurc, Keyvan Farahani, Tianhao Zhao, Rajarsi Gupta, Jin Tae Kwak, Nasir Rajpoot, Joel Saltz
- **Comment**: None
- **Journal**: None
- **Summary**: High-resolution microscopy images of tissue specimens provide detailed information about the morphology of normal and diseased tissue. Image analysis of tissue morphology can help cancer researchers develop a better understanding of cancer biology. Segmentation of nuclei and classification of tissue images are two common tasks in tissue image analysis. Development of accurate and efficient algorithms for these tasks is a challenging problem because of the complexity of tissue morphology and tumor heterogeneity. In this paper we present two computer algorithms; one designed for segmentation of nuclei and the other for classification of whole slide tissue images. The segmentation algorithm implements a multiscale deep residual aggregation network to accurately segment nuclear material and then separate clumped nuclei into individual nuclei. The classification algorithm initially carries out patch-level classification via a deep learning method, then patch-level statistical and morphological features are used as input to a random forest regression model for whole slide image classification. The segmentation and classification algorithms were evaluated in the MICCAI 2017 Digital Pathology challenge. The segmentation algorithm achieved an accuracy score of 0.78. The classification algorithm achieved an accuracy score of 0.81.



### Ionospheric activity prediction using convolutional recurrent neural networks
- **Arxiv ID**: http://arxiv.org/abs/1810.13273v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.13273v2)
- **Published**: 2018-10-31 13:25:17+00:00
- **Updated**: 2018-11-06 12:14:15+00:00
- **Authors**: Alexandre Boulch, Noëlie Cherrier, Thibaut Castaings
- **Comment**: Under submission at IEEE Transactions on Big Data
- **Journal**: None
- **Summary**: The ionosphere electromagnetic activity is a major factor of the quality of satellite telecommunications, Global Navigation Satellite Systems (GNSS) and other vital space applications. Being able to forecast globally the Total Electron Content (TEC) would enable a better anticipation of potential performance degradations. A few studies have proposed models able to predict the TEC locally, but not worldwide for most of them. Thanks to a large record of past TEC maps publicly available, we propose a method based on Deep Neural Networks (DNN) to forecast a sequence of global TEC maps consecutive to an input sequence of TEC maps, without introducing any prior knowledge other than Earth rotation periodicity. By combining several state-of-the-art architectures, the proposed approach is competitive with previous works on TEC forecasting while predicting the TEC globally.



### Anomaly Detection With Multiple-Hypotheses Predictions
- **Arxiv ID**: http://arxiv.org/abs/1810.13292v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1810.13292v5)
- **Published**: 2018-10-31 14:05:44+00:00
- **Updated**: 2019-05-31 12:25:42+00:00
- **Authors**: Duc Tam Nguyen, Zhongyu Lou, Michael Klar, Thomas Brox
- **Comment**: In proceedings of the 36th International Conference on Machine
  Learning (ICML), Long Beach, California, PMLR 97, 2019
- **Journal**: None
- **Summary**: In one-class-learning tasks, only the normal case (foreground) can be modeled with data, whereas the variation of all possible anomalies is too erratic to be described by samples. Thus, due to the lack of representative data, the wide-spread discriminative approaches cannot cover such learning tasks, and rather generative models, which attempt to learn the input density of the foreground, are used. However, generative models suffer from a large input dimensionality (as in images) and are typically inefficient learners. We propose to learn the data distribution of the foreground more efficiently with a multi-hypotheses autoencoder. Moreover, the model is criticized by a discriminator, which prevents artificial data modes not supported by data, and enforces diversity across hypotheses. Our multiple-hypothesesbased anomaly detection framework allows the reliable identification of out-of-distribution samples. For anomaly detection on CIFAR-10, it yields up to 3.9% points improvement over previously reported results. On a real anomaly detection task, the approach reduces the error of the baseline models from 6.8% to 1.5%.



### Acute and sub-acute stroke lesion segmentation from multimodal MRI
- **Arxiv ID**: http://arxiv.org/abs/1810.13304v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13304v2)
- **Published**: 2018-10-31 14:34:39+00:00
- **Updated**: 2019-04-24 07:59:58+00:00
- **Authors**: Albert Clèrigues, Sergi Valverde, Jose Bernal, Jordi Freixenet, Arnau Oliver, Xavier Lladó
- **Comment**: None
- **Journal**: None
- **Summary**: Acute stroke lesion segmentation tasks are of great clinical interest as they can help doctors make better informed treatment decisions. Magnetic resonance imaging (MRI) is time demanding but can provide images that are considered gold standard for diagnosis. Automated stroke lesion segmentation can provide with an estimate of the location and volume of the lesioned tissue, which can help in the clinical practice to better assess and evaluate the risks of each treatment. We propose a deep learning methodology for acute and sub-acute stroke lesion segmentation using multimodal MR imaging. The proposed method is evaluated using two public datasets from the 2015 Ischemic Stroke Lesion Segmentation challenge (ISLES 2015). These involve the tasks of sub-acute stroke lesion segmentation (SISS) and acute stroke penumbra estimation (SPES) from diffusion, perfusion and anatomical MRI modalities. The performance is compared against state-of-the-art methods with a blind online testing set evaluation on each of the challenges. At the time of submitting this manuscript, our approach is the first method in the online rankings for the SISS (DSC=0.59$\pm$0.31) and SPES sub-tasks (DSC=0.84$\pm$0.10). When compared with the rest of submitted strategies, we achieve top rank performance with a lower Hausdorff distance. Better segmentation results are obtained by leveraging the anatomy and pathophysiology of acute stroke lesions and using a combined approach to minimize the effects of class imbalance. The same training procedure is used for both tasks, showing the proposed methodology can generalize well enough to deal with different unrelated tasks and imaging modalities without training hyper-parameter tuning. A public version of the proposed method has been released to the scientific community at https://github.com/NIC-VICOROB/stroke-mri-segmentation.



### Analyzing biological and artificial neural networks: challenges with opportunities for synergy?
- **Arxiv ID**: http://arxiv.org/abs/1810.13373v1
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.AI, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.13373v1)
- **Published**: 2018-10-31 16:09:44+00:00
- **Updated**: 2018-10-31 16:09:44+00:00
- **Authors**: David G. T. Barrett, Ari S. Morcos, Jakob H. Macke
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) transform stimuli across multiple processing stages to produce representations that can be used to solve complex tasks, such as object recognition in images. However, a full understanding of how they achieve this remains elusive. The complexity of biological neural networks substantially exceeds the complexity of DNNs, making it even more challenging to understand the representations that they learn. Thus, both machine learning and computational neuroscience are faced with a shared challenge: how can we analyze their representations in order to understand how they solve complex tasks?   We review how data-analysis concepts and techniques developed by computational neuroscientists can be useful for analyzing representations in DNNs, and in turn, how recently developed techniques for analysis of DNNs can be useful for understanding representations in biological neural networks. We explore opportunities for synergy between the two fields, such as the use of DNNs as in-silico model systems for neuroscience, and how this synergy can lead to new hypotheses about the operating principles of biological neural networks.



### Performance assessment of the deep learning technologies in grading glaucoma severity
- **Arxiv ID**: http://arxiv.org/abs/1810.13376v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.13376v1)
- **Published**: 2018-10-31 16:12:30+00:00
- **Updated**: 2018-10-31 16:12:30+00:00
- **Authors**: Yi Zhen, Lei Wang, Han Liu, Jian Zhang, Jiantao Pu
- **Comment**: None
- **Journal**: None
- **Summary**: Objective: To validate and compare the performance of eight available deep learning architectures in grading the severity of glaucoma based on color fundus images. Materials and Methods: We retrospectively collected a dataset of 5978 fundus images and their glaucoma severities were annotated by the consensus of two experienced ophthalmologists. We preprocessed the images to generate global and local regions of interest (ROIs), namely the global field-of-view images and the local disc region images. We then divided the generated images into three independent sub-groups for training, validation, and testing purposes. With the datasets, eight convolutional neural networks (CNNs) (i.e., VGG16, VGG19, ResNet, DenseNet, InceptionV3, InceptionResNet, Xception, and NASNetMobile) were trained separately to grade glaucoma severity, and validated quantitatively using the area under the receiver operating characteristic (ROC) curve and the quadratic kappa score. Results: The CNNs, except VGG16 and VGG19, achieved average kappa scores of 80.36% and 78.22% when trained from scratch on global and local ROIs, and 85.29% and 82.72% when fine-tuned using the pre-trained weights, respectively. VGG16 and VGG19 achieved reasonable accuracy when trained from scratch, but they failed when using pre-trained weights for global and local ROIs. Among these CNNs, the DenseNet had the highest classification accuracy (i.e., 75.50%) based on pre-trained weights when using global ROIs, as compared to 65.50% when using local ROIs. Conclusion: The experiments demonstrated the feasibility of the deep learning technology in grading glaucoma severity. In particular, global field-of-view images contain relatively richer information that may be critical for glaucoma assessment, suggesting that we should use the entire field-of-view of a fundus image for training a deep learning network.



### Unsupervised Identification of Disease Marker Candidates in Retinal OCT Imaging Data
- **Arxiv ID**: http://arxiv.org/abs/1810.13404v1
- **DOI**: 10.1109/TMI.2018.2877080
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.13404v1)
- **Published**: 2018-10-31 16:55:46+00:00
- **Updated**: 2018-10-31 16:55:46+00:00
- **Authors**: Philipp Seeböck, Sebastian M. Waldstein, Sophie Klimscha, Hrvoje Bogunovic, Thomas Schlegl, Bianca S. Gerendas, René Donner, Ursula Schmidt-Erfurth, Georg Langs
- **Comment**: Accepted for publication in IEEE Transactions on Medical Imaging,
  2018
- **Journal**: None
- **Summary**: The identification and quantification of markers in medical images is critical for diagnosis, prognosis, and disease management. Supervised machine learning enables the detection and exploitation of findings that are known a priori after annotation of training examples by experts. However, supervision does not scale well, due to the amount of necessary training examples, and the limitation of the marker vocabulary to known entities. In this proof-of-concept study, we propose unsupervised identification of anomalies as candidates for markers in retinal Optical Coherence Tomography (OCT) imaging data without a constraint to a priori definitions. We identify and categorize marker candidates occurring frequently in the data, and demonstrate that these markers show predictive value in the task of detecting disease. A careful qualitative analysis of the identified data driven markers reveals how their quantifiable occurrence aligns with our current understanding of disease course, in early- and late age-related macular degeneration (AMD) patients. A multi-scale deep denoising autoencoder is trained on healthy images, and a one-class support vector machine identifies anomalies in new data. Clustering in the anomalies identifies stable categories. Using these markers to classify healthy-, early AMD- and late AMD cases yields an accuracy of 81.40%. In a second binary classification experiment on a publicly available data set (healthy vs. intermediate AMD) the model achieves an area under the ROC curve of 0.944.



### DEEPGONET: Multi-label Prediction of GO Annotation for Protein from Sequence Using Cascaded Convolutional and Recurrent Network
- **Arxiv ID**: http://arxiv.org/abs/1811.00053v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.00053v1)
- **Published**: 2018-10-31 18:26:41+00:00
- **Updated**: 2018-10-31 18:26:41+00:00
- **Authors**: Sheikh Muhammad Saiful Islam, Md Mahedi Hasan
- **Comment**: Accepted in ICCIT 2018
- **Journal**: None
- **Summary**: The present gap between the amount of available protein sequence due to the development of next generation sequencing technology (NGS) and slow and expensive experimental extraction of useful information like annotation of protein sequence in different functional aspects, is ever widening, which can be reduced by employing automatic function prediction (AFP) approaches. Gene Ontology (GO), comprising of more than 40, 000 classes, defines three aspects of protein function names Biological Process (BP), Cellular Component (CC), Molecular Function (MF). Multiple functions of a single protein, has made automatic function prediction a large-scale, multi-class, multi-label task. In this paper, we present DEEPGONET, a novel cascaded convolutional and recurrent neural network, to predict the top-level hierarchy of GO ontology. The network takes the primary sequence of protein as input which makes it more useful than other prevailing state-of-the-art deep learning based methods with multi-modal input, making them less applicable for proteins where only primary sequence is available. All predictions of different protein functions of our network are performed by the same architecture, a proof of better generalization as demonstrated by promising performance on a variety of organisms while trained on Homo sapiens only, which is made possible by efficient exploration of vast output space by leveraging hierarchical relationship among GO classes. The promising performance of our model makes it a potential avenue for directing experimental protein functions exploration efficiently by vastly eliminating possible routes which is done by the exploring only the suggested routes from our model. Our proposed model is also very simple and efficient in terms of computational time and space compared to other architectures in literature.



### Finding and Following of Honeycombing Regions in Computed Tomography Lung Images by Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1811.02651v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.02651v3)
- **Published**: 2018-10-31 18:29:45+00:00
- **Updated**: 2019-02-11 10:24:10+00:00
- **Authors**: Emre Eğriboz, Furkan Kaynar, Songül Varlı Albayrak, Benan Müsellim, Tuba Selçuk
- **Comment**: 4 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: In recent years, besides the medical treatment methods in medical field, Computer Aided Diagnosis (CAD) systems which can facilitate the decision making phase of the physician and can detect the disease at an early stage have started to be used frequently. The diagnosis of Idiopathic Pulmonary Fibrosis (IPF) disease by using CAD systems is very important in that it can be followed by doctors and radiologists. It has become possible to diagnose and follow up the disease with the help of CAD systems by the development of high resolution computed imaging scanners and increasing size of computation power. The purpose of this project is to design a tool that will help specialists diagnose and follow up the IPF disease by identifying areas of honeycombing and ground glass patterns in High Resolution Computed Tomography (HRCT) lung images. Creating a program module that segments the lung pair and creating a self-learner deep learning model from given Computed Tomography (CT) images for the specific diseased regions thanks to doctors are the main purposes of this work. Through the created model, program module will be able to find special regions in given new CT images. In this study, the performance of lung segmentation was tested by the S{\o}rensen-Dice coefficient method and the mean performance was measured as 90.7%, testing of the created model was performed with data not used in the training stage of the CNN network, and the average performance was measured as 87.8% for healthy regions, 73.3% for ground-glass areas and 69.1% for honeycombing zones.



### A Mixture of Expert Approach for Low-Cost Customization of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1811.00056v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.00056v1)
- **Published**: 2018-10-31 18:37:28+00:00
- **Updated**: 2018-10-31 18:37:28+00:00
- **Authors**: Boyu Zhang, Azadeh Davoodi, Yu-Hen Hu
- **Comment**: None
- **Journal**: None
- **Summary**: The ability to customize a trained Deep Neural Network (DNN) locally using user-specific data may greatly enhance user experiences, reduce development costs, and protect user's privacy. In this work, we propose to incorporate a novel Mixture of Experts (MOE) approach to accomplish this goal. This architecture comprises of a Global Expert (GE), a Local Expert (LE) and a Gating Network (GN). The GE is a trained DNN developed on a large training dataset representative of many potential users. After deployment on an embedded edge device, GE will be subject to customized, user-specific data (e.g., accent in speech) and its performance may suffer. This problem may be alleviated by training a local DNN (the local expert, LE) on a small size customized training data to correct the errors made by GE. A gating network then will be trained to determine whether an incoming data should be handled by GE or LE. Since the customized dataset is in general very small, the cost of training LE and GN would be much lower than that of re-training of GE. The training of LE and GN thus can be performed at local device, properly protecting the privacy of customized training data. In this work, we developed a prototype MOE architecture for handwritten alphanumeric character recognition task. We use EMNIST as the generic dataset, LeNet5 as GE, and handwritings of 10 users as the customized dataset. We show that with the LE and GN, the classification accuracy is significantly enhanced over the customized dataset with almost no degradation of accuracy over the generic dataset. In terms of energy and network size, the overhead of LE and GN is around 2.5% compared to those of GE.



### Generating Photo-Realistic Training Data to Improve Face Recognition Accuracy
- **Arxiv ID**: http://arxiv.org/abs/1811.00112v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.00112v1)
- **Published**: 2018-10-31 20:53:25+00:00
- **Updated**: 2018-10-31 20:53:25+00:00
- **Authors**: Daniel Sáez Trigueros, Li Meng, Margaret Hartnett
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we investigate the feasibility of using synthetic data to augment face datasets. In particular, we propose a novel generative adversarial network (GAN) that can disentangle identity-related attributes from non-identity-related attributes. This is done by training an embedding network that maps discrete identity labels to an identity latent space that follows a simple prior distribution, and training a GAN conditioned on samples from that distribution. Our proposed GAN allows us to augment face datasets by generating both synthetic images of subjects in the training set and synthetic images of new subjects not in the training set. By using recent advances in GAN training, we show that the synthetic images generated by our model are photo-realistic, and that training with augmented datasets can indeed increase the accuracy of face recognition models as compared with models trained with real images alone.



### Face Recognition: From Traditional to Deep Learning Methods
- **Arxiv ID**: http://arxiv.org/abs/1811.00116v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.00116v1)
- **Published**: 2018-10-31 20:58:39+00:00
- **Updated**: 2018-10-31 20:58:39+00:00
- **Authors**: Daniel Sáez Trigueros, Li Meng, Margaret Hartnett
- **Comment**: None
- **Journal**: None
- **Summary**: Starting in the seventies, face recognition has become one of the most researched topics in computer vision and biometrics. Traditional methods based on hand-crafted features and traditional machine learning techniques have recently been superseded by deep neural networks trained with very large datasets. In this paper we provide a comprehensive and up-to-date literature review of popular face recognition methods including both traditional (geometry-based, holistic, feature-based and hybrid methods) and deep learning methods.



### When Not to Classify: Detection of Reverse Engineering Attacks on DNN Image Classifiers
- **Arxiv ID**: http://arxiv.org/abs/1811.02658v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.02658v1)
- **Published**: 2018-10-31 20:59:49+00:00
- **Updated**: 2018-10-31 20:59:49+00:00
- **Authors**: Yujia Wang, David J. Miller, George Kesidis
- **Comment**: None
- **Journal**: None
- **Summary**: This paper addresses detection of a reverse engineering (RE) attack targeting a deep neural network (DNN) image classifier; by querying, RE's aim is to discover the classifier's decision rule. RE can enable test-time evasion attacks, which require knowledge of the classifier. Recently, we proposed a quite effective approach (ADA) to detect test-time evasion attacks. In this paper, we extend ADA to detect RE attacks (ADA-RE). We demonstrate our method is successful in detecting "stealthy" RE attacks before they learn enough to launch effective test-time evasion attacks.



### Regularized Fourier Ptychography using an Online Plug-and-Play Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1811.00120v2
- **DOI**: 10.1109/ICASSP.2019.8683057
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.00120v2)
- **Published**: 2018-10-31 21:04:42+00:00
- **Updated**: 2018-11-02 14:58:31+00:00
- **Authors**: Yu Sun, Shiqi Xu, Yunzhe Li, Lei Tian, Brendt Wohlberg, Ulugbek S. Kamilov
- **Comment**: None
- **Journal**: None
- **Summary**: The plug-and-play priors (PnP) framework has been recently shown to achieve state-of-the-art results in regularized image reconstruction by leveraging a sophisticated denoiser within an iterative algorithm. In this paper, we propose a new online PnP algorithm for Fourier ptychographic microscopy (FPM) based on the fast iterative shrinkage/threshold algorithm (FISTA). Specifically, the proposed algorithm uses only a subset of measurements, which makes it scalable to a large set of measurements. We validate the algorithm by showing that it can lead to significant performance gains on both simulated and experimental data.



### Democratizing Production-Scale Distributed Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1811.00143v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1811.00143v2)
- **Published**: 2018-10-31 22:39:59+00:00
- **Updated**: 2018-11-03 05:47:41+00:00
- **Authors**: Minghuang Ma, Hadi Pouransari, Daniel Chao, Saurabh Adya, Santiago Akle Serrano, Yi Qin, Dan Gimnicher, Dominic Walsh
- **Comment**: None
- **Journal**: None
- **Summary**: The interest and demand for training deep neural networks have been experiencing rapid growth, spanning a wide range of applications in both academia and industry. However, training them distributed and at scale remains difficult due to the complex ecosystem of tools and hardware involved. One consequence is that the responsibility of orchestrating these complex components is often left to one-off scripts and glue code customized for specific problems. To address these restrictions, we introduce \emph{Alchemist} - an internal service built at Apple from the ground up for \emph{easy}, \emph{fast}, and \emph{scalable} distributed training. We discuss its design, implementation, and examples of running different flavors of distributed training. We also present case studies of its internal adoption in the development of autonomous systems, where training times have been reduced by 10x to keep up with the ever-growing data collection.



### Conceptual Content in Deep Convolutional Neural Networks: An analysis into multi-faceted properties of neurons
- **Arxiv ID**: http://arxiv.org/abs/1811.00161v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.00161v3)
- **Published**: 2018-10-31 23:56:26+00:00
- **Updated**: 2020-07-01 10:02:20+00:00
- **Authors**: Zahra Sadeghi
- **Comment**: 12 pages, 6 figures, 1 table
- **Journal**: None
- **Summary**: In this paper, convolutional layers of pre-trained VGG16 model are analyzed. The analysis is based on the responses of neurons to the images of classes in ImageNet database. First, a visualization method is proposed in order to illustrate the learned content of each neuron. Next, single and multi-faceted neurons are investigated based on the diversity of neurons responses to different category of objects. Finally, neuronal similarities at each layer are computed and compared. The results demonstrate that the neurons in lower layers exhibit a multi-faceted behavior, whereas the majority of neurons in higher layers com-prise single-faceted property and tend to respond to a smaller number of concepts.



