# Arxiv Papers in cs.CV on 2018-10-04
### Domain Specific Approximation for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1810.02010v1
- **DOI**: 10.1109/MM.2018.112130335
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02010v1)
- **Published**: 2018-10-04 00:25:02+00:00
- **Updated**: 2018-10-04 00:25:02+00:00
- **Authors**: Ting-Wu Chin, Chia-Lin Yu, Matthew Halpern, Hasan Genc, Shiao-Li Tsao, Vijay Janapa Reddi
- **Comment**: 6 pages, 6 figures. Published in IEEE Micro, vol. 38, no. 1, pp.
  31-40, January/February 2018
- **Journal**: T. Chin, C. Yu, M. Halpern, H. Genc, S. Tsao and V. J. Reddi,
  "Domain-Specific Approximation for Object Detection," in IEEE Micro, vol. 38,
  no. 1, pp. 31-40, January/February 2018
- **Summary**: There is growing interest in object detection in advanced driver assistance systems and autonomous robots and vehicles. To enable such innovative systems, we need faster object detection. In this work, we investigate the trade-off between accuracy and speed with domain-specific approximations, i.e. category-aware image size scaling and proposals scaling, for two state-of-the-art deep learning-based object detection meta-architectures. We study the effectiveness of applying approximation both statically and dynamically to understand the potential and the applicability of them. By conducting experiments on the ImageNet VID dataset, we show that domain-specific approximation has great potential to improve the speed of the system without deteriorating the accuracy of object detectors, i.e. up to 7.5x speedup for dynamic domain-specific approximation. To this end, we present our insights toward harvesting domain-specific approximation as well as devise a proof-of-concept runtime, AutoFocus, that exploits dynamic domain-specific approximation.



### Transfer Incremental Learning using Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/1810.02020v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.02020v1)
- **Published**: 2018-10-04 01:38:02+00:00
- **Updated**: 2018-10-04 01:38:02+00:00
- **Authors**: Ghouthi Boukli Hacene, Vincent Gripon, Nicolas Farrugia, Matthieu Arzel, Michel Jezequel
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning-based methods have reached state of the art performances, relying on large quantity of available data and computational power. Such methods still remain highly inappropriate when facing a major open machine learning problem, which consists of learning incrementally new classes and examples over time. Combining the outstanding performances of Deep Neural Networks (DNNs) with the flexibility of incremental learning techniques is a promising venue of research. In this contribution, we introduce Transfer Incremental Learning using Data Augmentation (TILDA). TILDA is based on pre-trained DNNs as feature extractor, robust selection of feature vectors in subspaces using a nearest-class-mean based technique, majority votes and data augmentation at both the training and the prediction stages. Experiments on challenging vision datasets demonstrate the ability of the proposed method for low complexity incremental learning, while achieving significantly better accuracy than existing incremental counterparts.



### GPU based Parallel Optimization for Real Time Panoramic Video Stitching
- **Arxiv ID**: http://arxiv.org/abs/1810.03988v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.03988v2)
- **Published**: 2018-10-04 04:18:17+00:00
- **Updated**: 2018-10-22 07:56:26+00:00
- **Authors**: Chengyao Du, Jingling Yuan, Jiansheng Dong, Lin Li, Mincheng Chen, Tao Li
- **Comment**: under review for Pattern Recognition Letters
- **Journal**: None
- **Summary**: Panoramic video is a sort of video recorded at the same point of view to record the full scene. With the development of video surveillance and the requirement for 3D converged video surveillance in smart cities, CPU and GPU are required to possess strong processing abilities to make panoramic video. The traditional panoramic products depend on post processing, which results in high power consumption, low stability and unsatisfying performance in real time. In order to solve these problems,we propose a real-time panoramic video stitching framework.The framework we propose mainly consists of three algorithms, LORB image feature extraction algorithm, feature point matching algorithm based on LSH and GPU parallel video stitching algorithm based on CUDA.The experiment results show that the algorithm mentioned can improve the performance in the stages of feature extraction of images stitching and matching, the running speed of which is 11 times than that of the traditional ORB algorithm and 639 times than that of the traditional SIFT algorithm. Based on analyzing the GPU resources occupancy rate of each resolution image stitching, we further propose a stream parallel strategy to maximize the utilization of GPU resources. Compared with the L-ORB algorithm, the efficiency of this strategy is improved by 1.6-2.5 times, and it can make full use of GPU resources. The performance of the system accomplished in the paper is 29.2 times than that of the former embedded one, while the power dissipation is reduced to 10W.



### Image-to-Video Person Re-Identification by Reusing Cross-modal Embeddings
- **Arxiv ID**: http://arxiv.org/abs/1810.03989v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.03989v2)
- **Published**: 2018-10-04 04:19:49+00:00
- **Updated**: 2018-10-22 07:58:48+00:00
- **Authors**: Zhongwei Xie, Lin Li, Xian Zhong, Luo Zhong
- **Comment**: under review for Pattern Recognition Letters
- **Journal**: None
- **Summary**: Image-to-video person re-identification identifies a target person by a probe image from quantities of pedestrian videos captured by non-overlapping cameras. Despite the great progress achieved,it's still challenging to match in the multimodal scenario,i.e. between image and video. Currently,state-of-the-art approaches mainly focus on the task-specific data,neglecting the extra information on the different but related tasks. In this paper,we propose an end-to-end neural network framework for image-to-video person reidentification by leveraging cross-modal embeddings learned from extra information.Concretely speaking,cross-modal embeddings from image captioning and video captioning models are reused to help learned features be projected into a coordinated space,where similarity can be directly computed. Besides,training steps from fixed model reuse approach are integrated into our framework,which can incorporate beneficial information and eventually make the target networks independent of existing models. Apart from that,our proposed framework resorts to CNNs and LSTMs for extracting visual and spatiotemporal features,and combines the strengths of identification and verification model to improve the discriminative ability of the learned feature. The experimental results demonstrate the effectiveness of our framework on narrowing down the gap between heterogeneous data and obtaining observable improvement in image-to-video person re-identification.



### Towards Fast and Energy-Efficient Binarized Neural Network Inference on FPGA
- **Arxiv ID**: http://arxiv.org/abs/1810.02068v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.AR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02068v1)
- **Published**: 2018-10-04 06:29:59+00:00
- **Updated**: 2018-10-04 06:29:59+00:00
- **Authors**: Cheng Fu, Shilin Zhu, Hao Su, Ching-En Lee, Jishen Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN by using a single bit (-1/+1) for network parameters and intermediate representations, which has greatly reduced the off-chip data transfer and storage overhead. However, a large amount of computation redundancy still exists in BNN inference. By analyzing local properties of images and the learned BNN kernel weights, we observe an average of $\sim$78% input similarity and $\sim$59% weight similarity among weight kernels, measured by our proposed metric in common network architectures. Thus there does exist redundancy that can be exploited to further reduce the amount of on-chip computations.   Motivated by the observation, in this paper, we proposed two types of fast and energy-efficient architectures for BNN inference. We also provide analysis and insights to pick the better strategy of these two for different datasets and network models. By reusing the results from previous computation, much cycles for data buffer access and computations can be skipped. By experiments, we demonstrate that 80% of the computation and 40% of the buffer access can be skipped by exploiting BNN similarity. Thus, our design can achieve 17% reduction in total power consumption, 54% reduction in on-chip power consumption and 2.4$\times$ maximum speedup, compared to the baseline without applying our reuse technique. Our design also shows 1.9$\times$ more area-efficiency compared to state-of-the-art BNN inference design. We believe our deployment of BNN on FPGA leads to a promising future of running deep learning models on mobile devices.



### Unsupervised Adversarial Visual Level Domain Adaptation for Learning Video Object Detectors from Images
- **Arxiv ID**: http://arxiv.org/abs/1810.02074v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02074v1)
- **Published**: 2018-10-04 07:07:29+00:00
- **Updated**: 2018-10-04 07:07:29+00:00
- **Authors**: Avisek Lahiri, Charan Reddy, Prabir Kumar Biswas
- **Comment**: * First two authors contributed equally
- **Journal**: None
- **Summary**: Deep learning based object detectors require thousands of diversified bounding box and class annotated examples. Though image object detectors have shown rapid progress in recent years with the release of multiple large-scale static image datasets, object detection on videos still remains an open problem due to scarcity of annotated video frames. Having a robust video object detector is an essential component for video understanding and curating large-scale automated annotations in videos. Domain difference between images and videos makes the transferability of image object detectors to videos sub-optimal. The most common solution is to use weakly supervised annotations where a video frame has to be tagged for presence/absence of object categories. This still takes up manual effort. In this paper we take a step forward by adapting the concept of unsupervised adversarial image-to-image translation to perturb static high quality images to be visually indistinguishable from a set of video frames. We assume the presence of a fully annotated static image dataset and an unannotated video dataset. Object detector is trained on adversarially transformed image dataset using the annotations of the original dataset. Experiments on Youtube-Objects and Youtube-Objects-Subset datasets with two contemporary baseline object detectors reveal that such unsupervised pixel level domain adaptation boosts the generalization performance on video frames compared to direct application of original image object detector. Also, we achieve competitive performance compared to recent baselines of weakly supervised methods. This paper can be seen as an application of image translation for cross domain object detection.



### Transferring Physical Motion Between Domains for Neural Inertial Tracking
- **Arxiv ID**: http://arxiv.org/abs/1810.02076v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02076v1)
- **Published**: 2018-10-04 07:12:47+00:00
- **Updated**: 2018-10-04 07:12:47+00:00
- **Authors**: Changhao Chen, Yishu Miao, Chris Xiaoxuan Lu, Phil Blunsom, Andrew Markham, Niki Trigoni
- **Comment**: NIPS 2018 workshop on Modeling the Physical World: Perception,
  Learning, and Control. A complete version will be released soon
- **Journal**: None
- **Summary**: Inertial information processing plays a pivotal role in ego-motion awareness for mobile agents, as inertial measurements are entirely egocentric and not environment dependent. However, they are affected greatly by changes in sensor placement/orientation or motion dynamics, and it is infeasible to collect labelled data from every domain. To overcome the challenges of domain adaptation on long sensory sequences, we propose a novel framework that extracts domain-invariant features of raw sequences from arbitrary domains, and transforms to new domains without any paired data. Through the experiments, we demonstrate that it is able to efficiently and effectively convert the raw sequence from a new unlabelled target domain into an accurate inertial trajectory, benefiting from the physical motion knowledge transferred from the labelled source domain. We also conduct real-world experiments to show our framework can reconstruct physically meaningful trajectories from raw IMU measurements obtained with a standard mobile phone in various attachments.



### Improving the Segmentation of Anatomical Structures in Chest Radiographs using U-Net with an ImageNet Pre-trained Encoder
- **Arxiv ID**: http://arxiv.org/abs/1810.02113v1
- **DOI**: 10.1007/978-3-030-00946-5_17
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.02113v1)
- **Published**: 2018-10-04 09:18:42+00:00
- **Updated**: 2018-10-04 09:18:42+00:00
- **Authors**: Maayan Frid-Adar, Avi Ben-Cohen, Rula Amer, Hayit Greenspan
- **Comment**: Presented at the First International Workshop on Thoracic Image
  Analysis (TIA), MICCAI 2018
- **Journal**: None
- **Summary**: Accurate segmentation of anatomical structures in chest radiographs is essential for many computer-aided diagnosis tasks. In this paper we investigate the latest fully-convolutional architectures for the task of multi-class segmentation of the lungs field, heart and clavicles in a chest radiograph. In addition, we explore the influence of using different loss functions in the training process of a neural network for semantic segmentation. We evaluate all models on a common benchmark of 247 X-ray images from the JSRT database and ground-truth segmentation masks from the SCR dataset. Our best performing architecture, is a modified U-Net that benefits from pre-trained encoder weights. This model outperformed the current state-of-the-art methods tested on the same benchmark, with Jaccard overlap scores of 96.1% for lung fields, 90.6% for heart and 85.5% for clavicles.



### Survival prediction using ensemble tumor segmentation and transfer learning
- **Arxiv ID**: http://arxiv.org/abs/1810.04274v1
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1810.04274v1)
- **Published**: 2018-10-04 09:55:09+00:00
- **Updated**: 2018-10-04 09:55:09+00:00
- **Authors**: Mariano Cabezas, Sergi Valverde, Sandra González-Villà, Albert Clérigues, Mostafa Salem, Kaisar Kushibar, Jose Bernal, Arnau Oliver, Xavier Lladó
- **Comment**: Submitted to the BRATS2018 MICCAI challenge
- **Journal**: None
- **Summary**: Segmenting tumors and their subregions is a challenging task as demonstrated by the annual BraTS challenge. Moreover, predicting the survival of the patient using mainly imaging features, while being a desirable outcome to evaluate the treatment of the patient, it is also a difficult task. In this paper, we present a cascaded pipeline to segment the tumor and its subregions and then we use these results and other clinical features together with image features coming from a pretrained VGG-16 network to predict the survival of the patient. Preliminary results with the training and validation dataset show a promising start in terms of segmentation, while the prediction values could be improved with further testing on the feature extraction part of the network.



### Learning Finer-class Networks for Universal Representations
- **Arxiv ID**: http://arxiv.org/abs/1810.02126v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1810.02126v1)
- **Published**: 2018-10-04 09:58:34+00:00
- **Updated**: 2018-10-04 09:58:34+00:00
- **Authors**: Julien Girard, Youssef Tamaazousti, Hervé Le Borgne, Céline Hudelot
- **Comment**: British Machine Vision Conference (BMVC) 2018
- **Journal**: None
- **Summary**: Many real-world visual recognition use-cases can not directly benefit from state-of-the-art CNN-based approaches because of the lack of many annotated data. The usual approach to deal with this is to transfer a representation pre-learned on a large annotated source-task onto a target-task of interest. This raises the question of how well the original representation is "universal", that is to say directly adapted to many different target-tasks. To improve such universality, the state-of-the-art consists in training networks on a diversified source problem, that is modified either by adding generic or specific categories to the initial set of categories. In this vein, we proposed a method that exploits finer-classes than the most specific ones existing, for which no annotation is available. We rely on unsupervised learning and a bottom-up split and merge strategy. We show that our method learns more universal representations than state-of-the-art, leading to significantly better results on 10 target-tasks from multiple domains, using several network architectures, either alone or combined with networks learned at a coarser semantic level.



### Learning Depth with Convolutional Spatial Propagation Network
- **Arxiv ID**: http://arxiv.org/abs/1810.02695v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02695v3)
- **Published**: 2018-10-04 13:32:29+00:00
- **Updated**: 2019-10-04 03:29:01+00:00
- **Authors**: Xinjing Cheng, Peng Wang, Ruigang Yang
- **Comment**: v1.2: add some exps v1.1: fixed some mistakes, v1: 17 pages, 12
  figures. arXiv admin note: substantial text overlap with arXiv:1808.00150
- **Journal**: None
- **Summary**: Depth prediction is one of the fundamental problems in computer vision. In this paper, we propose a simple yet effective convolutional spatial propagation network (CSPN) to learn the affinity matrix for various depth estimation tasks. Specifically, it is an efficient linear propagation model, in which the propagation is performed with a manner of recurrent convolutional operation, and the affinity among neighboring pixels is learned through a deep convolutional neural network (CNN). We can append this module to any output from a state-of-the-art (SOTA) depth estimation networks to improve their performances. In practice, we further extend CSPN in two aspects: 1) take sparse depth map as additional input, which is useful for the task of depth completion; 2) similar to commonly used 3D convolution operation in CNNs, we propose 3D CSPN to handle features with one additional dimension, which is effective in the task of stereo matching using 3D cost volume. For the tasks of sparse to dense, a.k.a depth completion. We experimented the proposed CPSN conjunct algorithms over the popular NYU v2 and KITTI datasets, where we show that our proposed algorithms not only produce high quality (e.g., 30% more reduction in depth error), but also run faster (e.g., 2 to 5x faster) than previous SOTA spatial propagation network. We also evaluated our stereo matching algorithm on the Scene Flow and KITTI Stereo datasets, and rank 1st on both the KITTI Stereo 2012 and 2015 benchmarks, which demonstrates the effectiveness of the proposed module. The code of CSPN proposed in this work will be released at https://github.com/XinJCheng/CSPN.



### Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1810.02244v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02244v5)
- **Published**: 2018-10-04 14:31:57+00:00
- **Updated**: 2021-11-30 15:37:55+00:00
- **Authors**: Christopher Morris, Martin Ritzert, Matthias Fey, William L. Hamilton, Jan Eric Lenssen, Gaurav Rattan, Martin Grohe
- **Comment**: Extended version with proofs, accepted at AAAI 2019, added units of
  measurement of QM9 dataset into appendix, removed results from Wu et al.,
  2018 due to different units
- **Journal**: None
- **Summary**: In recent years, graph neural networks (GNNs) have emerged as a powerful neural architecture to learn vector representations of nodes and graphs in a supervised, end-to-end fashion. Up to now, GNNs have only been evaluated empirically -- showing promising results. The following work investigates GNNs from a theoretical point of view and relates them to the $1$-dimensional Weisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have the same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic (sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on this, we propose a generalization of GNNs, so-called $k$-dimensional GNNs ($k$-GNNs), which can take higher-order graph structures at multiple scales into account. These higher-order structures play an essential role in the characterization of social networks and molecule graphs. Our experimental evaluation confirms our theoretical findings as well as confirms that higher-order information is useful in the task of graph classification and regression.



### Episodic Curiosity through Reachability
- **Arxiv ID**: http://arxiv.org/abs/1810.02274v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02274v5)
- **Published**: 2018-10-04 15:24:06+00:00
- **Updated**: 2019-08-06 17:54:03+00:00
- **Authors**: Nikolay Savinov, Anton Raichuk, Raphaël Marinier, Damien Vincent, Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly
- **Comment**: Accepted to ICLR 2019. Code at
  https://github.com/google-research/episodic-curiosity/. Videos at
  https://sites.google.com/view/episodic-curiosity/
- **Journal**: None
- **Summary**: Rewards are sparse in the real world and most of today's reinforcement learning algorithms struggle with such sparsity. One solution to this problem is to allow the agent to create rewards for itself - thus making rewards dense and more suitable for learning. In particular, inspired by curious behaviour in animals, observing something novel could be rewarded with a bonus. Such bonus is summed up with the real task reward - making it possible for RL algorithms to learn from the combined reward. We propose a new curiosity method which uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observation from those in memory - which incorporates rich information about environment dynamics. This allows us to overcome the known "couch-potato" issues of prior work - when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. We test our approach in visually rich 3D environments in ViZDoom, DMLab and MuJoCo. In navigational tasks from ViZDoom and DMLab, our agent outperforms the state-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our curiosity module learns locomotion out of the first-person-view curiosity only.



### Direct Prediction of Cardiovascular Mortality from Low-dose Chest CT using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1810.02277v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02277v1)
- **Published**: 2018-10-04 15:33:14+00:00
- **Updated**: 2018-10-04 15:33:14+00:00
- **Authors**: Sanne G. M. van Velzen, Majd Zreik, Nikolas Lessmann, Max A. Viergever, Pim A. de Jong, Helena M. Verkooijen, Ivana Išgum
- **Comment**: This work has been submitted to SPIE 2019 conference
- **Journal**: None
- **Summary**: Cardiovascular disease (CVD) is a leading cause of death in the lung cancer screening population. Chest CT scans made in lung cancer screening are suitable for identification of participants at risk of CVD. Existing methods analyzing CT images from lung cancer screening for prediction of CVD events or mortality use engineered features extracted from the images combined with patient information. In this work we propose a method that automatically predicts 5-year cardiovascular mortality directly from chest CT scans without the need for hand-crafting image features. A set of 1,583 participants of the National Lung Screening Trial was included (1,188 survivors, 395 non-survivors). Low-dose chest CT images acquired at baseline were analyzed and the follow-up time was 5 years. To limit the analysis to the heart region, the heart was first localized by our previously developed algorithm for organ localization exploiting convolutional neural networks. Thereafter, a convolutional autoencoder was used to encode the identified heart region. Finally, based on the extracted encodings subjects were classified into survivors or non-survivors using a support vector machine classifier. The performance of the method was assessed in eight cross-validation experiments with 1,433 images used for training, 50 for validation and 100 for testing. The method achieved a performance with an area under the ROC curve of 0.72. The results demonstrate that prediction of cardiovascular mortality directly from low-dose screening chest CT scans, without hand-crafted features, is feasible, allowing identification of subjects at risk of fatal CVD events.



### Progressive Feature Fusion Network for Realistic Image Dehazing
- **Arxiv ID**: http://arxiv.org/abs/1810.02283v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02283v1)
- **Published**: 2018-10-04 15:56:22+00:00
- **Updated**: 2018-10-04 15:56:22+00:00
- **Authors**: Kangfu Mei, Aiwen Jiang, Juncheng Li, Mingwen Wang
- **Comment**: 14 pages, 7 figures, 1 tables, accepted by ACCV2018
- **Journal**: None
- **Summary**: Single image dehazing is a challenging ill-posed restoration problem. Various prior-based and learning-based methods have been proposed. Most of them follow a classic atmospheric scattering model which is an elegant simplified physical model based on the assumption of single-scattering and homogeneous atmospheric medium. The formulation of haze in realistic environment is more complicated. In this paper, we propose to take its essential mechanism as "black box", and focus on learning an input-adaptive trainable end-to-end dehazing model. An U-Net like encoder-decoder deep network via progressive feature fusions has been proposed to directly learn highly nonlinear transformation function from observed hazy image to haze-free ground-truth. The proposed network is evaluated on two public image dehazing benchmarks. The experiments demonstrate that it can achieve superior performance when compared with popular state-of-the-art methods. With efficient GPU memory usage, it can satisfactorily recover ultra high definition hazed image up to 4K resolution, which is unaffordable by many deep learning based dehazing algorithms.



### Computer vision-based framework for extracting geological lineaments from optical remote sensing data
- **Arxiv ID**: http://arxiv.org/abs/1810.02320v1
- **DOI**: 10.1080/01431161.2019.1674462
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1810.02320v1)
- **Published**: 2018-10-04 17:09:04+00:00
- **Updated**: 2018-10-04 17:09:04+00:00
- **Authors**: Ehsan Farahbakhsh, Rohitash Chandra, Hugo K. H. Olierook, Richard Scalzo, Chris Clark, Steven M. Reddy, R. Dietmar Muller
- **Comment**: 17 pages, 10 figures, 2 tables
- **Journal**: None
- **Summary**: The extraction of geological lineaments from digital satellite data is a fundamental application in remote sensing. The location of geological lineaments such as faults and dykes are of interest for a range of applications, particularly because of their association with hydrothermal mineralization. Although a wide range of applications have utilized computer vision techniques, a standard workflow for application of these techniques to mineral exploration is lacking. We present a framework for extracting geological lineaments using computer vision techniques which is a combination of edge detection and line extraction algorithms for extracting geological lineaments using optical remote sensing data. It features ancillary computer vision techniques for reducing data dimensionality, removing noise and enhancing the expression of lineaments. We test the proposed framework on Landsat 8 data of a mineral-rich portion of the Gascoyne Province in Western Australia using different dimension reduction techniques and convolutional filters. To validate the results, the extracted lineaments are compared to our manual photointerpretation and geologically mapped structures by the Geological Survey of Western Australia (GSWA). The results show that the best correlation between our extracted geological lineaments and the GSWA geological lineament map is achieved by applying a minimum noise fraction transformation and a Laplacian filter. Application of a directional filter instead shows a stronger correlation with the output of our manual photointerpretation and known sites of hydrothermal mineralization. Hence, our framework using either filter can be used for mineral prospectivity mapping in other regions where faults are exposed and observable in optical remote sensing data.



### Unsupervised Learning via Meta-Learning
- **Arxiv ID**: http://arxiv.org/abs/1810.02334v6
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02334v6)
- **Published**: 2018-10-04 17:29:17+00:00
- **Updated**: 2019-03-21 23:43:47+00:00
- **Authors**: Kyle Hsu, Sergey Levine, Chelsea Finn
- **Comment**: ICLR 2019 camera-ready. 24 pages, 2 figures, links to code available
  at https://sites.google.com/view/unsupervised-via-meta
- **Journal**: None
- **Summary**: A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods.



### Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding
- **Arxiv ID**: http://arxiv.org/abs/1810.02338v2
- **DOI**: None
- **Categories**: **cs.AI**, cs.CL, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.02338v2)
- **Published**: 2018-10-04 17:38:50+00:00
- **Updated**: 2019-01-14 23:07:12+00:00
- **Authors**: Kexin Yi, Jiajun Wu, Chuang Gan, Antonio Torralba, Pushmeet Kohli, Joshua B. Tenenbaum
- **Comment**: NeurIPS 2018 (spotlight). The first two authors contributed equally
  to this work. Project page: http://nsvqa.csail.mit.edu
- **Journal**: None
- **Summary**: We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the question. It then executes the program on the scene representation to obtain an answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model is more data- and memory-efficient: it performs well after learning on a small number of training data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step.



### SNIP: Single-shot Network Pruning based on Connection Sensitivity
- **Arxiv ID**: http://arxiv.org/abs/1810.02340v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.02340v2)
- **Published**: 2018-10-04 17:39:58+00:00
- **Updated**: 2019-02-23 07:45:29+00:00
- **Authors**: Namhoon Lee, Thalaiyasingam Ajanthan, Philip H. S. Torr
- **Comment**: ICLR 2019
- **Journal**: None
- **Summary**: Pruning large neural networks while maintaining their performance is often desirable due to the reduced space and time complexity. In existing methods, pruning is done within an iterative optimization procedure with either heuristically designed pruning schedules or additional hyperparameters, undermining their utility. In this work, we present a new approach that prunes a given network once at initialization prior to training. To achieve this, we introduce a saliency criterion based on connection sensitivity that identifies structurally important connections in the network for the given task. This eliminates the need for both pretraining and the complex pruning schedule while making it robust to architecture variations. After pruning, the sparse network is trained in the standard way. Our method obtains extremely sparse networks with virtually the same accuracy as the reference network on the MNIST, CIFAR-10, and Tiny-ImageNet classification tasks and is broadly applicable to various architectures including convolutional, residual and recurrent networks. Unlike existing methods, our approach enables us to demonstrate that the retained connections are indeed relevant to the given task.



### Multi-view X-ray R-CNN
- **Arxiv ID**: http://arxiv.org/abs/1810.02344v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02344v1)
- **Published**: 2018-10-04 17:48:54+00:00
- **Updated**: 2018-10-04 17:48:54+00:00
- **Authors**: Jan-Martin O. Steitz, Faraz Saeedan, Stefan Roth
- **Comment**: To appear at the 40th German Conference on Pattern Recognition (GCPR)
  2018
- **Journal**: None
- **Summary**: Motivated by the detection of prohibited objects in carry-on luggage as a part of avionic security screening, we develop a CNN-based object detection approach for multi-view X-ray image data. Our contributions are two-fold. First, we introduce a novel multi-view pooling layer to perform a 3D aggregation of 2D CNN-features extracted from each view. To that end, our pooling layer exploits the known geometry of the imaging system to ensure geometric consistency of the feature aggregation. Second, we introduce an end-to-end trainable multi-view detection pipeline based on Faster R-CNN, which derives the region proposals and performs the final classification in 3D using these aggregated multi-view features. Our approach shows significant accuracy gains compared to single-view detection while even being more efficient than performing single-view detection in each view.



### A method to Suppress Facial Expression in Posed and Spontaneous Videos
- **Arxiv ID**: http://arxiv.org/abs/1810.02401v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02401v1)
- **Published**: 2018-10-04 19:44:08+00:00
- **Updated**: 2018-10-04 19:44:08+00:00
- **Authors**: Ghada Zamzmi, Gabriel Ruiz, Matthew Shreve, Dmitry Goldgof, Rangachar Kasturi, Sudeep Sarkar
- **Comment**: None
- **Journal**: None
- **Summary**: We address the problem of suppressing facial expressions in videos because expressions can hinder the retrieval of important information in applications such as face recognition. To achieve this, we present an optical strain suppression method that removes any facial expression without requiring training for a specific expression. For each frame in a video, an optical strain map that provides the strain magnitude value at each pixel is generated; this strain map is then utilized to neutralize the expression by replacing pixels of high strain values with pixels from a reference face frame. Experimental results of testing the method on various expressions namely happiness, sadness, and anger for two publicly available data sets (i.e., BU-4DFE and AM-FED) show the ability of our method in suppressing facial expressions.



### Towards High Resolution Video Generation with Progressive Growing of Sliced Wasserstein GANs
- **Arxiv ID**: http://arxiv.org/abs/1810.02419v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.02419v2)
- **Published**: 2018-10-04 20:41:48+00:00
- **Updated**: 2018-12-06 15:57:41+00:00
- **Authors**: Dinesh Acharya, Zhiwu Huang, Danda Pani Paudel, Luc Van Gool
- **Comment**: Master Thesis from ETH Zurich, May 22, 2018
- **Journal**: None
- **Summary**: The extension of image generation to video generation turns out to be a very difficult task, since the temporal dimension of videos introduces an extra challenge during the generation process. Besides, due to the limitation of memory and training stability, the generation becomes increasingly challenging with the increase of the resolution/duration of videos. In this work, we exploit the idea of progressive growing of Generative Adversarial Networks (GANs) for higher resolution video generation. In particular, we begin to produce video samples of low-resolution and short-duration, and then progressively increase both resolution and duration alone (or jointly) by adding new spatiotemporal convolutional layers to the current networks. Starting from the learning on a very raw-level spatial appearance and temporal movement of the video distribution, the proposed progressive method learns spatiotemporal information incrementally to generate higher resolution videos. Furthermore, we introduce a sliced version of Wasserstein GAN (SWGAN) loss to improve the distribution learning on the video data of high-dimension and mixed-spatiotemporal distribution. SWGAN loss replaces the distance between joint distributions by that of one-dimensional marginal distributions, making the loss easier to compute. We evaluate the proposed model on our collected face video dataset of 10,900 videos to generate photorealistic face videos of 256x256x32 resolution. In addition, our model also reaches a record inception score of 14.57 in unsupervised action recognition dataset UCF-101.



### FashionNet: Personalized Outfit Recommendation with Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1810.02443v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.02443v1)
- **Published**: 2018-10-04 22:26:24+00:00
- **Updated**: 2018-10-04 22:26:24+00:00
- **Authors**: Tong He, Yang Hu
- **Comment**: None
- **Journal**: None
- **Summary**: With the rapid growth of fashion-focused social networks and online shopping, intelligent fashion recommendation is now in great need. We design algorithms which automatically suggest users outfits (e.g. a shirt, together with a skirt and a pair of high-heel shoes), that fit their personal fashion preferences. Recommending sets, each of which is composed of multiple interacted items, is relatively new to recommender systems, which usually recommend individual items to users. We explore the use of deep networks for this challenging task. Our system, dubbed FashionNet, consists of two components, a feature network for feature extraction and a matching network for compatibility computation. The former is achieved through a deep convolutional network. And for the latter, we adopt a multi-layer fully-connected network structure. We design and compare three alternative architectures for FashionNet. To achieve personalized recommendation, we develop a two-stage training strategy, which uses the fine-tuning technique to transfer a general compatibility model to a model that embeds personal preference. Experiments on a large scale data set collected from a popular fashion-focused social network validate the effectiveness of the proposed networks.



