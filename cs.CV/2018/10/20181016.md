# Arxiv Papers in cs.CV on 2018-10-16
### DN-ResNet: Efficient Deep Residual Network for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1810.06766v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.06766v1)
- **Published**: 2018-10-16 00:33:09+00:00
- **Updated**: 2018-10-16 00:33:09+00:00
- **Authors**: Haoyu Ren, Mostafa El-Khamy, Jungwon Lee
- **Comment**: None
- **Journal**: Asian Conference of Computer Vision 2018
- **Summary**: A deep learning approach to blind denoising of images without complete knowledge of the noise statistics is considered. We propose DN-ResNet, which is a deep convolutional neural network (CNN) consisting of several residual blocks (ResBlocks). With cascade training, DN-ResNet is more accurate and more computationally efficient than the state of art denoising networks. An edge-aware loss function is further utilized in training DN-ResNet, so that the denoising results have better perceptive quality compared to conventional loss function. Next, we introduce the depthwise separable DN-ResNet (DS-DN-ResNet) utilizing the proposed Depthwise Seperable ResBlock (DS-ResBlock) instead of standard ResBlock, which has much less computational cost. DS-DN-ResNet is incrementally evolved by replacing the ResBlocks in DN-ResNet by DS-ResBlocks stage by stage. As a result, high accuracy and good computational efficiency are achieved concurrently. Whereas previous state of art deep learning methods focused on denoising either Gaussian or Poisson corrupted images, we consider denoising images having the more practical Poisson with additive Gaussian noise as well. The results show that DN-ResNets are more efficient, robust, and perform better denoising than current state of art deep learning methods, as well as the popular variants of the BM3D algorithm, in cases of blind and non-blind denoising of images corrupted with Poisson, Gaussian or Poisson-Gaussian noise. Our network also works well for other image enhancement task such as compressed image restoration.



### Approximate Fisher Information Matrix to Characterise the Training of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1810.06767v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.06767v1)
- **Published**: 2018-10-16 00:37:03+00:00
- **Updated**: 2018-10-16 00:37:03+00:00
- **Authors**: Zhibin Liao, Tom Drummond, Ian Reid, Gustavo Carneiro
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a novel methodology for characterising the performance of deep learning networks (ResNets and DenseNet) with respect to training convergence and generalisation as a function of mini-batch size and learning rate for image classification. This methodology is based on novel measurements derived from the eigenvalues of the approximate Fisher information matrix, which can be efficiently computed even for high capacity deep models. Our proposed measurements can help practitioners to monitor and control the training process (by actively tuning the mini-batch size and learning rate) to allow for good training convergence and generalisation. Furthermore, the proposed measurements also allow us to show that it is possible to optimise the training process with a new dynamic sampling training approach that continuously and automatically change the mini-batch size and learning rate during the training process. Finally, we show that the proposed dynamic sampling training approach has a faster training time and a competitive classification accuracy compared to the current state of the art.



### A Robust Local Binary Similarity Pattern for Foreground Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1810.06797v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06797v2)
- **Published**: 2018-10-16 03:30:15+00:00
- **Updated**: 2018-10-18 09:50:40+00:00
- **Authors**: Dongdong Zeng, Ming Zhu, Hang Yang
- **Comment**: 2 pages
- **Journal**: None
- **Summary**: Accurate and fast extraction of the foreground object is one of the most significant issues to be solved due to its important meaning for object tracking and recognition in video surveillance. Although many foreground object detection methods have been proposed in the recent past, it is still regarded as a tough problem due to illumination variations and dynamic backgrounds challenges. In this paper, we propose a robust foreground object detection method with two aspects of contributions. First, we propose a robust texture operator named Robust Local Binary Similarity Pattern (RLBSP), which shows strong robustness to illumination variations and dynamic backgrounds. Second, a combination of color and texture features are used to characterize pixel representations, which compensate each other to make full use of their own advantages. Comprehensive experiments evaluated on the CDnet 2012 dataset demonstrate that the proposed method performs favorably against state-of-the-art methods.



### Combined Static and Motion Features for Deep-Networks Based Activity Recognition in Videos
- **Arxiv ID**: http://arxiv.org/abs/1810.06827v1
- **DOI**: 10.1109/TCSVT.2017.2760858
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06827v1)
- **Published**: 2018-10-16 06:04:35+00:00
- **Updated**: 2018-10-16 06:04:35+00:00
- **Authors**: Sameera Ramasinghe, Jathushan Rajasegaran, Vinoj Jayasundara, Kanchana Ranasinghe, Ranga Rodrigo, Ajith A. Pasqual
- **Comment**: None
- **Journal**: IEEE Transactions on Circuits and Systems for Video Technology
  (2017)
- **Summary**: Activity recognition in videos in a deep-learning setting---or otherwise---uses both static and pre-computed motion components. The method of combining the two components, whilst keeping the burden on the deep network less, still remains uninvestigated. Moreover, it is not clear what the level of contribution of individual components is, and how to control the contribution. In this work, we use a combination of CNN-generated static features and motion features in the form of motion tubes. We propose three schemas for combining static and motion components: based on a variance ratio, principal components, and Cholesky decomposition. The Cholesky decomposition based method allows the control of contributions. The ratio given by variance analysis of static and motion features match well with the experimental optimal ratio used in the Cholesky decomposition based method. The resulting activity recognition system is better or on par with existing state-of-the-art when tested with three popular datasets. The findings also enable us to characterize a dataset with respect to its richness in motion information.



### Semantic Aware Attention Based Deep Object Co-segmentation
- **Arxiv ID**: http://arxiv.org/abs/1810.06859v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06859v1)
- **Published**: 2018-10-16 07:57:04+00:00
- **Updated**: 2018-10-16 07:57:04+00:00
- **Authors**: Hong Chen, Yifei Huang, Hideki Nakayama
- **Comment**: None
- **Journal**: None
- **Summary**: Object co-segmentation is the task of segmenting the same objects from multiple images. In this paper, we propose the Attention Based Object Co-Segmentation for object co-segmentation that utilize a novel attention mechanism in the bottleneck layer of deep neural network for the selection of semantically related features. Furthermore, we take the benefit of attention learner and propose an algorithm to segment multi-input images in linear time complexity. Experiment results demonstrate that our model achieves state of the art performance on multiple datasets, with a significant reduction of computational time.



### Collaborative Deep Learning Across Multiple Data Centers
- **Arxiv ID**: http://arxiv.org/abs/1810.06877v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.06877v1)
- **Published**: 2018-10-16 08:33:33+00:00
- **Updated**: 2018-10-16 08:33:33+00:00
- **Authors**: Kele Xu, Haibo Mi, Dawei Feng, Huaimin Wang, Chuan Chen, Zibin Zheng, Xu Lan
- **Comment**: Submitted to AAAI 2019
- **Journal**: None
- **Summary**: Valuable training data is often owned by independent organizations and located in multiple data centers. Most deep learning approaches require to centralize the multi-datacenter data for performance purpose. In practice, however, it is often infeasible to transfer all data to a centralized data center due to not only bandwidth limitation but also the constraints of privacy regulations. Model averaging is a conventional choice for data parallelized training, but its ineffectiveness is claimed by previous studies as deep neural networks are often non-convex. In this paper, we argue that model averaging can be effective in the decentralized environment by using two strategies, namely, the cyclical learning rate and the increased number of epochs for local model training. With the two strategies, we show that model averaging can provide competitive performance in the decentralized mode compared to the data-centralized one. In a practical environment with multiple data centers, we conduct extensive experiments using state-of-the-art deep network architectures on different types of data. Results demonstrate the effectiveness and robustness of the proposed method.



### Rotational 3D Texture Classification Using Group Equivariant CNNs
- **Arxiv ID**: http://arxiv.org/abs/1810.06889v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06889v1)
- **Published**: 2018-10-16 09:22:36+00:00
- **Updated**: 2018-10-16 09:22:36+00:00
- **Authors**: Vincent Andrearczyk, Adrien Depeursinge
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) traditionally encode translation equivariance via the convolution operation. Generalization to other transformations has recently received attraction to encode the knowledge of the data geometry in group convolution operations. Equivariance to rotation is particularly important for 3D image analysis due to the large diversity of possible pattern orientations. 3D texture is a particularly important cue for the analysis of medical images such as CT and MRI scans as it describes different types of tissues and lesions. In this paper, we evaluate the use of 3D group equivariant CNNs accounting for the simplified group of right-angle rotations to classify 3D synthetic textures from a publicly available dataset. The results validate the importance of rotation equivariance in a controlled setup and yet motivate the use of a finer coverage of orientations in order to obtain equivariance to realistic rotations present in 3D textures.



### A Generative Model of Textures Using Hierarchical Probabilistic Principal Component Analysis
- **Arxiv ID**: http://arxiv.org/abs/1810.06892v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.06892v1)
- **Published**: 2018-10-16 09:24:19+00:00
- **Updated**: 2018-10-16 09:24:19+00:00
- **Authors**: Aiga Suzuki, Hayaru Shouno
- **Comment**: 6 pages, 9 figures; A proceeding of PDPTA'17 accepted as an oral
  presentation
- **Journal**: Proc. of the 2017 Intl. Conference on Parallel and Distributed
  Processing Techniques and Applications (PDPTA'17), CSREA Press, pp.333-338,
  (2017)
- **Summary**: Modeling of textures in natural images is an important task to make a microscopic model of natural images. Portilla and Simoncelli proposed a generative texture model, which is based on the mechanism of visual systems in brains, with a set of texture features and a feature matching. On the other hand, the texture features, used in Portillas' model, have redundancy between its components came from typical natural textures. In this paper, we propose a contracted texture model which provides a dimension reduction for the Portillas' feature. This model is based on a hierarchical principal components analysis using known group structure of the feature. In the experiment, we reveal effective dimensions to describe texture is fewer than the original description. Moreover, we also demonstrate how well the textures can be synthesized from the contracted texture representations.



### CNN-based Preprocessing to Optimize Watershed-based Cell Segmentation in 3D Confocal Microscopy Images
- **Arxiv ID**: http://arxiv.org/abs/1810.06933v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.06933v1)
- **Published**: 2018-10-16 11:30:54+00:00
- **Updated**: 2018-10-16 11:30:54+00:00
- **Authors**: Dennis Eschweiler, Thiago V. Spina, Rohan C. Choudhury, Elliot Meyerowitz, Alexandre Cunha, Johannes Stegmaier
- **Comment**: 5 pages, 4 figures, 1 table
- **Journal**: None
- **Summary**: The quantitative analysis of cellular membranes helps understanding developmental processes at the cellular level. Particularly 3D microscopic image data offers valuable insights into cell dynamics, but error-free automatic segmentation remains challenging due to the huge amount of data generated and strong variations in image intensities. In this paper, we propose a new 3D segmentation approach which combines the discriminative power of convolutional neural networks (CNNs) for preprocessing and investigates the performance of three watershed-based postprocessing strategies (WS), which are well suited to segment object shapes, even when supplied with vague seed and boundary constraints. To leverage the full potential of the watershed algorithm, the multi-instance segmentation problem is initially interpreted as three-class semantic segmentation problem, which in turn is well-suited for the application of CNNs. Using manually annotated 3D confocal microscopy images of Arabidopsis thaliana, we show the superior performance of the proposed method compared to the state of the art.



### Channel Attention and Multi-level Features Fusion for Single Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1810.06935v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06935v1)
- **Published**: 2018-10-16 11:33:09+00:00
- **Updated**: 2018-10-16 11:33:09+00:00
- **Authors**: Yue Lu, Yun Zhou, Zhuqing Jiang, Xiaoqiang Guo, Zixuan Yang
- **Comment**: 4 pages, 3 figures, Accepted as an oral presentation at VCIP
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have demonstrated superior performance in super-resolution (SR). However, most CNN-based SR methods neglect the different importance among feature channels or fail to take full advantage of the hierarchical features. To address these issues, this paper presents a novel recursive unit. Firstly, at the beginning of each unit, we adopt a compact channel attention mechanism to adaptively recalibrate the channel importance of input features. Then, the multi-level features, rather than only deep-level features, are extracted and fused. Additionally, we find that it will force our model to learn more details by using the learnable upsampling method (i.e., transposed convolution) only on residual branch (instead of using it both on residual branch and identity branch) while using the bicubic interpolation on the other branch. Analytic experiments show that our method achieves competitive results compared with the state-of-the-art methods and maintains faster speed as well.



### Hyper-Process Model: A Zero-Shot Learning algorithm for Regression Problems based on Shape Analysis
- **Arxiv ID**: http://arxiv.org/abs/1810.10330v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML, 68T99, I.2.6; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/1810.10330v1)
- **Published**: 2018-10-16 11:35:16+00:00
- **Updated**: 2018-10-16 11:35:16+00:00
- **Authors**: Joao Reis, Gil Gonçalves
- **Comment**: 36 pages, 4 figures, 2 tables, submitted to JMLR
- **Journal**: None
- **Summary**: Zero-shot learning (ZSL) can be defined by correctly solving a task where no training data is available, based on previous acquired knowledge from different, but related tasks. So far, this area has mostly drawn the attention from computer vision community where a new unseen image needs to be correctly classified, assuming the target class was not used in the training procedure. Apart from image classification, only a couple of generic methods were proposed that are applicable to both classification and regression. These learn the relation among model coefficients so new ones can be predicted according to provided conditions. So far, up to our knowledge, no methods exist that are applicable only to regression, and take advantage from such setting. Therefore, the present work proposes a novel algorithm for regression problems that uses data drawn from trained models, instead of model coefficients. In this case, a shape analyses on the data is performed to create a statistical shape model and generate new shapes to train new models. The proposed algorithm is tested in a theoretical setting using the beta distribution where main problem to solve is to estimate a function that predicts curves, based on already learned different, but related ones.



### UnrealROX: An eXtremely Photorealistic Virtual Reality Environment for Robotics Simulations and Synthetic Data Generation
- **Arxiv ID**: http://arxiv.org/abs/1810.06936v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1810.06936v2)
- **Published**: 2018-10-16 11:43:50+00:00
- **Updated**: 2019-11-08 17:58:02+00:00
- **Authors**: Pablo Martinez-Gonzalez, Sergiu Oprea, Alberto Garcia-Garcia, Alvaro Jover-Alvarez, Sergio Orts-Escolano, Jose Garcia-Rodriguez
- **Comment**: Published in Virtual Reality journal
- **Journal**: None
- **Summary**: Data-driven algorithms have surpassed traditional techniques in almost every aspect in robotic vision problems. Such algorithms need vast amounts of quality data to be able to work properly after their training process. Gathering and annotating that sheer amount of data in the real world is a time-consuming and error-prone task. Those problems limit scale and quality. Synthetic data generation has become increasingly popular since it is faster to generate and automatic to annotate. However, most of the current datasets and environments lack realism, interactions, and details from the real world. UnrealROX is an environment built over Unreal Engine 4 which aims to reduce that reality gap by leveraging hyperrealistic indoor scenes that are explored by robot agents which also interact with objects in a visually realistic manner in that simulated world. Photorealistic scenes and robots are rendered by Unreal Engine into a virtual reality headset which captures gaze so that a human operator can move the robot and use controllers for the robotic hands; scene information is dumped on a per-frame basis so that it can be reproduced offline to generate raw data and ground truth annotations. This virtual reality environment enables robotic vision researchers to generate realistic and visually plausible data with full ground truth for a wide variety of problems such as class and instance semantic segmentation, object detection, depth estimation, visual grasping, and navigation.



### Deep Metric Learning with Hierarchical Triplet Loss
- **Arxiv ID**: http://arxiv.org/abs/1810.06951v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06951v1)
- **Published**: 2018-10-16 12:23:32+00:00
- **Updated**: 2018-10-16 12:23:32+00:00
- **Authors**: Weifeng Ge, Weilin Huang, Dengke Dong, Matthew R. Scott
- **Comment**: Published in ECCV 2018
- **Journal**: None
- **Summary**: We present a novel hierarchical triplet loss (HTL) capable of automatically collecting informative training samples (triplets) via a defined hierarchical tree that encodes global context information. This allows us to cope with the main limitation of random sampling in training a conventional triplet loss, which is a central issue for deep metric learning. Our main contributions are two-fold. (i) we construct a hierarchical class-level tree where neighboring classes are merged recursively. The hierarchical structure naturally captures the intrinsic data distribution over the whole database. (ii) we formulate the problem of triplet collection by introducing a new violate margin, which is computed dynamically based on the designed hierarchical tree. This allows it to automatically select meaningful hard samples with the guide of global context. It encourages the model to learn more discriminative features from visual similar classes, leading to faster convergence and better performance. Our method is evaluated on the tasks of image retrieval and face recognition, where it outperforms the standard triplet loss substantially by 1%-18%. It achieves new state-of-the-art performance on a number of benchmarks, with much fewer learning iterations.



### Bottleneck Supervised U-Net for Pixel-wise Liver and Tumor Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1810.10331v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1810.10331v2)
- **Published**: 2018-10-16 13:02:57+00:00
- **Updated**: 2019-03-13 01:38:44+00:00
- **Authors**: Song Li, Geoffrey Kwok Fai Tso
- **Comment**: 21 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: In this paper, we propose a bottleneck supervised (BS) U-Net model for liver and tumor segmentation. Our main contributions are: first, we propose a variation of the original U-Net that incorporates dense modules, inception modules and dilated convolution in the encoding path; second, we propose a bottleneck supervised (BS) U-Net that contains an encoding U-Net and a segmentation U-Net. To train the BS U-Net, the encoding U-Net is first trained to get encodings of the label maps that contain the anatomical information (shape and location). Subsequently, this information is used to guide the training of the segmentation U-Net so as to reserve the anatomical features of the target objects. More specifically, the loss function for segmentation U-Net is set to be the weighted average of the dice loss and the MSE loss between the encodings and the bottleneck feature vectors. The model is applied to a public liver and tumor CT scan dataset. Experimental results show that besides achieving excellent overall segmentation performance, BS U-Net also works great in controlling shape distortion, reducing false positive and false negative cases.



### LRW-1000: A Naturally-Distributed Large-Scale Benchmark for Lip Reading in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1810.06990v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06990v6)
- **Published**: 2018-10-16 13:39:08+00:00
- **Updated**: 2019-04-24 00:40:56+00:00
- **Authors**: Shuang Yang, Yuanhang Zhang, Dalu Feng, Mingmin Yang, Chenhao Wang, Jingyun Xiao, Keyu Long, Shiguang Shan, Xilin Chen
- **Comment**: IEEE FG 2019
- **Journal**: None
- **Summary**: Large-scale datasets have successively proven their fundamental importance in several research fields, especially for early progress in some emerging topics. In this paper, we focus on the problem of visual speech recognition, also known as lipreading, which has received increasing interest in recent years. We present a naturally-distributed large-scale benchmark for lip reading in the wild, named LRW-1000, which contains 1,000 classes with 718,018 samples from more than 2,000 individual speakers. Each class corresponds to the syllables of a Mandarin word composed of one or several Chinese characters. To the best of our knowledge, it is currently the largest word-level lipreading dataset and also the only public large-scale Mandarin lipreading dataset. This dataset aims at covering a "natural" variability over different speech modes and imaging conditions to incorporate challenges encountered in practical applications. It has shown a large variation in this benchmark in several aspects, including the number of samples in each class, video resolution, lighting conditions, and speakers' attributes such as pose, age, gender, and make-up. Besides providing a detailed description of the dataset and its collection pipeline, we evaluate several typical popular lipreading methods and perform a thorough analysis of the results from several aspects. The results demonstrate the consistency and challenges of our dataset, which may open up some new promising directions for future work.



### SCPNet: Spatial-Channel Parallelism Network for Joint Holistic and Partial Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1810.06996v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.06996v1)
- **Published**: 2018-10-16 13:52:08+00:00
- **Updated**: 2018-10-16 13:52:08+00:00
- **Authors**: Xing Fan, Hao Luo, Xuan Zhang, Lingxiao He, Chi Zhang, Wei Jiang
- **Comment**: accepted by ACCV 2018
- **Journal**: None
- **Summary**: Holistic person re-identification (ReID) has received extensive study in the past few years and achieves impressive progress. However, persons are often occluded by obstacles or other persons in practical scenarios, which makes partial person re-identification non-trivial. In this paper, we propose a spatial-channel parallelism network (SCPNet) in which each channel in the ReID feature pays attention to a given spatial part of the body. The spatial-channel corresponding relationship supervises the network to learn discriminative feature for both holistic and partial person re-identification. The single model trained on four holistic ReID datasets achieves competitive accuracy on these four datasets, as well as outperforms the state-of-the-art methods on two partial ReID datasets without training.



### Dense Multi-path U-Net for Ischemic Stroke Lesion Segmentation in Multiple Image Modalities
- **Arxiv ID**: http://arxiv.org/abs/1810.07003v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07003v1)
- **Published**: 2018-10-16 13:59:11+00:00
- **Updated**: 2018-10-16 13:59:11+00:00
- **Authors**: Jose Dolz, Ismail Ben Ayed, Christian Desrosiers
- **Comment**: Submitted to the MICCAI BrainLes proceedings
- **Journal**: None
- **Summary**: Delineating infarcted tissue in ischemic stroke lesions is crucial to determine the extend of damage and optimal treatment for this life-threatening condition. However, this problem remains challenging due to high variability of ischemic strokes' location and shape. Recently, fully-convolutional neural networks (CNN), in particular those based on U-Net, have led to improved performances for this task. In this work, we propose a novel architecture that improves standard U-Net based methods in three important ways. First, instead of combining the available image modalities at the input, each of them is processed in a different path to better exploit their unique information. Moreover, the network is densely-connected (i.e., each layer is connected to all following layers), both within each path and across different paths, similar to HyperDenseNet. This gives our model the freedom to learn the scale at which modalities should be processed and combined. Finally, inspired by the Inception architecture, we improve standard U-Net modules by extending inception modules with two convolutional blocks with dilated convolutions of different scale. This helps handling the variability in lesion sizes. We split the 93 stroke datasets into training and validation sets containing 83 and 9 examples respectively. Our network was trained on a NVidia TITAN XP GPU with 16 GBs RAM, using ADAM as optimizer and a learning rate of 1$\times$10$^{-5}$ during 200 epochs. Training took around 5 hours and segmentation of a whole volume took between 0.2 and 2 seconds, as average. The performance on the test set obtained by our method is compared to several baselines, to demonstrate the effectiveness of our architecture, and to a state-of-art architecture that employs factorized dilated convolutions, i.e., ERFNet.



### Learning Inward Scaled Hypersphere Embedding: Exploring Projections in Higher Dimensions
- **Arxiv ID**: http://arxiv.org/abs/1810.07037v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07037v1)
- **Published**: 2018-10-16 14:30:45+00:00
- **Updated**: 2018-10-16 14:30:45+00:00
- **Authors**: Muhammad Kamran Janjua, Shah Nawaz, Alessandro Calefati, Ignazio Gallo
- **Comment**: None
- **Journal**: None
- **Summary**: Majority of the current dimensionality reduction or retrieval techniques rely on embedding the learned feature representations onto a computable metric space. Once the learned features are mapped, a distance metric aids the bridging of gaps between similar instances. Since the scaled projection is not exploited in these methods, discriminative embedding onto a hyperspace becomes a challenge. In this paper, we propose to inwardly scale feature representations in proportional to projecting them onto a hypersphere manifold for discriminative analysis. We further propose a novel, yet simpler, convolutional neural network based architecture and extensively evaluate the proposed methodology in the context of classification and retrieval tasks obtaining results comparable to state-of-the-art techniques.



### Generating Self-Guided Dense Annotations for Weakly Supervised Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1810.07050v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07050v1)
- **Published**: 2018-10-16 14:49:18+00:00
- **Updated**: 2018-10-16 14:49:18+00:00
- **Authors**: Zi-Yi Ke, Chiou-Ting Hsu
- **Comment**: 16 pages,6 figures
- **Journal**: None
- **Summary**: Learning semantic segmentation models under image-level supervision is far more challenging than under fully supervised setting. Without knowing the exact pixel-label correspondence, most weakly-supervised methods rely on external models to infer pseudo pixel-level labels for training semantic segmentation models. In this paper, we aim to develop a single neural network without resorting to any external models. We propose a novel self-guided strategy to fully utilize features learned across multiple levels to progressively generate the dense pseudo labels. First, we use high-level features as class-specific localization maps to roughly locate the classes. Next, we propose an affinity-guided method to encourage each localization map to be consistent with their intermediate level features. Third, we adopt the training image itself as guidance and propose a self-guided refinement to further transfer the image's inherent structure into the maps. Finally, we derive pseudo pixel-level labels from these localization maps and use the pseudo labels as ground truth to train the semantic segmentation model. Our proposed self-guided strategy is a unified framework, which is built on a single network and alternatively updates the feature representation and refines localization maps during the training procedure. Experimental results on PASCAL VOC 2012 segmentation benchmark demonstrate that our method outperforms other weakly-supervised methods under the same setting.



### Shallow-Deep Networks: Understanding and Mitigating Network Overthinking
- **Arxiv ID**: http://arxiv.org/abs/1810.07052v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.07052v3)
- **Published**: 2018-10-16 14:51:13+00:00
- **Updated**: 2019-05-09 00:49:52+00:00
- **Authors**: Yigitcan Kaya, Sanghyun Hong, Tudor Dumitras
- **Comment**: Accepted to ICML2019. Source code here: www.shallowdeep.network
- **Journal**: None
- **Summary**: We characterize a prevalent weakness of deep neural networks (DNNs)---overthinking---which occurs when a DNN can reach correct predictions before its final layer. Overthinking is computationally wasteful, and it can also be destructive when, by the final layer, a correct prediction changes into a misclassification. Understanding overthinking requires studying how each prediction evolves during a DNN's forward pass, which conventionally is opaque. For prediction transparency, we propose the Shallow-Deep Network (SDN), a generic modification to off-the-shelf DNNs that introduces internal classifiers. We apply SDN to four modern architectures, trained on three image classification tasks, to characterize the overthinking problem. We show that SDNs can mitigate the wasteful effect of overthinking with confidence-based early exits, which reduce the average inference cost by more than 50% and preserve the accuracy. We also find that the destructive effect occurs for 50% of misclassifications on natural inputs and that it can be induced, adversarially, with a recent backdooring attack. To mitigate this effect, we propose a new confusion metric to quantify the internal disagreements that will likely lead to misclassifications.



### A Multi-stage Framework with Context Information Fusion Structure for Skin Lesion Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1810.07075v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07075v1)
- **Published**: 2018-10-16 15:26:30+00:00
- **Updated**: 2018-10-16 15:26:30+00:00
- **Authors**: Yujiao Tang, Feng Yang, Shaofeng Yuan, Chang'an Zhan
- **Comment**: 4 pages, 3 figures, 1 table
- **Journal**: None
- **Summary**: The computer-aided diagnosis (CAD) systems can highly improve the reliability and efficiency of melanoma recognition. As a crucial step of CAD, skin lesion segmentation has the unsatisfactory accuracy in existing methods due to large variability in lesion appearance and artifacts. In this work, we propose a framework employing multi-stage UNets (MS-UNet) in the auto-context scheme to segment skin lesion accurately end-to-end. We apply two approaches to boost the performance of MS-UNet. First, UNet is coupled with a context information fusion structure (CIFS) to integrate the low-level and context information in the multi-scale feature space. Second, to alleviate the gradient vanishing problem, we use deep supervision mechanism through supervising MS-UNet by minimizing a weighted Jaccard distance loss function. Four out of five commonly used performance metrics, including Jaccard index and Dice coefficient, show that our approach outperforms the state-ofthe-art deep learning based methods on the ISBI 2016 Skin Lesion Challenge dataset.



### A Comparison of 1-D and 2-D Deep Convolutional Neural Networks in ECG Classification
- **Arxiv ID**: http://arxiv.org/abs/1810.07088v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07088v1)
- **Published**: 2018-10-16 15:40:33+00:00
- **Updated**: 2018-10-16 15:40:33+00:00
- **Authors**: Yunan Wu, Feng Yang, Ying Liu, Xuefan Zha, Shaofeng Yuan
- **Comment**: 4 pages, 5 figures, 3 tables
- **Journal**: None
- **Summary**: Effective detection of arrhythmia is an important task in the remote monitoring of electrocardiogram (ECG). The traditional ECG recognition depends on the judgment of the clinicians' experience, but the results suffer from the probability of human error due to the fatigue. To solve this problem, an ECG signal classification method based on the images is presented to classify ECG signals into normal and abnormal beats by using two-dimensional convolutional neural networks (2D-CNNs). First, we compare the accuracy and robustness between one-dimensional ECG signal input method and two-dimensional image input method in AlexNet network. Then, in order to alleviate the overfitting problem in two-dimensional network, we initialize AlexNet-like network with weights trained on ImageNet, to fit the training ECG images and fine-tune the model, and to further improve the accuracy and robustness of ECG classification. The performance evaluated on the MIT-BIH arrhythmia database demonstrates that the proposed method can achieve the accuracy of 98% and maintain high accuracy within SNR range from 20 dB to 35 dB. The experiment shows that the 2D-CNNs initialized with AlexNet weights performs better than one-dimensional signal method without a large-scale dataset.



### Salient Object Detection in Video using Deep Non-Local Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1810.07097v1
- **DOI**: 10.1016/j.jvcir.2020.102769
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07097v1)
- **Published**: 2018-10-16 15:55:57+00:00
- **Updated**: 2018-10-16 15:55:57+00:00
- **Authors**: Mohammad Shokri, Ahad Harati, Kimya Taba
- **Comment**: Submitted to Journal of Visual Communication and Image Representation
- **Journal**: None
- **Summary**: Detection of salient objects in image and video is of great importance in many computer vision applications. In spite of the fact that the state of the art in saliency detection for still images has been changed substantially over the last few years, there have been few improvements in video saliency detection. This paper investigates the use of recently introduced non-local neural networks in video salient object detection. Non-local neural networks are applied to capture global dependencies and hence determine the salient objects. The effect of non-local operations is studied separately on static and dynamic saliency detection in order to exploit both appearance and motion features. A novel deep non-local neural network architecture is introduced for video salient object detection and tested on two well-known datasets DAVIS and FBMS. The experimental results show that the proposed algorithm outperforms state-of-the-art video saliency detection methods.



### Multiple Interactions Made Easy (MIME): Large Scale Demonstrations Data for Imitation
- **Arxiv ID**: http://arxiv.org/abs/1810.07121v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.07121v1)
- **Published**: 2018-10-16 16:27:43+00:00
- **Updated**: 2018-10-16 16:27:43+00:00
- **Authors**: Pratyusha Sharma, Lekha Mohan, Lerrel Pinto, Abhinav Gupta
- **Comment**: 10 pages, CoRL 2018
- **Journal**: None
- **Summary**: In recent years, we have seen an emergence of data-driven approaches in robotics. However, most existing efforts and datasets are either in simulation or focus on a single task in isolation such as grasping, pushing or poking. In order to make progress and capture the space of manipulation, we would need to collect a large-scale dataset of diverse tasks such as pouring, opening bottles, stacking objects etc. But how does one collect such a dataset? In this paper, we present the largest available robotic-demonstration dataset (MIME) that contains 8260 human-robot demonstrations over 20 different robotic tasks (https://sites.google.com/view/mimedataset). These tasks range from the simple task of pushing objects to the difficult task of stacking household objects. Our dataset consists of videos of human demonstrations and kinesthetic trajectories of robot demonstrations. We also propose to use this dataset for the task of mapping 3rd person video features to robot trajectories. Furthermore, we present two different approaches using this dataset and evaluate the predicted robot trajectories against ground-truth trajectories. We hope our dataset inspires research in multiple areas including visual imitation, trajectory prediction, and multi-task robotic learning.



### Robust Gesture-Based Communication for Underwater Human-Robot Interaction in the context of Search and Rescue Diver Missions
- **Arxiv ID**: http://arxiv.org/abs/1810.07122v1
- **DOI**: 10.3390/jmse7010016
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.07122v1)
- **Published**: 2018-10-16 16:32:30+00:00
- **Updated**: 2018-10-16 16:32:30+00:00
- **Authors**: Arturo Gomez Chavez, Christian A. Mueller, Tobias Doernbach, Davide Chiarella, Andreas Birk
- **Comment**: Workshop on Human-Aiding Robotics. International Conference on
  Intelligent Robots and Systems 2018 (IROS)
- **Journal**: Journal of Marine Science and Engineering. Vol. 7 (2019)
- **Summary**: We propose a robust gesture-based communication pipeline for divers to instruct an Autonomous Underwater Vehicle (AUV) to assist them in performing high-risk tasks and helping in case of emergency. A gesture communication language (CADDIAN) is developed, based on consolidated and standardized diver gestures, including an alphabet, syntax and semantics, ensuring a logical consistency. A hierarchical classification approach is introduced for hand gesture recognition based on stereo imagery and multi-descriptor aggregation to specifically cope with underwater image artifacts, e.g. light backscatter or color attenuation. Once the classification task is finished, a syntax check is performed to filter out invalid command sequences sent by the diver or generated by errors in the classifier. Throughout this process, the diver receives constant feedback from an underwater tablet to acknowledge or abort the mission at any time. The objective is to prevent the AUV from executing unnecessary, infeasible or potentially harmful motions. Experimental results under different environmental conditions in archaeological exploration and bridge inspection applications show that the system performs well in the field.



### Memorization in Overparameterized Autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1810.10333v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.10333v3)
- **Published**: 2018-10-16 17:02:54+00:00
- **Updated**: 2019-09-03 22:37:13+00:00
- **Authors**: Adityanarayanan Radhakrishnan, Karren Yang, Mikhail Belkin, Caroline Uhler
- **Comment**: None
- **Journal**: None
- **Summary**: The ability of deep neural networks to generalize well in the overparameterized regime has become a subject of significant research interest. We show that overparameterized autoencoders exhibit memorization, a form of inductive bias that constrains the functions learned through the optimization process to concentrate around the training examples, although the network could in principle represent a much larger function class. In particular, we prove that single-layer fully-connected autoencoders project data onto the (nonlinear) span of the training examples. In addition, we show that deep fully-connected autoencoders learn a map that is locally contractive at the training examples, and hence iterating the autoencoder results in convergence to the training examples. Finally, we prove that depth is necessary and provide empirical evidence that it is also sufficient for memorization in convolutional autoencoders. Understanding this inductive bias may shed light on the generalization properties of overparametrized deep neural networks that are currently unexplained by classical statistical theory.



### Projecting Trouble: Light Based Adversarial Attacks on Deep Learning Classifiers
- **Arxiv ID**: http://arxiv.org/abs/1810.10337v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.10337v1)
- **Published**: 2018-10-16 17:47:07+00:00
- **Updated**: 2018-10-16 17:47:07+00:00
- **Authors**: Nicole Nichols, Robert Jasper
- **Comment**: None
- **Journal**: None
- **Summary**: This work demonstrates a physical attack on a deep learning image classification system using projected light onto a physical scene. Prior work is dominated by techniques for creating adversarial examples which directly manipulate the digital input of the classifier. Such an attack is limited to scenarios where the adversary can directly update the inputs to the classifier. This could happen by intercepting and modifying the inputs to an online API such as Clarifai or Cloud Vision. Such limitations have led to a vein of research around physical attacks where objects are constructed to be inherently adversarial or adversarial modifications are added to cause misclassification. Our work differs from other physical attacks in that we can cause misclassification dynamically without altering physical objects in a permanent way.   We construct an experimental setup which includes a light projection source, an object for classification, and a camera to capture the scene. Experiments are conducted against 2D and 3D objects from CIFAR-10. Initial tests show projected light patterns selected via differential evolution could degrade classification from 98% to 22% and 89% to 43% probability for 2D and 3D targets respectively. Subsequent experiments explore sensitivity to physical setup and compare two additional baseline conditions for all 10 CIFAR classes. Some physical targets are more susceptible to perturbation. Simple attacks show near equivalent success, and 6 of the 10 classes were disrupted by light.



### Cross-Modal and Hierarchical Modeling of Video and Text
- **Arxiv ID**: http://arxiv.org/abs/1810.07212v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07212v1)
- **Published**: 2018-10-16 18:07:47+00:00
- **Updated**: 2018-10-16 18:07:47+00:00
- **Authors**: Bowen Zhang, Hexiang Hu, Fei Sha
- **Comment**: Accepted by ECCV 2018
- **Journal**: None
- **Summary**: Visual data and text data are composed of information at multiple granularities. A video can describe a complex scene that is composed of multiple clips or shots, where each depicts a semantically coherent event or action. Similarly, a paragraph may contain sentences with different topics, which collectively conveys a coherent message or story. In this paper, we investigate the modeling techniques for such hierarchical sequential data where there are correspondences across multiple modalities. Specifically, we introduce hierarchical sequence embedding (HSE), a generic model for embedding sequential data of different modalities into hierarchically semantic spaces, with either explicit or implicit correspondence information. We perform empirical studies on large-scale video and paragraph retrieval datasets and demonstrated superior performance by the proposed methods. Furthermore, we examine the effectiveness of our learned embeddings when applied to downstream tasks. We show its utility in zero-shot action recognition and video captioning.



### Incremental Few-Shot Learning with Attention Attractor Networks
- **Arxiv ID**: http://arxiv.org/abs/1810.07218v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.07218v3)
- **Published**: 2018-10-16 18:25:17+00:00
- **Updated**: 2019-10-06 21:08:47+00:00
- **Authors**: Mengye Ren, Renjie Liao, Ethan Fetaya, Richard S. Zemel
- **Comment**: NeurIPS 2019
- **Journal**: None
- **Summary**: Machine learning classifiers are often trained to recognize a set of pre-defined classes. However, in many applications, it is often desirable to have the flexibility of learning additional concepts, with limited data and without re-training on the full training set. This paper addresses this problem, incremental few-shot learning, where a regular classification network has already been trained to recognize a set of base classes, and several extra novel classes are being considered, each with only a few labeled examples. After learning the novel classes, the model is then evaluated on the overall classification performance on both base and novel classes. To this end, we propose a meta-learning model, the Attention Attractor Network, which regularizes the learning of novel classes. In each episode, we train a set of new weights to recognize novel classes until they converge, and we show that the technique of recurrent back-propagation can back-propagate through the optimization process and facilitate the learning of these parameters. We demonstrate that the learned attractor network can help recognize novel classes while remembering old classes without the need to review the original training set, outperforming various baselines.



### Hybrid Feature Based SLAM Prototype
- **Arxiv ID**: http://arxiv.org/abs/1810.07230v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.07230v2)
- **Published**: 2018-10-16 18:54:06+00:00
- **Updated**: 2018-10-18 11:17:21+00:00
- **Authors**: V. I Mebin Jose, D. J Binoj
- **Comment**: 7 pages,1 figures
- **Journal**: None
- **Summary**: The development of data innovation as of late and the expanded limit, has permitted the acquaintance of artificial vision connected with SLAM, offering ascend to what is known as Visual SLAM. The objective of this paper is to build up a route framework dependent on Visual SLAM to get a robot to a fundamental and new condition, have the capacity to set and make a three-dimensional guide thereof, utilizing just as sources of info recording your way with a stereo vision camera. The consequence of this analysis is that the framework Visual SLAM together with the combination of Fast SLAM (combination of kalman with particulate filter and SIFT) perceive and recognize characteristic points in images so adequately exact and unambiguous. This framework uses MATLAB, since its adaptability and comfort for performing a wide range of tests. The program has been tested by inserting a prerecorded video input with a camera stereo in which a course is done by an office environment. The algorithm initially locates points of interest in a stereo frame captured by the camera. These will be located in 3D and they associate an identification descriptor. In the next frame, the camera likewise identified points of interest and it will be compared which of them have been previously detected by comparing their descriptors. This process is known as "data association" and its successful completion is fundamental to the SLAM algorithm. The position data of the robot and points interest stored in data structures known as "particles" that evolve independently. Its management is very important for the proper functioning of the algorithm Fast SLAM. The results are found to be satisfactory.



### Reduced-Gate Convolutional LSTM Using Predictive Coding for Spatiotemporal Prediction
- **Arxiv ID**: http://arxiv.org/abs/1810.07251v11
- **DOI**: 10.1111/coin.12277
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.07251v11)
- **Published**: 2018-10-16 19:55:51+00:00
- **Updated**: 2019-12-22 21:44:41+00:00
- **Authors**: Nelly Elsayed, Anthony S. Maida, Magdy Bayoumi
- **Comment**: A novel rgcLSTM model for spatiotemporal prediction. This version
  contains the full description and detailed empirical study of the rgcLSTM
  architecture. 28 pages, 12 figures, 20 tables
- **Journal**: None
- **Summary**: Spatiotemporal sequence prediction is an important problem in deep learning. We study next-frame(s) video prediction using a deep-learning-based predictive coding framework that uses convolutional, long short-term memory (convLSTM) modules. We introduce a novel reduced-gate convolutional LSTM(rgcLSTM) architecture that requires a significantly lower parameter budget than a comparable convLSTM. By using a single multi-function gate, our reduced-gate model achieves equal or better next-frame(s) prediction accuracy than the original convolutional LSTM while using a smaller parameter budget, thereby reducing training time and memory requirements. We tested our reduced gate modules within a predictive coding architecture on the moving MNIST and KITTI datasets. We found that our reduced-gate model has a significant reduction of approximately 40 percent of the total number of training parameters and a 25 percent reduction in elapsed training time in comparison with the standard convolutional LSTM model. The performance accuracy of the new model was also improved. This makes our model more attractive for hardware implementation, especially on small devices. We also explored a space of twenty different gated architectures to get insight into how our rgcLSTM fit into that space.



