# Arxiv Papers in cs.CV on 2018-10-30
### Generating new pictures in complex datasets with a simple neural network
- **Arxiv ID**: http://arxiv.org/abs/1810.12478v3
- **DOI**: None
- **Categories**: **cs.CV**, E.0, G.1.3, G.1.6, I.2.0, E.0; G.1.3; G.1.6; I.2.0
- **Links**: [PDF](http://arxiv.org/pdf/1810.12478v3)
- **Published**: 2018-10-30 01:38:21+00:00
- **Updated**: 2019-11-26 23:58:48+00:00
- **Authors**: Galin Georgiev
- **Comment**: 13 pages plus some images
- **Journal**: None
- **Summary**: We introduce a version of a variational auto-encoder (VAE), which can generate good perturbations of images, when trained on a complex dataset (in our experiments, CIFAR-10). The net is using only two latent generative dimensions per class, with uni-modal probability density. The price one has to pay for good generation is that not all training images are well reconstructed. An additional classifier is required to determine which training image is well reconstructed and generally the weights of training images. Only training images which are well reconstructed, can be perturbed. For good perturbations, we use the tentative empirical drifts of well reconstructed images. The construct is not predictive in the usual statistical sense.



### Re-evaluating Continual Learning Scenarios: A Categorization and Case for Strong Baselines
- **Arxiv ID**: http://arxiv.org/abs/1810.12488v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.12488v4)
- **Published**: 2018-10-30 02:08:35+00:00
- **Updated**: 2019-01-23 16:58:13+00:00
- **Authors**: Yen-Chang Hsu, Yen-Cheng Liu, Anita Ramasamy, Zsolt Kira
- **Comment**: Continual Learning Workshop, 32nd Conference on Neural Information
  Processing Systems (NIPS 2018)
- **Journal**: None
- **Summary**: Continual learning has received a great deal of attention recently with several approaches being proposed. However, evaluations involve a diverse set of scenarios making meaningful comparison difficult. This work provides a systematic categorization of the scenarios and evaluates them within a consistent framework including strong baselines and state-of-the-art methods. The results provide an understanding of the relative difficulty of the scenarios and that simple baselines (Adagrad, L2 regularization, and naive rehearsal strategies) can surprisingly achieve similar performance to current mainstream methods. We conclude with several suggestions for creating harder evaluation scenarios and future research directions. The code is available at https://github.com/GT-RIPL/Continual-Learning-Benchmark



### Shape and Margin-Aware Lung Nodule Classification in Low-dose CT Images via Soft Activation Mapping
- **Arxiv ID**: http://arxiv.org/abs/1810.12494v2
- **DOI**: 10.1016/j.media.2019.101628
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12494v2)
- **Published**: 2018-10-30 02:29:30+00:00
- **Updated**: 2019-12-17 12:23:40+00:00
- **Authors**: Yiming Lei, Yukun Tian, Hongming Shan, Junping Zhang, Ge Wang, Mannudeep Kalra
- **Comment**: None
- **Journal**: None
- **Summary**: A number of studies on lung nodule classification lack clinical/biological interpretations of the features extracted by convolutional neural network (CNN). The methods like class activation mapping (CAM) and gradient-based CAM (Grad-CAM) are tailored for interpreting localization and classification tasks while they ignored fine-grained features. Therefore, CAM and Grad-CAM cannot provide optimal interpretation for lung nodule categorization task in low-dose CT images, in that fine-grained pathological clues like discrete and irregular shape and margins of nodules are capable of enhancing sensitivity and specificity of nodule classification with regards to CNN. In this paper, we first develop a soft activation mapping (SAM) to enable fine-grained lung nodule shape \& margin (LNSM) feature analysis with a CNN so that it can access rich discrete features. Secondly, by combining high-level convolutional features with SAM, we further propose a high-level feature enhancement scheme (HESAM) to localize LNSM features. Experiments on the LIDC-IDRI dataset indicate that 1) SAM captures more fine-grained and discrete attention regions than existing methods, 2) HESAM localizes more accurately on LNSM features and obtains the state-of-the-art predictive performance, reducing the false positive rate, and 3) we design and conduct a visually matching experiment which incorporates radiologists study to increase the confidence level of applying our method to clinical diagnosis.



### DeepGRU: Deep Gesture Recognition Utility
- **Arxiv ID**: http://arxiv.org/abs/1810.12514v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1810.12514v4)
- **Published**: 2018-10-30 03:43:22+00:00
- **Updated**: 2019-10-10 05:41:24+00:00
- **Authors**: Mehran Maghoumi, Joseph J. LaViola Jr
- **Comment**: Published in ISVC 2019. Code is available at
  https://github.com/Maghoumi/DeepGRU
- **Journal**: None
- **Summary**: We propose DeepGRU, a novel end-to-end deep network model informed by recent developments in deep learning for gesture and action recognition, that is streamlined and device-agnostic. DeepGRU, which uses only raw skeleton, pose or vector data is quickly understood, implemented, and trained, and yet achieves state-of-the-art results on challenging datasets. At the heart of our method lies a set of stacked gated recurrent units (GRU), two fully-connected layers and a novel global attention model. We evaluate our method on seven publicly available datasets, containing various number of samples and spanning over a broad range of interactions (full-body, multi-actor, hand gestures, etc.). In all but one case we outperform the state-of-the-art pose-based methods. For instance, we achieve a recognition accuracy of 84.9% and 92.3% on cross-subject and cross-view tests of the NTU RGB+D dataset respectively, and also 100% recognition accuracy on the UT-Kinect dataset. While DeepGRU works well on large datasets with many training samples, we show that even in the absence of a large number of training data, and with as little as four samples per class, DeepGRU can beat traditional methods specifically designed for small training sets. Lastly, we demonstrate that even without powerful hardware, and using only the CPU, our method can still be trained in under 10 minutes on small-scale datasets, making it an enticing choice for rapid application prototyping and development.



### Gated Transfer Network for Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/1810.12521v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1810.12521v1)
- **Published**: 2018-10-30 04:31:48+00:00
- **Updated**: 2018-10-30 04:31:48+00:00
- **Authors**: Yi Zhu, Jia Xue, Shawn Newsam
- **Comment**: Accepted at ACCV 2018. Camera ready
- **Journal**: None
- **Summary**: Deep neural networks have led to a series of breakthroughs in computer vision given sufficient annotated training datasets. For novel tasks with limited labeled data, the prevalent approach is to transfer the knowledge learned in the pre-trained models to the new tasks by fine-tuning. Classic model fine-tuning utilizes the fact that well trained neural networks appear to learn cross domain features. These features are treated equally during transfer learning. In this paper, we explore the impact of feature selection in model fine-tuning by introducing a transfer module, which assigns weights to features extracted from pre-trained models. The proposed transfer module proves the importance of feature selection for transferring models from source to target domains. It is shown to significantly improve upon fine-tuning results with only marginal extra computational cost. We also incorporate an auxiliary classifier as an extra regularizer to avoid over-fitting. Finally, we build a Gated Transfer Network (GTN) based on our transfer module and achieve state-of-the-art results on six different tasks.



### Random Temporal Skipping for Multirate Video Analysis
- **Arxiv ID**: http://arxiv.org/abs/1810.12522v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1810.12522v1)
- **Published**: 2018-10-30 04:35:43+00:00
- **Updated**: 2018-10-30 04:35:43+00:00
- **Authors**: Yi Zhu, Shawn Newsam
- **Comment**: Accepted at ACCV 2018. Camera ready
- **Journal**: None
- **Summary**: Current state-of-the-art approaches to video understanding adopt temporal jittering to simulate analyzing the video at varying frame rates. However, this does not work well for multirate videos, in which actions or subactions occur at different speeds. The frame sampling rate should vary in accordance with the different motion speeds. In this work, we propose a simple yet effective strategy, termed random temporal skipping, to address this situation. This strategy effectively handles multirate videos by randomizing the sampling rate during training. It is an exhaustive approach, which can potentially cover all motion speed variations. Furthermore, due to the large temporal skipping, our network can see video clips that originally cover over 100 frames. Such a time range is enough to analyze most actions/events. We also introduce an occlusion-aware optical flow learning method that generates improved motion maps for human action recognition. Our framework is end-to-end trainable, runs in real-time, and achieves state-of-the-art performance on six widely adopted video benchmarks.



### Fully automatic structure from motion with a spline-based environment representation
- **Arxiv ID**: http://arxiv.org/abs/1810.12532v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12532v1)
- **Published**: 2018-10-30 04:59:53+00:00
- **Updated**: 2018-10-30 04:59:53+00:00
- **Authors**: Zhirui Wang, Laurent Kneip
- **Comment**: 12 pages (10 + 2 pages references), 6 figures
- **Journal**: None
- **Summary**: While the common environment representation in structure from motion is given by a sparse point cloud, the community has also investigated the use of lines to better enforce the inherent regularities in man-made surroundings. Following the potential of this idea, the present paper introduces a more flexible higher-order extension of points that provides a general model for structural edges in the environment, no matter if straight or curved. Our model relies on linked B\'ezier curves, the geometric intuition of which proves great benefits during parameter initialization and regularization. We present the first fully automatic pipeline that is able to generate spline-based representations without any human supervision. Besides a full graphical formulation of the problem, we introduce both geometric and photometric cues as well as higher-level concepts such overall curve visibility and viewing angle restrictions to automatically manage the correspondences in the graph. Results prove that curve-based structure from motion with splines is able to outperform state-of-the-art sparse feature-based methods, as well as to model curved edges in the environment.



### Gated Hierarchical Attention for Image Captioning
- **Arxiv ID**: http://arxiv.org/abs/1810.12535v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1810.12535v2)
- **Published**: 2018-10-30 05:20:49+00:00
- **Updated**: 2018-10-31 04:44:41+00:00
- **Authors**: Qingzhong Wang, Antoni B. Chan
- **Comment**: Accepted by ACCV
- **Journal**: None
- **Summary**: Attention modules connecting encoder and decoders have been widely applied in the field of object recognition, image captioning, visual question answering and neural machine translation, and significantly improves the performance. In this paper, we propose a bottom-up gated hierarchical attention (GHA) mechanism for image captioning. Our proposed model employs a CNN as the decoder which is able to learn different concepts at different layers, and apparently, different concepts correspond to different areas of an image. Therefore, we develop the GHA in which low-level concepts are merged into high-level concepts and simultaneously low-level attended features pass to the top to make predictions. Our GHA significantly improves the performance of the model that only applies one level attention, for example, the CIDEr score increases from 0.923 to 0.999, which is comparable to the state-of-the-art models that employ attributes boosting and reinforcement learning (RL). We also conduct extensive experiments to analyze the CNN decoder and our proposed GHA, and we find that deeper decoders cannot obtain better performance, and when the convolutional decoder becomes deeper the model is likely to collapse during training.



### 3D Traffic Simulation for Autonomous Vehicles in Unity and Python
- **Arxiv ID**: http://arxiv.org/abs/1810.12552v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12552v2)
- **Published**: 2018-10-30 07:21:43+00:00
- **Updated**: 2019-08-20 13:28:21+00:00
- **Authors**: Zhijing Jin, Tristan Swedish, Ramesh Raskar
- **Comment**: None
- **Journal**: None
- **Summary**: Over the recent years, there has been an explosion of studies on autonomous vehicles. Many collected large amount of data from human drivers. However, compared to the tedious data collection approach, building a virtual simulation of traffic makes the autonomous vehicle research more flexible, time-saving, and scalable. Our work features a 3D simulation that takes in real time position information parsed from street cameras. The simulation can easily switch between a global bird view of the traffic and a local perspective of a car. It can also filter out certain objects in its customized camera, creating various channels for objects of different categories. This provides alternative supervised or unsupervised ways to train deep neural networks. Another advantage of the 3D simulation is its conformation to physical laws. Its naturalness to accelerate and collide prepares the system for potential deep reinforcement learning needs.



### Scale-Invariant Structure Saliency Selection for Fast Image Fusion
- **Arxiv ID**: http://arxiv.org/abs/1810.12553v1
- **DOI**: 10.1016/j.neucom.2019.04.043
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12553v1)
- **Published**: 2018-10-30 07:22:21+00:00
- **Updated**: 2018-10-30 07:22:21+00:00
- **Authors**: Yixiong Liang, Yuan Mao, Jiazhi Xia, Yao Xiang, Jianfeng Liu
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a fast yet effective method for pixel-level scale-invariant image fusion in spatial domain based on the scale-space theory. Specifically, we propose a scale-invariant structure saliency selection scheme based on the difference-of-Gaussian (DoG) pyramid of images to build the weights or activity map. Due to the scale-invariant structure saliency selection, our method can keep both details of small size objects and the integrity information of large size objects in images. In addition, our method is very efficient since there are no complex operation involved and easy to be implemented and therefore can be used for fast high resolution images fusion. Experimental results demonstrate the proposed method yields competitive or even better results comparing to state-of-the-art image fusion methods both in terms of visual quality and objective evaluation metrics. Furthermore, the proposed method is very fast and can be used to fuse the high resolution images in real-time. Code is available at https://github.com/yiqingmy/Fusion.



### Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1810.12563v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.12563v1)
- **Published**: 2018-10-30 07:57:27+00:00
- **Updated**: 2018-10-30 07:57:27+00:00
- **Authors**: Haowen Luo
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) attained a good performance in hyperspectral sensing image (HSI) classification, but CNNs consider spectra as orderless vectors. Therefore, considering the spectra as sequences, recurrent neural networks (RNNs) have been applied in HSI classification, for RNNs is skilled at dealing with sequential data. However, for a long-sequence task, RNNs is difficult for training and not as effective as we expected. Besides, spatial contextual features are not considered in RNNs. In this study, we propose a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU) for HSI classification. A shorten RNN is more efficient and easier for training than band-by-band RNN. By combining converlusion layer, the St-SSpGRU model considers not only spectral but also spatial feature, which results in a better performance. An architecture named parallel-GRU is also proposed and applied in St-SS-pGRU. With this architecture, the model gets a better performance and is more robust.



### Nonlinear Prediction of Multidimensional Signals via Deep Regression with Applications to Image Coding
- **Arxiv ID**: http://arxiv.org/abs/1810.12568v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1810.12568v1)
- **Published**: 2018-10-30 08:14:11+00:00
- **Updated**: 2018-10-30 08:14:11+00:00
- **Authors**: Xi Zhang, Xiaolin Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep convolutional neural networks (DCNN) have enjoyed great successes in many signal processing applications because they can learn complex, non-linear causal relationships from input to output. In this light, DCNNs are well suited for the task of sequential prediction of multidimensional signals, such as images, and have the potential of improving the performance of traditional linear predictors. In this research we investigate how far DCNNs can push the envelop in terms of prediction precision. We propose, in a case study, a two-stage deep regression DCNN framework for nonlinear prediction of two-dimensional image signals. In the first-stage regression, the proposed deep prediction network (PredNet) takes the causal context as input and emits a prediction of the present pixel. Three PredNets are trained with the regression objectives of minimizing $\ell_1$, $\ell_2$ and $\ell_\infty$ norms of prediction residuals, respectively. The second-stage regression combines the outputs of the three PredNets to generate an even more precise and robust prediction. The proposed deep regression model is applied to lossless predictive image coding, and it outperforms the state-of-the-art linear predictors by appreciable margin.



### Rain Removal in Traffic Surveillance: Does it Matter?
- **Arxiv ID**: http://arxiv.org/abs/1810.12574v1
- **DOI**: 10.1109/TITS.2018.2872502
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12574v1)
- **Published**: 2018-10-30 08:25:54+00:00
- **Updated**: 2018-10-30 08:25:54+00:00
- **Authors**: Chris H. Bahnsen, Thomas B. Moeslund
- **Comment**: Published in IEEE Transactions on Intelligent Transportation Systems
- **Journal**: None
- **Summary**: Varying weather conditions, including rainfall and snowfall, are generally regarded as a challenge for computer vision algorithms. One proposed solution to the challenges induced by rain and snowfall is to artificially remove the rain from images or video using rain removal algorithms. It is the promise of these algorithms that the rain-removed image frames will improve the performance of subsequent segmentation and tracking algorithms. However, rain removal algorithms are typically evaluated on their ability to remove synthetic rain on a small subset of images. Currently, their behavior is unknown on real-world videos when integrated with a typical computer vision pipeline. In this paper, we review the existing rain removal algorithms and propose a new dataset that consists of 22 traffic surveillance sequences under a broad variety of weather conditions that all include either rain or snowfall. We propose a new evaluation protocol that evaluates the rain removal algorithms on their ability to improve the performance of subsequent segmentation, instance segmentation, and feature tracking algorithms under rain and snow. If successful, the de-rained frames of a rain removal algorithm should improve segmentation performance and increase the number of accurately tracked features. The results show that a recent single-frame-based rain removal algorithm increases the segmentation performance by 19.7% on our proposed dataset, but it eventually decreases the feature tracking performance and showed mixed results with recent instance segmentation methods. However, the best video-based rain removal algorithm improves the feature tracking accuracy by 7.72%.



### Neural Nearest Neighbors Networks
- **Arxiv ID**: http://arxiv.org/abs/1810.12575v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1810.12575v1)
- **Published**: 2018-10-30 08:32:47+00:00
- **Updated**: 2018-10-30 08:32:47+00:00
- **Authors**: Tobias Plötz, Stefan Roth
- **Comment**: to appear at NIPS*2018, code available at
  https://github.com/visinf/n3net/
- **Journal**: None
- **Summary**: Non-local methods exploiting the self-similarity of natural signals have been well studied, for example in image analysis and restoration. Existing approaches, however, rely on k-nearest neighbors (KNN) matching in a fixed feature space. The main hurdle in optimizing this feature space w.r.t. application performance is the non-differentiability of the KNN selection rule. To overcome this, we propose a continuous deterministic relaxation of KNN selection that maintains differentiability w.r.t. pairwise distances, but retains the original KNN as the limit of a temperature parameter approaching zero. To exploit our relaxation, we propose the neural nearest neighbors block (N3 block), a novel non-local processing layer that leverages the principle of self-similarity and can be used as building block in modern neural network architectures. We show its effectiveness for the set reasoning task of correspondence classification as well as for image restoration, including image denoising and single image super-resolution, where we outperform strong convolutional neural network (CNN) baselines and recent non-local models that rely on KNN selection in hand-chosen features spaces.



### Improved Network Robustness with Adversary Critic
- **Arxiv ID**: http://arxiv.org/abs/1810.12576v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1810.12576v1)
- **Published**: 2018-10-30 08:33:46+00:00
- **Updated**: 2018-10-30 08:33:46+00:00
- **Authors**: Alexander Matyasko, Lap-Pui Chau
- **Comment**: None
- **Journal**: None
- **Summary**: Ideally, what confuses neural network should be confusing to humans. However, recent experiments have shown that small, imperceptible perturbations can change the network prediction. To address this gap in perception, we propose a novel approach for learning robust classifier. Our main idea is: adversarial examples for the robust classifier should be indistinguishable from the regular data of the adversarial target. We formulate a problem of learning robust classifier in the framework of Generative Adversarial Networks (GAN), where the adversarial attack on classifier acts as a generator, and the critic network learns to distinguish between regular and adversarial images. The classifier cost is augmented with the objective that its adversarial examples should confuse the adversary critic. To improve the stability of the adversarial mapping, we introduce adversarial cycle-consistency constraint which ensures that the adversarial mapping of the adversarial examples is close to the original. In the experiments, we show the effectiveness of our defense. Our method surpasses in terms of robustness networks trained with adversarial training. Additionally, we verify in the experiments with human annotators on MTurk that adversarial examples are indeed visually confusing. Codes for the project are available at https://github.com/aam-at/adversary_critic.



### MAMMO: A Deep Learning Solution for Facilitating Radiologist-Machine Collaboration in Breast Cancer Diagnosis
- **Arxiv ID**: http://arxiv.org/abs/1811.02661v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.02661v1)
- **Published**: 2018-10-30 10:45:53+00:00
- **Updated**: 2018-10-30 10:45:53+00:00
- **Authors**: Trent Kyono, Fiona J. Gilbert, Mihaela van der Schaar
- **Comment**: 18 pages, 7 figures
- **Journal**: None
- **Summary**: With an aging and growing population, the number of women requiring either screening or symptomatic mammograms is increasing. To reduce the number of mammograms that need to be read by a radiologist while keeping the diagnostic accuracy the same or better than current clinical practice, we develop Man and Machine Mammography Oracle (MAMMO) - a clinical decision support system capable of triaging mammograms into those that can be confidently classified by a machine and those that cannot be, thus requiring the reading of a radiologist. The first component of MAMMO is a novel multi-view convolutional neural network (CNN) with multi-task learning (MTL). MTL enables the CNN to learn the radiological assessments known to be associated with cancer, such as breast density, conspicuity, suspicion, etc., in addition to learning the primary task of cancer diagnosis. We show that MTL has two advantages: 1) learning refined feature representations associated with cancer improves the classification performance of the diagnosis task and 2) issuing radiological assessments provides an additional layer of model interpretability that a radiologist can use to debug and scrutinize the diagnoses provided by the CNN. The second component of MAMMO is a triage network, which takes as input the radiological assessment and diagnostic predictions of the first network's MTL outputs and determines which mammograms can be correctly and confidently diagnosed by the CNN and which mammograms cannot, thus needing to be read by a radiologist. Results obtained on a private dataset of 8,162 patients show that MAMMO reduced the number of radiologist readings by 42.8% while improving the overall diagnostic accuracy in comparison to readings done by radiologists alone. We analyze the triage of patients decided by MAMMO to gain a better understanding of what unique mammogram characteristics require radiologists' expertise.



### Hybrid Knowledge Routed Modules for Large-scale Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1810.12681v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12681v1)
- **Published**: 2018-10-30 11:52:10+00:00
- **Updated**: 2018-10-30 11:52:10+00:00
- **Authors**: Chenhan Jiang, Hang Xu, Xiangdan Liang, Liang Lin
- **Comment**: 9 pages, 5 figures
- **Journal**: None
- **Summary**: The dominant object detection approaches treat the recognition of each region separately and overlook crucial semantic correlations between objects in one scene. This paradigm leads to substantial performance drop when facing heavy long-tail problems, where very few samples are available for rare classes and plenty of confusing categories exists. We exploit diverse human commonsense knowledge for reasoning over large-scale object categories and reaching semantic coherency within one image. Particularly, we present Hybrid Knowledge Routed Modules (HKRM) that incorporates the reasoning routed by two kinds of knowledge forms: an explicit knowledge module for structured constraints that are summarized with linguistic knowledge (e.g. shared attributes, relationships) about concepts; and an implicit knowledge module that depicts some implicit constraints (e.g. common spatial layouts). By functioning over a region-to-region graph, both modules can be individualized and adapted to coordinate with visual patterns in each image, guided by specific knowledge forms. HKRM are light-weight, general-purpose and extensible by easily incorporating multiple knowledge to endow any detection networks the ability of global semantic reasoning. Experiments on large-scale object detection benchmarks show HKRM obtains around 34.5% improvement on VisualGenome (1000 categories) and 30.4% on ADE in terms of mAP. Codes and trained model can be found in https://github.com/chanyn/HKRM.



### Role of Class-specific Features in Various Classification Frameworks for Human Epithelial (HEp-2) Cell Images
- **Arxiv ID**: http://arxiv.org/abs/1810.12690v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12690v1)
- **Published**: 2018-10-30 12:06:09+00:00
- **Updated**: 2018-10-30 12:06:09+00:00
- **Authors**: Vibha Gupta, Arnav Bhavsar
- **Comment**: None
- **Journal**: None
- **Summary**: The antinuclear antibody detection with human epithelial cells is a popular approach for autoimmune diseases diagnosis. The manual evaluation demands time, effort and capital, and automation in screening can greatly aid the physicians in these respects. In this work, we employ simple, efficient and visually more interpretable, class-specific features which defined based on the visual characteristics of each class. We believe that defining features with a good visual interpretation, is indeed important in a scenario, where such an approach is used in an interactive CAD system for pathologists. Considering that problem consists of few classes, and our rather simplistic feature definitions, frameworks can be structured as hierarchies of various binary classifiers. These variants include frameworks which are earlier explored and some which are not explored for this task. We perform various experiments which include traditional texture features and demonstrate the effectiveness of class-specific features in various frameworks. We make insightful comparisons between different types of classification frameworks given their silent aspects and pros and cons over each other. We also demonstrate an experiment with only intermediates samples for testing. The proposed work yields encouraging results with respect to the state-of-the-art and highlights the role of class-specific features in different classification frameworks.



### Reinforcement Learning and Deep Learning based Lateral Control for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/1810.12778v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.12778v1)
- **Published**: 2018-10-30 14:43:36+00:00
- **Updated**: 2018-10-30 14:43:36+00:00
- **Authors**: Dong Li, Dongbin Zhao, Qichao Zhang, Yaran Chen
- **Comment**: 14 pages, 12 figures, accepted to IEEE Computational Intelligence
  Magazine
- **Journal**: None
- **Summary**: This paper investigates the vision-based autonomous driving with deep learning and reinforcement learning methods. Different from the end-to-end learning method, our method breaks the vision-based lateral control system down into a perception module and a control module. The perception module which is based on a multi-task learning neural network first takes a driver-view image as its input and predicts the track features. The control module which is based on reinforcement learning then makes a control decision based on these features. In order to improve the data efficiency, we propose visual TORCS (VTORCS), a deep reinforcement learning environment which is based on the open racing car simulator (TORCS). By means of the provided functions, one can train an agent with the input of an image or various physical sensor measurement, or evaluate the perception algorithm on this simulator. The trained reinforcement learning controller outperforms the linear quadratic regulator (LQR) controller and model predictive control (MPC) controller on different tracks. The experiments demonstrate that the perception module shows promising performance and the controller is capable of controlling the vehicle drive well along the track center with visual input.



### Contextual Hourglass Network for Semantic Segmentation of High Resolution Aerial Imagery
- **Arxiv ID**: http://arxiv.org/abs/1810.12813v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12813v2)
- **Published**: 2018-10-30 15:33:47+00:00
- **Updated**: 2019-02-09 08:54:51+00:00
- **Authors**: Panfeng Li, Youzuo Lin, Emily Schultz-Fellenz
- **Comment**: Submitted to ICIP 2019
- **Journal**: None
- **Summary**: Semantic segmentation for aerial imagery is a challenging and important problem in remotely sensed imagery analysis. In recent years, with the success of deep learning, various convolutional neural network (CNN) based models have been developed. However, due to the varying sizes of the objects and imbalanced class labels, it can be challenging to obtain accurate pixel-wise semantic segmentation results. To address those challenges, we develop a novel semantic segmentation method and call it Contextual Hourglass Network. In our method, in order to improve the robustness of the prediction, we design a new contextual hourglass module which incorporates attention mechanism on processed low-resolution featuremaps to exploit the contextual semantics. We further exploit the stacked encoder-decoder structure by connecting multiple contextual hourglass modules from end to end. This architecture can effectively extract rich multi-scale features and add more feedback loops for better learning contextual semantics through intermediate supervision. To demonstrate the efficacy of our semantic segmentation method, we test it on Potsdam and Vaihingen datasets. Through the comparisons to other baseline methods, our method yields the best results on overall performance.



### Informed Democracy: Voting-based Novelty Detection for Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1810.12819v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12819v1)
- **Published**: 2018-10-30 15:42:55+00:00
- **Updated**: 2018-10-30 15:42:55+00:00
- **Authors**: Alina Roitberg, Ziad Al-Halah, Rainer Stiefelhagen
- **Comment**: Published in BMVC 2018. First and second authors contributed equally
  to this work
- **Journal**: None
- **Summary**: Novelty detection is crucial for real-life applications. While it is common in activity recognition to assume a closed-set setting, i.e. test samples are always of training categories, this assumption is impractical in a real-world scenario. Test samples can be of various categories including those never seen before during training. Thus, being able to know what we know and what we do not know is decisive for the model to avoid what can be catastrophic consequences. We present in this work a novel approach for identifying samples of activity classes that are not previously seen by the classifier. Our model employs a voting-based scheme that leverages the estimated uncertainty of the individual classifiers in their predictions to measure the novelty of a new input sample. Furthermore, the voting is privileged to a subset of informed classifiers that can best estimate whether a sample is novel or not when it is classified to a certain known category. In a thorough evaluation on UCF-101 and HMDB-51, we show that our model consistently outperforms state-of-the-art in novelty detection. Additionally, by combining our model with off-the-shelf zero-shot learning (ZSL) approaches, our model leads to a significant improvement in action classification accuracy for the generalized ZSL setting.



### Cross-Modal Attentional Context Learning for RGB-D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1810.12829v1
- **DOI**: 10.1109/TIP.2018.2878956
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12829v1)
- **Published**: 2018-10-30 15:57:18+00:00
- **Updated**: 2018-10-30 15:57:18+00:00
- **Authors**: Guanbin Li, Yukang Gan, Hejun Wu, Nong Xiao, Liang Lin
- **Comment**: Accept as a regular paper to IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: Recognizing objects from simultaneously sensed photometric (RGB) and depth channels is a fundamental yet practical problem in many machine vision applications such as robot grasping and autonomous driving. In this paper, we address this problem by developing a Cross-Modal Attentional Context (CMAC) learning framework, which enables the full exploitation of the context information from both RGB and depth data. Compared to existing RGB-D object detection frameworks, our approach has several appealing properties. First, it consists of an attention-based global context model for exploiting adaptive contextual information and incorporating this information into a region-based CNN (e.g., Fast RCNN) framework to achieve improved object detection performance. Second, our CMAC framework further contains a fine-grained object part attention module to harness multiple discriminative object parts inside each possible object region for superior local feature representation. While greatly improving the accuracy of RGB-D object detection, the effective cross-modal information fusion as well as attentional context modeling in our proposed model provide an interpretable visualization scheme. Experimental results demonstrate that the proposed method significantly improves upon the state of the art on all public benchmarks.



### General audio tagging with ensembling convolutional neural network and statistical features
- **Arxiv ID**: http://arxiv.org/abs/1810.12832v1
- **DOI**: 10.1121/1.5111059
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12832v1)
- **Published**: 2018-10-30 15:59:28+00:00
- **Updated**: 2018-10-30 15:59:28+00:00
- **Authors**: Kele Xu, Boqing Zhu, Qiuqiang Kong, Haibo Mi, Bo Ding, Dezhi Wang, Huaimin Wang
- **Comment**: Submitted to ICASSP
- **Journal**: None
- **Summary**: Audio tagging aims to infer descriptive labels from audio clips. Audio tagging is challenging due to the limited size of data and noisy labels. In this paper, we describe our solution for the DCASE 2018 Task 2 general audio tagging challenge. The contributions of our solution include: We investigated a variety of convolutional neural network architectures to solve the audio tagging task. Statistical features are applied to capture statistical patterns of audio features to improve the classification performance. Ensemble learning is applied to ensemble the outputs from the deep classifiers to utilize complementary information. a sample re-weight strategy is employed for ensemble training to address the noisy label problem. Our system achieves a mean average precision (mAP@3) of 0.958, outperforming the baseline system of 0.704. Our system ranked the 1st and 4th out of 558 submissions in the public and private leaderboard of DCASE 2018 Task 2 challenge. Our codes are available at https://github.com/Cocoxili/DCASE2018Task2/.



### Image Restoration using Total Variation Regularized Deep Image Prior
- **Arxiv ID**: http://arxiv.org/abs/1810.12864v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12864v1)
- **Published**: 2018-10-30 17:11:48+00:00
- **Updated**: 2018-10-30 17:11:48+00:00
- **Authors**: Jiaming Liu, Yu Sun, Xiaojian Xu, Ulugbek S. Kamilov
- **Comment**: None
- **Journal**: None
- **Summary**: In the past decade, sparsity-driven regularization has led to significant improvements in image reconstruction. Traditional regularizers, such as total variation (TV), rely on analytical models of sparsity. However, increasingly the field is moving towards trainable models, inspired from deep learning. Deep image prior (DIP) is a recent regularization framework that uses a convolutional neural network (CNN) architecture without data-driven training. This paper extends the DIP framework by combining it with the traditional TV regularization. We show that the inclusion of TV leads to considerable performance gains when tested on several traditional restoration tasks such as image denoising and deblurring.



### DropBlock: A regularization method for convolutional networks
- **Arxiv ID**: http://arxiv.org/abs/1810.12890v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12890v1)
- **Published**: 2018-10-30 17:39:42+00:00
- **Updated**: 2018-10-30 17:39:42+00:00
- **Authors**: Golnaz Ghiasi, Tsung-Yi Lin, Quoc V. Le
- **Comment**: Accepted at NIPS 2018
- **Journal**: None
- **Summary**: Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that activation units in convolutional layers are spatially correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together. We found that applying DropbBlock in skip connections in addition to the convolution layers increases the accuracy. Also, gradually increasing number of dropped units during training leads to better accuracy and more robust to hyperparameter choices. Extensive experiments show that DropBlock works better than dropout in regularizing convolutional networks. On ImageNet classification, ResNet-50 architecture with DropBlock achieves $78.13\%$ accuracy, which is more than $1.6\%$ improvement on the baseline. On COCO detection, DropBlock improves Average Precision of RetinaNet from $36.8\%$ to $38.4\%$.



### Joint detection and matching of feature points in multimodal images
- **Arxiv ID**: http://arxiv.org/abs/1810.12941v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12941v3)
- **Published**: 2018-10-30 18:06:58+00:00
- **Updated**: 2021-06-16 10:12:04+00:00
- **Authors**: Elad Ben Baruch, Yosi Keller
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we propose a novel Convolutional Neural Network (CNN) architecture for the joint detection and matching of feature points in images acquired by different sensors using a single forward pass. The resulting feature detector is tightly coupled with the feature descriptor, in contrast to classical approaches (SIFT, etc.), where the detection phase precedes and differs from computing the descriptor. Our approach utilizes two CNN subnetworks, the first being a Siamese CNN and the second, consisting of dual non-weight-sharing CNNs. This allows simultaneous processing and fusion of the joint and disjoint cues in the multimodal image patches. The proposed approach is experimentally shown to outperform contemporary state-of-the-art schemes when applied to multiple datasets of multimodal images. It is also shown to provide repeatable feature points detections across multisensor images, outperforming state-of-the-art detectors. To the best of our knowledge, it is the first unified approach for the detection and matching of such images.



### SDFN: Segmentation-based Deep Fusion Network for Thoracic Disease Classification in Chest X-ray Images
- **Arxiv ID**: http://arxiv.org/abs/1810.12959v2
- **DOI**: 10.1016/j.compmedimag.2019.05.005
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1810.12959v2)
- **Published**: 2018-10-30 18:37:10+00:00
- **Updated**: 2020-04-01 19:15:38+00:00
- **Authors**: Han Liu, Lei Wang, Yandong Nan, Faguang Jin, Qi Wang, Jiantao Pu
- **Comment**: 10 pages, 9 figures
- **Journal**: Comput Med Imaging Graph, 2019
- **Summary**: This study aims to automatically diagnose thoracic diseases depicted on the chest x-ray (CXR) images using deep convolutional neural networks. The existing methods generally used the entire CXR images for training purposes, but this strategy may suffer from two drawbacks. First, potential misalignment or the existence of irrelevant objects in the entire CXR images may cause unnecessary noise and thus limit the network performance. Second, the relatively low image resolution caused by the resizing operation, which is a common preprocessing procedure for training neural networks, may lead to the loss of image details, making it difficult to detect pathologies with small lesion regions. To address these issues, we present a novel method termed as segmentation-based deep fusion network (SDFN), which leverages the domain knowledge and the higherresolution information of local lung regions. Specifically, the local lung regions were identified and cropped by the Lung Region Generator (LRG). Two CNN-based classification models were then used as feature extractors to obtain the discriminative features of the entire CXR images and the cropped lung region images. Lastly, the obtained features were fused by the feature fusion module for disease classification. Evaluated by the NIH benchmark split on the Chest X-ray 14 Dataset, our experimental result demonstrated that the developed method achieved more accurate disease classification compared with the available approaches via the receiver operating characteristic (ROC) analyses. It was also found that the SDFN could localize the lesion regions more precisely as compared to the traditional method.



### A mixed signal architecture for convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1811.02636v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1811.02636v4)
- **Published**: 2018-10-30 18:51:57+00:00
- **Updated**: 2019-05-02 20:51:40+00:00
- **Authors**: Qiuwen Lou, Chenyun Pan, John McGuiness, Andras Horvath, Azad Naeemi, Michael Niemier, X. Sharon Hu
- **Comment**: 25 pages
- **Journal**: None
- **Summary**: Deep neural network (DNN) accelerators with improved energy and delay are desirable for meeting the requirements of hardware targeted for IoT and edge computing systems. Convolutional neural networks (CoNNs) belong to one of the most popular types of DNN architectures. This paper presents the design and evaluation of an accelerator for CoNNs. The system-level architecture is based on mixed-signal, cellular neural networks (CeNNs). Specifically, we present (i) the implementation of different layers, including convolution, ReLU, and pooling, in a CoNN using CeNN, (ii) modified CoNN structures with CeNN-friendly layers to reduce computational overheads typically associated with a CoNN, (iii) a mixed-signal CeNN architecture that performs CoNN computations in the analog and mixed signal domain, and (iv) design space exploration that identifies what CeNN-based algorithm and architectural features fare best compared to existing algorithms and architectures when evaluated over common datasets -- MNIST and CIFAR-10. Notably, the proposed approach can lead to 8.7$\times$ improvements in energy-delay product (EDP) per digit classification for the MNIST dataset at iso-accuracy when compared with the state-of-the-art DNN engine, while our approach could offer 4.3$\times$ improvements in EDP when compared to other network implementations for the CIFAR-10 dataset.



### Automated Diagnosis of Lymphoma with Digital Pathology Images Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1811.02668v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1811.02668v1)
- **Published**: 2018-10-30 19:40:50+00:00
- **Updated**: 2018-10-30 19:40:50+00:00
- **Authors**: Hanadi El Achi, Tatiana Belousova, Lei Chen, Amer Wahed, Iris Wang, Zhihong Hu, Zeyad Kanaan, Adan Rios, Andy N. D. Nguyen
- **Comment**: 13 pages, 2 figures, 2 tables
- **Journal**: None
- **Summary**: Recent studies have shown promising results in using Deep Learning to detect malignancy in whole slide imaging. However, they were limited to just predicting positive or negative finding for a specific neoplasm. We attempted to use Deep Learning with a convolutional neural network algorithm to build a lymphoma diagnostic model for four diagnostic categories: benign lymph node, diffuse large B cell lymphoma, Burkitt lymphoma, and small lymphocytic lymphoma. Our software was written in Python language. We obtained digital whole slide images of Hematoxylin and Eosin stained slides of 128 cases including 32 cases for each diagnostic category. Four sets of 5 representative images, 40x40 pixels in dimension, were taken for each case. A total of 2,560 images were obtained from which 1,856 were used for training, 464 for validation and 240 for testing. For each test set of 5 images, the predicted diagnosis was combined from prediction of 5 images. The test results showed excellent diagnostic accuracy at 95% for image-by-image prediction and at 10% for set-by-set prediction. This preliminary study provided a proof of concept for incorporating automated lymphoma diagnostic screen into future pathology workflow to augment the pathologists' productivity.



### R$^3$SGM: Real-time Raster-Respecting Semi-Global Matching for Power-Constrained Systems
- **Arxiv ID**: http://arxiv.org/abs/1810.12988v1
- **DOI**: 10.1109/FPT.2018.00025
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1810.12988v1)
- **Published**: 2018-10-30 20:10:02+00:00
- **Updated**: 2018-10-30 20:10:02+00:00
- **Authors**: Oscar Rahnama, Tommaso Cavallari, Stuart Golodetz, Simon Walker, Philip H. S. Torr
- **Comment**: Accepted in FPT 2018 as Oral presentation, 8 pages, 6 figures, 4
  tables
- **Journal**: 2018 International Conference on Field-Programmable Technology
  (FPT)
- **Summary**: Stereo depth estimation is used for many computer vision applications. Though many popular methods strive solely for depth quality, for real-time mobile applications (e.g. prosthetic glasses or micro-UAVs), speed and power efficiency are equally, if not more, important. Many real-world systems rely on Semi-Global Matching (SGM) to achieve a good accuracy vs. speed balance, but power efficiency is hard to achieve with conventional hardware, making the use of embedded devices such as FPGAs attractive for low-power applications. However, the full SGM algorithm is ill-suited to deployment on FPGAs, and so most FPGA variants of it are partial, at the expense of accuracy. In a non-FPGA context, the accuracy of SGM has been improved by More Global Matching (MGM), which also helps tackle the streaking artifacts that afflict SGM. In this paper, we propose a novel, resource-efficient method that is inspired by MGM's techniques for improving depth quality, but which can be implemented to run in real time on a low-power FPGA. Through evaluation on multiple datasets (KITTI and Middlebury), we show that in comparison to other real-time capable stereo approaches, we can achieve a state-of-the-art balance between accuracy, power efficiency and speed, making our approach highly desirable for use in real-time systems with limited power.



