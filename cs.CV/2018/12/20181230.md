# Arxiv Papers in cs.CV on 2018-12-30
### Machine learning in resting-state fMRI analysis
- **Arxiv ID**: http://arxiv.org/abs/1812.11477v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, q-bio.QM, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1812.11477v1)
- **Published**: 2018-12-30 06:37:46+00:00
- **Updated**: 2018-12-30 06:37:46+00:00
- **Authors**: Meenakshi Khosla, Keith Jamison, Gia H. Ngo, Amy Kuceyeski, Mert R. Sabuncu
- **Comment**: 51 pages, 6 figures
- **Journal**: None
- **Summary**: Machine learning techniques have gained prominence for the analysis of resting-state functional Magnetic Resonance Imaging (rs-fMRI) data. Here, we present an overview of various unsupervised and supervised machine learning applications to rs-fMRI. We present a methodical taxonomy of machine learning methods in resting-state fMRI. We identify three major divisions of unsupervised learning methods with regard to their applications to rs-fMRI, based on whether they discover principal modes of variation across space, time or population. Next, we survey the algorithms and rs-fMRI feature representations that have driven the success of supervised subject-level predictions. The goal is to provide a high-level overview of the burgeoning field of rs-fMRI from the perspective of machine learning applications.



### DART: Domain-Adversarial Residual-Transfer Networks for Unsupervised Cross-Domain Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1812.11478v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1812.11478v1)
- **Published**: 2018-12-30 06:49:08+00:00
- **Updated**: 2018-12-30 06:49:08+00:00
- **Authors**: Xianghong Fang, Haoli Bai, Ziyi Guo, Bin Shen, Steven Hoi, Zenglin Xu
- **Comment**: None
- **Journal**: None
- **Summary**: The accuracy of deep learning (e.g., convolutional neural networks) for an image classification task critically relies on the amount of labeled training data. Aiming to solve an image classification task on a new domain that lacks labeled data but gains access to cheaply available unlabeled data, unsupervised domain adaptation is a promising technique to boost the performance without incurring extra labeling cost, by assuming images from different domains share some invariant characteristics. In this paper, we propose a new unsupervised domain adaptation method named Domain-Adversarial Residual-Transfer (DART) learning of Deep Neural Networks to tackle cross-domain image classification tasks. In contrast to the existing unsupervised domain adaption approaches, the proposed DART not only learns domain-invariant features via adversarial training, but also achieves robust domain-adaptive classification via a residual-transfer strategy, all in an end-to-end training framework. We evaluate the performance of the proposed method for cross-domain image classification tasks on several well-known benchmark data sets, in which our method clearly outperforms the state-of-the-art approaches.



### A High-Performance CNN Method for Offline Handwritten Chinese Character Recognition and Visualization
- **Arxiv ID**: http://arxiv.org/abs/1812.11489v2
- **DOI**: 10.1007/s00500-019-04083-3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11489v2)
- **Published**: 2018-12-30 08:23:34+00:00
- **Updated**: 2019-05-28 07:33:45+00:00
- **Authors**: Pavlo Melnyk, Zhiqiang You, Keqin Li
- **Comment**: 11 pages, 4 figures; corrected typos; added figures; added section
  4.6; added details in section 3.3, 4.4
- **Journal**: None
- **Summary**: Recent researches introduced fast, compact and efficient convolutional neural networks (CNNs) for offline handwritten Chinese character recognition (HCCR). However, many of them did not address the problem of network interpretability. We propose a new architecture of a deep CNN with high recognition performance which is capable of learning deep features for visualization. A special characteristic of our model is the bottleneck layers which enable us to retain its expressiveness while reducing the number of multiply-accumulate operations and the required storage. We introduce a modification of global weighted average pooling (GWAP) - global weighted output average pooling (GWOAP). This paper demonstrates how they allow us to calculate class activation maps (CAMs) in order to indicate the most relevant input character image regions used by our CNN to identify a certain class. Evaluating on the ICDAR-2013 offline HCCR competition dataset, we show that our model enables a relative 0.83% error reduction while having 49% fewer parameters and the same computational cost compared to the current state-of-the-art single-network method trained only on handwritten data. Our solution outperforms even recent residual learning approaches.



### Impact of Ground Truth Annotation Quality on Performance of Semantic Image Segmentation of Traffic Conditions
- **Arxiv ID**: http://arxiv.org/abs/1901.00001v1
- **DOI**: 10.1007/978-3-030-16621-2_17
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.00001v1)
- **Published**: 2018-12-30 09:19:55+00:00
- **Updated**: 2018-12-30 09:19:55+00:00
- **Authors**: Vlad Taran, Yuri Gordienko, Alexandr Rokovyi, Oleg Alienin, Sergii Stirenko
- **Comment**: 10 pages, 6 figures, 2 tables, The Second International Conference on
  Computer Science, Engineering and Education Applications (ICCSEEA2019) 26-27
  January 2019, Kiev, Ukraine
- **Journal**: Hu Z., Petoukhov S., Dychka I., He M. (eds) Advances in Computer
  Science for Engineering and Education II. ICCSEEA 2019. Advances in
  Intelligent Systems and Computing, vol 938 (pp.183-193). Springer, Cham
- **Summary**: Preparation of high-quality datasets for the urban scene understanding is a labor-intensive task, especially, for datasets designed for the autonomous driving applications. The application of the coarse ground truth (GT) annotations of these datasets without detriment to the accuracy of semantic image segmentation (by the mean intersection over union - mIoU) could simplify and speedup the dataset preparation and model fine tuning before its practical application. Here the results of the comparative analysis for semantic segmentation accuracy obtained by PSPNet deep learning architecture are presented for fine and coarse annotated images from Cityscapes dataset. Two scenarios were investigated: scenario 1 - the fine GT images for training and prediction, and scenario 2 - the fine GT images for training and the coarse GT images for prediction. The obtained results demonstrated that for the most important classes the mean accuracy values of semantic image segmentation for coarse GT annotations are higher than for the fine GT ones, and the standard deviation values are vice versa. It means that for some applications some unimportant classes can be excluded and the model can be tuned further for some classes and specific regions on the coarse GT dataset without loss of the accuracy even. Moreover, this opens the perspectives to use deep neural networks for the preparation of such coarse GT datasets.



### CoSpace: Common Subspace Learning from Hyperspectral-Multispectral Correspondences
- **Arxiv ID**: http://arxiv.org/abs/1812.11501v2
- **DOI**: 10.1109/TGRS.2018.2890705
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11501v2)
- **Published**: 2018-12-30 10:03:08+00:00
- **Updated**: 2019-04-05 20:47:39+00:00
- **Authors**: Danfeng Hong, Naoto Yokoya, Jocelyn Chanussot, Xiao Xiang Zhu
- **Comment**: None
- **Journal**: IEEE Transactions on Geoscience and Remote Sensing, 2019
- **Summary**: With a large amount of open satellite multispectral imagery (e.g., Sentinel-2 and Landsat-8), considerable attention has been paid to global multispectral land cover classification. However, its limited spectral information hinders further improving the classification performance. Hyperspectral imaging enables discrimination between spectrally similar classes but its swath width from space is narrow compared to multispectral ones. To achieve accurate land cover classification over a large coverage, we propose a cross-modality feature learning framework, called common subspace learning (CoSpace), by jointly considering subspace learning and supervised classification. By locally aligning the manifold structure of the two modalities, CoSpace linearly learns a shared latent subspace from hyperspectral-multispectral(HS-MS) correspondences. The multispectral out-of-samples can be then projected into the subspace, which are expected to take advantages of rich spectral information of the corresponding hyperspectral data used for learning, and thus leads to a better classification. Extensive experiments on two simulated HSMS datasets (University of Houston and Chikusei), where HS-MS data sets have trade-offs between coverage and spectral resolution, are performed to demonstrate the superiority and effectiveness of the proposed method in comparison with previous state-of-the-art methods.



### Linear solution to the minimal absolute pose rolling shutter problem
- **Arxiv ID**: http://arxiv.org/abs/1812.11532v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11532v1)
- **Published**: 2018-12-30 13:43:59+00:00
- **Updated**: 2018-12-30 13:43:59+00:00
- **Authors**: Zuzana Kukelova, Cenek Albl, Akihiro Sugimoto, Tomas Pajdla
- **Comment**: 14th Asian Conference on Computer Vision (ACCV 2018)
- **Journal**: None
- **Summary**: This paper presents new efficient solutions to the rolling shutter camera absolute pose problem. Unlike the state-of-the-art polynomial solvers, we approach the problem using simple and fast linear solvers in an iterative scheme. We present several solutions based on fixing different sets of variables and investigate the performance of them thoroughly. We design a new alternation strategy that estimates all parameters in each iteration linearly by fixing just the non-linear terms. Our best 6-point solver, based on the new alternation technique, shows an identical or even better performance than the state-of-the-art R6P solver and is two orders of magnitude faster. In addition, a linear non-iterative solver is presented that requires a non-minimal number of 9 correspondences but provides even better results than the state-of-the-art R6P. Moreover, all proposed linear solvers provide a single solution while the state-of-the-art R6P provides up to 20 solutions which have to be pruned by expensive verification.



### Monte-Carlo Sampling applied to Multiple Instance Learning for Histological Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1812.11560v1
- **DOI**: 10.1007/978-3-030-00889-5
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1812.11560v1)
- **Published**: 2018-12-30 15:38:25+00:00
- **Updated**: 2018-12-30 15:38:25+00:00
- **Authors**: Marc Combalia, Veronica Vilaplana
- **Comment**: accepted at 4th International Workshop on Deep Learning for Medical
  Image Analysis (DLMIA), MICCAI 2018, Deep Learning in Medical Image Analysis
  and Multimodal Learning for Clinical Decision Support, Springer International
  Publishing, 2018
- **Journal**: None
- **Summary**: We propose a patch sampling strategy based on a sequential Monte-Carlo method for high resolution image classification in the context of Multiple Instance Learning. When compared with grid sampling and uniform sampling techniques, it achieves higher generalization performance. We validate the strategy on two artificial datasets and two histological datasets for breast cancer and sun exposure classification.



### Fingerprint Presentation Attack Detection: Generalization and Efficiency
- **Arxiv ID**: http://arxiv.org/abs/1812.11574v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11574v1)
- **Published**: 2018-12-30 17:23:53+00:00
- **Updated**: 2018-12-30 17:23:53+00:00
- **Authors**: Tarang Chugh, Anil K. Jain
- **Comment**: 10 pages, 10 figures
- **Journal**: None
- **Summary**: We study the problem of fingerprint presentation attack detection (PAD) under unknown PA materials not seen during PAD training. A dataset of 5,743 bonafide and 4,912 PA images of 12 different materials is used to evaluate a state-of-the-art PAD, namely Fingerprint Spoof Buster. We utilize 3D t-SNE visualization and clustering of material characteristics to identify a representative set of PA materials that cover most of PA feature space. We observe that a set of six PA materials, namely Silicone, 2D Paper, Play Doh, Gelatin, Latex Body Paint and Monster Liquid Latex provide a good representative set that should be included in training to achieve generalization of PAD. We also propose an optimized Android app of Fingerprint Spoof Buster that can run on a commodity smartphone (Xiaomi Redmi Note 4) without a significant drop in PAD performance (from TDR = 95.7% to 95.3% @ FDR = 0.2%) which can make a PA prediction in less than 300ms.



### Leishmaniasis Parasite Segmentation and Classification using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1812.11586v1
- **DOI**: 10.1007/978-3-319-94544-6
- **Categories**: **cs.CV**, cs.AI, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1812.11586v1)
- **Published**: 2018-12-30 18:42:08+00:00
- **Updated**: 2018-12-30 18:42:08+00:00
- **Authors**: Marc Górriz, Albert Aparicio, Berta Raventós, Verónica Vilaplana, Elisa Sayrol, Daniel López-Codina
- **Comment**: 10th International Conference, AMDO 2018, Palma de Mallorca, Spain,
  July 12-13, 2018, Proceedings
- **Journal**: Articulated Motion and Deformable Objects, Series volume 10945 ,
  2018, Springer International Publishing AG, part of Springer Nature
- **Summary**: Leishmaniasis is considered a neglected disease that causes thousands of deaths annually in some tropical and subtropical countries. There are various techniques to diagnose leishmaniasis of which manual microscopy is considered to be the gold standard. There is a need for the development of automatic techniques that are able to detect parasites in a robust and unsupervised manner. In this paper we present a procedure for automatizing the detection process based on a deep learning approach. We train a U-net model that successfully segments leismania parasites and classifies them into promastigotes, amastigotes and adhered parasites.



### Cascaded V-Net using ROI masks for brain tumor segmentation
- **Arxiv ID**: http://arxiv.org/abs/1812.11588v1
- **DOI**: 10.1007/978-3-319-75238-9
- **Categories**: **cs.CV**, cs.AI, cs.CY, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1812.11588v1)
- **Published**: 2018-12-30 18:51:37+00:00
- **Updated**: 2018-12-30 18:51:37+00:00
- **Authors**: Adrià Casamitjana, Marcel Catà, Irina Sánchez, Marc Combalia, Verónica Vilaplana
- **Comment**: Third International Workshop, BrainLes 2017, Held in Conjunction with
  MICCAI 2017, Quebec City, QC, Canada, September 14, 2017, Revised Selected
  Papers
- **Journal**: Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic
  Brain Injuries, Series volume 10670, 2018, Springer International Publishing
  AG, part of Springer Nature
- **Summary**: In this work we approach the brain tumor segmentation problem with a cascade of two CNNs inspired in the V-Net architecture \cite{VNet}, reformulating residual connections and making use of ROI masks to constrain the networks to train only on relevant voxels. This architecture allows dense training on problems with highly skewed class distributions, such as brain tumor segmentation, by focusing training only on the vecinity of the tumor area. We report results on BraTS2017 Training and Validation sets.



### Solar Potential Analysis of Rooftops Using Satellite Imagery
- **Arxiv ID**: http://arxiv.org/abs/1812.11606v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11606v2)
- **Published**: 2018-12-30 20:36:36+00:00
- **Updated**: 2019-12-06 11:03:51+00:00
- **Authors**: Akash Kumar
- **Comment**: None
- **Journal**: None
- **Summary**: Solar energy is one of the most important sources of renewable energy and the cleanest form of energy. In India, where solar energy could produce power around trillion kilowatt-hours in a year, our country is only able to produce power of around in gigawatts only. Many people are not aware of the solar potential of their rooftop, and hence they always think that installing solar panels is very much expensive. In this work, we introduce an approach through which we can generate a report remotely that provides the amount of solar potential of a building using only its latitude and longitude. We further evaluated various types of rooftops to make our solution more robust. We also provide an approximate area of rooftop that can be used for solar panels placement and a visual analysis of how solar panels can be placed to maximize the output of solar power at a location.



### Actor Conditioned Attention Maps for Video Action Detection
- **Arxiv ID**: http://arxiv.org/abs/1812.11631v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1812.11631v3)
- **Published**: 2018-12-30 23:12:27+00:00
- **Updated**: 2020-05-10 23:01:24+00:00
- **Authors**: Oytun Ulutan, Swati Rallapalli, Mudhakar Srivatsa, Carlos Torres, B. S. Manjunath
- **Comment**: WACV2020 Paper
- **Journal**: In The IEEE Winter Conference on Applications of Computer Vision
  (pp. 527-536) 2020
- **Summary**: While observing complex events with multiple actors, humans do not assess each actor separately, but infer from the context. The surrounding context provides essential information for understanding actions. To this end, we propose to replace region of interest(RoI) pooling with an attention module, which ranks each spatio-temporal region's relevance to a detected actor instead of cropping. We refer to these as Actor-Conditioned Attention Maps (ACAM), which amplify/dampen the features extracted from the entire scene. The resulting actor-conditioned features focus the model on regions that are relevant to the conditioned actor. For actor localization, we leverage pre-trained object detectors, which transfer better. The proposed model is efficient and our action detection pipeline achieves near real-time performance. Experimental results on AVA 2.1 and JHMDB demonstrate the effectiveness of attention maps, with improvements of 7 mAP on AVA and 4 mAP on JHMDB.



