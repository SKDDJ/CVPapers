# Arxiv Papers in cs.CV on 2018-01-18
### Sparsely Aggregated Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1801.05895v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.05895v3)
- **Published**: 2018-01-18 01:02:58+00:00
- **Updated**: 2019-02-07 07:51:35+00:00
- **Authors**: Ligeng Zhu, Ruizhi Deng, Michael Maire, Zhiwei Deng, Greg Mori, Ping Tan
- **Comment**: Accepted to ECCV 2018
- **Journal**: None
- **Summary**: We explore a key architectural aspect of deep convolutional neural networks: the pattern of internal skip connections used to aggregate outputs of earlier layers for consumption by deeper layers. Such aggregation is critical to facilitate training of very deep networks in an end-to-end manner. This is a primary reason for the widespread adoption of residual networks, which aggregate outputs via cumulative summation. While subsequent works investigate alternative aggregation operations (e.g. concatenation), we focus on an orthogonal question: which outputs to aggregate at a particular point in the network. We propose a new internal connection structure which aggregates only a sparse set of previous outputs at any given depth. Our experiments demonstrate this simple design change offers superior performance with fewer parameters and lower computational requirements. Moreover, we show that sparse aggregation allows networks to scale more robustly to 1000+ layers, thereby opening future avenues for training long-running visual processes.



### A state of the art of urban reconstruction: street, street network, vegetation, urban feature
- **Arxiv ID**: http://arxiv.org/abs/1803.04332v1
- **DOI**: None
- **Categories**: **cs.OH**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1803.04332v1)
- **Published**: 2018-01-18 02:11:18+00:00
- **Updated**: 2018-01-18 02:11:18+00:00
- **Authors**: Remi Cura, Julien Perret, Nicolas Paparoditis
- **Comment**: Extracted from PhD (chap1)
- **Journal**: None
- **Summary**: World population is raising, especially the part of people living in cities. With increased population and complex roles regarding their inhabitants and their surroundings, cities concentrate difficulties for design, planning and analysis. These tasks require a way to reconstruct/model a city. Traditionally, much attention has been given to buildings reconstruction, yet an essential part of city were neglected: streets. Streets reconstruction has been seldom researched. Streets are also complex compositions of urban features, and have a unique role for transportation (as they comprise roads). We aim at completing the recent state of the art for building reconstruction (Musialski2012) by considering all other aspect of urban reconstruction. We introduce the need for city models. Because reconstruction always necessitates data, we first analyse which data are available. We then expose a state of the art of street reconstruction, street network reconstruction, urban features reconstruction/modelling, vegetation , and urban objects reconstruction/modelling.   Although reconstruction strategies vary widely, we can order them by the role the model plays, from data driven approach, to model-based approach, to inverse procedural modelling and model catalogue matching. The main challenges seems to come from the complex nature of urban environment and from the limitations of the available data. Urban features have strong relationships, between them, and to their surrounding, as well as in hierarchical relations. Procedural modelling has the power to express these relations, and could be applied to the reconstruction of urban features via the Inverse Procedural Modelling paradigm.



### On the influence of Dice loss function in multi-class organ segmentation of abdominal CT using 3D fully convolutional networks
- **Arxiv ID**: http://arxiv.org/abs/1801.05912v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.05912v1)
- **Published**: 2018-01-18 02:46:06+00:00
- **Updated**: 2018-01-18 02:46:06+00:00
- **Authors**: Chen Shen, Holger R. Roth, Hirohisa Oda, Masahiro Oda, Yuichiro Hayashi, Kazunari Misawa, Kensaku Mori
- **Comment**: presented at MI-ken, November 2017, Takamatsu, Japan
  (http://www.ieice.org/iss/mi/)
- **Journal**: None
- **Summary**: Deep learning-based methods achieved impressive results for the segmentation of medical images. With the development of 3D fully convolutional networks (FCNs), it has become feasible to produce improved results for multi-organ segmentation of 3D computed tomography (CT) images. The results of multi-organ segmentation using deep learning-based methods not only depend on the choice of networks architecture, but also strongly rely on the choice of loss function. In this paper, we present a discussion on the influence of Dice-based loss functions for multi-class organ segmentation using a dataset of abdominal CT volumes. We investigated three different types of weighting the Dice loss functions based on class label frequencies (uniform, simple and square) and evaluate their influence on segmentation accuracies. Furthermore, we compared the influence of different initial learning rates. We achieved average Dice scores of 81.3%, 59.5% and 31.7% for uniform, simple and square types of weighting when the learning rate is 0.001, and 78.2%, 81.0% and 58.5% for each weighting when the learning rate is 0.01. Our experiments indicated a strong relationship between class balancing weights and initial learning rate in training.



### Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1801.05918v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.05918v1)
- **Published**: 2018-01-18 03:03:38+00:00
- **Updated**: 2018-01-18 03:03:38+00:00
- **Authors**: Liwen Zheng, Canmiao Fu, Yong Zhao
- **Comment**: 7 pages, 3 figures, 3 tables
- **Journal**: None
- **Summary**: Single Shot MultiBox Detector (SSD) is one of the fastest algorithms in the current object detection field, which uses fully convolutional neural network to detect all scaled objects in an image. Deconvolutional Single Shot Detector (DSSD) is an approach which introduces more context information by adding the deconvolution module to SSD. And the mean Average Precision (mAP) of DSSD on PASCAL VOC2007 is improved from SSD's 77.5% to 78.6%. Although DSSD obtains higher mAP than SSD by 1.1%, the frames per second (FPS) decreases from 46 to 11.8. In this paper, we propose a single stage end-to-end image detection model called ESSD to overcome this dilemma. Our solution to this problem is to cleverly extend better context information for the shallow layers of the best single stage (e.g. SSD) detectors. Experimental results show that our model can reach 79.4% mAP, which is higher than DSSD and SSD by 0.8 and 1.9 points respectively. Meanwhile, our testing speed is 25 FPS in Titan X GPU which is more than double the original DSSD.



### MRI Tumor Segmentation with Densely Connected 3D CNN
- **Arxiv ID**: http://arxiv.org/abs/1802.02427v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1802.02427v2)
- **Published**: 2018-01-18 05:16:26+00:00
- **Updated**: 2018-02-09 15:59:15+00:00
- **Authors**: Lele Chen, Yue Wu, Adora M. DSouza, Anas Z. Abidin, Axel Wismuller, Chenliang Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Glioma is one of the most common and aggressive types of primary brain tumors. The accurate segmentation of subcortical brain structures is crucial to the study of gliomas in that it helps the monitoring of the progression of gliomas and aids the evaluation of treatment outcomes. However, the large amount of required human labor makes it difficult to obtain the manually segmented Magnetic Resonance Imaging (MRI) data, limiting the use of precise quantitative measurements in the clinical practice. In this work, we try to address this problem by developing a 3D Convolutional Neural Network~(3D CNN) based model to automatically segment gliomas. The major difficulty of our segmentation model comes with the fact that the location, structure, and shape of gliomas vary significantly among different patients. In order to accurately classify each voxel, our model captures multi-scale contextual information by extracting features from two scales of receptive fields. To fully exploit the tumor structure, we propose a novel architecture that hierarchically segments different lesion regions of the necrotic and non-enhancing tumor~(NCR/NET), peritumoral edema~(ED) and GD-enhancing tumor~(ET). Additionally, we utilize densely connected convolutional blocks to further boost the performance. We train our model with a patch-wise training schema to mitigate the class imbalance problem. The proposed method is validated on the BraTS 2017 dataset and it achieves Dice scores of 0.72, 0.83 and 0.81 for the complete tumor, tumor core and enhancing tumor, respectively. These results are comparable to the reported state-of-the-art results, and our method is better than existing 3D-based methods in terms of compactness, time and space efficiency.



### PTB-TIR: A Thermal Infrared Pedestrian Tracking Benchmark
- **Arxiv ID**: http://arxiv.org/abs/1801.05944v3
- **DOI**: 10.1109/TMM.2019.2932615
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.05944v3)
- **Published**: 2018-01-18 05:44:32+00:00
- **Updated**: 2019-11-06 14:29:44+00:00
- **Authors**: Qiao Liu, Zhenyu He, Xin Li, Yuan Zheng
- **Comment**: 10 pages,IEEE Transactions on Multimedia (2019)
- **Journal**: None
- **Summary**: Thermal infrared (TIR) pedestrian tracking is one of the important components among numerous applications of computer vision, which has a major advantage: it can track pedestrians in total darkness. The ability to evaluate the TIR pedestrian tracker fairly, on a benchmark dataset, is significant for the development of this field. However, there is not a benchmark dataset. In this paper, we develop a TIR pedestrian tracking dataset for the TIR pedestrian tracker evaluation. The dataset includes 60 thermal sequences with manual annotations. Each sequence has nine attribute labels for the attribute based evaluation. In addition to the dataset, we carry out the large-scale evaluation experiments on our benchmark dataset using nine publicly available trackers. The experimental results help us understand the strengths and weaknesses of these trackers.In addition, in order to gain more insight into the TIR pedestrian tracker, we divide its functions into three components: feature extractor, motion model, and observation model. Then, we conduct three comparison experiments on our benchmark dataset to validate how each component affects the tracker's performance. The findings of these experiments provide some guidelines for future research. The dataset and evaluation toolkit can be downloaded at {https://github.com/QiaoLiuHit/PTB-TIR_Evaluation_toolkit}.



### 3D CNN-based classification using sMRI and MD-DTI images for Alzheimer disease studies
- **Arxiv ID**: http://arxiv.org/abs/1801.05968v1
- **DOI**: None
- **Categories**: **cs.CV**, 68U10
- **Links**: [PDF](http://arxiv.org/pdf/1801.05968v1)
- **Published**: 2018-01-18 08:42:28+00:00
- **Updated**: 2018-01-18 08:42:28+00:00
- **Authors**: Alexander Khvostikov, Karim Aderghal, Jenny Benois-Pineau, Andrey Krylov, Gwenaelle Catheline
- **Comment**: None
- **Journal**: None
- **Summary**: Computer-aided early diagnosis of Alzheimers Disease (AD) and its prodromal form, Mild Cognitive Impairment (MCI), has been the subject of extensive research in recent years. Some recent studies have shown promising results in the AD and MCI determination using structural and functional Magnetic Resonance Imaging (sMRI, fMRI), Positron Emission Tomography (PET) and Diffusion Tensor Imaging (DTI) modalities. Furthermore, fusion of imaging modalities in a supervised machine learning framework has shown promising direction of research.   In this paper we first review major trends in automatic classification methods such as feature extraction based methods as well as deep learning approaches in medical image analysis applied to the field of Alzheimer's Disease diagnostics. Then we propose our own algorithm for Alzheimer's Disease diagnostics based on a convolutional neural network and sMRI and DTI modalities fusion on hippocampal ROI using data from the Alzheimers Disease Neuroimaging Initiative (ADNI) database (http://adni.loni.usc.edu). Comparison with a single modality approach shows promising results. We also propose our own method of data augmentation for balancing classes of different size and analyze the impact of the ROI size on the classification results as well.



### Near-lossless $\ell_\infty$-constrained Image Decompression via Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1801.07987v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.07987v5)
- **Published**: 2018-01-18 12:25:42+00:00
- **Updated**: 2020-01-17 22:25:45+00:00
- **Authors**: Xi Zhang, Xiaolin Wu
- **Comment**: Accepted by DCC 2019
- **Journal**: None
- **Summary**: Recently a number of CNN-based techniques were proposed to remove image compression artifacts. As in other restoration applications, these techniques all learn a mapping from decompressed patches to the original counterparts under the ubiquitous $\ell_\infty$ metric. However, this approach is incapable of restoring distinctive image details which may be statistical outliers but have high semantic importance (e.g., tiny lesions in medical images). To overcome this weakness, we propose to incorporate an $\ell_\infty$ fidelity criterion in the design of neural network so that no small, distinctive structures of the original image can be dropped or distorted. Experimental results demonstrate that the proposed method outperforms the state-of-the-art methods in $\ell_\infty$ error metric and perceptual quality, while being competitive in $\ell_2$ error metric as well. It can restore subtle image details that are otherwise destroyed or missed by other algorithms. Our research suggests a new machine learning paradigm of ultra high fidelity image compression that is ideally suited for applications in medicine, space, and sciences.



### Invariants of multidimensional time series based on their iterated-integral signature
- **Arxiv ID**: http://arxiv.org/abs/1801.06104v2
- **DOI**: None
- **Categories**: **cs.CV**, math.RT
- **Links**: [PDF](http://arxiv.org/pdf/1801.06104v2)
- **Published**: 2018-01-18 15:53:00+00:00
- **Updated**: 2018-05-09 12:18:09+00:00
- **Authors**: Joscha Diehl, Jeremy Reizenstein
- **Comment**: complete rewrite of Section 3.3
- **Journal**: None
- **Summary**: We introduce a novel class of features for multidimensional time series, that are invariant with respect to transformations of the ambient space. The general linear group, the group of rotations and the group of permutations of the axes are considered. The starting point for their construction is Chen's iterated-integral signature.



### Robust Kronecker Component Analysis
- **Arxiv ID**: http://arxiv.org/abs/1801.06432v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1801.06432v2)
- **Published**: 2018-01-18 18:01:50+00:00
- **Updated**: 2018-11-10 20:55:20+00:00
- **Authors**: Mehdi Bahri, Yannis Panagakis, Stefanos Zafeiriou
- **Comment**: In IEEE Transactions on Pattern Analysis and Machine Intelligence,
  Special Issue on Compact and Efficient Feature Representation and Learning in
  Computer Vision, 2018. Contains appendices. arXiv admin note: text overlap
  with arXiv:1703.07886
- **Journal**: None
- **Summary**: Dictionary learning and component analysis models are fundamental for learning compact representations that are relevant to a given task (feature extraction, dimensionality reduction, denoising, etc.). The model complexity is encoded by means of specific structure, such as sparsity, low-rankness, or nonnegativity. Unfortunately, approaches like K-SVD - that learn dictionaries for sparse coding via Singular Value Decomposition (SVD) - are hard to scale to high-volume and high-dimensional visual data, and fragile in the presence of outliers. Conversely, robust component analysis methods such as the Robust Principal Component Analysis (RPCA) are able to recover low-complexity (e.g., low-rank) representations from data corrupted with noise of unknown magnitude and support, but do not provide a dictionary that respects the structure of the data (e.g., images), and also involve expensive computations. In this paper, we propose a novel Kronecker-decomposable component analysis model, coined as Robust Kronecker Component Analysis (RKCA), that combines ideas from sparse dictionary learning and robust component analysis. RKCA has several appealing properties, including robustness to gross corruption; it can be used for low-rank modeling, and leverages separability to solve significantly smaller problems. We design an efficient learning algorithm by drawing links with a restricted form of tensor factorization, and analyze its optimality and low-rankness properties. The effectiveness of the proposed approach is demonstrated on real-world applications, namely background subtraction and image denoising and completion, by performing a thorough comparison with the current state of the art.



