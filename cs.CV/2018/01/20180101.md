# Arxiv Papers in cs.CV on 2018-01-01
### Semantic Segmentation of Human Thigh Quadriceps Muscle in Magnetic Resonance Images
- **Arxiv ID**: http://arxiv.org/abs/1801.00415v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00415v2)
- **Published**: 2018-01-01 08:58:10+00:00
- **Updated**: 2018-08-09 17:02:05+00:00
- **Authors**: Ezak Ahmad, Manu Goyal, Jamie S. McPhee, Hans Degens, Moi Hoon Yap
- **Comment**: 27 pages, 7 figures and 5 tables
- **Journal**: None
- **Summary**: This paper presents an end-to-end solution for MRI thigh quadriceps segmentation. This is the first attempt that deep learning methods are used for the MRI thigh segmentation task. We use the state-of-the-art Fully Convolutional Networks with transfer learning approach for the semantic segmentation of regions of interest in MRI thigh scans. To further improve the performance of the segmentation, we propose a post-processing technique using basic image processing methods. With our proposed method, we have established a new benchmark for MRI thigh quadriceps segmentation with mean Jaccard Similarity Index of 0.9502 and processing time of 0.117 second per image.



### Least Square Error Method Robustness of Computation: What is not usually considered and taught
- **Arxiv ID**: http://arxiv.org/abs/1802.07591v1
- **DOI**: 10.15439/978-83-946253-7-5
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1802.07591v1)
- **Published**: 2018-01-01 13:55:09+00:00
- **Updated**: 2018-01-01 13:55:09+00:00
- **Authors**: Vaclav Skala
- **Comment**: None
- **Journal**: None
- **Summary**: There are many practical applications based on the Least Square Error (LSE) approximation. It is based on a square error minimization 'on a vertical' axis. The LSE method is simple and easy also for analytical purposes. However, if data span is large over several magnitudes or non-linear LSE is used, severe numerical instability can be expected. The presented contribution describes a simple method for large span of data LSE computation. It is especially convenient if large span of data are to be processed, when the 'standard' pseudoinverse matrix is ill conditioned. It is actually based on a LSE solution using orthogonal basis vectors instead of orthonormal basis vectors. The presented approach has been used for a linear regression as well as for approximation using radial basis functions.



### Facial emotion recognition using min-max similarity classifier
- **Arxiv ID**: http://arxiv.org/abs/1801.00451v1
- **DOI**: 10.1109/ICACCI.2017.8125932
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00451v1)
- **Published**: 2018-01-01 14:51:02+00:00
- **Updated**: 2018-01-01 14:51:02+00:00
- **Authors**: Olga Krestinskaya, Alex Pappachen James
- **Comment**: None
- **Journal**: 2017 International Conference on Advances in Computing,
  Communications and Informatics (ICACCI), Udupi, 2017, pp. 752-758
- **Summary**: Recognition of human emotions from the imaging templates is useful in a wide variety of human-computer interaction and intelligent systems applications. However, the automatic recognition of facial expressions using image template matching techniques suffer from the natural variability with facial features and recording conditions. In spite of the progress achieved in facial emotion recognition in recent years, the effective and computationally simple feature selection and classification technique for emotion recognition is still an open problem. In this paper, we propose an efficient and straightforward facial emotion recognition algorithm to reduce the problem of inter-class pixel mismatch during classification. The proposed method includes the application of pixel normalization to remove intensity offsets followed-up with a Min-Max metric in a nearest neighbor classifier that is capable of suppressing feature outliers. The results indicate an improvement of recognition performance from 92.85% to 98.57% for the proposed Min-Max classification method when tested on JAFFE database. The proposed emotion recognition technique outperforms the existing template matching methods.



### Quality assessment metrics for edge detection and edge-aware filtering: A tutorial review
- **Arxiv ID**: http://arxiv.org/abs/1801.00454v1
- **DOI**: 10.1109/ICACCI.2017.8126200
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00454v1)
- **Published**: 2018-01-01 15:01:15+00:00
- **Updated**: 2018-01-01 15:01:15+00:00
- **Authors**: Diana Sadykova, Alex Pappachen James
- **Comment**: None
- **Journal**: 2017 International Conference on Advances in Computing,
  Communications and Informatics (ICACCI), Udupi, 2017, pp. 2366-2369
- **Summary**: The quality assessment of edges in an image is an important topic as it helps to benchmark the performance of edge detectors, and edge-aware filters that are used in a wide range of image processing tasks. The most popular image quality metrics such as Mean squared error (MSE), Peak signal-to-noise ratio (PSNR) and Structural similarity (SSIM) metrics for assessing and justifying the quality of edges. However, they do not address the structural and functional accuracy of edges in images with a wide range of natural variabilities. In this review, we provide an overview of all the most relevant performance metrics that can be used to benchmark the quality performance of edges in images. We identify four major groups of metrics and also provide a critical insight into the evaluation protocol and governing equations.



### Automated image segmentation for detecting cell spreading for metastasizing assessments of cancer development
- **Arxiv ID**: http://arxiv.org/abs/1801.00455v1
- **DOI**: 10.1109/ICACCI.2017.8126203
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00455v1)
- **Published**: 2018-01-01 15:06:31+00:00
- **Updated**: 2018-01-01 15:06:31+00:00
- **Authors**: Sholpan Kauanova, Ivan Vorobjev, Alex Pappachen James
- **Comment**: None
- **Journal**: 2017 International Conference on Advances in Computing,
  Communications and Informatics (ICACCI), Udupi, 2017, pp. 2382-2387
- **Summary**: The automated segmentation of cells in microscopic images is an open research problem that has important implications for studies of the developmental and cancer processes based on in vitro models. In this paper, we present the approach for segmentation of the DIC images of cultured cells using G-neighbor smoothing followed by Kauwahara filtering and local standard deviation approach for boundary detection. NIH FIJI/ImageJ tools are used to create the ground truth dataset. The results of this work indicate that detection of cell boundaries using segmentation approach even in the case of realistic measurement conditions is a challenging problem.



### Script Identification in Natural Scene Image and Video Frame using Attention based Convolutional-LSTM Network
- **Arxiv ID**: http://arxiv.org/abs/1801.00470v4
- **DOI**: 10.1016/j.patcog.2018.07.034
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00470v4)
- **Published**: 2018-01-01 16:42:50+00:00
- **Updated**: 2018-08-07 17:37:58+00:00
- **Authors**: Ankan Kumar Bhunia, Aishik Konwer, Ayan Kumar Bhunia, Abir Bhowmick, Partha P. Roy, Umapada Pal
- **Comment**: The first and second authors contributed equally. Accepted in Pattern
  Recognition Journal
- **Journal**: None
- **Summary**: Script identification plays a significant role in analysing documents and videos. In this paper, we focus on the problem of script identification in scene text images and video scripts. Because of low image quality, complex background and similar layout of characters shared by some scripts like Greek, Latin, etc., text recognition in those cases become challenging. In this paper, we propose a novel method that involves extraction of local and global features using CNN-LSTM framework and weighting them dynamically for script identification. First, we convert the images into patches and feed them into a CNN-LSTM framework. Attention-based patch weights are calculated applying softmax layer after LSTM. Next, we do patch-wise multiplication of these weights with corresponding CNN to yield local features. Global features are also extracted from last cell state of LSTM. We employ a fusion technique which dynamically weights the local and global features for an individual patch. Experiments have been done in four public script identification datasets: SIW-13, CVSI2015, ICDAR-17 and MLe2e. The proposed framework achieves superior results in comparison to conventional methods.



### Aggregated Channels Network for Real-Time Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1801.00476v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00476v1)
- **Published**: 2018-01-01 16:58:25+00:00
- **Updated**: 2018-01-01 16:58:25+00:00
- **Authors**: Farzin Ghorban, Javier Mar√≠n, Yu Su, Alessandro Colombo, Anton Kummert
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have demonstrated their superiority in numerous computer vision tasks, yet their computational cost results prohibitive for many real-time applications such as pedestrian detection which is usually performed on low-consumption hardware. In order to alleviate this drawback, most strategies focus on using a two-stage cascade approach. Essentially, in the first stage a fast method generates a significant but reduced amount of high quality proposals that later, in the second stage, are evaluated by the CNN. In this work, we propose a novel detection pipeline that further benefits from the two-stage cascade strategy. More concretely, the enriched and subsequently compressed features used in the first stage are reused as the CNN input. As a consequence, a simpler network architecture, adapted for such small input sizes, allows to achieve real-time performance and obtain results close to the state-of-the-art while running significantly faster without the use of GPU. In particular, considering that the proposed pipeline runs in frame rate, the achieved performance is highly competitive. We furthermore demonstrate that the proposed pipeline on itself can serve as an effective proposal generator.



### Depth-Adaptive Computational Policies for Efficient Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1801.00508v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00508v1)
- **Published**: 2018-01-01 20:54:33+00:00
- **Updated**: 2018-01-01 20:54:33+00:00
- **Authors**: Chris Ying, Katerina Fragkiadaki
- **Comment**: presented at EMMCVPR 2017 in Venice, Italy
- **Journal**: None
- **Summary**: Current convolutional neural networks algorithms for video object tracking spend the same amount of computation for each object and video frame. However, it is harder to track an object in some frames than others, due to the varying amount of clutter, scene complexity, amount of motion, and object's distinctiveness against its background. We propose a depth-adaptive convolutional Siamese network that performs video tracking adaptively at multiple neural network depths. Parametric gating functions are trained to control the depth of the convolutional feature extractor by minimizing a joint loss of computational cost and tracking error. Our network achieves accuracy comparable to the state-of-the-art on the VOT2016 benchmark. Furthermore, our adaptive depth computation achieves higher accuracy for a given computational cost than traditional fixed-structure neural networks. The presented framework extends to other tasks that use convolutional neural networks and enables trading speed for accuracy at runtime.



### Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs for Contour Prediction
- **Arxiv ID**: http://arxiv.org/abs/1801.00524v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00524v1)
- **Published**: 2018-01-01 22:48:44+00:00
- **Updated**: 2018-01-01 22:48:44+00:00
- **Authors**: Dan Xu, Wanli Ouyang, Xavier Alameda-Pineda, Elisa Ricci, Xiaogang Wang, Nicu Sebe
- **Comment**: Accepted at NIPS 2017
- **Journal**: None
- **Summary**: Recent works have shown that exploiting multi-scale representations deeply learned via convolutional neural networks (CNN) is of tremendous importance for accurate contour detection. This paper presents a novel approach for predicting contours which advances the state of the art in two fundamental aspects, i.e. multi-scale feature generation and fusion. Different from previous works directly consider- ing multi-scale feature maps obtained from the inner layers of a primary CNN architecture, we introduce a hierarchical deep model which produces more rich and complementary representations. Furthermore, to refine and robustly fuse the representations learned at different scales, the novel Attention-Gated Conditional Random Fields (AG-CRFs) are proposed. The experiments ran on two publicly available datasets (BSDS500 and NYUDv2) demonstrate the effectiveness of the latent AG-CRF model and of the overall hierarchical framework.



