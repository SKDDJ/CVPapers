# Arxiv Papers in cs.CV on 2018-06-09
### Method to Annotate Arrhythmias by Deep Network
- **Arxiv ID**: http://arxiv.org/abs/1806.07715v1
- **DOI**: 10.1109/Cybermatics_2018.2018.00307
- **Categories**: **eess.SP**, cs.CV, cs.IR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1806.07715v1)
- **Published**: 2018-06-09 00:15:06+00:00
- **Updated**: 2018-06-09 00:15:06+00:00
- **Authors**: Weijia Lu, Jie Shuai, Shuyan Gu, Joel Xue
- **Comment**: None
- **Journal**: None
- **Summary**: This study targets to automatically annotate on arrhythmia by deep network. The investigated types include sinus rhythm, asystole (Asys), supraventricular tachycardia (Tachy), ventricular flutter or fibrillation (VF/VFL), ventricular tachycardia (VT). Methods: 13s limb lead ECG chunks from MIT malignant ventricular arrhythmia database (VFDB) and MIT normal sinus rhythm database were partitioned into subsets for 5-fold cross validation. These signals were resampled to 200Hz, filtered to remove baseline wandering, projected to 2D gray spectrum and then fed into a deep network with brand-new structure. In this network, a feature vector for a single time point was retrieved by residual layers, from which latent representation was extracted by variational autoencoder (VAE). These front portions were trained to meet a certain threshold in loss function, then fixed while training procedure switched to remaining bidirectional recurrent neural network (RNN), the very portions to predict an arrhythmia category. Attention windows were polynomial lumped on RNN outputs for learning from details to outlines. And over sampling was employed for imbalanced data. The trained model was wrapped into docker image for deployment in edge or cloud. Conclusion: Promising sensitivities were achieved in four arrhythmias and good precision rates in two ventricular arrhythmias were also observed. Moreover, it was proven that latent representation by VAE, can significantly boost the speed of convergence and accuracy.



### Localizing and Quantifying Damage in Social Media Images
- **Arxiv ID**: http://arxiv.org/abs/1806.07378v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.07378v1)
- **Published**: 2018-06-09 02:30:23+00:00
- **Updated**: 2018-06-09 02:30:23+00:00
- **Authors**: Xukun Li, Huaiyu Zhang, Doina Caragea, Muhammad Imran
- **Comment**: None
- **Journal**: None
- **Summary**: Traditional post-disaster assessment of damage heavily relies on expensive GIS data, especially remote sensing image data. In recent years, social media has become a rich source of disaster information that may be useful in assessing damage at a lower cost. Such information includes text (e.g., tweets) or images posted by eyewitnesses of a disaster. Most of the existing research explores the use of text in identifying situational awareness information useful for disaster response teams. The use of social media images to assess disaster damage is limited. In this paper, we propose a novel approach, based on convolutional neural networks and class activation maps, to locate damage in a disaster image and to quantify the degree of the damage. Our proposed approach enables the use of social network images for post-disaster damage assessment and provides an inexpensive and feasible alternative to the more expensive GIS approach.



### Fully Convolutional Networks with Sequential Information for Robust Crop and Weed Detection in Precision Farming
- **Arxiv ID**: http://arxiv.org/abs/1806.03412v1
- **DOI**: 10.1109/LRA.2018.2846289
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03412v1)
- **Published**: 2018-06-09 04:56:01+00:00
- **Updated**: 2018-06-09 04:56:01+00:00
- **Authors**: Philipp Lottes, Jens Behley, Andres Milioto, Cyrill Stachniss
- **Comment**: Accepted for publication in IEEE Robotics and Automation Letters
  (RA-L), 2018
- **Journal**: None
- **Summary**: Reducing the use of agrochemicals is an important component towards sustainable agriculture. Robots that can perform targeted weed control offer the potential to contribute to this goal, for example, through specialized weeding actions such as selective spraying or mechanical weed removal. A prerequisite of such systems is a reliable and robust plant classification system that is able to distinguish crop and weed in the field. A major challenge in this context is the fact that different fields show a large variability. Thus, classification systems have to robustly cope with substantial environmental changes with respect to weed pressure and weed types, growth stages of the crop, visual appearance, and soil conditions. In this paper, we propose a novel crop-weed classification system that relies on a fully convolutional network with an encoder-decoder structure and incorporates spatial information by considering image sequences. Exploiting the crop arrangement information that is observable from the image sequences enables our system to robustly estimate a pixel-wise labeling of the images into crop and weed, i.e., a semantic segmentation. We provide a thorough experimental evaluation, which shows that our system generalizes well to previously unseen fields under varying environmental conditions --- a key capability to actually use such systems in precision framing. We provide comparisons to other state-of-the-art approaches and show that our system substantially improves the accuracy of crop-weed classification without requiring a retraining of the model.



### Joint Stem Detection and Crop-Weed Classification for Plant-specific Treatment in Precision Farming
- **Arxiv ID**: http://arxiv.org/abs/1806.03413v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03413v1)
- **Published**: 2018-06-09 04:56:07+00:00
- **Updated**: 2018-06-09 04:56:07+00:00
- **Authors**: Philipp Lottes, Jens Behley, Nived Chebrolu, Andres Milioto, Cyrill Stachniss
- **Comment**: Submitted to the International Conference on Intelligent Robots and
  Systems (IROS), 2018
- **Journal**: None
- **Summary**: Applying agrochemicals is the default procedure for conventional weed control in crop production, but has negative impacts on the environment. Robots have the potential to treat every plant in the field individually and thus can reduce the required use of such chemicals. To achieve that, robots need the ability to identify crops and weeds in the field and must additionally select effective treatments. While certain types of weed can be treated mechanically, other types need to be treated by (selective) spraying. In this paper, we present an approach that provides the necessary information for effective plant-specific treatment. It outputs the stem location for weeds, which allows for mechanical treatments, and the covered area of the weed for selective spraying. Our approach uses an end-to-end trainable fully convolutional network that simultaneously estimates stem positions as well as the covered area of crops and weeds. It jointly learns the class-wise stem detection and the pixel-wise semantic segmentation. Experimental evaluations on different real-world datasets show that our approach is able to reliably solve this problem. Compared to state-of-the-art approaches, our approach not only substantially improves the stem detection accuracy, i.e., distinguishing crop and weed stems, but also provides an improvement in the semantic segmentation performance.



### Efficient Optimization Algorithms for Robust Principal Component Analysis and Its Variants
- **Arxiv ID**: http://arxiv.org/abs/1806.03430v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1806.03430v1)
- **Published**: 2018-06-09 07:27:01+00:00
- **Updated**: 2018-06-09 07:27:01+00:00
- **Authors**: Shiqian Ma, Necdet Serhat Aybat
- **Comment**: to appear in Proceedings of the IEEE
- **Journal**: None
- **Summary**: Robust PCA has drawn significant attention in the last decade due to its success in numerous application domains, ranging from bio-informatics, statistics, and machine learning to image and video processing in computer vision. Robust PCA and its variants such as sparse PCA and stable PCA can be formulated as optimization problems with exploitable special structures. Many specialized efficient optimization methods have been proposed to solve robust PCA and related problems. In this paper we review existing optimization methods for solving convex and nonconvex relaxations/variants of robust PCA, discuss their advantages and disadvantages, and elaborate on their convergence behaviors. We also provide some insights for possible future research directions including new algorithmic frameworks that might be suitable for implementing on multi-processor setting to handle large-scale problems.



### Abstaining Classification When Error Costs are Unequal and Unknown
- **Arxiv ID**: http://arxiv.org/abs/1806.03445v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03445v2)
- **Published**: 2018-06-09 09:00:08+00:00
- **Updated**: 2018-07-25 03:37:34+00:00
- **Authors**: Hongjiao Guan, Yingtao Zhang, H. D. Cheng, Xianglong Tang
- **Comment**: None
- **Journal**: None
- **Summary**: Abstaining classificaiton aims to reject to classify the easily misclassified examples, so it is an effective approach to increase the clasificaiton reliability and reduce the misclassification risk in the cost-sensitive applications. In such applications, different types of errors (false positive or false negative) usaully have unequal costs. And the error costs, which depend on specific applications, are usually unknown. However, current abstaining classification methods either do not distinguish the error types, or they need the cost information of misclassification and rejection, which are realized in the framework of cost-sensitive learning. In this paper, we propose a bounded-abstention method with two constraints of reject rates (BA2), which performs abstaining classification when error costs are unequal and unknown. BA2 aims to obtain the optimal area under the ROC curve (AUC) by constraining the reject rates of the positive and negative classes respectively. Specifically, we construct the receiver operating characteristic (ROC) curve, and stepwise search the optimal reject thresholds from both ends of the curve, untill the two constraints are satisfied. Experimental results show that BA2 obtains higher AUC and lower total cost than the state-of-the-art abstaining classification methods. Meanwhile, BA2 achieves controllable reject rates of the positive and negative classes.



### Robust Semantic Segmentation with Ladder-DenseNet Models
- **Arxiv ID**: http://arxiv.org/abs/1806.03465v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1806.03465v1)
- **Published**: 2018-06-09 11:48:23+00:00
- **Updated**: 2018-06-09 11:48:23+00:00
- **Authors**: Ivan Krešo, Marin Oršić, Petra Bevandić, Siniša Šegvić
- **Comment**: 4 pages, 4 figures, CVPR 2018 Robust Vision Challenge Workshop
- **Journal**: None
- **Summary**: We present semantic segmentation experiments with a model capable to perform predictions on four benchmark datasets: Cityscapes, ScanNet, WildDash and KITTI. We employ a ladder-style convolutional architecture featuring a modified DenseNet-169 model in the downsampling datapath, and only one convolution in each stage of the upsampling datapath. Due to limited computing resources, we perform the training only on Cityscapes Fine train+val, ScanNet train, WildDash val and KITTI train. We evaluate the trained model on the test subsets of the four benchmarks in concordance with the guidelines of the Robust Vision Challenge ROB 2018. The performed experiments reveal several interesting findings which we describe and discuss.



### Learning to Grasp from a Single Demonstration
- **Arxiv ID**: http://arxiv.org/abs/1806.03486v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1806.03486v1)
- **Published**: 2018-06-09 15:30:36+00:00
- **Updated**: 2018-06-09 15:30:36+00:00
- **Authors**: Pieter Van Molle, Tim Verbelen, Elias De Coninck, Cedric De Boom, Pieter Simoens, Bart Dhoedt
- **Comment**: 10 pages, 5 figures, IAS-15 2018 workshop on Learning Applications
  for Intelligent Autonomous Robots
- **Journal**: None
- **Summary**: Learning-based approaches for robotic grasping using visual sensors typically require collecting a large size dataset, either manually labeled or by many trial and errors of a robotic manipulator in the real or simulated world. We propose a simpler learning-from-demonstration approach that is able to detect the object to grasp from merely a single demonstration using a convolutional neural network we call GraspNet. In order to increase robustness and decrease the training time even further, we leverage data from previous demonstrations to quickly fine-tune a GrapNet for each new demonstration. We present some preliminary results on a grasping experiment with the Franka Panda cobot for which we can train a GraspNet with only hundreds of train iterations.



### Generalized Earley Parser: Bridging Symbolic Grammars and Sequence Data for Future Prediction
- **Arxiv ID**: http://arxiv.org/abs/1806.03497v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CL, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1806.03497v1)
- **Published**: 2018-06-09 16:07:02+00:00
- **Updated**: 2018-06-09 16:07:02+00:00
- **Authors**: Siyuan Qi, Baoxiong Jia, Song-Chun Zhu
- **Comment**: ICML 2018
- **Journal**: None
- **Summary**: Future predictions on sequence data (e.g., videos or audios) require the algorithms to capture non-Markovian and compositional properties of high-level semantics. Context-free grammars are natural choices to capture such properties, but traditional grammar parsers (e.g., Earley parser) only take symbolic sentences as inputs. In this paper, we generalize the Earley parser to parse sequence data which is neither segmented nor labeled. This generalized Earley parser integrates a grammar parser with a classifier to find the optimal segmentation and labels, and makes top-down future predictions. Experiments show that our method significantly outperforms other approaches for future human activity prediction.



### Feature Pyramid Network for Multi-Class Land Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1806.03510v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03510v2)
- **Published**: 2018-06-09 17:30:30+00:00
- **Updated**: 2018-06-19 19:17:09+00:00
- **Authors**: Selim S. Seferbekov, Vladimir I. Iglovikov, Alexander V. Buslaev, Alexey A. Shvets
- **Comment**: None
- **Journal**: None
- **Summary**: Semantic segmentation is in-demand in satellite imagery processing. Because of the complex environment, automatic categorization and segmentation of land cover is a challenging problem. Solving it can help to overcome many obstacles in urban planning, environmental engineering or natural landscape monitoring. In this paper, we propose an approach for automatic multi-class land segmentation based on a fully convolutional neural network of feature pyramid network (FPN) family. This network is consisted of pre-trained on ImageNet Resnet50 encoder and neatly developed decoder. Based on validation results, leaderboard score and our own experience this network shows reliable results for the DEEPGLOBE - CVPR 2018 land cover classification sub-challenge. Moreover, this network moderately uses memory that allows using GTX 1080 or 1080 TI video cards to perform whole training and makes pretty fast predictions.



### Cell Detection with Star-convex Polygons
- **Arxiv ID**: http://arxiv.org/abs/1806.03535v2
- **DOI**: 10.1007/978-3-030-00934-2_30
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03535v2)
- **Published**: 2018-06-09 19:38:24+00:00
- **Updated**: 2018-11-08 15:25:25+00:00
- **Authors**: Uwe Schmidt, Martin Weigert, Coleman Broaddus, Gene Myers
- **Comment**: Conference paper at MICCAI 2018
- **Journal**: None
- **Summary**: Automatic detection and segmentation of cells and nuclei in microscopy images is important for many biological applications. Recent successful learning-based approaches include per-pixel cell segmentation with subsequent pixel grouping, or localization of bounding boxes with subsequent shape refinement. In situations of crowded cells, these can be prone to segmentation errors, such as falsely merging bordering cells or suppressing valid cell instances due to the poor approximation with bounding boxes. To overcome these issues, we propose to localize cell nuclei via star-convex polygons, which are a much better shape representation as compared to bounding boxes and thus do not need shape refinement. To that end, we train a convolutional neural network that predicts for every pixel a polygon for the cell instance at that position. We demonstrate the merits of our approach on two synthetic datasets and one challenging dataset of diverse fluorescence microscopy images.



### Representation Learning on Graphs with Jumping Knowledge Networks
- **Arxiv ID**: http://arxiv.org/abs/1806.03536v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1806.03536v2)
- **Published**: 2018-06-09 19:49:57+00:00
- **Updated**: 2018-06-25 19:52:28+00:00
- **Authors**: Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, Stefanie Jegelka
- **Comment**: ICML 2018, accepted as a long oral presentation
- **Journal**: None
- **Summary**: Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of "neighboring" nodes that a node's representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture -- jumping knowledge (JK) networks -- that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models' performance.



### Sparse Over-complete Patch Matching
- **Arxiv ID**: http://arxiv.org/abs/1806.03556v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.03556v2)
- **Published**: 2018-06-09 23:18:11+00:00
- **Updated**: 2018-11-08 07:21:38+00:00
- **Authors**: Akila Pemasiri, Kien Nguyen, Sridha Sridharan, Clinton Fookes
- **Comment**: None
- **Journal**: None
- **Summary**: Image patch matching, which is the process of identifying corresponding patches across images, has been used as a subroutine for many computer vision and image processing tasks. State -of-the-art patch matching techniques take image patches as input to a convolutional neural network to extract the patch features and evaluate their similarity. Our aim in this paper is to improve on the state of the art patch matching techniques by observing the fact that a sparse-overcomplete representation of an image posses statistical properties of natural visual scenes which can be exploited for patch matching. We propose a new paradigm which encodes image patch details by encoding the patch and subsequently using this sparse representation as input to a neural network to compare the patches. As sparse coding is based on a generative model of natural image patches, it can represent the patch in terms of the fundamental visual components from which it has been composed of, leading to similar sparse codes for patches which are built from similar components. Once the sparse coded features are extracted, we employ a fully-connected neural network, which captures the non-linear relationships between features, for comparison. We have evaluated our approach using the Liberty and Notredame subsets of the popular UBC patch dataset and set a new benchmark outperforming all state-of-the-art patch matching techniques for these datasets.



