# Arxiv Papers in cs.CV on 2018-06-23
### Towards Practical Visual Search Engine within Elasticsearch
- **Arxiv ID**: http://arxiv.org/abs/1806.08896v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.08896v3)
- **Published**: 2018-06-23 02:47:51+00:00
- **Updated**: 2019-03-17 00:22:20+00:00
- **Authors**: Cun Mu, Jun Zhao, Guang Yang, Jing Zhang, Zheng Yan
- **Comment**: Accepted by SIGIR eCom'18
- **Journal**: None
- **Summary**: In this paper, we describe our end-to-end content-based image retrieval system built upon Elasticsearch, a well-known and popular textual search engine. As far as we know, this is the first time such a system has been implemented in eCommerce, and our efforts have turned out to be highly worthwhile. We end up with a novel and exciting visual search solution that is extremely easy to be deployed, distributed, scaled and monitored in a cost-friendly manner. Moreover, our platform is intrinsically flexible in supporting multimodal searches, where visual and textual information can be jointly leveraged in retrieval.   The core idea is to encode image feature vectors into a collection of string tokens in a way such that closer vectors will share more string tokens in common. By doing that, we can utilize Elasticsearch to efficiently retrieve similar images based on similarities within encoded sting tokens. As part of the development, we propose a novel vector to string encoding method, which is shown to substantially outperform the previous ones in terms of both precision and latency.   First-hand experiences in implementing this Elasticsearch-based platform are extensively addressed, which should be valuable to practitioners also interested in building visual search engine on top of Elasticsearch.



### Privacy-Protective-GAN for Face De-identification
- **Arxiv ID**: http://arxiv.org/abs/1806.08906v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.08906v1)
- **Published**: 2018-06-23 04:30:57+00:00
- **Updated**: 2018-06-23 04:30:57+00:00
- **Authors**: Yifan Wu, Fan Yang, Haibin Ling
- **Comment**: None
- **Journal**: None
- **Summary**: Face de-identification has become increasingly important as the image sources are explosively growing and easily accessible. The advance of new face recognition techniques also arises people's concern regarding the privacy leakage. The mainstream pipelines of face de-identification are mostly based on the k-same framework, which bears critiques of low effectiveness and poor visual quality. In this paper, we propose a new framework called Privacy-Protective-GAN (PP-GAN) that adapts GAN with novel verificator and regulator modules specially designed for the face de-identification problem to ensure generating de-identified output with retained structure similarity according to a single input. We evaluate the proposed approach in terms of privacy protection, utility preservation, and structure similarity. Our approach not only outperforms existing face de-identification techniques but also provides a practical framework of adapting GAN with priors of domain knowledge.



### Toward Performance Optimization in IoT-based Next-Gen Wireless Sensor Networks
- **Arxiv ID**: http://arxiv.org/abs/1806.09980v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV, cs.NI, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1806.09980v1)
- **Published**: 2018-06-23 08:42:01+00:00
- **Updated**: 2018-06-23 08:42:01+00:00
- **Authors**: Muzammil Behzad, Manal Abdullah, Muhammad Talal Hassan, Yao Ge, Mahmood Ashraf Khan
- **Comment**: 45 pages, 22 figures, pending article. arXiv admin note: substantial
  text overlap with arXiv:1712.04259
- **Journal**: None
- **Summary**: In this paper, we propose a novel framework for performance optimization in Internet of Things (IoT)-based next-generation wireless sensor networks. In particular, a computationally-convenient system is presented to combat two major research problems in sensor networks. First is the conventionally-tackled resource optimization problem which triggers the drainage of battery at a faster rate within a network. Such drainage promotes inefficient resource usage thereby causing sudden death of the network. The second main bottleneck for such networks is that of data degradation. This is because the nodes in such networks communicate via a wireless channel, where the inevitable presence of noise corrupts the data making it unsuitable for practical applications. Therefore, we present a layer-adaptive method via 3-tier communication mechanism to ensure the efficient use of resources. This is supported with a mathematical coverage model that deals with the formation of coverage holes. We also present a transform-domain based robust algorithm to effectively remove the unwanted components from the data. Our proposed framework offers a handy algorithm that enjoys desirable complexity for real-time applications as shown by the extensive simulation results.



### Multi-Exposure Image Fusion Based on Exposure Compensation
- **Arxiv ID**: http://arxiv.org/abs/1806.09607v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.09607v1)
- **Published**: 2018-06-23 09:58:35+00:00
- **Updated**: 2018-06-23 09:58:35+00:00
- **Authors**: Yuma Kinoshita, Taichi Yoshida, Sayaka Shiota, Hitoshi Kiya
- **Comment**: in Proc. IEEE International Conference on Acoustics, Speech and
  Signal Processing, pp.1388-1392, Calgary, Alberta, Canada, 19th April, 2018.
  arXiv admin note: substantial text overlap with arXiv:1805.11211
- **Journal**: None
- **Summary**: This paper proposes a novel multi-exposure image fusion method based on exposure compensation. Multi-exposure image fusion is a method to produce images without color saturation regions, by using photos with different exposures. However, in conventional works, it is unclear how to determine appropriate exposure values, and moreover, it is difficult to set appropriate exposure values at the time of photographing due to time constraints. In the proposed method, the luminance of the input multi-exposure images is adjusted on the basis of the relationship between exposure values and pixel values, where the relationship is obtained by assuming that a digital camera has a linear response function. The use of a local contrast enhancement method is also considered to improve input multi-exposure images. The compensated images are finally combined by one of existing multi-exposure image fusion methods. In some experiments, the effectiveness of the proposed method are evaluated in terms of the tone mapped image quality index, statistical naturalness, and discrete entropy, by comparing the proposed one with conventional ones.



### Evaluation of Momentum Diverse Input Iterative Fast Gradient Sign Method (M-DI2-FGSM) Based Attack Method on MCS 2018 Adversarial Attacks on Black Box Face Recognition System
- **Arxiv ID**: http://arxiv.org/abs/1806.08970v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.08970v1)
- **Published**: 2018-06-23 14:05:16+00:00
- **Updated**: 2018-06-23 14:05:16+00:00
- **Authors**: Md Ashraful Alam Milton
- **Comment**: The Code is available for download in the following github link:
  https://github.com/miltonbd/mcs_2018_adversarial_attack . arXiv admin note:
  text overlap with arXiv:1803.06978 by other authors
- **Journal**: None
- **Summary**: The convolutional neural network is the crucial tool for the recent success of deep learning based methods on various computer vision tasks like classification, segmentation, and detection. Convolutional neural networks achieved state-of-the-art performance in these tasks and every day pushing the limit of computer vision and AI. However, adversarial attack on computer vision systems is threatening their application in the real life and in safety-critical applications. Necessarily, Finding adversarial examples are important to detect susceptible models to attack and take safeguard measures to overcome the adversarial attacks. In this regard, MCS 2018 Adversarial Attacks on Black Box Face Recognition challenge aims to facilitate the research of finding new adversarial attack techniques and their effectiveness in generating adversarial examples. In this challenge, the attack"s nature is targeted-attack on the black-box neural network where we have no knowledge about black-block"s inner structure. The attacker must modify a set of five images of a single person so that the neural network miss-classify them as target image which is a set of five images of another person. In this competition, we applied Momentum Diverse Input Iterative Fast Gradient Sign Method (M-DI2-FGSM) to make an adversarial attack on black-box face recognition system. We tested our method on MCS 2018 Adversarial Attacks on Black Box Face Recognition challenge and found competitive result. Our solution got validation score 1.404 which better than baseline score 1.407 and stood 14 place among 132 teams in the leader-board. Further improvement can be achieved by finding improved feature extraction from source image, carefully chosen hyper-parameters, finding improved substitute model of the black-box and better optimization method.



### Extracting Tree-structures in CT data by Tracking Multiple Statistically Ranked Hypotheses
- **Arxiv ID**: http://arxiv.org/abs/1806.08981v2
- **DOI**: 10.1002/mp.13711
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.08981v2)
- **Published**: 2018-06-23 15:03:09+00:00
- **Updated**: 2019-07-10 15:23:20+00:00
- **Authors**: Raghavendra Selvan, Jens Petersen, Jesper H Pedersen, Marleen de Bruijne
- **Comment**: Accepted for publication at the International Journal of Medical
  Physics and Practice
- **Journal**: None
- **Summary**: In this work, we adapt a method based on multiple hypothesis tracking (MHT) that has been shown to give state-of-the-art vessel segmentation results in interactive settings, for the purpose of extracting trees. Regularly spaced tubular templates are fit to image data forming local hypotheses. These local hypotheses are used to construct the MHT tree, which is then traversed to make segmentation decisions. However, some critical parameters in this method are scale-dependent and have an adverse effect when tracking structures of varying dimensions. We propose to use statistical ranking of local hypotheses in constructing the MHT tree, which yields a probabilistic interpretation of scores across scales and helps alleviate the scale-dependence of MHT parameters. This enables our method to track trees starting from a single seed point. Our method is evaluated on chest CT data to extract airway trees and coronary arteries. In both cases, we show that our method performs significantly better than the original MHT method.



### Stroke-based Character Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1806.08990v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1806.08990v3)
- **Published**: 2018-06-23 15:47:34+00:00
- **Updated**: 2018-11-29 13:44:28+00:00
- **Authors**: Zhewei Huang, Wen Heng, Yuanzheng Tao, Shuchang Zhou
- **Comment**: 6 pages, 7 figures
- **Journal**: None
- **Summary**: Background elimination for noisy character images or character images from real scene is still a challenging problem, due to the bewildering backgrounds, uneven illumination, low resolution and different distortions. We propose a stroke-based character reconstruction(SCR) method that use a weighted quadratic Bezier curve(WQBC) to represent strokes of a character. Only training on our synthetic data, our stroke extractor can achieve excellent reconstruction effect in real scenes. Meanwhile. It can also help achieve great ability in defending adversarial attacks of character recognizers.



### Leveraging Implicit Spatial Information in Global Features for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1806.08991v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.08991v1)
- **Published**: 2018-06-23 15:47:46+00:00
- **Updated**: 2018-06-23 15:47:46+00:00
- **Authors**: Pierre Jacob, David Picard, Aymeric Histace, Edouard Klein
- **Comment**: 8 pages, 2 figures and 1 table. Draft paper for conference, IEEE
  International Conference on Image Processing (ICIP) 2018
- **Journal**: None
- **Summary**: Most image retrieval methods use global features that aggregate local distinctive patterns into a single representation. However, the aggregation process destroys the relative spatial information by considering orderless sets of local descriptors. We propose to integrate relative spatial information into the aggregation process by taking into account co-occurrences of local patterns in a tensor framework. The resulting signature called Improved Spatial Tensor Aggregation (ISTA) is able to reach state of the art performances on well known datasets such as Holidays, Oxford5k and Paris6k.



### Considerations for a PAP Smear Image Analysis System with CNN Features
- **Arxiv ID**: http://arxiv.org/abs/1806.09025v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.09025v1)
- **Published**: 2018-06-23 19:49:19+00:00
- **Updated**: 2018-06-23 19:49:19+00:00
- **Authors**: Srishti Gautam, Harinarayan K. K., Nirmal Jith, Anil K. Sao, Arnav Bhavsar, Adarsh Natarajan
- **Comment**: None
- **Journal**: None
- **Summary**: It has been shown that for automated PAP-smear image classification, nucleus features can be very informative. Therefore, the primary step for automated screening can be cell-nuclei detection followed by segmentation of nuclei in the resulting single cell PAP-smear images. We propose a patch based approach using CNN for segmentation of nuclei in single cell images. We then pose the question of ion of segmentation for classification using representation learning with CNN, and whether low-level CNN features may be useful for classification. We suggest a CNN-based feature level analysis and a transfer learning based approach for classification using both segmented as well full single cell images. We also propose a decision-tree based approach for classification. Experimental results demonstrate the effectiveness of the proposed algorithms individually (with low-level CNN features), and simultaneously proving the sufficiency of cell-nuclei detection (rather than accurate segmentation) for classification. Thus, we propose a system for analysis of multi-cell PAP-smear images consisting of a simple nuclei detection algorithm followed by classification using transfer learning.



### Variational Wasserstein Clustering
- **Arxiv ID**: http://arxiv.org/abs/1806.09045v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.09045v4)
- **Published**: 2018-06-23 22:00:25+00:00
- **Updated**: 2018-07-26 06:22:43+00:00
- **Authors**: Liang Mi, Wen Zhang, Xianfeng Gu, Yalin Wang
- **Comment**: Accepted to ECCV 2018
- **Journal**: None
- **Summary**: We propose a new clustering method based on optimal transportation. We solve optimal transportation with variational principles, and investigate the use of power diagrams as transportation plans for aggregating arbitrary domains into a fixed number of clusters. We iteratively drive centroids through target domains while maintaining the minimum clustering energy by adjusting the power diagrams. Thus, we simultaneously pursue clustering and the Wasserstein distances between the centroids and the target domains, resulting in a measure-preserving mapping. We demonstrate the use of our method in domain adaptation, remeshing, and representation learning on synthetic and real data.



### Disease Classification in Metagenomics with 2D Embeddings and Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1806.09046v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1806.09046v1)
- **Published**: 2018-06-23 22:01:27+00:00
- **Updated**: 2018-06-23 22:01:27+00:00
- **Authors**: Thanh Hai Nguyen, Edi Prifti, Yann Chevaleyre, Nataliya Sokolovska, Jean-Daniel Zucker
- **Comment**: The annual French Conference in Machine Learning (CAp 2018) - La
  Conf\'erence sur l'Apprentissage automatique (CAp), June 2018, Rouen, France.
  Oral presentation C12. http://cap2018.litislab.fr/Programme-en.html 10 pages,
  7 figures, 4 tables
- **Journal**: None
- **Summary**: Deep learning (DL) techniques have shown unprecedented success when applied to images, waveforms, and text. Generally, when the sample size ($N$) is much bigger than the number of features ($d$), DL often outperforms other machine learning (ML) techniques, often through the use of Convolutional Neural Networks (CNNs). However, in many bioinformatics fields (including metagenomics), we encounter the opposite situation where $d$ is significantly greater than $N$. In these situations, applying DL techniques would lead to severe overfitting.   Here we aim to improve classification of various diseases with metagenomic data through the use of CNNs. For this we proposed to represent metagenomic data as images. The proposed Met2Img approach relies on taxonomic and t-SNE embeddings to transform abundance data into "synthetic images".   We applied our approach to twelve benchmark data sets including more than 1400 metagenomic samples. Our results show significant improvements over the state-of-the-art algorithms (Random Forest (RF), Support Vector Machine (SVM)). We observe that the integration of phylogenetic information alongside abundance data improves classification. The proposed approach is not only important in classification setting but also allows to visualize complex metagenomic data. The Met2Img is implemented in Python.



