# Arxiv Papers in cs.CV on 2018-03-30
### Deep learning-based virtual histology staining using auto-fluorescence of label-free tissue
- **Arxiv ID**: http://arxiv.org/abs/1803.11293v1
- **DOI**: 10.1038/s41551-019-0362-y
- **Categories**: **cs.CV**, cs.LG, physics.med-ph, 68T01, 68T05, 68U10, 62M45, 78M32, 92C50, 92C55, 94A08, I.2; I.2.1; I.2.6; I.2.10; I.3; I.3.3; I.4.3; I.4.4; I.4.9; J.3
- **Links**: [PDF](http://arxiv.org/pdf/1803.11293v1)
- **Published**: 2018-03-30 00:23:22+00:00
- **Updated**: 2018-03-30 00:23:22+00:00
- **Authors**: Yair Rivenson, Hongda Wang, Zhensong Wei, Yibo Zhang, Harun Gunaydin, Aydogan Ozcan
- **Comment**: None
- **Journal**: Nature Biomedical Engineering (2019)
- **Summary**: Histological analysis of tissue samples is one of the most widely used methods for disease diagnosis. After taking a sample from a patient, it goes through a lengthy and laborious preparation, which stains the tissue to visualize different histological features under a microscope. Here, we demonstrate a label-free approach to create a virtually-stained microscopic image using a single wide-field auto-fluorescence image of an unlabeled tissue sample, bypassing the standard histochemical staining process, saving time and cost. This method is based on deep learning, and uses a convolutional neural network trained using a generative adversarial network model to transform an auto-fluorescence image of an unlabeled tissue section into an image that is equivalent to the bright-field image of the stained-version of the same sample. We validated this method by successfully creating virtually-stained microscopic images of human tissue samples, including sections of salivary gland, thyroid, kidney, liver and lung tissue, also covering three different stains. This label-free virtual-staining method eliminates cumbersome and costly histochemical staining procedures, and would significantly simplify tissue preparation in pathology and histology fields.



### Pancreas Segmentation in CT and MRI Images via Domain Specific Network Designing and Recurrent Neural Contextual Learning
- **Arxiv ID**: http://arxiv.org/abs/1803.11303v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11303v1)
- **Published**: 2018-03-30 01:31:53+00:00
- **Updated**: 2018-03-30 01:31:53+00:00
- **Authors**: Jinzheng Cai, Le Lu, Fuyong Xing, Lin Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic pancreas segmentation in radiology images, eg., computed tomography (CT) and magnetic resonance imaging (MRI), is frequently required by computer-aided screening, diagnosis, and quantitative assessment. Yet pancreas is a challenging abdominal organ to segment due to the high inter-patient anatomical variability in both shape and volume metrics. Recently, convolutional neural networks (CNNs) have demonstrated promising performance on accurate segmentation of pancreas. However, the CNN-based method often suffers from segmentation discontinuity for reasons such as noisy image quality and blurry pancreatic boundary. From this point, we propose to introduce recurrent neural networks (RNNs) to address the problem of spatial non-smoothness of inter-slice pancreas segmentation across adjacent image slices. To inference initial segmentation, we first train a 2D CNN sub-network, where we modify its network architecture with deep-supervision and multi-scale feature map aggregation so that it can be trained from scratch with small-sized training data and presents superior performance than transferred models. Thereafter, the successive CNN outputs are processed by another RNN sub-network, which refines the consistency of segmented shapes. More specifically, the RNN sub-network consists convolutional long short-term memory (CLSTM) units in both top-down and bottom-up directions, which regularizes the segmentation of an image by integrating predictions of its neighboring slices. We train the stacked CNN-RNN model end-to-end and perform quantitative evaluations on both CT and MRI images.



### Robust Subspace Clustering with Compressed Data
- **Arxiv ID**: http://arxiv.org/abs/1803.11305v6
- **DOI**: 10.1109/TIP.2019.2917857
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11305v6)
- **Published**: 2018-03-30 01:34:55+00:00
- **Updated**: 2019-08-22 09:36:46+00:00
- **Authors**: Guangcan Liu, Zhao Zhang, Qingshan Liu, Kongkai Xiong
- **Comment**: None
- **Journal**: IEEE Transactions on Image Processing, 2019
- **Summary**: Dimension reduction is widely regarded as an effective way for decreasing the computation, storage and communication loads of data-driven intelligent systems, leading to a growing demand for statistical methods that allow analysis (e.g., clustering) of compressed data. We therefore study in this paper a novel problem called compressive robust subspace clustering, which is to perform robust subspace clustering with the compressed data, and which is generated by projecting the original high-dimensional data onto a lower-dimensional subspace chosen at random. Given only the compressed data and sensing matrix, the proposed method, row space pursuit (RSP), recovers the authentic row space that gives correct clustering results under certain conditions. Extensive experiments show that RSP is distinctly better than the competing methods, in terms of both clustering accuracy and computational efficiency.



### Task-Driven Super Resolution: Object Detection in Low-resolution Images
- **Arxiv ID**: http://arxiv.org/abs/1803.11316v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11316v1)
- **Published**: 2018-03-30 02:15:24+00:00
- **Updated**: 2018-03-30 02:15:24+00:00
- **Authors**: Muhammad Haris, Greg Shakhnarovich, Norimichi Ukita
- **Comment**: None
- **Journal**: None
- **Summary**: We consider how image super resolution (SR) can contribute to an object detection task in low-resolution images. Intuitively, SR gives a positive impact on the object detection task. While several previous works demonstrated that this intuition is correct, SR and detector are optimized independently in these works. This paper proposes a novel framework to train a deep neural network where the SR sub-network explicitly incorporates a detection loss in its training objective, via a tradeoff with a traditional detection loss. This end-to-end training procedure allows us to train SR preprocessing for any differentiable detector. We demonstrate that our task-driven SR consistently and significantly improves accuracy of an object detector on low-resolution images for a variety of conditions and scaling factors.



### Transductive Unbiased Embedding for Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1803.11320v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11320v1)
- **Published**: 2018-03-30 02:43:15+00:00
- **Updated**: 2018-03-30 02:43:15+00:00
- **Authors**: Jie Song, Chengchao Shen, Yezhou Yang, Yang Liu, Mingli Song
- **Comment**: Accepted to CVPR2018
- **Journal**: None
- **Summary**: Most existing Zero-Shot Learning (ZSL) methods have the strong bias problem, in which instances of unseen (target) classes tend to be categorized as one of the seen (source) classes. So they yield poor performance after being deployed in the generalized ZSL settings. In this paper, we propose a straightforward yet effective method named Quasi-Fully Supervised Learning (QFSL) to alleviate the bias problem. Our method follows the way of transductive learning, which assumes that both the labeled source images and unlabeled target images are available for training. In the semantic embedding space, the labeled source images are mapped to several fixed points specified by the source categories, and the unlabeled target images are forced to be mapped to other points specified by the target categories. Experiments conducted on AwA2, CUB and SUN datasets demonstrate that our method outperforms existing state-of-the-art approaches by a huge margin of 9.3~24.5% following generalized ZSL settings, and by a large margin of 0.2~16.2% following conventional ZSL settings.



### Learning View-Specific Deep Networks for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1803.11333v1
- **DOI**: 10.1109/TIP.2018.2818438
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11333v1)
- **Published**: 2018-03-30 04:10:06+00:00
- **Updated**: 2018-03-30 04:10:06+00:00
- **Authors**: Zhanxiang Feng, Jianhuang Lai, Xiaohua Xie
- **Comment**: 12 pages, 8 figures, accepted by IEEE Transactions on image
  processing
- **Journal**: Feng Z, Lai J, Xie X. Learning View-Specific Deep Networks for
  Person Re-Identification[J]. IEEE Transactions on Image Processing, 2018
- **Summary**: In recent years, a growing body of research has focused on the problem of person re-identification (re-id). The re-id techniques attempt to match the images of pedestrians from disjoint non-overlapping camera views. A major challenge of re-id is the serious intra-class variations caused by changing viewpoints. To overcome this challenge, we propose a deep neural network-based framework which utilizes the view information in the feature extraction stage. The proposed framework learns a view-specific network for each camera view with a cross-view Euclidean constraint (CV-EC) and a cross-view center loss (CV-CL). We utilize CV-EC to decrease the margin of the features between diverse views and extend the center loss metric to a view-specific version to better adapt the re-id problem. Moreover, we propose an iterative algorithm to optimize the parameters of the view-specific networks from coarse to fine. The experiments demonstrate that our approach significantly improves the performance of the existing deep networks and outperforms the state-of-the-art methods on the VIPeR, CUHK01, CUHK03, SYSU-mReId, and Market-1501 benchmarks.



### Efficient and Deep Person Re-Identification using Multi-Level Similarity
- **Arxiv ID**: http://arxiv.org/abs/1803.11353v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11353v2)
- **Published**: 2018-03-30 06:18:28+00:00
- **Updated**: 2018-04-02 03:06:54+00:00
- **Authors**: Yiluan Guo, Ngai-Man Cheung
- **Comment**: To appear in CVPR2018
- **Journal**: None
- **Summary**: Person Re-Identification (ReID) requires comparing two images of person captured under different conditions. Existing work based on neural networks often computes the similarity of feature maps from one single convolutional layer. In this work, we propose an efficient, end-to-end fully convolutional Siamese network that computes the similarities at multiple levels. We demonstrate that multi-level similarity can improve the accuracy considerably using low-complexity network structures in ReID problem. Specifically, first, we use several convolutional layers to extract the features of two input images. Then, we propose Convolution Similarity Network to compute the similarity score maps for the inputs. We use spatial transformer networks (STNs) to determine spatial attention. We propose to apply efficient depth-wise convolution to compute the similarity. The proposed Convolution Similarity Networks can be inserted into different convolutional layers to extract visual similarities at different levels. Furthermore, we use an improved ranking loss to further improve the performance. Our work is the first to propose to compute visual similarities at low, middle and high levels for ReID. With extensive experiments and analysis, we demonstrate that our system, compact yet effective, can achieve competitive results with much smaller model size and computational complexity.



### DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer
- **Arxiv ID**: http://arxiv.org/abs/1803.11361v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11361v1)
- **Published**: 2018-03-30 06:49:30+00:00
- **Updated**: 2018-03-30 06:49:30+00:00
- **Authors**: Joseph Suarez, Justin Johnson, Fei-Fei Li
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel Dynamic Differentiable Reasoning (DDR) framework for jointly learning branching programs and the functions composing them; this resolves a significant nondifferentiability inhibiting recent dynamic architectures. We apply our framework to two settings in two highly compact and data efficient architectures: DDRprog for CLEVR Visual Question Answering and DDRstack for reverse Polish notation expression evaluation. DDRprog uses a recurrent controller to jointly predict and execute modular neural programs that directly correspond to the underlying question logic; it explicitly forks subprocesses to handle logical branching. By effectively leveraging additional structural supervision, we achieve a large improvement over previous approaches in subtask consistency and a small improvement in overall accuracy. We further demonstrate the benefits of structural supervision in the RPN setting: the inclusion of a stack assumption in DDRstack allows our approach to generalize to long expressions where an LSTM fails the task.



### Joint Optimization Framework for Learning with Noisy Labels
- **Arxiv ID**: http://arxiv.org/abs/1803.11364v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1803.11364v1)
- **Published**: 2018-03-30 06:53:40+00:00
- **Updated**: 2018-03-30 06:53:40+00:00
- **Authors**: Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, Kiyoharu Aizawa
- **Comment**: To appear at CVPR 2018 (poster), including supplementary material
- **Journal**: CVPR 2018, pp.5552--5550
- **Summary**: Deep neural networks (DNNs) trained on large-scale datasets have exhibited significant performance in image classification. Many large-scale datasets are collected from websites, however they tend to contain inaccurate labels that are termed as noisy labels. Training on such noisy labeled datasets causes performance degradation because DNNs easily overfit to noisy labels. To overcome this problem, we propose a joint optimization framework of learning DNN parameters and estimating true labels. Our framework can correct labels during training by alternating update of network parameters and labels. We conduct experiments on the noisy CIFAR-10 datasets and the Clothing1M dataset. The results indicate that our approach significantly outperforms other state-of-the-art methods.



### Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1803.11365v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11365v1)
- **Published**: 2018-03-30 06:53:43+00:00
- **Updated**: 2018-03-30 06:53:43+00:00
- **Authors**: Naoto Inoue, Ryosuke Furuta, Toshihiko Yamasaki, Kiyoharu Aizawa
- **Comment**: To appear at CVPR2018 (poster), including supplementary materials
- **Journal**: None
- **Summary**: Can we detect common objects in a variety of image domains without instance-level annotations? In this paper, we present a framework for a novel task, cross-domain weakly supervised object detection, which addresses this question. For this paper, we have access to images with instance-level annotations in a source domain (e.g., natural image) and images with image-level annotations in a target domain (e.g., watercolor). In addition, the classes to be detected in the target domain are all or a subset of those in the source domain. Starting from a fully supervised object detector, which is pre-trained on the source domain, we propose a two-step progressive domain adaptation technique by fine-tuning the detector on two types of artificially and automatically generated samples. We test our methods on our newly collected datasets containing three image domains, and achieve an improvement of approximately 5 to 20 percentage points in terms of mean average precision (mAP) compared to the best-performing baselines.



### Disentangling Features in 3D Face Shapes for Joint Face Reconstruction and Recognition
- **Arxiv ID**: http://arxiv.org/abs/1803.11366v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11366v1)
- **Published**: 2018-03-30 06:58:40+00:00
- **Updated**: 2018-03-30 06:58:40+00:00
- **Authors**: Feng Liu, Ronghang Zhu, Dan Zeng, Qijun Zhao, Xiaoming Liu
- **Comment**: CVPR 2018
- **Journal**: None
- **Summary**: This paper proposes an encoder-decoder network to disentangle shape features during 3D face reconstruction from single 2D images, such that the tasks of reconstructing accurate 3D face shapes and learning discriminative shape features for face recognition can be accomplished simultaneously. Unlike existing 3D face reconstruction methods, our proposed method directly regresses dense 3D face shapes from single 2D images, and tackles identity and residual (i.e., non-identity) components in 3D face shapes explicitly and separately based on a composite 3D face shape model with latent representations. We devise a training process for the proposed network with a joint loss measuring both face identification error and 3D face shape reconstruction error. To construct training data we develop a method for fitting 3D morphable model (3DMM) to multiple 2D images of a subject. Comprehensive experiments have been done on MICC, BU3DFE, LFW and YTF databases. The results show that our method expands the capacity of 3DMM for capturing discriminative shape features and facial detail, and thus outperforms existing methods both in 3D face reconstruction accuracy and in face recognition accuracy.



### Parallel Grid Pooling for Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/1803.11370v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11370v1)
- **Published**: 2018-03-30 07:25:00+00:00
- **Updated**: 2018-03-30 07:25:00+00:00
- **Authors**: Akito Takeki, Daiki Ikami, Go Irie, Kiyoharu Aizawa
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural network (CNN) architectures utilize downsampling layers, which restrict the subsequent layers to learn spatially invariant features while reducing computational costs. However, such a downsampling operation makes it impossible to use the full spectrum of input features. Motivated by this observation, we propose a novel layer called parallel grid pooling (PGP) which is applicable to various CNN models. PGP performs downsampling without discarding any intermediate feature. It works as data augmentation and is complementary to commonly used data augmentation techniques. Furthermore, we demonstrate that a dilated convolution can naturally be represented using PGP operations, which suggests that the dilated convolution can also be regarded as a type of data augmentation technique. Experimental results based on popular image classification benchmarks demonstrate the effectiveness of the proposed method. Code is available at: https://github.com/akitotakeki



### Contrast-Oriented Deep Neural Networks for Salient Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1803.11395v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1803.11395v1)
- **Published**: 2018-03-30 09:51:04+00:00
- **Updated**: 2018-03-30 09:51:04+00:00
- **Authors**: Guanbin Li, Yizhou Yu
- **Comment**: Accept to TNNLS
- **Journal**: None
- **Summary**: Deep convolutional neural networks have become a key element in the recent breakthrough of salient object detection. However, existing CNN-based methods are based on either patch-wise (region-wise) training and inference or fully convolutional networks. Methods in the former category are generally time-consuming due to severe storage and computational redundancies among overlapping patches. To overcome this deficiency, methods in the second category attempt to directly map a raw input image to a predicted dense saliency map in a single network forward pass. Though being very efficient, it is arduous for these methods to detect salient objects of different scales or salient regions with weak semantic information. In this paper, we develop hybrid contrast-oriented deep neural networks to overcome the aforementioned limitations. Each of our deep networks is composed of two complementary components, including a fully convolutional stream for dense prediction and a segment-level spatial pooling stream for sparse saliency inference. We further propose an attentional module that learns weight maps for fusing the two saliency predictions from these two streams. A tailored alternate scheme is designed to train these deep networks by fine-tuning pre-trained baseline models. Finally, a customized fully connected CRF model incorporating a salient contour feature embedding can be optionally applied as a post-processing step to improve spatial coherence and contour positioning in the fused result from these two streams. Extensive experiments on six benchmark datasets demonstrate that our proposed model can significantly outperform the state of the art in terms of all popular evaluation metrics.



### Cross-modal Deep Variational Hand Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1803.11404v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11404v1)
- **Published**: 2018-03-30 10:27:06+00:00
- **Updated**: 2018-03-30 10:27:06+00:00
- **Authors**: Adrian Spurr, Jie Song, Seonwook Park, Otmar Hilliges
- **Comment**: None
- **Journal**: None
- **Summary**: The human hand moves in complex and high-dimensional ways, making estimation of 3D hand pose configurations from images alone a challenging task. In this work we propose a method to learn a statistical hand model represented by a cross-modal trained latent space via a generative deep neural network. We derive an objective function from the variational lower bound of the VAE framework and jointly optimize the resulting cross-modal KL-divergence and the posterior reconstruction objective, naturally admitting a training regime that leads to a coherent latent space across multiple modalities such as RGB images, 2D keypoint detections or 3D hand configurations. Additionally, it grants a straightforward way of using semi-supervision. This latent space can be directly used to estimate 3D hand poses from RGB images, outperforming the state-of-the art in different settings. Furthermore, we show that our proposed method can be used without changes on depth images and performs comparably to specialized methods. Finally, the model is fully generative and can synthesize consistent pairs of hand configurations across modalities. We evaluate our method on both RGB and depth datasets and analyze the latent space qualitatively.



### Learning Structure and Strength of CNN Filters for Small Sample Size Training
- **Arxiv ID**: http://arxiv.org/abs/1803.11405v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11405v1)
- **Published**: 2018-03-30 10:34:33+00:00
- **Updated**: 2018-03-30 10:34:33+00:00
- **Authors**: Rohit Keshari, Mayank Vatsa, Richa Singh, Afzel Noore
- **Comment**: 10 pages, 9 figures, Accepted in CVPR 2018
- **Journal**: None
- **Summary**: Convolutional Neural Networks have provided state-of-the-art results in several computer vision problems. However, due to a large number of parameters in CNNs, they require a large number of training samples which is a limiting factor for small sample size problems. To address this limitation, we propose SSF-CNN which focuses on learning the structure and strength of filters. The structure of the filter is initialized using a dictionary-based filter learning algorithm and the strength of the filter is learned using the small sample training data. The architecture provides the flexibility of training with both small and large training databases and yields good accuracies even with small size training data. The effectiveness of the algorithm is first demonstrated on MNIST, CIFAR10, and NORB databases, with a varying number of training samples. The results show that SSF-CNN significantly reduces the number of parameters required for training while providing high accuracies the test databases. On small sample size problems such as newborn face recognition and Omniglot, it yields state-of-the-art results. Specifically, on the IIITD Newborn Face Database, the results demonstrate improvement in rank-1 identification accuracy by at least 10%.



### The Resistance to Label Noise in K-NN and DNN Depends on its Concentration
- **Arxiv ID**: http://arxiv.org/abs/1803.11410v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1803.11410v3)
- **Published**: 2018-03-30 11:06:43+00:00
- **Updated**: 2020-12-03 09:18:17+00:00
- **Authors**: Amnon Drory, Oria Ratzon, Shai Avidan, Raja Giryes
- **Comment**: None
- **Journal**: None
- **Summary**: We investigate the classification performance of K-nearest neighbors (K-NN) and deep neural networks (DNNs) in the presence of label noise. We first show empirically that a DNN's prediction for a given test example depends on the labels of the training examples in its local neighborhood. This motivates us to derive a realizable analytic expression that approximates the multi-class K-NN classification error in the presence of label noise, which is of independent importance. We then suggest that the expression for K-NN may serve as a first-order approximation for the DNN error. Finally, we demonstrate empirically the proximity of the developed expression to the observed performance of K-NN and DNN classifiers. Our result may explain the already observed surprising resistance of DNN to some types of label noise. It also characterizes an important factor of it showing that the more concentrated the noise the greater is the degradation in performance.



### Scalable Deep Learning Logo Detection
- **Arxiv ID**: http://arxiv.org/abs/1803.11417v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11417v2)
- **Published**: 2018-03-30 11:22:16+00:00
- **Updated**: 2018-04-02 19:37:23+00:00
- **Authors**: Hang Su, Shaogang Gong, Xiatian Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Existing logo detection methods usually consider a small number of logo classes and limited images per class with a strong assumption of requiring tedious object bounding box annotations, therefore not scalable to real-world dynamic applications. In this work, we tackle these challenges by exploring the webly data learning principle without the need for exhaustive manual labelling. Specifically, we propose a novel incremental learning approach, called Scalable Logo Self-co-Learning (SL^2), capable of automatically self-discovering informative training images from noisy web data for progressively improving model capability in a cross-model co-learning manner. Moreover, we introduce a very large (2,190,757 images of 194 logo classes) logo dataset "WebLogo-2M" by an automatic web data collection and processing method. Extensive comparative evaluations demonstrate the superiority of the proposed SL^2 method over the state-of-the-art strongly and weakly supervised detection models and contemporary webly data learning approaches.



### Reconstruction Network for Video Captioning
- **Arxiv ID**: http://arxiv.org/abs/1803.11438v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11438v1)
- **Published**: 2018-03-30 13:09:30+00:00
- **Updated**: 2018-03-30 13:09:30+00:00
- **Authors**: Bairui Wang, Lin Ma, Wei Zhang, Wei Liu
- **Comment**: Accepted by CVPR 2018
- **Journal**: None
- **Summary**: In this paper, the problem of describing visual contents of a video sequence with natural language is addressed. Unlike previous video captioning work mainly exploiting the cues of video contents to make a language description, we propose a reconstruction network (RecNet) with a novel encoder-decoder-reconstructor architecture, which leverages both the forward (video to sentence) and backward (sentence to video) flows for video captioning. Specifically, the encoder-decoder makes use of the forward flow to produce the sentence description based on the encoded video semantic features. Two types of reconstructors are customized to employ the backward flow and reproduce the video features based on the hidden state sequence generated by the decoder. The generation loss yielded by the encoder-decoder and the reconstruction loss introduced by the reconstructor are jointly drawn into training the proposed RecNet in an end-to-end fashion. Experimental results on benchmark datasets demonstrate that the proposed reconstructor can boost the encoder-decoder models and leads to significant gains in video caption accuracy.



### Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present
- **Arxiv ID**: http://arxiv.org/abs/1803.11439v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1803.11439v2)
- **Published**: 2018-03-30 13:15:56+00:00
- **Updated**: 2018-04-07 01:49:44+00:00
- **Authors**: Xinpeng Chen, Lin Ma, Wenhao Jiang, Jian Yao, Wei Liu
- **Comment**: Accepted by CVPR 2018
- **Journal**: None
- **Summary**: Recently, caption generation with an encoder-decoder framework has been extensively studied and applied in different domains, such as image captioning, code captioning, and so on. In this paper, we propose a novel architecture, namely Auto-Reconstructor Network (ARNet), which, coupling with the conventional encoder-decoder framework, works in an end-to-end fashion to generate captions. ARNet aims at reconstructing the previous hidden state with the present one, besides behaving as the input-dependent transition operator. Therefore, ARNet encourages the current hidden state to embed more information from the previous one, which can help regularize the transition dynamics of recurrent neural networks (RNNs). Extensive experimental results show that our proposed ARNet boosts the performance over the existing encoder-decoder models on both image captioning and source code captioning tasks. Additionally, ARNet remarkably reduces the discrepancy between training and inference processes for caption generation. Furthermore, the performance on permuted sequential MNIST demonstrates that ARNet can effectively regularize RNN, especially on modeling long-term dependencies. Our code is available at: https://github.com/chenxinpeng/ARNet



### 3D Pose Estimation and 3D Model Retrieval for Objects in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1803.11493v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1803.11493v1)
- **Published**: 2018-03-30 14:47:49+00:00
- **Updated**: 2018-03-30 14:47:49+00:00
- **Authors**: Alexander Grabner, Peter M. Roth, Vincent Lepetit
- **Comment**: Accepted to Conference on Computer Vision and Pattern Recognition
  (CVPR) 2018
- **Journal**: Conference on Computer Vision and Pattern Recognition 2018
- **Summary**: We propose a scalable, efficient and accurate approach to retrieve 3D models for objects in the wild. Our contribution is twofold. We first present a 3D pose estimation approach for object categories which significantly outperforms the state-of-the-art on Pascal3D+. Second, we use the estimated pose as a prior to retrieve 3D models which accurately represent the geometry of objects in RGB images. For this purpose, we render depth images from 3D models under our predicted pose and match learned image descriptors of RGB images against those of rendered depth images using a CNN-based multi-view metric learning approach. In this way, we are the first to report quantitative results for 3D model retrieval on Pascal3D+, where our method chooses the same models as human annotators for 50% of the validation images on average. In addition, we show that our method, which was trained purely on Pascal3D+, retrieves rich and accurate 3D models from ShapeNet given RGB images of objects in the wild.



### Predicting Future Instance Segmentation by Forecasting Convolutional Features
- **Arxiv ID**: http://arxiv.org/abs/1803.11496v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11496v2)
- **Published**: 2018-03-30 14:55:32+00:00
- **Updated**: 2018-10-03 10:12:48+00:00
- **Authors**: Pauline Luc, Camille Couprie, Yann LeCun, Jakob Verbeek
- **Comment**: None
- **Journal**: None
- **Summary**: Anticipating future events is an important prerequisite towards intelligent behavior. Video forecasting has been studied as a proxy task towards this goal. Recent work has shown that to predict semantic segmentation of future frames, forecasting at the semantic level is more effective than forecasting RGB frames and then segmenting these. In this paper we consider the more challenging problem of future instance segmentation, which additionally segments out individual objects. To deal with a varying number of output labels per image, we develop a predictive model in the space of fixed-sized convolutional features of the Mask R-CNN instance segmentation model. We apply the "detection head'" of Mask R-CNN on the predicted features to produce the instance segmentation of future frames. Experiments show that this approach significantly improves over strong baselines based on optical flow and repurposed instance segmentation architectures.



### Vibration-Based Damage Detection in Wind Turbine Blades using Phase-Based Motion Estimation and Motion Magnification
- **Arxiv ID**: http://arxiv.org/abs/1804.00558v1
- **DOI**: 10.1016/j.jsv.2018.01.050
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1804.00558v1)
- **Published**: 2018-03-30 16:03:35+00:00
- **Updated**: 2018-03-30 16:03:35+00:00
- **Authors**: Aral Sarrafi, Zhu Mao, Christopher Niezrecki, Peyman Poozesh
- **Comment**: None
- **Journal**: Journal of Sound and Vibration, 421 (2018) 300-318
- **Summary**: Vibration-based Structural Health Monitoring (SHM) techniques are among the most common approaches for structural damage identification. The presence of damage in structures may be identified by monitoring the changes in dynamic behavior subject to external loading, and is typically performed by using experimental modal analysis (EMA) or operational modal analysis (OMA). These tools for SHM normally require a limited number of physically attached transducers (e.g. accelerometers) in order to record the response of the structure for further analysis. Signal conditioners, wires, wireless receivers and a data acquisition system (DAQ) are also typical components of traditional sensing systems used in vibration-based SHM. However, instrumentation of lightweight structures with contact sensors such as accelerometers may induce mass-loading effects, and for large-scale structures, the instrumentation is labor intensive and time consuming. Achieving high spatial measurement resolution for a large-scale structure is not always feasible while working with traditional contact sensors, and there is also the potential for a lack of reliability associated with fixed contact sensors in outliving the life-span of the host structure. Among the state-of-the-art non-contact measurements, digital video cameras are able to rapidly collect high-density spatial information from structures remotely. In this paper, the subtle motions from recorded video (i.e. a sequence of images) are extracted by means of Phase-based Motion Estimation (PME) and the extracted information is used to conduct damage identification on a 2.3-meter long Skystream wind turbine blade (WTB). The PME and phased-based motion magnification approach estimates the structural motion from the captured sequence of images for both a baseline and damaged test cases on a wind turbine blade.



### SpiderCNN: Deep Learning on Point Sets with Parameterized Convolutional Filters
- **Arxiv ID**: http://arxiv.org/abs/1803.11527v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11527v3)
- **Published**: 2018-03-30 16:10:21+00:00
- **Updated**: 2018-09-12 15:42:21+00:00
- **Authors**: Yifan Xu, Tianqi Fan, Mingye Xu, Long Zeng, Yu Qiao
- **Comment**: European Conference on Computer Vision 2018 (ECCV 2018)
- **Journal**: None
- **Summary**: Deep neural networks have enjoyed remarkable success for various vision tasks, however it remains challenging to apply CNNs to domains lacking a regular underlying structures such as 3D point clouds. Towards this we propose a novel convolutional architecture, termed SpiderCNN, to efficiently extract geometric features from point clouds. SpiderCNN is comprised of units called SpiderConv, which extend convolutional operations from regular grids to irregular point sets that can be embedded in R^n, by parametrizing a family of convolutional filters. We design the filter as a product of a simple step function that captures local geodesic information and a Taylor polynomial that ensures the expressiveness. SpiderCNN inherits the multi-scale hierarchical architecture from classical CNNs, which allows it to extract semantic deep features. Experiments on ModelNet40 demonstrate that SpiderCNN achieves state-of-the-art accuracy 92.4% on standard benchmarks, and shows competitive performance on segmentation task.



### Guide Me: Interacting with Deep Networks
- **Arxiv ID**: http://arxiv.org/abs/1803.11544v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11544v1)
- **Published**: 2018-03-30 17:28:52+00:00
- **Updated**: 2018-03-30 17:28:52+00:00
- **Authors**: Christian Rupprecht, Iro Laina, Nassir Navab, Gregory D. Hager, Federico Tombari
- **Comment**: CVPR 2018
- **Journal**: None
- **Summary**: Interaction and collaboration between humans and intelligent machines has become increasingly important as machine learning methods move into real-world applications that involve end users. While much prior work lies at the intersection of natural language and vision, such as image captioning or image generation from text descriptions, less focus has been placed on the use of language to guide or improve the performance of a learned visual processing algorithm. In this paper, we explore methods to flexibly guide a trained convolutional neural network through user input to improve its performance during inference. We do so by inserting a layer that acts as a spatio-semantic guide into the network. This guide is trained to modify the network's activations, either directly via an energy minimization scheme or indirectly through a recurrent model that translates human language queries to interaction weights. Learning the verbal interaction is fully automatic and does not require manual text annotations. We evaluate the method on two datasets, showing that guiding a pre-trained network can improve performance, and provide extensive insights into the interaction between the guide and the CNN.



### Multi-modal Disease Classification in Incomplete Datasets Using Geometric Matrix Completion
- **Arxiv ID**: http://arxiv.org/abs/1803.11550v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1803.11550v1)
- **Published**: 2018-03-30 17:40:02+00:00
- **Updated**: 2018-03-30 17:40:02+00:00
- **Authors**: Gerome Vivar, Andreas Zwergal, Nassir Navab, Seyed-Ahmad Ahmadi
- **Comment**: None
- **Journal**: None
- **Summary**: In large population-based studies and in clinical routine, tasks like disease diagnosis and progression prediction are inherently based on a rich set of multi-modal data, including imaging and other sensor data, clinical scores, phenotypes, labels and demographics. However, missing features, rater bias and inaccurate measurements are typical ailments of real-life medical datasets. Recently, it has been shown that deep learning with graph convolution neural networks (GCN) can outperform traditional machine learning in disease classification, but missing features remain an open problem. In this work, we follow up on the idea of modeling multi-modal disease classification as a matrix completion problem, with simultaneous classification and non-linear imputation of features. Compared to methods before, we arrange subjects in a graph-structure and solve classification through geometric matrix completion, which simulates a heat diffusion process that is learned and solved with a recurrent neural network. We demonstrate the potential of this method on the ADNI-based TADPOLE dataset and on the task of predicting the transition from MCI to Alzheimer's disease. With an AUC of 0.950 and classification accuracy of 87%, our approach outperforms standard linear and non-linear classifiers, as well as several state-of-the-art results in related literature, including a recently proposed GCN-based approach.



### Learning to Anonymize Faces for Privacy Preserving Action Detection
- **Arxiv ID**: http://arxiv.org/abs/1803.11556v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1803.11556v2)
- **Published**: 2018-03-30 17:55:04+00:00
- **Updated**: 2018-07-26 18:40:52+00:00
- **Authors**: Zhongzheng Ren, Yong Jae Lee, Michael S. Ryoo
- **Comment**: ECCV'18 camera ready
- **Journal**: None
- **Summary**: There is an increasing concern in computer vision devices invading users' privacy by recording unwanted videos. On the one hand, we want the camera systems to recognize important events and assist human daily lives by understanding its videos, but on the other hand we want to ensure that they do not intrude people's privacy. In this paper, we propose a new principled approach for learning a video \emph{face anonymizer}. We use an adversarial training setting in which two competing systems fight: (1) a video anonymizer that modifies the original video to remove privacy-sensitive information while still trying to maximize spatial action detection performance, and (2) a discriminator that tries to extract privacy-sensitive information from the anonymized videos. The end result is a video anonymizer that performs pixel-level modifications to anonymize each person's face, with minimal effect on action detection performance. We experimentally confirm the benefits of our approach compared to conventional hand-crafted anonymization methods including masking, blurring, and noise adding. Code, demo, and more results can be found on our project page https://jason718.github.io/project/privacy/main.html.



### Hierarchical Transfer Convolutional Neural Networks for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1804.00021v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1804.00021v2)
- **Published**: 2018-03-30 18:19:32+00:00
- **Updated**: 2018-05-09 19:38:24+00:00
- **Authors**: Xishuang Dong, Hsiang-Huang Wu, Yuzhong Yan, Lijun Qian
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we address the issue of how to enhance the generalization performance of convolutional neural networks (CNN) in the early learning stage for image classification. This is motivated by real-time applications that require the generalization performance of CNN to be satisfactory within limited training time. In order to achieve this, a novel hierarchical transfer CNN framework is proposed. It consists of a group of shallow CNNs and a cloud CNN, where the shallow CNNs are trained firstly and then the first layers of the trained shallow CNNs are used to initialize the first layer of the cloud CNN. This method will boost the generalization performance of the cloud CNN significantly, especially during the early stage of training. Experiments using CIFAR-10 and ImageNet datasets are performed to examine the proposed method. Results demonstrate the improvement of testing accuracy is 12% on average and as much as 20% for the CIFAR-10 case while 5% testing accuracy improvement for the ImageNet case during the early stage of learning. It is also shown that universal improvements of testing accuracy are obtained across different settings of dropout and number of shallow CNNs.



### Class Subset Selection for Transfer Learning using Submodularity
- **Arxiv ID**: http://arxiv.org/abs/1804.00060v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1804.00060v1)
- **Published**: 2018-03-30 21:36:59+00:00
- **Updated**: 2018-03-30 21:36:59+00:00
- **Authors**: Varun Manjunatha, Srikumar Ramalingam, Tim K. Marks, Larry Davis
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, it is common practice to extract fully-connected layer (fc) features that were learned while performing image classification on a source dataset, such as ImageNet, and apply them generally to a wide range of other tasks. The general usefulness of some large training datasets for transfer learning is not yet well understood, and raises a number of questions. For example, in the context of transfer learning, what is the role of a specific class in the source dataset, and how is the transferability of fc features affected when they are trained using various subsets of the set of all classes in the source dataset? In this paper, we address the question of how to select an optimal subset of the set of classes, subject to a budget constraint, that will more likely generate good features for other tasks. To accomplish this, we use a submodular set function to model the accuracy achievable on a new task when the features have been learned on a given subset of classes of the source dataset. An optimal subset is identified as the set that maximizes this submodular function. The maximization can be accomplished using an efficient greedy algorithm that comes with guarantees on the optimality of the solution. We empirically validate our submodular model by successfully identifying subsets of classes that produce good features for new tasks.



### Learning Beyond Human Expertise with Generative Models for Dental Restorations
- **Arxiv ID**: http://arxiv.org/abs/1804.00064v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1804.00064v1)
- **Published**: 2018-03-30 21:56:38+00:00
- **Updated**: 2018-03-30 21:56:38+00:00
- **Authors**: Jyh-Jing Hwang, Sergei Azernikov, Alexei A. Efros, Stella X. Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Computer vision has advanced significantly that many discriminative approaches such as object recognition are now widely used in real applications. We present another exciting development that utilizes generative models for the mass customization of medical products such as dental crowns. In the dental industry, it takes a technician years of training to design synthetic crowns that restore the function and integrity of missing teeth. Each crown must be customized to individual patients, and it requires human expertise in a time-consuming and labor-intensive process, even with computer-assisted design software. We develop a fully automatic approach that learns not only from human designs of dental crowns, but also from natural spatial profiles between opposing teeth. The latter is hard to account for by technicians but important for proper biting and chewing functions. Built upon a Generative Adversar-ial Network architecture (GAN), our deep learning model predicts the customized crown-filled depth scan from the crown-missing depth scan and opposing depth scan. We propose to incorporate additional space constraints and statistical compatibility into learning. Our automatic designs exceed human technicians' standards for good morphology and functionality, and our algorithm is being tested for production use.



