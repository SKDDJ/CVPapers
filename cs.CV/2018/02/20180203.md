# Arxiv Papers in cs.CV on 2018-02-03
### Build a Compact Binary Neural Network through Bit-level Sensitivity and Data Pruning
- **Arxiv ID**: http://arxiv.org/abs/1802.00904v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.00904v1)
- **Published**: 2018-02-03 03:50:41+00:00
- **Updated**: 2018-02-03 03:50:41+00:00
- **Authors**: Yixing Li, Fengbo Ren
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural network (CNN) has been widely used for vision-based tasks. Due to the high computational complexity and memory storage requirement, it is hard to directly deploy a full-precision CNN on embedded devices. The hardware-friendly designs are needed for re-source-limited and energy-constrained embed-ded devices. Emerging solutions are adopted for the neural network compression, e.g., bina-ry/ternary weight network, pruned network and quantized network. Among them, Binarized Neural Network (BNN) is believed to be the most hardware-friendly framework due to its small network size and low computational com-plexity. No existing work has further shrunk the size of BNN. In this work, we explore the redun-dancy in BNN and build a compact BNN (CBNN) based on the bit-level sensitivity analy-sis and bit-level data pruning. The input data is converted to a high dimensional bit-sliced for-mat. In post-training stage, we analyze the im-pact of different bit slices to the accuracy. By pruning the redundant input bit slices and shrinking the network size, we are able to build a more compact BNN. Our result shows that we can further scale down the network size of the BNN up to 3.9x with no more than 1% accuracy drop. The actual runtime can be reduced up to 2x and 9.9x compared with the baseline BNN and its full-precision counterpart, respectively.



### Active, Continual Fine Tuning of Convolutional Neural Networks for Reducing Annotation Efforts
- **Arxiv ID**: http://arxiv.org/abs/1802.00912v5
- **DOI**: 10.1016/j.media.2021.101997
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1802.00912v5)
- **Published**: 2018-02-03 05:01:17+00:00
- **Updated**: 2021-04-10 22:38:32+00:00
- **Authors**: Zongwei Zhou, Jae Y. Shin, Suryakanth R. Gurudu, Michael B. Gotway, Jianming Liang
- **Comment**: None
- **Journal**: None
- **Summary**: The splendid success of convolutional neural networks (CNNs) in computer vision is largely attributable to the availability of massive annotated datasets, such as ImageNet and Places. However, in medical imaging, it is challenging to create such large annotated datasets, as annotating medical images is not only tedious, laborious, and time consuming, but it also demands costly, specialty-oriented skills, which are not easily accessible. To dramatically reduce annotation cost, this paper presents a novel method to naturally integrate active learning and transfer learning (fine-tuning) into a single framework, which starts directly with a pre-trained CNN to seek "worthy" samples for annotation and gradually enhances the (fine-tuned) CNN via continual fine-tuning. We have evaluated our method using three distinct medical imaging applications, demonstrating that it can reduce annotation efforts by at least half compared with random selection.



### Deep Learning Framework for Multi-class Breast Cancer Histology Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1802.00931v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.00931v1)
- **Published**: 2018-02-03 07:13:02+00:00
- **Updated**: 2018-02-03 07:13:02+00:00
- **Authors**: Yeeleng S. Vang, Zhen Chen, Xiaohui Xie
- **Comment**: 8 pages, 2 figures, 3 tables, ICIAR2018 workshop
- **Journal**: None
- **Summary**: In this work, we present a deep learning framework for multi-class breast cancer image classification as our submission to the International Conference on Image Analysis and Recognition (ICIAR) 2018 Grand Challenge on BreAst Cancer Histology images (BACH). As these histology images are too large to fit into GPU memory, we first propose using Inception V3 to perform patch level classification. The patch level predictions are then passed through an ensemble fusion framework involving majority voting, gradient boosting machine (GBM), and logistic regression to obtain the image level prediction. We improve the sensitivity of the Normal and Benign predicted classes by designing a Dual Path Network (DPN) to be used as a feature extractor where these extracted features are further sent to a second layer of ensemble prediction fusion using GBM, logistic regression, and support vector machine (SVM) to refine predictions. Experimental results demonstrate our framework shows a 12.5$\%$ improvement over the state-of-the-art model.



### Recent Advances in Efficient Computation of Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1802.00939v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.00939v2)
- **Published**: 2018-02-03 08:52:12+00:00
- **Updated**: 2018-02-11 10:22:38+00:00
- **Authors**: Jian Cheng, Peisong Wang, Gang Li, Qinghao Hu, Hanqing Lu
- **Comment**: 14 pages, 3 figures
- **Journal**: None
- **Summary**: Deep neural networks have evolved remarkably over the past few years and they are currently the fundamental tools of many intelligent systems. At the same time, the computational complexity and resource consumption of these networks also continue to increase. This will pose a significant challenge to the deployment of such networks, especially in real-time applications or on resource-limited devices. Thus, network acceleration has become a hot topic within the deep learning community. As for hardware implementation of deep neural networks, a batch of accelerators based on FPGA/ASIC have been proposed in recent years. In this paper, we provide a comprehensive survey of recent advances in network acceleration, compression and accelerator design from both algorithm and hardware points of view. Specifically, we provide a thorough analysis of each of the following topics: network pruning, low-rank approximation, network quantization, teacher-student networks, compact network design and hardware accelerators. Finally, we will introduce and discuss a few possible future directions.



### Learning the Synthesizability of Dynamic Texture Samples
- **Arxiv ID**: http://arxiv.org/abs/1802.00941v1
- **DOI**: 10.1109/TIP.2018.2886807
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.00941v1)
- **Published**: 2018-02-03 09:22:29+00:00
- **Updated**: 2018-02-03 09:22:29+00:00
- **Authors**: Feng Yang, Gui-Song Xia, Dengxin Dai, Liangpei Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: A dynamic texture (DT) refers to a sequence of images that exhibit temporal regularities and has many applications in computer vision and graphics. Given an exemplar of dynamic texture, it is a dynamic but challenging task to generate new samples with high quality that are perceptually similar to the input exemplar, which is known to be {\em example-based dynamic texture synthesis (EDTS)}. Numerous approaches have been devoted to this problem, in the past decades, but none them are able to tackle all kinds of dynamic textures equally well. In this paper, we investigate the synthesizability of dynamic texture samples: {\em given a dynamic texture sample, how synthesizable it is by using EDTS, and which EDTS method is the most suitable to synthesize it?} To this end, we propose to learn regression models to connect dynamic texture samples with synthesizability scores, with the help of a compiled dynamic texture dataset annotated in terms of synthesizability. More precisely, we first define the synthesizability of DT samples and characterize them by a set of spatiotemporal features. Based on these features and an annotated dynamic texture dataset, we then train regression models to predict the synthesizability scores of texture samples and learn classifiers to select the most suitable EDTS methods. We further complete the selection, partition and synthesizability prediction of dynamic texture samples in a hierarchical scheme. We finally apply the learned synthesizability to detecting synthesizable regions in videos. The experiments demonstrate that our method can effectively learn and predict the synthesizability of DT samples.



### Ensembling Neural Networks for Digital Pathology Images Classification and Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1802.00947v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.00947v1)
- **Published**: 2018-02-03 10:05:28+00:00
- **Updated**: 2018-02-03 10:05:28+00:00
- **Authors**: Gleb Makarchuk, Vladimir Kondratenko, Maxim Pisov, Artem Pimkin, Egor Krivov, Mikhail Belyaev
- **Comment**: None
- **Journal**: None
- **Summary**: In the last years, neural networks have proven to be a powerful framework for various image analysis problems. However, some application domains have specific limitations. Notably, digital pathology is an example of such fields due to tremendous image sizes and quite limited number of training examples available. In this paper, we adopt state-of-the-art convolutional neural networks (CNN) architectures for digital pathology images analysis. We propose to classify image patches to increase effective sample size and then to apply an ensembling technique to build prediction for the original images. To validate the developed approaches, we conducted experiments with \textit{Breast Cancer Histology Challenge} dataset and obtained 90\% accuracy for the 4-class tissue classification task.



### Pose Flow: Efficient Online Pose Tracking
- **Arxiv ID**: http://arxiv.org/abs/1802.00977v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1802.00977v2)
- **Published**: 2018-02-03 14:08:36+00:00
- **Updated**: 2018-07-02 18:40:46+00:00
- **Authors**: Yuliang Xiu, Jiefeng Li, Haoyu Wang, Yinghong Fang, Cewu Lu
- **Comment**: Our source codes and models are made publicly available at
  https://github.com/YuliangXiu/PoseFlow and
  https://github.com/MVIG-SJTU/AlphaPose
- **Journal**: British Machine Vision Conference (BMVC), 2018
- **Summary**: Multi-person articulated pose tracking in unconstrained videos is an important while challenging problem. In this paper, going along the road of top-down approaches, we propose a decent and efficient pose tracker based on pose flows. First, we design an online optimization framework to build the association of cross-frame poses and form pose flows (PF-Builder). Second, a novel pose flow non-maximum suppression (PF-NMS) is designed to robustly reduce redundant pose flows and re-link temporal disjoint ones. Extensive experiments show that our method significantly outperforms best-reported results on two standard Pose Tracking datasets by 13 mAP 25 MOTA and 6 mAP 3 MOTA respectively. Moreover, in the case of working on detected poses in individual frames, the extra computation of pose tracker is very minor, guaranteeing online 10FPS tracking. Our source codes are made publicly available(https://github.com/YuliangXiu/PoseFlow).



### On the Generalizability of Linear and Non-Linear Region of Interest-Based Multivariate Regression Models for fMRI Data
- **Arxiv ID**: http://arxiv.org/abs/1802.02423v1
- **DOI**: None
- **Categories**: **stat.AP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1802.02423v1)
- **Published**: 2018-02-03 17:39:17+00:00
- **Updated**: 2018-02-03 17:39:17+00:00
- **Authors**: Ethan C. Jackson, James Alexander Hughes, Mark Daley
- **Comment**: Pre-print of paper submitted for review to 2018 IEEE CIBCB
- **Journal**: None
- **Summary**: In contrast to conventional, univariate analysis, various types of multivariate analysis have been applied to functional magnetic resonance imaging (fMRI) data. In this paper, we compare two contemporary approaches for multivariate regression on task-based fMRI data: linear regression with ridge regularization and non-linear symbolic regression using genetic programming. The data for this project is representative of a contemporary fMRI experimental design for visual stimuli. Linear and non-linear models were generated for 10 subjects, with another 4 withheld for validation. Model quality is evaluated by comparing $R$ scores (Pearson product-moment correlation) in various contexts, including single run self-fit, within-subject generalization, and between-subject generalization. Propensity for modelling strategies to overfit is estimated using a separate resting state scan. Results suggest that neither method is objectively or inherently better than the other.



### Image Posterization Using Fuzzy Logic and Bilateral Filter
- **Arxiv ID**: http://arxiv.org/abs/1802.01009v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.01009v1)
- **Published**: 2018-02-03 17:57:22+00:00
- **Updated**: 2018-02-03 17:57:22+00:00
- **Authors**: Mahmoud Afifi
- **Comment**: None
- **Journal**: None
- **Summary**: Image posterization is converting images with a large number of tones into synthetic images with distinct flat areas and a fewer number of tones. In this technical report, we present the implementation and results of using fuzzy logic in order to generate a posterized image in a simple and fast way. The image filter is based on fuzzy logic and bilateral filtering; where, the given image is blurred to remove small details. Then, the fuzzy logic is used to classify each pixel into one of three specific categories in order to reduce the number of colors. This filter was developed during building the Specs on Face dataset in order to add a new level of difficulty to the original face images in the dataset. This filter does not hurt the human detection performance; however, it is considered a hindrance evading the face detection process. This filter can be used generally for posterizing images, especially those have a high contrast to get images with vivid colors.



