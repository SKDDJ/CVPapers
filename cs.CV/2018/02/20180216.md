# Arxiv Papers in cs.CV on 2018-02-16
### ISEC: Iterative over-Segmentation via Edge Clustering
- **Arxiv ID**: http://arxiv.org/abs/1802.05816v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05816v1)
- **Published**: 2018-02-16 01:52:11+00:00
- **Updated**: 2018-02-16 01:52:11+00:00
- **Authors**: Marcelo Santos, Luciano Oliveira
- **Comment**: None
- **Journal**: None
- **Summary**: Several image pattern recognition tasks rely on superpixel generation as a fundamental step. Image analysis based on superpixels facilitates domain-specific applications, also speeding up the overall processing time of the task. Recent superpixel methods have been designed to fit boundary adherence, usually regulating the size and shape of each superpixel in order to mitigate the occurrence of undersegmentation failures. Superpixel regularity and compactness sometimes imposes an excessive number of segments in the image, which ultimately decreases the efficiency of the final segmentation, specially in video segmentation. We propose here a novel method to generate superpixels, called iterative over-segmentation via edge clustering (ISEC), which addresses the over-segmentation problem from a different perspective in contrast to recent state-of-the-art approaches. ISEC iteratively clusters edges extracted from the image objects, providing adaptive superpixels in size, shape and quantity, while preserving suitable adherence to the real object boundaries. All this is achieved at a very low computational cost. Experiments show that ISEC stands out from existing methods, meeting a favorable balance between segmentation stability and accurate representation of motion discontinuities, which are features specially suitable to video segmentation.



### SpaRTA - Tracking across occlusions via global partitioning of 3D clouds of points
- **Arxiv ID**: http://arxiv.org/abs/1802.05878v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05878v1)
- **Published**: 2018-02-16 09:40:16+00:00
- **Updated**: 2018-02-16 09:40:16+00:00
- **Authors**: Andrea Cavagna, Stefania Melillo, Leonardo Parisi, Federico Ricci-Tersenghi
- **Comment**: None
- **Journal**: None
- **Summary**: Any 3D tracking algorithm has to deal with occlusions: multiple targets get so close to each other that the loss of their identities becomes likely. In the best case scenario, trajectories are interrupted, thus curbing the completeness of the data-set; in the worse case scenario, identity switches arise, potentially affecting in severe ways the very quality of the data. Here, we present a novel tracking method that addresses the problem of occlusions within large groups of featureless objects by means of three steps: i) it represents each target as a cloud of points in 3D; ii) once a 3D cluster corresponding to an occlusion occurs, it defines a partitioning problem by introducing a cost function that uses both attractive and repulsive spatio-temporal proximity links; iii) it minimizes the cost function through a semi-definite optimization technique specifically designed to cope with link frustration. The algorithm is independent of the specific experimental method used to collect the data. By performing tests on public data-sets, we show that the new algorithm produces a significant improvement over the state-of-the-art tracking methods, both by reducing the number of identity switches and by increasing the accuracy of the actual positions of the targets in real space.



### Joint Estimation of Room Geometry and Modes with Compressed Sensing
- **Arxiv ID**: http://arxiv.org/abs/1802.05879v1
- **DOI**: None
- **Categories**: **eess.AS**, cs.CV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1802.05879v1)
- **Published**: 2018-02-16 09:41:56+00:00
- **Updated**: 2018-02-16 09:41:56+00:00
- **Authors**: Helena Peić Tukuljac, Thach Pham Vu, Hervé Lissek, Pierre Vandergheynst
- **Comment**: 5 pages, 4 figures
- **Journal**: None
- **Summary**: Acoustical behavior of a room for a given position of microphone and sound source is usually described using the room impulse response. If we rely on the standard uniform sampling, the estimation of room impulse response for arbitrary positions in the room requires a large number of measurements. In order to lower the required sampling rate, some solutions have emerged that exploit the sparse representation of the room wavefield in the terms of plane waves in the low-frequency domain. The plane wave representation has a simple form in rectangular rooms. In our solution, we observe the basic axial modes of the wave vector grid for extraction of the room geometry and then we propagate the knowledge to higher order modes out of the low-pass version of the measurements. Estimation of the approximate structure of the $k$-space should lead to the reduction in the terms of number of required measurements and in the increase of the speed of the reconstruction without great losses of quality.



### Training Deep Face Recognition Systems with Synthetic Data
- **Arxiv ID**: http://arxiv.org/abs/1802.05891v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05891v1)
- **Published**: 2018-02-16 11:05:18+00:00
- **Updated**: 2018-02-16 11:05:18+00:00
- **Authors**: Adam Kortylewski, Andreas Schneider, Thomas Gerig, Bernhard Egger, Andreas Morel-Forster, Thomas Vetter
- **Comment**: None
- **Journal**: None
- **Summary**: Recent advances in deep learning have significantly increased the performance of face recognition systems. The performance and reliability of these models depend heavily on the amount and quality of the training data. However, the collection of annotated large datasets does not scale well and the control over the quality of the data decreases with the size of the dataset. In this work, we explore how synthetically generated data can be used to decrease the number of real-world images needed for training deep face recognition systems. In particular, we make use of a 3D morphable face model for the generation of images with arbitrary amounts of facial identities and with full control over image variations, such as pose, illumination, and background. In our experiments with an off-the-shelf face recognition software we observe the following phenomena: 1) The amount of real training data needed to train competitive deep face recognition systems can be reduced significantly. 2) Combining large-scale real-world data with synthetic data leads to an increased performance. 3) Models trained only on synthetic data with strong variations in pose, illumination, and background perform very well across different datasets even without dataset adaptation. 4) The real-to-virtual performance gap can be closed when using synthetic data for pre-training, followed by fine-tuning with real-world images. 5) There are no observable negative effects of pre-training with synthetic data. Thus, any face recognition system in our experiments benefits from using synthetic face images. The synthetic data generator, as well as all experiments, are publicly available.



### A complete hand-drawn sketch vectorization framework
- **Arxiv ID**: http://arxiv.org/abs/1802.05902v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05902v1)
- **Published**: 2018-02-16 11:47:05+00:00
- **Updated**: 2018-02-16 11:47:05+00:00
- **Authors**: Luca Donati, Simone Cesano, Andrea Prati
- **Comment**: None
- **Journal**: None
- **Summary**: Vectorizing hand-drawn sketches is a challenging task, which is of paramount importance for creating CAD vectorized versions for the fashion and creative workflows. This paper proposes a complete framework that automatically transforms noisy and complex hand-drawn sketches with different stroke types in a precise, reliable and highly-simplified vectorized model. The proposed framework includes a novel line extraction algorithm based on a multi-resolution application of Pearson's cross correlation and a new unbiased thinning algorithm that can get rid of scribbles and variable-width strokes to obtain clean 1-pixel lines. Other contributions include variants of pruning, merging and edge linking procedures to post-process the obtained paths. Finally, a modification of the original Schneider's vectorization algorithm is designed to obtain fewer control points in the resulting Bezier splines. All the proposed steps of the framework have been extensively tested and compared with state-of-the-art algorithms, showing (both qualitatively and quantitatively) its outperformance.



### Recognizing Cuneiform Signs Using Graph Based Methods
- **Arxiv ID**: http://arxiv.org/abs/1802.05908v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05908v2)
- **Published**: 2018-02-16 12:28:28+00:00
- **Updated**: 2018-03-09 07:52:49+00:00
- **Authors**: Nils M. Kriege, Matthias Fey, Denis Fisseler, Petra Mutzel, Frank Weichert
- **Comment**: None
- **Journal**: None
- **Summary**: The cuneiform script constitutes one of the earliest systems of writing and is realized by wedge-shaped marks on clay tablets. A tremendous number of cuneiform tablets have already been discovered and are incrementally digitalized and made available to automated processing. As reading cuneiform script is still a manual task, we address the real-world application of recognizing cuneiform signs by two graph based methods with complementary runtime characteristics. We present a graph model for cuneiform signs together with a tailored distance measure based on the concept of the graph edit distance. We propose efficient heuristics for its computation and demonstrate its effectiveness in classification tasks experimentally. To this end, the distance measure is used to implement a nearest neighbor classifier leading to a high computational cost for the prediction phase with increasing training set size. In order to overcome this issue, we propose to use CNNs adapted to graphs as an alternative approach shifting the computational cost to the training phase. We demonstrate the practicability of both approaches in an extensive experimental comparison regarding runtime and prediction accuracy. Although currently available annotated real-world data is still limited, we obtain a high accuracy using CNNs, in particular, when the training set is enriched by augmented examples.



### An Image Processing based Object Counting Approach for Machine Vision Application
- **Arxiv ID**: http://arxiv.org/abs/1802.05911v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05911v1)
- **Published**: 2018-02-16 12:31:35+00:00
- **Updated**: 2018-02-16 12:31:35+00:00
- **Authors**: Mehmet Baygin, Mehmet Karakose, Alisan Sarimaden, Erhan Akin
- **Comment**: International Conference on Advances and Innovations in Engineering
  (ICAIE)
- **Journal**: None
- **Summary**: Machine vision applications are low cost and high precision measurement systems which are frequently used in production lines. With these systems that provide contactless control and measurement, production facilities are able to reach high production numbers without errors. Machine vision operations such as product counting, error control, dimension measurement can be performed through a camera. In this paper, a machine vision application is proposed, which can perform object-independent product counting. The proposed approach is based on Otsu thresholding and Hough transformation and performs automatic counting independently of product type and color. Basically one camera is used in the system. Through this camera, an image of the products passing through a conveyor is taken and various image processing algorithms are applied to these images. In this approach using images obtained from a real experimental setup, a real-time machine vision application was installed. As a result of the experimental studies performed, it has been determined that the proposed approach gives fast, accurate and reliable results.



### 3D Regression Neural Network for the Quantification of Enlarged Perivascular Spaces in Brain MRI
- **Arxiv ID**: http://arxiv.org/abs/1802.05914v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.05914v2)
- **Published**: 2018-02-16 12:49:59+00:00
- **Updated**: 2018-10-28 22:52:32+00:00
- **Authors**: Florian Dubost, Hieab Adams, Gerda Bortsova, M. Arfan Ikram, Wiro Niessen, Meike Vernooij, Marleen de Bruijne
- **Comment**: None
- **Journal**: None
- **Summary**: Enlarged perivascular spaces (EPVS) in the brain are an emerging imaging marker for cerebral small vessel disease, and have been shown to be related to increased risk of various neurological diseases, including stroke and dementia. Automatic quantification of EPVS would greatly help to advance research into its etiology and its potential as a risk indicator of disease. We propose a convolutional network regression method to quantify the extent of EPVS in the basal ganglia from 3D brain MRI. We first segment the basal ganglia and subsequently apply a 3D convolutional regression network designed for small object detection within this region of interest. The network takes an image as input, and outputs a quantification score of EPVS. The network has significantly more convolution operations than pooling ones and no final activation, allowing it to span the space of real numbers. We validated our approach using a dataset of 2000 brain MRI scans scored visually. Experiments with varying sizes of training and test sets showed that a good performance can be achieved with a training set of only 200 scans. With a training set of 1000 scans, the intraclass correlation coefficient (ICC) between our scoring method and the expert's visual score was 0.74. Our method outperforms by a large margin - more than 0.10 - four more conventional automated approaches based on intensities, scale-invariant feature transform, and random forest. We show that the network learns the structures of interest and investigate the influence of hyper-parameters on the performance. We also evaluate the reproducibility of our network using a set of 60 subjects scanned twice (scan-rescan reproducibility). On this set our network achieves an ICC of 0.93, while the intrarater agreement reaches 0.80. Furthermore, the automatic EPVS scoring correlates similarly to age as visual scoring.



### Spectral Normalization for Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1802.05957v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1802.05957v1)
- **Published**: 2018-02-16 14:41:39+00:00
- **Updated**: 2018-02-16 14:41:39+00:00
- **Authors**: Takeru Miyato, Toshiki Kataoka, Masanori Koyama, Yuichi Yoshida
- **Comment**: Published as a conference paper at ICLR 2018
- **Journal**: None
- **Summary**: One of the challenges in the study of generative adversarial networks is the instability of its training. In this paper, we propose a novel weight normalization technique called spectral normalization to stabilize the training of the discriminator. Our new normalization technique is computationally light and easy to incorporate into existing implementations. We tested the efficacy of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable of generating images of better or equal quality relative to the previous training stabilization techniques.



### Abductive reasoning as the basis to reproduce expert criteria in ECG Atrial Fibrillation identification
- **Arxiv ID**: http://arxiv.org/abs/1802.05998v1
- **DOI**: 10.1088/1361-6579/aad7e4
- **Categories**: **cs.AI**, cs.CV, 68T10
- **Links**: [PDF](http://arxiv.org/pdf/1802.05998v1)
- **Published**: 2018-02-16 16:06:42+00:00
- **Updated**: 2018-02-16 16:06:42+00:00
- **Authors**: Tomás Teijeiro, Constantino A. García, Daniel Castro, Paulo Félix
- **Comment**: 15 pages, 6 figures, 6 tables
- **Journal**: Physiological Measurement. 2018 Aug 31;39(8):084006
- **Summary**: Objective: This work aims at providing a new method for the automatic detection of atrial fibrillation, other arrhythmia and noise on short single lead ECG signals, emphasizing the importance of the interpretability of the classification results.   Approach: A morphological and rhythm description of the cardiac behavior is obtained by a knowledge-based interpretation of the signal using the \textit{Construe} abductive framework. Then, a set of meaningful features are extracted for each individual heartbeat and as a summary of the full record. The feature distributions were used to elucidate the expert criteria underlying the labeling of the 2017 Physionet/CinC Challenge dataset, enabling a manual partial relabeling to improve the consistency of the classification rules. Finally, state-of-the-art machine learning methods are combined to provide an answer on the basis of the feature values.   Main results: The proposal tied for the first place in the official stage of the Challenge, with a combined $F_1$ score of 0.83, and was even improved in the follow-up stage to 0.85 with a significant simplification of the model.   Significance: This approach demonstrates the potential of \textit{Construe} to provide robust and valuable descriptions of temporal data even with significant amounts of noise and artifacts. Also, we discuss the importance of a consistent classification criteria in manually labeled training datasets, and the fundamental advantages of knowledge-based approaches to formalize and validate that criteria.



### Bridging Cognitive Programs and Machine Learning
- **Arxiv ID**: http://arxiv.org/abs/1802.06091v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1802.06091v1)
- **Published**: 2018-02-16 19:19:00+00:00
- **Updated**: 2018-02-16 19:19:00+00:00
- **Authors**: Amir Rosenfeld, John K. Tsotsos
- **Comment**: None
- **Journal**: None
- **Summary**: While great advances are made in pattern recognition and machine learning, the successes of such fields remain restricted to narrow applications and seem to break down when training data is scarce, a shift in domain occurs, or when intelligent reasoning is required for rapid adaptation to new environments. In this work, we list several of the shortcomings of modern machine-learning solutions, specifically in the contexts of computer vision and in reinforcement learning and suggest directions to explore in order to try to ameliorate these weaknesses.



### Scenarios: A New Representation for Complex Scene Understanding
- **Arxiv ID**: http://arxiv.org/abs/1802.06117v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.06117v1)
- **Published**: 2018-02-16 20:49:30+00:00
- **Updated**: 2018-02-16 20:49:30+00:00
- **Authors**: Zachary A. Daniels, Dimitris N. Metaxas
- **Comment**: None
- **Journal**: None
- **Summary**: The ability for computational agents to reason about the high-level content of real world scene images is important for many applications. Existing attempts at addressing the problem of complex scene understanding lack representational power, efficiency, and the ability to create robust meta-knowledge about scenes. In this paper, we introduce scenarios as a new way of representing scenes. The scenario is a simple, low-dimensional, data-driven representation consisting of sets of frequently co-occurring objects and is useful for a wide range of scene understanding tasks. We learn scenarios from data using a novel matrix factorization method which we integrate into a new neural network architecture, the ScenarioNet. Using ScenarioNet, we can recover semantic information about real world scene images at three levels of granularity: 1) scene categories, 2) scenarios, and 3) objects. Training a single ScenarioNet model enables us to perform scene classification, scenario recognition, multi-object recognition, content-based scene image retrieval, and content-based image comparison. In addition to solving many tasks in a single, unified framework, ScenarioNet is more computationally efficient than other CNNs because it requires significantly fewer parameters while achieving similar performance on benchmark tasks and is more interpretable because it produces explanations when making decisions. We validate the utility of scenarios and ScenarioNet on a diverse set of scene understanding tasks on several benchmark datasets.



### Fast, Trainable, Multiscale Denoising
- **Arxiv ID**: http://arxiv.org/abs/1802.06130v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.06130v1)
- **Published**: 2018-02-16 21:27:30+00:00
- **Updated**: 2018-02-16 21:27:30+00:00
- **Authors**: Sungjoon Choi, John Isidoro, Pascal Getreuer, Peyman Milanfar
- **Comment**: None
- **Journal**: None
- **Summary**: Denoising is a fundamental imaging problem. Versatile but fast filtering has been demanded for mobile camera systems. We present an approach to multiscale filtering which allows real-time applications on low-powered devices. The key idea is to learn a set of kernels that upscales, filters, and blends patches of different scales guided by local structure analysis. This approach is trainable so that learned filters are capable of treating diverse noise patterns and artifacts. Experimental results show that the presented approach produces comparable results to state-of-the-art algorithms while processing time is orders of magnitude faster.



### Real-Time 3D Shape of Micro-Details
- **Arxiv ID**: http://arxiv.org/abs/1802.06140v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.06140v1)
- **Published**: 2018-02-16 21:55:16+00:00
- **Updated**: 2018-02-16 21:55:16+00:00
- **Authors**: Maryam Khanian, Ali Sharifi Boroujerdi, Michael Breuss
- **Comment**: 18 Pages, 12 Figures
- **Journal**: None
- **Summary**: Motivated by the growing demand for interactive environments, we propose an accurate real-time 3D shape reconstruction technique. To provide a reliable 3D reconstruction which is still a challenging task when dealing with real-world applications, we integrate several components including (i) Photometric Stereo (PS), (ii) perspective Cook-Torrance reflectance model that enables PS to deal with a broad range of possible real-world object reflections, (iii) realistic lightening situation, (iv) a Recurrent Optimization Network (RON) and finally (v) heuristic Dijkstra Gaussian Mean Curvature (DGMC) initialization approach. We demonstrate the potential benefits of our hybrid model by providing 3D shape with highly-detailed information from micro-prints for the first time. All real-world images are taken by a mobile phone camera under a simple setup as a consumer-level equipment. In addition, complementary synthetic experiments confirm the beneficial properties of our novel method and its superiority over the state-of-the-art approaches.



