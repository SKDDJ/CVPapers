# Arxiv Papers in cs.CV on 2018-02-11
### RoadTracer: Automatic Extraction of Road Networks from Aerial Images
- **Arxiv ID**: http://arxiv.org/abs/1802.03680v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.03680v2)
- **Published**: 2018-02-11 02:38:17+00:00
- **Updated**: 2018-04-26 22:12:54+00:00
- **Authors**: Favyen Bastani, Songtao He, Sofiane Abbar, Mohammad Alizadeh, Hari Balakrishnan, Sanjay Chawla, Sam Madden, David DeWitt
- **Comment**: CVPR 2018
- **Journal**: None
- **Summary**: Mapping road networks is currently both expensive and labor-intensive. High-resolution aerial imagery provides a promising avenue to automatically infer a road network. Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to a road (segmentation), and then uses complex post-processing heuristics to infer graph connectivity. We show that these segmentation methods have high error rates because noisy CNN outputs are difficult to correct. We propose RoadTracer, a new method to automatically construct accurate road network maps from aerial images. RoadTracer uses an iterative search process guided by a CNN-based decision function to derive the road network graph directly from the output of the CNN. We compare our approach with a segmentation method on fifteen cities, and find that at a 5% error rate, RoadTracer correctly captures 45% more junctions across these cities.



### Lightweight Classification of IoT Malware based on Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1802.03714v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1802.03714v1)
- **Published**: 2018-02-11 09:03:00+00:00
- **Updated**: 2018-02-11 09:03:00+00:00
- **Authors**: Jiawei Su, Danilo Vasconcellos Vargas, Sanjiva Prasad, Daniele Sgandurra, Yaokai Feng, Kouichi Sakurai
- **Comment**: None
- **Journal**: None
- **Summary**: The Internet of Things (IoT) is an extension of the traditional Internet, which allows a very large number of smart devices, such as home appliances, network cameras, sensors and controllers to connect to one another to share information and improve user experiences. Current IoT devices are typically micro-computers for domain-specific computations rather than traditional functionspecific embedded devices. Therefore, many existing attacks, targeted at traditional computers connected to the Internet, may also be directed at IoT devices. For example, DDoS attacks have become very common in IoT environments, as these environments currently lack basic security monitoring and protection mechanisms, as shown by the recent Mirai and Brickerbot IoT botnets. In this paper, we propose a novel light-weight approach for detecting DDos malware in IoT environments.We firstly extract one-channel gray-scale images converted from binaries, and then utilize a lightweight convolutional neural network for classifying IoT malware families. The experimental results show that the proposed system can achieve 94.0% accuracy for the classification of goodware and DDoS malware, and 81.8% accuracy for the classification of goodware and two main malware families.



### FD-MobileNet: Improved MobileNet with a Fast Downsampling Strategy
- **Arxiv ID**: http://arxiv.org/abs/1802.03750v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.03750v1)
- **Published**: 2018-02-11 15:01:47+00:00
- **Updated**: 2018-02-11 15:01:47+00:00
- **Authors**: Zheng Qin, Zhaoning Zhang, Xiaotao Chen, Yuxing Peng
- **Comment**: 5 pages, 1 figures
- **Journal**: None
- **Summary**: We present Fast-Downsampling MobileNet (FD-MobileNet), an efficient and accurate network for very limited computational budgets (e.g., 10-140 MFLOPs). Our key idea is applying an aggressive downsampling strategy to MobileNet framework. In FD-MobileNet, we perform 32$\times$ downsampling within 12 layers, only half the layers in the original MobileNet. This design brings three advantages: (i) It remarkably reduces the computational cost. (ii) It increases the information capacity and achieves significant performance improvements. (iii) It is engineering-friendly and provides fast actual inference speed. Experiments on ILSVRC 2012 and PASCAL VOC 2007 datasets demonstrate that FD-MobileNet consistently outperforms MobileNet and achieves comparable results with ShuffleNet under different computational budgets, for instance, surpassing MobileNet by 5.5% on the ILSVRC 2012 top-1 accuracy and 3.6% on the VOC 2007 mAP under a complexity of 12 MFLOPs. On an ARM-based device, FD-MobileNet achieves 1.11$\times$ inference speedup over MobileNet and 1.82$\times$ over ShuffleNet under the same complexity.



### Supervised classification of Dermatological diseases by Deep learning
- **Arxiv ID**: http://arxiv.org/abs/1802.03752v3
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1802.03752v3)
- **Published**: 2018-02-11 15:34:20+00:00
- **Updated**: 2018-07-31 17:23:02+00:00
- **Authors**: Sourav Mishra, Toshihiko Yamasaki, Hideaki Imaizumi
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a deep-learning based efficient classifier for common dermatological conditions, aimed at people without easy access to skin specialists. We report approximately 80% accuracy, in a situation where primary care doctors have attained 57% success rate, according to recent literature. The rationale of its design is centered on deploying and updating it on handheld devices in near future. Dermatological diseases are common in every population and have a wide spectrum in severity. With a shortage of dermatological expertise being observed in several countries, machine learning solutions can augment medical services and advise regarding existence of common diseases. The paper implements supervised classification of nine distinct conditions which have high occurrence in East Asian countries. Our current attempt establishes that deep learning based techniques are viable avenues for preliminary information to aid patients.



### Learning Deep Convolutional Networks for Demosaicing
- **Arxiv ID**: http://arxiv.org/abs/1802.03769v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.03769v1)
- **Published**: 2018-02-11 16:57:50+00:00
- **Updated**: 2018-02-11 16:57:50+00:00
- **Authors**: Nai-Sheng Syu, Yu-Sheng Chen, Yung-Yu Chuang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a comprehensive study of applying the convolutional neural network (CNN) to solving the demosaicing problem. The paper presents two CNN models that learn end-to-end mappings between the mosaic samples and the original image patches with full information. In the case the Bayer color filter array (CFA) is used, an evaluation with ten competitive methods on popular benchmarks confirms that the data-driven, automatically learned features by the CNN models are very effective. Experiments show that the proposed CNN models can perform equally well in both the sRGB space and the linear space. It is also demonstrated that the CNN model can perform joint denoising and demosaicing. The CNN model is very flexible and can be easily adopted for demosaicing with any CFA design. We train CNN models for demosaicing with three different CFAs and obtain better results than existing methods. With the great flexibility to be coupled with any CFA, we present the first data-driven joint optimization of the CFA design and the demosaicing method using CNN. Experiments show that the combination of the automatically discovered CFA pattern and the automatically devised demosaicing method significantly outperforms the current best demosaicing results. Visual comparisons confirm that the proposed methods reduce more visual artifacts than existing methods. Finally, we show that the CNN model is also effective for the more general demosaicing problem with spatially varying exposure and color and can be used for taking images of higher dynamic ranges with a single shot. The proposed models and the thorough experiments together demonstrate that CNN is an effective and versatile tool for solving the demosaicing problem.



### FlipDial: A Generative Model for Two-Way Visual Dialogue
- **Arxiv ID**: http://arxiv.org/abs/1802.03803v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.03803v2)
- **Published**: 2018-02-11 19:40:16+00:00
- **Updated**: 2018-04-03 13:59:08+00:00
- **Authors**: Daniela Massiceti, N. Siddharth, Puneet K. Dokania, Philip H. S. Torr
- **Comment**: None
- **Journal**: None
- **Summary**: We present FlipDial, a generative model for visual dialogue that simultaneously plays the role of both participants in a visually-grounded dialogue. Given context in the form of an image and an associated caption summarising the contents of the image, FlipDial learns both to answer questions and put forward questions, capable of generating entire sequences of dialogue (question-answer pairs) which are diverse and relevant to the image. To do this, FlipDial relies on a simple but surprisingly powerful idea: it uses convolutional neural networks (CNNs) to encode entire dialogues directly, implicitly capturing dialogue context, and conditional VAEs to learn the generative model. FlipDial outperforms the state-of-the-art model in the sequential answering task (one-way visual dialogue) on the VisDial dataset by 5 points in Mean Rank using the generated answers. We are the first to extend this paradigm to full two-way visual dialogue, where our model is capable of generating both questions and answers in sequence based on a visual input, for which we propose a set of novel evaluation measures and metrics.



### Analyzing and Mitigating the Impact of Permanent Faults on a Systolic Array Based Neural Network Accelerator
- **Arxiv ID**: http://arxiv.org/abs/1802.04657v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AR, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1802.04657v2)
- **Published**: 2018-02-11 19:51:35+00:00
- **Updated**: 2018-02-17 06:19:12+00:00
- **Authors**: Jeff Zhang, Tianyu Gu, Kanad Basu, Siddharth Garg
- **Comment**: To appear at IEEE VLSI Test Symposium 2018
- **Journal**: None
- **Summary**: Due to their growing popularity and computational cost, deep neural networks (DNNs) are being targeted for hardware acceleration. A popular architecture for DNN acceleration, adopted by the Google Tensor Processing Unit (TPU), utilizes a systolic array based matrix multiplication unit at its core. This paper deals with the design of fault-tolerant, systolic array based DNN accelerators for high defect rate technologies. To this end, we empirically show that the classification accuracy of a baseline TPU drops significantly even at extremely low fault rates (as low as $0.006\%$). We then propose two novel strategies, fault-aware pruning (FAP) and fault-aware pruning+retraining (FAP+T), that enable the TPU to operate at fault rates of up to $50\%$, with negligible drop in classification accuracy (as low as $0.1\%$) and no run-time performance overhead. The FAP+T does introduce a one-time retraining penalty per TPU chip before it is deployed, but we propose optimizations that reduce this one-time penalty to under 12 minutes. The penalty is then amortized over the entire lifetime of the TPU's operation.



### Edge-Host Partitioning of Deep Neural Networks with Feature Space Encoding for Resource-Constrained Internet-of-Things Platforms
- **Arxiv ID**: http://arxiv.org/abs/1802.03835v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1802.03835v1)
- **Published**: 2018-02-11 23:04:36+00:00
- **Updated**: 2018-02-11 23:04:36+00:00
- **Authors**: Jong Hwan Ko, Taesik Na, Mohammad Faisal Amir, Saibal Mukhopadhyay
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces partitioning an inference task of a deep neural network between an edge and a host platform in the IoT environment. We present a DNN as an encoding pipeline, and propose to transmit the output feature space of an intermediate layer to the host. The lossless or lossy encoding of the feature space is proposed to enhance the maximum input rate supported by the edge platform and/or reduce the energy of the edge platform. Simulation results show that partitioning a DNN at the end of convolutional (feature extraction) layers coupled with feature space encoding enables significant improvement in the energy-efficiency and throughput over the baseline configurations that perform the entire inference at the edge or at the host.



