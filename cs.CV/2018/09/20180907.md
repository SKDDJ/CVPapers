# Arxiv Papers in cs.CV on 2018-09-07
### Representing Images in 200 Bytes: Compression via Triangulation
- **Arxiv ID**: http://arxiv.org/abs/1809.02257v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02257v2)
- **Published**: 2018-09-07 00:05:57+00:00
- **Updated**: 2018-09-20 23:57:51+00:00
- **Authors**: David Marwood, Pascal Massimino, Michele Covell, Shumeet Baluja
- **Comment**: IEEE ICIP 2018
- **Journal**: None
- **Summary**: A rapidly increasing portion of internet traffic is dominated by requests from mobile devices with limited and metered bandwidth constraints. To satisfy these requests, it has become standard practice for websites to transmit small and extremely compressed image previews as part of the initial page load process to improve responsiveness. Increasing thumbnail compression beyond the capabilities of existing codecs is therefore an active research direction. In this work, we concentrate on extreme compression rates, where the size of the image is typically 200 bytes or less. First, we propose a novel approach for image compression that, unlike commonly used methods, does not rely on block-based statistics. We use an approach based on an adaptive triangulation of the target image, devoting more triangles to high entropy regions of the image. Second, we present a novel algorithm for encoding the triangles. The results show favorable statistics, in terms of PSNR and SSIM, over both the JPEG and the WebP standards.



### BubGAN: Bubble Generative Adversarial Networks for Synthesizing Realistic Bubbly Flow Images
- **Arxiv ID**: http://arxiv.org/abs/1809.02266v1
- **DOI**: 10.1016/j.ces.2019.04.004
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02266v1)
- **Published**: 2018-09-07 01:19:59+00:00
- **Updated**: 2018-09-07 01:19:59+00:00
- **Authors**: Yucheng Fu, Yang Liu
- **Comment**: 20 pages, 15 figures
- **Journal**: None
- **Summary**: Bubble segmentation and size detection algorithms have been developed in recent years for their high efficiency and accuracy in measuring bubbly two-phase flows. In this work, we proposed an architecture called bubble generative adversarial networks (BubGAN) for the generation of realistic synthetic images which could be further used as training or benchmarking data for the development of advanced image processing algorithms. The BubGAN is trained initially on a labeled bubble dataset consisting of ten thousand images. By learning the distribution of these bubbles, the BubGAN can generate more realistic bubbles compared to the conventional models used in the literature. The trained BubGAN is conditioned on bubble feature parameters and has full control of bubble properties in terms of aspect ratio, rotation angle, circularity and edge ratio. A million bubble dataset is pre-generated using the trained BubGAN. One can then assemble realistic bubbly flow images using this dataset and associated image processing tool. These images contain detailed bubble information, therefore do not require additional manual labeling. This is more useful compared with the conventional GAN which generates images without labeling information. The tool could be used to provide benchmarking and training data for existing image processing algorithms and to guide the future development of bubble detecting algorithms.



### Computation of Total Kidney Volume from CT images in Autosomal Dominant Polycystic Kidney Disease using Multi-Task 3D Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1809.02268v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02268v1)
- **Published**: 2018-09-07 01:22:52+00:00
- **Updated**: 2018-09-07 01:22:52+00:00
- **Authors**: Deepak Keshwani, Yoshiro Kitamura, Yuanzhong Li
- **Comment**: 8 pages, 5 figures, To appear in the Proceedings of the 21st
  International Conference On Medical Image Computing & Computer Assisted
  Intervention, Machine Learning in Medical Imaging workshop, 16-20 September
  2018, Granada, Spain
- **Journal**: None
- **Summary**: Autosomal Dominant Polycystic Kidney Disease (ADPKD) characterized by progressive growth of renal cysts is the most prevalent and potentially lethal monogenic renal disease, affecting one in every 500-100 people. Total Kidney Volume (TKV) and its growth computed from Computed Tomography images has been accepted as an essential prognostic marker for renal function loss. Due to large variation in shape and size of kidney in ADPKD, existing methods to compute TKV (i.e. to segment ADKP) including those based on 2D convolutional neural networks are not accurate enough to be directly useful in clinical practice. In this work, we propose multi-task 3D Convolutional Neural Networks to segment ADPK and achieve a mean DICE score of 0.95 and mean absolute percentage TKV error of 3.86. Additionally, to solve the challenge of class imbalance, we propose to simply bootstrap cross entropy loss and compare results with recently prevalent dice loss in medical image segmentation community.



### Tensor Ring Decomposition with Rank Minimization on Latent Space: An Efficient Approach for Tensor Completion
- **Arxiv ID**: http://arxiv.org/abs/1809.02288v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1809.02288v2)
- **Published**: 2018-09-07 03:05:08+00:00
- **Updated**: 2018-11-30 08:03:46+00:00
- **Authors**: Longhao Yuan, Chao Li, Danilo Mandic, Jianting Cao, Qibin Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: In tensor completion tasks, the traditional low-rank tensor decomposition models suffer from the laborious model selection problem due to their high model sensitivity. In particular, for tensor ring (TR) decomposition, the number of model possibilities grows exponentially with the tensor order, which makes it rather challenging to find the optimal TR decomposition. In this paper, by exploiting the low-rank structure of the TR latent space, we propose a novel tensor completion method which is robust to model selection. In contrast to imposing the low-rank constraint on the data space, we introduce nuclear norm regularization on the latent TR factors, resulting in the optimization step using singular value decomposition (SVD) being performed at a much smaller scale. By leveraging the alternating direction method of multipliers (ADMM) scheme, the latent TR factors with optimal rank and the recovered tensor can be obtained simultaneously. Our proposed algorithm is shown to effectively alleviate the burden of TR-rank selection, thereby greatly reducing the computational cost. The extensive experimental results on both synthetic and real-world data demonstrate the superior performance and efficiency of the proposed approach against the state-of-the-art algorithms.



### Neurons Merging Layer: Towards Progressive Redundancy Reduction for Deep Supervised Hashing
- **Arxiv ID**: http://arxiv.org/abs/1809.02302v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1809.02302v4)
- **Published**: 2018-09-07 04:10:47+00:00
- **Updated**: 2019-11-26 08:40:00+00:00
- **Authors**: Chaoyou Fu, Liangchen Song, Xiang Wu, Guoli Wang, Ran He
- **Comment**: Accepted by IJCAI 2019
- **Journal**: None
- **Summary**: Deep supervised hashing has become an active topic in information retrieval. It generates hashing bits by the output neurons of a deep hashing network. During binary discretization, there often exists much redundancy between hashing bits that degenerates retrieval performance in terms of both storage and accuracy. This paper proposes a simple yet effective Neurons Merging Layer (NMLayer) for deep supervised hashing. A graph is constructed to represent the redundancy relationship between hashing bits that is used to guide the learning of a hashing network. Specifically, it is dynamically learned by a novel mechanism defined in our active and frozen phases. According to the learned relationship, the NMLayer merges the redundant neurons together to balance the importance of each output neuron. Moreover, multiple NMLayers are progressively trained for a deep hashing network to learn a more compact hashing code from a long redundant code. Extensive experiments on four datasets demonstrate that our proposed method outperforms state-of-the-art hashing methods.



### Scaling Video Analytics Systems to Large Camera Deployments
- **Arxiv ID**: http://arxiv.org/abs/1809.02318v4
- **DOI**: None
- **Categories**: **cs.DC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1809.02318v4)
- **Published**: 2018-09-07 05:54:12+00:00
- **Updated**: 2019-07-05 20:38:15+00:00
- **Authors**: Samvit Jain, Ganesh Ananthanarayanan, Junchen Jiang, Yuanchao Shu, Joseph E. Gonzalez
- **Comment**: HotMobile 2019
- **Journal**: None
- **Summary**: Driven by advances in computer vision and the falling costs of camera hardware, organizations are deploying video cameras en masse for the spatial monitoring of their physical premises. Scaling video analytics to massive camera deployments, however, presents a new and mounting challenge, as compute cost grows proportionally to the number of camera feeds. This paper is driven by a simple question: can we scale video analytics in such a way that cost grows sublinearly, or even remains constant, as we deploy more cameras, while inference accuracy remains stable, or even improves. We believe the answer is yes. Our key observation is that video feeds from wide-area camera deployments demonstrate significant content correlations (e.g. to other geographically proximate feeds), both in space and over time. These spatio-temporal correlations can be harnessed to dramatically reduce the size of the inference search space, decreasing both workload and false positive rates in multi-camera video analytics. By discussing use-cases and technical challenges, we propose a roadmap for scaling video analytics to large camera networks, and outline a plan for its realization.



### Predicting Lung Nodule Malignancies by Combining Deep Convolutional Neural Network and Handcrafted Features
- **Arxiv ID**: http://arxiv.org/abs/1809.02333v2
- **DOI**: 10.1088/1361-6560/ab326a
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02333v2)
- **Published**: 2018-09-07 07:43:17+00:00
- **Updated**: 2018-12-27 13:09:53+00:00
- **Authors**: Shulong Li, Panpan Xu, Bin Li, Liyuan Chen, Zhiguo Zhou, Hongxia Hao, Yingying Duan, Michael Folkert, Jianhua Ma, Steve Jiang, Jing Wang
- **Comment**: 11 pages, 5 figures, 5 tables. This work has been submitted to the
  IEEE for possible publication
- **Journal**: None
- **Summary**: To predict lung nodule malignancy with a high sensitivity and specificity, we propose a fusion algorithm that combines handcrafted features (HF) into the features learned at the output layer of a 3D deep convolutional neural network (CNN). First, we extracted twenty-nine handcrafted features, including nine intensity features, eight geometric features, and twelve texture features based on grey-level co-occurrence matrix (GLCM) averaged from thirteen directions. We then trained 3D CNNs modified from three state-of-the-art 2D CNN architectures (AlexNet, VGG-16 Net and Multi-crop Net) to extract the CNN features learned at the output layer. For each 3D CNN, the CNN features combined with the 29 handcrafted features were used as the input for the support vector machine (SVM) coupled with the sequential forward feature selection (SFS) method to select the optimal feature subset and construct the classifiers. The fusion algorithm takes full advantage of the handcrafted features and the highest level CNN features learned at the output layer. It can overcome the disadvantage of the handcrafted features that may not fully reflect the unique characteristics of a particular lesion by combining the intrinsic CNN features. Meanwhile, it also alleviates the requirement of a large scale annotated dataset for the CNNs based on the complementary of handcrafted features. The patient cohort includes 431 malignant nodules and 795 benign nodules extracted from the LIDC/IDRI database. For each investigated CNN architecture, the proposed fusion algorithm achieved the highest AUC, accuracy, sensitivity, and specificity scores among all competitive classification models.



### Information-Theoretic Active Learning for Content-Based Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1809.02337v2
- **DOI**: 10.1007/978-3-030-12939-2_45
- **Categories**: **cs.CV**, cs.IR, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1809.02337v2)
- **Published**: 2018-09-07 07:57:26+00:00
- **Updated**: 2019-03-19 15:19:35+00:00
- **Authors**: Björn Barz, Christoph Käding, Joachim Denzler
- **Comment**: GCPR 2018 paper (14 pages text + 2 pages references + 6 pages
  appendix)
- **Journal**: Pattern Recognition. GCPR 2018. Lecture Notes in Computer Science,
  vol 11269, pp. 650-666
- **Summary**: We propose Information-Theoretic Active Learning (ITAL), a novel batch-mode active learning method for binary classification, and apply it for acquiring meaningful user feedback in the context of content-based image retrieval. Instead of combining different heuristics such as uncertainty, diversity, or density, our method is based on maximizing the mutual information between the predicted relevance of the images and the expected user feedback regarding the selected batch. We propose suitable approximations to this computationally demanding problem and also integrate an explicit model of user behavior that accounts for possible incorrect labels and unnameable instances. Furthermore, our approach does not only take the structure of the data but also the expected model output change caused by the user feedback into account. In contrast to other methods, ITAL turns out to be highly flexible and provides state-of-the-art performance across various datasets, such as MIRFLICKR and ImageNet.



### Infinite Curriculum Learning for Efficiently Detecting Gastric Ulcers in WCE Images
- **Arxiv ID**: http://arxiv.org/abs/1809.02371v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02371v1)
- **Published**: 2018-09-07 09:33:56+00:00
- **Updated**: 2018-09-07 09:33:56+00:00
- **Authors**: Xiaolu Zhang, Shiwan Zhao, Lingxi Xie
- **Comment**: 9 pages, 4 figures
- **Journal**: None
- **Summary**: The Wireless Capsule Endoscopy (WCE) is becoming a popular way of screening gastrointestinal system diseases and cancer. However, the time-consuming process in inspecting WCE data limits its applications and increases the cost of examinations. This paper considers WCE-based gastric ulcer detection, in which the major challenge is to detect the lesions in a local region. We propose an approach named infinite curriculum learning, which generalizes curriculum learning to an infinite sampling space by approximately measuring the difficulty of each patch by its scale. This allows us to adapt our model from local patches to global images gradually, leading to a consistent accuracy gain. Experiments are performed on a large dataset with more than 3 million WCE images. Our approach achieves a binary classification accuracy of 87%, and is able to detect some lesions mis-annotated by the physicians. In a real-world application, our approach can reduce the workload of a physician by 90%-98% in gastric ulcer screening.



### Group-based Learning of Disentangled Representations with Generalizability for Novel Contents
- **Arxiv ID**: http://arxiv.org/abs/1809.02383v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1809.02383v2)
- **Published**: 2018-09-07 10:00:54+00:00
- **Updated**: 2021-01-25 00:55:30+00:00
- **Authors**: Haruo Hosoya
- **Comment**: None
- **Journal**: published in IJCAI 2019
- **Summary**: Sensory data are often comprised of independent content and transformation factors. For example, face images may have shapes as content and poses as transformation. To infer separately these factors from given data, various ``disentangling'' models have been proposed. However, many of these are supervised or semi-supervised, either requiring attribute labels that are often unavailable or disallowing for generalization over new contents. In this study, we introduce a novel deep generative model, called group-based variational autoencoders. In this, we assume no explicit labels, but a weaker form of structure that groups together data instances having the same content but transformed differently; we thereby separately estimate a group-common factor as content and an instance-specific factor as transformation. This approach allows for learning to represent a general continuous space of contents, which can accommodate unseen contents. Despite the simplicity, our model succeeded in learning, from five datasets, content representations that are highly separate from the transformation representation and generalizable to data with novel contents. We further provide detailed analysis of the latent content code and show insight into how our model obtains the notable transformation invariance and content generalizability.



### Optimizing deep video representation to match brain activity
- **Arxiv ID**: http://arxiv.org/abs/1809.02440v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1809.02440v1)
- **Published**: 2018-09-07 12:37:50+00:00
- **Updated**: 2018-09-07 12:37:50+00:00
- **Authors**: Hugo Richard, Ana Pinho, Bertrand Thirion, Guillaume Charpiat
- **Comment**: None
- **Journal**: 2018 Conference on Cognitive Computational Neuroscience, Sep 2018,
  Philadelphia, United States
- **Summary**: The comparison of observed brain activity with the statistics generated by artificial intelligence systems is useful to probe brain functional organization under ecological conditions. Here we study fMRI activity in ten subjects watching color natural movies and compute deep representations of these movies with an architecture that relies on optical flow and image content. The association of activity in visual areas with the different layers of the deep architecture displays complexity-related contrasts across visual areas and reveals a striking foveal/peripheral dichotomy.



### A Deeper Look at 3D Shape Classifiers
- **Arxiv ID**: http://arxiv.org/abs/1809.02560v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1809.02560v2)
- **Published**: 2018-09-07 16:10:23+00:00
- **Updated**: 2018-09-30 18:14:18+00:00
- **Authors**: Jong-Chyi Su, Matheus Gadelha, Rui Wang, Subhransu Maji
- **Comment**: Accepted to Second Workshop on 3D Reconstruction Meets Semantics,
  ECCV 2018
- **Journal**: None
- **Summary**: We investigate the role of representations and architectures for classifying 3D shapes in terms of their computational efficiency, generalization, and robustness to adversarial transformations. By varying the number of training examples and employing cross-modal transfer learning we study the role of initialization of existing deep architectures for 3D shape classification. Our analysis shows that multiview methods continue to offer the best generalization even without pretraining on large labeled image datasets, and even when trained on simplified inputs such as binary silhouettes. Furthermore, the performance of voxel-based 3D convolutional networks and point-based architectures can be improved via cross-modal transfer from image representations. Finally, we analyze the robustness of 3D shape classifiers to adversarial transformations and present a novel approach for generating adversarial perturbations of a 3D shape for multiview classifiers using a differentiable renderer. We find that point-based networks are more robust to point position perturbations while voxel-based and multiview networks are easily fooled with the addition of imperceptible noise to the input.



### Skin lesion classification with ensemble of squeeze-and-excitation networks and semi-supervised learning
- **Arxiv ID**: http://arxiv.org/abs/1809.02568v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02568v1)
- **Published**: 2018-09-07 16:24:21+00:00
- **Updated**: 2018-09-07 16:24:21+00:00
- **Authors**: Shunsuke Kitada, Hitoshi Iyatomi
- **Comment**: 6 pages, 4 figures, ISIC2018
- **Journal**: None
- **Summary**: In this report, we introduce the outline of our system in Task 3: Disease Classification of ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection. We fine-tuned multiple pre-trained neural network models based on Squeeze-and-Excitation Networks (SENet) which achieved state-of-the-art results in the field of image recognition. In addition, we used the mean teachers as a semi-supervised learning framework and introduced some specially designed data augmentation strategies for skin lesion analysis. We confirmed our data augmentation strategy improved classification performance and demonstrated 87.2% in balanced accuracy on the official ISIC2018 validation dataset.



### Self-Supervised Generation of Spatial Audio for 360 Video
- **Arxiv ID**: http://arxiv.org/abs/1809.02587v1
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, cs.LG, cs.MM, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/1809.02587v1)
- **Published**: 2018-09-07 17:25:59+00:00
- **Updated**: 2018-09-07 17:25:59+00:00
- **Authors**: Pedro Morgado, Nuno Vasconcelos, Timothy Langlois, Oliver Wang
- **Comment**: To appear in NIPS 2018
- **Journal**: None
- **Summary**: We introduce an approach to convert mono audio recorded by a 360 video camera into spatial audio, a representation of the distribution of sound over the full viewing sphere. Spatial audio is an important component of immersive 360 video viewing, but spatial audio microphones are still rare in current 360 video production. Our system consists of end-to-end trainable neural networks that separate individual sound sources and localize them on the viewing sphere, conditioned on multi-modal analysis of audio and 360 video frames. We introduce several datasets, including one filmed ourselves, and one collected in-the-wild from YouTube, consisting of 360 videos uploaded with spatial audio. During training, ground-truth spatial audio serves as self-supervision and a mixed down mono track forms the input to our network. Using our approach, we show that it is possible to infer the spatial location of sound sources based only on 360 video and a mono audio track.



### Accelerating Deep Neural Networks with Spatial Bottleneck Modules
- **Arxiv ID**: http://arxiv.org/abs/1809.02601v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02601v1)
- **Published**: 2018-09-07 17:54:54+00:00
- **Updated**: 2018-09-07 17:54:54+00:00
- **Authors**: Junran Peng, Lingxi Xie, Zhaoxiang Zhang, Tieniu Tan, Jingdong Wang
- **Comment**: 9 pages, 5 figures
- **Journal**: None
- **Summary**: This paper presents an efficient module named spatial bottleneck for accelerating the convolutional layers in deep neural networks. The core idea is to decompose convolution into two stages, which first reduce the spatial resolution of the feature map, and then restore it to the desired size. This operation decreases the sampling density in the spatial domain, which is independent yet complementary to network acceleration approaches in the channel domain. Using different sampling rates, we can tradeoff between recognition accuracy and model complexity.   As a basic building block, spatial bottleneck can be used to replace any single convolutional layer, or the combination of two convolutional layers. We empirically verify the effectiveness of spatial bottleneck by applying it to the deep residual networks. Spatial bottleneck achieves 2x and 1.4x speedup on the regular and channel-bottlenecked residual blocks, respectively, with the accuracies retained in recognizing low-resolution images, and even improved in recognizing high-resolution images.



### SECS: Efficient Deep Stream Processing via Class Skew Dichotomy
- **Arxiv ID**: http://arxiv.org/abs/1809.06691v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.PF
- **Links**: [PDF](http://arxiv.org/pdf/1809.06691v1)
- **Published**: 2018-09-07 18:03:47+00:00
- **Updated**: 2018-09-07 18:03:47+00:00
- **Authors**: Boyuan Feng, Kun Wan, Shu Yang, Yufei Ding
- **Comment**: arXiv admin note: text overlap with arXiv:1611.06453 by other authors
- **Journal**: None
- **Summary**: Despite that accelerating convolutional neural network (CNN) receives an increasing research focus, the save on resource consumption always comes with a decrease in accuracy. To both increase accuracy and decrease resource consumption, we explore an environment information, called class skew, which is easily available and exists widely in daily life. Since the class skew may switch as time goes, we bring up probability layer to utilize class skew without any overhead during the runtime. Further, we observe class skew dichotomy that some class skew may appear frequently in the future, called hot class skew, and others will never appear again or appear seldom, called cold class skew. Inspired by techniques from source code optimization, two modes, i.e., interpretation and compilation, are proposed. The interpretation mode pursues efficient adaption during runtime for cold class skew and the compilation mode aggressively optimize on hot ones for more efficient deployment in the future. Aggressive optimization is processed by class-specific pruning and provides extra benefit. Finally, we design a systematic framework, SECS, to dynamically detect class skew, processing interpretation and compilation, as well as select the most accurate architectures under the runtime resource budget. Extensive evaluations show that SECS can realize end-to-end classification speedups by a factor of 3x to 11x relative to state-of-the-art convolutional neural networks, at a higher accuracy.



### Reservoir Computing based Neural Image Filters
- **Arxiv ID**: http://arxiv.org/abs/1809.02651v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.ET, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1809.02651v1)
- **Published**: 2018-09-07 19:58:53+00:00
- **Updated**: 2018-09-07 19:58:53+00:00
- **Authors**: Samiran Ganguly, Yunfei Gu, Yunkun Xie, Mircea R. Stan, Avik W. Ghosh, Nibir K. Dhar
- **Comment**: 5 pages, 4 figures, To appear in Conference Proceedings of The 44th
  Annual Conference of IEEE Industrial Electronics Society (2018): Special
  Session on Machine Vision, Control and Navigation
- **Journal**: None
- **Summary**: Clean images are an important requirement for machine vision systems to recognize visual features correctly. However, the environment, optics, electronics of the physical imaging systems can introduce extreme distortions and noise in the acquired images. In this work, we explore the use of reservoir computing, a dynamical neural network model inspired from biological systems, in creating dynamic image filtering systems that extracts signal from noise using inverse modeling. We discuss the possibility of implementing these networks in hardware close to the sensors.



### Are You Sure You Want To Do That? Classification with Verification
- **Arxiv ID**: http://arxiv.org/abs/1809.02652v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1809.02652v2)
- **Published**: 2018-09-07 19:59:43+00:00
- **Updated**: 2018-09-13 03:04:38+00:00
- **Authors**: Harris Chan, Atef Chaudhury, Kevin Shen
- **Comment**: 9 pages, 5 figures, preprint
- **Journal**: None
- **Summary**: Classification systems typically act in isolation, meaning they are required to implicitly memorize the characteristics of all candidate classes in order to classify. The cost of this is increased memory usage and poor sample efficiency. We propose a model which instead verifies using reference images during the classification process, reducing the burden of memorization. The model uses iterative nondifferentiable queries in order to classify an image. We demonstrate that such a model is feasible to train and can match baseline accuracy while being more parameter efficient. However, we show that finding the correct balance between image recognition and verification is essential to pushing the model towards desired behavior, suggesting that a pipeline of recognition followed by verification is a more promising approach.



### Query Attack via Opposite-Direction Feature:Towards Robust Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1809.02681v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02681v2)
- **Published**: 2018-09-07 21:29:32+00:00
- **Updated**: 2020-10-20 04:04:01+00:00
- **Authors**: Zhedong Zheng, Liang Zheng, Yi Yang, Fei Wu
- **Comment**: 12 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: Most existing works of adversarial samples focus on attacking image recognition models, while little attention is paid to the image retrieval task. In this paper, we identify two inherent challenges in applying prevailing image recognition attack methods to image retrieval. First, image retrieval demands discriminative visual features, which is significantly different from the one-hot class prediction in image recognition. Second, due to the disjoint and potentially unrelated classes between the training and test set in image retrieval, predicting the query category from predefined training classes is not accurate and leads to a sub-optimal adversarial gradient. To address these limitations, we propose a new white-box attack approach, Opposite-Direction Feature Attack (ODFA), to generate adversarial queries. Opposite-Direction Feature Attack (ODFA) effectively exploits feature-level adversarial gradients and takes advantage of feature distance in the representation space. To our knowledge, we are among the early attempts to design an attack method specifically for image retrieval. When we deploy an attacked image as the query, the true matches are prone to receive low ranks. We demonstrate through extensive experiments that (1) only crafting adversarial queries is sufficient to fool the state-of-the-art retrieval systems; (2) the proposed attack method, ODFA, leads to a higher attack success rate than classification attack methods, validating the necessity of leveraging characteristics of image retrieval; (3) the adversarial queries generated by our method have good transferability to other retrieval models without accessing their parameters, i.e.,the black-box setting.



### Selective Refinement Network for High Performance Face Detection
- **Arxiv ID**: http://arxiv.org/abs/1809.02693v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02693v1)
- **Published**: 2018-09-07 22:00:18+00:00
- **Updated**: 2018-09-07 22:00:18+00:00
- **Authors**: Cheng Chi, Shifeng Zhang, Junliang Xing, Zhen Lei, Stan Z. Li, Xudong Zou
- **Comment**: The first two authors have equal contributions. Corresponding author:
  Shifeng Zhang (shifeng.zhang@nlpr.ia.ac.cn)
- **Journal**: None
- **Summary**: High performance face detection remains a very challenging problem, especially when there exists many tiny faces. This paper presents a novel single-shot face detector, named Selective Refinement Network (SRN), which introduces novel two-step classification and regression operations selectively into an anchor-based face detector to reduce false positives and improve location accuracy simultaneously. In particular, the SRN consists of two modules: the Selective Two-step Classification (STC) module and the Selective Two-step Regression (STR) module. The STC aims to filter out most simple negative anchors from low level detection layers to reduce the search space for the subsequent classifier, while the STR is designed to coarsely adjust the locations and sizes of anchors from high level detection layers to provide better initialization for the subsequent regressor. Moreover, we design a Receptive Field Enhancement (RFE) block to provide more diverse receptive field, which helps to better capture faces in some extreme poses. As a consequence, the proposed SRN detector achieves state-of-the-art performance on all the widely used face detection benchmarks, including AFW, PASCAL face, FDDB, and WIDER FACE datasets. Codes will be released to facilitate further studies on the face detection problem.



### DensSiam: End-to-End Densely-Siamese Network with Self-Attention Model for Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1809.02714v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1809.02714v1)
- **Published**: 2018-09-07 23:41:02+00:00
- **Updated**: 2018-09-07 23:41:02+00:00
- **Authors**: Mohamed H. Abdelpakey, Mohamed S. Shehata, Mostafa M. Mohamed
- **Comment**: 11 pages, 3 figures, Accepted by ISVC18
- **Journal**: None
- **Summary**: Convolutional Siamese neural networks have been recently used to track objects using deep features. Siamese architecture can achieve real time speed, however it is still difficult to find a Siamese architecture that maintains the generalization capability, high accuracy and speed while decreasing the number of shared parameters especially when it is very deep. Furthermore, a conventional Siamese architecture usually processes one local neighborhood at a time, which makes the appearance model local and non-robust to appearance changes.   To overcome these two problems, this paper proposes DensSiam, a novel convolutional Siamese architecture, which uses the concept of dense layers and connects each dense layer to all layers in a feed-forward fashion with a similarity-learning function. DensSiam also includes a Self-Attention mechanism to force the network to pay more attention to the non-local features during offline training. Extensive experiments are performed on four tracking benchmarks: OTB2013 and OTB2015 for validation set; and VOT2015, VOT2016 and VOT2017 for testing set. The obtained results show that DensSiam achieves superior results on these benchmarks compared to other current state-of-the-art methods.



