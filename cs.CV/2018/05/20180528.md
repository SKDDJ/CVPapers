# Arxiv Papers in cs.CV on 2018-05-28
### Discriminator Feature-based Inference by Recycling the Discriminator of GANs
- **Arxiv ID**: http://arxiv.org/abs/1805.10717v2
- **DOI**: 10.1007/s11263-020-01311-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10717v2)
- **Published**: 2018-05-28 00:22:18+00:00
- **Updated**: 2020-03-04 09:16:37+00:00
- **Authors**: Duhyeon Bang, Seoungyoon Kang, Hyunjung Shim
- **Comment**: None
- **Journal**: International Journal of Computer Vision 2020
- **Summary**: Generative adversarial networks (GANs)successfully generate high quality data by learning amapping from a latent vector to the data. Various studies assert that the latent space of a GAN is semanticallymeaningful and can be utilized for advanced data analysis and manipulation. To analyze the real data in thelatent space of a GAN, it is necessary to build an inference mapping from the data to the latent vector. Thispaper proposes an effective algorithm to accurately infer the latent vector by utilizing GAN discriminator features. Our primary goal is to increase inference mappingaccuracy with minimal training overhead. Furthermore,using the proposed algorithm, we suggest a conditionalimage generation algorithm, namely a spatially conditioned GAN. Extensive evaluations confirmed that theproposed inference algorithm achieved more semantically accurate inference mapping than existing methodsand can be successfully applied to advanced conditionalimage generation tasks.



### Multi-region segmentation of bladder cancer structures in MRI with progressive dilated convolutional networks
- **Arxiv ID**: http://arxiv.org/abs/1805.10720v4
- **DOI**: 10.1002/mp.13240
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10720v4)
- **Published**: 2018-05-28 00:28:56+00:00
- **Updated**: 2018-11-20 19:54:30+00:00
- **Authors**: Jose Dolz, Xiaopan Xu, Jerome Rony, Jing Yuan, Yang Liu, Eric Granger, Christian Desrosiers, Xi Zhang, Ismail Ben Ayed, Hongbing Lu
- **Comment**: Published at the journal of Medical Physics
- **Journal**: None
- **Summary**: Precise segmentation of bladder walls and tumor regions is an essential step towards non-invasive identification of tumor stage and grade, which is critical for treatment decision and prognosis of patients with bladder cancer (BC). However, the automatic delineation of bladder walls and tumor in magnetic resonance images (MRI) is a challenging task, due to important bladder shape variations, strong intensity inhomogeneity in urine and very high variability across population, particularly on tumors appearance. To tackle these issues, we propose to use a deep fully convolutional neural network. The proposed network includes dilated convolutions to increase the receptive field without incurring extra cost nor degrading its performance. Furthermore, we introduce progressive dilations in each convolutional block, thereby enabling extensive receptive fields without the need for large dilation rates. The proposed network is evaluated on 3.0T T2-weighted MRI scans from 60 pathologically confirmed patients with BC. Experiments shows the proposed model to achieve high accuracy, with a mean Dice similarity coefficient of 0.98, 0.84 and 0.69 for inner wall, outer wall and tumor region, respectively. These results represent a very good agreement with reference contours and an increase in performance compared to existing methods. In addition, inference times are less than a second for a whole 3D volume, which is between 2-3 orders of magnitude faster than related state-of-the-art methods for this application. We showed that a CNN can yield precise segmentation of bladder walls and tumors in bladder cancer patients on MRI. The whole segmentation process is fully-automatic and yields results in very good agreement with the reference standard, demonstrating the viability of deep learning models for the automatic multi-region segmentation of bladder cancer MRI images.



### A Neurobiological Evaluation Metric for Neural Network Model Search
- **Arxiv ID**: http://arxiv.org/abs/1805.10726v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10726v4)
- **Published**: 2018-05-28 01:33:49+00:00
- **Updated**: 2018-11-27 00:51:03+00:00
- **Authors**: Nathaniel Blanchard, Jeffery Kinnison, Brandon RichardWebster, Pouya Bashivan, Walter J. Scheirer
- **Comment**: Under review
- **Journal**: None
- **Summary**: Neuroscience theory posits that the brain's visual system coarsely identifies broad object categories via neural activation patterns, with similar objects producing similar neural responses. Artificial neural networks also have internal activation behavior in response to stimuli. We hypothesize that networks exhibiting brain-like activation behavior will demonstrate brain-like characteristics, e.g., stronger generalization capabilities. In this paper we introduce a human-model similarity (HMS) metric, which quantifies the similarity of human fMRI and network activation behavior. To calculate HMS, representational dissimilarity matrices (RDMs) are created as abstractions of activation behavior, measured by the correlations of activations to stimulus pairs. HMS is then the correlation between the fMRI RDM and the neural network RDM across all stimulus pairs. We test the metric on unsupervised predictive coding networks, which specifically model visual perception, and assess the metric for statistical significance over a large range of hyperparameters. Our experiments show that networks with increased human-model similarity are correlated with better performance on two computer vision tasks: next frame prediction and object matching accuracy. Further, HMS identifies networks with high performance on both tasks. An unexpected secondary finding is that the metric can be employed during training as an early-stopping mechanism.



### A neural network trained to predict future video frames mimics critical properties of biological neuronal responses and perception
- **Arxiv ID**: http://arxiv.org/abs/1805.10734v2
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.10734v2)
- **Published**: 2018-05-28 02:15:09+00:00
- **Updated**: 2018-05-30 02:47:58+00:00
- **Authors**: William Lotter, Gabriel Kreiman, David Cox
- **Comment**: None
- **Journal**: None
- **Summary**: While deep neural networks take loose inspiration from neuroscience, it is an open question how seriously to take the analogies between artificial deep networks and biological neuronal systems. Interestingly, recent work has shown that deep convolutional neural networks (CNNs) trained on large-scale image recognition tasks can serve as strikingly good models for predicting the responses of neurons in visual cortex to visual stimuli, suggesting that analogies between artificial and biological neural networks may be more than superficial. However, while CNNs capture key properties of the average responses of cortical neurons, they fail to explain other properties of these neurons. For one, CNNs typically require large quantities of labeled input data for training. Our own brains, in contrast, rarely have access to this kind of supervision, so to the extent that representations are similar between CNNs and brains, this similarity must arise via different training paths. In addition, neurons in visual cortex produce complex time-varying responses even to static inputs, and they dynamically tune themselves to temporal regularities in the visual environment. We argue that these differences are clues to fundamental differences between the computations performed in the brain and in deep networks. To begin to close the gap, here we study the emergent properties of a previously-described recurrent generative network that is trained to predict future video frames in a self-supervised manner. Remarkably, the model is able to capture a wide variety of seemingly disparate phenomena observed in visual cortex, ranging from single unit response dynamics to complex perceptual motion illusions. These results suggest potentially deep connections between recurrent predictive neural network models and the brain, providing new leads that can enrich both fields.



### Deep Adversarial Context-Aware Landmark Detection for Ultrasound Imaging
- **Arxiv ID**: http://arxiv.org/abs/1805.10737v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10737v1)
- **Published**: 2018-05-28 02:27:32+00:00
- **Updated**: 2018-05-28 02:27:32+00:00
- **Authors**: Ahmet Tuysuzoglu, Jeremy Tan, Kareem Eissa, Atilla P. Kiraly, Mamadou Diallo, Ali Kamen
- **Comment**: None
- **Journal**: None
- **Summary**: Real-time localization of prostate gland in trans-rectal ultrasound images is a key technology that is required to automate the ultrasound guided prostate biopsy procedures. In this paper, we propose a new deep learning based approach which is aimed at localizing several prostate landmarks efficiently and robustly. We propose a multitask learning approach primarily to make the overall algorithm more contextually aware. In this approach, we not only consider the explicit learning of landmark locations, but also build-in a mechanism to learn the contour of the prostate. This multitask learning is further coupled with an adversarial arm to promote the generation of feasible structures. We have trained this network using ~4000 labeled trans-rectal ultrasound images and tested on an independent set of images with ground truth landmark locations. We have achieved an overall Dice score of 92.6% for the adversarially trained multitask approach, which is significantly better than the Dice score of 88.3% obtained by only learning of landmark locations. The overall mean distance error using the adversarial multitask approach has also improved by 20% while reducing the standard deviation of the error compared to learning landmark locations only. In terms of computational complexity both approaches can process the images in real-time using standard computer with a standard CUDA enabled GPU.



### Learning Instance-Aware Object Detection Using Determinantal Point Processes
- **Arxiv ID**: http://arxiv.org/abs/1805.10765v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10765v3)
- **Published**: 2018-05-28 04:25:33+00:00
- **Updated**: 2019-09-02 02:14:07+00:00
- **Authors**: Nuri Kim, Donghoon Lee, Songhwai Oh
- **Comment**: None
- **Journal**: None
- **Summary**: Recent object detectors find instances while categorizing candidate regions. As each region is evaluated independently, the number of candidate regions from a detector is usually larger than the number of objects. Since the final goal of detection is to assign a single detection to each object, a heuristic algorithm, such as non-maximum suppression (NMS), is used to select a single bounding box for an object. While simple heuristic algorithms are effective for stand-alone objects, they can fail to detect overlapped objects. In this paper, we address this issue by training a network to distinguish different objects using the relationship between candidate boxes. We propose an instance-aware detection network (IDNet), which can learn to extract features from candidate regions and measure their similarities. Based on pairwise similarities and detection qualities, the IDNet selects a subset of candidate bounding boxes using instance-aware determinantal point process inference (IDPP). Extensive experiments demonstrate that the proposed algorithm achieves significant improvements for detecting overlapped objects compared to existing state-of-the-art detection methods on the PASCAL VOC and MS COCO datasets.



### Improving the Resolution of CNN Feature Maps Efficiently with Multisampling
- **Arxiv ID**: http://arxiv.org/abs/1805.10766v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.10766v1)
- **Published**: 2018-05-28 04:29:02+00:00
- **Updated**: 2018-05-28 04:29:02+00:00
- **Authors**: Shayan Sadigh, Pradeep Sen
- **Comment**: Preprint
- **Journal**: None
- **Summary**: We describe a new class of subsampling techniques for CNNs, termed multisampling, that significantly increases the amount of information kept by feature maps through subsampling layers. One version of our method, which we call checkered subsampling, significantly improves the accuracy of state-of-the-art architectures such as DenseNet and ResNet without any additional parameters and, remarkably, improves the accuracy of certain pretrained ImageNet models without any training or fine-tuning. We glean new insight into the nature of data augmentations and demonstrate, for the first time, that coarse feature maps are significantly bottlenecking the performance of neural networks in image classification.



### Object-Level Representation Learning for Few-Shot Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1805.10777v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.10777v1)
- **Published**: 2018-05-28 05:46:17+00:00
- **Updated**: 2018-05-28 05:46:17+00:00
- **Authors**: Liangqu Long, Wei Wang, Jun Wen, Meihui Zhang, Qian Lin, Beng Chin Ooi
- **Comment**: None
- **Journal**: None
- **Summary**: Few-shot learning that trains image classifiers over few labeled examples per category is a challenging task. In this paper, we propose to exploit an additional big dataset with different categories to improve the accuracy of few-shot learning over our target dataset. Our approach is based on the observation that images can be decomposed into objects, which may appear in images from both the additional dataset and our target dataset. We use the object-level relation learned from the additional dataset to infer the similarity of images in our target dataset with unseen categories. Nearest neighbor search is applied to do image classification, which is a non-parametric model and thus does not need fine-tuning. We evaluate our algorithm on two popular datasets, namely Omniglot and MiniImagenet. We obtain 8.5\% and 2.7\% absolute improvements for 5-way 1-shot and 5-way 5-shot experiments on MiniImagenet, respectively. Source code will be published upon acceptance.



### Keep and Learn: Continual Learning by Constraining the Latent Space for Knowledge Preservation in Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.10784v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10784v1)
- **Published**: 2018-05-28 06:26:58+00:00
- **Updated**: 2018-05-28 06:26:58+00:00
- **Authors**: Hyo-Eun Kim, Seungwook Kim, Jaehwan Lee
- **Comment**: accepted for presentation at MICCAI 2018
- **Journal**: None
- **Summary**: Data is one of the most important factors in machine learning. However, even if we have high-quality data, there is a situation in which access to the data is restricted. For example, access to the medical data from outside is strictly limited due to the privacy issues. In this case, we have to learn a model sequentially only with the data accessible in the corresponding stage. In this work, we propose a new method for preserving learned knowledge by modeling the high-level feature space and the output space to be mutually informative, and constraining feature vectors to lie in the modeled space during training. The proposed method is easy to implement as it can be applied by simply adding a reconstruction loss to an objective function. We evaluate the proposed method on CIFAR-10/100 and a chest X-ray dataset, and show benefits in terms of knowledge preservation compared to previous approaches.



### GenAttack: Practical Black-box Attacks with Gradient-Free Optimization
- **Arxiv ID**: http://arxiv.org/abs/1805.11090v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1805.11090v3)
- **Published**: 2018-05-28 06:40:55+00:00
- **Updated**: 2019-07-01 00:32:03+00:00
- **Authors**: Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, Huan Zhang, Cho-Jui Hsieh, Mani Srivastava
- **Comment**: Accepted in The Genetic and Evolutionary Computation Conference
  (GECCO) 2019
- **Journal**: None
- **Summary**: Deep neural networks are vulnerable to adversarial examples, even in the black-box setting, where the attacker is restricted solely to query access. Existing black-box approaches to generating adversarial examples typically require a significant number of queries, either for training a substitute network or performing gradient estimation. We introduce GenAttack, a gradient-free optimization technique that uses genetic algorithms for synthesizing adversarial examples in the black-box setting. Our experiments on different datasets (MNIST, CIFAR-10, and ImageNet) show that GenAttack can successfully generate visually imperceptible adversarial examples against state-of-the-art image recognition models with orders of magnitude fewer queries than previous approaches. Against MNIST and CIFAR-10 models, GenAttack required roughly 2,126 and 2,568 times fewer queries respectively, than ZOO, the prior state-of-the-art black-box attack. In order to scale up the attack to large-scale high-dimensional ImageNet models, we perform a series of optimizations that further improve the query efficiency of our attack leading to 237 times fewer queries against the Inception-v3 model than ZOO. Furthermore, we show that GenAttack can successfully attack some state-of-the-art ImageNet defenses, including ensemble adversarial training and non-differentiable or randomized input transformations. Our results suggest that evolutionary algorithms open up a promising area of research into effective black-box attacks.



### Deep CT to MR Synthesis using Paired and Unpaired Data
- **Arxiv ID**: http://arxiv.org/abs/1805.10790v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10790v2)
- **Published**: 2018-05-28 07:14:05+00:00
- **Updated**: 2018-09-03 13:33:28+00:00
- **Authors**: Cheng-Bin Jin, Hakil Kim, Wonmo Jung, Seongsu Joo, Ensik Park, Ahn Young Saem, In Ho Han, Jae Il Lee, Xuenan Cui
- **Comment**: 23 pages, 7 figures, and 4 tables
- **Journal**: None
- **Summary**: MR imaging will play a very important role in radiotherapy treatment planning for segmentation of tumor volumes and organs. However, the use of MR-based radiotherapy is limited because of the high cost and the increased use of metal implants such as cardiac pacemakers and artificial joints in aging society. To improve the accuracy of CT-based radiotherapy planning, we propose a synthetic approach that translates a CT image into an MR image using paired and unpaired training data. In contrast to the current synthetic methods for medical images, which depend on sparse pairwise-aligned data or plentiful unpaired data, the proposed approach alleviates the rigid registration challenge of paired training and overcomes the context-misalignment problem of the unpaired training. A generative adversarial network was trained to transform 2D brain CT image slices into 2D brain MR image slices, combining adversarial loss, dual cycle-consistent loss, and voxel-wise loss. The experiments were analyzed using CT and MR images of 202 patients. Qualitative and quantitative comparisons against independent paired training and unpaired training methods demonstrate the superiority of our approach.



### Deep Discriminative Latent Space for Clustering
- **Arxiv ID**: http://arxiv.org/abs/1805.10795v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1805.10795v1)
- **Published**: 2018-05-28 07:34:14+00:00
- **Updated**: 2018-05-28 07:34:14+00:00
- **Authors**: Elad Tzoreff, Olga Kogan, Yoni Choukroun
- **Comment**: A version of this paper has been submitted to NIPS 2018. The paper
  contains 9 pages including references, and 4 figures
- **Journal**: None
- **Summary**: Clustering is one of the most fundamental tasks in data analysis and machine learning. It is central to many data-driven applications that aim to separate the data into groups with similar patterns. Moreover, clustering is a complex procedure that is affected significantly by the choice of the data representation method. Recent research has demonstrated encouraging clustering results by learning effectively these representations. In most of these works a deep auto-encoder is initially pre-trained to minimize a reconstruction loss, and then jointly optimized with clustering centroids in order to improve the clustering objective. Those works focus mainly on the clustering phase of the procedure, while not utilizing the potential benefit out of the initial phase. In this paper we propose to optimize an auto-encoder with respect to a discriminative pairwise loss function during the auto-encoder pre-training phase. We demonstrate the high accuracy obtained by the proposed method as well as its rapid convergence (e.g. reaching above 92% accuracy on MNIST during the pre-training phase, in less than 50 epochs), even with small networks.



### Visual Relationship Detection Based on Guided Proposals and Semantic Knowledge Distillation
- **Arxiv ID**: http://arxiv.org/abs/1805.10802v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10802v1)
- **Published**: 2018-05-28 07:59:28+00:00
- **Updated**: 2018-05-28 07:59:28+00:00
- **Authors**: François Plesse, Alexandru Ginsca, Bertrand Delezoide, Françoise Prêteux
- **Comment**: Accepted submission to ICME 2018
- **Journal**: None
- **Summary**: A thorough comprehension of image content demands a complex grasp of the interactions that may occur in the natural world. One of the key issues is to describe the visual relationships between objects. When dealing with real world data, capturing these very diverse interactions is a difficult problem. It can be alleviated by incorporating common sense in a network. For this, we propose a framework that makes use of semantic knowledge and estimates the relevance of object pairs during both training and test phases. Extracted from precomputed models and training annotations, this information is distilled into the neural network dedicated to this task. Using this approach, we observe a significant improvement on all classes of Visual Genome, a challenging visual relationship dataset. A 68.5% relative gain on the recall at 100 is directly related to the relevance estimate and a 32.7% gain to the knowledge distillation.



### Fast Dynamic Routing Based on Weighted Kernel Density Estimation
- **Arxiv ID**: http://arxiv.org/abs/1805.10807v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10807v2)
- **Published**: 2018-05-28 08:18:31+00:00
- **Updated**: 2018-09-01 03:14:29+00:00
- **Authors**: Suofei Zhang, Wei Zhao, Xiaofu Wu, Quan Zhou
- **Comment**: 16 pages, 4 figures, submitted to eccv 2018
- **Journal**: None
- **Summary**: Capsules as well as dynamic routing between them are most recently proposed structures for deep neural networks. A capsule groups data into vectors or matrices as poses rather than conventional scalars to represent specific properties of target instance. Besides of pose, a capsule should be attached with a probability (often denoted as activation) for its presence. The dynamic routing helps capsules achieve more generalization capacity with many fewer model parameters. However, the bottleneck that prevents widespread applications of capsule is the expense of computation during routing. To address this problem, we generalize existing routing methods within the framework of weighted kernel density estimation, and propose two fast routing methods with different optimization strategies. Our methods prompt the time efficiency of routing by nearly 40\% with negligible performance degradation. By stacking a hybrid of convolutional layers and capsule layers, we construct a network architecture to handle inputs at a resolution of $64\times{64}$ pixels. The proposed models achieve a parallel performance with other leading methods in multiple benchmarks.



### A non-invertible cancelable fingerprint template generation based on ridge feature transformation
- **Arxiv ID**: http://arxiv.org/abs/1805.10853v1
- **DOI**: 10.1117/1.JEI.27.5.053031
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10853v1)
- **Published**: 2018-05-28 10:27:47+00:00
- **Updated**: 2018-05-28 10:27:47+00:00
- **Authors**: Rudresh Dwivedi, Somnath Dey
- **Comment**: None
- **Journal**: None
- **Summary**: In a biometric verification system, leakage of biometric data leads to permanent identity loss since original biometric data is inherently linked to a user. Further, various types of attacks on a biometric system may reveal the original template and utility in other applications. To address these security and privacy concerns cancelable biometric has been introduced. Cancelable biometric constructs a protected template from the original biometric template using transformation functions and performs the comparison between templates in the transformed domain. Recent approaches towards cancelable fingerprint generation either rely on aligning minutiae points with respect to singular points (core/delta) or utilize the absolute coordinate positions of minutiae points. In this paper, we propose a novel non-invertible ridge feature transformation method to protect the original fingerprint template information. The proposed method partitions the fingerprint region into a number of sectors with reference to each minutia point employing a ridge-based co-ordinate system. The nearest neighbor minutiae in each sector are identified, and ridge-based features are computed. Further, a cancelable template is generated by applying the Cantor pairing function followed by random projection. We have evaluated our method with FVC2002, FVC2004 and FVC2006 databases. It is evident from the experimental results that the proposed method outperforms existing methods in the literature. Moreover, the security analysis demonstrates that the proposed method fulfills the necessary requirements of non-invertibility, revocability, and diversity with a minor performance degradation caused due to cancelable transformation.



### Distributed Weight Consolidation: A Brain Segmentation Case Study
- **Arxiv ID**: http://arxiv.org/abs/1805.10863v9
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.10863v9)
- **Published**: 2018-05-28 10:50:11+00:00
- **Updated**: 2019-01-16 11:37:26+00:00
- **Authors**: Patrick McClure, Charles Y. Zheng, Jakub R. Kaczmarzyk, John A. Lee, Satrajit S. Ghosh, Dylan Nielson, Peter Bandettini, Francisco Pereira
- **Comment**: Published in NeurIPS 2018
- **Journal**: None
- **Summary**: Collecting the large datasets needed to train deep neural networks can be very difficult, particularly for the many applications for which sharing and pooling data is complicated by practical, ethical, or legal concerns. However, it may be the case that derivative datasets or predictive models developed within individual sites can be shared and combined with fewer restrictions. Training on distributed data and combining the resulting networks is often viewed as continual learning, but these methods require networks to be trained sequentially. In this paper, we introduce distributed weight consolidation (DWC), a continual learning method to consolidate the weights of separate neural networks, each trained on an independent dataset. We evaluated DWC with a brain segmentation case study, where we consolidated dilated convolutional neural networks trained on independent structural magnetic resonance imaging (sMRI) datasets from different sites. We found that DWC led to increased performance on test sets from the different sites, while maintaining generalization performance for a very large and completely independent multi-site dataset, compared to an ensemble baseline.



### Constructing Fast Network through Deconstruction of Convolution
- **Arxiv ID**: http://arxiv.org/abs/1806.07370v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1806.07370v5)
- **Published**: 2018-05-28 10:54:27+00:00
- **Updated**: 2018-10-31 13:28:43+00:00
- **Authors**: Yunho Jeon, Junmo Kim
- **Comment**: To be appeared in NIPS 2018
- **Journal**: None
- **Summary**: Convolutional neural networks have achieved great success in various vision tasks; however, they incur heavy resource costs. By using deeper and wider networks, network accuracy can be improved rapidly. However, in an environment with limited resources (e.g., mobile applications), heavy networks may not be usable. This study shows that naive convolution can be deconstructed into a shift operation and pointwise convolution. To cope with various convolutions, we propose a new shift operation called active shift layer (ASL) that formulates the amount of shift as a learnable function with shift parameters. This new layer can be optimized end-to-end through backpropagation and it can provide optimal shift values. Finally, we apply this layer to a light and fast network that surpasses existing state-of-the-art networks.



### Versatile Auxiliary Regressor with Generative Adversarial network (VAR+GAN)
- **Arxiv ID**: http://arxiv.org/abs/1805.10864v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1805.10864v1)
- **Published**: 2018-05-28 10:55:12+00:00
- **Updated**: 2018-05-28 10:55:12+00:00
- **Authors**: Shabab Bazrafkan, Peter Corcoran
- **Comment**: None
- **Journal**: None
- **Summary**: Being able to generate constrained samples is one of the most appealing applications of the deep generators. Conditional generators are one of the successful implementations of such models wherein the created samples are constrained to a specific class. In this work, the application of these networks is extended to regression problems wherein the conditional generator is restrained to any continuous aspect of the data. A new loss function is presented for the regression network and also implementations for generating faces with any particular set of landmarks is provided.



### CerfGAN: A Compact, Effective, Robust, and Fast Model for Unsupervised Multi-Domain Image-to-Image Translation
- **Arxiv ID**: http://arxiv.org/abs/1805.10871v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10871v2)
- **Published**: 2018-05-28 11:29:23+00:00
- **Updated**: 2019-01-15 20:44:54+00:00
- **Authors**: Xiao Liu, Shengchuan Zhang, Hong Liu, Xin Liu, Cheng Deng, Rongrong Ji
- **Comment**: 16 pages
- **Journal**: None
- **Summary**: In this paper, we aim at solving the multi-domain image-to-image translation problem with a unified model in an unsupervised manner. The most successful work in this area refers to StarGAN, which works well in tasks like face attribute modulation. However, StarGAN is unable to match multiple translation mappings when encountering general translations with very diverse domain shifts. On the other hand, StarGAN adopts an Encoder-Decoder-Discriminator (EDD) architecture, where the model is time-consuming and unstable to train. To this end, we propose a Compact, effective, robust, and fast GAN model, termed CerfGAN, to solve the above problem. In principle, CerfGAN contains a novel component, i.e., a multi-class discriminator (MCD), which gives the model an extremely powerful ability to match multiple translation mappings. To stabilize the training process, MCD also plays a role of the encoder in CerfGAN, which saves a lot of computation and memory costs. We perform extensive experiments to verify the effectiveness of the proposed method. Quantitatively, CerfGAN is demonstrated to handle a serial of image-to-image translation tasks including style transfer, season transfer, face hallucination, etc, where the input images are sampled from diverse domains. The comparisons to several recently proposed approaches demonstrate the superiority and novelty of the proposed method.



### Image Distortion Detection using Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1805.10881v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10881v1)
- **Published**: 2018-05-28 12:04:53+00:00
- **Updated**: 2018-05-28 12:04:53+00:00
- **Authors**: Namhyuk Ahn, Byungkon Kang, Kyung-Ah Sohn
- **Comment**: Accepted to ACPR 2017
- **Journal**: None
- **Summary**: Image distortion classification and detection is an important task in many applications. For example when compressing images, if we know the exact location of the distortion, then it is possible to re-compress images by adjusting the local compression level dynamically. In this paper, we address the problem of detecting the distortion region and classifying the distortion type of a given image. We show that our model significantly outperforms the state-of-the-art distortion classifier, and report accurate detection results for the first time. We expect that such results prove the usefulness of our approach in many potential applications such as image compression or distortion restoration.



### Training Medical Image Analysis Systems like Radiologists
- **Arxiv ID**: http://arxiv.org/abs/1805.10884v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1805.10884v3)
- **Published**: 2018-05-28 12:11:03+00:00
- **Updated**: 2019-02-04 05:12:29+00:00
- **Authors**: Gabriel Maicas, Andrew P. Bradley, Jacinto C. Nascimento, Ian Reid, Gustavo Carneiro
- **Comment**: Oral Presentation at MICCAI 2018
- **Journal**: None
- **Summary**: The training of medical image analysis systems using machine learning approaches follows a common script: collect and annotate a large dataset, train the classifier on the training set, and test it on a hold-out test set. This process bears no direct resemblance with radiologist training, which is based on solving a series of tasks of increasing difficulty, where each task involves the use of significantly smaller datasets than those used in machine learning. In this paper, we propose a novel training approach inspired by how radiologists are trained. In particular, we explore the use of meta-training that models a classifier based on a series of tasks. Tasks are selected using teacher-student curriculum learning, where each task consists of simple classification problems containing small training sets. We hypothesize that our proposed meta-training approach can be used to pre-train medical image analysis models. This hypothesis is tested on the automatic breast screening classification from DCE-MRI trained with weakly labeled datasets. The classification performance achieved by our approach is shown to be the best in the field for that application, compared to state of art baseline approaches: DenseNet, multiple instance learning and multi-task learning.



### Online Multi-Object Tracking with Historical Appearance Matching and Scene Adaptive Detection Filtering
- **Arxiv ID**: http://arxiv.org/abs/1805.10916v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10916v4)
- **Published**: 2018-05-28 13:36:09+00:00
- **Updated**: 2018-09-18 12:31:13+00:00
- **Authors**: Young-chul Yoon, Abhijeet Boragule, Young-min Song, Kwangjin Yoon, Moongu Jeon
- **Comment**: Accepted to IEEE International Conference on Advanced Video and
  Signal-based Surveillance(AVSS) 2018
- **Journal**: None
- **Summary**: In this paper, we propose the methods to handle temporal errors during multi-object tracking. Temporal error occurs when objects are occluded or noisy detections appear near the object. In those situations, tracking may fail and various errors like drift or ID-switching occur. It is hard to overcome temporal errors only by using motion and shape information. So, we propose the historical appearance matching method and joint-input siamese network which was trained by 2-step process. It can prevent tracking failures although objects are temporally occluded or last matching information is unreliable. We also provide useful technique to remove noisy detections effectively according to scene condition. Tracking performance, especially identity consistency, is highly improved by attaching our methods.



### Face hallucination using cascaded super-resolution and identity priors
- **Arxiv ID**: http://arxiv.org/abs/1805.10938v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10938v2)
- **Published**: 2018-05-28 14:25:31+00:00
- **Updated**: 2019-02-11 07:59:44+00:00
- **Authors**: Klemen Grm, Simon Dobrišek, Walter J. Scheirer, Vitomir Štruc
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we address the problem of hallucinating high-resolution facial images from unaligned low-resolution inputs at high magnification factors. We approach the problem with convolutional neural networks (CNNs) and propose a novel (deep) face hallucination model that incorporates identity priors into the learning procedure. The model consists of two main parts: i) a cascaded super-resolution network that upscales the low-resolution images, and ii) an ensemble of face recognition models that act as identity priors for the super-resolution network during training. Different from competing super-resolution approaches that typically rely on a single model for upscaling (even with large magnification factors), our network uses a cascade of multiple SR models that progressively upscale the low-resolution images using steps of $2\times$. This characteristic allows us to apply supervision signals (target appearances) at different resolutions and incorporate identity constraints at multiple-scales. Our model is able to upscale (very) low-resolution images captured in unconstrained conditions and produce visually convincing results. We rigorously evaluate the proposed model on a large datasets of facial images and report superior performance compared to the state-of-the-art.



### Fusion of Methods Based on Minutiae, Ridges and Pores for Robust Fingerprint Recognition
- **Arxiv ID**: http://arxiv.org/abs/1805.10949v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10949v1)
- **Published**: 2018-05-28 14:39:47+00:00
- **Updated**: 2018-05-28 14:39:47+00:00
- **Authors**: Lucas Alexandre Ramos, Aparecido Nilceu Marana
- **Comment**: None
- **Journal**: None
- **Summary**: The use of physical and behavioral characteristics for human identification is known as biometrics. Among the many biometrics traits available, the fingerprint is the most widely used. The fingerprint identification is based on the impression patterns, as the pattern of ridges and minutiae, characteristics of first and second levels respectively. The current identification systems use these two levels of fingerprint features due to the low cost of the sensors. However, due the recent advances in sensor technology, it is possible to use third level features present within the ridges, such as the perspiration pores. Recent studies have shown that the use of third-level features can increase security and fraud protection in biometric systems, since they are difficult to reproduce. In addition, recent researches have also focused on multibiometrics recognition due to its many advantages. The goal of this work was to apply fusion techniques for fingerprint recognition in order to combine minutiae, ridges and pore-based methods and, thus, provide more robust biometrics recognition systems. We evaluated isotropic-based and adaptive-based automatic pore extraction methods and the fusion of pore-based method with the identification methods based on minutiae and ridges. The experiments were performed on the public database PolyU HRF and showed a reduction of approximately 16% in the Equal Error Rate compared to the best results obtained by the methods individually.



### GLAC Net: GLocal Attention Cascading Networks for Multi-image Cued Story Generation
- **Arxiv ID**: http://arxiv.org/abs/1805.10973v3
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, 68T99, I.2.7
- **Links**: [PDF](http://arxiv.org/pdf/1805.10973v3)
- **Published**: 2018-05-28 15:30:21+00:00
- **Updated**: 2019-02-13 05:27:28+00:00
- **Authors**: Taehyeong Kim, Min-Oh Heo, Seonil Son, Kyoung-Wha Park, Byoung-Tak Zhang
- **Comment**: 6 pages, 3 figures, paper for Visual Storytelling Challenge in
  Storytelling Workshop co-located with NAACL 2018, source code and pre-trained
  models are available at https://github.com/tkim-snu/GLACNet
- **Journal**: None
- **Summary**: The task of multi-image cued story generation, such as visual storytelling dataset (VIST) challenge, is to compose multiple coherent sentences from a given sequence of images. The main difficulty is how to generate image-specific sentences within the context of overall images. Here we propose a deep learning network model, GLAC Net, that generates visual stories by combining global-local (glocal) attention and context cascading mechanisms. The model incorporates two levels of attention, i.e., overall encoding level and image feature level, to construct image-dependent sentences. While standard attention configuration needs a large number of parameters, the GLAC Net implements them in a very simple way via hard connections from the outputs of encoders or image features onto the sentence generators. The coherency of the generated story is further improved by conveying (cascading) the information of the previous sentence to the next sentence serially. We evaluate the performance of the GLAC Net on the visual storytelling dataset (VIST) and achieve very competitive results compared to the state-of-the-art techniques. Our code and pre-trained models are available here.



### Long-term Large-scale Mapping and Localization Using maplab
- **Arxiv ID**: http://arxiv.org/abs/1805.10994v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1805.10994v1)
- **Published**: 2018-05-28 15:57:32+00:00
- **Updated**: 2018-05-28 15:57:32+00:00
- **Authors**: Marcin Dymczyk, Marius Fehr, Thomas Schneider, Roland Siegwart
- **Comment**: Workshop on Long-term autonomy and deployment of intelligent robots
  in the real-world, ICRA 2018, Brisbane, Australia
- **Journal**: None
- **Summary**: This paper discusses a large-scale and long-term mapping and localization scenario using the maplab open-source framework. We present a brief overview of the specific algorithms in the system that enable building a consistent map from multiple sessions. We then demonstrate that such a map can be reused even a few months later for efficient 6-DoF localization and also new trajectories can be registered within the existing 3D model. The datasets presented in this paper are made publicly available.



### Adversarial Examples in Remote Sensing
- **Arxiv ID**: http://arxiv.org/abs/1805.10997v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.10997v1)
- **Published**: 2018-05-28 16:01:05+00:00
- **Updated**: 2018-05-28 16:01:05+00:00
- **Authors**: Wojciech Czaja, Neil Fendley, Michael Pekala, Christopher Ratto, I-Jeng Wang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper considers attacks against machine learning algorithms used in remote sensing applications, a domain that presents a suite of challenges that are not fully addressed by current research focused on natural image data such as ImageNet. In particular, we present a new study of adversarial examples in the context of satellite image classification problems. Using a recently curated data set and associated classifier, we provide a preliminary analysis of adversarial examples in settings where the targeted classifier is permitted multiple observations of the same location over time. While our experiments to date are purely digital, our problem setup explicitly incorporates a number of practical considerations that a real-world attacker would need to take into account when mounting a physical attack. We hope this work provides a useful starting point for future studies of potential vulnerabilities in this setting.



### BlockCNN: A Deep Network for Artifact Removal and Image Compression
- **Arxiv ID**: http://arxiv.org/abs/1805.11091v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11091v1)
- **Published**: 2018-05-28 17:29:48+00:00
- **Updated**: 2018-05-28 17:29:48+00:00
- **Authors**: Danial Maleki, Soheila Nadalian, Mohammad Mahdi Derakhshani, Mohammad Amin Sadeghi
- **Comment**: None
- **Journal**: The IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR) Workshops, 2018, pp. 2555-2558
- **Summary**: We present a general technique that performs both artifact removal and image compression. For artifact removal, we input a JPEG image and try to remove its compression artifacts. For compression, we input an image and process its 8 by 8 blocks in a sequence. For each block, we first try to predict its intensities based on previous blocks; then, we store a residual with respect to the input image. Our technique reuses JPEG's legacy compression and decompression routines. Both our artifact removal and our image compression techniques use the same deep network, but with different training weights. Our technique is simple and fast and it significantly improves the performance of artifact removal and image compression.



### Adding New Tasks to a Single Network with Weight Transformations using Binary Masks
- **Arxiv ID**: http://arxiv.org/abs/1805.11119v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11119v2)
- **Published**: 2018-05-28 18:22:42+00:00
- **Updated**: 2018-06-14 17:26:08+00:00
- **Authors**: Massimiliano Mancini, Elisa Ricci, Barbara Caputo, Samuel Rota Bulò
- **Comment**: None
- **Journal**: None
- **Summary**: Visual recognition algorithms are required today to exhibit adaptive abilities. Given a deep model trained on a specific, given task, it would be highly desirable to be able to adapt incrementally to new tasks, preserving scalability as the number of new tasks increases, while at the same time avoiding catastrophic forgetting issues. Recent work has shown that masking the internal weights of a given original conv-net through learned binary variables is a promising strategy. We build upon this intuition and take into account more elaborated affine transformations of the convolutional weights that include learned binary masks. We show that with our generalization it is possible to achieve significantly higher levels of adaptation to new tasks, enabling the approach to compete with fine tuning strategies by requiring slightly more than 1 bit per network parameter per additional task. Experiments on two popular benchmarks showcase the power of our approach, that achieves the new state of the art on the Visual Decathlon Challenge.



### Global Sum Pooling: A Generalization Trick for Object Counting with Small Datasets of Large Images
- **Arxiv ID**: http://arxiv.org/abs/1805.11123v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11123v2)
- **Published**: 2018-05-28 18:33:37+00:00
- **Updated**: 2019-09-27 04:06:21+00:00
- **Authors**: Shubhra Aich, Ian Stavness
- **Comment**: CVPR 2019 Deep Vision Workshop
  (https://sites.google.com/view/deepvision2019)
- **Journal**: None
- **Summary**: In this paper, we explore the problem of training one-look regression models for counting objects in datasets comprising a small number of high-resolution, variable-shaped images. We illustrate that conventional global average pooling (GAP) based models are unreliable due to the patchwise cancellation of true overestimates and underestimates for patchwise inference. To overcome this limitation and reduce overfitting caused by the training on full-resolution images, we propose to employ global sum pooling (GSP) instead of GAP or fully connected (FC) layers at the backend of a convolutional network. Although computationally equivalent to GAP, we show through comprehensive experimentation that GSP allows convolutional networks to learn the counting task as a simple linear mapping problem generalized over the input shape and the number of objects present. This generalization capability allows GSP to avoid both patchwise cancellation and overfitting by training on small patches and inference on full-resolution images as a whole. We evaluate our approach on four different aerial image datasets - two car counting datasets (CARPK and COWC), one crowd counting dataset (ShanghaiTech; parts A and B) and one new challenging dataset for wheat spike counting. Our GSP models improve upon the state-of-the-art approaches on all four datasets with a simple architecture. Also, GSP architectures trained with smaller-sized image patches exhibit better localization property due to their focus on learning from smaller regions while training.



### Exemplar Guided Unsupervised Image-to-Image Translation with Semantic Consistency
- **Arxiv ID**: http://arxiv.org/abs/1805.11145v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11145v4)
- **Published**: 2018-05-28 19:47:07+00:00
- **Updated**: 2019-03-13 18:30:30+00:00
- **Authors**: Liqian Ma, Xu Jia, Stamatios Georgoulis, Tinne Tuytelaars, Luc Van Gool
- **Comment**: To appear in ICLR 2019
- **Journal**: None
- **Summary**: Image-to-image translation has recently received significant attention due to advances in deep learning. Most works focus on learning either a one-to-one mapping in an unsupervised way or a many-to-many mapping in a supervised way. However, a more practical setting is many-to-many mapping in an unsupervised way, which is harder due to the lack of supervision and the complex inner- and cross-domain variations. To alleviate these issues, we propose the Exemplar Guided & Semantically Consistent Image-to-image Translation (EGSC-IT) network which conditions the translation process on an exemplar image in the target domain. We assume that an image comprises of a content component which is shared across domains, and a style component specific to each domain. Under the guidance of an exemplar from the target domain we apply Adaptive Instance Normalization to the shared content component, which allows us to transfer the style information of the target domain to the source domain. To avoid semantic inconsistencies during translation that naturally appear due to the large inner- and cross-domain variations, we introduce the concept of feature masks that provide coarse semantic guidance without requiring the use of any semantic labels. Experimental results on various datasets show that EGSC-IT does not only translate the source image to diverse instances in the target domain, but also preserves the semantic consistency during the process.



### Unsupervised Learning of Artistic Styles with Archetypal Style Analysis
- **Arxiv ID**: http://arxiv.org/abs/1805.11155v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.11155v2)
- **Published**: 2018-05-28 19:58:01+00:00
- **Updated**: 2018-10-02 15:59:02+00:00
- **Authors**: Daan Wynen, Cordelia Schmid, Julien Mairal
- **Comment**: Accepted at NIPS 2018, Montr\'eal, Canada
- **Journal**: None
- **Summary**: In this paper, we introduce an unsupervised learning approach to automatically discover, summarize, and manipulate artistic styles from large collections of paintings. Our method is based on archetypal analysis, which is an unsupervised learning technique akin to sparse coding with a geometric interpretation. When applied to deep image representations from a collection of artworks, it learns a dictionary of archetypal styles, which can be easily visualized. After training the model, the style of a new image, which is characterized by local statistics of deep visual features, is approximated by a sparse convex combination of archetypes. This enables us to interpret which archetypal styles are present in the input image, and in which proportion. Finally, our approach allows us to manipulate the coefficients of the latent archetypal decomposition, and achieve various special effects such as style enhancement, transfer, and interpolation between multiple archetypes.



### Confidence Prediction for Lexicon-Free OCR
- **Arxiv ID**: http://arxiv.org/abs/1805.11161v1
- **DOI**: 10.1109/WACV.2018.00030
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11161v1)
- **Published**: 2018-05-28 20:24:04+00:00
- **Updated**: 2018-05-28 20:24:04+00:00
- **Authors**: Noam Mor, Lior Wolf
- **Comment**: None
- **Journal**: None
- **Summary**: Having a reliable accuracy score is crucial for real world applications of OCR, since such systems are judged by the number of false readings. Lexicon-based OCR systems, which deal with what is essentially a multi-class classification problem, often employ methods explicitly taking into account the lexicon, in order to improve accuracy. However, in lexicon-free scenarios, filtering errors requires an explicit confidence calculation. In this work we show two explicit confidence measurement techniques, and show that they are able to achieve a significant reduction in misreads on both standard benchmarks and a proprietary dataset.



### Towards computational fluorescence microscopy: Machine learning-based integrated prediction of morphological and molecular tumor profiles
- **Arxiv ID**: http://arxiv.org/abs/1805.11178v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.11178v1)
- **Published**: 2018-05-28 21:16:30+00:00
- **Updated**: 2018-05-28 21:16:30+00:00
- **Authors**: Alexander Binder, Michael Bockmayr, Miriam Hägele, Stephan Wienert, Daniel Heim, Katharina Hellweg, Albrecht Stenzinger, Laura Parlow, Jan Budczies, Benjamin Goeppert, Denise Treue, Manato Kotani, Masaru Ishii, Manfred Dietel, Andreas Hocke, Carsten Denkert, Klaus-Robert Müller, Frederick Klauschen
- **Comment**: None
- **Journal**: None
- **Summary**: Recent advances in cancer research largely rely on new developments in microscopic or molecular profiling techniques offering high level of detail with respect to either spatial or molecular features, but usually not both. Here, we present a novel machine learning-based computational approach that allows for the identification of morphological tissue features and the prediction of molecular properties from breast cancer imaging data. This integration of microanatomic information of tumors with complex molecular profiling data, including protein or gene expression, copy number variation, gene methylation and somatic mutations, provides a novel means to computationally score molecular markers with respect to their relevance to cancer and their spatial associations within the tumor microenvironment.



### Learning From Less Data: Diversified Subset Selection and Active Learning in Image Classification Tasks
- **Arxiv ID**: http://arxiv.org/abs/1805.11191v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.11191v1)
- **Published**: 2018-05-28 22:27:29+00:00
- **Updated**: 2018-05-28 22:27:29+00:00
- **Authors**: Vishal Kaushal, Anurag Sahoo, Khoshrav Doctor, Narasimha Raju, Suyash Shetty, Pankaj Singh, Rishabh Iyer, Ganesh Ramakrishnan
- **Comment**: 15 pages, 7 figures
- **Journal**: None
- **Summary**: Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry and pose the challenges of not having adequate computing resources and of high costs involved in human labeling efforts. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges respectively. A special class of subset selection functions naturally model notions of diversity, coverage and representation and they can be used to eliminate redundancy and thus lend themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location and Disparity-Min models for training-data subset selection and reducing labeling effort. We do this for a variety of computer vision tasks including Gender Recognition, Scene Recognition and Object Recognition. Our results show that subset selection done in the right way can add 2-3% in accuracy on existing baselines, particularly in the case of less training data. This allows the training of complex machine learning models (like Convolutional Neural Networks) with much less training data while incurring minimal performance loss.



### CapsNet comparative performance evaluation for image classification
- **Arxiv ID**: http://arxiv.org/abs/1805.11195v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.11195v1)
- **Published**: 2018-05-28 22:54:17+00:00
- **Updated**: 2018-05-28 22:54:17+00:00
- **Authors**: Rinat Mukhometzianov, Juan Carrillo
- **Comment**: None
- **Journal**: None
- **Summary**: Image classification has become one of the main tasks in the field of computer vision technologies. In this context, a recent algorithm called CapsNet that implements an approach based on activity vectors and dynamic routing between capsules may overcome some of the limitations of the current state of the art artificial neural networks (ANN) classifiers, such as convolutional neural networks (CNN). In this paper, we evaluated the performance of the CapsNet algorithm in comparison with three well-known classifiers (Fisher-faces, LeNet, and ResNet). We tested the classification accuracy on four datasets with a different number of instances and classes, including images of faces, traffic signs, and everyday objects. The evaluation results show that even for simple architectures, training the CapsNet algorithm requires significant computational resources and its classification performance falls below the average accuracy values of the other three classifiers. However, we argue that CapsNet seems to be a promising new technique for image classification, and further experiments using more robust computation resources and re-fined CapsNet architectures may produce better outcomes.



