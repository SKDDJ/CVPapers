# Arxiv Papers in cs.CV on 2018-05-21
### Parallel Transport Convolution: A New Tool for Convolutional Neural Networks on Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1805.07857v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, math.NA, stat.ML, 68U05, 68T05, 68T10
- **Links**: [PDF](http://arxiv.org/pdf/1805.07857v2)
- **Published**: 2018-05-21 01:13:20+00:00
- **Updated**: 2018-12-08 21:36:34+00:00
- **Authors**: Stefan C. Schonsheck, Bin Dong, Rongjie Lai
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Convolution has been playing a prominent role in various applications in science and engineering for many years. It is the most important operation in convolutional neural networks. There has been a recent growth of interests of research in generalizing convolutions on curved domains such as manifolds and graphs. However, existing approaches cannot preserve all the desirable properties of Euclidean convolutions, namely compactly supported filters, directionality, transferability across different manifolds. In this paper we develop a new generalization of the convolution operation, referred to as parallel transport convolution (PTC), on Riemannian manifolds and their discrete counterparts. PTC is designed based on the parallel transportation which is able to translate information along a manifold and to intrinsically preserve directionality. PTC allows for the construction of compactly supported filters and is also robust to manifold deformations. This enables us to preform wavelet-like operations and to define deep convolutional neural networks on curved domains.



### Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference
- **Arxiv ID**: http://arxiv.org/abs/1805.07862v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.07862v2)
- **Published**: 2018-05-21 01:49:18+00:00
- **Updated**: 2018-09-29 20:30:06+00:00
- **Authors**: Ruying Bao, Sihang Liang, Qingcan Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have been demonstrated to be vulnerable to adversarial attacks, where small perturbations intentionally added to the original inputs can fool the classifier. In this paper, we propose a defense method, Featurized Bidirectional Generative Adversarial Networks (FBGAN), to extract the semantic features of the input and filter the non-semantic perturbation. FBGAN is pre-trained on the clean dataset in an unsupervised manner, adversarially learning a bidirectional mapping between the high-dimensional data space and the low-dimensional semantic space; also mutual information is applied to disentangle the semantically meaningful features. After the bidirectional mapping, the adversarial data can be reconstructed to denoised data, which could be fed into any pre-trained classifier. We empirically show the quality of reconstruction images and the effectiveness of defense.



### Spherical Convolutional Neural Network for 3D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/1805.07872v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07872v2)
- **Published**: 2018-05-21 02:32:31+00:00
- **Updated**: 2018-05-22 05:27:34+00:00
- **Authors**: Huan Lei, Naveed Akhtar, Ajmal Mian
- **Comment**: Submitted to a conference
- **Journal**: None
- **Summary**: We propose a neural network for 3D point cloud processing that exploits `spherical' convolution kernels and octree partitioning of space. The proposed metric-based spherical kernels systematically quantize point neighborhoods to identify local geometric structures in data, while maintaining the properties of translation-invariance and asymmetry. The network architecture itself is guided by octree data structuring that takes full advantage of the sparse nature of irregular point clouds. We specify spherical kernels with the help of neurons in each layer that in turn are associated with spatial locations. We exploit this association to avert dynamic kernel generation during network training, that enables efficient learning with high resolution point clouds. We demonstrate the utility of the spherical convolutional neural network for 3D object classification on standard benchmark datasets.



### How Many Samples are Needed to Estimate a Convolutional or Recurrent Neural Network?
- **Arxiv ID**: http://arxiv.org/abs/1805.07883v3
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.07883v3)
- **Published**: 2018-05-21 03:56:17+00:00
- **Updated**: 2019-06-30 00:24:50+00:00
- **Authors**: Simon S. Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan Salakhutdinov, Aarti Singh
- **Comment**: Revised version, with new results on recurrent neural networks.
  Preliminary version in NeurIPS 2018
- **Journal**: None
- **Summary**: It is widely believed that the practical success of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) owes to the fact that CNNs and RNNs use a more compact parametric representation than their Fully-Connected Neural Network (FNN) counterparts, and consequently require fewer training examples to accurately estimate their parameters. We initiate the study of rigorously characterizing the sample-complexity of estimating CNNs and RNNs. We show that the sample-complexity to learn CNNs and RNNs scales linearly with their intrinsic dimension and this sample-complexity is much smaller than for their FNN counterparts. For both CNNs and RNNs, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main technical tools for deriving these results are a localized empirical process analysis and a new technical lemma characterizing the convolutional and recurrent structure. We believe that these tools may inspire further developments in understanding CNNs and RNNs.



### DeepPhys: Video-Based Physiological Measurement Using Convolutional Attention Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.07888v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1805.07888v2)
- **Published**: 2018-05-21 04:42:42+00:00
- **Updated**: 2018-08-07 19:25:30+00:00
- **Authors**: Weixuan Chen, Daniel McDuff
- **Comment**: Accepted paper at ECCV 2018. 16 pages, 3 figures, supplementary
  materials in the ancillary files
- **Journal**: None
- **Summary**: Non-contact video-based physiological measurement has many applications in health care and human-computer interaction. Practical applications require measurements to be accurate even in the presence of large head rotations. We propose the first end-to-end system for video-based measurement of heart and breathing rate using a deep convolutional network. The system features a new motion representation based on a skin reflection model and a new attention mechanism using appearance information to guide motion estimation, both of which enable robust measurement under heterogeneous lighting and major motions. Our approach significantly outperforms all current state-of-the-art methods on both RGB and infrared video datasets. Furthermore, it allows spatial-temporal distributions of physiological signals to be visualized via the attention mechanism.



### Constructing Unrestricted Adversarial Examples with Generative Models
- **Arxiv ID**: http://arxiv.org/abs/1805.07894v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.07894v4)
- **Published**: 2018-05-21 05:19:08+00:00
- **Updated**: 2018-12-02 22:18:56+00:00
- **Authors**: Yang Song, Rui Shu, Nate Kushman, Stefano Ermon
- **Comment**: Neural Information Processing Systems (NeurIPS 2018)
- **Journal**: None
- **Summary**: Adversarial examples are typically constructed by perturbing an existing data point within a small matrix norm, and current defense methods are focused on guarding against this type of attack. In this paper, we propose unrestricted adversarial examples, a new threat model where the attackers are not restricted to small norm-bounded perturbations. Different from perturbation-based attacks, we propose to synthesize unrestricted adversarial examples entirely from scratch using conditional generative models. Specifically, we first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to model the class-conditional distribution over data samples. Then, conditioned on a desired class, we search over the AC-GAN latent space to find images that are likely under the generative model and are misclassified by a target classifier. We demonstrate through human evaluation that unrestricted adversarial examples generated this way are legitimate and belong to the desired class. Our empirical results on the MNIST, SVHN, and CelebA datasets show that unrestricted adversarial examples can bypass strong adversarial training and certified defense methods designed for traditional adversarial attacks.



### Unsupervised Deep Context Prediction for Background Foreground Separation
- **Arxiv ID**: http://arxiv.org/abs/1805.07903v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07903v1)
- **Published**: 2018-05-21 06:12:15+00:00
- **Updated**: 2018-05-21 06:12:15+00:00
- **Authors**: Maryam Sultana, Arif Mahmood, Sajid Javed, Soon Ki Jung
- **Comment**: 17 pages
- **Journal**: Machine Vision and Applications 2018
- **Summary**: In many advanced video based applications background modeling is a pre-processing step to eliminate redundant data, for instance in tracking or video surveillance applications. Over the past years background subtraction is usually based on low level or hand-crafted features such as raw color components, gradients, or local binary patterns. The background subtraction algorithms performance suffer in the presence of various challenges such as dynamic backgrounds, photometric variations, camera jitters, and shadows. To handle these challenges for the purpose of accurate background modeling we propose a unified framework based on the algorithm of image inpainting. It is an unsupervised visual feature learning hybrid Generative Adversarial algorithm based on context prediction. We have also presented the solution of random region inpainting by the fusion of center region inpaiting and random region inpainting with the help of poisson blending technique. Furthermore we also evaluated foreground object detection with the fusion of our proposed method and morphological operations. The comparison of our proposed method with 12 state-of-the-art methods shows its stability in the application of background estimation and foreground detection.



### Class Representative Autoencoder for Low Resolution Multi-Spectral Gender Classification
- **Arxiv ID**: http://arxiv.org/abs/1805.07905v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07905v1)
- **Published**: 2018-05-21 06:26:29+00:00
- **Updated**: 2018-05-21 06:26:29+00:00
- **Authors**: Maneet Singh, Shruti Nagpal, Richa Singh, Mayank Vatsa
- **Comment**: Published at IJCNN 2017
- **Journal**: None
- **Summary**: Gender is one of the most common attributes used to describe an individual. It is used in multiple domains such as human computer interaction, marketing, security, and demographic reports. Research has been performed to automate the task of gender recognition in constrained environment using face images, however, limited attention has been given to gender classification in unconstrained scenarios. This work attempts to address the challenging problem of gender classification in multi-spectral low resolution face images. We propose a robust Class Representative Autoencoder model, termed as AutoGen for the same. The proposed model aims to minimize the intra-class variations while maximizing the inter-class variations for the learned feature representations. Results on visible as well as near infrared spectrum data for different resolutions and multiple databases depict the efficacy of the proposed model. Comparative results with existing approaches and two commercial off-the-shelf systems further motivate the use of class representative features for classification.



### Multi-View Stereo with Asymmetric Checkerboard Propagation and Multi-Hypothesis Joint View Selection
- **Arxiv ID**: http://arxiv.org/abs/1805.07920v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07920v1)
- **Published**: 2018-05-21 07:10:59+00:00
- **Updated**: 2018-05-21 07:10:59+00:00
- **Authors**: Qingshan Xu, Wenbing Tao
- **Comment**: None
- **Journal**: None
- **Summary**: In computer vision domain, how to fast and accurately perform multiview stereo (MVS) is still a challenging problem. In this paper we present a fast yet accurate method for 3D dense reconstruction, called AMHMVS, built on the PatchMatch based stereo algorithm. Different from the regular symmetric propagation scheme, our approach adopts an asymmetric checkerboard propagation strategy, which can adaptively make effective hypotheses expand further according to the confidence of current neighbor hypotheses. In order to aggregate visual information from multiple images better, we propose the multi-hypothesis joint view selection for each pixel, which leverages a cost matrix based on the multiple propagated hypotheses to robustly infer an appropriate aggregation subset parallel. Combined with the above two steps, our approach not only has the capacity of massively parallel computation, but also obtains high accuracy and completeness. Experiments on extensive datasets show that our method achieves more accurate and robust results, and runs faster than the competing methods.



### Batch-Instance Normalization for Adaptively Style-Invariant Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.07925v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07925v3)
- **Published**: 2018-05-21 07:30:26+00:00
- **Updated**: 2019-04-25 08:02:35+00:00
- **Authors**: Hyeonseob Nam, Hyo-Eun Kim
- **Comment**: None
- **Journal**: None
- **Summary**: Real-world image recognition is often challenged by the variability of visual styles including object textures, lighting conditions, filter effects, etc. Although these variations have been deemed to be implicitly handled by more training data and deeper networks, recent advances in image style transfer suggest that it is also possible to explicitly manipulate the style information. Extending this idea to general visual recognition problems, we present Batch-Instance Normalization (BIN) to explicitly normalize unnecessary styles from images. Considering certain style features play an essential role in discriminative tasks, BIN learns to selectively normalize only disturbing styles while preserving useful styles. The proposed normalization module is easily incorporated into existing network architectures such as Residual Networks, and surprisingly improves the recognition performance in various scenarios. Furthermore, experiments verify that BIN effectively adapts to completely different tasks like object classification and style transfer, by controlling the trade-off between preserving and removing style variations. BIN can be implemented with only a few lines of code using popular deep learning frameworks.



### Asynchronous Convolutional Networks for Object Detection in Neuromorphic Cameras
- **Arxiv ID**: http://arxiv.org/abs/1805.07931v3
- **DOI**: None
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1805.07931v3)
- **Published**: 2018-05-21 07:53:26+00:00
- **Updated**: 2019-06-13 14:17:55+00:00
- **Authors**: Marco Cannici, Marco Ciccone, Andrea Romanoni, Matteo Matteucci
- **Comment**: accepted at CVPR2019 Event-based Vision Workshop
- **Journal**: None
- **Summary**: Event-based cameras, also known as neuromorphic cameras, are bioinspired sensors able to perceive changes in the scene at high frequency with low power consumption. Becoming available only very recently, a limited amount of work addresses object detection on these devices. In this paper we propose two neural networks architectures for object detection: YOLE, which integrates the events into surfaces and uses a frame-based model to process them, and fcYOLE, an asynchronous event-based fully convolutional network which uses a novel and general formalization of the convolutional and max pooling layers to exploit the sparsity of camera events. We evaluate the algorithm with different extensions of publicly available datasets and on a novel synthetic dataset.



### Bilinear Attention Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.07932v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.07932v2)
- **Published**: 2018-05-21 07:58:31+00:00
- **Updated**: 2018-10-19 11:29:49+00:00
- **Authors**: Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang
- **Comment**: Accepted by NIPS 2018; Figure 1 was updated
- **Journal**: None
- **Summary**: Attention networks in multimodal learning provide an efficient way to utilize given visual information selectively. However, the computational cost to learn attention distributions for every pair of multimodal input channels is prohibitively expensive. To solve this problem, co-attention builds two separate attention distributions for each modality neglecting the interaction between multimodal inputs. In this paper, we propose bilinear attention networks (BAN) that find bilinear attention distributions to utilize given vision-language information seamlessly. BAN considers bilinear interactions among two groups of input channels, while low-rank bilinear pooling extracts the joint representations for each pair of channels. Furthermore, we propose a variant of multimodal residual networks to exploit eight-attention maps of the BAN efficiently. We quantitatively and qualitatively evaluate our model on visual question answering (VQA 2.0) and Flickr30k Entities datasets, showing that BAN significantly outperforms previous methods and achieves new state-of-the-arts on both datasets.



### DEEPEYE: A Compact and Accurate Video Comprehension at Terminal Devices Compressed with Quantization and Tensorization
- **Arxiv ID**: http://arxiv.org/abs/1805.07935v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1805.07935v2)
- **Published**: 2018-05-21 08:08:07+00:00
- **Updated**: 2018-06-07 16:17:33+00:00
- **Authors**: Yuan Cheng, Guangya Li, Hai-Bao Chen, Sheldon X. -D. Tan, Hao Yu
- **Comment**: 10 pages, 9 figures and 2 tables
- **Journal**: None
- **Summary**: As it requires a huge number of parameters when exposed to high dimensional inputs in video detection and classification, there is a grand challenge to develop a compact yet accurate video comprehension at terminal devices. Current works focus on optimizations of video detection and classification in a separated fashion. In this paper, we introduce a video comprehension (object detection and action recognition) system for terminal devices, namely DEEPEYE. Based on You Only Look Once (YOLO), we have developed an 8-bit quantization method when training YOLO; and also developed a tensorized-compression method of Recurrent Neural Network (RNN) composed of features extracted from YOLO. The developed quantization and tensorization can significantly compress the original network model yet with maintained accuracy. Using the challenging video datasets: MOMENTS and UCF11 as benchmarks, the results show that the proposed DEEPEYE achieves 3.994x model compression rate with only 0.47% mAP decreased; and 15,047x parameter reduction and 2.87x speed-up with 16.58% accuracy improvement.



### Coarse-to-Fine Salient Object Detection with Low-Rank Matrix Recovery
- **Arxiv ID**: http://arxiv.org/abs/1805.07936v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.07936v4)
- **Published**: 2018-05-21 08:08:55+00:00
- **Updated**: 2019-09-09 01:50:50+00:00
- **Authors**: Qi Zheng, Shujian Yu, Xinge You, Qinmu Peng
- **Comment**: Manuscript accepted by Neurocomputing, matlab code is available from
  https://github.com/qizhust/HLRSaliency
- **Journal**: None
- **Summary**: Low-Rank Matrix Recovery (LRMR) has recently been applied to saliency detection by decomposing image features into a low-rank component associated with background and a sparse component associated with visual salient regions. Despite its great potential, existing LRMR-based saliency detection methods seldom consider the inter-relationship among elements within these two components, thus are prone to generating scattered or incomplete saliency maps. In this paper, we introduce a novel and efficient LRMR-based saliency detection model under a coarse-to-fine framework to circumvent this limitation. First, we roughly measure the saliency of image regions with a baseline LRMR model that integrates a $\ell_1$-norm sparsity constraint and a Laplacian regularization smooth term. Given samples from the coarse saliency map, we then learn a projection that maps image features to refined saliency values, to significantly sharpen the object boundaries and to preserve the object entirety. We evaluate our framework against existing LRMR-based methods on three benchmark datasets. Experimental results validate the superiority of our method as well as the effectiveness of our suggested coarse-to-fine framework, especially for images containing multiple objects.



### Quantizing Convolutional Neural Networks for Low-Power High-Throughput Inference Engines
- **Arxiv ID**: http://arxiv.org/abs/1805.07941v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.07941v1)
- **Published**: 2018-05-21 08:31:46+00:00
- **Updated**: 2018-05-21 08:31:46+00:00
- **Authors**: Sean O. Settle, Manasa Bollavaram, Paolo D'Alberto, Elliott Delaye, Oscar Fernandez, Nicholas Fraser, Aaron Ng, Ashish Sirasao, Michael Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning as a means to inferencing has proliferated thanks to its versatility and ability to approach or exceed human-level accuracy. These computational models have seemingly insatiable appetites for computational resources not only while training, but also when deployed at scales ranging from data centers all the way down to embedded devices. As such, increasing consideration is being made to maximize the computational efficiency given limited hardware and energy resources and, as a result, inferencing with reduced precision has emerged as a viable alternative to the IEEE 754 Standard for Floating-Point Arithmetic. We propose a quantization scheme that allows inferencing to be carried out using arithmetic that is fundamentally more efficient when compared to even half-precision floating-point. Our quantization procedure is significant in that we determine our quantization scheme parameters by calibrating against its reference floating-point model using a single inference batch rather than (re)training and achieve end-to-end post quantization accuracies comparable to the reference model.



### A Nonconvex Projection Method for Robust PCA
- **Arxiv ID**: http://arxiv.org/abs/1805.07962v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.NA, math.NA, 65F30, 65F50, 65K05, 65K10, 49M30
- **Links**: [PDF](http://arxiv.org/pdf/1805.07962v2)
- **Published**: 2018-05-21 09:49:06+00:00
- **Updated**: 2020-01-24 16:20:55+00:00
- **Authors**: Aritra Dutta, Filip Hanzely, Peter Richtárik
- **Comment**: In the proceedings of Thirty-Third AAAI Conference on Artificial
  Intelligence (AAAI-19)
- **Journal**: In the proceedings of Thirty-Third AAAI Conference on Artificial
  Intelligence (AAAI-19), 33(01), pp. 1468-1476, 2019
- **Summary**: Robust principal component analysis (RPCA) is a well-studied problem with the goal of decomposing a matrix into the sum of low-rank and sparse components. In this paper, we propose a nonconvex feasibility reformulation of RPCA problem and apply an alternating projection method to solve it. To the best of our knowledge, we are the first to propose a method that solves RPCA problem without considering any objective function, convex relaxation, or surrogate convex constraints. We demonstrate through extensive numerical experiments on a variety of applications, including shadow removal, background estimation, face detection, and galaxy evolution, that our approach matches and often significantly outperforms current state-of-the-art in various ways.



### Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.07997v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.07997v1)
- **Published**: 2018-05-21 11:43:12+00:00
- **Updated**: 2018-05-21 11:43:12+00:00
- **Authors**: Sitao Xiang, Hao Li
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning-based style transfer between images has recently become a popular area of research. A common way of encoding "style" is through a feature representation based on the Gram matrix of features extracted by some pre-trained neural network or some other form of feature statistics. Such a definition is based on an arbitrary human decision and may not best capture what a style really is. In trying to gain a better understanding of "style", we propose a metric learning-based method to explicitly encode the style of an artwork. In particular, our definition of style captures the differences between artists, as shown by classification performances, and such that the style representation can be interpreted, manipulated and visualized through style-conditioned image generation through a Generative Adversarial Network. We employ this method to explore the style space of anime portrait illustrations.



### Adversarial Noise Layer: Regularize Neural Network By Adding Noise
- **Arxiv ID**: http://arxiv.org/abs/1805.08000v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.08000v2)
- **Published**: 2018-05-21 11:50:59+00:00
- **Updated**: 2018-10-30 03:02:45+00:00
- **Authors**: Zhonghui You, Jinmian Ye, Kunming Li, Zenglin Xu, Ping Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a novel regularization method called Adversarial Noise Layer (ANL) and its efficient version called Class Adversarial Noise Layer (CANL), which are able to significantly improve CNN's generalization ability by adding carefully crafted noise into the intermediate layer activations. ANL and CANL can be easily implemented and integrated with most of the mainstream CNN-based models. We compared the effects of the different types of noise and visually demonstrate that our proposed adversarial noise instruct CNN models to learn to extract cleaner feature maps, which further reduce the risk of over-fitting. We also conclude that models trained with ANL or CANL are more robust to the adversarial examples generated by FGSM than the traditional adversarial training approaches.



### Object Detection in Equirectangular Panorama
- **Arxiv ID**: http://arxiv.org/abs/1805.08009v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08009v1)
- **Published**: 2018-05-21 12:11:38+00:00
- **Updated**: 2018-05-21 12:11:38+00:00
- **Authors**: Wenyan Yang, Yanlin Qian, Francesco Cricri, Lixin Fan, Joni-Kristian Kamarainen
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: We introduced a high-resolution equirectangular panorama (360-degree, virtual reality) dataset for object detection and propose a multi-projection variant of YOLO detector. The main challenge with equirectangular panorama image are i) the lack of annotated training data, ii) high-resolution imagery and iii) severe geometric distortions of objects near the panorama projection poles. In this work, we solve the challenges by i) using training examples available in the "conventional datasets" (ImageNet and COCO), ii) employing only low-resolution images that require only moderate GPU computing power and memory, and iii) our multi-projection YOLO handles projection distortions by making multiple stereographic sub-projections. In our experiments, YOLO outperforms the other state-of-art detector, Faster RCNN and our multi-projection YOLO achieves the best accuracy with low-resolution input.



### DifNet: Semantic Segmentation by Diffusion Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.08015v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08015v4)
- **Published**: 2018-05-21 12:29:02+00:00
- **Updated**: 2018-10-26 16:41:39+00:00
- **Authors**: Peng Jiang, Fanglin Gu, Yunhai Wang, Changhe Tu, Baoquan Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) have recently shown state of the art performance on semantic segmentation tasks, however, they still suffer from problems of poor boundary localization and spatial fragmented predictions. The difficulties lie in the requirement of making dense predictions from a long path model all at once since details are hard to keep when data goes through deeper layers. Instead, in this work, we decompose this difficult task into two relative simple sub-tasks: seed detection which is required to predict initial predictions without the need of wholeness and preciseness, and similarity estimation which measures the possibility of any two nodes belong to the same class without the need of knowing which class they are. We use one branch network for one sub-task each, and apply a cascade of random walks base on hierarchical semantics to approximate a complex diffusion process which propagates seed information to the whole image according to the estimated similarities. The proposed DifNet consistently produces improvements over the baseline models with the same depth and with the equivalent number of parameters, and also achieves promising performance on Pascal VOC and Pascal Context dataset. OurDifNet is trained end-to-end without complex loss functions.



### DiDA: Disentangled Synthesis for Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1805.08019v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08019v1)
- **Published**: 2018-05-21 12:43:17+00:00
- **Updated**: 2018-05-21 12:43:17+00:00
- **Authors**: Jinming Cao, Oren Katzir, Peng Jiang, Dani Lischinski, Danny Cohen-Or, Changhe Tu, Yangyan Li
- **Comment**: None
- **Journal**: None
- **Summary**: Unsupervised domain adaptation aims at learning a shared model for two related, but not identical, domains by leveraging supervision from a source domain to an unsupervised target domain. A number of effective domain adaptation approaches rely on the ability to extract discriminative, yet domain-invariant, latent factors which are common to both domains. Extracting latent commonality is also useful for disentanglement analysis, enabling separation between the common and the domain-specific features of both domains. In this paper, we present a method for boosting domain adaptation performance by leveraging disentanglement analysis. The key idea is that by learning to separately extract both the common and the domain-specific features, one can synthesize more target domain data with supervision, thereby boosting the domain adaptation performance. Better common feature extraction, in turn, helps further improve the disentanglement analysis and disentangled synthesis. We show that iterating between domain adaptation and disentanglement analysis can consistently improve each other on several unsupervised domain adaptation tasks, for various domain adaptation backbone models.



### Graph Capsule Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1805.08090v4
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.08090v4)
- **Published**: 2018-05-21 14:38:31+00:00
- **Updated**: 2018-08-26 00:13:38+00:00
- **Authors**: Saurabh Verma, Zhi-Li Zhang
- **Comment**: Accepted at Joint ICML and IJCAI Workshop on Computational Biology,
  Stockholm, Sweden, 2018
- **Journal**: None
- **Summary**: Graph Convolutional Neural Networks (GCNNs) are the most recent exciting advancement in deep learning field and their applications are quickly spreading in multi-cross-domains including bioinformatics, chemoinformatics, social networks, natural language processing and computer vision. In this paper, we expose and tackle some of the basic weaknesses of a GCNN model with a capsule idea presented in \cite{hinton2011transforming} and propose our Graph Capsule Network (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve especially graph classification problem which current GCNN models find challenging. Through extensive experiments, we show that our proposed Graph Capsule Network can significantly outperforms both the existing state-of-art deep learning methods and graph kernels on graph classification benchmark datasets.



### Variational based Mixed Noise Removal with CNN Deep Learning Regularization
- **Arxiv ID**: http://arxiv.org/abs/1805.08094v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1805.08094v1)
- **Published**: 2018-05-21 14:52:06+00:00
- **Updated**: 2018-05-21 14:52:06+00:00
- **Authors**: Faqiang Wang, Haiyang Huang, Jun Liu
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, the traditional model based variational method and learning based algorithms are naturally integrated to address mixed noise removal problem. To be different from single type noise (e.g. Gaussian) removal, it is a challenge problem to accurately discriminate noise types and levels for each pixel. We propose a variational method to iteratively estimate the noise parameters, and then the algorithm can automatically classify the noise according to the different statistical parameters. The proposed variational problem can be separated into regularization, synthesis, parameter estimation and noise classification four steps with the operator splitting scheme. Each step is related to an optimization subproblem. To enforce the regularization, the deep learning method is employed to learn the natural images priori. Compared with some model based regularizations, the CNN regularizer can significantly improve the quality of the restored images. Compared with some learning based methods, the synthesis step can produce better reconstructions by analyzing the recognized noise types and levels. In our method, the convolution neutral network (CNN) can be regarded as an operator which associated to a variational functional. From this viewpoint, the proposed method can be extended to many image reconstruction and inverse problems. Numerical experiments in the paper show that our method can achieve some state-of-the-art results for mixed noise removal.



### Small steps and giant leaps: Minimal Newton solvers for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1805.08095v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NA, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.08095v1)
- **Published**: 2018-05-21 14:54:28+00:00
- **Updated**: 2018-05-21 14:54:28+00:00
- **Authors**: João F. Henriques, Sebastien Ehrhardt, Samuel Albanie, Andrea Vedaldi
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a fast second-order method that can be used as a drop-in replacement for current deep learning solvers. Compared to stochastic gradient descent (SGD), it only requires two additional forward-mode automatic differentiation operations per iteration, which has a computational cost comparable to two standard forward passes and is easy to implement. Our method addresses long-standing issues with current second-order solvers, which invert an approximate Hessian matrix every iteration exactly or by conjugate-gradient methods, a procedure that is both costly and sensitive to noise. Instead, we propose to keep a single estimate of the gradient projected by the inverse Hessian matrix, and update it once per iteration. This estimate has the same size and is similar to the momentum variable that is commonly used in SGD. No estimate of the Hessian is maintained. We first validate our method, called CurveBall, on small problems with known closed-form solutions (noisy Rosenbrock function and degenerate 2-layer linear networks), where current deep learning solvers seem to struggle. We then train several large models on CIFAR and ImageNet, including ResNet and VGG-f networks, where we demonstrate faster convergence with no hyperparameter tuning. Code is available.



### Comparison of Semantic Segmentation Approaches for Horizon/Sky Line Detection
- **Arxiv ID**: http://arxiv.org/abs/1805.08105v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08105v1)
- **Published**: 2018-05-21 15:03:19+00:00
- **Updated**: 2018-05-21 15:03:19+00:00
- **Authors**: Touqeer Ahmad, Pavel Campr, Martin Čadík, George Bebis
- **Comment**: Proceedings of the International Joint Conference on Neural Networks
  (IJCNN) (oral presentation), IEEE Computational Intelligence Society, 2017
- **Journal**: None
- **Summary**: Horizon or skyline detection plays a vital role towards mountainous visual geo-localization, however most of the recently proposed visual geo-localization approaches rely on \textbf{user-in-the-loop} skyline detection methods. Detecting such a segmenting boundary fully autonomously would definitely be a step forward for these localization approaches. This paper provides a quantitative comparison of four such methods for autonomous horizon/sky line detection on an extensive data set. Specifically, we provide the comparison between four recently proposed segmentation methods; one explicitly targeting the problem of horizon detection\cite{Ahmad15}, second focused on visual geo-localization but relying on accurate detection of skyline \cite{Saurer16} and other two proposed for general semantic segmentation -- Fully Convolutional Networks (FCN) \cite{Long15} and SegNet\cite{Badrinarayanan15}. Each of the first two methods is trained on a common training set \cite{Baatz12} comprised of about 200 images while models for the third and fourth method are fine tuned for sky segmentation problem through transfer learning using the same data set. Each of the method is tested on an extensive test set (about 3K images) covering various challenging geographical, weather, illumination and seasonal conditions. We report average accuracy and average absolute pixel error for each of the presented formulation.



### Stacked Semantic-Guided Attention Model for Fine-Grained Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1805.08113v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08113v1)
- **Published**: 2018-05-21 15:12:19+00:00
- **Updated**: 2018-05-21 15:12:19+00:00
- **Authors**: Yunlong Yu, Zhong Ji, Yanwei Fu, Jichang Guo, Yanwei Pang, Zhongfei Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Zero-Shot Learning (ZSL) is achieved via aligning the semantic relationships between the global image feature vector and the corresponding class semantic descriptions. However, using the global features to represent fine-grained images may lead to sub-optimal results since they neglect the discriminative differences of local regions. Besides, different regions contain distinct discriminative information. The important regions should contribute more to the prediction. To this end, we propose a novel stacked semantics-guided attention (S2GA) model to obtain semantic relevant features by using individual class semantic features to progressively guide the visual features to generate an attention map for weighting the importance of different local regions. Feeding both the integrated visual features and the class semantic features into a multi-class classification architecture, the proposed framework can be trained end-to-end. Extensive experimental results on CUB and NABird datasets show that the proposed approach has a consistent improvement on both fine-grained zero-shot classification and retrieval tasks.



### Meta-learning with differentiable closed-form solvers
- **Arxiv ID**: http://arxiv.org/abs/1805.08136v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.08136v3)
- **Published**: 2018-05-21 15:44:51+00:00
- **Updated**: 2019-07-24 14:43:31+00:00
- **Authors**: Luca Bertinetto, João F. Henriques, Philip H. S. Torr, Andrea Vedaldi
- **Comment**: Published at ICLR'19. Code and data available at
  http://www.robots.ox.ac.uk/~luca/r2d2.html
- **Journal**: None
- **Summary**: Adapting deep networks to new concepts from a few examples is challenging, due to the high computational requirements of standard fine-tuning procedures. Most work on few-shot learning has thus focused on simple learning techniques for adaptation, such as nearest neighbours or gradient descent. Nonetheless, the machine learning literature contains a wealth of methods that learn non-deep models very efficiently. In this paper, we propose to use these fast convergent methods as the main adaptation mechanism for few-shot learning. The main idea is to teach a deep network to use standard machine learning tools, such as ridge regression, as part of its own internal model, enabling it to quickly adapt to novel data. This requires back-propagating errors through the solver steps. While normally the cost of the matrix operations involved in such a process would be significant, by using the Woodbury identity we can make the small number of examples work to our advantage. We propose both closed-form and iterative solvers, based on ridge regression and logistic regression components. Our methods constitute a simple and novel approach to the problem of few-shot learning and achieve performance competitive with or superior to the state of the art on three benchmarks.



### VideoCapsuleNet: A Simplified Network for Action Detection
- **Arxiv ID**: http://arxiv.org/abs/1805.08162v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08162v1)
- **Published**: 2018-05-21 16:28:47+00:00
- **Updated**: 2018-05-21 16:28:47+00:00
- **Authors**: Kevin Duarte, Yogesh S Rawat, Mubarak Shah
- **Comment**: None
- **Journal**: None
- **Summary**: The recent advances in Deep Convolutional Neural Networks (DCNNs) have shown extremely good results for video human action classification, however, action detection is still a challenging problem. The current action detection approaches follow a complex pipeline which involves multiple tasks such as tube proposals, optical flow, and tube classification. In this work, we present a more elegant solution for action detection based on the recently developed capsule network. We propose a 3D capsule network for videos, called VideoCapsuleNet: a unified network for action detection which can jointly perform pixel-wise action segmentation along with action classification. The proposed network is a generalization of capsule network from 2D to 3D, which takes a sequence of video frames as input. The 3D generalization drastically increases the number of capsules in the network, making capsule routing computationally expensive. We introduce capsule-pooling in the convolutional capsule layer to address this issue which makes the voting algorithm tractable. The routing-by-agreement in the network inherently models the action representations and various action characteristics are captured by the predicted capsules. This inspired us to utilize the capsules for action localization and the class-specific capsules predicted by the network are used to determine a pixel-wise localization of actions. The localization is further improved by parameterized skip connections with the convolutional capsule layers and the network is trained end-to-end with a classification as well as localization loss. The proposed network achieves sate-of-the-art performance on multiple action detection datasets including UCF-Sports, J-HMDB, and UCF-101 (24 classes) with an impressive ~20% improvement on UCF-101 and ~15% improvement on J-HMDB in terms of v-mAP scores.



### Turbo Learning for Captionbot and Drawingbot
- **Arxiv ID**: http://arxiv.org/abs/1805.08170v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08170v2)
- **Published**: 2018-05-21 16:43:47+00:00
- **Updated**: 2018-11-29 17:04:51+00:00
- **Authors**: Qiuyuan Huang, Pengchuan Zhang, Dapeng Wu, Lei Zhang
- **Comment**: in proceedings of NeurIPS 2018
- **Journal**: None
- **Summary**: We study in this paper the problems of both image captioning and text-to-image generation, and present a novel turbo learning approach to jointly training an image-to-text generator (a.k.a. CaptionBot) and a text-to-image generator (a.k.a. DrawingBot). The key idea behind the joint training is that image-to-text generation and text-to-image generation as dual problems can form a closed loop to provide informative feedback to each other. Based on such feedback, we introduce a new loss metric by comparing the original input with the output produced by the closed loop. In addition to the old loss metrics used in CaptionBot and DrawingBot, this extra loss metric makes the jointly trained CaptionBot and DrawingBot better than the separately trained CaptionBot and DrawingBot. Furthermore, the turbo-learning approach enables semi-supervised learning since the closed loop can provide pseudo-labels for unlabeled samples. Experimental results on the COCO dataset demonstrate that the proposed turbo learning can significantly improve the performance of both CaptionBot and DrawingBot by a large margin.



### Reproducibility Report for "Learning To Count Objects In Natural Images For Visual Question Answering"
- **Arxiv ID**: http://arxiv.org/abs/1805.08174v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1805.08174v1)
- **Published**: 2018-05-21 16:50:55+00:00
- **Updated**: 2018-05-21 16:50:55+00:00
- **Authors**: Shagun Sodhani, Vardaan Pahuja
- **Comment**: Submitted to Reproducibility in ML Workshop, ICML'18
- **Journal**: None
- **Summary**: This is the reproducibility report for the paper "Learning To Count Objects In Natural Images For Visual QuestionAnswering"



### Constrained Sparse Subspace Clustering with Side-Information
- **Arxiv ID**: http://arxiv.org/abs/1805.08183v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08183v2)
- **Published**: 2018-05-21 17:06:17+00:00
- **Updated**: 2018-05-22 01:10:51+00:00
- **Authors**: Chun-Guang Li, Junjian Zhang, Jun Guo
- **Comment**: 8 pages, 2 figures, and 3 tables. This work has been accepted by ICPR
  2018 as oral presentation
- **Journal**: None
- **Summary**: Subspace clustering refers to the problem of segmenting high dimensional data drawn from a union of subspaces into the respective subspaces. In some applications, partial side-information to indicate "must-link" or "cannot-link" in clustering is available. This leads to the task of subspace clustering with side-information. However, in prior work the supervision value of the side-information for subspace clustering has not been fully exploited. To this end, in this paper, we present an enhanced approach for constrained subspace clustering with side-information, termed Constrained Sparse Subspace Clustering plus (CSSC+), in which the side-information is used not only in the stage of learning an affinity matrix but also in the stage of spectral clustering. Moreover, we propose to estimate clustering accuracy based on the partial side-information and theoretically justify the connection to the ground-truth clustering accuracy in terms of the Rand index. We conduct experiments on three cancer gene expression datasets to validate the effectiveness of our proposals.



### Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation
- **Arxiv ID**: http://arxiv.org/abs/1805.08191v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1805.08191v3)
- **Published**: 2018-05-21 17:23:31+00:00
- **Updated**: 2019-01-18 07:58:43+00:00
- **Authors**: Qiuyuan Huang, Zhe Gan, Asli Celikyilmaz, Dapeng Wu, Jianfeng Wang, Xiaodong He
- **Comment**: Accepted to AAAI 2019
- **Journal**: None
- **Summary**: We propose a hierarchically structured reinforcement learning approach to address the challenges of planning for generating coherent multi-sentence stories for the visual storytelling task. Within our framework, the task of generating a story given a sequence of images is divided across a two-level hierarchical decoder. The high-level decoder constructs a plan by generating a semantic concept (i.e., topic) for each image in sequence. The low-level decoder generates a sentence for each image using a semantic compositional network, which effectively grounds the sentence generation conditioned on the topic. The two decoders are jointly trained end-to-end using reinforcement learning. We evaluate our model on the visual storytelling (VIST) dataset. Empirical results from both automatic and human evaluations demonstrate that the proposed hierarchically structured reinforced training achieves significantly better performance compared to a strong flat deep reinforcement learning baseline.



### A Simple Cache Model for Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1805.08709v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.08709v2)
- **Published**: 2018-05-21 17:50:14+00:00
- **Updated**: 2018-11-26 18:24:18+00:00
- **Authors**: A. Emin Orhan
- **Comment**: Published as a conference paper at NIPS 2018
- **Journal**: None
- **Summary**: Training large-scale image recognition models is computationally expensive. This raises the question of whether there might be simple ways to improve the test performance of an already trained model without having to re-train or fine-tune it with new data. Here, we show that, surprisingly, this is indeed possible. The key observation we make is that the layers of a deep network close to the output layer contain independent, easily extractable class-relevant information that is not contained in the output layer itself. We propose to extract this extra class-relevant information using a simple key-value cache memory to improve the classification performance of the model at test time. Our cache memory is directly inspired by a similar cache model previously proposed for language modeling (Grave et al., 2017). This cache component does not require any training or fine-tuning; it can be applied to any pre-trained model and, by properly setting only two hyper-parameters, leads to significant improvements in its classification performance. Improvements are observed across several architectures and datasets. In the cache component, using features extracted from layers close to the output (but not from the output layer itself) as keys leads to the largest improvements. Concatenating features from multiple layers to form keys can further improve performance over using single-layer features as keys. The cache component also has a regularizing effect, a simple consequence of which is that it substantially increases the robustness of models against adversarial attacks.



### Improving CNN classifiers by estimating test-time priors
- **Arxiv ID**: http://arxiv.org/abs/1805.08235v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08235v2)
- **Published**: 2018-05-21 18:06:53+00:00
- **Updated**: 2019-04-09 08:36:53+00:00
- **Authors**: Milan Sulc, Jiri Matas
- **Comment**: None
- **Journal**: None
- **Summary**: The problem of different training and test set class priors is addressed in the context of CNN classifiers. We compare two different approaches to estimating the new priors: an existing Maximum Likelihood Estimation approach (optimized by an EM algorithm or by projected gradient descend) and a proposed Maximum a Posteriori approach, which increases the stability of the estimate by introducing a Dirichlet hyper-prior on the class prior probabilities. Experimental results show a significant improvement on the fine-grained classification tasks using known evaluation-time priors, increasing the top-1 accuracy by 4.0% on the FGVC iNaturalist 2018 validation set and by 3.9% on the FGVCx Fungi 2018 validation set. Estimation of the unknown test set priors noticeably increases the accuracy on the PlantCLEF dataset, allowing a single CNN model to achieve state-of-the-art results and outperform the competition-winning ensemble of 12 CNNs. The proposed Maximum a Posteriori estimation increases the prediction accuracy by 2.8% on PlantCLEF 2017 and by 1.8% on FGVCx Fungi, where the existing MLE method would lead to a decrease accuracy.



### Classifier-agnostic saliency map extraction
- **Arxiv ID**: http://arxiv.org/abs/1805.08249v3
- **DOI**: 10.1016/j.cviu.2020.102969
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.08249v3)
- **Published**: 2018-05-21 18:36:52+00:00
- **Updated**: 2020-07-19 16:56:49+00:00
- **Authors**: Konrad Zolna, Krzysztof J. Geras, Kyunghyun Cho
- **Comment**: None
- **Journal**: Computer Vision and Image Understanding, Volume 196, 2020, 102969,
  ISSN 1077-3142
- **Summary**: Currently available methods for extracting saliency maps identify parts of the input which are the most important to a specific fixed classifier. We show that this strong dependence on a given classifier hinders their performance. To address this problem, we propose classifier-agnostic saliency map extraction, which finds all parts of the image that any classifier could use, not just one given in advance. We observe that the proposed approach extracts higher quality saliency maps than prior work while being conceptually simple and easy to implement. The method sets the new state of the art result for localization task on the ImageNet data, outperforming all existing weakly-supervised localization techniques, despite not using the ground truth labels at the inference time. The code reproducing the results is available at https://github.com/kondiz/casme .   The final version of this manuscript is published in Computer Vision and Image Understanding and is available online at https://doi.org/10.1016/j.cviu.2020.102969 .



### Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation
- **Arxiv ID**: http://arxiv.org/abs/1805.08298v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08298v2)
- **Published**: 2018-05-21 21:40:02+00:00
- **Updated**: 2018-11-24 15:11:11+00:00
- **Authors**: Christy Y. Li, Xiaodan Liang, Zhiting Hu, Eric P. Xing
- **Comment**: None
- **Journal**: None
- **Summary**: Generating long and coherent reports to describe medical images poses challenges to bridging visual patterns with informative human linguistic descriptions. We propose a novel Hybrid Retrieval-Generation Reinforced Agent (HRGR-Agent) which reconciles traditional retrieval-based approaches populated with human prior knowledge, with modern learning-based approaches to achieve structured, robust, and diverse report generation. HRGR-Agent employs a hierarchical decision-making procedure. For each sentence, a high-level retrieval policy module chooses to either retrieve a template sentence from an off-the-shelf template database, or invoke a low-level generation module to generate a new sentence. HRGR-Agent is updated via reinforcement learning, guided by sentence-level and word-level rewards. Experiments show that our approach achieves the state-of-the-art results on two medical report datasets, generating well-balanced structured sentences with robust coverage of heterogeneous medical report contents. In addition, our model achieves the highest detection accuracy of medical terminologies, and improved human evaluation performance.



### Compression of Deep Convolutional Neural Networks under Joint Sparsity Constraints
- **Arxiv ID**: http://arxiv.org/abs/1805.08303v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1805.08303v2)
- **Published**: 2018-05-21 22:00:21+00:00
- **Updated**: 2018-10-29 02:18:12+00:00
- **Authors**: Yoojin Choi, Mostafa El-Khamy, Jungwon Lee
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the optimization of deep convolutional neural networks (CNNs) such that they provide good performance while having reduced complexity if deployed on either conventional systems utilizing spatial-domain convolution or lower complexity systems designed for Winograd convolution. Furthermore, we explore the universal quantization and compression of these networks. In particular, the proposed framework produces one compressed model whose convolutional filters can be made sparse either in the spatial domain or in the Winograd domain. Hence, one compressed model can be deployed universally on any platform, without need for re-training on the deployed platform, and the sparsity of its convolutional filters can be exploited for further complexity reduction in either domain. To get a better compression ratio, the sparse model is compressed in the spatial domain which has a less number of parameters. From our experiments, we obtain $24.2\times$, $47.7\times$ and $35.4\times$ compressed models for ResNet-18, AlexNet and CT-SRCNN, while their computational cost is also reduced by $4.5\times$, $5.1\times$ and $23.5\times$, respectively.



### AgileNet: Lightweight Dictionary-based Few-shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1805.08311v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1805.08311v1)
- **Published**: 2018-05-21 22:36:11+00:00
- **Updated**: 2018-05-21 22:36:11+00:00
- **Authors**: Mohammad Ghasemzadeh, Fang Lin, Bita Darvish Rouhani, Farinaz Koushanfar, Ke Huang
- **Comment**: 10 Pages
- **Journal**: None
- **Summary**: The success of deep learning models is heavily tied to the use of massive amount of labeled data and excessively long training time. With the emergence of intelligent edge applications that use these models, the critical challenge is to obtain the same inference capability on a resource-constrained device while providing adaptability to cope with the dynamic changes in the data. We propose AgileNet, a novel lightweight dictionary-based few-shot learning methodology which provides reduced complexity deep neural network for efficient execution at the edge while enabling low-cost updates to capture the dynamics of the new data. Evaluations of state-of-the-art few-shot learning benchmarks demonstrate the superior accuracy of AgileNet compared to prior arts. Additionally, AgileNet is the first few-shot learning approach that prevents model updates by eliminating the knowledge obtained from the primary training. This property is ensured through the dictionaries learned by our novel end-to-end structured decomposition, which also reduces the memory footprint and computation complexity to match the edge device constraints.



### Learning long-range spatial dependencies with horizontal gated-recurrent units
- **Arxiv ID**: http://arxiv.org/abs/1805.08315v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1805.08315v4)
- **Published**: 2018-05-21 22:52:25+00:00
- **Updated**: 2019-06-11 13:00:56+00:00
- **Authors**: Drew Linsley, Junkyung Kim, Vijay Veerabadran, Thomas Serre
- **Comment**: Published at NeurIPS 2018
  https://papers.nips.cc/paper/7300-learning-long-range-spatial-dependencies-with-horizontal-gated-recurrent-units
- **Journal**: None
- **Summary**: Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching -- and sometimes even surpassing -- human accuracy on a variety of visual recognition tasks. Here, however, we show that these neural networks and their recent extensions struggle in recognition tasks where co-dependent visual features must be detected over long spatial ranges. We introduce the horizontal gated-recurrent unit (hGRU) to learn intrinsic horizontal connections -- both within and across feature columns. We demonstrate that a single hGRU layer matches or outperforms all tested feedforward hierarchical baselines including state-of-the-art architectures which have orders of magnitude more free parameters. We further discuss the biological plausibility of the hGRU in comparison to anatomical data from the visual cortex as well as human behavioral data on a classic contour detection task.



### Measurement-wise Occlusion in Multi-object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1805.08324v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1805.08324v1)
- **Published**: 2018-05-21 23:49:40+00:00
- **Updated**: 2018-05-21 23:49:40+00:00
- **Authors**: Michael Motro, Joydeep Ghosh
- **Comment**: presenting at 21st International Conference on Information Fusion,
  2018
- **Journal**: None
- **Summary**: Handling object interaction is a fundamental challenge in practical multi-object tracking, even for simple interactive effects such as one object temporarily occluding another. We formalize the problem of occlusion in tracking with two different abstractions. In object-wise occlusion, objects that are occluded by other objects do not generate measurements. In measurement-wise occlusion, a previously unstudied approach, all objects may generate measurements but some measurements may be occluded by others. While the relative validity of each abstraction depends on the situation and sensor, measurement-wise occlusion fits into probabilistic multi-object tracking algorithms with much looser assumptions on object interaction. Its value is demonstrated by showing that it naturally derives a popular approximation for lidar tracking, and by an example of visual tracking in image space.



