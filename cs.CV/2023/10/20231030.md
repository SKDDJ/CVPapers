# Arxiv Papers in cs.CV on 2023-10-30
### Generalized Category Discovery with Clustering Assignment Consistency
- **Arxiv ID**: http://arxiv.org/abs/2310.19210v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2310.19210v1)
- **Published**: 2023-10-30 00:32:47+00:00
- **Updated**: 2023-10-30 00:32:47+00:00
- **Authors**: Xiangli Yang, Xinglin Pan, Irwin King, Zenglin Xu
- **Comment**: ICONIP 2023,This paper has been nominated for ICONIP2023 Best Paper
  Award
- **Journal**: None
- **Summary**: Generalized category discovery (GCD) is a recently proposed open-world task. Given a set of images consisting of labeled and unlabeled instances, the goal of GCD is to automatically cluster the unlabeled samples using information transferred from the labeled dataset. The unlabeled dataset comprises both known and novel classes. The main challenge is that unlabeled novel class samples and unlabeled known class samples are mixed together in the unlabeled dataset. To address the GCD without knowing the class number of unlabeled dataset, we propose a co-training-based framework that encourages clustering consistency. Specifically, we first introduce weak and strong augmentation transformations to generate two sufficiently different views for the same sample. Then, based on the co-training assumption, we propose a consistency representation learning strategy, which encourages consistency between feature-prototype similarity and clustering assignment. Finally, we use the discriminative embeddings learned from the semi-supervised representation learning process to construct an original sparse network and use a community detection method to obtain the clustering results and the number of categories simultaneously. Extensive experiments show that our method achieves state-of-the-art performance on three generic benchmarks and three fine-grained visual recognition datasets. Especially in the ImageNet-100 data set, our method significantly exceeds the best baseline by 15.5\% and 7.0\% on the \texttt{Novel} and \texttt{All} classes, respectively.



### Modular Anti-noise Deep Learning Network for Robotic Grasp Detection Based on RGB Images
- **Arxiv ID**: http://arxiv.org/abs/2310.19223v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2310.19223v1)
- **Published**: 2023-10-30 02:01:49+00:00
- **Updated**: 2023-10-30 02:01:49+00:00
- **Authors**: Zhaocong Li
- **Comment**: None
- **Journal**: None
- **Summary**: While traditional methods relies on depth sensors, the current trend leans towards utilizing cost-effective RGB images, despite their absence of depth cues. This paper introduces an interesting approach to detect grasping pose from a single RGB image. To this end, we propose a modular learning network augmented with grasp detection and semantic segmentation, tailored for robots equipped with parallel-plate grippers. Our network not only identifies graspable objects but also fuses prior grasp analyses with semantic segmentation, thereby boosting grasp detection precision. Significantly, our design exhibits resilience, adeptly handling blurred and noisy visuals. Key contributions encompass a trainable network for grasp detection from RGB images, a modular design facilitating feasible grasp implementation, and an architecture robust against common image distortions. We demonstrate the feasibility and accuracy of our proposed approach through practical experiments and evaluations.



### CHAMMI: A benchmark for channel-adaptive models in microscopy imaging
- **Arxiv ID**: http://arxiv.org/abs/2310.19224v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2310.19224v1)
- **Published**: 2023-10-30 02:03:28+00:00
- **Updated**: 2023-10-30 02:03:28+00:00
- **Authors**: Zitong Chen, Chau Pham, Siqi Wang, Michael Doron, Nikita Moshkov, Bryan A. Plummer, Juan C. Caicedo
- **Comment**: Accepted at NeurIPS Track on Datasets and Benchmarks, 2023
- **Journal**: None
- **Summary**: Most neural networks assume that input images have a fixed number of channels (three for RGB images). However, there are many settings where the number of channels may vary, such as microscopy images where the number of channels changes depending on instruments and experimental goals. Yet, there has not been a systemic attempt to create and evaluate neural networks that are invariant to the number and type of channels. As a result, trained models remain specific to individual studies and are hardly reusable for other microscopy settings. In this paper, we present a benchmark for investigating channel-adaptive models in microscopy imaging, which consists of 1) a dataset of varied-channel single-cell images, and 2) a biologically relevant evaluation framework. In addition, we adapted several existing techniques to create channel-adaptive models and compared their performance on this benchmark to fixed-channel, baseline models. We find that channel-adaptive models can generalize better to out-of-domain tasks and can be computationally efficient. We contribute a curated dataset (https://doi.org/10.5281/zenodo.7988357) and an evaluation API (https://github.com/broadinstitute/MorphEm.git) to facilitate objective comparisons in future research and applications.



### There Are No Data Like More Data- Datasets for Deep Learning in Earth Observation
- **Arxiv ID**: http://arxiv.org/abs/2310.19231v1
- **DOI**: 10.1109/MGRS.2023.3293459
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2310.19231v1)
- **Published**: 2023-10-30 02:19:16+00:00
- **Updated**: 2023-10-30 02:19:16+00:00
- **Authors**: Michael Schmitt, Seyed Ali Ahmadi, Yonghao Xu, Gulsen Taskin, Ujjwal Verma, Francescopaolo Sica, Ronny Hansch
- **Comment**: None
- **Journal**: Published in IEEE Geoscience and Remote Sensing Magazine, vol. 11,
  no. 3, pp. 63-97, Sept. 2023
- **Summary**: Carefully curated and annotated datasets are the foundation of machine learning, with particularly data-hungry deep neural networks forming the core of what is often called Artificial Intelligence (AI). Due to the massive success of deep learning applied to Earth Observation (EO) problems, the focus of the community has been largely on the development of ever-more sophisticated deep neural network architectures and training strategies largely ignoring the overall importance of datasets. For that purpose, numerous task-specific datasets have been created that were largely ignored by previously published review articles on AI for Earth observation. With this article, we want to change the perspective and put machine learning datasets dedicated to Earth observation data and applications into the spotlight. Based on a review of the historical developments, currently available resources are described and a perspective for future developments is formed. We hope to contribute to an understanding that the nature of our data is what distinguishes the Earth observation community from many other communities that apply deep learning techniques to image data, and that a detailed understanding of EO data peculiarities is among the core competencies of our discipline.



