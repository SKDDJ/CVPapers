# Arxiv Papers in cs.CV on 2019-09-15
### Loam_livox: A fast, robust, high-precision LiDAR odometry and mapping package for LiDARs of small FoV
- **Arxiv ID**: http://arxiv.org/abs/1909.06700v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.06700v1)
- **Published**: 2019-09-15 00:36:28+00:00
- **Updated**: 2019-09-15 00:36:28+00:00
- **Authors**: Jiarong Lin, Fu Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: LiDAR odometry and mapping (LOAM) has been playing an important role in autonomous vehicles, due to its ability to simultaneously localize the robot's pose and build high-precision, high-resolution maps of the surrounding environment. This enables autonomous navigation and safe path planning of autonomous vehicles. In this paper, we present a robust, real-time LOAM algorithm for LiDARs with small FoV and irregular samplings. By taking effort on both front-end and back-end, we address several fundamental challenges arising from such LiDARs, and achieve better performance in both precision and efficiency compared to existing baselines. To share our findings and to make contributions to the community, we open source our codes on Github



### Subtractive Perceptrons for Learning Images: A Preliminary Report
- **Arxiv ID**: http://arxiv.org/abs/1909.12933v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.12933v1)
- **Published**: 2019-09-15 01:13:41+00:00
- **Updated**: 2019-09-15 01:13:41+00:00
- **Authors**: H. R. Tizhoosh, Shivam Kalra, Shalev Lifshitz, Morteza Babaie
- **Comment**: To appear in the 9th Intern. Conf. on Image Processing Theory, Tools
  and Applications (IPTA 2019), Istanbul, Turkey
- **Journal**: None
- **Summary**: In recent years, artificial neural networks have achieved tremendous success for many vision-based tasks. However, this success remains within the paradigm of \emph{weak AI} where networks, among others, are specialized for just one given task. The path toward \emph{strong AI}, or Artificial General Intelligence, remains rather obscure. One factor, however, is clear, namely that the feed-forward structure of current networks is not a realistic abstraction of the human brain. In this preliminary work, some ideas are proposed to define a \textit{subtractive Perceptron} (s-Perceptron), a graph-based neural network that delivers a more compact topology to learn one specific task. In this preliminary study, we test the s-Perceptron with the MNIST dataset, a commonly used image archive for digit recognition. The proposed network achieves excellent results compared to the benchmark networks that rely on more complex topologies.



### LRS-DAG: Low Resource Supervised Domain Adaptation with Generalization Across Domains
- **Arxiv ID**: http://arxiv.org/abs/1909.06718v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.06718v2)
- **Published**: 2019-09-15 02:38:49+00:00
- **Updated**: 2019-11-15 03:57:30+00:00
- **Authors**: Rheeya Uppaal
- **Comment**: 10 pages, 3 figures. Accepted to NewInML Workshop at NeurIPS, 2019
- **Journal**: None
- **Summary**: Current state of the art methods in Domain Adaptation follow adversarial approaches, making training a challenge. Existing non-adversarial methods learn mappings between the source and target domains, to achieve reasonable performance. However, even these methods do not focus on a key aspect: maintaining performance on the source domain, even after optimizing over the target domain. Additionally, there exist very few methods in low resource supervised domain adaptation. This work proposes a method, LRS-DAG, that aims to solve these current issues in the field. By adding a set of "encoder layers" which map the target domain to the source, and can be removed when dealing directly with the source data, the model learns to perform optimally on both domains. LRS-DAG showcases its uniqueness by being a new algorithm for low resource domain adaptation which maintains performance over the source domain, with a new metric for learning mappings between domains being introduced. We show that, in the case of FCNs, when transferring from MNIST to SVHN, LRS-DAG performs comparably to fine tuning, with the advantage of maintaining performance over the source domain. LRS-DAG outperforms fine tuning when transferring to a synthetic dataset similar to MNIST, which is a setting more representative of low resource supervised domain adaptation.



### Mining Minimal Map-Segments for Visual Place Classifiers
- **Arxiv ID**: http://arxiv.org/abs/1909.09594v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.09594v1)
- **Published**: 2019-09-15 02:49:47+00:00
- **Updated**: 2019-09-15 02:49:47+00:00
- **Authors**: Tanaka Kanji
- **Comment**: 8 pages, 4 figures, technical report
- **Journal**: None
- **Summary**: In visual place recognition (VPR), map segmentation (MS) is a preprocessing technique used to partition a given view-sequence map into place classes (i.e., map segments) so that each class has good place-specific training images for a visual place classifier (VPC). Existing approaches to MS implicitly/explicitly suppose that map segments have a certain size, or individual map segments are balanced in size. However, recent VPR systems showed that very small important map segments (minimal map segments) often suffice for VPC, and the remaining large unimportant portion of the map should be discarded to minimize map maintenance cost. Here, a new MS algorithm that can mine minimal map segments from a large view-sequence map is presented. To solve the inherently NP hard problem, MS is formulated as a video-segmentation problem and the efficient point-trajectory based paradigm of video segmentation is used. The proposed map representation was implemented with three types of VPC: deep convolutional neural network, bag-of-words, and object class detector, and each was integrated into a Monte Carlo localization algorithm (MCL) within a topometric VPR framework. Experiments using the publicly available NCLT dataset thoroughly investigate the efficacy of MS in terms of VPR performance.



### Cascade RPN: Delving into High-Quality Region Proposal Network with Adaptive Convolution
- **Arxiv ID**: http://arxiv.org/abs/1909.06720v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06720v2)
- **Published**: 2019-09-15 02:57:36+00:00
- **Updated**: 2019-12-04 08:16:10+00:00
- **Authors**: Thang Vu, Hyunjun Jang, Trung X. Pham, Chang D. Yoo
- **Comment**: To appear in NeurIPS 2019 (spotlight)
- **Journal**: None
- **Summary**: This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN) for improving the region-proposal quality and detection performance by \textit{systematically} addressing the limitation of the conventional RPN that \textit{heuristically defines} the anchors and \textit{aligns} the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a \textit{single anchor} per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, \textit{adaptive convolution} is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves AR 13.4 points higher than that of the conventional RPN, surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively. The code is made publicly available at \url{https://github.com/thangvubk/Cascade-RPN.git}.



### MSU-Net: Multiscale Statistical U-Net for Real-time 3D Cardiac MRI Video Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.06726v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.06726v1)
- **Published**: 2019-09-15 03:56:15+00:00
- **Updated**: 2019-09-15 03:56:15+00:00
- **Authors**: Tianchen Wang, Jinjun Xiong, Xiaowei Xu, Meng Jiang, Yiyu Shi, Haiyun Yuan, Meiping Huang, Jian Zhuang
- **Comment**: MICCAI19
- **Journal**: None
- **Summary**: Cardiac magnetic resonance imaging (MRI) is an essential tool for MRI-guided surgery and real-time intervention. The MRI videos are expected to be segmented on-the-fly in real practice. However, existing segmentation methods would suffer from drastic accuracy loss when modified for speedup. In this work, we propose Multiscale Statistical U-Net (MSU-Net) for real-time 3D MRI video segmentation in cardiac surgical guidance. Our idea is to model the input samples as multiscale canonical form distributions for speedup, while the spatio-temporal correlation is still fully utilized. A parallel statistical U-Net is then designed to efficiently process these distributions. The fast data sampling and efficient parallel structure of MSU-Net endorse the fast and accurate inference. Compared with vanilla U-Net and a modified state-of-the-art method GridNet, our method achieves up to 268% and 237% speedup with 1.6% and 3.6% increased Dice scores.



### Road Network Reconstruction from Satellite Images with Machine Learning Supported by Topological Methods
- **Arxiv ID**: http://arxiv.org/abs/1909.06728v1
- **DOI**: 10.1145/3347146.3359348
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06728v1)
- **Published**: 2019-09-15 04:16:05+00:00
- **Updated**: 2019-09-15 04:16:05+00:00
- **Authors**: Tamal K. Dey, Jiayuan Wang, Yusu Wang
- **Comment**: 26 pages, 13 figures, ACM SIGSPATIAL 2019
- **Journal**: None
- **Summary**: Automatic Extraction of road network from satellite images is a goal that can benefit and even enable new technologies. Methods that combine machine learning (ML) and computer vision have been proposed in recent years which make the task semi-automatic by requiring the user to provide curated training samples. The process can be fully automatized if training samples can be produced algorithmically. Of course, this requires a robust algorithm that can reconstruct the road networks from satellite images reliably so that the output can be fed as training samples. In this work, we develop such a technique by infusing a persistence-guided discrete Morse based graph reconstruction algorithm into ML framework.   We elucidate our contributions in two phases. First, in a semi-automatic framework, we combine a discrete-Morse based graph reconstruction algorithm with an existing CNN framework to segment input satellite images. We show that this leads to reconstructions with better connectivity and less noise. Next, in a fully automatic framework, we leverage the power of the discrete-Morse based graph reconstruction algorithm to train a CNN from a collection of images without labelled data and use the same algorithm to produce the final output from the segmented images created by the trained CNN. We apply the discrete-Morse based graph reconstruction algorithm iteratively to improve the accuracy of the CNN. We show promising experimental results of this new framework on datasets from SpaceNet Challenge.



### A Full-Image Full-Resolution End-to-End-Trainable CNN Framework for Image Forgery Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.06751v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06751v1)
- **Published**: 2019-09-15 07:08:37+00:00
- **Updated**: 2019-09-15 07:08:37+00:00
- **Authors**: Francesco Marra, Diego Gragnaniello, Luisa Verdoliva, Giovanni Poggi
- **Comment**: 13 pages, 12 figures, journal
- **Journal**: None
- **Summary**: Due to limited computational and memory resources, current deep learning models accept only rather small images in input, calling for preliminary image resizing. This is not a problem for high-level vision problems, where discriminative features are barely affected by resizing. On the contrary, in image forensics, resizing tends to destroy precious high-frequency details, impacting heavily on performance. One can avoid resizing by means of patch-wise processing, at the cost of renouncing whole-image analysis. In this work, we propose a CNN-based image forgery detection framework which makes decisions based on full-resolution information gathered from the whole image. Thanks to gradient checkpointing, the framework is trainable end-to-end with limited memory resources and weak (image-level) supervision, allowing for the joint optimization of all parameters. Experiments on widespread image forensics datasets prove the good performance of the proposed approach, which largely outperforms all baselines and all reference methods.



### Multitask Learning to Improve Egocentric Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1909.06761v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.06761v1)
- **Published**: 2019-09-15 08:29:46+00:00
- **Updated**: 2019-09-15 08:29:46+00:00
- **Authors**: Georgios Kapidis, Ronald Poppe, Elsbeth van Dam, Lucas Noldus, Remco Veltkamp
- **Comment**: 10 pages, 3 figures, accepted at the 5th Egocentric Perception,
  Interaction and Computing (EPIC) workshop at ICCV 2019, code repository:
  https://github.com/georkap/hand_track_classification
- **Journal**: None
- **Summary**: In this work we employ multitask learning to capitalize on the structure that exists in related supervised tasks to train complex neural networks. It allows training a network for multiple objectives in parallel, in order to improve performance on at least one of them by capitalizing on a shared representation that is developed to accommodate more information than it otherwise would for a single task. We employ this idea to tackle action recognition in egocentric videos by introducing additional supervised tasks. We consider learning the verbs and nouns from which action labels consist of and predict coordinates that capture the hand locations and the gaze-based visual saliency for all the frames of the input video segments. This forces the network to explicitly focus on cues from secondary tasks that it might otherwise have missed resulting in improved inference. Our experiments on EPIC-Kitchens and EGTEA Gaze+ show consistent improvements when training with multiple tasks over the single-task baseline. Furthermore, in EGTEA Gaze+ we outperform the state-of-the-art in action recognition by 3.84%. Apart from actions, our method produces accurate hand and gaze estimations as side tasks, without requiring any additional input at test time other than the RGB video clips.



### Deep Learning for Low-Field to High-Field MR: Image Quality Transfer with Probabilistic Decimation Simulator
- **Arxiv ID**: http://arxiv.org/abs/1909.06763v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.06763v1)
- **Published**: 2019-09-15 08:56:44+00:00
- **Updated**: 2019-09-15 08:56:44+00:00
- **Authors**: Hongxiang Lin, Matteo Figini, Ryutaro Tanno, Stefano B. Blumberg, Enrico Kaden, Godwin Ogbole, Biobele J. Brown, Felice D'Arco, David W. Carmichael, Ikeoluwa Lagunju, Helen J. Cross, Delmiro Fernandez-Reyes, Daniel C. Alexander
- **Comment**: None
- **Journal**: None
- **Summary**: MR images scanned at low magnetic field ($<1$T) have lower resolution in the slice direction and lower contrast, due to a relatively small signal-to-noise ratio (SNR) than those from high field (typically 1.5T and 3T). We adapt the recent idea of Image Quality Transfer (IQT) to enhance very low-field structural images aiming to estimate the resolution, spatial coverage, and contrast of high-field images. Analogous to many learning-based image enhancement techniques, IQT generates training data from high-field scans alone by simulating low-field images through a pre-defined decimation model. However, the ground truth decimation model is not well-known in practice, and lack of its specification can bias the trained model, aggravating performance on the real low-field scans. In this paper we propose a probabilistic decimation simulator to improve robustness of model training. It is used to generate and augment various low-field images whose parameters are random variables and sampled from an empirical distribution related to tissue-specific SNR on a 0.36T scanner. The probabilistic decimation simulator is model-agnostic, that is, it can be used with any super-resolution networks. Furthermore we propose a variant of U-Net architecture to improve its learning performance. We show promising qualitative results from clinical low-field images confirming the strong efficacy of IQT in an important new application area: epilepsy diagnosis in sub-Saharan Africa where only low-field scanners are normally available.



### Graph-guided Architecture Search for Real-time Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.06793v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06793v2)
- **Published**: 2019-09-15 12:45:55+00:00
- **Updated**: 2020-04-01 04:38:55+00:00
- **Authors**: Peiwen Lin, Peng Sun, Guangliang Cheng, Sirui Xie, Xi Li, Jianping Shi
- **Comment**: CVPR2020
- **Journal**: None
- **Summary**: Designing a lightweight semantic segmentation network often requires researchers to find a trade-off between performance and speed, which is always empirical due to the limited interpretability of neural networks. In order to release researchers from these tedious mechanical trials, we propose a Graph-guided Architecture Search (GAS) pipeline to automatically search real-time semantic segmentation networks. Unlike previous works that use a simplified search space and stack a repeatable cell to form a network, we introduce a novel search mechanism with new search space where a lightweight model can be effectively explored through the cell-level diversity and latencyoriented constraint. Specifically, to produce the cell-level diversity, the cell-sharing constraint is eliminated through the cell-independent manner. Then a graph convolution network (GCN) is seamlessly integrated as a communication mechanism between cells. Finally, a latency-oriented constraint is endowed into the search process to balance the speed and performance. Extensive experiments on Cityscapes and CamVid datasets demonstrate that GAS achieves the new state-of-the-art trade-off between accuracy and speed. In particular, on Cityscapes dataset, GAS achieves the new best performance of 73.5% mIoU with speed of 108.4 FPS on Titan Xp.



### OpenMPR: Recognize Places Using Multimodal Data for People with Visual Impairments
- **Arxiv ID**: http://arxiv.org/abs/1909.06795v1
- **DOI**: 10.1088/1361-6501/ab2106
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06795v1)
- **Published**: 2019-09-15 12:58:53+00:00
- **Updated**: 2019-09-15 12:58:53+00:00
- **Authors**: Ruiqi Cheng, Kaiwei Wang, Jian Bai, Zhijie Xu
- **Comment**: The paper is accepted by the special issue of Measurement Science and
  Engineering
- **Journal**: None
- **Summary**: Place recognition plays a crucial role in navigational assistance, and is also a challenging issue of assistive technology. The place recognition is prone to erroneous localization owing to various changes between database and query images. Aiming at the wearable assistive device for visually impaired people, we propose an open-sourced place recognition algorithm OpenMPR, which utilizes the multimodal data to address the challenging issues of place recognition. Compared with conventional place recognition, the proposed OpenMPR not only leverages multiple effective descriptors, but also assigns different weights to those descriptors in image matching. Incorporating GNSS data into the algorithm, the cone-based sequence searching is used for robust place recognition. The experiments illustrate that the proposed algorithm manages to solve the place recognition issue in the real-world scenarios and surpass the state-of-the-art algorithms in terms of assistive navigation performance. On the real-world testing dataset, the online OpenMPR achieves 88.7% precision at 100% recall without illumination changes, and achieves 57.8% precision at 99.3% recall with illumination changes. The OpenMPR is available at https://github.com/chengricky/OpenMultiPR.



### GradNet: Gradient-Guided Network for Visual Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1909.06800v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06800v1)
- **Published**: 2019-09-15 13:39:49+00:00
- **Updated**: 2019-09-15 13:39:49+00:00
- **Authors**: Peixia Li, Boyu Chen, Wanli Ouyang, Dong Wang, Xiaoyun Yang, Huchuan Lu
- **Comment**: accepted by ICCV2019 (Oral)
- **Journal**: None
- **Summary**: The fully-convolutional siamese network based on template matching has shown great potentials in visual tracking. During testing, the template is fixed with the initial target feature and the performance totally relies on the general matching ability of the siamese network. However, this manner cannot capture the temporal variations of targets or background clutter. In this work, we propose a novel gradient-guided network to exploit the discriminative information in gradients and update the template in the siamese network through feed-forward and backward operations. Our algorithm performs feed-forward and backward operations to exploit the discriminative informaiton in gradients and capture the core attention of the target. To be specific, the algorithm can utilize the information from the gradient to update the template in the current frame. In addition, a template generalization training method is proposed to better use gradient information and avoid overfitting. To our knowledge, this work is the first attempt to exploit the information in the gradient for template update in siamese-based trackers. Extensive experiments on recent benchmarks demonstrate that our method achieves better performance than other state-of-the-art trackers.



### Scaling Object Detection by Transferring Classification Weights
- **Arxiv ID**: http://arxiv.org/abs/1909.06804v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.06804v1)
- **Published**: 2019-09-15 13:59:29+00:00
- **Updated**: 2019-09-15 13:59:29+00:00
- **Authors**: Jason Kuen, Federico Perazzi, Zhe Lin, Jianming Zhang, Yap-Peng Tan
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: Large scale object detection datasets are constantly increasing their size in terms of the number of classes and annotations count. Yet, the number of object-level categories annotated in detection datasets is an order of magnitude smaller than image-level classification labels. State-of-the art object detection models are trained in a supervised fashion and this limits the number of object classes they can detect. In this paper, we propose a novel weight transfer network (WTN) to effectively and efficiently transfer knowledge from classification network's weights to detection network's weights to allow detection of novel classes without box supervision. We first introduce input and feature normalization schemes to curb the under-fitting during training of a vanilla WTN. We then propose autoencoder-WTN (AE-WTN) which uses reconstruction loss to preserve classification network's information over all classes in the target latent space to ensure generalization to novel classes. Compared to vanilla WTN, AE-WTN obtains absolute performance gains of 6% on two Open Images evaluation sets with 500 seen and 57 novel classes respectively, and 25% on a Visual Genome evaluation set with 200 novel classes. The code is available at https://github.com/xternalz/AE-WTN.



### DashNet: A Hybrid Artificial and Spiking Neural Network for High-speed Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1909.12942v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.12942v1)
- **Published**: 2019-09-15 14:59:53+00:00
- **Updated**: 2019-09-15 14:59:53+00:00
- **Authors**: Zheyu Yang, Yujie Wu, Guanrui Wang, Yukuan Yang, Guoqi Li, Lei Deng, Jun Zhu, Luping Shi
- **Comment**: None
- **Journal**: None
- **Summary**: Computer-science-oriented artificial neural networks (ANNs) have achieved tremendous success in a variety of scenarios via powerful feature extraction and high-precision data operations. It is well known, however, that ANNs usually suffer from expensive processing resources and costs. In contrast, neuroscience-oriented spiking neural networks (SNNs) are promising for energy-efficient information processing benefit from the event-driven spike activities, whereas, they are yet be evidenced to achieve impressive effectiveness on real complicated tasks. How to combine the advantage of these two model families is an open question of great interest. Two significant challenges need to be addressed: (1) lack of benchmark datasets including both ANN-oriented (frames) and SNN-oriented (spikes) signal resources; (2) the difficulty in jointly processing the synchronous activation from ANNs and event-driven spikes from SNNs. In this work, we proposed a hybrid paradigm, named as DashNet, to demonstrate the advantages of combining ANNs and SNNs in a single model. A simulator and benchmark dataset NFS-DAVIS is built, and a temporal complementary filter (TCF) and attention module are designed to address the two mentioned challenges, respectively. In this way, it is shown that DashNet achieves the record-breaking speed of 2083FPS on neuromorphic chips and the best tracking performance on NFS-DAVIS and PRED18 datasets. To the best of our knowledge, DashNet is the first framework that can integrate and process ANNs and SNNs in a hybrid paradigm, which provides a novel solution to achieve both effectiveness and efficiency for high-speed object tracking.



### Beyond Top-Grasps Through Scene Completion
- **Arxiv ID**: http://arxiv.org/abs/1909.12908v2
- **DOI**: 10.1109/ICRA40945.2020.9197320
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.12908v2)
- **Published**: 2019-09-15 15:12:14+00:00
- **Updated**: 2020-03-02 18:31:03+00:00
- **Authors**: Jens Lundell, Francesco Verdoja, Ville Kyrki
- **Comment**: Accepted to 2020 IEEE Conference on Robotics and Automation (ICRA)
- **Journal**: 2020 IEEE International Conference on Robotics and Automation
  (ICRA), Paris, France, 2020, pp. 545-551
- **Summary**: Current end-to-end grasp planning methods propose grasps in the order of seconds that attain high grasp success rates on a diverse set of objects, but often by constraining the workspace to top-grasps. In this work, we present a method that allows end-to-end top-grasp planning methods to generate full six-degree-of-freedom grasps using a single RGB-D view as input. This is achieved by estimating the complete shape of the object to be grasped, then simulating different viewpoints of the object, passing the simulated viewpoints to an end-to-end grasp generation method, and finally executing the overall best grasp. The method was experimentally validated on a Franka Emika Panda by comparing 429 grasps generated by the state-of-the-art Fully Convolutional Grasp Quality CNN, both on simulated and real camera images. The results show statistically significant improvements in terms of grasp success rate when using simulated images over real camera images, especially when the real camera viewpoint is angled. Code and video are available at https://irobotics.aalto.fi/beyond-top-grasps-through-scene-completion/.



### End-to-End Deep Residual Learning with Dilated Convolutions for Myocardial Infarction Detection and Localization
- **Arxiv ID**: http://arxiv.org/abs/1909.12923v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.12923v1)
- **Published**: 2019-09-15 15:48:29+00:00
- **Updated**: 2019-09-15 15:48:29+00:00
- **Authors**: Iván López-Espejo
- **Comment**: None
- **Journal**: None
- **Summary**: In this report, I investigate the use of end-to-end deep residual learning with dilated convolutions for myocardial infarction (MI) detection and localization from electrocardiogram (ECG) signals. Although deep residual learning has already been applied to MI detection and localization, I propose a more accurate system that distinguishes among a higher number (i.e., six) of MI locations. Inspired by speech waveform processing with neural networks, I found a more robust front-end than directly arranging the multi-lead ECG signal into an input matrix consisting of the use of a single one-dimensional convolutional layer per ECG lead to extract a pseudo-time-frequency representation and create a compact and discriminative input feature volume. As a result, I end up with a system achieving an MI detection and localization accuracy of 99.99% on the well-known Physikalisch-Technische Bundesanstalt (PTB) database.



### 3D U-Net Based Brain Tumor Segmentation and Survival Days Prediction
- **Arxiv ID**: http://arxiv.org/abs/1909.12901v2
- **DOI**: 10.1007/978-3-030-46640-4_13
- **Categories**: **eess.IV**, cs.CV, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1909.12901v2)
- **Published**: 2019-09-15 15:59:37+00:00
- **Updated**: 2020-03-31 14:16:41+00:00
- **Authors**: Feifan Wang, Runzhou Jiang, Liqin Zheng, Chun Meng, Bharat Biswal
- **Comment**: Third place award of the 2019 MICCAI BraTS challenge survival task
  [BraTS 2019](https://www.med.upenn.edu/cbica/brats2019.html)
- **Journal**: None
- **Summary**: Past few years have witnessed the prevalence of deep learning in many application scenarios, among which is medical image processing. Diagnosis and treatment of brain tumors requires an accurate and reliable segmentation of brain tumors as a prerequisite. However, such work conventionally requires brain surgeons significant amount of time. Computer vision techniques could provide surgeons a relief from the tedious marking procedure. In this paper, a 3D U-net based deep learning model has been trained with the help of brain-wise normalization and patching strategies for the brain tumor segmentation task in the BraTS 2019 competition. Dice coefficients for enhancing tumor, tumor core, and the whole tumor are 0.737, 0.807 and 0.894 respectively on the validation dataset. These three values on the test dataset are 0.778, 0.798 and 0.852. Furthermore, numerical features including ratio of tumor size to brain size and the area of tumor surface as well as age of subjects are extracted from predicted tumor labels and have been used for the overall survival days prediction task. The accuracy could be 0.448 on the validation dataset, and 0.551 on the final test dataset.



### PedHunter: Occlusion Robust Pedestrian Detector in Crowded Scenes
- **Arxiv ID**: http://arxiv.org/abs/1909.06826v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06826v1)
- **Published**: 2019-09-15 16:02:25+00:00
- **Updated**: 2019-09-15 16:02:25+00:00
- **Authors**: Cheng Chi, Shifeng Zhang, Junliang Xing, Zhen Lei, Stan Z. Li, Xudong Zou
- **Comment**: None
- **Journal**: None
- **Summary**: Pedestrian detection in crowded scenes is a challenging problem, because occlusion happens frequently among different pedestrians. In this paper, we propose an effective and efficient detection network to hunt pedestrians in crowd scenes. The proposed method, namely PedHunter, introduces strong occlusion handling ability to existing region-based detection networks without bringing extra computations in the inference stage. Specifically, we design a mask-guided module to leverage the head information to enhance the feature representation learning of the backbone network. Moreover, we develop a strict classification criterion by improving the quality of positive samples during training to eliminate common false positives of pedestrian detection in crowded scenes. Besides, we present an occlusion-simulated data augmentation to enrich the pattern and quantity of occlusion samples to improve the occlusion robustness. As a consequent, we achieve state-of-the-art results on three pedestrian detection datasets including CityPersons, Caltech-USA and CrowdHuman. To facilitate further studies on the occluded pedestrian detection in surveillance scenes, we release a new pedestrian dataset, called SUR-PED, with a total of over 162k high-quality manually labeled instances in 10k images. The proposed dataset, source codes and trained models will be released.



### Comparison of UNet, ENet, and BoxENet for Segmentation of Mast Cells in Scans of Histological Slices
- **Arxiv ID**: http://arxiv.org/abs/1909.06840v3
- **DOI**: 10.1109/SIBIRCON48586.2019.8958121
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.06840v3)
- **Published**: 2019-09-15 17:26:56+00:00
- **Updated**: 2019-11-22 16:14:21+00:00
- **Authors**: Alexander Karimov, Artem Razumov, Ruslana Manbatchurina, Ksenia Simonova, Irina Donets, Anastasia Vlasova, Yulia Khramtsova, Konstantin Ushenin
- **Comment**: 4 pages, 5 figures, 1 table
- **Journal**: None
- **Summary**: Deep neural networks show high accuracy in theproblem of semantic and instance segmentation of biomedicaldata. However, this approach is computationally expensive. Thecomputational cost may be reduced with network simplificationafter training or choosing the proper architecture, which providessegmentation with less accuracy but does it much faster. In thepresent study, we analyzed the accuracy and performance ofUNet and ENet architectures for the problem of semantic imagesegmentation. In addition, we investigated the ENet architecture by replacing of some convolution layers with box-convolutionlayers. The analysis performed on the original dataset consisted of histology slices with mast cells. These cells provide a region forsegmentation with different types of borders, which vary fromclearly visible to ragged. ENet was less accurate than UNet byonly about 1-2%, but ENet performance was 8-15 times faster than UNet one.



### Wasserstein Diffusion Tikhonov Regularization
- **Arxiv ID**: http://arxiv.org/abs/1909.06860v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.06860v1)
- **Published**: 2019-09-15 19:10:16+00:00
- **Updated**: 2019-09-15 19:10:16+00:00
- **Authors**: Alex Tong Lin, Yonatan Dukler, Wuchen Li, Guido Montufar
- **Comment**: None
- **Journal**: None
- **Summary**: We propose regularization strategies for learning discriminative models that are robust to in-class variations of the input data. We use the Wasserstein-2 geometry to capture semantically meaningful neighborhoods in the space of images, and define a corresponding input-dependent additive noise data augmentation model. Expanding and integrating the augmented loss yields an effective Tikhonov-type Wasserstein diffusion smoothness regularizer. This approach allows us to apply high levels of regularization and train functions that have low variability within classes but remain flexible across classes. We provide efficient methods for computing the regularizer at a negligible cost in comparison to training with adversarial data augmentation. Initial experiments demonstrate improvements in generalization performance under adversarial perturbations and also large in-class variations of the input data.



### A Dual-hierarchy Semantic Graph for Robust Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1909.06867v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06867v3)
- **Published**: 2019-09-15 19:49:58+00:00
- **Updated**: 2020-04-30 15:49:58+00:00
- **Authors**: Isaac Weiss
- **Comment**: None
- **Journal**: None
- **Summary**: We present a system for object recognition based on a semantic graph representation, which the system can learn from image examples. This graph is based on intrinsic properties of objects such as structure and geometry, so it is more robust than the current machine learning methods that can be fooled by changing a few pixels. Current methods have proved to be powerful but brittle because they ignore the structure and semantics of the objects. We define semantics as a form of abstraction, in terms of the intrinsic properties of the object, not in terms of human perception. Thus, it can be learned automatically. This is facilitated by the graph having two distinct hierarchies: abstraction and parts, which also makes its representation of objects more accurate and versatile. Previous semantic networks had only one amorphous hierarchy and were difficult to build and traverse. Our system performs both the learning and recognition by an algorithm that traverses both hierarchies at the same time, combining the advantages of top-down and bottom-up strategies. This reduces dimensionality and obviates the need for the brute force of big data training.



### Performance Evaluation of Learned 3D Features
- **Arxiv ID**: http://arxiv.org/abs/1909.06884v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06884v1)
- **Published**: 2019-09-15 21:05:49+00:00
- **Updated**: 2019-09-15 21:05:49+00:00
- **Authors**: Riccardo Spezialetti, Samuele Salti, Luigi Di Stefano
- **Comment**: None
- **Journal**: International Conference on Image Analysis and Processing.
  Springer, Cham, 2019
- **Summary**: Matching surfaces is a challenging 3D Computer Vision problem typically addressed by local features. Although a variety of 3D feature detectors and descriptors has been proposed in literature, they have seldom been proposed together and it is yet not clear how to identify the most effective detector-descriptor pair for a specific application. A promising solution is to leverage machine learning to learn the optimal 3D detector for any given 3D descriptor [15]. In this paper, we report a performance evaluation of the detector-descriptor pairs obtained by learning a paired 3D detector for the most popular 3D descriptors. In particular, we address experimental settings dealing with object recognition and surface registration.



### Learning an Effective Equivariant 3D Descriptor Without Supervision
- **Arxiv ID**: http://arxiv.org/abs/1909.06887v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06887v1)
- **Published**: 2019-09-15 21:27:23+00:00
- **Updated**: 2019-09-15 21:27:23+00:00
- **Authors**: Riccardo Spezialetti, Samuele Salti, Luigi Di Stefano
- **Comment**: Accepted to International Conference on Computer Vision 2019
- **Journal**: None
- **Summary**: Establishing correspondences between 3D shapes is a fundamental task in 3D Computer Vision, typically addressed by matching local descriptors. Recently, a few attempts at applying the deep learning paradigm to the task have shown promising results. Yet, the only explored way to learn rotation invariant descriptors has been to feed neural networks with highly engineered and invariant representations provided by existing hand-crafted descriptors, a path that goes in the opposite direction of end-to-end learning from raw data so successfully deployed for 2D images. In this paper, we explore the benefits of taking a step back in the direction of end-to-end learning of 3D descriptors by disentangling the creation of a robust and distinctive rotation equivariant representation, which can be learned from unoriented input data, and the definition of a good canonical orientation, required only at test time to obtain an invariant descriptor. To this end, we leverage two recent innovations: spherical convolutional neural networks to learn an equivariant descriptor and plane folding decoders to learn without supervision. The effectiveness of the proposed approach is experimentally validated by outperforming hand-crafted and learned descriptors on a standard benchmark.



### TiM-DNN: Ternary in-Memory accelerator for Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1909.06892v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.AR, cs.CV, cs.ET
- **Links**: [PDF](http://arxiv.org/pdf/1909.06892v3)
- **Published**: 2019-09-15 21:43:19+00:00
- **Updated**: 2020-05-05 02:42:18+00:00
- **Authors**: Shubham Jain, Sumeet Kumar Gupta, Anand Raghunathan
- **Comment**: 12 pages, 18 figures, Accepted in IEEE Transactions on Very Large
  Scale Integration (VLSI) Systems 2020
- **Journal**: None
- **Summary**: The use of lower precision has emerged as a popular technique to optimize the compute and storage requirements of complex Deep Neural Networks (DNNs). In the quest for lower precision, recent studies have shown that ternary DNNs (which represent weights and activations by signed ternary values) represent a promising sweet spot, achieving accuracy close to full-precision networks on complex tasks. We propose TiM-DNN, a programmable in-memory accelerator that is specifically designed to execute ternary DNNs. TiM-DNN supports various ternary representations including unweighted {-1,0,1}, symmetric weighted {-a,0,a}, and asymmetric weighted {-a,0,b} ternary systems. The building blocks of TiM-DNN are TiM tiles -- specialized memory arrays that perform massively parallel signed ternary vector-matrix multiplications with a single access. TiM tiles are in turn composed of Ternary Processing Cells (TPCs), bit-cells that function as both ternary storage units and signed ternary multiplication units. We evaluate an implementation of TiM-DNN in 32nm technology using an architectural simulator calibrated with SPICE simulations and RTL synthesis. We evaluate TiM-DNN across a suite of state-of-the-art DNN benchmarks including both deep convolutional and recurrent neural networks. A 32-tile instance of TiM-DNN achieves a peak performance of 114 TOPs/s, consumes 0.9W power, and occupies 1.96mm2 chip area, representing a 300X and 388X improvement in TOPS/W and TOPS/mm2, respectively, compared to an NVIDIA Tesla V100 GPU. In comparison to specialized DNN accelerators, TiM-DNN achieves 55X-240X and 160X-291X improvement in TOPS/W and TOPS/mm2, respectively. Finally, when compared to a well-optimized near-memory accelerator for ternary DNNs, TiM-DNN demonstrates 3.9x-4.7x improvement in system-level energy and 3.2x-4.2x speedup, underscoring the potential of in-memory computing for ternary DNNs.



### Non-Causal Tracking by Deblatting
- **Arxiv ID**: http://arxiv.org/abs/1909.06894v1
- **DOI**: 10.1007/978-3-030-33676-9_9
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.06894v1)
- **Published**: 2019-09-15 22:02:43+00:00
- **Updated**: 2019-09-15 22:02:43+00:00
- **Authors**: Denys Rozumnyi, Jan Kotera, Filip Šroubek, Jiří Matas
- **Comment**: Published at GCPR 2019, oral presentation, Best Paper Honorable
  Mention Award
- **Journal**: None
- **Summary**: Tracking by Deblatting stands for solving an inverse problem of deblurring and image matting for tracking motion-blurred objects. We propose non-causal Tracking by Deblatting which estimates continuous, complete and accurate object trajectories. Energy minimization by dynamic programming is used to detect abrupt changes of motion, called bounces. High-order polynomials are fitted to segments, which are parts of the trajectory separated by bounces. The output is a continuous trajectory function which assigns location for every real-valued time stamp from zero to the number of frames. Additionally, we show that from the trajectory function precise physical calculations are possible, such as radius, gravity or sub-frame object velocity. Velocity estimation is compared to the high-speed camera measurements and radars. Results show high performance of the proposed method in terms of Trajectory-IoU, recall and velocity estimation.



### Brno Urban Dataset -- The New Data for Self-Driving Agents and Mapping Tasks
- **Arxiv ID**: http://arxiv.org/abs/1909.06897v1
- **DOI**: 10.1109/ICRA40945.2020.9197277
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.06897v1)
- **Published**: 2019-09-15 22:06:34+00:00
- **Updated**: 2019-09-15 22:06:34+00:00
- **Authors**: Adam Ligocki, Ales Jelinek, Ludek Zalud
- **Comment**: 7 pages, ICRA 2020 submitted
- **Journal**: 2020 IEEE International Conference on Robotics and Automation
  (ICRA)
- **Summary**: Autonomous driving is a dynamically growing field of research, where quality and amount of experimental data is critical. Although several rich datasets are available these days, the demands of researchers and technical possibilities are evolving. Through this paper, we bring a new dataset recorded in Brno, Czech Republic. It offers data from four WUXGA cameras, two 3D LiDARs, inertial measurement unit, infrared camera and especially differential RTK GNSS receiver with centimetre accuracy which, to the best knowledge of the authors, is not available from any other public dataset so far. In addition, all the data are precisely timestamped with sub-millisecond precision to allow wider range of applications. At the time of publishing of this paper, recordings of more than 350 km of rides in varying environment are shared at: https: //github.com/RoboticsBUT/Brno-Urban-Dataset.



### Using an AI creativity system to explore how aesthetic experiences are processed along the brains perceptual neural pathways
- **Arxiv ID**: http://arxiv.org/abs/1909.06904v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1909.06904v1)
- **Published**: 2019-09-15 22:49:41+00:00
- **Updated**: 2019-09-15 22:49:41+00:00
- **Authors**: Vanessa Utz, Steve DiPaola
- **Comment**: None
- **Journal**: Cognitive Systems Research, 2019
- **Summary**: With the increased sophistication of AI techniques, the application of these systems has been expanding to ever newer fields. Increasingly, these systems are being used in modeling of human aesthetics and creativity, e.g. how humans create artworks and design products. Our lab has developed one such AI creativity deep learning system that can be used to create artworks in the form of images and videos. In this paper, we describe this system and its use in studying the human visual system and the formation of aesthetic experiences. Specifically, we show how time-based AI created media can be used to explore the nature of the dual-pathway neuro-architecture of the human visual system and how this relates to higher cognitive judgments such as aesthetic experiences that rely on these divergent information streams. We propose a theoretical framework for how the movement within percepts such as video clips, causes the engagement of reflexive attention and a subsequent focus on visual information that are primarily processed via the dorsal stream, thereby modulating aesthetic experiences that rely on information relayed via the ventral stream. We outline our recent study in support of our proposed framework, which serves as the first study that investigates the relationship between the two visual streams and aesthetic experiences.



### X-ToM: Explaining with Theory-of-Mind for Gaining Justified Human Trust
- **Arxiv ID**: http://arxiv.org/abs/1909.06907v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.HC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.06907v1)
- **Published**: 2019-09-15 23:24:32+00:00
- **Updated**: 2019-09-15 23:24:32+00:00
- **Authors**: Arjun R. Akula, Changsong Liu, Sari Saba-Sadiya, Hongjing Lu, Sinisa Todorovic, Joyce Y. Chai, Song-Chun Zhu
- **Comment**: A short version of this was presented at CVPR 2019 Workshop on
  Explainable AI
- **Journal**: None
- **Summary**: We present a new explainable AI (XAI) framework aimed at increasing justified human trust and reliance in the AI machine through explanations. We pose explanation as an iterative communication process, i.e. dialog, between the machine and human user. More concretely, the machine generates sequence of explanations in a dialog which takes into account three important aspects at each dialog turn: (a) human's intention (or curiosity); (b) human's understanding of the machine; and (c) machine's understanding of the human user. To do this, we use Theory of Mind (ToM) which helps us in explicitly modeling human's intention, machine's mind as inferred by the human as well as human's mind as inferred by the machine. In other words, these explicit mental representations in ToM are incorporated to learn an optimal explanation policy that takes into account human's perception and beliefs. Furthermore, we also show that ToM facilitates in quantitatively measuring justified human trust in the machine by comparing all the three mental representations.   We applied our framework to three visual recognition tasks, namely, image classification, action recognition, and human body pose estimation. We argue that our ToM based explanations are practical and more natural for both expert and non-expert users to understand the internal workings of complex machine learning models. To the best of our knowledge, this is the first work to derive explanations using ToM. Extensive human study experiments verify our hypotheses, showing that the proposed explanations significantly outperform the state-of-the-art XAI methods in terms of all the standard quantitative and qualitative XAI evaluation metrics including human trust, reliance, and explanation satisfaction.



