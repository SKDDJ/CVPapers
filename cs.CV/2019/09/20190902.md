# Arxiv Papers in cs.CV on 2019-09-02
### Reusing Convolutional Activations from Frame to Frame to Speed up Training and Inference
- **Arxiv ID**: http://arxiv.org/abs/1909.05632v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.05632v2)
- **Published**: 2019-09-02 00:21:03+00:00
- **Updated**: 2019-09-15 05:59:09+00:00
- **Authors**: Arno Khachatourian
- **Comment**: None
- **Journal**: None
- **Summary**: When processing similar frames in succession, we can take advantage of the locality of the convolution operation to reevaluate only portions of the image that changed from the previous frame. By saving the output of a layer of convolutions and calculating the change from frame to frame, we can reuse previous activations and save computational resources that would otherwise be wasted recalculating convolutions whose outputs we have already observed. This technique can be applied to many domains, such as processing videos from stationary video cameras, studying the effects of occluding or distorting sections of images, applying convolution to multiple frames of audio or time series data, or playing Atari games. Furthermore, this technique can be applied to speed up both training and inference.



### Dynamic Spatial-Temporal Representation Learning for Traffic Flow Prediction
- **Arxiv ID**: http://arxiv.org/abs/1909.02902v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.02902v4)
- **Published**: 2019-09-02 01:41:38+00:00
- **Updated**: 2020-06-13 01:21:01+00:00
- **Authors**: Lingbo Liu, Jiajie Zhen, Guanbin Li, Geng Zhan, Zhaocheng He, Bowen Du, Liang Lin
- **Comment**: Accepted by IEEE Transactions on Intelligent Transportation Systems.
  arXiv admin note: text overlap with arXiv:1809.00101
- **Journal**: None
- **Summary**: As a crucial component in intelligent transportation systems, traffic flow prediction has recently attracted widespread research interest in the field of artificial intelligence (AI) with the increasing availability of massive traffic mobility data. Its key challenge lies in how to integrate diverse factors (such as temporal rules and spatial dependencies) to infer the evolution trend of traffic flow. To address this problem, we propose a unified neural network called Attentive Traffic Flow Machine (ATFM), which can effectively learn the spatial-temporal feature representations of traffic flow with an attention mechanism. In particular, our ATFM is composed of two progressive Convolutional Long Short-Term Memory (ConvLSTM \cite{xingjian2015convolutional}) units connected with a convolutional layer. Specifically, the first ConvLSTM unit takes normal traffic flow features as input and generates a hidden state at each time-step, which is further fed into the connected convolutional layer for spatial attention map inference. The second ConvLSTM unit aims at learning the dynamic spatial-temporal representations from the attentionally weighted traffic flow features. Further, we develop two deep learning frameworks based on ATFM to predict citywide short-term/long-term traffic flow by adaptively incorporating the sequential and periodic data as well as other external influences. Extensive experiments on two standard benchmarks well demonstrate the superiority of the proposed method for traffic flow prediction. Moreover, to verify the generalization of our method, we also apply the customized framework to forecast the passenger pickup/dropoff demands in traffic prediction and show its superior performance. Our code and data are available at {\color{blue}\url{https://github.com/liulingbo918/ATFM}}.



### Sparse Deep Neural Network Graph Challenge
- **Arxiv ID**: http://arxiv.org/abs/1909.05631v1
- **DOI**: 10.1109/HPEC.2019.8916336
- **Categories**: **cs.CV**, cs.LG, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05631v1)
- **Published**: 2019-09-02 02:29:52+00:00
- **Updated**: 2019-09-02 02:29:52+00:00
- **Authors**: Jeremy Kepner, Simon Alford, Vijay Gadepally, Michael Jones, Lauren Milechin, Ryan Robinett, Sid Samsi
- **Comment**: 7 pages, 5 figures, 3 tables, 60 references, accepted to IEEE HPEC
  2019. arXiv admin note: substantial text overlap with arXiv:1807.03165,
  arXiv:1708.02937, arXiv:1708.06866
- **Journal**: None
- **Summary**: The MIT/IEEE/Amazon GraphChallenge.org encourages community approaches to developing new solutions for analyzing graphs and sparse data. Sparse AI analytics present unique scalability difficulties. The proposed Sparse Deep Neural Network (DNN) Challenge draws upon prior challenges from machine learning, high performance computing, and visual analytics to create a challenge that is reflective of emerging sparse AI systems. The Sparse DNN Challenge is based on a mathematically well-defined DNN inference computation and can be implemented in any programming environment. Sparse DNN inference is amenable to both vertex-centric implementations and array-based implementations (e.g., using the GraphBLAS.org standard). The computations are simple enough that performance predictions can be made based on simple computing hardware models. The input data sets are derived from the MNIST handwritten letters. The surrounding I/O and verification provide the context for each sparse DNN inference that allows rigorous definition of both the input and the output. Furthermore, since the proposed sparse DNN challenge is scalable in both problem size and hardware, it can be used to measure and quantitatively compare a wide range of present day and future systems. Reference implementations have been implemented and their serial and parallel performance have been measured. Specifications, data, and software are publicly available at GraphChallenge.org



### Flexible Auto-weighted Local-coordinate Concept Factorization: A Robust Framework for Unsupervised Clustering
- **Arxiv ID**: http://arxiv.org/abs/1909.00523v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.00523v1)
- **Published**: 2019-09-02 03:16:01+00:00
- **Updated**: 2019-09-02 03:16:01+00:00
- **Authors**: Zhao Zhang, Yan Zhang, Sheng Li, Guangcan Liu, Dan Zeng, Shuicheng Yan, Meng Wang
- **Comment**: Accepted by IEEE Transactions on Knowledge and Data Engineering (IEEE
  TKDE)
- **Journal**: None
- **Summary**: Concept Factorization (CF) and its variants may produce inaccurate representation and clustering results due to the sensitivity to noise, hard constraint on the reconstruction error and pre-obtained approximate similarities. To improve the representation ability, a novel unsupervised Robust Flexible Auto-weighted Local-coordinate Concept Factorization (RFA-LCF) framework is proposed for clustering high-dimensional data. Specifically, RFA-LCF integrates the robust flexible CF by clean data space recovery, robust sparse local-coordinate coding and adaptive weighting into a unified model. RFA-LCF improves the representations by enhancing the robustness of CF to noise and errors, providing a flexible constraint on the reconstruction error and optimizing the locality jointly. For robust learning, RFA-LCF clearly learns a sparse projection to recover the underlying clean data space, and then the flexible CF is performed in the projected feature space. RFA-LCF also uses a L2,1-norm based flexible residue to encode the mismatch between the recovered data and its reconstruction, and uses the robust sparse local-coordinate coding to represent data using a few nearby basis concepts. For auto-weighting, RFA-LCF jointly preserves the manifold structures in the basis concept space and new coordinate space in an adaptive manner by minimizing the reconstruction errors on clean data, anchor points and coordinates. By updating the local-coordinate preserving data, basis concepts and new coordinates alternately, the representation abilities can be potentially improved. Extensive results on public databases show that RFA-LCF delivers the state-of-the-art clustering results compared with other related methods.



### Semantic Segmentation of Panoramic Images Using a Synthetic Dataset
- **Arxiv ID**: http://arxiv.org/abs/1909.00532v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00532v1)
- **Published**: 2019-09-02 04:10:34+00:00
- **Updated**: 2019-09-02 04:10:34+00:00
- **Authors**: Yuanyou Xu, Kaiwei Wang, Kailun Yang, Dongming Sun, Jia Fu
- **Comment**: 15 pages, 12 figures, SPIE Security + Defence International Symposium
- **Journal**: None
- **Summary**: Panoramic images have advantages in information capacity and scene stability due to their large field of view (FoV). In this paper, we propose a method to synthesize a new dataset of panoramic image. We managed to stitch the images taken from different directions into panoramic images, together with their labeled images, to yield the panoramic semantic segmentation dataset denominated as SYNTHIA-PANO. For the purpose of finding out the effect of using panoramic images as training dataset, we designed and performed a comprehensive set of experiments. Experimental results show that using panoramic images as training data is beneficial to the segmentation result. In addition, it has been shown that by using panoramic images with a 180 degree FoV as training data the model has better performance. Furthermore, the model trained with panoramic images also has a better capacity to resist the image distortion.



### Resource Optimized Neural Architecture Search for 3D Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.00548v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.00548v1)
- **Published**: 2019-09-02 05:08:25+00:00
- **Updated**: 2019-09-02 05:08:25+00:00
- **Authors**: Woong Bae, Seungho Lee, Yeha Lee, Beomhee Park, Minki Chung, Kyu-Hwan Jung
- **Comment**: MICCAI(International Conference on Medical Image Computing and
  Computer Assisted Intervention) 2019 accepted
- **Journal**: None
- **Summary**: Neural Architecture Search (NAS), a framework which automates the task of designing neural networks, has recently been actively studied in the field of deep learning. However, there are only a few NAS methods suitable for 3D medical image segmentation. Medical 3D images are generally very large; thus it is difficult to apply previous NAS methods due to their GPU computational burden and long training time. We propose the resource-optimized neural architecture search method which can be applied to 3D medical segmentation tasks in a short training time (1.39 days for 1GB dataset) using a small amount of computation power (one RTX 2080Ti, 10.8GB GPU memory). Excellent performance can also be achieved without retraining(fine-tuning) which is essential in most NAS methods. These advantages can be achieved by using a reinforcement learning-based controller with parameter sharing and focusing on the optimal search space configuration of macro search rather than micro search. Our experiments demonstrate that the proposed NAS method outperforms manually designed networks with state-of-the-art performance in 3D medical image segmentation.



### Self-Ensembling with GAN-based Data Augmentation for Domain Adaptation in Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.00589v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00589v1)
- **Published**: 2019-09-02 08:15:16+00:00
- **Updated**: 2019-09-02 08:15:16+00:00
- **Authors**: Jaehoon Choi, Taekyung Kim, Changick Kim
- **Comment**: Accepted to International Conference on Computer Vision (ICCV) 2019
- **Journal**: None
- **Summary**: Deep learning-based semantic segmentation methods have an intrinsic limitation that training a model requires a large amount of data with pixel-level annotations. To address this challenging issue, many researchers give attention to unsupervised domain adaptation for semantic segmentation. Unsupervised domain adaptation seeks to adapt the model trained on the source domain to the target domain. In this paper, we introduce a self-ensembling technique, one of the successful methods for domain adaptation in classification. However, applying self-ensembling to semantic segmentation is very difficult because heavily-tuned manual data augmentation used in self-ensembling is not useful to reduce the large domain gap in the semantic segmentation. To overcome this limitation, we propose a novel framework consisting of two components, which are complementary to each other. First, we present a data augmentation method based on Generative Adversarial Networks (GANs), which is computationally efficient and effective to facilitate domain alignment. Given those augmented images, we apply self-ensembling to enhance the performance of the segmentation network on the target domain. The proposed method outperforms state-of-the-art semantic segmentation methods on unsupervised domain adaptation benchmarks.



### Self-Training and Adversarial Background Regularization for Unsupervised Domain Adaptive One-Stage Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.00597v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00597v1)
- **Published**: 2019-09-02 08:37:27+00:00
- **Updated**: 2019-09-02 08:37:27+00:00
- **Authors**: Seunghyeon Kim, Jaehoon Choi, Taekyung Kim, Changick Kim
- **Comment**: ICCV 2019 (oral)
- **Journal**: None
- **Summary**: Deep learning-based object detectors have shown remarkable improvements. However, supervised learning-based methods perform poorly when the train data and the test data have different distributions. To address the issue, domain adaptation transfers knowledge from the label-sufficient domain (source domain) to the label-scarce domain (target domain). Self-training is one of the powerful ways to achieve domain adaptation since it helps class-wise domain adaptation. Unfortunately, a naive approach that utilizes pseudo-labels as ground-truth degenerates the performance due to incorrect pseudo-labels. In this paper, we introduce a weak self-training (WST) method and adversarial background score regularization (BSR) for domain adaptive one-stage object detection. WST diminishes the adverse effects of inaccurate pseudo-labels to stabilize the learning procedure. BSR helps the network extract discriminative features for target backgrounds to reduce the domain shift. Two components are complementary to each other as BSR enhances discrimination between foregrounds and backgrounds, whereas WST strengthen class-wise discrimination. Experimental results show that our approach effectively improves the performance of the one-stage object detection in unsupervised domain adaptation setting.



### Reinforcing Medical Image Classifier to Improve Generalization on Small Datasets
- **Arxiv ID**: http://arxiv.org/abs/1909.05630v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05630v2)
- **Published**: 2019-09-02 09:12:36+00:00
- **Updated**: 2019-10-07 04:28:33+00:00
- **Authors**: Walid Abdullah Al, Il Dong Yun
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: With the advents of deep learning, improved image classification with complex discriminative models has been made possible. However, such deep models with increased complexity require a huge set of labeled samples to generalize the training. Such classification models can easily overfit when applied for medical images because of limited training data, which is a common problem in the field of medical image analysis. This paper proposes and investigates a reinforced classifier for improving the generalization under a few available training data. Partially following the idea of reinforcement learning, the proposed classifier uses a generalization-feedback from a subset of the training data to update its parameter instead of only using the conventional cross-entropy loss about the training data. We evaluate the improvement of the proposed classifier by applying it on three different classification problems against the standard deep classifiers equipped with existing overfitting-prevention techniques. Besides an overall improvement in classification performance, the proposed classifier showed remarkable characteristics of generalized learning, which can have great potential in medical classification tasks.



### Reinforcement Learning-based Automatic Diagnosis of Acute Appendicitis in Abdominal CT
- **Arxiv ID**: http://arxiv.org/abs/1909.00617v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.00617v1)
- **Published**: 2019-09-02 09:19:33+00:00
- **Updated**: 2019-09-02 09:19:33+00:00
- **Authors**: Walid Abdullah Al, Il Dong Yun, Kyong Joon Lee
- **Comment**: 9 pages, 6 figures
- **Journal**: None
- **Summary**: Acute appendicitis characterized by a painful inflammation of the vermiform appendix is one of the most common surgical emergencies. Localizing the appendix is challenging due to its unclear anatomy amidst the complex colon-structure as observed in the conventional CT views, resulting in a time-consuming diagnosis. End-to-end learning of a convolutional neural network (CNN) is also not likely to be useful because of the negligible size of the appendix compared with the abdominal CT volume. With no prior computational approaches to the best of our knowledge, we propose the first computerized automation for acute appendicitis diagnosis. In our approach, we utilize a reinforcement learning agent deployed in the lower abdominal region to obtain the appendix location first to reduce the search space for diagnosis. Then, we obtain the classification scores (i.e., the likelihood of acute appendicitis) for the local neighborhood around the localized position, using a CNN trained only on a small appendix patch per volume. From the spatial representation of the resultant scores, we finally define a region of low-entropy (RLE) to choose the optimal diagnosis score, which helps improve the classification accuracy showing robustness even under high appendix localization error cases. In our experiment with 319 abdominal CT volumes, the proposed RLE-based decision with prior localization showed significant improvement over the standard CNN-based diagnosis approaches.



### Towards Flops-constrained Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1909.00632v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00632v1)
- **Published**: 2019-09-02 09:42:52+00:00
- **Updated**: 2019-09-02 09:42:52+00:00
- **Authors**: Yu Liu, Guanglu Song, Manyuan Zhang, Jihao Liu, Yucong Zhou, Junjie Yan
- **Comment**: ICCV2019 LFR workshop
- **Journal**: None
- **Summary**: Large scale face recognition is challenging especially when the computational budget is limited. Given a \textit{flops} upper bound, the key is to find the optimal neural network architecture and optimization method. In this article, we briefly introduce the solutions of team 'trojans' for the ICCV19 - Lightweight Face Recognition Challenge~\cite{lfr}. The challenge requires each submission to be one single model with the computational budget no higher than 30 GFlops. We introduce a searched network architecture `Efficient PolyFace' based on the Flops constraint, a novel loss function `ArcNegFace', a novel frame aggregation method `QAN++', together with a bag of useful tricks in our implementation (augmentations, regular face, label smoothing, anchor finetuning, etc.). Our basic model, `Efficient PolyFace', takes 28.25 Gflops for the `deepglint-large' image-based track, and the `PolyFace+QAN++' solution takes 24.12 Gflops for the `iQiyi-large' video-based track. These two solutions achieve 94.198\% @ 1e-8 and 72.981\% @ 1e-4 in the two tracks respectively, which are the state-of-the-art results.



### Relationship-Aware Spatial Perception Fusion for Realistic Scene Layout Generation
- **Arxiv ID**: http://arxiv.org/abs/1909.00640v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00640v2)
- **Published**: 2019-09-02 09:55:29+00:00
- **Updated**: 2019-11-13 16:59:08+00:00
- **Authors**: Hongdong Zheng, Yalong Bai, Wei Zhang, Tao Mei
- **Comment**: There is a serious mistake
- **Journal**: None
- **Summary**: The significant progress on Generative Adversarial Networks (GANs) have made it possible to generate surprisingly realistic images for single object based on natural language descriptions. However, controlled generation of images for multiple entities with explicit interactions is still difficult to achieve due to the scene layout generation heavily suffer from the diversity object scaling and spatial locations. In this paper, we proposed a novel framework for generating realistic image layout from textual scene graphs. In our framework, a spatial constraint module is designed to fit reasonable scaling and spatial layout of object pairs with considering relationship between them. Moreover, a contextual fusion module is introduced for fusing pair-wise spatial information in terms of object dependency in scene graph. By using these two modules, our proposed framework tends to generate more commonsense layout which is helpful for realistic image generation. Experimental results including quantitative results, qualitative results and user studies on two different scene graph datasets demonstrate our proposed framework's ability to generate complex and logical layout with multiple objects from scene graph.



### This is not what I imagined: Error Detection for Semantic Segmentation through Visual Dissimilarity
- **Arxiv ID**: http://arxiv.org/abs/1909.00676v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00676v1)
- **Published**: 2019-09-02 11:38:43+00:00
- **Updated**: 2019-09-02 11:38:43+00:00
- **Authors**: David Haldimann, Hermann Blum, Roland Siegwart, Cesar Cadena
- **Comment**: None
- **Journal**: None
- **Summary**: There has been a remarkable progress in the accuracy of semantic segmentation due to the capabilities of deep learning. Unfortunately, these methods are not able to generalize much further than the distribution of their training data and fail to handle out-of-distribution classes appropriately. This limits the applicability to autonomous or safety critical systems. We propose a novel method leveraging generative models to detect wrongly segmented or out-of-distribution instances. Conditioned on the predicted semantic segmentation, an RGB image is generated. We then learn a dissimilarity metric that compares the generated image with the original input and detects inconsistencies introduced by the semantic segmentation. We present test cases for outlier and misclassification detection and evaluate our method qualitatively and quantitatively on multiple datasets.



### Semantic filtering through deep source separation on microscopy images
- **Arxiv ID**: http://arxiv.org/abs/1909.00691v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00691v1)
- **Published**: 2019-09-02 12:39:34+00:00
- **Updated**: 2019-09-02 12:39:34+00:00
- **Authors**: Avelino Javer, Jens Rittscher
- **Comment**: None
- **Journal**: None
- **Summary**: By their very nature microscopy images of cells and tissues consist of a limited number of object types or components. In contrast to most natural scenes, the composition is known a priori. Decomposing biological images into semantically meaningful objects and layers is the aim of this paper. Building on recent approaches to image de-noising we present a framework that achieves state-of-the-art segmentation results requiring little or no manual annotations. Here, synthetic images generated by adding cell crops are sufficient to train the model. Extensive experiments on cellular images, a histology data set, and small animal videos demonstrate that our approach generalizes to a broad range of experimental settings. As the proposed methodology does not require densely labelled training images and is capable of resolving the partially overlapping objects it holds the promise of being of use in a number of different applications.



### Training-Time-Friendly Network for Real-Time Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.00700v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00700v3)
- **Published**: 2019-09-02 12:59:18+00:00
- **Updated**: 2019-11-24 08:08:22+00:00
- **Authors**: Zili Liu, Tu Zheng, Guodong Xu, Zheng Yang, Haifeng Liu, Deng Cai
- **Comment**: Accepted to AAAI2020 (8 pages, 3 figures)
- **Journal**: None
- **Summary**: Modern object detectors can rarely achieve short training time, fast inference speed, and high accuracy at the same time. To strike a balance among them, we propose the Training-Time-Friendly Network (TTFNet). In this work, we start with light-head, single-stage, and anchor-free designs, which enable fast inference speed. Then, we focus on shortening training time. We notice that encoding more training samples from annotated boxes plays a similar role as increasing batch size, which helps enlarge the learning rate and accelerate the training process. To this end, we introduce a novel approach using Gaussian kernels to encode training samples. Besides, we design the initiative sample weights for better information utilization. Experiments on MS COCO show that our TTFNet has great advantages in balancing training time, inference speed, and accuracy. It has reduced training time by more than seven times compared to previous real-time detectors while maintaining state-of-the-art performances. In addition, our super-fast version of TTFNet-18 and TTFNet-53 can outperform SSD300 and YOLOv3 by less than one-tenth of their training time, respectively. The code has been made available at \url{https://github.com/ZJULearning/ttfnet}.



### Learned Semantic Multi-Sensor Depth Map Fusion
- **Arxiv ID**: http://arxiv.org/abs/1909.00703v1
- **DOI**: 10.1109/ICCVW.2019.00264
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00703v1)
- **Published**: 2019-09-02 13:15:24+00:00
- **Updated**: 2019-09-02 13:15:24+00:00
- **Authors**: Denys Rozumnyi, Ian Cherabier, Marc Pollefeys, Martin R. Oswald
- **Comment**: 11 pages, 7 figures, 2 tables, accepted for the 2nd Workshop on 3D
  Reconstruction in the Wild (3DRW2019) in conjunction with ICCV2019
- **Journal**: 2019 IEEE/CVF International Conference on Computer Vision Workshop
  (ICCVW)
- **Summary**: Volumetric depth map fusion based on truncated signed distance functions has become a standard method and is used in many 3D reconstruction pipelines. In this paper, we are generalizing this classic method in multiple ways: 1) Semantics: Semantic information enriches the scene representation and is incorporated into the fusion process. 2) Multi-Sensor: Depth information can originate from different sensors or algorithms with very different noise and outlier statistics which are considered during data fusion. 3) Scene denoising and completion: Sensors can fail to recover depth for certain materials and light conditions, or data is missing due to occlusions. Our method denoises the geometry, closes holes and computes a watertight surface for every semantic class. 4) Learning: We propose a neural network reconstruction method that unifies all these properties within a single powerful framework. Our method learns sensor or algorithm properties jointly with semantic depth fusion and scene completion and can also be used as an expert system, e.g. to unify the strengths of various photometric stereo algorithms. Our approach is the first to unify all these properties. Experimental evaluations on both synthetic and real data sets demonstrate clear improvements.



### Estimation of Absolute Scale in Monocular SLAM Using Synthetic Data
- **Arxiv ID**: http://arxiv.org/abs/1909.00713v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.00713v1)
- **Published**: 2019-09-02 13:35:01+00:00
- **Updated**: 2019-09-02 13:35:01+00:00
- **Authors**: Danila Rukhovich, Daniel Mouritzen, Ralf Kaestner, Martin Rufli, Alexander Velizhev
- **Comment**: None
- **Journal**: None
- **Summary**: This paper addresses the problem of scale estimation in monocular SLAM by estimating absolute distances between camera centers of consecutive image frames. These estimates would improve the overall performance of classical (not deep) SLAM systems and allow metric feature locations to be recovered from a single monocular camera. We propose several network architectures that lead to an improvement of scale estimation accuracy over the state of the art. In addition, we exploit a possibility to train the neural network only with synthetic data derived from a computer graphics simulator. Our key insight is that, using only synthetic training inputs, we can achieve similar scale estimation accuracy as that obtained from real data. This fact indicates that fully annotated simulated data is a viable alternative to existing deep-learning-based SLAM systems trained on real (unlabeled) data. Our experiments with unsupervised domain adaptation also show that the difference in visual appearance between simulated and real data does not affect scale estimation results. Our method operates with low-resolution images (0.03MP), which makes it practical for real-time SLAM applications with a monocular camera.



### Combining Deep Learning and Model-Based Methods for Robust Real-Time Semantic Landmark Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.00733v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00733v1)
- **Published**: 2019-09-02 14:28:45+00:00
- **Updated**: 2019-09-02 14:28:45+00:00
- **Authors**: Benjamin Naujoks, Patrick Burger, Hans-Joachim Wuensche
- **Comment**: In 22nd International Conference on Information Fusion (FUSION), 2019
- **Journal**: None
- **Summary**: Compared to abstract features, significant objects, so-called landmarks, are a more natural means for vehicle localization and navigation, especially in challenging unstructured environments. The major challenge is to recognize landmarks in various lighting conditions and changing environment (growing vegetation) while only having few training samples available. We propose a new method which leverages Deep Learning as well as model-based methods to overcome the need of a large data set. Using RGB images and light detection and ranging (LiDAR) point clouds, our approach combines state-of-the-art classification results of Convolutional Neural Networks (CNN), with robust model-based methods by taking prior knowledge of previous time steps into account. Evaluations on a challenging real-wold scenario, with trees and bushes as landmarks, show promising results over pure learning-based state-of-the-art 3D detectors, while being significant faster.



### Kidney tumor segmentation using an ensembling multi-stage deep learning approach. A contribution to the KiTS19 challenge
- **Arxiv ID**: http://arxiv.org/abs/1909.00735v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00735v1)
- **Published**: 2019-09-02 14:35:32+00:00
- **Updated**: 2019-09-02 14:35:32+00:00
- **Authors**: Gianmarco Santini, Noémie Moreau, Mathieu Rubeaux
- **Comment**: 11 pages, 4 figures, submitted to MICCAI 2019 - KiTS Challenge
- **Journal**: None
- **Summary**: Precise characterization of the kidney and kidney tumor characteristics is of outmost importance in the context of kidney cancer treatment, especially for nephron sparing surgery which requires a precise localization of the tissues to be removed. The need for accurate and automatic delineation tools is at the origin of the KiTS19 challenge. It aims at accelerating the research and development in this field to aid prognosis and treatment planning by providing a characterized dataset of 300 CT scans to be segmented. To address the challenge, we proposed an automatic, multi-stage, 2.5D deep learning-based segmentation approach based on Residual UNet framework. An ensembling operation is added at the end to combine prediction results from previous stages reducing the variance between single models. Our neural network segmentation algorithm reaches a mean Dice score of 0.96 and 0.74 for kidney and kidney tumors, respectively on 90 unseen test cases. The results obtained are promising and could be improved by incorporating prior knowledge about the benign cysts that regularly lower the tumor segmentation results.



### VISIR: Visual and Semantic Image Label Refinement
- **Arxiv ID**: http://arxiv.org/abs/1909.00741v1
- **DOI**: 10.1145/3159652.3159693
- **Categories**: **cs.MM**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1909.00741v1)
- **Published**: 2019-09-02 14:41:44+00:00
- **Updated**: 2019-09-02 14:41:44+00:00
- **Authors**: Sreyasi Nag Chowdhury, Niket Tandon, Hakan Ferhatosmanoglu, Gerhard Weikum
- **Comment**: Published in WSDM 2018
- **Journal**: ACM ISBN 978-1-4503-5581-0/18/02 2018
- **Summary**: The social media explosion has populated the Internet with a wealth of images. There are two existing paradigms for image retrieval: 1) content-based image retrieval (CBIR), which has traditionally used visual features for similarity search (e.g., SIFT features), and 2) tag-based image retrieval (TBIR), which has relied on user tagging (e.g., Flickr tags). CBIR now gains semantic expressiveness by advances in deep-learning-based detection of visual labels. TBIR benefits from query-and-click logs to automatically infer more informative labels. However, learning-based tagging still yields noisy labels and is restricted to concrete objects, missing out on generalizations and abstractions. Click-based tagging is limited to terms that appear in the textual context of an image or in queries that lead to a click. This paper addresses the above limitations by semantically refining and expanding the labels suggested by learning-based object detection. We consider the semantic coherence between the labels for different objects, leverage lexical and commonsense knowledge, and cast the label assignment into a constrained optimization problem solved by an integer linear program. Experiments show that our method, called VISIR, improves the quality of the state-of-the-art visual labeling tools like LSDA and YOLO.



### Analysis of SparseHash: an efficient embedding of set-similarity via sparse projections
- **Arxiv ID**: http://arxiv.org/abs/1909.01802v1
- **DOI**: None
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.01802v1)
- **Published**: 2019-09-02 15:41:54+00:00
- **Updated**: 2019-09-02 15:41:54+00:00
- **Authors**: Diego Valsesia, Sophie Marie Fosson, Chiara Ravazzi, Tiziano Bianchi, Enrico Magli
- **Comment**: 25 pages, 6 figures
- **Journal**: None
- **Summary**: Embeddings provide compact representations of signals in order to perform efficient inference in a wide variety of tasks. In particular, random projections are common tools to construct Euclidean distance-preserving embeddings, while hashing techniques are extensively used to embed set-similarity metrics, such as the Jaccard coefficient. In this letter, we theoretically prove that a class of random projections based on sparse matrices, called SparseHash, can preserve the Jaccard coefficient between the supports of sparse signals, which can be used to estimate set similarities. Moreover, besides the analysis, we provide an efficient implementation and we test the performance in several numerical experiments, both on synthetic and real datasets.



### Adversarial Learning and Self-Teaching Techniques for Domain Adaptation in Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.00781v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.00781v2)
- **Published**: 2019-09-02 16:05:05+00:00
- **Updated**: 2020-03-02 15:46:24+00:00
- **Authors**: Umberto Michieli, Matteo Biasetton, Gianluca Agresti, Pietro Zanuttigh
- **Comment**: Accepted at IEEE Transactions on Intelligent Vehicles (T-IV) 10
  pages, 2 figures, 7 tables
- **Journal**: None
- **Summary**: Deep learning techniques have been widely used in autonomous driving systems for the semantic understanding of urban scenes. However, they need a huge amount of labeled data for training, which is difficult and expensive to acquire. A recently proposed workaround is to train deep networks using synthetic data, but the domain shift between real world and synthetic representations limits the performance. In this work, a novel Unsupervised Domain Adaptation (UDA) strategy is introduced to solve this issue. The proposed learning strategy is driven by three components: a standard supervised learning loss on labeled synthetic data; an adversarial learning module that exploits both labeled synthetic data and unlabeled real data; finally, a self-teaching strategy applied to unlabeled data. The last component exploits a region growing framework guided by the segmentation confidence. Furthermore, we weighted this component on the basis of the class frequencies to enhance the performance on less common classes. Experimental results prove the effectiveness of the proposed strategy in adapting a segmentation network trained on synthetic datasets, like GTA5 and SYNTHIA, to real world datasets like Cityscapes and Mapillary.



### Geometry Normalization Networks for Accurate Scene Text Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.00794v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00794v1)
- **Published**: 2019-09-02 16:47:05+00:00
- **Updated**: 2019-09-02 16:47:05+00:00
- **Authors**: Youjiang Xu, Jiaqi Duan, Zhanghui Kuang, Xiaoyu Yue, Hongbin Sun, Yue Guan, Wayne Zhang
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: Large geometry (e.g., orientation) variances are the key challenges in the scene text detection. In this work, we first conduct experiments to investigate the capacity of networks for learning geometry variances on detecting scene texts, and find that networks can handle only limited text geometry variances. Then, we put forward a novel Geometry Normalization Module (GNM) with multiple branches, each of which is composed of one Scale Normalization Unit and one Orientation Normalization Unit, to normalize each text instance to one desired canonical geometry range through at least one branch. The GNM is general and readily plugged into existing convolutional neural network based text detectors to construct end-to-end Geometry Normalization Networks (GNNets). Moreover, we propose a geometry-aware training scheme to effectively train the GNNets by sampling and augmenting text instances from a uniform geometry variance distribution. Finally, experiments on popular benchmarks of ICDAR 2015 and ICDAR 2017 MLT validate that our method outperforms all the state-of-the-art approaches remarkably by obtaining one-forward test F-scores of 88.52 and 74.54 respectively.



### Dynamic Approach for Lane Detection using Google Street View and CNN
- **Arxiv ID**: http://arxiv.org/abs/1909.00798v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.00798v1)
- **Published**: 2019-09-02 17:10:01+00:00
- **Updated**: 2019-09-02 17:10:01+00:00
- **Authors**: Rama Sai Mamidala, Uday Uthkota, Mahamkali Bhavani Shankar, A. Joseph Antony, A. V. Narasimhadhan
- **Comment**: Preprint: To be published in the proceedings of IEEE TENCON 2019
- **Journal**: None
- **Summary**: Lane detection algorithms have been the key enablers for a fully-assistive and autonomous navigation systems. In this paper, a novel and pragmatic approach for lane detection is proposed using a convolutional neural network (CNN) model based on SegNet encoder-decoder architecture. The encoder block renders low-resolution feature maps of the input and the decoder block provides pixel-wise classification from the feature maps. The proposed model has been trained over 2000 image data-set and tested against their corresponding ground-truth provided in the data-set for evaluation. To enable real-time navigation, we extend our model's predictions interfacing it with the existing Google APIs evaluating the metrics of the model tuning the hyper-parameters. The novelty of this approach lies in the integration of existing segNet architecture with google APIs. This interface makes it handy for assistive robotic systems. The observed results show that the proposed method is robust under challenging occlusion conditions due to pre-processing involved and gives superior performance when compared to the existing methods.



### White-Box Evaluation of Fingerprint Matchers: Robustness to Minutiae Perturbations
- **Arxiv ID**: http://arxiv.org/abs/1909.00799v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00799v4)
- **Published**: 2019-09-02 17:11:17+00:00
- **Updated**: 2020-04-12 13:07:33+00:00
- **Authors**: Steven A. Grosz, Joshua J. Engelsma, Nicholas G. Paulter Jr., Anil K. Jain
- **Comment**: None
- **Journal**: None
- **Summary**: Prevailing evaluations of fingerprint recognition systems have been performed as end-to-end black-box tests of fingerprint identification or authentication accuracy. However, performance of the end-to-end system is subject to errors arising in any of its constituent modules, including: fingerprint scanning, preprocessing, feature extraction, and matching. Conversely, white-box evaluations provide a more granular evaluation by studying the individual sub-components of a system. While a few studies have conducted stand-alone evaluations of the fingerprint reader and feature extraction modules of fingerprint recognition systems, little work has been devoted towards white-box evaluations of the fingerprint matching module. We report results of a controlled, white-box evaluation of one open-source and two commercial-off-the-shelf (COTS) minutiae-based matchers in terms of their robustness against controlled perturbations (random noise and non-linear distortions) introduced into the input minutiae feature sets. Our white-box evaluations reveal that the performance of fingerprint minutiae matchers are more susceptible to non-linear distortion and missing minutiae than spurious minutiae and small positional displacements of the minutiae locations.



### HishabNet: Detection, Localization and Calculation of Handwritten Bengali Mathematical Expressions
- **Arxiv ID**: http://arxiv.org/abs/1909.00823v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.00823v1)
- **Published**: 2019-09-02 18:28:14+00:00
- **Updated**: 2019-09-02 18:28:14+00:00
- **Authors**: Md Nafee Al Islam, Siamul Karim Khan
- **Comment**: 6 pages, 5 figures, This paper is under review in "22nd International
  Conference on Computer and Information Technology (ICCIT), 2019"
- **Journal**: None
- **Summary**: Recently, recognition of handwritten Bengali letters and digits have captured a lot of attention among the researchers of the AI community. In this work, we propose a Convolutional Neural Network (CNN) based object detection model which can recognize and evaluate handwritten Bengali mathematical expressions. This method is able to detect multiple Bengali digits and operators and locate their positions in the image. With that information, it is able to construct numbers from series of digits and perform mathematical operations on them. For the object detection task, the state-of-the-art YOLOv3 algorithm was utilized. For training and evaluating the model, we have engineered a new dataset 'Hishab' which is the first Bengali handwritten digits dataset intended for object detection. The model achieved an overall validation mean average precision (mAP) of 98.6%. Also, the classification accuracy of the feature extractor backbone CNN used in our model was tested on two publicly available Bengali handwritten digits datasets: NumtaDB and CMATERdb. The backbone CNN achieved a test set accuracy of 99.6252% on NumtaDB and 99.0833% on CMATERdb.



### HiCoRe: Visual Hierarchical Context-Reasoning
- **Arxiv ID**: http://arxiv.org/abs/1909.00848v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.00848v1)
- **Published**: 2019-09-02 19:57:05+00:00
- **Updated**: 2019-09-02 19:57:05+00:00
- **Authors**: Pedro H. Bugatti, Priscila T. M. Saito, Larry S. Davis
- **Comment**: None
- **Journal**: None
- **Summary**: Reasoning about images/objects and their hierarchical interactions is a key concept for the next generation of computer vision approaches. Here we present a new framework to deal with it through a visual hierarchical context-based reasoning. Current reasoning methods use the fine-grained labels from images' objects and their interactions to predict labels to new objects. Our framework modifies this current information flow. It goes beyond and is independent of the fine-grained labels from the objects to define the image context. It takes into account the hierarchical interactions between different abstraction levels (i.e. taxonomy) of information in the images and their bounding-boxes. Besides these connections, it considers their intrinsic characteristics. To do so, we build and apply graphs to graph convolution networks with convolutional neural networks. We show a strong effectiveness over widely used convolutional neural networks, reaching a gain 3 times greater on well-known image datasets. We evaluate the capability and the behavior of our framework under different scenarios, considering distinct (superclass, subclass and hierarchical) granularity levels. We also explore attention mechanisms through graph attention networks and pre-processing methods considering dimensionality expansion and/or reduction of the features' representations. Further analyses are performed comparing supervised and semi-supervised approaches.



### Performance comparison of 3D correspondence grouping algorithm for 3D plant point clouds
- **Arxiv ID**: http://arxiv.org/abs/1909.00866v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00866v1)
- **Published**: 2019-09-02 21:02:00+00:00
- **Updated**: 2019-09-02 21:02:00+00:00
- **Authors**: Shiva Azimi, Tapan K. Gandhi
- **Comment**: None
- **Journal**: None
- **Summary**: Plant Phenomics can be used to monitor the health and the growth of plants. Computer vision applications like stereo reconstruction, image retrieval, object tracking, and object recognition play an important role in imaging based plant phenotyping. This paper offers a comparative evaluation of some popular 3D correspondence grouping algorithms, motivated by the important role that they can play in tasks such as model creation, plant recognition and identifying plant parts. Another contribution of this paper is the extension of 2D maximum likelihood matching to 3D Maximum Likelihood Estimation Sample Consensus (MLEASAC). MLESAC is efficient and is computationally less intense than 3D random sample consensus (RANSAC). We test these algorithms on 3D point clouds of plants along with two standard benchmarks addressing shape retrieval and point cloud registration scenarios. The performance is evaluated in terms of precision and recall.



### FACSIMILE: Fast and Accurate Scans From an Image in Less Than a Second
- **Arxiv ID**: http://arxiv.org/abs/1909.00883v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00883v1)
- **Published**: 2019-09-02 22:39:05+00:00
- **Updated**: 2019-09-02 22:39:05+00:00
- **Authors**: David Smith, Matthew Loper, Xiaochen Hu, Paris Mavroidis, Javier Romero
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: Current methods for body shape estimation either lack detail or require many images. They are usually architecturally complex and computationally expensive. We propose FACSIMILE (FAX), a method that estimates a detailed body from a single photo, lowering the bar for creating virtual representations of humans. Our approach is easy to implement and fast to execute, making it easily deployable. FAX uses an image-translation network which recovers geometry at the original resolution of the image. Counterintuitively, the main loss which drives FAX is on per-pixel surface normals instead of per-pixel depth, making it possible to estimate detailed body geometry without any depth supervision. We evaluate our approach both qualitatively and quantitatively, and compare with a state-of-the-art method.



### Domain Randomization and Pyramid Consistency: Simulation-to-Real Generalization without Accessing Target Domain Data
- **Arxiv ID**: http://arxiv.org/abs/1909.00889v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.00889v2)
- **Published**: 2019-09-02 23:33:47+00:00
- **Updated**: 2022-08-10 04:32:05+00:00
- **Authors**: Xiangyu Yue, Yang Zhang, Sicheng Zhao, Alberto Sangiovanni-Vincentelli, Kurt Keutzer, Boqing Gong
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: We propose to harness the potential of simulation for the semantic segmentation of real-world self-driving scenes in a domain generalization fashion. The segmentation network is trained without any data of target domains and tested on the unseen target domains. To this end, we propose a new approach of domain randomization and pyramid consistency to learn a model with high generalizability. First, we propose to randomize the synthetic images with the styles of real images in terms of visual appearances using auxiliary datasets, in order to effectively learn domain-invariant representations. Second, we further enforce pyramid consistency across different "stylized" images and within an image, in order to learn domain-invariant and scale-invariant features, respectively. Extensive experiments are conducted on the generalization from GTA and SYNTHIA to Cityscapes, BDDS and Mapillary; and our method achieves superior results over the state-of-the-art techniques. Remarkably, our generalization results are on par with or even better than those obtained by state-of-the-art simulation-to-real domain adaptation methods, which access the target domain data at training time.



