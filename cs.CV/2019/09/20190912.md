# Arxiv Papers in cs.CV on 2019-09-12
### Flow-Motion and Depth Network for Monocular Stereo and Beyond
- **Arxiv ID**: http://arxiv.org/abs/1909.05452v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05452v1)
- **Published**: 2019-09-12 04:49:38+00:00
- **Updated**: 2019-09-12 04:49:38+00:00
- **Authors**: Kaixuan Wang, Shaojie Shen
- **Comment**: Under Review
- **Journal**: None
- **Summary**: We propose a learning-based method that solves monocular stereo and can be extended to fuse depth information from multiple target frames. Given two unconstrained images from a monocular camera with known intrinsic calibration, our network estimates relative camera poses and the depth map of the source image. The core contribution of the proposed method is threefold. First, a network is tailored for static scenes that jointly estimates the optical flow and camera motion. By the joint estimation, the optical flow search space is gradually reduced resulting in an efficient and accurate flow estimation. Second, a novel triangulation layer is proposed to encode the estimated optical flow and camera motion while avoiding common numerical issues caused by epipolar. Third, beyond two-view depth estimation, we further extend the above networks to fuse depth information from multiple target images and estimate the depth map of the source image. To further benefit the research community, we introduce tools to generate photorealistic structure-from-motion datasets such that deep networks can be well trained and evaluated. The proposed method is compared with previous methods and achieves state-of-the-art results within less time. Images from real-world applications and Google Earth are used to demonstrate the generalization ability of the method.



### diffGrad: An Optimization Method for Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1909.11015v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1909.11015v4)
- **Published**: 2019-09-12 06:20:05+00:00
- **Updated**: 2021-11-27 01:58:07+00:00
- **Authors**: Shiv Ram Dubey, Soumendu Chakraborty, Swalpa Kumar Roy, Snehasis Mukherjee, Satish Kumar Singh, Bidyut Baran Chaudhuri
- **Comment**: None
- **Journal**: IEEE Transactions on Neural Networks and Learning Systems, 2020
- **Summary**: Stochastic Gradient Decent (SGD) is one of the core techniques behind the success of deep neural networks. The gradient provides information on the direction in which a function has the steepest rate of change. The main problem with basic SGD is to change by equal sized steps for all parameters, irrespective of gradient behavior. Hence, an efficient way of deep network optimization is to make adaptive step sizes for each parameter. Recently, several attempts have been made to improve gradient descent methods such as AdaGrad, AdaDelta, RMSProp and Adam. These methods rely on the square roots of exponential moving averages of squared past gradients. Thus, these methods do not take advantage of local change in gradients. In this paper, a novel optimizer is proposed based on the difference between the present and the immediate past gradient (i.e., diffGrad). In the proposed diffGrad optimization technique, the step size is adjusted for each parameter in such a way that it should have a larger step size for faster gradient changing parameters and a lower step size for lower gradient changing parameters. The convergence analysis is done using the regret bound approach of online learning framework. Rigorous analysis is made in this paper over three synthetic complex non-convex functions. The image categorization experiments are also conducted over the CIFAR10 and CIFAR100 datasets to observe the performance of diffGrad with respect to the state-of-the-art optimizers such as SGDM, AdaGrad, AdaDelta, RMSProp, AMSGrad, and Adam. The residual unit (ResNet) based Convolutional Neural Networks (CNN) architecture is used in the experiments. The experiments show that diffGrad outperforms other optimizers. Also, we show that diffGrad performs uniformly well for training CNN using different activation functions. The source code is made publicly available at https://github.com/shivram1987/diffGrad.



### Generating Accurate Pseudo-labels in Semi-Supervised Learning and Avoiding Overconfident Predictions via Hermite Polynomial Activations
- **Arxiv ID**: http://arxiv.org/abs/1909.05479v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05479v2)
- **Published**: 2019-09-12 06:42:08+00:00
- **Updated**: 2020-03-31 06:01:54+00:00
- **Authors**: Vishnu Suresh Lokhande, Songwong Tasneeyapant, Abhay Venkatesh, Sathya N. Ravi, Vikas Singh
- **Comment**: Accepted at 2020 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR)
- **Journal**: None
- **Summary**: Rectified Linear Units (ReLUs) are among the most widely used activation function in a broad variety of tasks in vision. Recent theoretical results suggest that despite their excellent practical performance, in various cases, a substitution with basis expansions (e.g., polynomials) can yield significant benefits from both the optimization and generalization perspective. Unfortunately, the existing results remain limited to networks with a couple of layers, and the practical viability of these results is not yet known. Motivated by some of these results, we explore the use of Hermite polynomial expansions as a substitute for ReLUs in deep networks. While our experiments with supervised learning do not provide a clear verdict, we find that this strategy offers considerable benefits in semi-supervised learning (SSL) / transductive learning settings. We carefully develop this idea and show how the use of Hermite polynomials based activations can yield improvements in pseudo-label accuracies and sizable financial savings (due to concurrent runtime benefits). Further, we show via theoretical analysis, that the networks (with Hermite activations) offer robustness to noise and other attractive mathematical properties.



### 3D Ken Burns Effect from a Single Image
- **Arxiv ID**: http://arxiv.org/abs/1909.05483v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1909.05483v1)
- **Published**: 2019-09-12 06:55:07+00:00
- **Updated**: 2019-09-12 06:55:07+00:00
- **Authors**: Simon Niklaus, Long Mai, Jimei Yang, Feng Liu
- **Comment**: TOG 2019, http://sniklaus.com/kenburns
- **Journal**: None
- **Summary**: The Ken Burns effect allows animating still images with a virtual camera scan and zoom. Adding parallax, which results in the 3D Ken Burns effect, enables significantly more compelling results. Creating such effects manually is time-consuming and demands sophisticated editing skills. Existing automatic methods, however, require multiple input images from varying viewpoints. In this paper, we introduce a framework that synthesizes the 3D Ken Burns effect from a single image, supporting both a fully automatic mode and an interactive mode with the user controlling the camera. Our framework first leverages a depth prediction pipeline, which estimates scene depth that is suitable for view synthesis tasks. To address the limitations of existing depth estimation methods such as geometric distortions, semantic distortions, and inaccurate depth boundaries, we develop a semantic-aware neural network for depth prediction, couple its estimate with a segmentation-based depth adjustment process, and employ a refinement neural network that facilitates accurate depth predictions at object boundaries. According to this depth estimate, our framework then maps the input image to a point cloud and synthesizes the resulting video frames by rendering the point cloud from the corresponding camera positions. To address disocclusions while maintaining geometrically and temporally coherent synthesis results, we utilize context-aware color- and depth-inpainting to fill in the missing information in the extreme views of the camera path, thus extending the scene geometry of the point cloud. Experiments with a wide variety of image content show that our method enables realistic synthesis results. Our study demonstrates that our system allows users to achieve better results while requiring little effort compared to existing solutions for the 3D Ken Burns effect creation.



### An Automatic Cardiac Segmentation Framework based on Multi-sequence MR Image
- **Arxiv ID**: http://arxiv.org/abs/1909.05488v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.05488v1)
- **Published**: 2019-09-12 07:19:11+00:00
- **Updated**: 2019-09-12 07:19:11+00:00
- **Authors**: Yashu Liu, Wei Wang, Kuanquan Wang, Chengqin Ye, Gongning Luo
- **Comment**: accepted by STACOM 2019
- **Journal**: None
- **Summary**: LGE CMR is an efficient technology for detecting infarcted myocardium. An efficient and objective ventricle segmentation method in LGE can benefit the location of the infarcted myocardium. In this paper, we proposed an automatic framework for LGE image segmentation. There are just 5 labeled LGE volumes with about 15 slices of each volume. We adopted histogram match, an invariant of rotation registration method, on the other labeled modalities to achieve effective augmentation of the training data. A CNN segmentation model was trained based on the augmented training data by leave-one-out strategy. The predicted result of the model followed a connected component analysis for each class to remain the largest connected component as the final segmentation result. Our model was evaluated by the 2019 Multi-sequence Cardiac MR Segmentation Challenge. The mean testing result of 40 testing volumes on Dice score, Jaccard score, Surface distance, and Hausdorff distance is 0.8087, 0.6976, 2.8727mm, and 15.6387mm, respectively. The experiment result shows a satisfying performance of the proposed framework. Code is available at https://github.com/Suiiyu/MS-CMR2019.



### CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1909.05506v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05506v1)
- **Published**: 2019-09-12 08:46:11+00:00
- **Updated**: 2019-09-12 08:46:11+00:00
- **Authors**: Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, Jing Shao
- **Comment**: Accepted by ICCV 2019
- **Journal**: None
- **Summary**: Text-image cross-modal retrieval is a challenging task in the field of language and vision. Most previous approaches independently embed images and sentences into a joint embedding space and compare their similarities. However, previous approaches rarely explore the interactions between images and sentences before calculating similarities in the joint space. Intuitively, when matching between images and sentences, human beings would alternatively attend to regions in images and words in sentences, and select the most salient information considering the interaction between both modalities. In this paper, we propose Cross-modal Adaptive Message Passing (CAMP), which adaptively controls the information flow for message passing across modalities. Our approach not only takes comprehensive and fine-grained cross-modal interactions into account, but also properly handles negative pairs and irrelevant information with an adaptive gating scheme. Moreover, instead of conventional joint embedding approaches for text-image matching, we infer the matching score based on the fused features, and propose a hardest negative binary cross-entropy loss for training. Results on COCO and Flickr30k significantly surpass state-of-the-art methods, demonstrating the effectiveness of our approach.



### Effective training of deep convolutional neural networks for hyperspectral image classification through artificial labeling
- **Arxiv ID**: http://arxiv.org/abs/1909.05507v2
- **DOI**: 10.3390/rs12162653
- **Categories**: **cs.NE**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.05507v2)
- **Published**: 2019-09-12 08:47:21+00:00
- **Updated**: 2020-10-22 08:48:33+00:00
- **Authors**: Wojciech Masarczyk, Przemysław Głomb, Bartosz Grabowski, Mateusz Ostaszewski
- **Comment**: None
- **Journal**: Remote Sens. 2020, 12, 2653
- **Summary**: Hyperspectral imaging is a rich source of data, allowing for multitude of effective applications. However, such imaging remains challenging because of large data dimension and, typically, small pool of available training examples. While deep learning approaches have been shown to be successful in providing effective classification solutions, especially for high dimensional problems, unfortunately they work best with a lot of labelled examples available. To alleviate the second requirement for a particular dataset the transfer learning approach can be used: first the network is pre-trained on some dataset with large amount of training labels available, then the actual dataset is used to fine-tune the network. This strategy is not straightforward to apply with hyperspectral images, as it is often the case that only one particular image of some type or characteristic is available. In this paper, we propose and investigate a simple and effective strategy of transfer learning that uses unsupervised pre-training step without label information. This approach can be applied to many of the hyperspectral classification problems. Performed experiments show that it is very effective at improving the classification accuracy without being restricted to a particular image type or neural network architecture. The experiments were carried out on several deep neural network architectures and various sizes of labeled training sets. The greatest improvement in overall accuracy on the Indian Pines and Pavia University datasets is over 21 and 13 percentage points, respectively. An additional advantage of the proposed approach is the unsupervised nature of the pre-training step, which can be done immediately after image acquisition, without the need of the potentially costly expert's time.



### On the Effect of Observed Subject Biases in Apparent Personality Analysis from Audio-visual Signals
- **Arxiv ID**: http://arxiv.org/abs/1909.05568v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05568v2)
- **Published**: 2019-09-12 11:18:54+00:00
- **Updated**: 2019-11-28 17:00:59+00:00
- **Authors**: Ricardo Darío Pérez Principi, Cristina Palmero, Julio C. S. Jacques Junior, Sergio Escalera
- **Comment**: Accepted in IEEE Transactions on Affective Computing (TAC)
- **Journal**: None
- **Summary**: Personality perception is implicitly biased due to many subjective factors, such as cultural, social, contextual, gender and appearance. Approaches developed for automatic personality perception are not expected to predict the real personality of the target, but the personality external observers attributed to it. Hence, they have to deal with human bias, inherently transferred to the training data. However, bias analysis in personality computing is an almost unexplored area. In this work, we study different possible sources of bias affecting personality perception, including emotions from facial expressions, attractiveness, age, gender, and ethnicity, as well as their influence on prediction ability for apparent personality estimation. To this end, we propose a multi-modal deep neural network that combines raw audio and visual information alongside predictions of attribute-specific models to regress apparent personality. We also analyse spatio-temporal aggregation schemes and the effect of different time intervals on first impressions. We base our study on the ChaLearn First Impressions dataset, consisting of one-person conversational videos. Our model shows state-of-the-art results regressing apparent personality based on the Big-Five model. Furthermore, given the interpretability nature of our network design, we provide an incremental analysis on the impact of each possible source of bias on final network predictions.



### Human-Machine Collaborative Design for Accelerated Design of Compact Deep Neural Networks for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/1909.05587v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1909.05587v1)
- **Published**: 2019-09-12 12:00:50+00:00
- **Updated**: 2019-09-12 12:00:50+00:00
- **Authors**: Mohammad Javad Shafiee, Mirko Nentwig, Yohannes Kassahun, Francis Li, Stanislav Bochkarev, Akif Kamal, David Dolson, Secil Altintas, Arif Virani, Alexander Wong
- **Comment**: 7 pages; BMVC Workshop on Visual AI and Entrepreneurship (VAIE)
- **Journal**: None
- **Summary**: An effective deep learning development process is critical for widespread industrial adoption, particularly in the automotive sector. A typical industrial deep learning development cycle involves customizing and re-designing an off-the-shelf network architecture to meet the operational requirements of the target application, leading to considerable trial and error work by a machine learning practitioner. This approach greatly impedes development with a long turnaround time and the unsatisfactory quality of the created models. As a result, a development platform that can aid engineers in greatly accelerating the design and production of compact, optimized deep neural networks is highly desirable. In this joint industrial case study, we study the efficacy of the GenSynth AI-assisted AI design platform for accelerating the design of custom, optimized deep neural networks for autonomous driving through human-machine collaborative design. We perform a quantitative examination by evaluating 10 different compact deep neural networks produced by GenSynth for the purpose of object detection via a NASNet-based user network prototype design, targeted at a low-cost GPU-based accelerated embedded system. Furthermore, we quantitatively assess the talent hours and GPU processing hours used by the GenSynth process and three other approaches based on the typical industrial development process. In addition, we quantify the annual cloud cost savings for comprehensive testing using networks produced by GenSynth. Finally, we assess the usability and merits of the GenSynth process through user feedback. The findings of this case study showed that GenSynth is easy to use and can be effective at accelerating the design and production of compact, customized deep neural network.



### A Camera That CNNs: Towards Embedded Neural Networks on Pixel Processor Arrays
- **Arxiv ID**: http://arxiv.org/abs/1909.05647v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.ET
- **Links**: [PDF](http://arxiv.org/pdf/1909.05647v2)
- **Published**: 2019-09-12 13:39:42+00:00
- **Updated**: 2019-09-13 13:07:04+00:00
- **Authors**: Laurie Bose, Jianing Chen, Stephen J. Carey, Piotr Dudek, Walterio Mayol-Cuevas
- **Comment**: Accepted into ICCV 2019
- **Journal**: None
- **Summary**: We present a convolutional neural network implementation for pixel processor array (PPA) sensors. PPA hardware consists of a fine-grained array of general-purpose processing elements, each capable of light capture, data storage, program execution, and communication with neighboring elements. This allows images to be stored and manipulated directly at the point of light capture, rather than having to transfer images to external processing hardware. Our CNN approach divides this array up into 4x4 blocks of processing elements, essentially trading-off image resolution for increased local memory capacity per 4x4 "pixel". We implement parallel operations for image addition, subtraction and bit-shifting images in this 4x4 block format. Using these components we formulate how to perform ternary weight convolutions upon these images, compactly store results of such convolutions, perform max-pooling, and transfer the resulting sub-sampled data to an attached micro-controller. We train ternary weight filter CNNs for digit recognition and a simple tracking task, and demonstrate inference of these networks upon the SCAMP5 PPA system. This work represents a first step towards embedding neural network processing capability directly onto the focal plane of a sensor.



### Recognition of Handwritten Digit using Convolutional Neural Network in Python with Tensorflow and Comparison of Performance for Various Hidden Layers
- **Arxiv ID**: http://arxiv.org/abs/1909.08490v1
- **DOI**: 10.1109/ICAEE48663.2019.8975496
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1909.08490v1)
- **Published**: 2019-09-12 13:44:38+00:00
- **Updated**: 2019-09-12 13:44:38+00:00
- **Authors**: Fathma Siddique, Shadman Sakib, Md. Abu Bakr Siddique
- **Comment**: To be published in 5th International Conference on Advances in
  Electrical Engineering (ICAEE-2019)
- **Journal**: 2019 5th International Conference on Advances in Electrical
  Engineering (ICAEE)
- **Summary**: In recent times, with the increase of Artificial Neural Network (ANN), deep learning has brought a dramatic twist in the field of machine learning by making it more artificially intelligent. Deep learning is remarkably used in vast ranges of fields because of its diverse range of applications such as surveillance, health, medicine, sports, robotics, drones, etc. In deep learning, Convolutional Neural Network (CNN) is at the center of spectacular advances that mixes Artificial Neural Network (ANN) and up to date deep learning strategies. It has been used broadly in pattern recognition, sentence classification, speech recognition, face recognition, text categorization, document analysis, scene, and handwritten digit recognition. The goal of this paper is to observe the variation of accuracies of CNN to classify handwritten digits using various numbers of hidden layers and epochs and to make the comparison between the accuracies. For this performance evaluation of CNN, we performed our experiment using Modified National Institute of Standards and Technology (MNIST) dataset. Further, the network is trained using stochastic gradient descent and the backpropagation algorithm.



### Map Matching Algorithm for Large-scale Datasets
- **Arxiv ID**: http://arxiv.org/abs/1910.05312v1
- **DOI**: None
- **Categories**: **cs.NI**, cs.CV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1910.05312v1)
- **Published**: 2019-09-12 13:49:32+00:00
- **Updated**: 2019-09-12 13:49:32+00:00
- **Authors**: David Fiedler, Michal Čáp, Jan Nykl, Pavol Žilecký, Martin Schaefer
- **Comment**: None
- **Journal**: None
- **Summary**: GPS receivers embedded in cell phones and connected vehicles generate a series of location measurements that can be used for various analytical purposes. A common pre-processing step of this data is the so-called map matching. The goal of map matching is to infer the trajectory that the device followed in a road network from a potentially sparse series of noisy location measurements. Although accurate and robust map matching algorithms based on probabilistic models exist, they are computationally heavy and thus impractical for processing of large datasets. In this paper, we present a scalable map-matching algorithm based on Dijkstra shortest path method, that is both accurate and applicable to large datasets. Our experiments on a publicly-available dataset showed that the proposed method achieves accuracy that is comparable to that of the existing map matching methods using only a fraction of computational resources. In result, our algorithm can be used to efficiently process large datasets of noisy and potentially sparse location data that would be unexploitable using existing techniques due to their high computational requirements.



### VeREFINE: Integrating Object Pose Verification with Physics-guided Iterative Refinement
- **Arxiv ID**: http://arxiv.org/abs/1909.05730v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.05730v3)
- **Published**: 2019-09-12 14:48:00+00:00
- **Updated**: 2020-05-18 11:36:02+00:00
- **Authors**: Dominik Bauer, Timothy Patten, Markus Vincze
- **Comment**: Revised version
- **Journal**: None
- **Summary**: Accurate and robust object pose estimation for robotics applications requires verification and refinement steps. In this work, we propose to integrate hypotheses verification with object pose refinement guided by physics simulation. This allows the physical plausibility of individual object pose estimates and the stability of the estimated scene to be considered in a unified optimization. The proposed method is able to adapt to scenes of multiple objects and efficiently focuses on refining the most promising object poses in multi-hypotheses scenarios. We call this integrated approach VeREFINE and evaluate it on three datasets with varying scene complexity. The generality of the approach is shown by using three state-of-the-art pose estimators and three baseline refiners. Results show improvements over all baselines and on all datasets. Furthermore, our approach is applied in real-world grasping experiments and outperforms competing methods in terms of grasp success rate. Code is publicly available at github.com/dornik/verefine.



### CvxNet: Learnable Convex Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1909.05736v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.05736v4)
- **Published**: 2019-09-12 14:59:52+00:00
- **Updated**: 2020-04-12 23:43:12+00:00
- **Authors**: Boyang Deng, Kyle Genova, Soroosh Yazdani, Sofien Bouaziz, Geoffrey Hinton, Andrea Tagliasacchi
- **Comment**: None
- **Journal**: None
- **Summary**: Any solid object can be decomposed into a collection of convex polytopes (in short, convexes). When a small number of convexes are used, such a decomposition can be thought of as a piece-wise approximation of the geometry. This decomposition is fundamental in computer graphics, where it provides one of the most common ways to approximate geometry, for example, in real-time physics simulation. A convex object also has the property of being simultaneously an explicit and implicit representation: one can interpret it explicitly as a mesh derived by computing the vertices of a convex hull, or implicitly as the collection of half-space constraints or support functions. Their implicit representation makes them particularly well suited for neural network training, as they abstract away from the topology of the geometry they need to represent. However, at testing time, convexes can also generate explicit representations -- polygonal meshes -- which can then be used in any downstream application. We introduce a network architecture to represent a low dimensional family of convexes. This family is automatically derived via an auto-encoding process. We investigate the applications of this architecture including automatic convex decomposition, image to 3D reconstruction, and part-based shape retrieval.



### Revealing Stable and Unstable Modes of Generic Denoisers through Nonlinear Eigenvalue Analysis
- **Arxiv ID**: http://arxiv.org/abs/1909.12775v3
- **DOI**: None
- **Categories**: **math.NA**, cs.CV, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1909.12775v3)
- **Published**: 2019-09-12 15:01:48+00:00
- **Updated**: 2020-07-06 08:56:03+00:00
- **Authors**: Ester Hait-Fraenkel, Guy Gilboa
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose to analyze stable and unstable modes of generic image denoisers through nonlinear eigenvalue analysis. We attempt to find input images for which the output of a black-box denoiser is proportional to the input. We treat this as a nonlinear eigenvalue problem. This has potentially wide implications, since most image processing algorithms can be viewed as generic nonlinear operators. We introduce a generalized nonlinear power-method to solve eigenproblems for such black-box operators. Using this method we reveal stable modes of nonlinear denoisers. These modes are optimal inputs for the denoiser, achieving superior PSNR in noise removal. Analogously to the linear case (low-pass-filter), such stable modes are eigenfunctions corresponding to large eigenvalues, characterized by large piece-wise-smooth structures. We also provide a method to generate the complementary, most unstable modes, which the denoiser suppresses strongly. These modes are textures with small eigenvalues. We validate the method using total-variation (TV) and demonstrate it on the EPLL denoiser (Zoran-Weiss). Finally, we suggest an encryption-decryption application.



### Rethinking the CSC Model for Natural Images
- **Arxiv ID**: http://arxiv.org/abs/1909.05742v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.05742v1)
- **Published**: 2019-09-12 15:10:21+00:00
- **Updated**: 2019-09-12 15:10:21+00:00
- **Authors**: Dror Simon, Michael Elad
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse representation with respect to an overcomplete dictionary is often used when regularizing inverse problems in signal and image processing. In recent years, the Convolutional Sparse Coding (CSC) model, in which the dictionary consists of shift-invariant filters, has gained renewed interest. While this model has been successfully used in some image processing problems, it still falls behind traditional patch-based methods on simple tasks such as denoising.   In this work we provide new insights regarding the CSC model and its capability to represent natural images, and suggest a Bayesian connection between this model and its patch-based ancestor. Armed with these observations, we suggest a novel feed-forward network that follows an MMSE approximation process to the CSC model, using strided convolutions. The performance of this supervised architecture is shown to be on par with state of the art methods while using much fewer parameters.



### Recognizing Object Affordances to Support Scene Reasoning for Manipulation Tasks
- **Arxiv ID**: http://arxiv.org/abs/1909.05770v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.05770v2)
- **Published**: 2019-09-12 15:58:30+00:00
- **Updated**: 2020-09-12 22:39:14+00:00
- **Authors**: Fu-Jen Chu, Ruinian Xu, Chao Tang, Patricio A. Vela
- **Comment**: 20 pages
- **Journal**: None
- **Summary**: Affordance information about a scene provides important clues as to what actions may be executed in pursuit of meeting a specified goal state. Thus, integrating affordance-based reasoning into symbolic action plannning pipelines would enhance the flexibility of robot manipulation. Unfortunately, the top performing affordance recognition methods use object category priors to boost the accuracy of affordance detection and segmentation. Object priors limit generalization to unknown object categories. This paper describes an affordance recognition pipeline based on a category-agnostic region proposal network for proposing instance regions of an image across categories. To guide affordance learning in the absence of category priors, the training process includes the auxiliary task of explicitly inferencing existing affordances within a proposal. Secondly, a self-attention mechanism trained to interpret each proposal learns to capture rich contextual dependencies through the region. Visual benchmarking shows that the trained network, called AffContext, reduces the performance gap between object-agnostic and object-informed affordance recognition. AffContext is linked to the Planning Domain Definition Language (PDDL) with an augmented state keeper for action planning across temporally spaced goal-oriented tasks. Manipulation experiments show that AffContext can successfully parse scene content to seed a symbolic planner problem specification, whose execution completes the target task. Additionally, task-oriented grasping for cutting and pounding actions demonstrate the exploitation of multiple affordances for a given object to complete specified tasks.



### PILOT: Physics-Informed Learned Optimized Trajectories for Accelerated MRI
- **Arxiv ID**: http://arxiv.org/abs/1909.05773v5
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1909.05773v5)
- **Published**: 2019-09-12 16:10:31+00:00
- **Updated**: 2021-04-13 06:02:39+00:00
- **Authors**: Tomer Weiss, Ortal Senouf, Sanketh Vedula, Oleg Michailovich, Michael Zibulevsky, Alex Bronstein
- **Comment**: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://melba-journal.org
- **Journal**: None
- **Summary**: Magnetic Resonance Imaging (MRI) has long been considered to be among "the gold standards" of diagnostic medical imaging. The long acquisition times, however, render MRI prone to motion artifacts, let alone their adverse contribution to the relative high costs of MRI examination. Over the last few decades, multiple studies have focused on the development of both physical and post-processing methods for accelerated acquisition of MRI scans. These two approaches, however, have so far been addressed separately. On the other hand, recent works in optical computational imaging have demonstrated growing success of concurrent learning-based design of data acquisition and image reconstruction schemes. Such schemes have already demonstrated substantial effectiveness, leading to considerably shorter acquisition times and improved quality of image reconstruction. Inspired by this initial success, in this work, we propose a novel approach to the learning of optimal schemes for conjoint acquisition and reconstruction of MRI scans, with the optimization carried out simultaneously with respect to the time-efficiency of data acquisition and the quality of resulting reconstructions. To be of a practical value, the schemes are encoded in the form of general k-space trajectories, whose associated magnetic gradients are constrained to obey a set of predefined hardware requirements (as defined in terms of, e.g., peak currents and maximum slew rates of magnetic gradients). With this proviso in mind, we propose a novel algorithm for the end-to-end training of a combined acquisition-reconstruction pipeline using a deep neural network with differentiable forward- and back-propagation operators. We demonstrate its effectiveness on image reconstruction and image segmentation tasks, reporting substantial improvements in terms of acceleration factors as well as the quality of these tasks.



### I-SAFE: Instant Suspicious Activity identiFication at the Edge using Fuzzy Decision Making
- **Arxiv ID**: http://arxiv.org/abs/1909.05776v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05776v1)
- **Published**: 2019-09-12 16:14:37+00:00
- **Updated**: 2019-09-12 16:14:37+00:00
- **Authors**: Seyed Yahya Nikouei, Yu Chen, Alexander Aved, Erik Blasch, Timothy R. Faughnan
- **Comment**: Manuscript has been accepted and to be presented at the Fourth
  ACM/IEEE Symposium on Edge Computing, Washington DC, November 7-9, 2019
- **Journal**: None
- **Summary**: Urban imagery usually serves as forensic analysis and by design is available for incident mitigation. As more imagery collected, it is harder to narrow down to certain frames among thousands of video clips to a specific incident. A real-time, proactive surveillance system is desirable, which could instantly detect dubious personnel, identify suspicious activities, or raise momentous alerts. The recent proliferation of the edge computing paradigm allows more data-intensive tasks to be accomplished by smart edge devices with lightweight but powerful algorithms. This paper presents a forensic surveillance strategy by introducing an Instant Suspicious Activity identiFication at the Edge (I-SAFE) using fuzzy decision making. A fuzzy control system is proposed to mimic the decision-making process of a security officer. Decisions are made based on video features extracted by a lightweight Deep Machine Learning (DML) model. Based on the requirements from the first-line law enforcement officers, several features are selected and fuzzified to cope with the state of uncertainty that exists in the officers' decision-making process. Using features in the edge hierarchy minimizes the communication delay such that instant alerting is achieved. Additionally, leveraging the Microservices architecture, the I-SAFE scheme possesses good scalability given the increasing complexities at the network edge. Implemented as an edge-based application and tested using exemplary and various labeled dataset surveillance videos, the I-SAFE scheme raises alerts by identifying the suspicious activity in an average of 0.002 seconds. Compared to four other state-of-the-art methods over two other data sets, the experimental study verified the superiority of the I-SAFE decentralized method.



### Recurrent Connectivity Aids Recognition of Partly Occluded Objects
- **Arxiv ID**: http://arxiv.org/abs/1909.06175v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.06175v1)
- **Published**: 2019-09-12 16:42:34+00:00
- **Updated**: 2019-09-12 16:42:34+00:00
- **Authors**: Markus Roland Ernst, Jochen Triesch, Thomas Burwick
- **Comment**: 9 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1907.08831
- **Journal**: None
- **Summary**: Feedforward convolutional neural networks are the prevalent model of core object recognition. For challenging conditions, such as occlusion, neuroscientists believe that the recurrent connectivity in the visual cortex aids object recognition. In this work we investigate if and how artificial neural networks can also benefit from recurrent connectivity. For this we systematically compare architectures comprised of bottom-up (B), lateral (L) and top-down (T) connections. To evaluate performance, we introduce two novel stereoscopic occluded object datasets, which bridge the gap from classifying digits to recognizing 3D objects. The task consists of recognizing one target object occluded by multiple occluder objects. We find that recurrent models perform significantly better than their feedforward counterparts, which were matched in parametric complexity. We show that for challenging stimuli, the recurrent feedback is able to correctly revise the initial feedforward guess of the network. Overall, our results suggest that both artificial and biological neural networks can exploit recurrence for improved object recognition.



### Hierarchical Foresight: Self-Supervised Learning of Long-Horizon Tasks via Visual Subgoal Generation
- **Arxiv ID**: http://arxiv.org/abs/1909.05829v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05829v1)
- **Published**: 2019-09-12 17:36:45+00:00
- **Updated**: 2019-09-12 17:36:45+00:00
- **Authors**: Suraj Nair, Chelsea Finn
- **Comment**: 16 pages, 9 figures
- **Journal**: None
- **Summary**: Video prediction models combined with planning algorithms have shown promise in enabling robots to learn to perform many vision-based tasks through only self-supervision, reaching novel goals in cluttered scenes with unseen objects. However, due to the compounding uncertainty in long horizon video prediction and poor scalability of sampling-based planning optimizers, one significant limitation of these approaches is the ability to plan over long horizons to reach distant goals. To that end, we propose a framework for subgoal generation and planning, hierarchical visual foresight (HVF), which generates subgoal images conditioned on a goal image, and uses them for planning. The subgoal images are directly optimized to decompose the task into easy to plan segments, and as a result, we observe that the method naturally identifies semantically meaningful states as subgoals. Across three out of four simulated vision-based manipulation tasks, we find that our method achieves nearly a 200% performance improvement over planning without subgoals and model-free RL approaches. Further, our experiments illustrate that our approach extends to real, cluttered visual scenes. Project page: https://sites.google.com/stanford.edu/hvf



### DeepPruner: Learning Efficient Stereo Matching via Differentiable PatchMatch
- **Arxiv ID**: http://arxiv.org/abs/1909.05845v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05845v1)
- **Published**: 2019-09-12 17:50:04+00:00
- **Updated**: 2019-09-12 17:50:04+00:00
- **Authors**: Shivam Duggal, Shenlong Wang, Wei-Chiu Ma, Rui Hu, Raquel Urtasun
- **Comment**: Accepted at International Conference on Computer Vision (ICCV) 2019
- **Journal**: None
- **Summary**: Our goal is to significantly speed up the runtime of current state-of-the-art stereo algorithms to enable real-time inference. Towards this goal, we developed a differentiable PatchMatch module that allows us to discard most disparities without requiring full cost volume evaluation. We then exploit this representation to learn which range to prune for each pixel. By progressively reducing the search space and effectively propagating such information, we are able to efficiently compute the cost volume for high likelihood hypotheses and achieve savings in both memory and computation. Finally, an image guided refinement module is exploited to further improve the performance. Since all our components are differentiable, the full network can be trained end-to-end. Our experiments show that our method achieves competitive results on KITTI and SceneFlow datasets while running in real-time at 62ms.



### Efficient 2.5D Hand Pose Estimation via Auxiliary Multi-Task Training for Embedded Devices
- **Arxiv ID**: http://arxiv.org/abs/1909.05897v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1909.05897v1)
- **Published**: 2019-09-12 18:33:05+00:00
- **Updated**: 2019-09-12 18:33:05+00:00
- **Authors**: Prajwal Chidananda, Ayan Sinha, Adithya Rao, Douglas Lee, Andrew Rabinovich
- **Comment**: CVPR Workshop on Computer Vision for Augmented and Virtual Reality,
  Long Beach, CA, 2019
- **Journal**: None
- **Summary**: 2D Key-point estimation is an important precursor to 3D pose estimation problems for human body and hands. In this work, we discuss the data, architecture, and training procedure necessary to deploy extremely efficient 2.5D hand pose estimation on embedded devices with highly constrained memory and compute envelope, such as AR/VR wearables. Our 2.5D hand pose estimation consists of 2D key-point estimation of joint positions on an egocentric image, captured by a depth sensor, and lifted to 2.5D using the corresponding depth values. Our contributions are two fold: (a) We discuss data labeling and augmentation strategies, the modules in the network architecture that collectively lead to $3\%$ the flop count and $2\%$ the number of parameters when compared to the state of the art MobileNetV2 architecture. (b) We propose an auxiliary multi-task training strategy needed to compensate for the small capacity of the network while achieving comparable performance to MobileNetV2. Our 32-bit trained model has a memory footprint of less than 300 Kilobytes, operates at more than 50 Hz with less than 35 MFLOPs.



### Perceptual Image Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.05904v2
- **DOI**: 10.1007/978-3-030-41404-7_12
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.05904v2)
- **Published**: 2019-09-12 18:50:08+00:00
- **Updated**: 2020-02-28 09:09:06+00:00
- **Authors**: Nina Tuluptceva, Bart Bakker, Irina Fedulova, Anton Konushin
- **Comment**: The final authenticated publication is available online at
  https://doi.org/10.1007/978-3-030-41404-7_12
- **Journal**: In: Palaiahnakote S., Sanniti di Baja G., Wang L., Yan W. (eds)
  Pattern Recognition. ACPR 2019. Lecture Notes in Computer Science, vol 12046.
  Springer, Cham
- **Summary**: We present a novel method for image anomaly detection, where algorithms that use samples drawn from some distribution of "normal" data, aim to detect out-of-distribution (abnormal) samples. Our approach includes a combination of encoder and generator for mapping an image distribution to a predefined latent distribution and vice versa. It leverages Generative Adversarial Networks to learn these data distributions and uses perceptual loss for the detection of image abnormality. To accomplish this goal, we introduce a new similarity metric, which expresses the perceived similarity between images and is robust to changes in image contrast. Secondly, we introduce a novel approach for the selection of weights of a multi-objective loss function (image reconstruction and distribution mapping) in the absence of a validation dataset for hyperparameter tuning. After training, our model measures the abnormality of the input image as the perceptual dissimilarity between it and the closest generated image of the modeled data distribution. The proposed approach is extensively evaluated on several publicly available image benchmarks and achieves state-of-the-art performance.



### A method for Cloud Mapping in the Field of View of the Infra-Red Camera during the EUSO-SPB1 flight
- **Arxiv ID**: http://arxiv.org/abs/1909.05917v1
- **DOI**: None
- **Categories**: **astro-ph.IM**, astro-ph.EP, cs.CV, cs.LG, J.2
- **Links**: [PDF](http://arxiv.org/pdf/1909.05917v1)
- **Published**: 2019-09-12 19:26:19+00:00
- **Updated**: 2019-09-12 19:26:19+00:00
- **Authors**: Alessandro Bruno, Anna Anzalone, Carlo Vigorito
- **Comment**: 7 pages, 8 figures, 36th International Cosmic Ray Conference
  -ICRC2019
- **Journal**: 36th International Cosmic Ray Conference (ICRC2019), volume=36,
  year=2019 }
- **Summary**: EUSO-SPB1 was released on April 24th, 2017, from the NASA balloon launch site in Wanaka (New Zealand) and landed on the South Pacific Ocean on May 7th. The data collected by the instruments onboard the balloon were analyzed to search UV pulse signatures of UHECR (Ultra High Energy Cosmic Rays) air showers. Indirect measurements of UHECRs can be affected by cloud presence during nighttime, therefore it is crucial to know the meteorological conditions during the observation period of the detector. During the flight, the onboard EUSO-SPB1 UCIRC camera (University of Chicago Infra-Red Camera), acquired images in the field of view of the UV telescope. The available nighttime and daytime images include information on meteorological conditions of the atmosphere observed in two infra-red bands. The presence of clouds has been investigated employing a method developed to provide a dense cloudiness map for each available infra-red image. The final masks are intended to give pixel cloudiness information at the IR-camera pixel resolution that is nearly 4-times higher than the one of the UV-camera. In this work, cloudiness maps are obtained by using an expert system based on the analysis of different low-level image features. Furthermore, an image enhancement step was needed to be applied as a preprocessing step to deal with uncalibrated data.



### Towards Model-Agnostic Adversarial Defenses using Adversarially Trained Autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1909.05921v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.05921v3)
- **Published**: 2019-09-12 19:51:14+00:00
- **Updated**: 2020-03-29 23:38:30+00:00
- **Authors**: Pratik Vaishnavi, Kevin Eykholt, Atul Prakash, Amir Rahmati
- **Comment**: None
- **Journal**: None
- **Summary**: Adversarial machine learning is a well-studied field of research where an adversary causes predictable errors in a machine learning algorithm through precise manipulation of the input. Numerous techniques have been proposed to harden machine learning algorithms and mitigate the effect of adversarial attacks. Of these techniques, adversarial training, which augments the training data with adversarial samples, has proven to be an effective defense with respect to a certain class of attacks. However, adversarial training is computationally expensive and its improvements are limited to a single model. In this work, we take a first step toward creating a model-agnostic adversarial defense. We propose Adversarially-Trained Autoencoder Augmentation (AAA), the first model-agnostic adversarial defense that is robust against certain adaptive adversaries. We show that AAA allows us to achieve a partially model-agnostic defense by training a single autoencoder to protect multiple pre-trained classifiers; achieving adversarial performance on par or better than adversarial training without modifying the classifiers. Furthermore, we demonstrate that AAA can be used to create a fully model-agnostic defense for MNIST and Fashion MNIST datasets by improving the adversarial performance of a never before seen pre-trained classifier by at least 45% with no additional training. Finally, using a natural image corruption dataset, we show that our approach improves robustness to naturally corrupted images,which has been identified as strongly indicative of true adversarial robustness.



### Encoding Visual Attributes in Capsules for Explainable Medical Diagnoses
- **Arxiv ID**: http://arxiv.org/abs/1909.05926v5
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05926v5)
- **Published**: 2019-09-12 20:04:16+00:00
- **Updated**: 2020-06-20 23:52:39+00:00
- **Authors**: Rodney LaLonde, Drew Torigian, Ulas Bagci
- **Comment**: Accepted for publication at MICCAI 2020 (23rd International
  Conference on Medical Image Computing and Computer Assisted Intervention).
  Code is publicly available at https://github.com/lalonderodney/X-Caps
- **Journal**: None
- **Summary**: Convolutional neural network based systems have largely failed to be adopted in many high-risk application areas, including healthcare, military, security, transportation, finance, and legal, due to their highly uninterpretable "black-box" nature. Towards solving this deficiency, we teach a novel multi-task capsule network to improve the explainability of predictions by embodying the same high-level language used by human-experts. Our explainable capsule network, X-Caps, encodes high-level visual object attributes within the vectors of its capsules, then forms predictions based solely on these human-interpretable features. To encode attributes, X-Caps utilizes a new routing sigmoid function to independently route information from child capsules to parents. Further, to provide radiologists with an estimate of model confidence, we train our network on a distribution of expert labels, modeling inter-observer agreement and punishing over/under confidence during training, supervised by human-experts' agreement. X-Caps simultaneously learns attribute and malignancy scores from a multi-center dataset of over 1000 CT scans of lung cancer screening patients. We demonstrate a simple 2D capsule network can outperform a state-of-the-art deep dense dual-path 3D CNN at capturing visually-interpretable high-level attributes and malignancy prediction, while providing malignancy prediction scores approaching that of non-explainable 3D CNNs. To the best of our knowledge, this is the first study to investigate capsule networks for making predictions based on radiologist-level interpretable attributes and its applications to medical image diagnosis. Code is publicly available at https://github.com/lalonderodney/X-Caps .



### Using Synthetic Data and Deep Networks to Recognize Primitive Shapes for Object Grasping
- **Arxiv ID**: http://arxiv.org/abs/1909.08508v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.08508v1)
- **Published**: 2019-09-12 20:05:57+00:00
- **Updated**: 2019-09-12 20:05:57+00:00
- **Authors**: Yunzhi Lin, Chao Tang, Fu-Jen Chu, Patricio A. Vela
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: A segmentation-based architecture is proposed to decompose objects into multiple primitive shapes from monocular depth input for robotic manipulation. The backbone deep network is trained on synthetic data with 6 classes of primitive shapes generated by a simulation engine. Each primitive shape is designed with parametrized grasp families, permitting the pipeline to identify multiple grasp candidates per shape primitive region. The grasps are priority ordered via proposed ranking algorithm, with the first feasible one chosen for execution. On task-free grasping of individual objects, the method achieves a 94% success rate. On task-oriented grasping, it achieves a 76% success rate. Overall, the method supports the hypothesis that shape primitives can support task-free and task-relevant grasp prediction.



### SegNAS3D: Network Architecture Search with Derivative-Free Global Optimization for 3D Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.05962v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1909.05962v1)
- **Published**: 2019-09-12 21:51:28+00:00
- **Updated**: 2019-09-12 21:51:28+00:00
- **Authors**: Ken C. L. Wong, Mehdi Moradi
- **Comment**: This paper was accepted by the International Conference on Medical
  Image Computing and Computer-Assisted Intervention - MICCAI 2019
- **Journal**: None
- **Summary**: Deep learning has largely reduced the need for manual feature selection in image segmentation. Nevertheless, network architecture optimization and hyperparameter tuning are mostly manual and time consuming. Although there are increasing research efforts on network architecture search in computer vision, most works concentrate on image classification but not segmentation, and there are very limited efforts on medical image segmentation especially in 3D. To remedy this, here we propose a framework, SegNAS3D, for network architecture search of 3D image segmentation. In this framework, a network architecture comprises interconnected building blocks that consist of operations such as convolution and skip connection. By representing the block structure as a learnable directed acyclic graph, hyperparameters such as the number of feature channels and the option of using deep supervision can be learned together through derivative-free global optimization. Experiments on 43 3D brain magnetic resonance images with 19 structures achieved an average Dice coefficient of 82%. Each architecture search required less than three days on three GPUs and produced architectures that were much smaller than the state-of-the-art manually created architectures.



### Content-Aware Unsupervised Deep Homography Estimation
- **Arxiv ID**: http://arxiv.org/abs/1909.05983v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.05983v2)
- **Published**: 2019-09-12 22:55:21+00:00
- **Updated**: 2020-07-20 10:17:03+00:00
- **Authors**: Jirong Zhang, Chuan Wang, Shuaicheng Liu, Lanpeng Jia, Nianjin Ye, Jue Wang, Ji Zhou, Jian Sun
- **Comment**: Accepted by ECCV 2020 (Oral, Top 2%, 3 over 3 Strong Accepts). Jirong
  Zhang and Chuan Wang are joint first authors, and Shuaicheng Liu is the
  corresponding author
- **Journal**: None
- **Summary**: Homography estimation is a basic image alignment method in many applications. It is usually conducted by extracting and matching sparse feature points, which are error-prone in low-light and low-texture images. On the other hand, previous deep homography approaches use either synthetic images for supervised learning or aerial images for unsupervised learning, both ignoring the importance of handling depth disparities and moving objects in real world applications. To overcome these problems, in this work we propose an unsupervised deep homography method with a new architecture design. In the spirit of the RANSAC procedure in traditional methods, we specifically learn an outlier mask to only select reliable regions for homography estimation. We calculate loss with respect to our learned deep features instead of directly comparing image content as did previously. To achieve the unsupervised training, we also formulate a novel triplet loss customized for our network. We verify our method by conducting comprehensive comparisons on a new dataset that covers a wide range of scenes with varying degrees of difficulties for the task. Experimental results reveal that our method outperforms the state-of-the-art including deep solutions and feature-based solutions.



