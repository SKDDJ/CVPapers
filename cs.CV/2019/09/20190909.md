# Arxiv Papers in cs.CV on 2019-09-09
### LCSCNet: Linear Compressing Based Skip-Connecting Network for Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1909.03573v1
- **DOI**: 10.1109/TIP.2019.2940679
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03573v1)
- **Published**: 2019-09-09 00:36:45+00:00
- **Updated**: 2019-09-09 00:36:45+00:00
- **Authors**: Wenming Yang, Xuechen Zhang, Yapeng Tian, Wei Wang, Jing-Hao Xue, Qingmin Liao
- **Comment**: Accepted by IEEE Transactions on Image Processing (IEEE-TIP)
- **Journal**: None
- **Summary**: In this paper, we develop a concise but efficient network architecture called linear compressing based skip-connecting network (LCSCNet) for image super-resolution. Compared with two representative network architectures with skip connections, ResNet and DenseNet, a linear compressing layer is designed in LCSCNet for skip connection, which connects former feature maps and distinguishes them from newly-explored feature maps. In this way, the proposed LCSCNet enjoys the merits of the distinguish feature treatment of DenseNet and the parameter-economic form of ResNet. Moreover, to better exploit hierarchical information from both low and high levels of various receptive fields in deep models, inspired by gate units in LSTM, we also propose an adaptive element-wise fusion strategy with multi-supervised training. Experimental results in comparison with state-of-the-art algorithms validate the effectiveness of LCSCNet.



### Extreme Low Resolution Activity Recognition with Confident Spatial-Temporal Attention Transfer
- **Arxiv ID**: http://arxiv.org/abs/1909.03580v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03580v4)
- **Published**: 2019-09-09 01:02:11+00:00
- **Updated**: 2021-10-10 13:58:53+00:00
- **Authors**: Yucai Bai, Qin Zou, Xieyuanli Chen, Lingxi Li, Zhengming Ding, Long Chen
- **Comment**: 12 pages, 9 fugures. 2nd-round review of TIP
- **Journal**: None
- **Summary**: Activity recognition on extreme low-resolution videos, e.g., a resolution of 12*16 pixels, plays a vital role in far-view surveillance and privacy-preserving multimedia analysis. Low-resolution videos only contain limited information. Given the fact that one same activity may be represented by videos in both high resolution (HR) and extreme low resolution (eLR), it is worth studying to utilize the relevant HR data to improve the eLR activity recognition. In this work, we propose a novel Confident Spatial-Temporal Attention Transfer (CSTAT) for eLR activity recognition. CSTAT can acquire information from HR data by reducing the attention differences with a transfer-learning strategy. Besides, the credibility of the supervisory signal is also taken into consideration for a more confident transferring process. Experimental results on two well-known datasets, i.e., UCF101 and HMDB51, demonstrate that, the proposed method can effectively improve the accuracy of eLR activity recognition and achieve an accuracy of 59.23% on 12*16 videos in HMDB51, a state-of-the-art performance.



### Unified Underwater Structure-from-Motion
- **Arxiv ID**: http://arxiv.org/abs/1909.03583v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03583v1)
- **Published**: 2019-09-09 01:38:37+00:00
- **Updated**: 2019-09-09 01:38:37+00:00
- **Authors**: Kazuto Ichimaru, Yuichi Taguchi, Hiroshi Kawasaki
- **Comment**: Accepted in International Conference on 3D Vision (3DV 2019)
- **Journal**: None
- **Summary**: This paper shows that accurate underwater 3D shape reconstruction is possible using a single camera, observing a target through a refractive interface. We provide unified reconstruction techniques for a variety of scenarios such as single static camera and moving refractive interface, single moving camera and static refractive interface, and single moving camera and moving refractive interface. In our basic setup, we assume that the refractive interface is planar, and simultaneously estimate the unknown transformations of the planar interface and the camera, and the unknown target shape using bundle adjustment. We also extend it to relax the planarity assumption, which enables us to use waves of the refractive interface for the reconstruction task. Experiments with real data show the superiority of our method to existing methods.



### An Acceleration Framework for High Resolution Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1909.03611v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03611v1)
- **Published**: 2019-09-09 03:19:25+00:00
- **Updated**: 2019-09-09 03:19:25+00:00
- **Authors**: Jinlin Liu, Yuan Yao, Jianqiang Ren
- **Comment**: None
- **Journal**: None
- **Summary**: Synthesis of high resolution images using Generative Adversarial Networks (GANs) is challenging, which usually requires numbers of high-end graphic cards with large memory and long time of training. In this paper, we propose a two-stage framework to accelerate the training process of synthesizing high resolution images. High resolution images are first transformed to small codes via the trained encoder and decoder networks. The code in latent space is times smaller than the original high resolution images. Then, we train a code generation network to learn the distribution of the latent codes. In this way, the generator only learns to generate small latent codes instead of large images. Finally, we decode the generated latent codes to image space via the decoder networks so as to output the synthesized high resolution images. Experimental results show that the proposed method accelerates the training process significantly and increases the quality of the generated samples. The proposed acceleration framework makes it possible to generate high resolution images using less training time with limited hardware resource. After using the proposed acceleration method, it takes only 3 days to train a 1024 *1024 image generator on Celeba-HQ dataset using just one NVIDIA P100 graphic card.



### Weakly Supervised Localization Using Background Images
- **Arxiv ID**: http://arxiv.org/abs/1909.03619v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03619v3)
- **Published**: 2019-09-09 03:34:34+00:00
- **Updated**: 2019-09-11 00:33:11+00:00
- **Authors**: Ziyi Kou, Wentian Zhao, Guofeng Cui, Shaojie Wang
- **Comment**: Course project of CSC577, University of Rochester
- **Journal**: None
- **Summary**: Weakly Supervised Object Localization (WSOL) methodsusually rely on fully convolutional networks in order to ob-tain class activation maps(CAMs) of targeted labels. How-ever, these networks always highlight the most discriminativeparts to perform the task, the located areas are much smallerthan entire targeted objects. In this work, we propose a novelend-to-end model to enlarge CAMs generated from classifi-cation models, which can localize targeted objects more pre-cisely. In detail, we add an additional module in traditionalclassification networks to extract foreground object propos-als from images without classifying them into specific cate-gories. Then we set these normalized regions as unrestrictedpixel-level mask supervision for the following classificationtask. We collect a set of images defined as Background ImageSet from the Internet. The number of them is much smallerthan the targeted dataset but surprisingly well supports themethod to extract foreground regions from different pictures.The region extracted is independent from classification task,where the extracted region in each image covers almost en-tire object rather than just a significant part. Therefore, theseregions can serve as masks to supervise the response mapgenerated from classification models to become larger andmore precise. The method achieves state-of-the-art results onCUB-200-2011 in terms of Top-1 and Top-5 localization er-ror while has a competitive result on ILSVRC2016 comparedwith other approaches.



### Transfer Reward Learning for Policy Gradient-Based Text Generation
- **Arxiv ID**: http://arxiv.org/abs/1909.03622v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.03622v1)
- **Published**: 2019-09-09 03:36:42+00:00
- **Updated**: 2019-09-09 03:36:42+00:00
- **Authors**: James O' Neill, Danushka Bollegala
- **Comment**: None
- **Journal**: None
- **Summary**: Task-specific scores are often used to optimize for and evaluate the performance of conditional text generation systems. However, such scores are non-differentiable and cannot be used in the standard supervised learning paradigm. Hence, policy gradient methods are used since the gradient can be computed without requiring a differentiable objective.   However, we argue that current n-gram overlap based measures that are used as rewards can be improved by using model-based rewards transferred from tasks that directly compare the similarity of sentence pairs. These reward models either output a score of sentence-level syntactic and semantic similarity between entire predicted and target sentences as the expected return, or for intermediate phrases as segmented accumulative rewards.   We demonstrate that using a \textit{Transferable Reward Learner} leads to improved results on semantical evaluation measures in policy-gradient models for image captioning tasks. Our InferSent actor-critic model improves over a BLEU trained actor-critic model on MSCOCO when evaluated on a Word Mover's Distance similarity measure by 6.97 points, also improving on a Sliding Window Cosine Similarity measure by 10.48 points. Similar performance improvements are also obtained on the smaller Flickr-30k dataset, demonstrating the general applicability of the proposed transfer learning method.



### CBNet: A Novel Composite Backbone Network Architecture for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1909.03625v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03625v1)
- **Published**: 2019-09-09 04:01:01+00:00
- **Updated**: 2019-09-09 04:01:01+00:00
- **Authors**: Yudong Liu, Yongtao Wang, Siwei Wang, TingTing Liang, Qijie Zhao, Zhi Tang, Haibin Ling
- **Comment**: 7 pages,6 figures
- **Journal**: None
- **Summary**: In existing CNN based detectors, the backbone network is a very important component for basic feature extraction, and the performance of the detectors highly depends on it. In this paper, we aim to achieve better detection performance by building a more powerful backbone from existing backbones like ResNet and ResNeXt. Specifically, we propose a novel strategy for assembling multiple identical backbones by composite connections between the adjacent backbones, to form a more powerful backbone named Composite Backbone Network (CBNet). In this way, CBNet iteratively feeds the output features of the previous backbone, namely high-level features, as part of input features to the succeeding backbone, in a stage-by-stage fashion, and finally the feature maps of the last backbone (named Lead Backbone) are used for object detection. We show that CBNet can be very easily integrated into most state-of-the-art detectors and significantly improve their performances. For example, it boosts the mAP of FPN, Mask R-CNN and Cascade R-CNN on the COCO dataset by about 1.5 to 3.0 percent. Meanwhile, experimental results show that the instance segmentation results can also be improved. Specially, by simply integrating the proposed CBNet into the baseline detector Cascade Mask R-CNN, we achieve a new state-of-the-art result on COCO dataset (mAP of 53.3) with single model, which demonstrates great effectiveness of the proposed CBNet architecture. Code will be made available on https://github.com/PKUbahuangliuhe/CBNet.



### Theory of Optimal Bayesian Feature Filtering
- **Arxiv ID**: http://arxiv.org/abs/1909.03637v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, 62F15, 62C10, 62F07, 92C37
- **Links**: [PDF](http://arxiv.org/pdf/1909.03637v1)
- **Published**: 2019-09-09 05:41:10+00:00
- **Updated**: 2019-09-09 05:41:10+00:00
- **Authors**: Ali Foroughi pour, Lori A. Dalton
- **Comment**: 51 pages, 5 figures, 6 tables
- **Journal**: None
- **Summary**: Optimal Bayesian feature filtering (OBF) is a supervised screening method designed for biomarker discovery. In this article, we prove two major theoretical properties of OBF. First, optimal Bayesian feature selection under a general family of Bayesian models reduces to filtering if and only if the underlying Bayesian model assumes all features are mutually independent. Therefore, OBF is optimal if and only if one assumes all features are mutually independent, and OBF is the only filter method that is optimal under at least one model in the general Bayesian framework. Second, OBF under independent Gaussian models is consistent under very mild conditions, including cases where the data is non-Gaussian with correlated features. This result provides conditions where OBF is guaranteed to identify the correct feature set given enough data, and it justifies the use of OBF in non-design settings where its assumptions are invalid.



### A Comprehensive Benchmark for Single Image Compression Artifacts Reduction
- **Arxiv ID**: http://arxiv.org/abs/1909.03647v1
- **DOI**: 10.1109/TIP.2020.3007828
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03647v1)
- **Published**: 2019-09-09 06:26:24+00:00
- **Updated**: 2019-09-09 06:26:24+00:00
- **Authors**: Jiaying Liu, Dong Liu, Wenhan Yang, Sifeng Xia, Xiaoshuai Zhang, Yuanying Dai
- **Comment**: https://flyywh.github.io/LIU4K_Website/
- **Journal**: None
- **Summary**: We present a comprehensive study and evaluation of existing single image compression artifacts removal algorithms, using a new 4K resolution benchmark including diversified foreground objects and background scenes with rich structures, called Large-scale Ideal Ultra high definition 4K (LIU4K) benchmark. Compression artifacts removal, as a common post-processing technique, aims at alleviating undesirable artifacts such as blockiness, ringing, and banding caused by quantization and approximation in the compression process. In this work, a systematic listing of the reviewed methods is presented based on their basic models (handcrafted models and deep networks). The main contributions and novelties of these methods are highlighted, and the main development directions, including architectures, multi-domain sources, signal structures, and new targeted units, are summarized. Furthermore, based on a unified deep learning configuration (i.e. same training data, loss function, optimization algorithm, etc.), we evaluate recent deep learning-based methods based on diversified evaluation measures. The experimental results show the state-of-the-art performance comparison of existing methods based on both full-reference, non-reference and task-driven metrics. Our survey would give a comprehensive reference source for future research on single image compression artifacts removal and inspire new directions of the related fields.



### Saliency based Semi-supervised Learning for Orbiting Satellite Tracking
- **Arxiv ID**: http://arxiv.org/abs/1909.03656v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03656v1)
- **Published**: 2019-09-09 06:50:33+00:00
- **Updated**: 2019-09-09 06:50:33+00:00
- **Authors**: Peizhuo Li, Yunda Sun, Xue Wan
- **Comment**: The first two authors contributed equally to the paper. Corresponding
  Author: Xue Wan
- **Journal**: None
- **Summary**: The trajectory and boundary of an orbiting satellite are fundamental information for on-orbit repairing and manipulation by space robots. This task, however, is challenging owing to the freely and rapidly motion of on-orbiting satellites, the quickly varying background and the sudden change in illumination conditions. Traditional tracking usually relies on a single bounding box of the target object, however, more detailed information should be provided by visual tracking such as binary mask. In this paper, we proposed a SSLT (Saliency-based Semi-supervised Learning for Tracking) algorithm that provides both the bounding box and segmentation binary mask of target satellites at 12 frame per second without requirement of annotated data. Our method, SSLT, improves the segmentation performance by generating a saliency map based semi-supervised on-line learning approach within the initial bounding box estimated by tracking. Once a customized segmentation model has been trained, the bounding box and satellite trajectory will be refined using the binary segmentation result. Experiment using real on-orbit rendezvous and docking video from NASA (Nation Aeronautics and Space Administration), simulated satellite animation sequence from ESA (European Space Agency) and image sequences of 3D printed satellite model took in our laboratory demonstrate the robustness, versatility and fast speed of our method compared to state-of-the-art tracking and segmentation methods. Our dataset will be released for academic use in future.



### DensePoint: Learning Densely Contextual Representation for Efficient Point Cloud Processing
- **Arxiv ID**: http://arxiv.org/abs/1909.03669v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.03669v1)
- **Published**: 2019-09-09 07:18:30+00:00
- **Updated**: 2019-09-09 07:18:30+00:00
- **Authors**: Yongcheng Liu, Bin Fan, Gaofeng Meng, Jiwen Lu, Shiming Xiang, Chunhong Pan
- **Comment**: Accepted to ICCV 2019. 15 pages, 8 figures, 16 tables
- **Journal**: None
- **Summary**: Point cloud processing is very challenging, as the diverse shapes formed by irregular points are often indistinguishable. A thorough grasp of the elusive shape requires sufficiently contextual semantic information, yet few works devote to this. Here we propose DensePoint, a general architecture to learn densely contextual representation for point cloud processing. Technically, it extends regular grid CNN to irregular point configuration by generalizing a convolution operator, which holds the permutation invariance of points, and achieves efficient inductive learning of local patterns. Architecturally, it finds inspiration from dense connection mode, to repeatedly aggregate multi-level and multi-scale semantics in a deep hierarchy. As a result, densely contextual information along with rich semantics, can be acquired by DensePoint in an organic manner, making it highly effective. Extensive experiments on challenging benchmarks across four tasks, as well as thorough model analysis, verify DensePoint achieves the state of the arts.



### Learning Task-Specific Generalized Convolutions in the Permutohedral Lattice
- **Arxiv ID**: http://arxiv.org/abs/1909.03677v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03677v1)
- **Published**: 2019-09-09 07:36:02+00:00
- **Updated**: 2019-09-09 07:36:02+00:00
- **Authors**: Anne S. Wannenwetsch, Martin Kiefel, Peter V. Gehler, Stefan Roth
- **Comment**: To appear at GCPR 2019
- **Journal**: None
- **Summary**: Dense prediction tasks typically employ encoder-decoder architectures, but the prevalent convolutions in the decoder are not image-adaptive and can lead to boundary artifacts. Different generalized convolution operations have been introduced to counteract this. We go beyond these by leveraging guidance data to redefine their inherent notion of proximity. Our proposed network layer builds on the permutohedral lattice, which performs sparse convolutions in a high-dimensional space allowing for powerful non-local operations despite small filters. Multiple features with different characteristics span this permutohedral space. In contrast to prior work, we learn these features in a task-specific manner by generalizing the basic permutohedral operations to learnt feature representations. As the resulting objective is complex, a carefully designed framework and learning procedure are introduced, yielding rich feature embeddings in practice. We demonstrate the general applicability of our approach in different joint upsampling tasks. When adding our network layer to state-of-the-art networks for optical flow and semantic segmentation, boundary artifacts are removed and the accuracy is improved.



### Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases
- **Arxiv ID**: http://arxiv.org/abs/1909.03683v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.03683v1)
- **Published**: 2019-09-09 07:44:24+00:00
- **Updated**: 2019-09-09 07:44:24+00:00
- **Authors**: Christopher Clark, Mark Yatskar, Luke Zettlemoyer
- **Comment**: In EMNLP 2019
- **Journal**: None
- **Summary**: State-of-the-art models often make use of superficial patterns in the data that do not generalize well to out-of-domain or adversarial settings. For example, textual entailment models often learn that particular key words imply entailment, irrespective of context, and visual question answering models learn to predict prototypical answers, without considering evidence in the image. In this paper, we show that if we have prior knowledge of such biases, we can train a model to be more robust to domain shift. Our method has two stages: we (1) train a naive model that makes predictions exclusively based on dataset biases, and (2) train a robust model as part of an ensemble with the naive one in order to encourage it to focus on other patterns in the data that are more likely to generalize. Experiments on five datasets with out-of-domain test sets show significantly improved robustness in all settings, including a 12 point gain on a changing priors visual question answering dataset and a 9 point gain on an adversarial question answering test set.



### Latent Multi-view Semi-Supervised Classification
- **Arxiv ID**: http://arxiv.org/abs/1909.03712v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.03712v1)
- **Published**: 2019-09-09 09:18:39+00:00
- **Updated**: 2019-09-09 09:18:39+00:00
- **Authors**: Xiaofan Bo, Zhao Kang, Zhitong Zhao, Yuanzhang Su, Wenyu Chen
- **Comment**: ACML 2019
- **Journal**: None
- **Summary**: To explore underlying complementary information from multiple views, in this paper, we propose a novel Latent Multi-view Semi-Supervised Classification (LMSSC) method. Unlike most existing multi-view semi-supervised classification methods that learn the graph using original features, our method seeks an underlying latent representation and performs graph learning and label propagation based on the learned latent representation. With the complementarity of multiple views, the latent representation could depict the data more comprehensively than every single view individually, accordingly making the graph more accurate and robust as well. Finally, LMSSC integrates latent representation learning, graph construction, and label propagation into a unified framework, which makes each subtask optimized. Experimental results on real-world benchmark datasets validate the effectiveness of our proposed method.



### Self-supervised Scale Equivariant Network for Weakly Supervised Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.03714v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03714v1)
- **Published**: 2019-09-09 09:23:11+00:00
- **Updated**: 2019-09-09 09:23:11+00:00
- **Authors**: Yude Wang, Jie Zhang, Meina Kan, Shiguang Shan, Xilin Chen
- **Comment**: 8 pages, 6 figures
- **Journal**: None
- **Summary**: Weakly supervised semantic segmentation has attracted much research interest in recent years considering its advantage of low labeling cost. Most of the advanced algorithms follow the design principle that expands and constrains the seed regions from class activation maps (CAM). As well-known, conventional CAM tends to be incomplete or over-activated due to weak supervision. Fortunately, we find that semantic segmentation has a characteristic of spatial transformation equivariance, which can form a few self-supervisions to help weakly supervised learning. This work mainly explores the advantages of scale equivariant constrains for CAM generation, formulated as a self-supervised scale equivariant network (SSENet). Specifically, a novel scale equivariant regularization is elaborately designed to ensure consistency of CAMs from the same input image with different resolutions. This novel scale equivariant regularization can guide the whole network to learn more accurate class activation. This regularized CAM can be embedded in most recent advanced weakly supervised semantic segmentation framework. Extensive experiments on PASCAL VOC 2012 datasets demonstrate that our method achieves the state-of-the-art performance both quantitatively and qualitatively for weakly supervised semantic segmentation. Code has been made available.



### Deep Super-Resolution Network for Single Image Super-Resolution with Realistic Degradations
- **Arxiv ID**: http://arxiv.org/abs/1909.03748v1
- **DOI**: 10.1145/3349801.3349823
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03748v1)
- **Published**: 2019-09-09 10:40:06+00:00
- **Updated**: 2019-09-09 10:40:06+00:00
- **Authors**: Rao Muhammad Umer, Gian Luca Foresti, Christian Micheloni
- **Comment**: 7 pages
- **Journal**: 13th International Conference on Distributed Smart Cameras (ICDSC
  2019)
- **Summary**: Single Image Super-Resolution (SISR) aims to generate a high-resolution (HR) image of a given low-resolution (LR) image. The most of existing convolutional neural network (CNN) based SISR methods usually take an assumption that a LR image is only bicubicly down-sampled version of an HR image. However, the true degradation (i.e. the LR image is a bicubicly downsampled, blurred and noisy version of an HR image) of a LR image goes beyond the widely used bicubic assumption, which makes the SISR problem highly ill-posed nature of inverse problems. To address this issue, we propose a deep SISR network that works for blur kernels of different sizes, and different noise levels in an unified residual CNN-based denoiser network, which significantly improves a practical CNN-based super-resolver for real applications. Extensive experimental results on synthetic LR datasets and real images demonstrate that our proposed method not only can produce better results on more realistic degradation but also computational efficient to practical SISR applications.



### Learning Visual Dynamics Models of Rigid Objects using Relational Inductive Biases
- **Arxiv ID**: http://arxiv.org/abs/1909.03749v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.03749v3)
- **Published**: 2019-09-09 10:43:56+00:00
- **Updated**: 2019-10-23 17:32:04+00:00
- **Authors**: Fabio Ferreira, Lin Shao, Tamim Asfour, Jeannette Bohg
- **Comment**: short paper (4 pages, two figures), accepted to NeurIPS 2019 Graph
  Representation Learning workshop
- **Journal**: None
- **Summary**: Endowing robots with human-like physical reasoning abilities remains challenging. We argue that existing methods often disregard spatio-temporal relations and by using Graph Neural Networks (GNNs) that incorporate a relational inductive bias, we can shift the learning process towards exploiting relations. In this work, we learn action-conditional forward dynamics models of a simulated manipulation task from visual observations involving cluttered and irregularly shaped objects. We investigate two GNN approaches and empirically assess their capability to generalize to scenarios with novel and an increasing number of objects. The first, Graph Networks (GN) based approach, considers explicitly defined edge attributes and not only does it consistently underperform an auto-encoder baseline that we modified to predict future states, our results indicate how different edge attributes can significantly influence the predictions. Consequently, we develop the Auto-Predictor that does not rely on explicitly defined edge attributes. It outperforms the baseline and the GN-based models. Overall, our results show the sensitivity of GNN-based approaches to the task representation, the efficacy of relational inductive biases and advocate choosing lightweight approaches that implicitly reason about relations over ones that leave these decisions to human designers.



### Adaptive Unimodal Cost Volume Filtering for Deep Stereo Matching
- **Arxiv ID**: http://arxiv.org/abs/1909.03751v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03751v2)
- **Published**: 2019-09-09 10:45:20+00:00
- **Updated**: 2019-11-19 13:44:15+00:00
- **Authors**: Youmin Zhang, Yimin Chen, Xiao Bai, Suihanjin Yu, Kun Yu, Zhiwei Li, Kuiyuan Yang
- **Comment**: Accepted by AAAI 2020
- **Journal**: None
- **Summary**: State-of-the-art deep learning based stereo matching approaches treat disparity estimation as a regression problem, where loss function is directly defined on true disparities and their estimated ones. However, disparity is just a byproduct of a matching process modeled by cost volume, while indirectly learning cost volume driven by disparity regression is prone to overfitting since the cost volume is under constrained. In this paper, we propose to directly add constraints to the cost volume by filtering cost volume with unimodal distribution peaked at true disparities. In addition, variances of the unimodal distributions for each pixel are estimated to explicitly model matching uncertainty under different contexts. The proposed architecture achieves state-of-the-art performance on Scene Flow and two KITTI stereo benchmarks. In particular, our method ranked the $1^{st}$ place of KITTI 2012 evaluation and the $4^{th}$ place of KITTI 2015 evaluation (recorded on 2019.8.20). The codes of AcfNet are available at: https://github.com/DeepMotionAIResearch/DenseMatchingBenchmark.



### Masking by Moving: Learning Distraction-Free Radar Odometry from Pose Information
- **Arxiv ID**: http://arxiv.org/abs/1909.03752v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.03752v4)
- **Published**: 2019-09-09 10:46:15+00:00
- **Updated**: 2020-01-17 16:14:26+00:00
- **Authors**: Dan Barnes, Rob Weston, Ingmar Posner
- **Comment**: Conference on Robot Learning (CoRL), 2019. Video summary:
  https://youtu.be/eG4Q-j3_6dk
- **Journal**: None
- **Summary**: This paper presents an end-to-end radar odometry system which delivers robust, real-time pose estimates based on a learned embedding space free of sensing artefacts and distractor objects. The system deploys a fully differentiable, correlation-based radar matching approach. This provides the same level of interpretability as established scan-matching methods and allows for a principled derivation of uncertainty estimates. The system is trained in a (self-)supervised way using only previously obtained pose information as a training signal. Using 280km of urban driving data, we demonstrate that our approach outperforms the previous state-of-the-art in radar odometry by reducing errors by up 68% whilst running an order of magnitude faster.



### OCR4all -- An Open-Source Tool Providing a (Semi-)Automatic OCR Workflow for Historical Printings
- **Arxiv ID**: http://arxiv.org/abs/1909.04032v1
- **DOI**: 10.3390/app9224853
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.04032v1)
- **Published**: 2019-09-09 11:15:40+00:00
- **Updated**: 2019-09-09 11:15:40+00:00
- **Authors**: Christian Reul, Dennis Christ, Alexander Hartelt, Nico Balbach, Maximilian Wehner, Uwe Springmann, Christoph Wick, Christine Grundig, Andreas Büttner, Frank Puppe
- **Comment**: submitted to MDPI - Applied Sciences
- **Journal**: https://www.mdpi.com/2076-3417/9/22/4853/htm
- **Summary**: Optical Character Recognition (OCR) on historical printings is a challenging task mainly due to the complexity of the layout and the highly variant typography. Nevertheless, in the last few years great progress has been made in the area of historical OCR, resulting in several powerful open-source tools for preprocessing, layout recognition and segmentation, character recognition and post-processing. The drawback of these tools often is their limited applicability by non-technical users like humanist scholars and in particular the combined use of several tools in a workflow. In this paper we present an open-source OCR software called OCR4all, which combines state-of-the-art OCR components and continuous model training into a comprehensive workflow. A comfortable GUI allows error corrections not only in the final output, but already in early stages to minimize error propagations. Further on, extensive configuration capabilities are provided to set the degree of automation of the workflow and to make adaptations to the carefully selected default parameters for specific printings, if necessary. Experiments showed that users with minimal or no experience were able to capture the text of even the earliest printed books with manageable effort and great quality, achieving excellent character error rates (CERs) below 0.5%. The fully automated application on 19th century novels showed that OCR4all can considerably outperform the commercial state-of-the-art tool ABBYY Finereader on moderate layouts if suitably pretrained mixed OCR models are available. The architecture of OCR4all allows the easy integration (or substitution) of newly developed tools for its main components by standardized interfaces like PageXML, thus aiming at continual higher automation for historical printings.



### Balancing Reconstruction Quality and Regularisation in ELBO for VAEs
- **Arxiv ID**: http://arxiv.org/abs/1909.03765v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.03765v1)
- **Published**: 2019-09-09 11:18:52+00:00
- **Updated**: 2019-09-09 11:18:52+00:00
- **Authors**: Shuyu Lin, Stephen Roberts, Niki Trigoni, Ronald Clark
- **Comment**: 8 pages for main contents and 15 pages for supplemental materials
  that include data pre-processing, model architectures and more results
- **Journal**: None
- **Summary**: A trade-off exists between reconstruction quality and the prior regularisation in the Evidence Lower Bound (ELBO) loss that Variational Autoencoder (VAE) models use for learning. There are few satisfactory approaches to deal with a balance between the prior and reconstruction objective, with most methods dealing with this problem through heuristics. In this paper, we show that the noise variance (often set as a fixed value) in the Gaussian likelihood p(x|z) for real-valued data can naturally act to provide such a balance. By learning this noise variance so as to maximise the ELBO loss, we automatically obtain an optimal trade-off between the reconstruction error and the prior constraint on the posteriors. This variance can be interpreted intuitively as the necessary noise level for the current model to be the best explanation of the observed dataset. Further, by allowing the variance inference to be more flexible it can conveniently be used as an uncertainty estimator for reconstructed or generated samples. We demonstrate that optimising the noise variance is a crucial component of VAE learning, and showcase the performance on MNIST, Fashion MNIST and CelebA datasets. We find our approach can significantly improve the quality of generated samples whilst maintaining a smooth latent-space manifold to represent the data. The method also offers an indication of uncertainty in the final generative model.



### Picture What you Read
- **Arxiv ID**: http://arxiv.org/abs/1909.05663v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1909.05663v1)
- **Published**: 2019-09-09 11:26:35+00:00
- **Updated**: 2019-09-09 11:26:35+00:00
- **Authors**: Ignazio Gallo, Shah Nawaz, Alessandro Calefati, Riccardo La Grassa, Nicola Landro
- **Comment**: 7 pages, Dicta2019 conference
- **Journal**: None
- **Summary**: Visualization refers to our ability to create an image in our head based on the text we read or the words we hear. It is one of the many skills that makes reading comprehension possible. Convolutional Neural Networks (CNN) are an excellent tool for recognizing and classifying text documents. In addition, it can generate images conditioned on natural language. In this work, we utilize CNNs capabilities to generate realistic images representative of the text illustrating the semantic concept. We conducted various experiments to highlight the capacity of the proposed model to generate representative images of the text descriptions used as input to the proposed model.



### HoughNet: neural network architecture for vanishing points detection
- **Arxiv ID**: http://arxiv.org/abs/1909.03812v2
- **DOI**: 10.1109/ICDAR.2019.00140
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1909.03812v2)
- **Published**: 2019-09-09 12:45:19+00:00
- **Updated**: 2019-10-06 07:41:38+00:00
- **Authors**: Alexander Sheshkus, Anastasia Ingacheva, Vladimir Arlazarov, Dmitry Nikolaev
- **Comment**: 6 pages, 6 figures, 2 tables, 28 references, conference
- **Journal**: 15th International Conference on Document Analysis and Recognition
  (ICDAR 2019)
- **Summary**: In this paper we introduce a novel neural network architecture based on Fast Hough Transform layer. The layer of this type allows our neural network to accumulate features from linear areas across the entire image instead of local areas. We demonstrate its potential by solving the problem of vanishing points detection in the images of documents. Such problem occurs when dealing with camera shots of the documents in uncontrolled conditions. In this case, the document image can suffer several specific distortions including projective transform. To train our model, we use MIDV-500 dataset and provide testing results. The strong generalization ability of the suggested method is proven with its applying to a completely different ICDAR 2011 dewarping contest. In previously published papers considering these dataset authors measured the quality of vanishing point detection by counting correctly recognized words with open OCR engine Tesseract. To compare with them, we reproduce this experiment and show that our method outperforms the state-of-the-art result.



### Crowd Counting on Images with Scale Variation and Isolated Clusters
- **Arxiv ID**: http://arxiv.org/abs/1909.03839v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03839v1)
- **Published**: 2019-09-09 13:17:26+00:00
- **Updated**: 2019-09-09 13:17:26+00:00
- **Authors**: Haoyue Bai, Song Wen, S. -H. Gary Chan
- **Comment**: Accepted at International Conference on Computer Vision (ICCV) 2019
  Workshop
- **Journal**: None
- **Summary**: Crowd counting is to estimate the number of objects (e.g., people or vehicles) in an image of unconstrained congested scenes. Designing a general crowd counting algorithm applicable to a wide range of crowd images is challenging, mainly due to the possibly large variation in object scales and the presence of many isolated small clusters. Previous approaches based on convolution operations with multi-branch architecture are effective for only some narrow bands of scales and have not captured the long-range contextual relationship due to isolated clustering. To address that, we propose SACANet, a novel scale-adaptive long-range context-aware network for crowd counting. SACANet consists of three major modules: the pyramid contextual module which extracts long-range contextual information and enlarges the receptive field, a scale-adaptive self-attention multi-branch module to attain high scale sensitivity and detection accuracy of isolated clusters, and a hierarchical fusion module to fuse multi-level self-attention features. With group normalization, SACANet achieves better optimality in the training process. We have conducted extensive experiments using the VisDrone2019 People dataset, the VisDrone2019 Vehicle dataset, and some other challenging benchmarks. As compared with the state-of-the-art methods, SACANet is shown to be effective, especially for extremely crowded conditions with diverse scales and scattered clusters, and achieves much lower MAE as compared with baselines.



### Robust Multi-Modality Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1909.03850v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03850v1)
- **Published**: 2019-09-09 13:37:09+00:00
- **Updated**: 2019-09-09 13:37:09+00:00
- **Authors**: Wenwei Zhang, Hui Zhou, Shuyang Sun, Zhe Wang, Jianping Shi, Chen Change Loy
- **Comment**: To appear in ICCV 2019. Code and models are available at
  https://github.com/ZwwWayne/mmMOT
- **Journal**: None
- **Summary**: Multi-sensor perception is crucial to ensure the reliability and accuracy in autonomous driving system, while multi-object tracking (MOT) improves that by tracing sequential movement of dynamic objects. Most current approaches for multi-sensor multi-object tracking are either lack of reliability by tightly relying on a single input source (e.g., center camera), or not accurate enough by fusing the results from multiple sensors in post processing without fully exploiting the inherent information. In this study, we design a generic sensor-agnostic multi-modality MOT framework (mmMOT), where each modality (i.e., sensors) is capable of performing its role independently to preserve reliability, and further improving its accuracy through a novel multi-modality fusion module. Our mmMOT can be trained in an end-to-end manner, enables joint optimization for the base feature extractor of each modality and an adjacency estimator for cross modality. Our mmMOT also makes the first attempt to encode deep representation of point cloud in data association process in MOT. We conduct extensive experiments to evaluate the effectiveness of the proposed framework on the challenging KITTI benchmark and report state-of-the-art performance. Code and models are available at https://github.com/ZwwWayne/mmMOT.



### On the Evaluation and Real-World Usage Scenarios of Deep Vessel Segmentation for Retinography
- **Arxiv ID**: http://arxiv.org/abs/1909.03856v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03856v3)
- **Published**: 2019-09-09 13:43:34+00:00
- **Updated**: 2020-03-17 06:42:40+00:00
- **Authors**: Tim Laibacher, André Anjos
- **Comment**: None
- **Journal**: None
- **Summary**: We identify and address three research gaps in the field of vessel segmentation for funduscopy. The first focuses on the task of inference on high-resolution fundus images for which only a limited set of ground-truth data is publicly available. Notably, we highlight that simple rescaling and padding or cropping of lower resolution datasets is surprisingly effective. Additionally we explore the effectiveness of semi-supervised learning for better domain adaptation. Our results show competitive performance on a set of common public retinal vessel datasets using a small and light-weight neural network. For HRF, the only very high-resolution dataset currently available, we reach new state-of-the-art performance by solely relying on training images from lower-resolution datasets. The second topic concerns evaluation metrics. We investigate the variability of the F1-score on the existing datasets and report results for recent SOTA architectures. Our evaluation show that most SOTA results are actually comparable to each other in performance. Last, we address the issue of reproducibility by open-sourcing our complete pipeline.



### Gaussian Temporal Awareness Networks for Action Localization
- **Arxiv ID**: http://arxiv.org/abs/1909.03877v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03877v1)
- **Published**: 2019-09-09 14:13:48+00:00
- **Updated**: 2019-09-09 14:13:48+00:00
- **Authors**: Fuchen Long, Ting Yao, Zhaofan Qiu, Xinmei Tian, Jiebo Luo, Tao Mei
- **Comment**: CVPR 2019 Oral
- **Journal**: None
- **Summary**: Temporally localizing actions in a video is a fundamental challenge in video understanding. Most existing approaches have often drawn inspiration from image object detection and extended the advances, e.g., SSD and Faster R-CNN, to produce temporal locations of an action in a 1D sequence. Nevertheless, the results can suffer from robustness problem due to the design of predetermined temporal scales, which overlooks the temporal structure of an action and limits the utility on detecting actions with complex variations. In this paper, we propose to address the problem by introducing Gaussian kernels to dynamically optimize temporal scale of each action proposal. Specifically, we present Gaussian Temporal Awareness Networks (GTAN) --- a new architecture that novelly integrates the exploitation of temporal structure into an one-stage action localization framework. Technically, GTAN models the temporal structure through learning a set of Gaussian kernels, each for a cell in the feature maps. Each Gaussian kernel corresponds to a particular interval of an action proposal and a mixture of Gaussian kernels could further characterize action proposals with various length. Moreover, the values in each Gaussian curve reflect the contextual contributions to the localization of an action proposal. Extensive experiments are conducted on both THUMOS14 and ActivityNet v1.3 datasets, and superior results are reported when comparing to state-of-the-art approaches. More remarkably, GTAN achieves 1.9% and 1.1% improvements in mAP on testing set of the two datasets.



### TDAPNet: Prototype Network with Recurrent Top-Down Attention for Robust Object Classification under Partial Occlusion
- **Arxiv ID**: http://arxiv.org/abs/1909.03879v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.03879v2)
- **Published**: 2019-09-09 14:17:59+00:00
- **Updated**: 2019-11-14 06:57:01+00:00
- **Authors**: Mingqing Xiao, Adam Kortylewski, Ruihai Wu, Siyuan Qiao, Wei Shen, Alan Yuille
- **Comment**: None
- **Journal**: None
- **Summary**: Despite deep convolutional neural networks' great success in object classification, it suffers from severe generalization performance drop under occlusion due to the inconsistency between training and testing data. Because of the large variance of occluders, our goal is a model trained on occlusion-free data while generalizable to occlusion conditions. In this work, we integrate prototypes, partial matching and top-down attention regulation into deep neural networks to realize robust object classification under occlusion. We first introduce prototype learning as its regularization encourages compact data clusters, which enables better generalization ability under inconsistent conditions. Then, attention map at intermediate layer based on feature dictionary and activation scale is estimated for partial matching, which sifts irrelevant information out when comparing features with prototypes. Further, inspired by neuroscience research that reveals the important role of feedback connection for object recognition under occlusion, a top-down feedback attention regulation is introduced into convolution layers, purposefully reducing the contamination by occlusion during feature extraction stage. Our experiment results on partially occluded MNIST and vehicles from the PASCAL3D+ dataset demonstrate that the proposed network significantly improves the robustness of current deep neural networks under occlusion. Our code will be released.



### Deep Metric Learning with Density Adaptivity
- **Arxiv ID**: http://arxiv.org/abs/1909.03909v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1909.03909v1)
- **Published**: 2019-09-09 15:04:26+00:00
- **Updated**: 2019-09-09 15:04:26+00:00
- **Authors**: Yehao Li, Ting Yao, Yingwei Pan, Hongyang Chao, Tao Mei
- **Comment**: Accepted by IEEE Transactions on Multimedia
- **Journal**: None
- **Summary**: The problem of distance metric learning is mostly considered from the perspective of learning an embedding space, where the distances between pairs of examples are in correspondence with a similarity metric. With the rise and success of Convolutional Neural Networks (CNN), deep metric learning (DML) involves training a network to learn a nonlinear transformation to the embedding space. Existing DML approaches often express the supervision through maximizing inter-class distance and minimizing intra-class variation. However, the results can suffer from overfitting problem, especially when the training examples of each class are embedded together tightly and the density of each class is very high. In this paper, we integrate density, i.e., the measure of data concentration in the representation, into the optimization of DML frameworks to adaptively balance inter-class similarity and intra-class variation by training the architecture in an end-to-end manner. Technically, the knowledge of density is employed as a regularizer, which is pluggable to any DML architecture with different objective functions such as contrastive loss, N-pair loss and triplet loss. Extensive experiments on three public datasets consistently demonstrate clear improvements by amending three types of embedding with the density adaptivity. More remarkably, our proposal increases Recall@1 from 67.95% to 77.62%, from 52.01% to 55.64% and from 68.20% to 70.56% on Cars196, CUB-200-2011 and Stanford Online Products dataset, respectively.



### SE-SLAM: Semi-Dense Structured Edge-Based Monocular SLAM
- **Arxiv ID**: http://arxiv.org/abs/1909.03917v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03917v1)
- **Published**: 2019-09-09 15:18:14+00:00
- **Updated**: 2019-09-09 15:18:14+00:00
- **Authors**: Juan Jose Tarrio, Claus Smitt, Sol Pedre
- **Comment**: 13 pages
- **Journal**: None
- **Summary**: Vision-based Simultaneous Localization And Mapping (VSLAM) is a mature problem in Robotics. Most VSLAM systems are feature based methods, which are robust and present high accuracy, but yield sparse maps with limited application for further navigation tasks. Most recently, direct methods which operate directly on image intensity have been introduced, capable of reconstructing richer maps at the cost of higher processing power. In this work, an edge-based monocular SLAM system (SE-SLAM) is proposed as a middle point: edges present good localization as point features, while enabling a structural semidense map reconstruction. However, edges are not easy to associate, track and optimize over time, as they lack descriptors and biunivocal correspondence, unlike point features. To tackle these issues, this paper presents a method to match edges between frames in a consistent manner; a feasible strategy to solve the optimization problem, since its size rapidly increases when working with edges; and the use of non-linear optimization techniques. The resulting system achieves comparable precision to state of the art feature-based and dense/semi-dense systems, while inherently building a structural semi-dense reconstruction of the environment, providing relevant structure data for further navigation algorithms. To achieve such accuracy, state of the art non-linear optimization is needed, over a continuous feed of 10000 edgepoints per frame, to optimize the full semi-dense output. Despite its heavy processing requirements, the system achieves near to real-time operation, thanks to a custom built solver and parallelization of its key stages. In order to encourage further development of edge-based SLAM systems, SE-SLAM source code will be released as open source.



### Hierarchy Parsing for Image Captioning
- **Arxiv ID**: http://arxiv.org/abs/1909.03918v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1909.03918v2)
- **Published**: 2019-09-09 15:18:21+00:00
- **Updated**: 2019-09-10 13:39:52+00:00
- **Authors**: Ting Yao, Yingwei Pan, Yehao Li, Tao Mei
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: It is always well believed that parsing an image into constituent visual patterns would be helpful for understanding and representing an image. Nevertheless, there has not been evidence in support of the idea on describing an image with a natural-language utterance. In this paper, we introduce a new design to model a hierarchy from instance level (segmentation), region level (detection) to the whole image to delve into a thorough image understanding for captioning. Specifically, we present a HIerarchy Parsing (HIP) architecture that novelly integrates hierarchical structure into image encoder. Technically, an image decomposes into a set of regions and some of the regions are resolved into finer ones. Each region then regresses to an instance, i.e., foreground of the region. Such process naturally builds a hierarchal tree. A tree-structured Long Short-Term Memory (Tree-LSTM) network is then employed to interpret the hierarchal structure and enhance all the instance-level, region-level and image-level features. Our HIP is appealing in view that it is pluggable to any neural captioning models. Extensive experiments on COCO image captioning dataset demonstrate the superiority of HIP. More remarkably, HIP plus a top-down attention-based LSTM decoder increases CIDEr-D performance from 120.1% to 127.2% on COCO Karpathy test split. When further endowing instance-level and region-level features from HIP with semantic relation learnt through Graph Convolutional Networks (GCN), CIDEr-D is boosted up to 130.6%.



### GAN-Leaks: A Taxonomy of Membership Inference Attacks against Generative Models
- **Arxiv ID**: http://arxiv.org/abs/1909.03935v3
- **DOI**: 10.1145/3372297.3417238
- **Categories**: **cs.LG**, cs.CR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.03935v3)
- **Published**: 2019-09-09 15:34:07+00:00
- **Updated**: 2020-11-23 18:11:05+00:00
- **Authors**: Dingfan Chen, Ning Yu, Yang Zhang, Mario Fritz
- **Comment**: CCS 2020, 20 pages
- **Journal**: Proceedings of the 2020 ACM SIGSAC Conference on Computer and
  Communications Security (CCS)
- **Summary**: Deep learning has achieved overwhelming success, spanning from discriminative models to generative models. In particular, deep generative models have facilitated a new level of performance in a myriad of areas, ranging from media manipulation to sanitized dataset generation. Despite the great success, the potential risks of privacy breach caused by generative models have not been analyzed systematically. In this paper, we focus on membership inference attack against deep generative models that reveals information about the training data used for victim models. Specifically, we present the first taxonomy of membership inference attacks, encompassing not only existing attacks but also our novel ones. In addition, we propose the first generic attack model that can be instantiated in a large range of settings and is applicable to various kinds of deep generative models. Moreover, we provide a theoretically grounded attack calibration technique, which consistently boosts the attack performance in all cases, across different attack settings, data modalities, and training configurations. We complement the systematic analysis of attack performance by a comprehensive experimental study, that investigates the effectiveness of various attacks w.r.t. model type and training configurations, over three diverse application scenarios (i.e., images, medical data, and location data).



### Unsupervised Domain Adaptation for Depth Prediction from Images
- **Arxiv ID**: http://arxiv.org/abs/1909.03943v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.03943v1)
- **Published**: 2019-09-09 15:43:26+00:00
- **Updated**: 2019-09-09 15:43:26+00:00
- **Authors**: Alessio Tonioni, Matteo Poggi, Stefano Mattoccia, Luigi Di Stefano
- **Comment**: 14 pages, 7 pages. Accepted to TPAMI
- **Journal**: None
- **Summary**: State-of-the-art approaches to infer dense depth measurements from images rely on CNNs trained end-to-end on a vast amount of data. However, these approaches suffer a drastic drop in accuracy when dealing with environments much different in appearance and/or context from those observed at training time. This domain shift issue is usually addressed by fine-tuning on smaller sets of images from the target domain annotated with depth labels. Unfortunately, relying on such supervised labeling is seldom feasible in most practical settings. Therefore, we propose an unsupervised domain adaptation technique which does not require groundtruth labels. Our method relies only on image pairs and leverages on classical stereo algorithms to produce disparity measurements alongside with confidence estimators to assess upon their reliability. We propose to fine-tune both depth-from-stereo as well as depth-from-mono architectures by a novel confidence-guided loss function that handles the measured disparities as noisy labels weighted according to the estimated confidence. Extensive experimental results based on standard datasets and evaluation protocols prove that our technique can address effectively the domain shift issue with both stereo and monocular depth prediction architectures and outperforms other state-of-the-art unsupervised loss functions that may be alternatively deployed to pursue domain adaptation.



### Deep Learning-based Radiomic Features for Improving Neoadjuvant Chemoradiation Response Prediction in Locally Advanced Rectal Cancer
- **Arxiv ID**: http://arxiv.org/abs/1909.04012v1
- **DOI**: 10.1088/1361-6560/ab7970
- **Categories**: **physics.med-ph**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.04012v1)
- **Published**: 2019-09-09 17:48:27+00:00
- **Updated**: 2019-09-09 17:48:27+00:00
- **Authors**: Jie Fu, Xinran Zhong, Ning Li, Ritchell Van Dams, John Lewis, Kyunghyun Sung, Ann C. Raldow, Jing Jin, X. Sharon Qi
- **Comment**: Review in progress
- **Journal**: 2020 Phys. Med. Biol
- **Summary**: Radiomic features achieve promising results in cancer diagnosis, treatment response prediction, and survival prediction. Our goal is to compare the handcrafted (explicitly designed) and deep learning (DL)-based radiomic features extracted from pre-treatment diffusion-weighted magnetic resonance images (DWIs) for predicting neoadjuvant chemoradiation treatment (nCRT) response in patients with locally advanced rectal cancer (LARC). 43 patients receiving nCRT were included. All patients underwent DWIs before nCRT and total mesorectal excision surgery 6-12 weeks after completion of nCRT. Gross tumor volume (GTV) contours were drawn by an experienced radiation oncologist on DWIs. The patient-cohort was split into the responder group (n=22) and the non-responder group (n=21) based on the post-nCRT response assessed by postoperative pathology, MRI or colonoscopy. Handcrafted and DL-based features were extracted from the apparent diffusion coefficient (ADC) map of the DWI using conventional computer-aided diagnosis methods and a pre-trained convolution neural network, respectively. Least absolute shrinkage and selection operator (LASSO)-logistic regression models were constructed using extracted features for predicting treatment response. The model performance was evaluated with repeated 20 times stratified 4-fold cross-validation using receiver operating characteristic (ROC) curves and compared using the corrected resampled t-test. The model built with handcrafted features achieved the mean area under the ROC curve (AUC) of 0.64, while the one built with DL-based features yielded the mean AUC of 0.73. The corrected resampled t-test on AUC showed P-value < 0.05. DL-based features extracted from pre-treatment DWIs achieved significantly better classification performance compared with handcrafted features for predicting nCRT response in patients with LARC.



### Understanding the Effects of Pre-Training for Object Detectors via Eigenspectrum
- **Arxiv ID**: http://arxiv.org/abs/1909.04021v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.04021v1)
- **Published**: 2019-09-09 17:59:11+00:00
- **Updated**: 2019-09-09 17:59:11+00:00
- **Authors**: Yosuke Shinya, Edgar Simo-Serra, Taiji Suzuki
- **Comment**: ICCV 2019 Workshop on Neural Architects (Oral)
- **Journal**: None
- **Summary**: ImageNet pre-training has been regarded as essential for training accurate object detectors for a long time. Recently, it has been shown that object detectors trained from randomly initialized weights can be on par with those fine-tuned from ImageNet pre-trained models. However, the effects of pre-training and the differences caused by pre-training are still not fully understood. In this paper, we analyze the eigenspectrum dynamics of the covariance matrix of each feature map in object detectors. Based on our analysis on ResNet-50, Faster R-CNN with FPN, and Mask R-CNN, we show that object detectors trained from ImageNet pre-trained models and those trained from scratch behave differently from each other even if both object detectors have similar accuracy. Furthermore, we propose a method for automatically determining the widths (the numbers of channels) of object detectors based on the eigenspectrum. We train Faster R-CNN with FPN from randomly initialized weights, and show that our method can reduce ~27% of the parameters of ResNet-50 without increasing Multiply-Accumulate operations and losing accuracy. Our results indicate that we should develop more appropriate methods for transferring knowledge from image classification to object detection (or other tasks).



### Privacy-Net: An Adversarial Approach for Identity-Obfuscated Segmentation of Medical Images
- **Arxiv ID**: http://arxiv.org/abs/1909.04087v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.04087v3)
- **Published**: 2019-09-09 18:17:10+00:00
- **Updated**: 2020-11-13 19:00:09+00:00
- **Authors**: Bach Ngoc Kim, Jose Dolz, Pierre-Marc Jodoin, Christian Desrosiers
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a client/server privacy-preserving network in the context of multicentric medical image analysis. Our approach is based on adversarial learning which encodes images to obfuscate the patient identity while preserving enough information for a target task. Our novel architecture is composed of three components: 1) an encoder network which removes identity-specific features from input medical images, 2) a discriminator network that attempts to identify the subject from the encoded images, 3) a medical image analysis network which analyzes the content of the encoded images (segmentation in our case). By simultaneously fooling the discriminator and optimizing the medical analysis network, the encoder learns to remove privacy-specific features while keeping those essentials for the target task. Our approach is illustrated on the problem of segmenting brain MRI from the large-scale Parkinson Progression Marker Initiative (PPMI) dataset. Using longitudinal data from PPMI, we show that the discriminator learns to heavily distort input images while allowing for highly accurate segmentation results.



### Neural Naturalist: Generating Fine-Grained Image Comparisons
- **Arxiv ID**: http://arxiv.org/abs/1909.04101v3
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1909.04101v3)
- **Published**: 2019-09-09 18:54:40+00:00
- **Updated**: 2019-11-14 01:19:36+00:00
- **Authors**: Maxwell Forbes, Christine Kaeser-Chen, Piyush Sharma, Serge Belongie
- **Comment**: Published at EMNLP 2019
- **Journal**: None
- **Summary**: We introduce the new Birds-to-Words dataset of 41k sentences describing fine-grained differences between photographs of birds. The language collected is highly detailed, while remaining understandable to the everyday observer (e.g., "heart-shaped face," "squat body"). Paragraph-length descriptions naturally adapt to varying levels of taxonomic and visual distance---drawn from a novel stratified sampling approach---with the appropriate level of detail. We propose a new model called Neural Naturalist that uses a joint image encoding and comparative module to generate comparative language, and evaluate the results with humans who must use the descriptions to distinguish real images.   Our results indicate promising potential for neural models to explain differences in visual embedding space using natural language, as well as a concrete path for machine learning to aid citizen scientists in their effort to preserve biodiversity.



### Towards Learning a Self-inverse Network for Bidirectional Image-to-image Translation
- **Arxiv ID**: http://arxiv.org/abs/1909.04104v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1909.04104v2)
- **Published**: 2019-09-09 18:56:30+00:00
- **Updated**: 2019-09-16 20:46:02+00:00
- **Authors**: Zengming Shen, Yifan Chen, S. Kevin Zhou, Bogdan Georgescu, Xuqi Liu, Thomas S. Huang
- **Comment**: 10 pages, 9 figures
- **Journal**: None
- **Summary**: The one-to-one mapping is necessary for many bidirectional image-to-image translation applications, such as MRI image synthesis as MRI images are unique to the patient. State-of-the-art approaches for image synthesis from domain X to domain Y learn a convolutional neural network that meticulously maps between the domains. A different network is typically implemented to map along the opposite direction, from Y to X. In this paper, we explore the possibility of only wielding one network for bi-directional image synthesis. In other words, such an autonomous learning network implements a self-inverse function. A self-inverse network shares several distinct advantages: only one network instead of two, better generalization and more restricted parameter space. Most importantly, a self-inverse function guarantees a one-to-one mapping, a property that cannot be guaranteed by earlier approaches that are not self-inverse. The experiments on three datasets show that, compared with the baseline approaches that use two separate models for the image synthesis along two directions, our self-inverse network achieves better synthesis results in terms of standard metrics. Finally, our sensitivity analysis confirms the feasibility of learning a self-inverse function for the bidirectional image translation.



### Adversarial Policy Gradient for Deep Learning Image Augmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.04108v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.04108v1)
- **Published**: 2019-09-09 19:04:21+00:00
- **Updated**: 2019-09-09 19:04:21+00:00
- **Authors**: Kaiyang Cheng, Claudia Iriondo, Francesco Calivá, Justin Krogue, Sharmila Majumdar, Valentina Pedoia
- **Comment**: 9 pages, 2 figures, MICCAI 2019, First two authors contributed
  equally
- **Journal**: None
- **Summary**: The use of semantic segmentation for masking and cropping input images has proven to be a significant aid in medical imaging classification tasks by decreasing the noise and variance of the training dataset. However, implementing this approach with classical methods is challenging: the cost of obtaining a dense segmentation is high, and the precise input area that is most crucial to the classification task is difficult to determine a-priori. We propose a novel joint-training deep reinforcement learning framework for image augmentation. A segmentation network, weakly supervised with policy gradient optimization, acts as an agent, and outputs masks as actions given samples as states, with the goal of maximizing reward signals from the classification network. In this way, the segmentation network learns to mask unimportant imaging features. Our method, Adversarial Policy Gradient Augmentation (APGA), shows promising results on Stanford's MURA dataset and on a hip fracture classification task with an increase in global accuracy of up to 7.33% and improved performance over baseline methods in 9/10 tasks evaluated. We discuss the broad applicability of our joint training strategy to a variety of medical imaging tasks.



### One-to-one Mapping for Unpaired Image-to-image Translation
- **Arxiv ID**: http://arxiv.org/abs/1909.04110v6
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.04110v6)
- **Published**: 2019-09-09 19:10:05+00:00
- **Updated**: 2020-01-15 03:13:18+00:00
- **Authors**: Zengming Shen, S. Kevin Zhou, Yifan Chen, Bogdan Georgescu, Xuqi Liu, Thomas S. Huang
- **Comment**: Accepted by WACV 2020
- **Journal**: None
- **Summary**: Recently image-to-image translation has attracted significant interests in the literature, starting from the successful use of the generative adversarial network (GAN), to the introduction of cyclic constraint, to extensions to multiple domains. However, in existing approaches, there is no guarantee that the mapping between two image domains is unique or one-to-one. Here we propose a self-inverse network learning approach for unpaired image-to-image translation. Building on top of CycleGAN, we learn a self-inverse function by simply augmenting the training samples by swapping inputs and outputs during training and with separated cycle consistency loss for each mapping direction. The outcome of such learning is a proven one-to-one mapping function. Our extensive experiments on a variety of datasets, including cross-modal medical image synthesis, object transfiguration, and semantic labeling, consistently demonstrate clear improvement over the CycleGAN method both qualitatively and quantitatively. Especially our proposed method reaches the state-of-the-art result on the cityscapes benchmark dataset for the label to photo unpaired directional image translation.



### Estimating Fingertip Forces, Torques, and Local Curvatures from Fingernail Images
- **Arxiv ID**: http://arxiv.org/abs/1909.05659v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.05659v1)
- **Published**: 2019-09-09 19:22:32+00:00
- **Updated**: 2019-09-09 19:22:32+00:00
- **Authors**: Nutan Chen, Göran Westling, Benoni B. Edin, Patrick van der Smagt
- **Comment**: Robotica
- **Journal**: None
- **Summary**: The study of dexterous manipulation has provided important insights in humans sensorimotor control as well as inspiration for manipulation strategies in robotic hands. Previous work focused on experimental environment with restrictions. Here we describe a method using the deformation and color distribution of the fingernail and its surrounding skin, to estimate the fingertip forces, torques and contact surface curvatures for various objects, including the shape and material of the contact surfaces and the weight of the objects. The proposed method circumvents limitations associated with sensorized objects, gloves or fixed contact surface type. In addition, compared with previous single finger estimation in an experimental environment, we extend the approach to multiple finger force estimation, which can be used for applications such as human grasping analysis. Four algorithms are used, c.q., Gaussian process (GP), Convolutional Neural Networks (CNN), Neural Networks with Fast Dropout (NN-FD) and Recurrent Neural Networks with Fast Dropout (RNN-FD), to model a mapping from images to the corresponding labels. The results further show that the proposed method has high accuracy to predict force, torque and contact surface.



### DeepObfuscator: Obfuscating Intermediate Representations with Privacy-Preserving Adversarial Learning on Smartphones
- **Arxiv ID**: http://arxiv.org/abs/1909.04126v2
- **DOI**: 10.1145/3450268.3453519
- **Categories**: **cs.CR**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.04126v2)
- **Published**: 2019-09-09 19:57:01+00:00
- **Updated**: 2021-05-06 02:46:26+00:00
- **Authors**: Ang Li, Jiayi Guo, Huanrui Yang, Flora D. Salim, Yiran Chen
- **Comment**: This paper is to be published in IoTDI'21
- **Journal**: None
- **Summary**: Deep learning has been widely applied in many computer vision applications, with remarkable success. However, running deep learning models on mobile devices is generally challenging due to the limitation of computing resources. A popular alternative is to use cloud services to run deep learning models to process raw data. This, however, imposes privacy risks. Some prior arts proposed sending the features extracted from raw data to the cloud. Unfortunately, these extracted features can still be exploited by attackers to recover raw images and to infer embedded private attributes. In this paper, we propose an adversarial training framework, DeepObfuscator, which prevents the usage of the features for reconstruction of the raw images and inference of private attributes. This is done while retaining useful information for the intended cloud service. DeepObfuscator includes a learnable obfuscator that is designed to hide privacy-related sensitive information from the features by performing our proposed adversarial training algorithm. The proposed algorithm is designed by simulating the game between an attacker who makes efforts to reconstruct raw image and infer private attributes from the extracted features and a defender who aims to protect user privacy. By deploying the trained obfuscator on the smartphone, features can be locally extracted and then sent to the cloud. Our experiments on CelebA and LFW datasets show that the quality of the reconstructed images from the obfuscated features of the raw image is dramatically decreased from 0.9458 to 0.3175 in terms of multi-scale structural similarity. The person in the reconstructed image, hence, becomes hardly to be re-identified. The classification accuracy of the inferred private attributes that can be achieved by the attacker is significantly reduced to a random-guessing level.



### Detection and Classification of Breast Cancer Metastates Based on U-Net
- **Arxiv ID**: http://arxiv.org/abs/1909.04141v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1909.04141v1)
- **Published**: 2019-09-09 20:34:32+00:00
- **Updated**: 2019-09-09 20:34:32+00:00
- **Authors**: Lin Xu, Cheng Xu, Yi Tong, Yu Chun Su
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents U-net based breast cancer metastases detection and classification in lymph nodes, as well as patient-level classification based on metastases detection. The whole pipeline can be divided into five steps: preprocessing and data argumentation, patch-based segmentation, post processing, slide-level classification, and patient-level classification. In order to reduce overfitting and speedup convergence, we applied batch normalization and dropout into U-Net. The final Kappa score reaches 0.902 on training data.



### DaTscan SPECT Image Classification for Parkinson's Disease
- **Arxiv ID**: http://arxiv.org/abs/1909.04142v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1909.04142v1)
- **Published**: 2019-09-09 20:35:23+00:00
- **Updated**: 2019-09-09 20:35:23+00:00
- **Authors**: Justin Quan, Lin Xu, Rene Xu, Tyrael Tong, Jean Su
- **Comment**: None
- **Journal**: None
- **Summary**: Parkinson's Disease (PD) is a neurodegenerative disease that currently does not have a cure. In order to facilitate disease management and reduce the speed of symptom progression, early diagnosis is essential. The current clinical, diagnostic approach is to have radiologists perform human visual analysis of the degeneration of dopaminergic neurons in the substantia nigra region of the brain. Clinically, dopamine levels are monitored through observing dopamine transporter (DaT) activity. One method of DaT activity analysis is performed with the injection of an Iodine-123 fluoropropyl (123I-FP-CIT) tracer combined with single photon emission computerized tomography (SPECT) imaging. The tracer illustrates the region of interest in the resulting DaTscan SPECT images. Human visual analysis is slow and vulnerable to subjectivity between radiologists, so the goal was to develop an introductory implementation of a deep convolutional neural network that can objectively and accurately classify DaTscan SPECT images as Parkinson's Disease or normal. This study illustrates the approach of using a deep convolutional neural network and evaluates its performance on DaTscan SPECT image classification. The data used in this study was obtained through a database provided by the Parkinson's Progression Markers Initiative (PPMI). The deep neural network in this study utilizes the InceptionV3 architecture, 1st runner up in the 2015 ImageNet Large Scale Visual Recognition Competition (ILSVRC), as a base model. A custom, binary classifier block was added on top of this base. In order to account for the small dataset size, a ten fold cross validation was implemented to evaluate the model's performance.



### Joint Learning of Saliency Detection and Weakly Supervised Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1909.04161v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.04161v1)
- **Published**: 2019-09-09 21:17:10+00:00
- **Updated**: 2019-09-09 21:17:10+00:00
- **Authors**: Yu Zeng, Yunzhi Zhuge, Huchuan Lu, Lihe Zhang
- **Comment**: Accepted by ICCV19
- **Journal**: None
- **Summary**: Existing weakly supervised semantic segmentation (WSSS) methods usually utilize the results of pre-trained saliency detection (SD) models without explicitly modeling the connections between the two tasks, which is not the most efficient configuration. Here we propose a unified multi-task learning framework to jointly solve WSSS and SD using a single network, \ie saliency, and segmentation network (SSNet). SSNet consists of a segmentation network (SN) and a saliency aggregation module (SAM). For an input image, SN generates the segmentation result and, SAM predicts the saliency of each category and aggregating the segmentation masks of all categories into a saliency map. The proposed network is trained end-to-end with image-level category labels and class-agnostic pixel-level saliency labels. Experiments on PASCAL VOC 2012 segmentation dataset and four saliency benchmark datasets show the performance of our method compares favorably against state-of-the-art weakly supervised segmentation methods and fully supervised saliency detection methods.



### MLOD: A multi-view 3D object detection based on robust feature fusion method
- **Arxiv ID**: http://arxiv.org/abs/1909.04163v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1909.04163v1)
- **Published**: 2019-09-09 21:18:41+00:00
- **Updated**: 2019-09-09 21:18:41+00:00
- **Authors**: Jian Deng, Krzysztof Czarnecki
- **Comment**: 6 pages, 6 figures, 2019 22st International Conference on Intelligent
  Transportation Systems (ITSC)
- **Journal**: None
- **Summary**: This paper presents Multi-view Labelling Object Detector (MLOD). The detector takes an RGB image and a LIDAR point cloud as input and follows the two-stage object detection framework. A Region Proposal Network (RPN) generates 3D proposals in a Bird's Eye View (BEV) projection of the point cloud. The second stage projects the 3D proposal bounding boxes to the image and BEV feature maps and sends the corresponding map crops to a detection header for classification and bounding-box regression. Unlike other multi-view based methods, the cropped image features are not directly fed to the detection header, but masked by the depth information to filter out parts outside 3D bounding boxes. The fusion of image and BEV features is challenging, as they are derived from different perspectives. We introduce a novel detection header, which provides detection results not just from fusion layer, but also from each sensor channel. Hence the object detector can be trained on data labelled in different views to avoid the degeneration of feature extractors. MLOD achieves state-of-the-art performance on the KITTI 3D object detection benchmark. Most importantly, the evaluation shows that the new header architecture is effective in preventing image feature extractor degeneration.



### Learning Object-specific Distance from a Monocular Image
- **Arxiv ID**: http://arxiv.org/abs/1909.04182v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1909.04182v1)
- **Published**: 2019-09-09 22:13:51+00:00
- **Updated**: 2019-09-09 22:13:51+00:00
- **Authors**: Jing Zhu, Yi Fang, Husam Abu-Haimed, Kuo-Chin Lien, Dongdong Fu, Junli Gu
- **Comment**: 10 pages, 6 figures, accepted by International Conference on Computer
  Vision (ICCV) 2019
- **Journal**: None
- **Summary**: Environment perception, including object detection and distance estimation, is one of the most crucial tasks for autonomous driving. Many attentions have been paid on the object detection task, but distance estimation only arouse few interests in the computer vision community. Observing that the traditional inverse perspective mapping algorithm performs poorly for objects far away from the camera or on the curved road, in this paper, we address the challenging distance estimation problem by developing the first end-to-end learning-based model to directly predict distances for given objects in the images. Besides the introduction of a learning-based base model, we further design an enhanced model with a keypoint regressor, where a projection loss is defined to enforce a better distance estimation, especially for objects close to the camera. To facilitate the research on this task, we construct the extented KITTI and nuScenes (mini) object detection datasets with a distance for each object. Our experiments demonstrate that our proposed methods outperform alternative approaches (e.g., the traditional IPM, SVR) on object-specific distance estimation, particularly for the challenging cases that objects are on a curved road. Moreover, the performance margin implies the effectiveness of our enhanced method.



