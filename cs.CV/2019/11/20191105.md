# Arxiv Papers in cs.CV on 2019-11-05
### Improving Long Handwritten Text Line Recognition with Convolutional Multi-way Associative Memory
- **Arxiv ID**: http://arxiv.org/abs/1911.01577v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01577v2)
- **Published**: 2019-11-05 02:42:09+00:00
- **Updated**: 2020-01-22 06:46:13+00:00
- **Authors**: Duc Nguyen, Nhan Tran, Hung Le
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Recurrent Neural Networks (CRNNs) excel at scene text recognition. Unfortunately, they are likely to suffer from vanishing/exploding gradient problems when processing long text images, which are commonly found in scanned documents. This poses a major challenge to goal of completely solving Optical Character Recognition (OCR) problem. Inspired by recently proposed memory-augmented neural networks (MANNs) for long-term sequential modeling, we present a new architecture dubbed Convolutional Multi-way Associative Memory (CMAM) to tackle the limitation of current CRNNs. By leveraging recent memory accessing mechanisms in MANNs, our architecture demonstrates superior performance against other CRNN counterparts in three real-world long text OCR datasets.



### A Deep Gradient Boosting Network for Optic Disc and Cup Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1911.01648v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01648v1)
- **Published**: 2019-11-05 07:23:53+00:00
- **Updated**: 2019-11-05 07:23:53+00:00
- **Authors**: Qing Liu, Beiji Zou, Yang Zhao, Yixiong Liang
- **Comment**: None
- **Journal**: None
- **Summary**: Segmentation of optic disc (OD) and optic cup (OC) is critical in automated fundus image analysis system. Existing state-of-the-arts focus on designing deep neural networks with one or multiple dense prediction branches. Such kind of designs ignore connections among prediction branches and their learning capacity is limited. To build connections among prediction branches, this paper introduces gradient boosting framework to deep classification model and proposes a gradient boosting network called BoostNet. Specifically, deformable side-output unit and aggregation unit with deep supervisions are proposed to learn base functions and expansion coefficients in gradient boosting framework. By stacking aggregation units in a deep-to-shallow manner, models' performances are gradually boosted along deep to shallow stages. BoostNet achieves superior results to existing deep OD and OC segmentation networks on the public dataset ORIGA.



### High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1911.01655v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01655v1)
- **Published**: 2019-11-05 07:44:57+00:00
- **Updated**: 2019-11-05 07:44:57+00:00
- **Authors**: Ruben Villegas, Arkanath Pathak, Harini Kannan, Dumitru Erhan, Quoc V. Le, Honglak Lee
- **Comment**: In Advances in Neural Information Processing Systems (NeurIPS), 2019
- **Journal**: None
- **Summary**: Predicting future video frames is extremely challenging, as there are many factors of variation that make up the dynamics of how frames change through time. Previously proposed solutions require complex inductive biases inside network architectures with highly specialized computation, including segmentation masks, optical flow, and foreground and background separation. In this work, we question if such handcrafted architectures are necessary and instead propose a different approach: finding minimal inductive bias for video prediction while maximizing network capacity. We investigate this question by performing the first large-scale empirical study and demonstrate state-of-the-art performance by learning large models on three different datasets: one for modeling object interactions, one for modeling human motion, and one for modeling car driving.



### Adaptive Context Network for Scene Parsing
- **Arxiv ID**: http://arxiv.org/abs/1911.01664v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01664v1)
- **Published**: 2019-11-05 08:16:28+00:00
- **Updated**: 2019-11-05 08:16:28+00:00
- **Authors**: Jun Fu, Jing Liu, Yuhang Wang, Yong Li, Yongjun Bao, Jinhui Tang, Hanqing Lu
- **Comment**: Accepted by ICCV 2019
- **Journal**: International Conference on Computer Vision 2019
- **Summary**: Recent works attempt to improve scene parsing performance by exploring different levels of contexts, and typically train a well-designed convolutional network to exploit useful contexts across all pixels equally. However, in this paper, we find that the context demands are varying from different pixels or regions in each image. Based on this observation, we propose an Adaptive Context Network (ACNet) to capture the pixel-aware contexts by a competitive fusion of global context and local context according to different per-pixel demands. Specifically, when given a pixel, the global context demand is measured by the similarity between the global feature and its local feature, whose reverse value can be used to measure the local context demand. We model the two demand measurements by the proposed global context module and local context module, respectively, to generate adaptive contextual features. Furthermore, we import multiple such modules to build several adaptive context blocks in different levels of network to obtain a coarse-to-fine result. Finally, comprehensive experimental evaluations demonstrate the effectiveness of the proposed ACNet, and new state-of-the-arts performances are achieved on all four public datasets, i.e. Cityscapes, ADE20K, PASCAL Context, and COCO Stuff.



### ROI Pooled Correlation Filters for Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1911.01668v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01668v1)
- **Published**: 2019-11-05 08:52:48+00:00
- **Updated**: 2019-11-05 08:52:48+00:00
- **Authors**: Yuxuan Sun, Chong Sun, Dong Wang, You He, Huchuan Lu
- **Comment**: CVPR 2019 Accepted.10 pages
- **Journal**: None
- **Summary**: The ROI (region-of-interest) based pooling method performs pooling operations on the cropped ROI regions for various samples and has shown great success in the object detection methods. It compresses the model size while preserving the localization accuracy, thus it is useful in the visual tracking field. Though being effective, the ROI-based pooling operation is not yet considered in the correlation filter formula. In this paper, we propose a novel ROI pooled correlation filter (RPCF) algorithm for robust visual tracking. Through mathematical derivations, we show that the ROI-based pooling can be equivalently achieved by enforcing additional constraints on the learned filter weights, which makes the ROI-based pooling feasible on the virtual circular samples. Besides, we develop an efficient joint training formula for the proposed correlation filter algorithm, and derive the Fourier solvers for efficient model training. Finally, we evaluate our RPCF tracker on OTB-2013, OTB-2015 and VOT-2017 benchmark datasets. Experimental results show that our tracker performs favourably against other state-of-the-art trackers.



### Spatial Sparse subspace clustering for Compressive Spectral imaging
- **Arxiv ID**: http://arxiv.org/abs/1911.01671v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01671v1)
- **Published**: 2019-11-05 09:07:27+00:00
- **Updated**: 2019-11-05 09:07:27+00:00
- **Authors**: Jianchen Zhu, Tong Zhang, Shengjie Zhao, Carlos Hinojosa, Zengli Liu, Gonzalo R. Arce
- **Comment**: None
- **Journal**: None
- **Summary**: This paper aims at developing a clustering approach with spectral images directly from CASSI compressive measurements. The proposed clustering method first assumes that compressed measurements lie in the union of multiple low-dimensional subspaces. Therefore, sparse subspace clustering (SSC) is an unsupervised method that assigns compressed measurements to their respective subspaces. In addition, a 3D spatial regularizer is added into the SSC problem, thus taking full advantages of the spatial information contained in spectral images. The performance of the proposed spectral image clustering approach is improved by taking optimal CASSI measurements obtained when optimal coded apertures are used in CASSI system. Simulation with one real dataset illustrates the accuracy of the proposed spectral image clustering approach.



### Congestion Analysis of Convolutional Neural Network-Based Pedestrian Counting Methods on Helicopter Footage
- **Arxiv ID**: http://arxiv.org/abs/1911.01672v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01672v1)
- **Published**: 2019-11-05 09:07:35+00:00
- **Updated**: 2019-11-05 09:07:35+00:00
- **Authors**: Gergely Cs√∂nde, Yoshihide Sekimoto, Takehiro Kashiyama
- **Comment**: 9 pages, 7 figures
- **Journal**: None
- **Summary**: Over the past few years, researchers have presented many different applications for convolutional neural networks, including those for the detection and recognition of objects from images. The desire to understand our own nature has always been an important motivation for research. Thus, the visual recognition of humans is among the most important issues facing machine learning today. Most solutions for this task have been developed and tested by using several publicly available datasets. These datasets typically contain images taken from street-level closed-circuit television cameras offering a low-angle view. There are major differences between such images and those taken from the sky. In addition, aerial images are often very congested, containing hundreds of targets. These factors may have significant impact on the quality of the results. In this paper, we investigate state-of-the-art methods for counting pedestrians and the related performance of aerial footage. Furthermore, we analyze this performance with respect to the congestion levels of the images.



### Cumulo: A Dataset for Learning Cloud Classes
- **Arxiv ID**: http://arxiv.org/abs/1911.04227v3
- **DOI**: None
- **Categories**: **physics.ao-ph**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.04227v3)
- **Published**: 2019-11-05 09:36:16+00:00
- **Updated**: 2022-10-13 19:29:37+00:00
- **Authors**: Valentina Zantedeschi, Fabrizio Falasca, Alyson Douglas, Richard Strange, Matt J. Kusner, Duncan Watson-Parris
- **Comment**: None
- **Journal**: Tackling Climate Change with Machine Learning Workshop, 33rd
  Conference on Neural Information Processing Systems (NeurIPS 2019),
  Vancouver, Canada
- **Summary**: One of the greatest sources of uncertainty in future climate projections comes from limitations in modelling clouds and in understanding how different cloud types interact with the climate system. A key first step in reducing this uncertainty is to accurately classify cloud types at high spatial and temporal resolution. In this paper, we introduce Cumulo, a benchmark dataset for training and evaluating global cloud classification models. It consists of one year of 1km resolution MODIS hyperspectral imagery merged with pixel-width 'tracks' of CloudSat cloud labels. Bringing these complementary datasets together is a crucial first step, enabling the Machine-Learning community to develop innovative new techniques which could greatly benefit the Climate community. To showcase Cumulo, we provide baseline performance analysis using an invertible flow generative model (IResNet), which further allows us to discover new sub-classes for a given cloud class by exploring the latent space. To compare methods, we introduce a set of evaluation criteria, to identify models that are not only accurate, but also physically-realistic. CUMULO can be download from https://www.dropbox.com/sh/i3s9q2v2jjyk2it/AACxXnXfMF5wuIqLXqH4NJOra?dl=0 .



### Optimizing the Dice Score and Jaccard Index for Medical Image Segmentation: Theory & Practice
- **Arxiv ID**: http://arxiv.org/abs/1911.01685v1
- **DOI**: 10.1007/978-3-030-32245-8_11
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01685v1)
- **Published**: 2019-11-05 09:42:25+00:00
- **Updated**: 2019-11-05 09:42:25+00:00
- **Authors**: Jeroen Bertels, Tom Eelbode, Maxim Berman, Dirk Vandermeulen, Frederik Maes, Raf Bisschops, Matthew Blaschko
- **Comment**: MICCAI 2019
- **Journal**: LNCS 11765, Springer Nature Switzerland AG 2019
- **Summary**: The Dice score and Jaccard index are commonly used metrics for the evaluation of segmentation tasks in medical imaging. Convolutional neural networks trained for image segmentation tasks are usually optimized for (weighted) cross-entropy. This introduces an adverse discrepancy between the learning optimization objective (the loss) and the end target metric. Recent works in computer vision have proposed soft surrogates to alleviate this discrepancy and directly optimize the desired metric, either through relaxations (soft-Dice, soft-Jaccard) or submodular optimization (Lov\'asz-softmax). The aim of this study is two-fold. First, we investigate the theoretical differences in a risk minimization framework and question the existence of a weighted cross-entropy loss with weights theoretically optimized to surrogate Dice or Jaccard. Second, we empirically investigate the behavior of the aforementioned loss functions w.r.t. evaluation with Dice score and Jaccard index on five medical segmentation tasks. Through the application of relative approximation bounds, we show that all surrogates are equivalent up to a multiplicative factor, and that no optimal weighting of cross-entropy exists to approximate Dice or Jaccard measures. We validate these findings empirically and show that, while it is important to opt for one of the target metric surrogates rather than a cross-entropy-based loss, the choice of the surrogate does not make a statistical difference on a wide range of medical segmentation tasks.



### DocParser: Hierarchical Structure Parsing of Document Renderings
- **Arxiv ID**: http://arxiv.org/abs/1911.01702v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.01702v2)
- **Published**: 2019-11-05 10:42:08+00:00
- **Updated**: 2021-01-25 11:54:38+00:00
- **Authors**: Johannes Rausch, Octavio Martinez, Fabian Bissig, Ce Zhang, Stefan Feuerriegel
- **Comment**: AAAI 2021
- **Journal**: None
- **Summary**: Translating renderings (e. g. PDFs, scans) into hierarchical document structures is extensively demanded in the daily routines of many real-world applications. However, a holistic, principled approach to inferring the complete hierarchical structure of documents is missing. As a remedy, we developed "DocParser": an end-to-end system for parsing the complete document structure - including all text elements, nested figures, tables, and table cell structures. Our second contribution is to provide a dataset for evaluating hierarchical document structure parsing. Our third contribution is to propose a scalable learning framework for settings where domain-specific data are scarce, which we address by a novel approach to weak supervision that significantly improves the document structure parsing performance. Our experiments confirm the effectiveness of our proposed weak supervision: Compared to the baseline without weak supervision, it improves the mean average precision for detecting document entities by 39.1 % and improves the F1 score of classifying hierarchical relations by 35.8 %.



### An "augmentation-free" rotation invariant classification scheme on point-cloud and its application to neuroimaging
- **Arxiv ID**: http://arxiv.org/abs/1911.03443v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.03443v1)
- **Published**: 2019-11-05 10:45:56+00:00
- **Updated**: 2019-11-05 10:45:56+00:00
- **Authors**: Liu Yang, Rudrasis Chakraborty
- **Comment**: arXiv admin note: text overlap with arXiv:1910.13050 and
  arXiv:1911.01705
- **Journal**: None
- **Summary**: Recent years have witnessed the emergence and increasing popularity of 3D medical imaging techniques with the development of 3D sensors and technology. However, achieving geometric invariance in the processing of 3D medical images is computationally expensive but nonetheless essential due to the presence of possible errors caused by rigid registration techniques. An alternative way to analyze medical imaging is by understanding the 3D shapes represented in terms of point-cloud. Though in the medical imaging community, 3D point-cloud processing is not a "go-to" choice, it is a canonical way to preserve rotation invariance. Unfortunately, due to the presence of discrete topology, one can not use the standard convolution operator on point-cloud. To the best of our knowledge, the existing ways to do "convolution" can not preserve the rotation invariance without explicit data augmentation. Therefore, we propose a rotation invariant convolution operator by inducing topology from hypersphere. Experimental validation has been performed on publicly available OASIS dataset in terms of classification accuracy between subjects with (without) dementia, demonstrating the usefulness of our proposed method in terms of model complexity, classification accuracy, and last but most important invariance to rotations.



### LACI: Low-effort Automatic Calibration of Infrastructure Sensors
- **Arxiv ID**: http://arxiv.org/abs/1911.01711v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01711v1)
- **Published**: 2019-11-05 11:04:06+00:00
- **Updated**: 2019-11-05 11:04:06+00:00
- **Authors**: Johannes M√ºller, Martin Herrmann, Jan Strohbeck, Vasileios Belagiannis, Michael Buchholz
- **Comment**: 6 pages, published at ITSC 2019
- **Journal**: None
- **Summary**: Sensor calibration usually is a time consuming yet important task. While classical approaches are sensor-specific and often need calibration targets as well as a widely overlapping field of view (FOV), within this work, a cooperative intelligent vehicle is used as callibration target. The vehicleis detected in the sensor frame and then matched with the information received from the cooperative awareness messagessend by the coperative intelligent vehicle. The presented algorithm is fully automated as well as sensor-independent, relying only on a very common set of assumptions. Due to the direct registration on the world frame, no overlapping FOV is necessary. The algorithm is evaluated through experiment for four laserscanners as well as one pair of stereo cameras showing a repetition error within the measurement uncertainty of the sensors. A plausibility check rules out systematic errors that might not have been covered by evaluating the repetition error.



### Detecting and Tracking Small Moving Objects in Wide Area Motion Imagery (WAMI) Using Convolutional Neural Networks (CNNs)
- **Arxiv ID**: http://arxiv.org/abs/1911.01727v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01727v2)
- **Published**: 2019-11-05 11:43:53+00:00
- **Updated**: 2019-11-08 14:13:54+00:00
- **Authors**: Yifan Zhou, Simon Maskell
- **Comment**: Accepted for publication in 22nd International Conference on
  Information Fusion (FUSION 2019)
- **Journal**: None
- **Summary**: This paper proposes an approach to detect moving objects in Wide Area Motion Imagery (WAMI), in which the objects are both small and well separated. Identifying the objects only using foreground appearance is difficult since a $100-$pixel vehicle is hard to distinguish from objects comprising the background. Our approach is based on background subtraction as an efficient and unsupervised method that is able to output the shape of objects. In order to reliably detect low contrast and small objects, we configure the background subtraction to extract foreground regions that might be objects of interest. While this dramatically increases the number of false alarms, a Convolutional Neural Network (CNN) considering both spatial and temporal information is then trained to reject the false alarms. In areas with heavy traffic, the background subtraction yields merged detections. To reduce the complexity of multi-target tracker needed, we train another CNN to predict the positions of multiple moving objects in an area. Our approach shows competitive detection performance on smaller objects relative to the state-of-the-art. We adopt a GM-PHD filter to associate detections over time and analyse the resulting performance.



### Weakly Supervised Fine Tuning Approach for Brain Tumor Segmentation Problem
- **Arxiv ID**: http://arxiv.org/abs/1911.01738v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.01738v2)
- **Published**: 2019-11-05 12:14:40+00:00
- **Updated**: 2019-11-06 07:48:01+00:00
- **Authors**: Sergey Pavlov, Alexey Artemov, Maksim Sharaev, Alexander Bernstein, Evgeny Burnaev
- **Comment**: Accepted to IEEE International Conference on Machine Learning and
  Applications (ICMLA 2019). Typos corrected, images updated
- **Journal**: None
- **Summary**: Segmentation of tumors in brain MRI images is a challenging task, where most recent methods demand large volumes of data with pixel-level annotations, which are generally costly to obtain. In contrast, image-level annotations, where only the presence of lesion is marked, are generally cheap, generated in far larger volumes compared to pixel-level labels, and contain less labeling noise. In the context of brain tumor segmentation, both pixel-level and image-level annotations are commonly available; thus, a natural question arises whether a segmentation procedure could take advantage of both. In the present work we: 1) propose a learning-based framework that allows simultaneous usage of both pixel- and image-level annotations in MRI images to learn a segmentation model for brain tumor; 2) study the influence of comparative amounts of pixel- and image-level annotations on the quality of brain tumor segmentation; 3) compare our approach to the traditional fully-supervised approach and show that the performance of our method in terms of segmentation quality may be competitive.



### OntoScene, A Logic-based Scene Interpreter: Implementation and Application in the Rock Art Domain
- **Arxiv ID**: http://arxiv.org/abs/1911.04863v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LO, cs.MA
- **Links**: [PDF](http://arxiv.org/pdf/1911.04863v1)
- **Published**: 2019-11-05 13:22:05+00:00
- **Updated**: 2019-11-05 13:22:05+00:00
- **Authors**: Daniela Briola, Viviana Mascardi, Massimiliano Gioseffi
- **Comment**: Under consideration in Theory and Practice of Logic Programming
  (TPLP)
- **Journal**: None
- **Summary**: We present OntoScene, a framework aimed at understanding the semantics of visual scenes starting from the semantics of their elements and the spatial relations holding between them. OntoScene exploits ontologies for representing knowledge and Prolog for specifying the interpretation rules that domain experts may adopt, and for implementing the SceneInterpreter engine. Ontologies allow the designer to formalize the domain in a reusable way, and make the system modular and interoperable with existing multiagent systems, while Prolog provides a solid basis to define complex rules of interpretation in a way that can be affordable even for people with no background in Computational Logics. The domain selected for experimenting OntoScene is that of prehistoric rock art, which provides us with a fascinating and challenging testbed. Under consideration in Theory and Practice of Logic Programming (TPLP)



### Visual Privacy Protection via Mapping Distortion
- **Arxiv ID**: http://arxiv.org/abs/1911.01769v4
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01769v4)
- **Published**: 2019-11-05 13:41:45+00:00
- **Updated**: 2021-02-03 09:39:37+00:00
- **Authors**: Yiming Li, Peidong Liu, Yong Jiang, Shu-Tao Xia
- **Comment**: Accepted by the ICASSP 2021. The first two authors contributed
  equally to this work
- **Journal**: None
- **Summary**: Privacy protection is an important research area, which is especially critical in this big data era. To a large extent, the privacy of visual classification data is mainly in the mapping between the image and its corresponding label, since this relation provides a great amount of information and can be used in other scenarios. In this paper, we propose the mapping distortion based protection (MDP) and its augmentation-based extension (AugMDP) to protect the data privacy by modifying the original dataset. In the modified dataset generated by MDP, the image and its label are not consistent ($e.g.$, a cat-like image is labeled as the dog), whereas the DNNs trained on it can still achieve good performance on benign testing set. As such, this method can protect privacy when the dataset is leaked. Extensive experiments are conducted, which verify the effectiveness and feasibility of our method. The code for reproducing main results is available at \url{https://github.com/PerdonLiu/Visual-Privacy-Protection-via-Mapping-Distortion}.



### Deep Flow Collaborative Network for Online Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1911.01786v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1911.01786v1)
- **Published**: 2019-11-05 14:13:07+00:00
- **Updated**: 2019-11-05 14:13:07+00:00
- **Authors**: Peidong Liu, Xiyu Yan, Yong Jiang, Shu-Tao Xia
- **Comment**: None
- **Journal**: None
- **Summary**: The deep learning-based visual tracking algorithms such as MDNet achieve high performance leveraging to the feature extraction ability of a deep neural network. However, the tracking efficiency of these trackers is not very high due to the slow feature extraction for each frame in a video. In this paper, we propose an effective tracking algorithm to alleviate the time-consuming problem. Specifically, we design a deep flow collaborative network, which executes the expensive feature network only on sparse keyframes and transfers the feature maps to other frames via optical flow. Moreover, we raise an effective adaptive keyframe scheduling mechanism to select the most appropriate keyframe. We evaluate the proposed approach on large-scale datasets: OTB2013 and OTB2015. The experiment results show that our algorithm achieves considerable speedup and high precision as well.



### Detection of vertebral fractures in CT using 3D Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1911.01816v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01816v1)
- **Published**: 2019-11-05 14:43:00+00:00
- **Updated**: 2019-11-05 14:43:00+00:00
- **Authors**: Joeri Nicolaes, Steven Raeymaeckers, David Robben, Guido Wilms, Dirk Vandermeulen, Cesar Libanati, Marc Debois
- **Comment**: 13 pages, 7 figures, pre-print MICCAI CSI
- **Journal**: None
- **Summary**: Osteoporosis induced fractures occur worldwide about every 3 seconds. Vertebral compression fractures are early signs of the disease and considered risk predictors for secondary osteoporotic fractures. We present a detection method to opportunistically screen spine-containing CT images for the presence of these vertebral fractures. Inspired by radiology practice, existing methods are based on 2D and 2.5D features but we present, to the best of our knowledge, the first method for detecting vertebral fractures in CT using automatically learned 3D feature maps. The presented method explicitly localizes these fractures allowing radiologists to interpret its results. We train a voxel-classification 3D Convolutional Neural Network (CNN) with a training database of 90 cases that has been semi-automatically generated using radiologist readings that are readily available in clinical practice. Our 3D method produces an Area Under the Curve (AUC) of 95% for patient-level fracture detection and an AUC of 93% for vertebra-level fracture detection in a five-fold cross-validation experiment.



### Video Captioning with Text-based Dynamic Attention and Step-by-Step Learning
- **Arxiv ID**: http://arxiv.org/abs/1911.01857v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.01857v1)
- **Published**: 2019-11-05 15:14:12+00:00
- **Updated**: 2019-11-05 15:14:12+00:00
- **Authors**: Huanhou Xiao, Jinglun Shi
- **Comment**: The paper is under consideration at Pattern Recognition Letters
- **Journal**: None
- **Summary**: Automatically describing video content with natural language has been attracting much attention in CV and NLP communities. Most existing methods predict one word at a time, and by feeding the last generated word back as input at the next time, while the other generated words are not fully exploited. Furthermore, traditional methods optimize the model using all the training samples in each epoch without considering their learning situations, which leads to a lot of unnecessary training and can not target the difficult samples. To address these issues, we propose a text-based dynamic attention model named TDAM, which imposes a dynamic attention mechanism on all the generated words with the motivation to improve the context semantic information and enhance the overall control of the whole sentence. Moreover, the text-based dynamic attention mechanism and the visual attention mechanism are linked together to focus on the important words. They can benefit from each other during training. Accordingly, the model is trained through two steps: "starting from scratch" and "checking for gaps". The former uses all the samples to optimize the model, while the latter only trains for samples with poor control. Experimental results on the popular datasets MSVD and MSR-VTT demonstrate that our non-ensemble model outperforms the state-of-the-art video captioning benchmarks.



### 3D Deformable Convolutions for MRI classification
- **Arxiv ID**: http://arxiv.org/abs/1911.01898v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1911.01898v1)
- **Published**: 2019-11-05 16:02:10+00:00
- **Updated**: 2019-11-05 16:02:10+00:00
- **Authors**: Marina Pominova, Ekaterina Kondrateva, Maksim Sharaev, Sergey Pavlov, Alexander Bernstein, Evgeny Burnaev
- **Comment**: Accepted to IEEE International Conference on Machine Learning and
  Applications (ICMLA 2019)
- **Journal**: None
- **Summary**: Deep learning convolutional neural networks have proved to be a powerful tool for MRI analysis. In current work, we explore the potential of the deformable convolutional deep neural network layers for MRI data classification. We propose new 3D deformable convolutions(d-convolutions), implement them in VoxResNet architecture and apply for structural MRI data classification. We show that 3D d-convolutions outperform standard ones and are effective for unprocessed 3D MR images being robust to particular geometrical properties of the data. Firstly proposed dVoxResNet architecture exhibits high potential for the use in MRI data classification.



### Scalable Variational Gaussian Processes for Crowdsourcing: Glitch Detection in LIGO
- **Arxiv ID**: http://arxiv.org/abs/1911.01915v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, gr-qc, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.01915v1)
- **Published**: 2019-11-05 16:20:38+00:00
- **Updated**: 2019-11-05 16:20:38+00:00
- **Authors**: Pablo Morales-√Ålvarez, Pablo Ruiz, Scott Coughlin, Rafael Molina, Aggelos K. Katsaggelos
- **Comment**: 16 pages, under review
- **Journal**: None
- **Summary**: In the last years, crowdsourcing is transforming the way classification training sets are obtained. Instead of relying on a single expert annotator, crowdsourcing shares the labelling effort among a large number of collaborators. For instance, this is being applied to the data acquired by the laureate Laser Interferometer Gravitational Waves Observatory (LIGO), in order to detect glitches which might hinder the identification of true gravitational-waves. The crowdsourcing scenario poses new challenging difficulties, as it deals with different opinions from a heterogeneous group of annotators with unknown degrees of expertise. Probabilistic methods, such as Gaussian Processes (GP), have proven successful in modeling this setting. However, GPs do not scale well to large data sets, which hampers their broad adoption in real practice (in particular at LIGO). This has led to the recent introduction of deep learning based crowdsourcing methods, which have become the state-of-the-art. However, the accurate uncertainty quantification of GPs has been partially sacrificed. This is an important aspect for astrophysicists in LIGO, since a glitch detection system should provide very accurate probability distributions of its predictions. In this work, we leverage the most popular sparse GP approximation to develop a novel GP based crowdsourcing method that factorizes into mini-batches. This makes it able to cope with previously-prohibitive data sets. The approach, which we refer to as Scalable Variational Gaussian Processes for Crowdsourcing (SVGPCR), brings back GP-based methods to the state-of-the-art, and excels at uncertainty quantification. SVGPCR is shown to outperform deep learning based methods and previous probabilistic approaches when applied to the LIGO data. Moreover, its behavior and main properties are carefully analyzed in a controlled experiment based on the MNIST data set.



### Scribble-based Hierarchical Weakly Supervised Learning for Brain Tumor Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1911.02014v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.02014v1)
- **Published**: 2019-11-05 16:56:35+00:00
- **Updated**: 2019-11-05 16:56:35+00:00
- **Authors**: Zhanghexuan Ji, Yan Shen, Chunwei Ma, Mingchen Gao
- **Comment**: 22nd International Conference on Medical Image Computing and Computer
  Assisted Intervention (MICCAI 2019) Accept
- **Journal**: None
- **Summary**: The recent state-of-the-art deep learning methods have significantly improved brain tumor segmentation. However, fully supervised training requires a large amount of manually labeled masks, which is highly time-consuming and needs domain expertise. Weakly supervised learning with scribbles provides a good trade-off between model accuracy and the effort of manual labeling. However, for segmenting the hierarchical brain tumor structures, manually labeling scribbles for each substructure could still be demanding. In this paper, we use only two kinds of weak labels, i.e., scribbles on whole tumor and healthy brain tissue, and global labels for the presence of each substructure, to train a deep learning model to segment all the sub-regions. Specifically, we train two networks in two phases: first, we only use whole tumor scribbles to train a whole tumor (WT) segmentation network, which roughly recovers the WT mask of training data; then we cluster the WT region with the guide of global labels. The rough substructure segmentation from clustering is used as weak labels to train the second network. The dense CRF loss is used to refine the weakly supervised segmentation. We evaluate our approach on the BraTS2017 dataset and achieve competitive WT dice score as well as comparable scores on substructure segmentation compared to an upper bound when trained with fully annotated masks.



### Bipolar Morphological Neural Networks: Convolution Without Multiplication
- **Arxiv ID**: http://arxiv.org/abs/1911.01971v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1911.01971v1)
- **Published**: 2019-11-05 17:57:35+00:00
- **Updated**: 2019-11-05 17:57:35+00:00
- **Authors**: Elena Limonova, Daniil Matveev, Dmitry Nikolaev, Vladimir V. Arlazarov
- **Comment**: Submitted to International Conference on Machine Vision 2019
- **Journal**: None
- **Summary**: In the paper we introduce a novel bipolar morphological neuron and bipolar morphological layer models. The models use only such operations as addition, subtraction and maximum inside the neuron and exponent and logarithm as activation functions for the layer. The proposed models unlike previously introduced morphological neural networks approximate the classical computations and show better recognition results. We also propose layer-by-layer approach to train the bipolar morphological networks, which can be further developed to an incremental approach for separate neurons to get higher accuracy. Both these approaches do not require special training algorithms and can use a variety of gradient descent methods. To demonstrate efficiency of the proposed model we consider classical convolutional neural networks and convert the pre-trained convolutional layers to the bipolar morphological layers. Seeing that the experiments on recognition of MNIST and MRZ symbols show only moderate decrease of accuracy after conversion and training, bipolar neuron model can provide faster inference and be very useful in mobile and embedded systems.



### Dancing to Music
- **Arxiv ID**: http://arxiv.org/abs/1911.02001v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.02001v1)
- **Published**: 2019-11-05 18:56:15+00:00
- **Updated**: 2019-11-05 18:56:15+00:00
- **Authors**: Hsin-Ying Lee, Xiaodong Yang, Ming-Yu Liu, Ting-Chun Wang, Yu-Ding Lu, Ming-Hsuan Yang, Jan Kautz
- **Comment**: NeurIPS 2019; Project page: https://github.com/NVlabs/Dancing2Music
- **Journal**: None
- **Summary**: Dancing to music is an instinctive move by humans. Learning to model the music-to-dance generation process is, however, a challenging problem. It requires significant efforts to measure the correlation between music and dance as one needs to simultaneously consider multiple aspects, such as style and beat of both music and dance. Additionally, dance is inherently multimodal and various following movements of a pose at any moment are equally likely. In this paper, we propose a synthesis-by-analysis learning framework to generate dance from music. In the analysis phase, we decompose a dance into a series of basic dance units, through which the model learns how to move. In the synthesis phase, the model learns how to compose a dance by organizing multiple basic dancing movements seamlessly according to the input music. Experimental qualitative and quantitative results demonstrate that the proposed method can synthesize realistic, diverse,style-consistent, and beat-matching dances from music.



### Satellite Pose Estimation Challenge: Dataset, Competition Design and Results
- **Arxiv ID**: http://arxiv.org/abs/1911.02050v2
- **DOI**: 10.1109/TAES.2020.2989063
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1911.02050v2)
- **Published**: 2019-11-05 19:29:18+00:00
- **Updated**: 2020-04-24 18:50:25+00:00
- **Authors**: Mate Kisantal, Sumant Sharma, Tae Ha Park, Dario Izzo, Marcus M√§rtens, Simone D'Amico
- **Comment**: Accepted to IEEE Transactions on Aerospace and Electronic Systems
- **Journal**: None
- **Summary**: Reliable pose estimation of uncooperative satellites is a key technology for enabling future on-orbit servicing and debris removal missions. The Kelvins Satellite Pose Estimation Challenge aims at evaluating and comparing monocular vision-based approaches and pushing the state-of-the-art on this problem. This work is based on the Satellite Pose Estimation Dataset, the first publicly available machine learning set of synthetic and real spacecraft imageries. The choice of dataset reflects one of the unique challenges associated with spaceborne computer vision tasks, namely the lack of spaceborne images to train and validate the developed algorithms. This work briefly reviews the basic properties and the collection process of the dataset which was made publicly available. The competition design, including the definition of performance metrics and the adopted testbed, is also discussed. The main contribution of this paper is the analysis of the submissions of the 48 competitors, which compares the performance of different approaches and uncovers what factors make the satellite pose estimation problem especially challenging.



### A Method to Model Conditional Distributions with Normalizing Flows
- **Arxiv ID**: http://arxiv.org/abs/1911.02052v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1911.02052v1)
- **Published**: 2019-11-05 19:37:37+00:00
- **Updated**: 2019-11-05 19:37:37+00:00
- **Authors**: Zhisheng Xiao, Qing Yan, Yali Amit
- **Comment**: 10 pages. Work in progress
- **Journal**: None
- **Summary**: In this work, we investigate the use of normalizing flows to model conditional distributions. In particular, we use our proposed method to analyze inverse problems with invertible neural networks by maximizing the posterior likelihood. Our method uses only a single loss and is easy to train. This is an improvement on the previous method that solves similar inverse problems with invertible neural networks but which involves a combination of several loss terms with ad-hoc weighting. In addition, our method provides a natural framework to incorporate conditioning in normalizing flows, and therefore, we can train an invertible network to perform conditional generation. We analyze our method and perform a careful comparison with previous approaches. Simple experiments show the effectiveness of our method, and more comprehensive experimental evaluations are undergoing.



### Federated Adversarial Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1911.02054v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1911.02054v2)
- **Published**: 2019-11-05 19:45:49+00:00
- **Updated**: 2019-12-21 22:03:36+00:00
- **Authors**: Xingchao Peng, Zijun Huang, Yizhe Zhu, Kate Saenko
- **Comment**: Published as a conference paper at ICLR 2020
- **Journal**: None
- **Summary**: Federated learning improves data privacy and efficiency in machine learning performed over networks of distributed devices, such as mobile phones, IoT and wearable devices, etc. Yet models trained with federated learning can still fail to generalize to new devices due to the problem of domain shift. Domain shift occurs when the labeled data collected by source nodes statistically differs from the target node's unlabeled data. In this work, we present a principled approach to the problem of federated domain adaptation, which aims to align the representations learned among the different nodes with the data distribution of the target node. Our approach extends adversarial adaptation techniques to the constraints of the federated setting. In addition, we devise a dynamic attention mechanism and leverage feature disentanglement to enhance knowledge transfer. Empirically, we perform extensive experiments on several image and text classification tasks and show promising results under unsupervised federated domain adaptation setting.



### An Alternative Probabilistic Interpretation of the Huber Loss
- **Arxiv ID**: http://arxiv.org/abs/1911.02088v3
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1911.02088v3)
- **Published**: 2019-11-05 21:15:19+00:00
- **Updated**: 2020-11-18 19:27:22+00:00
- **Authors**: Gregory P. Meyer
- **Comment**: None
- **Journal**: None
- **Summary**: The Huber loss is a robust loss function used for a wide range of regression tasks. To utilize the Huber loss, a parameter that controls the transitions from a quadratic function to an absolute value function needs to be selected. We believe the standard probabilistic interpretation that relates the Huber loss to the Huber density fails to provide adequate intuition for identifying the transition point. As a result, a hyper-parameter search is often necessary to determine an appropriate value. In this work, we propose an alternative probabilistic interpretation of the Huber loss, which relates minimizing the loss to minimizing an upper-bound on the Kullback-Leibler divergence between Laplace distributions, where one distribution represents the noise in the ground-truth and the other represents the noise in the prediction. In addition, we show that the parameters of the Laplace distributions are directly related to the transition point of the Huber loss. We demonstrate, through a toy problem, that the optimal transition point of the Huber loss is closely related to the distribution of the noise in the ground-truth data. As a result, our interpretation provides an intuitive way to identify well-suited hyper-parameters by approximating the amount of noise in the data, which we demonstrate through a case study and experimentation on the Faster R-CNN and RetinaNet object detectors.



### Recurrent Instance Segmentation using Sequences of Referring Expressions
- **Arxiv ID**: http://arxiv.org/abs/1911.02103v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1911.02103v1)
- **Published**: 2019-11-05 21:49:55+00:00
- **Updated**: 2019-11-05 21:49:55+00:00
- **Authors**: Alba Herrera-Palacio, Carles Ventura, Carina Silberer, Ionut-Teodor Sorodoc, Gemma Boleda, Xavier Giro-i-Nieto
- **Comment**: 3rd NeurIPS Workshop on Visually Grounded Interaction and Language
  (ViGIL, 2019)
- **Journal**: None
- **Summary**: The goal of this work is to segment the objects in an image that are referred to by a sequence of linguistic descriptions (referring expressions). We propose a deep neural network with recurrent layers that output a sequence of binary masks, one for each referring expression provided by the user. The recurrent layers in the architecture allow the model to condition each predicted mask on the previous ones, from a spatial perspective within the same image. Our multimodal approach uses off-the-shelf architectures to encode both the image and the referring expressions. The visual branch provides a tensor of pixel embeddings that are concatenated with the phrase embeddings produced by a language encoder. Our experiments on the RefCOCO dataset for still images indicate how the proposed architecture successfully exploits the sequences of referring expressions to solve a pixel-wise task of instance segmentation.



### Contextual Grounding of Natural Language Entities in Images
- **Arxiv ID**: http://arxiv.org/abs/1911.02133v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1911.02133v1)
- **Published**: 2019-11-05 23:23:58+00:00
- **Updated**: 2019-11-05 23:23:58+00:00
- **Authors**: Farley Lai, Ning Xie, Derek Doran, Asim Kadav
- **Comment**: Accepted to NeurIPS 2019 workshop on Visually Grounded Interaction
  and Language (ViGIL)
- **Journal**: None
- **Summary**: In this paper, we introduce a contextual grounding approach that captures the context in corresponding text entities and image regions to improve the grounding accuracy. Specifically, the proposed architecture accepts pre-trained text token embeddings and image object features from an off-the-shelf object detector as input. Additional encoding to capture the positional and spatial information can be added to enhance the feature quality. There are separate text and image branches facilitating respective architectural refinements for different modalities. The text branch is pre-trained on a large-scale masked language modeling task while the image branch is trained from scratch. Next, the model learns the contextual representations of the text tokens and image objects through layers of high-order interaction respectively. The final grounding head ranks the correspondence between the textual and visual representations through cross-modal interaction. In the evaluation, we show that our model achieves the state-of-the-art grounding accuracy of 71.36% over the Flickr30K Entities dataset. No additional pre-training is necessary to deliver competitive results compared with related work that often requires task-agnostic and task-specific pre-training on cross-modal dadasets. The implementation is publicly available at https://gitlab.com/necla-ml/grounding.



