# Arxiv Papers in cs.CV on 2019-10-16
### Solving Rubik's Cube with a Robot Hand
- **Arxiv ID**: http://arxiv.org/abs/1910.07113v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.07113v1)
- **Published**: 2019-10-16 00:59:05+00:00
- **Updated**: 2019-10-16 00:59:05+00:00
- **Authors**: OpenAI, Ilge Akkaya, Marcin Andrychowicz, Maciek Chociej, Mateusz Litwin, Bob McGrew, Arthur Petron, Alex Paino, Matthias Plappert, Glenn Powell, Raphael Ribas, Jonas Schneider, Nikolas Tezak, Jerry Tworek, Peter Welinder, Lilian Weng, Qiming Yuan, Wojciech Zaremba, Lei Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: We demonstrate that models trained only in simulation can be used to solve a manipulation problem of unprecedented complexity on a real robot. This is made possible by two key components: a novel algorithm, which we call automatic domain randomization (ADR) and a robot platform built for machine learning. ADR automatically generates a distribution over randomized environments of ever-increasing difficulty. Control policies and vision state estimators trained with ADR exhibit vastly improved sim2real transfer. For control policies, memory-augmented models trained on an ADR-generated distribution of environments show clear signs of emergent meta-learning at test time. The combination of ADR with our custom robot platform allows us to solve a Rubik's cube with a humanoid robot hand, which involves both control and state estimation problems. Videos summarizing our results are available: https://openai.com/blog/solving-rubiks-cube/



### Automated Detection of Left Ventricle in Arterial Input Function Images for Inline Perfusion Mapping using Deep Learning: A study of 15,000 Patients
- **Arxiv ID**: http://arxiv.org/abs/1910.07122v2
- **DOI**: 10.1002/mrm.27954
- **Categories**: **q-bio.QM**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07122v2)
- **Published**: 2019-10-16 01:22:38+00:00
- **Updated**: 2020-04-06 21:41:36+00:00
- **Authors**: Hui Xue, Ethan Tseng, Kristopher D Knott, Tushar Kotecha, Louise Brown, Sven Plein, Marianna Fontana, James C Moon, Peter Kellman
- **Comment**: Accepted by Magnetic Resonance in Medicine on March 30, 2020
- **Journal**: None
- **Summary**: Quantification of myocardial perfusion has the potential to improve detection of regional and global flow reduction. Significant effort has been made to automate the workflow, where one essential step is the arterial input function (AIF) extraction. Since failure here invalidates quantification, high accuracy is required. For this purpose, this study presents a robust AIF detection method using the convolutional neural net (CNN) model. CNN models were trained by assembling 25,027 scans (N=12,984 patients) from three hospitals, seven scanners. A test set of 5,721 scans (N=2,805 patients) evaluated model performance. The 2D+T AIF time series was inputted into CNN. Two variations were investigated: a) Two Classes (2CS) for background and foreground (LV mask); b) Three Classes (3CS) for background, foreground LV and RV. Final model was deployed on MR scanners via the Gadgetron InlineAI. Model loading time on MR scanner was ~340ms and applying it took ~180ms. The 3CS model successfully detect LV for 99.98% of all test cases (1 failed out of 5,721 cases). The mean Dice ratio for 3CS was 0.87+/-0.08 with 92.0% of all test cases having Dice ratio >0.75, while the 2CS model gave lower Dice of 0.82+/-0.22 (P<1e-5). Extracted AIF signals using CNN were further compared to manual ground-truth for foot-time, peak-time, first-pass duration, peak value and area-under-curve. No significant differences were found for all features (P>0.2). This study proposed, validated, and deployed a robust CNN solution to detect the LV for the extraction of the AIF signal used in fully automated perfusion flow mapping. A very large data cohort was assembled and resulting models were deployed to MR scanners for fully inline AI in clinical hospitals.



### Large-Scale Landslides Detection from Satellite Images with Incomplete Labels
- **Arxiv ID**: http://arxiv.org/abs/1910.07129v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07129v1)
- **Published**: 2019-10-16 02:04:10+00:00
- **Updated**: 2019-10-16 02:04:10+00:00
- **Authors**: Masanari Kimura
- **Comment**: None
- **Journal**: None
- **Summary**: Earthquakes and tropical cyclones cause the suffering of millions of people around the world every year. The resulting landslides exacerbate the effects of these disasters. Landslide detection is, therefore, a critical task for the protection of human life and livelihood in mountainous areas. To tackle this problem, we propose a combination of satellite technology and Deep Neural Networks (DNNs). We evaluate the performance of multiple DNN-based methods for landslide detection on actual satellite images of landslide damage. Our analysis demonstrates the potential for a meaningful social impact in terms of disasters and rescue.



### Design of a Simple Orthogonal Multiwavelet Filter by Matrix Spectral Factorization
- **Arxiv ID**: http://arxiv.org/abs/1910.07133v2
- **DOI**: 10.1007/s00034-019-01240-9
- **Categories**: **cs.CV**, cs.CE, cs.NA, cs.SY, eess.SY, math.NA, 47Axx, 42Cxx, 65Txx, 65Dxx, 11Cxx, 12Yxx, 13P15, 15BXX, 94Axx,
  97H60, 97R20,, B.7; C.5; E.4; G.1; I.4; I.5; I.6; J.7
- **Links**: [PDF](http://arxiv.org/pdf/1910.07133v2)
- **Published**: 2019-10-16 02:21:52+00:00
- **Updated**: 2021-08-18 22:08:30+00:00
- **Authors**: Vasil Kolev, Todor Cooklev, Fritz Keinert
- **Comment**: This is a preprint of a paper whose final and definite form is
  published in Circuits, Systems, and Signal Processing,, Springer,
  https://link.springer.com/article/10.1007/s00034-019-01240-9, ISSN 0278-081X
  (print), ISSN 1531-5878 (Online)
- **Journal**: None
- **Summary**: We consider the design of an orthogonal symmetric/antisymmetric multiwavelet from its matrix product filter by matrix spectral factorization (MSF). As a test problem, we construct a simple matrix product filter with desirable properties, and factor it using Bauer's method, which in this case can be done in closed form. The corresponding orthogonal multiwavelet function is derived using algebraic techniques which allow symmetry to be considered. This leads to the known orthogonal multiwavelet SA1, which can also be derived directly. We also give a lifting scheme for SA1, investigate the influence of the number of significant digits in the calculations, and show some numerical experiments.



### Consistency-based Semi-supervised Active Learning: Towards Minimizing Labeling Cost
- **Arxiv ID**: http://arxiv.org/abs/1910.07153v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07153v2)
- **Published**: 2019-10-16 03:31:53+00:00
- **Updated**: 2020-07-18 04:21:15+00:00
- **Authors**: Mingfei Gao, Zizhao Zhang, Guo Yu, Sercan O. Arik, Larry S. Davis, Tomas Pfister
- **Comment**: Accepted by ECCV2020
- **Journal**: None
- **Summary**: Active learning (AL) combines data labeling and model training to minimize the labeling cost by prioritizing the selection of high value data that can best improve model performance. In pool-based active learning, accessible unlabeled data are not used for model training in most conventional methods. Here, we propose to unify unlabeled sample selection and model training towards minimizing labeling cost, and make two contributions towards that end. First, we exploit both labeled and unlabeled data using semi-supervised learning (SSL) to distill information from unlabeled data during the training stage. Second, we propose a consistency-based sample selection metric that is coherent with the training objective such that the selected samples are effective at improving model performance. We conduct extensive experiments on image classification tasks. The experimental results on CIFAR-10, CIFAR-100 and ImageNet demonstrate the superior performance of our proposed method with limited labeled data, compared to the existing methods and the alternative AL and SSL combinations. Additionally, we study an important yet under-explored problem -- "When can we start learning-based AL selection?". We propose a measure that is empirically correlated with the AL target loss and is potentially useful for determining the proper starting point of learning-based AL methods.



### Generative Modeling for Small-Data Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1910.07169v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.07169v1)
- **Published**: 2019-10-16 04:57:25+00:00
- **Updated**: 2019-10-16 04:57:25+00:00
- **Authors**: Lanlan Liu, Michael Muelly, Jia Deng, Tomas Pfister, Li-Jia Li
- **Comment**: Published in ICCV 2019
- **Journal**: None
- **Summary**: This paper explores object detection in the small data regime, where only a limited number of annotated bounding boxes are available due to data rarity and annotation expense. This is a common challenge today with machine learning being applied to many new tasks where obtaining training data is more challenging, e.g. in medical images with rare diseases that doctors sometimes only see once in their life-time. In this work we explore this problem from a generative modeling perspective by learning to generate new images with associated bounding boxes, and using these for training an object detector. We show that simply training previously proposed generative models does not yield satisfactory performance due to them optimizing for image realism rather than object detection accuracy. To this end we develop a new model with a novel unrolling mechanism that jointly optimizes the generative model and a detector such that the generated images improve the performance of the detector. We show this method outperforms the state of the art on two challenging datasets, disease detection and small data pedestrian detection, improving the average precision on NIH Chest X-ray by a relative 20% and localization accuracy by a relative 50%.



### Deep Semantic Segmentation of Natural and Medical Images: A Review
- **Arxiv ID**: http://arxiv.org/abs/1910.07655v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07655v3)
- **Published**: 2019-10-16 06:35:50+00:00
- **Updated**: 2020-06-03 22:20:36+00:00
- **Authors**: Saeid Asgari Taghanaki, Kumar Abhishek, Joseph Paul Cohen, Julien Cohen-Adad, Ghassan Hamarneh
- **Comment**: 45 pages, 16 figures. Accepted for publication in Springer Artificial
  Intelligence Review
- **Journal**: None
- **Summary**: The semantic image segmentation task consists of classifying each pixel of an image into an instance, where each instance corresponds to a class. This task is a part of the concept of scene understanding or better explaining the global context of an image. In the medical image analysis domain, image segmentation can be used for image-guided interventions, radiotherapy, or improved radiological diagnostics. In this review, we categorize the leading deep learning-based medical and non-medical image segmentation solutions into six main groups of deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods and provide a comprehensive review of the contributions in each of these groups. Further, for each group, we analyze each variant of these groups and discuss the limitations of the current approaches and present potential future research directions for semantic image segmentation.



### Animating Landscape: Self-Supervised Learning of Decoupled Motion and Appearance for Single-Image Video Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1910.07192v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07192v1)
- **Published**: 2019-10-16 07:20:58+00:00
- **Updated**: 2019-10-16 07:20:58+00:00
- **Authors**: Yuki Endo, Yoshihiro Kanamori, Shigeru Kuriyama
- **Comment**: Published at SIGGRAPH Asia 2019 (ACM Transactions on Graphics)
- **Journal**: None
- **Summary**: Automatic generation of a high-quality video from a single image remains a challenging task despite the recent advances in deep generative models. This paper proposes a method that can create a high-resolution, long-term animation using convolutional neural networks (CNNs) from a single landscape image where we mainly focus on skies and waters. Our key observation is that the motion (e.g., moving clouds) and appearance (e.g., time-varying colors in the sky) in natural scenes have different time scales. We thus learn them separately and predict them with decoupled control while handling future uncertainty in both predictions by introducing latent codes. Unlike previous methods that infer output frames directly, our CNNs predict spatially-smooth intermediate data, i.e., for motion, flow fields for warping, and for appearance, color transfer maps, via self-supervised learning, i.e., without explicitly-provided ground truth. These intermediate data are applied not to each previous output frame, but to the input image only once for each output frame. This design is crucial to alleviate error accumulation in long-term predictions, which is the essential problem in previous recurrent approaches. The output frames can be looped like cinemagraph, and also be controlled directly by specifying latent codes or indirectly via visual annotations. We demonstrate the effectiveness of our method through comparisons with the state-of-the-arts on video prediction as well as appearance manipulation.



### Aerial Images Processing for Car Detection using Convolutional Neural Networks: Comparison between Faster R-CNN and YoloV3
- **Arxiv ID**: http://arxiv.org/abs/1910.07234v3
- **DOI**: 10.3390/electronics10070820
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07234v3)
- **Published**: 2019-10-16 09:25:35+00:00
- **Updated**: 2021-12-22 11:26:29+00:00
- **Authors**: Adel Ammar, Anis Koubaa, Mohanned Ahmed, Abdulrahman Saad, Bilel Benjdira
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we address the problem of car detection from aerial images using Convolutional Neural Networks (CNN). This problem presents additional challenges as compared to car (or any object) detection from ground images because features of vehicles from aerial images are more difficult to discern. To investigate this issue, we assess the performance of two state-of-the-art CNN algorithms, namely Faster R-CNN, which is the most popular region-based algorithm, and YOLOv3, which is known to be the fastest detection algorithm. We analyze two datasets with different characteristics to check the impact of various factors, such as UAV's altitude, camera resolution, and object size. A total of 39 training experiments were conducted to account for the effect of different hyperparameter values. The objective of this work is to conduct the most robust and exhaustive comparison between these two cutting-edge algorithms on the specific domain of aerial images. By using a variety of metrics, we show that YOLOv3 yields better performance in most configurations, except that it exhibits a lower recall and less confident detections when object sizes and scales in the testing dataset differ largely from those in the training dataset.



### Transform the Set: Memory Attentive Generation of Guided and Unguided Image Collages
- **Arxiv ID**: http://arxiv.org/abs/1910.07236v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.07236v2)
- **Published**: 2019-10-16 09:28:40+00:00
- **Updated**: 2019-11-28 10:57:00+00:00
- **Authors**: Nikolay Jetchev, Urs Bergmann, Gökhan Yildirim
- **Comment**: To be presented at the NeurIPS 2019 workshop on Creativity and AI
- **Journal**: None
- **Summary**: Cutting and pasting image segments feels intuitive: the choice of source templates gives artists flexibility in recombining existing source material. Formally, this process takes an image set as input and outputs a collage of the set elements. Such selection from sets of source templates does not fit easily in classical convolutional neural models requiring inputs of fixed size. Inspired by advances in attention and set-input machine learning, we present a novel architecture that can generate in one forward pass image collages of source templates using set-structured representations. This paper has the following contributions: (i) a novel framework for image generation called Memory Attentive Generation of Image Collages (MAGIC) which gives artists new ways to create digital collages; (ii) from the machine-learning perspective, we show a novel Generative Adversarial Networks (GAN) architecture that uses Set-Transformer layers and set-pooling to blend sets of random image samples - a hybrid non-parametric approach.



### Segmentation Criteria in the Problem of Porosity Determination based on CT Scans
- **Arxiv ID**: http://arxiv.org/abs/1910.07328v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1910.07328v1)
- **Published**: 2019-10-16 13:01:25+00:00
- **Updated**: 2019-10-16 13:01:25+00:00
- **Authors**: V. Kokhan, M. Grigoriev, A. Buzmakov, V. Uvarov, A. Ingacheva, E. Shvets, M. Chukalina
- **Comment**: ICMV 2019, 8 pages, 5 figures
- **Journal**: None
- **Summary**: Porous materials are widely used in different applications, in particular they are used to create various filters. Their quality depends on parameters that characterize the internal structure such as porosity, permeability and so on. Computed tomography (CT) allows one to see the internal structure of a porous object without destroying it. The result of tomography is a gray image. To evaluate the desired parameters, the image should be segmented. Traditional intensity threshold approaches did not reliably produce correct results due to limitations with CT images quality. Errors in the evaluation of characteristics of porous materials based on segmented images can lead to the incorrect estimation of their quality and consequently to the impossibility of exploitation, financial losses and even to accidents. It is difficult to perform correctly segmentation due to the strong difference in voxel intensities of the reconstructed object and the presence of noise. Image filtering as a preprocessing procedure is used to improve the quality of segmentation. Nevertheless, there is a problem of choosing an optimal filter. In this work, a method for selecting an optimal filter based on attributive indicator of porous objects (should be free from 'levitating stones' inside of pores) is proposed. In this paper, we use real data where beam hardening artifacts are removed, which allows us to focus on the noise reduction process



### A Generalized and Robust Method Towards Practical Gaze Estimation on Smart Phone
- **Arxiv ID**: http://arxiv.org/abs/1910.07331v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1910.07331v1)
- **Published**: 2019-10-16 13:15:57+00:00
- **Updated**: 2019-10-16 13:15:57+00:00
- **Authors**: Tianchu Guo, Yongchao Liu, Hui Zhang, Xiabing Liu, Youngjun Kwak, Byung In Yoo, Jae-Joon Han, Changkyu Choi
- **Comment**: Accepted by ICCV 2019 Workshop. Fix the error of the Figure 1 in the
  camera ready file
- **Journal**: None
- **Summary**: Gaze estimation for ordinary smart phone, e.g. estimating where the user is looking at on the phone screen, can be applied in various applications. However, the widely used appearance-based CNN methods still have two issues for practical adoption. First, due to the limited dataset, gaze estimation is very likely to suffer from over-fitting, leading to poor accuracy at run time. Second, the current methods are usually not robust, i.e. their prediction results having notable jitters even when the user is performing gaze fixation, which degrades user experience greatly. For the first issue, we propose a new tolerant and talented (TAT) training scheme, which is an iterative random knowledge distillation framework enhanced with cosine similarity pruning and aligned orthogonal initialization. The knowledge distillation is a tolerant teaching process providing diverse and informative supervision. The enhanced pruning and initialization is a talented learning process prompting the network to escape from the local minima and re-born from a better start. For the second issue, we define a new metric to measure the robustness of gaze estimator, and propose an adversarial training based Disturbance with Ordinal loss (DwO) method to improve it. The experimental results show that our TAT method achieves state-of-the-art performance on GazeCapture dataset, and that our DwO method improves the robustness while keeping comparable accuracy.



### Conditional Invertible Flow for Point Cloud Generation
- **Arxiv ID**: http://arxiv.org/abs/1910.07344v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.07344v1)
- **Published**: 2019-10-16 13:47:05+00:00
- **Updated**: 2019-10-16 13:47:05+00:00
- **Authors**: Michał Stypułkowski, Maciej Zamorski, Maciej Zięba, Jan Chorowski
- **Comment**: Published in Sets & Partitions Workshop at NeurIPS 2019
  (https://www.sets.parts/)
- **Journal**: None
- **Summary**: This paper focuses on a novel generative approach for 3D point clouds that makes use of invertible flow-based models. The main idea of the method is to treat a point cloud as a probability density in 3D space that is modeled using a cloud-specific neural network. To capture the similarity between point clouds we rely on parameter sharing among networks, with each cloud having only a small embedding vector that defines it. We use invertible flows networks to generate the individual point clouds, and to regularize the embedding vectors. We evaluate the generative capabilities of the model both in qualitative and quantitative manner.



### Conservation AI: Live Stream Analysis for the Detection of Endangered Species Using Convolutional Neural Networks and Drone Technology
- **Arxiv ID**: http://arxiv.org/abs/1910.07360v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1910.07360v1)
- **Published**: 2019-10-16 14:11:24+00:00
- **Updated**: 2019-10-16 14:11:24+00:00
- **Authors**: C. Chalmers, P. Fergus, Serge Wich, Aday Curbelo Montanez
- **Comment**: The papaer is 10 pages and contains 11 images and 1 table
- **Journal**: None
- **Summary**: Many different species are adversely affected by poaching. In response to this escalating crisis, efforts to stop poaching using hidden cameras, drones and DNA tracking have been implemented with varying degrees of success. Limited resources, costs and logistical limitations are often the cause of most unsuccessful poaching interventions. The study presented in this paper outlines a flexible and interoperable framework for the automatic detection of animals and poaching activity to facilitate early intervention practices. Using a robust deep learning pipeline, a convolutional neural network is trained and implemented to detect rhinos and cars (considered an important tool in poaching for fast access and artefact transportation in natural habitats) in the study, that are found within live video streamed from drones Transfer learning with the Faster RCNN Resnet 101 is performed to train a custom model with 350 images of rhinos and 350 images of cars. Inference is performed using a frame sampling technique to address the required trade-off control precision and processing speed and maintain synchronisation with the live feed. Inference models are hosted on a web platform using flask web serving, OpenCV and TensorFlow 1.13. Video streams are transmitted from a DJI Mavic Pro 2 drone using the Real-Time Messaging Protocol (RMTP). The best trained Faster RCNN model achieved a mAP of 0.83 @IOU 0.50 and 0.69 @IOU 0.75 respectively. In comparison an SSD-mobilenetmodel trained under the same experimental conditions achieved a mAP of 0.55 @IOU .50 and 0.27 @IOU 0.75.The results demonstrate that using a FRCNN and off-the-shelf drones is a promising and scalable option for a range of conservation projects.



### Iterative Augmentation of Visual Evidence for Weakly-Supervised Lesion Localization in Deep Interpretability Frameworks: Application to Color Fundus Images
- **Arxiv ID**: http://arxiv.org/abs/1910.07373v2
- **DOI**: 10.1109/TMI.2020.2994463
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1910.07373v2)
- **Published**: 2019-10-16 14:30:47+00:00
- **Updated**: 2022-02-01 14:09:12+00:00
- **Authors**: Cristina González-Gonzalo, Bart Liefers, Bram van Ginneken, Clara I. Sánchez
- **Comment**: None
- **Journal**: IEEE Transactions on Medical Imaging. Available online 18 May 2020
- **Summary**: Interpretability of deep learning (DL) systems is gaining attention in medical imaging to increase experts' trust in the obtained predictions and facilitate their integration in clinical settings. We propose a deep visualization method to generate interpretability of DL classification tasks in medical imaging by means of visual evidence augmentation. The proposed method iteratively unveils abnormalities based on the prediction of a classifier trained only with image-level labels. For each image, initial visual evidence of the prediction is extracted with a given visual attribution technique. This provides localization of abnormalities that are then removed through selective inpainting. We iteratively apply this procedure until the system considers the image as normal. This yields augmented visual evidence, including less discriminative lesions which were not detected at first but should be considered for final diagnosis. We apply the method to grading of two retinal diseases in color fundus images: diabetic retinopathy (DR) and age-related macular degeneration (AMD). We evaluate the generated visual evidence and the performance of weakly-supervised localization of different types of DR and AMD abnormalities, both qualitatively and quantitatively. We show that the augmented visual evidence of the predictions highlights the biomarkers considered by experts for diagnosis and improves the final localization performance. It results in a relative increase of 11.2+/-2.0% per image regarding sensitivity averaged at 10 false positives/image on average, when applied to different classification tasks, visual attribution techniques and network architectures. This makes the proposed method a useful tool for exhaustive visual support of DL classifiers in medical imaging.



### Offline handwritten mathematical symbol recognition utilising deep learning
- **Arxiv ID**: http://arxiv.org/abs/1910.07395v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.6; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1910.07395v1)
- **Published**: 2019-10-16 15:02:07+00:00
- **Updated**: 2019-10-16 15:02:07+00:00
- **Authors**: Azadeh Nazemi, Niloofar Tavakolian, Donal Fitzpatrick, Chandrik a Fernando, Ching Y. Suen
- **Comment**: None
- **Journal**: None
- **Summary**: This paper describes an approach for offline recognition of handwritten mathematical symbols. The process of symbol recognition in this paper includes symbol segmentation and accurate classification for over 300 classes. Many multidimensional mathematical symbols need both horizontal and vertical projection to be segmented. However, some symbols do not permit to be projected and stop segmentation, such as the root symbol. Besides, many mathematical symbols are structurally similar, specifically in handwritten such as 0 and null. There are more than 300 Mathematical symbols. Therefore, designing an accurate classifier for more than 300 classes is required. This paper initially addresses the issue regarding segmentation using Simple Linear Iterative Clustering (SLIC). Experimental results indicate that the accuracy of the designed kNN classifier is 84% for salient, 57% Histogram of Oriented Gradient (HOG), 53% for Linear Binary Pattern (LBP) and finally 43% for pixel intensity of raw image for 66 classes. 87 classes using modified LeNet represents 90% accuracy. Finally, for 101 classes, SqueezeNet ac



### On the Global Optima of Kernelized Adversarial Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1910.07423v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.07423v2)
- **Published**: 2019-10-16 15:37:14+00:00
- **Updated**: 2019-12-25 16:41:09+00:00
- **Authors**: Bashir Sadeghi, Runyi Yu, Vishnu Naresh Boddeti
- **Comment**: Accepted for publication at ICCV 2019. This version includes
  additional theoretical and experimental analysis. Minor update to the GMM
  experiment
- **Journal**: None
- **Summary**: Adversarial representation learning is a promising paradigm for obtaining data representations that are invariant to certain sensitive attributes while retaining the information necessary for predicting target attributes. Existing approaches solve this problem through iterative adversarial minimax optimization and lack theoretical guarantees. In this paper, we first study the "linear" form of this problem i.e., the setting where all the players are linear functions. We show that the resulting optimization problem is both non-convex and non-differentiable. We obtain an exact closed-form expression for its global optima through spectral learning and provide performance guarantees in terms of analytical bounds on the achievable utility and invariance. We then extend this solution and analysis to non-linear functions through kernel representation. Numerical experiments on UCI, Extended Yale B and CIFAR-100 datasets indicate that, (a) practically, our solution is ideal for "imparting" provable invariance to any biased pre-trained data representation, and (b) empirically, the trade-off between utility and invariance provided by our solution is comparable to iterative minimax optimization of existing deep neural network based approaches. Code is available at https://github.com/human-analysis/Kernel-ARL



### Gaze Gestures and Their Applications in human-computer interaction with a head-mounted display
- **Arxiv ID**: http://arxiv.org/abs/1910.07428v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07428v1)
- **Published**: 2019-10-16 15:42:10+00:00
- **Updated**: 2019-10-16 15:42:10+00:00
- **Authors**: W. X. Chen, X. Y. Cui, J. Zheng, J. M. Zhang, S. Chen, Y. D. Yao
- **Comment**: None
- **Journal**: None
- **Summary**: A head-mounted display (HMD) is a portable and interactive display device. With the development of 5G technology, it may become a general-purpose computing platform in the future. Human-computer interaction (HCI) technology for HMDs has also been of significant interest in recent years. In addition to tracking gestures and speech, tracking human eyes as a means of interaction is highly effective. In this paper, we propose two UnityEyes-based convolutional neural network models, UEGazeNet and UEGazeNet*, which can be used for input images with low resolution and high resolution, respectively. These models can perform rapid interactions by classifying gaze trajectories (GTs), and a GTgestures dataset containing data for 10,200 "eye-painting gestures" collected from 15 individuals is established with our gaze-tracking method. We evaluated the performance both indoors and outdoors and the UEGazeNet can obtaine results 52\% and 67\% better than those of state-of-the-art networks. The generalizability of our GTgestures dataset using a variety of gaze-tracking models is evaluated, and an average recognition rate of 96.71\% is obtained by our method.



### Label-Conditioned Next-Frame Video Generation with Neural Flows
- **Arxiv ID**: http://arxiv.org/abs/1910.11106v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.11106v1)
- **Published**: 2019-10-16 16:08:28+00:00
- **Updated**: 2019-10-16 16:08:28+00:00
- **Authors**: David Donahue
- **Comment**: Computer Vision class project, 9 pages
- **Journal**: None
- **Summary**: Recent state-of-the-art video generation systems employ Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs) to produce novel videos. However, VAE models typically produce blurry outputs when faced with sub-optimal conditioning of the input, and GANs are known to be unstable for large output sizes. In addition, the output videos of these models are difficult to evaluate, partly because the GAN loss function is not an accurate measure of convergence. In this work, we propose using a state-of-the-art neural flow generator called Glow to generate videos conditioned on a textual label, one frame at a time. Neural flow models are more stable than standard GANs, as they only optimize a single cross entropy loss function, which is monotonic and avoids the circular convergence issues of the GAN minimax objective. In addition, we also show how to condition Glow on external context, while still preserving the invertible nature of each "flow" layer. Finally, we evaluate the proposed Glow model by calculating cross entropy on a held-out validation set of videos, in order to compare multiple versions of the proposed model via an ablation study. We show generated videos and discuss future improvements.



### A Survey on Recent Advancements for AI Enabled Radiomics in Neuro-Oncology
- **Arxiv ID**: http://arxiv.org/abs/1910.07470v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07470v1)
- **Published**: 2019-10-16 16:50:02+00:00
- **Updated**: 2019-10-16 16:50:02+00:00
- **Authors**: Syed Muhammad Anwar, Tooba Altaf, Khola Rafique, Harish RaviPrakash, Hassan Mohy-ud-Din, Ulas Bagci
- **Comment**: Accepted in MICCAI RNO workshop
- **Journal**: None
- **Summary**: Artificial intelligence (AI) enabled radiomics has evolved immensely especially in the field of oncology. Radiomics provide assistancein diagnosis of cancer, planning of treatment strategy, and predictionof survival. Radiomics in neuro-oncology has progressed significantly inthe recent past. Deep learning has outperformed conventional machinelearning methods in most image-based applications. Convolutional neu-ral networks (CNNs) have seen some popularity in radiomics, since theydo not require hand-crafted features and can automatically extract fea-tures during the learning process. In this regard, it is observed that CNNbased radiomics could provide state-of-the-art results in neuro-oncology,similar to the recent success of such methods in a wide spectrum ofmedical image analysis applications. Herein we present a review of the most recent best practices and establish the future trends for AI enabled radiomics in neuro-oncology.



### Adaptive and Iteratively Improving Recurrent Lateral Connections
- **Arxiv ID**: http://arxiv.org/abs/1910.11105v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.11105v1)
- **Published**: 2019-10-16 16:58:26+00:00
- **Updated**: 2019-10-16 16:58:26+00:00
- **Authors**: Barak Battash, Lior Wolf
- **Comment**: None
- **Journal**: None
- **Summary**: The current leading computer vision models are typically feed forward neural models, in which the output of one computational block is passed to the next one sequentially. This is in sharp contrast to the organization of the primate visual cortex, in which feedback and lateral connections are abundant. In this work, we propose a computational model for the role of lateral connections in a given block, in which the weights of the block vary dynamically as a function of its activations, and the input from the upstream blocks is iteratively reintroduced. We demonstrate how this novel architectural modification can lead to sizable gains in performance, when applied to visual action recognition without pretraining and that it outperforms the literature architectures with recurrent feedback processing on ImageNet.



### LOST: A flexible framework for semi-automatic image annotation
- **Arxiv ID**: http://arxiv.org/abs/1910.07486v2
- **DOI**: None
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1910.07486v2)
- **Published**: 2019-10-16 17:34:27+00:00
- **Updated**: 2019-11-04 09:27:34+00:00
- **Authors**: Jonas Jäger, Gereon Reus, Joachim Denzler, Viviane Wolff, Klaus Fricke-Neuderth
- **Comment**: Under review at: Computer Vision and Image Understanding
- **Journal**: None
- **Summary**: State-of-the-art computer vision approaches rely on huge amounts of annotated data. The collection of such data is a time consuming process since it is mainly performed by humans. The literature shows that semi-automatic annotation approaches can significantly speed up the annotation process by the automatic generation of annotation proposals to support the annotator. In this paper we present a framework that allows for a quick and flexible design of semi-automatic annotation pipelines. We show that a good design of the process will speed up the collection of annotations. Our contribution is a new approach to image annotation that allows for the combination of different annotation tools and machine learning algorithms in one process. We further present potential applications of our approach. The source code of our framework called LOST (Label Objects and Save Time) is available at: https://github.com/l3p-cv/lost.



### Exploiting video sequences for unsupervised disentangling in generative adversarial networks
- **Arxiv ID**: http://arxiv.org/abs/1910.11104v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1910.11104v1)
- **Published**: 2019-10-16 17:37:43+00:00
- **Updated**: 2019-10-16 17:37:43+00:00
- **Authors**: Facundo Tuesca, Lucas C. Uzal
- **Comment**: This preprint is the result of the work done for the undergraduate
  dissertation of F. Tuesca supervised by L.C. Uzal and presented in June 2018
- **Journal**: None
- **Summary**: In this work we present an adversarial training algorithm that exploits correlations in video to learn --without supervision-- an image generator model with a disentangled latent space. The proposed methodology requires only a few modifications to the standard algorithm of Generative Adversarial Networks (GAN) and involves training with sets of frames taken from short videos. We train our model over two datasets of face-centered videos which present different people speaking or moving the head: VidTIMIT and YouTube Faces datasets. We found that our proposal allows us to split the generator latent space into two subspaces. One of them controls content attributes, those that do not change along short video sequences. For the considered datasets, this is the identity of the generated face. The other subspace controls motion attributes, those attributes that are observed to change along short videos. We observed that these motion attributes are face expressions, head orientation, lips and eyes movement. The presented experiments provide quantitative and qualitative evidence supporting that the proposed methodology induces a disentangling of this two kinds of attributes in the latent space.



### Global Saliency: Aggregating Saliency Maps to Assess Dataset Artefact Bias
- **Arxiv ID**: http://arxiv.org/abs/1910.07604v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1910.07604v2)
- **Published**: 2019-10-16 20:45:19+00:00
- **Updated**: 2019-12-04 00:14:28+00:00
- **Authors**: Jacob Pfau, Albert T. Young, Maria L. Wei, Michael J. Keiser
- **Comment**: Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended
  Abstract
- **Journal**: None
- **Summary**: In high-stakes applications of machine learning models, interpretability methods provide guarantees that models are right for the right reasons. In medical imaging, saliency maps have become the standard tool for determining whether a neural model has learned relevant robust features, rather than artefactual noise. However, saliency maps are limited to local model explanation because they interpret predictions on an image-by-image basis. We propose aggregating saliency globally, using semantic segmentation masks, to provide quantitative measures of model bias across a dataset. To evaluate global saliency methods, we propose two metrics for quantifying the validity of saliency explanations. We apply the global saliency method to skin lesion diagnosis to determine the effect of artefacts, such as ink, on model bias.



### Conditional Driving from Natural Language Instructions
- **Arxiv ID**: http://arxiv.org/abs/1910.07615v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07615v1)
- **Published**: 2019-10-16 21:14:08+00:00
- **Updated**: 2019-10-16 21:14:08+00:00
- **Authors**: Junha Roh, Chris Paxton, Andrzej Pronobis, Ali Farhadi, Dieter Fox
- **Comment**: Accepted by the 3rd Conference on Robot Learning, Osaka, Japan (CoRL
  2019)
- **Journal**: None
- **Summary**: Widespread adoption of self-driving cars will depend not only on their safety but largely on their ability to interact with human users. Just like human drivers, self-driving cars will be expected to understand and safely follow natural-language directions that suddenly alter the pre-planned route according to user's preference or in presence of ambiguities, particularly in locations with poor or outdated map coverage. To this end, we propose a language-grounded driving agent implementing a hierarchical policy using recurrent layers and gated attention. The hierarchical approach enables us to reason both in terms of high-level language instructions describing long time horizons and low-level, complex, continuous state/action spaces required for real-time control of a self-driving car. We train our policy with conditional imitation learning from realistic language data collected from human drivers and navigators. Through quantitative and interactive experiments within the CARLA framework, we show that our model can successfully interpret language instructions and follow them safely, even when generalizing to previously unseen environments. Code and video are available at https://sites.google.com/view/language-grounded-driving.



### Optimal Transport Based Generative Autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1910.07636v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1910.07636v1)
- **Published**: 2019-10-16 22:01:51+00:00
- **Updated**: 2019-10-16 22:01:51+00:00
- **Authors**: Oliver Zhang, Ruei-Sung Lin, Yuchuan Gou
- **Comment**: 15 pages
- **Journal**: None
- **Summary**: The field of deep generative modeling is dominated by generative adversarial networks (GANs). However, the training of GANs often lacks stability, fails to converge, and suffers from model collapse. It takes an assortment of tricks to solve these problems, which may be difficult to understand for those seeking to apply generative modeling. Instead, we propose two novel generative autoencoders, AE-OTtrans and AE-OTgen, which rely on optimal transport instead of adversarial training. AE-OTtrans and AEOTgen, unlike VAE and WAE, preserve the manifold of the data; they do not force the latent distribution to match a normal distribution, resulting in greater quality images. AEOTtrans and AE-OTgen also produce images of higher diversity compared to their predecessor, AE-OT. We show that AE-OTtrans and AE-OTgen surpass GANs in the MNIST and FashionMNIST datasets. Furthermore, We show that AE-OTtrans and AE-OTgen do state of the art on the MNIST, FashionMNIST, and CelebA image sets comapred to other non-adversarial generative models.



### CFEA: Collaborative Feature Ensembling Adaptation for Domain Adaptation in Unsupervised Optic Disc and Cup Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1910.07638v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1910.07638v1)
- **Published**: 2019-10-16 22:11:16+00:00
- **Updated**: 2019-10-16 22:11:16+00:00
- **Authors**: Peng Liu, Bin Kong, Zhongyu Li, Shaoting Zhang, Ruogu Fang
- **Comment**: None
- **Journal**: the 22nd International Conference on Medical Image Computing and
  Computer Assisted Intervention (MICCAI 2019)
- **Summary**: Recently, deep neural networks have demonstrated comparable and even better performance with board-certified ophthalmologists in well-annotated datasets. However, the diversity of retinal imaging devices poses a significant challenge: domain shift, which leads to performance degradation when applying the deep learning models to new testing domains. In this paper, we propose a novel unsupervised domain adaptation framework, called Collaborative Feature Ensembling Adaptation (CFEA), to effectively overcome this challenge. Our proposed CFEA is an interactive paradigm which presents an exquisite of collaborative adaptation through both adversarial learning and ensembling weights. In particular, we simultaneously achieve domain-invariance and maintain an exponential moving average of the historical predictions, which achieves a better prediction for the unlabeled data, via ensembling weights during training. Without annotating any sample from the target domain, multiple adversarial losses in encoder and decoder layers guide the extraction of domain-invariant features to confuse the domain classifier and meanwhile benefit the ensembling of smoothing weights. Comprehensive experimental results demonstrate that our CFEA model can overcome performance degradation and outperform the state-of-the-art methods in segmenting retinal optic disc and cup from fundus images. \textit{Code is available at \url{https://github.com/cswin/AWC}}.



### A Combined Deep Learning-Gradient Boosting Machine Framework for Fluid Intelligence Prediction
- **Arxiv ID**: http://arxiv.org/abs/1910.07640v1
- **DOI**: 10.1007/978-3-030-31901-4_1
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1910.07640v1)
- **Published**: 2019-10-16 22:32:13+00:00
- **Updated**: 2019-10-16 22:32:13+00:00
- **Authors**: Yeeleng S. Vang, Yingxin Cao, Xiaohui Xie
- **Comment**: Challenge in Adolescent Brain Cognitive Development Neurocognitive
  Prediction
- **Journal**: In: Pohl K., Thompson W., Adeli E., Linguraru M. (eds) Adolescent
  Brain Cognitive Development Neurocognitive Prediction. ABCD-NP 2019. Lecture
  Notes in Computer Science, vol 11791. Springer, Cham (2019)
- **Summary**: The ABCD Neurocognitive Prediction Challenge is a community driven competition asking competitors to develop algorithms to predict fluid intelligence score from T1-w MRIs. In this work, we propose a deep learning combined with gradient boosting machine framework to solve this task. We train a convolutional neural network to compress the high dimensional MRI data and learn meaningful image features by predicting the 123 continuous-valued derived data provided with each MRI. These extracted features are then used to train a gradient boosting machine that predicts the residualized fluid intelligence score. Our approach achieved mean square error (MSE) scores of 18.4374, 68.7868, and 96.1806 for the training, validation, and test set respectively.



### RGB-D Individual Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1910.07641v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1910.07641v2)
- **Published**: 2019-10-16 22:41:16+00:00
- **Updated**: 2019-11-11 04:18:39+00:00
- **Authors**: Wenqiang Xu, Yanjun Fu, Yuchen Luo, Chang Liu, Cewu Lu
- **Comment**: We found some significant errors which could influence the
  correctness of this paper, and we still need more time to find our solutions
- **Journal**: None
- **Summary**: Fine-grained recognition task deals with sub-category classification problem, which is important for real-world applications. In this work, we are particularly interested in the segmentation task on the \emph{finest-grained} level, which is specifically named "individual segmentation". In other words, the individual-level category has no sub-category under it. Segmentation problem in the individual level reveals some new properties, limited training data for single individual object, unknown background, and difficulty for the use of depth. To address these new problems, we propose a "Context Less-Aware" (CoLA) pipeline, which produces RGB-D object-predominated images that have less background context, and enables a scale-aware training and testing with 3D information. Extensive experiments show that the proposed CoLA strategy largely outperforms baseline methods on YCB-Video dataset and our proposed Supermarket-10K dataset. Code, trained model and new dataset will be published with this paper.



### SPEC2: SPECtral SParsE CNN Accelerator on FPGAs
- **Arxiv ID**: http://arxiv.org/abs/1910.11103v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1910.11103v1)
- **Published**: 2019-10-16 23:30:22+00:00
- **Updated**: 2019-10-16 23:30:22+00:00
- **Authors**: Yue Niu, Hanqing Zeng, Ajitesh Srivastava, Kartik Lakhotia, Rajgopal Kannan, Yanzhi Wang, Viktor Prasanna
- **Comment**: This is a 10-page conference paper in 26TH IEEE International
  Conference On High Performance Computing, Data, and Analytics (HiPC)
- **Journal**: None
- **Summary**: To accelerate inference of Convolutional Neural Networks (CNNs), various techniques have been proposed to reduce computation redundancy. Converting convolutional layers into frequency domain significantly reduces the computation complexity of the sliding window operations in space domain. On the other hand, weight pruning techniques address the redundancy in model parameters by converting dense convolutional kernels into sparse ones. To obtain high-throughput FPGA implementation, we propose SPEC2 -- the first work to prune and accelerate spectral CNNs. First, we propose a systematic pruning algorithm based on Alternative Direction Method of Multipliers (ADMM). The offline pruning iteratively sets the majority of spectral weights to zero, without using any handcrafted heuristics. Then, we design an optimized pipeline architecture on FPGA that has efficient random access into the sparse kernels and exploits various dimensions of parallelism in convolutional layers. Overall, SPEC2 achieves high inference throughput with extremely low computation complexity and negligible accuracy degradation. We demonstrate SPEC2 by pruning and implementing LeNet and VGG16 on the Xilinx Virtex platform. After pruning 75% of the spectral weights, SPEC2 achieves 0% accuracy loss for LeNet, and <1% accuracy loss for VGG16. The resulting accelerators achieve up to 24x higher throughput, compared with the state-of-the-art FPGA implementations for VGG16.



