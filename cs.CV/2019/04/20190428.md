# Arxiv Papers in cs.CV on 2019-04-28
### Weighted Dark Channel Dehazing
- **Arxiv ID**: http://arxiv.org/abs/1904.12245v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12245v1)
- **Published**: 2019-04-28 02:30:53+00:00
- **Updated**: 2019-04-28 02:30:53+00:00
- **Authors**: Zhu Mingzhu, He Bingwei, Liu Jiantao
- **Comment**: None
- **Journal**: None
- **Summary**: In dark channel based methods, local constant assumption is widely used to make the algorithms invertible. It inevitably introduces defects since the assumption can not perfectly avoid depth discontinuities and meanwhile cover enough pixels. Unfortunately, because of the limitation of the prior, which only confirms the existence of dark things but does not specify their locations or likelihood, no fidelity measurement is available in refinement thus the defects are either under-corrected or over-corrected. In this paper, we go deeper than the dark channel theory to overcome this problem. We split the concept of dark channel into dark pixels and local constant assumption, and then, control the problematic assumption based on a novel weight map. With such effort, our methods show significant improvement on quality and have competitive speed. In the last, we show that the method is highly robust to initial transmission estimates and can be ever-improved by providing better dark pixel locations.



### Supervised Online Hashing via Hadamard Codebook Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.03694v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1905.03694v2)
- **Published**: 2019-04-28 02:33:53+00:00
- **Updated**: 2019-05-24 18:02:53+00:00
- **Authors**: Mingbao Lin, Rongrong Ji, Hong Liu, Yongjian Liu
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, binary code learning, a.k.a hashing, has received extensive attention in large-scale multimedia retrieval. It aims to encode high-dimensional data points to binary codes, hence the original high-dimensional metric space can be efficiently approximated via Hamming space. However, most existing hashing methods adopted offline batch learning, which is not suitable to handle incremental datasets with streaming data or new instances. In contrast, the robustness of the existing online hashing remains as an open problem, while the embedding of supervised/semantic information hardly boosts the performance of the online hashing, mainly due to the defect of unknown category numbers in supervised learning. In this paper, we proposed an online hashing scheme, termed Hadamard Codebook based Online Hashing (HCOH), which aims to solve the above problems towards robust and supervised online hashing. In particular, we first assign an appropriate high-dimensional binary codes to each class label, which is generated randomly by Hadamard codes to each class label, which is generated randomly by Hadamard codes. Subsequently, LSH is adopted to reduce the length of such Hadamard codes in accordance with the hash bits, which can adapt the predefined binary codes online, and theoretically guarantee the semantic similarity. Finally, we consider the setting of stochastic data acquisition, which facilitates our method to efficiently learn the corresponding hashing functions via stochastic gradient descend (SGD) online. Notably, the proposed HCOH can be embedded with supervised labels and it not limited to a predefined category number. Extensive experiments on three widely-used benchmarks demonstrate the merits of the proposed scheme over the state-of-the-art methods. The code is available at https://github.com/lmbxmu/mycode/tree/master/2018ACMMM_HCOH.



### Hierarchical Recurrent Neural Network for Video Summarization
- **Arxiv ID**: http://arxiv.org/abs/1904.12251v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12251v1)
- **Published**: 2019-04-28 03:32:21+00:00
- **Updated**: 2019-04-28 03:32:21+00:00
- **Authors**: Bin Zhao, Xuelong Li, Xiaoqiang Lu
- **Comment**: published by ACM Conference on MultiMedia
- **Journal**: None
- **Summary**: Exploiting the temporal dependency among video frames or subshots is very important for the task of video summarization. Practically, RNN is good at temporal dependency modeling, and has achieved overwhelming performance in many video-based tasks, such as video captioning and classification. However, RNN is not capable enough to handle the video summarization task, since traditional RNNs, including LSTM, can only deal with short videos, while the videos in the summarization task are usually in longer duration. To address this problem, we propose a hierarchical recurrent neural network for video summarization, called H-RNN in this paper. Specifically, it has two layers, where the first layer is utilized to encode short video subshots cut from the original video, and the final hidden state of each subshot is input to the second layer for calculating its confidence to be a key subshot. Compared to traditional RNNs, H-RNN is more suitable to video summarization, since it can exploit long temporal dependency among frames, meanwhile, the computation operations are significantly lessened. The results on two popular datasets, including the Combined dataset and VTW dataset, have demonstrated that the proposed H-RNN outperforms the state-of-the-arts.



### Translate-to-Recognize Networks for RGB-D Scene Recognition
- **Arxiv ID**: http://arxiv.org/abs/1904.12254v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12254v1)
- **Published**: 2019-04-28 03:51:23+00:00
- **Updated**: 2019-04-28 03:51:23+00:00
- **Authors**: Dapeng Du, Limin Wang, Huiling Wang, Kai Zhao, Gangshan Wu
- **Comment**: Accepted by CVPR 2019. Project:
  https://ownstyledu.github.io/Translate-to-Recognize-Networks/
- **Journal**: None
- **Summary**: Cross-modal transfer is helpful to enhance modality-specific discriminative power for scene recognition. To this end, this paper presents a unified framework to integrate the tasks of cross-modal translation and modality-specific recognition, termed as Translate-to-Recognize Network (TRecgNet). Specifically, both translation and recognition tasks share the same encoder network, which allows to explicitly regularize the training of recognition task with the help of translation, and thus improve its final generalization ability. For translation task, we place a decoder module on top of the encoder network and it is optimized with a new layer-wise semantic loss, while for recognition task, we use a linear classifier based on the feature embedding from encoder and its training is guided by the standard cross-entropy loss. In addition, our TRecgNet allows to exploit large numbers of unlabeled RGB-D data to train the translation task and thus improve the representation power of encoder network. Empirically, we verify that this new semi-supervised setting is able to further enhance the performance of recognition network. We perform experiments on two RGB-D scene recognition benchmarks: NYU Depth v2 and SUN RGB-D, demonstrating that TRecgNet achieves superior performance to the existing state-of-the-art methods, especially for recognition solely based on a single modality.



### Spatio-Temporal Filter Adaptive Network for Video Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1904.12257v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12257v2)
- **Published**: 2019-04-28 04:35:19+00:00
- **Updated**: 2019-08-01 07:34:25+00:00
- **Authors**: Shangchen Zhou, Jiawei Zhang, Jinshan Pan, Haozhe Xie, Wangmeng Zuo, Jimmy Ren
- **Comment**: ICCV 2019
- **Journal**: None
- **Summary**: Video deblurring is a challenging task due to the spatially variant blur caused by camera shake, object motions, and depth variations, etc. Existing methods usually estimate optical flow in the blurry video to align consecutive frames or approximate blur kernels. However, they tend to generate artifacts or cannot effectively remove blur when the estimated optical flow is not accurate. To overcome the limitation of separate optical flow estimation, we propose a Spatio-Temporal Filter Adaptive Network (STFAN) for the alignment and deblurring in a unified framework. The proposed STFAN takes both blurry and restored images of the previous frame as well as blurry image of the current frame as input, and dynamically generates the spatially adaptive filters for the alignment and deblurring. We then propose the new Filter Adaptive Convolutional (FAC) layer to align the deblurred features of the previous frame with the current frame and remove the spatially variant blur from the features of the current frame. Finally, we develop a reconstruction network which takes the fusion of two transformed features to restore the clear frames. Both quantitative and qualitative evaluation results on the benchmark datasets and real-world videos demonstrate that the proposed algorithm performs favorably against state-of-the-art methods in terms of accuracy, speed as well as model size.



### Improving Image-Based Localization with Deep Learning: The Impact of the Loss Function
- **Arxiv ID**: http://arxiv.org/abs/1905.03692v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1905.03692v2)
- **Published**: 2019-04-28 05:47:37+00:00
- **Updated**: 2019-07-28 13:06:02+00:00
- **Authors**: Isaac Ronald Ward, M. A. Asim K. Jalwana, Mohammed Bennamoun
- **Comment**: Version 2
- **Journal**: None
- **Summary**: This work investigates the impact of the loss function on the performance of Neural Networks, in the context of a monocular, RGB-only, image localization task. A common technique used when regressing a camera's pose from an image is to formulate the loss as a linear combination of positional and rotational mean squared error (using tuned hyperparameters as coefficients). In this work we observe that changes to rotation and position mutually affect the captured image, and in order to improve performance, a pose regression network's loss function should include a term which combines the error of both of these coupled quantities. Based on task specific observations and experimental tuning, we present said loss term, and create a new model by appending this loss term to the loss function of the pre-existing pose regression network `PoseNet'. We achieve improvements in the localization accuracy of the network for indoor scenes; with decreases of up to 26.7% and 24.0% in the median positional and rotational error respectively, when compared to the default PoseNet.



### X-Ray Image Compression Using Convolutional Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1904.12271v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1904.12271v2)
- **Published**: 2019-04-28 07:40:41+00:00
- **Updated**: 2019-05-09 16:05:36+00:00
- **Authors**: Asif Shahriyar Sushmit, Shakib Uz Zaman, Ahmed Imtiaz Humayun, Taufiq Hasan, Mohammed Imamul Hassan Bhuiyan
- **Comment**: 4 pages, 2 figures, IEEE BHI 2019
- **Journal**: None
- **Summary**: In the advent of a digital health revolution, vast amounts of clinical data are being generated, stored and processed on a daily basis. This has made the storage and retrieval of large volumes of health-care data, especially, high-resolution medical images, particularly challenging. Effective image compression for medical images thus plays a vital role in today's healthcare information system, particularly in teleradiology. In this work, an X-ray image compression method based on a Convolutional Recurrent Neural Networks RNN-Conv is presented. The proposed architecture can provide variable compression rates during deployment while it requires each network to be trained only once for a specific dimension of X-ray images. The model uses a multi-level pooling scheme that learns contextualized features for effective compression. We perform our image compression experiments on the National Institute of Health (NIH) ChestX-ray8 dataset and compare the performance of the proposed architecture with a state-of-the-art RNN based technique and JPEG 2000. The experimental results depict improved compression performance achieved by the proposed method in terms of Structural Similarity Index (SSIM) and Peak Signal-to-Noise Ratio (PSNR) metrics. To the best of our knowledge, this is the first reported evaluation on using a deep convolutional RNN for medical image compression.



### Robust subspace clustering by Cauchy loss function
- **Arxiv ID**: http://arxiv.org/abs/1904.12274v1
- **DOI**: 10.1109/TNNLS.2018.2876327.
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12274v1)
- **Published**: 2019-04-28 07:58:27+00:00
- **Updated**: 2019-04-28 07:58:27+00:00
- **Authors**: Xuelong Li, Quanmao Lu, Yongsheng Dong, Dacheng Tao
- **Comment**: 13 pages, 5 figures
- **Journal**: IEEE Transactions on Neural Networks and Learning Systems, 2018
- **Summary**: Subspace clustering is a problem of exploring the low-dimensional subspaces of high-dimensional data. State-of-the-arts approaches are designed by following the model of spectral clustering based method. These methods pay much attention to learn the representation matrix to construct a suitable similarity matrix and overlook the influence of the noise term on subspace clustering. However, the real data are always contaminated by the noise and the noise usually has a complicated statistical distribution. To alleviate this problem, we in this paper propose a subspace clustering method based on Cauchy loss function (CLF). Particularly, it uses CLF to penalize the noise term for suppressing the large noise mixed in the real data. This is due to that the CLF's influence function has a upper bound which can alleviate the influence of a single sample, especially the sample with a large noise, on estimating the residuals. Furthermore, we theoretically prove the grouping effect of our proposed method, which means that highly correlated data can be grouped together. Finally, experimental results on five real datasets reveal that our proposed method outperforms several representative clustering methods.



### 3D Dynamic Point Cloud Denoising via Spatial-Temporal Graph Learning
- **Arxiv ID**: http://arxiv.org/abs/1904.12284v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1904.12284v2)
- **Published**: 2019-04-28 09:07:26+00:00
- **Updated**: 2020-04-08 04:06:17+00:00
- **Authors**: Wei Hu, Qianjiang Hu, Zehua Wang, Xiang Gao
- **Comment**: None
- **Journal**: None
- **Summary**: The prevalence of accessible depth sensing and 3D laser scanning techniques has enabled the convenient acquisition of 3D dynamic point clouds, which provide efficient representation of arbitrarily-shaped objects in motion. Nevertheless, dynamic point clouds are often perturbed by noise due to hardware, software or other causes. While a plethora of methods have been proposed for static point cloud denoising, few efforts are made for the denoising of dynamic point clouds with varying number of irregularly-sampled points in each frame. In this paper, we represent dynamic point clouds naturally on graphs and address the denoising problem by inferring the underlying graph via spatio-temporal graph learning, exploiting both the intra-frame similarity and inter-frame consistency. Firstly, assuming the availability of a relevant feature vector per node, we pose spatial-temporal graph learning as optimizing a Mahalanobis distance metric $\mathbf{M}$, which is formulated as the minimization of graph Laplacian regularizer. Secondly, to ease the optimization of the symmetric and positive definite metric matrix $\mathbf{M}$, we decompose it into $\mathbf{M}=\mathbf{R}^{\top}\mathbf{R}$ and solve $\mathbf{R}$ instead via proximal gradient. Finally, based on the spatial-temporal graph learning, we formulate dynamic point cloud denoising as the joint optimization of the desired point cloud and underlying spatio-temporal graph, which leverages both intra-frame affinities and inter-frame consistency and is solved via alternating minimization. Experimental results show that the proposed method significantly outperforms independent denoising of each frame from state-of-the-art static point cloud denoising approaches.



### Synthetic Data Generation and Adaption for Object Detection in Smart Vending Machines
- **Arxiv ID**: http://arxiv.org/abs/1904.12294v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, I.3.5; I.3.7; I.4.7; I.4.10; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1904.12294v1)
- **Published**: 2019-04-28 10:16:04+00:00
- **Updated**: 2019-04-28 10:16:04+00:00
- **Authors**: Kai Wang, Fuyuan Shi, Wenqi Wang, Yibing Nan, Shiguo Lian
- **Comment**: 9 pages, 9 figures
- **Journal**: None
- **Summary**: This paper presents an improved scheme for the generation and adaption of synthetic images for the training of deep Convolutional Neural Networks(CNNs) to perform the object detection task in smart vending machines. While generating synthetic data has proved to be effective for complementing the training data in supervised learning methods, challenges still exist for generating virtual images which are similar to those of the complex real scenes and minimizing redundant training data. To solve these problems, we consider the simulation of cluttered objects placed in a virtual scene and the wide-angle camera with distortions used to capture the whole scene in the data generation process, and post-processed the generated images with a elaborately-designed generative network to make them more similar to the real images. Various experiments have been conducted to prove the efficiency of using the generated virtual images to enhance the detection precision on existing datasets with limited real training data and the generalization ability of applying the trained network to datasets collected in new environment.



### RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion
- **Arxiv ID**: http://arxiv.org/abs/1904.12304v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1904.12304v1)
- **Published**: 2019-04-28 11:08:04+00:00
- **Updated**: 2019-04-28 11:08:04+00:00
- **Authors**: Muhammad Sarmad, Hyunjoo Jenny Lee, Young Min Kim
- **Comment**: Accepted to IEEE CVPR 2019
- **Journal**: None
- **Summary**: We present RL-GAN-Net, where a reinforcement learning (RL) agent provides fast and robust control of a generative adversarial network (GAN). Our framework is applied to point cloud shape completion that converts noisy, partial point cloud data into a high-fidelity completed shape by controlling the GAN. While a GAN is unstable and hard to train, we circumvent the problem by (1) training the GAN on the latent space representation whose dimension is reduced compared to the raw point cloud input and (2) using an RL agent to find the correct input to the GAN to generate the latent space representation of the shape that best fits the current input of incomplete point cloud. The suggested pipeline robustly completes point cloud with large missing regions. To the best of our knowledge, this is the first attempt to train an RL agent to control the GAN, which effectively learns the highly nonlinear mapping from the input noise of the GAN to the latent space of point cloud. The RL agent replaces the need for complex optimization and consequently makes our technique real time. Additionally, we demonstrate that our pipelines can be used to enhance the classification accuracy of point cloud with missing data.



### Classification and Detection in Mammograms with Weak Supervision via Dual Branch Deep Neural Net
- **Arxiv ID**: http://arxiv.org/abs/1904.12319v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12319v1)
- **Published**: 2019-04-28 13:11:10+00:00
- **Updated**: 2019-04-28 13:11:10+00:00
- **Authors**: Ran Bakalo, Rami Ben-Ari, Jacob Goldberger
- **Comment**: Accepted to IEEE International Symposium on Biomedical Imaging (ISBI)
  2019 (oral)
- **Journal**: None
- **Summary**: The high cost of generating expert annotations, poses a strong limitation for supervised machine learning methods in medical imaging. Weakly supervised methods may provide a solution to this tangle. In this study, we propose a novel deep learning architecture for multi-class classification of mammograms according to the severity of their containing anomalies, having only a global tag over the image. The suggested scheme further allows localization of the different types of findings in full resolution. The new scheme contains a dual branch network that combines region-level classification with region ranking. We evaluate our method on a large multi-center mammography dataset including $\sim$3,000 mammograms with various anomalies and demonstrate the advantages of the proposed method over a previous weakly-supervised strategy.



### An approach to image denoising using manifold approximation without clean images
- **Arxiv ID**: http://arxiv.org/abs/1904.12323v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1904.12323v1)
- **Published**: 2019-04-28 13:53:28+00:00
- **Updated**: 2019-04-28 13:53:28+00:00
- **Authors**: Rohit Jena
- **Comment**: None
- **Journal**: None
- **Summary**: Image restoration has been an extensively researched topic in numerous fields. With the advent of deep learning, a lot of the current algorithms were replaced by algorithms that are more flexible and robust. Deep networks have demonstrated impressive performance in a variety of tasks like blind denoising, image enhancement, deblurring, super-resolution, inpainting, among others. Most of these learning-based algorithms use a large amount of clean data during the training process. However, in certain applications in medical image processing, one may not have access to a large amount of clean data. In this paper, we propose a method for denoising that attempts to learn the denoising process by pushing the noisy data close to the clean data manifold, using only noisy images during training. Furthermore, we use perceptual loss terms and an iterative refinement step to further refine the clean images without losing important features.



### Measuring similarity between geo-tagged videos using largest common view
- **Arxiv ID**: http://arxiv.org/abs/1905.03695v1
- **DOI**: 10.1049/el.2018.7499
- **Categories**: **cs.CV**, cs.DB, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.03695v1)
- **Published**: 2019-04-28 14:46:06+00:00
- **Updated**: 2019-04-28 14:46:06+00:00
- **Authors**: Wei Ding, KwangSoo Yang, Kwang Woo Nam
- **Comment**: 2 pages
- **Journal**: IET electronics letters, vol.55, no. 8, pp.450-452, 2019
- **Summary**: This paper presents a novel problem for discovering the similar trajectories based on the field of view (FoV) of the video data. The problem is important for many societal applications such as grouping moving objects, classifying geo-images, and identifying the interesting trajectory patterns. Prior work consider only either spatial locations or spatial relationship between two line-segments. However, these approaches show a limitation to find the similar moving objects with common views. In this paper, we propose new algorithm that can group both spatial locations and points of view to identify similar trajectories. We also propose novel methods that reduce the computational cost for the proposed work. Experimental results using real-world datasets demonstrates that the proposed approach outperforms prior work and reduces the computational cost.



### Video Analytics with Zero-streaming Cameras
- **Arxiv ID**: http://arxiv.org/abs/1904.12342v4
- **DOI**: None
- **Categories**: **cs.DB**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1904.12342v4)
- **Published**: 2019-04-28 16:35:02+00:00
- **Updated**: 2021-06-17 06:03:35+00:00
- **Authors**: Mengwei Xu, Tiantu Xu, Yunxin Liu, Felix Xiaozhu Lin
- **Comment**: Mengwei Xu and Tiantu Xu contributed equally to the paper
- **Journal**: None
- **Summary**: Low-cost cameras enable powerful analytics. An unexploited opportunity is that most captured videos remain "cold" without being queried. For efficiency, we advocate for these cameras to be zero streaming: capturing videos to local storage and communicating with the cloud only when analytics is requested. How to query zero-streaming cameras efficiently? Our response is a camera/cloud runtime system called DIVA. It addresses two key challenges: to best use limited camera resource during video capture; to rapidly explore massive videos during query execution. DIVA contributes two unconventional techniques. (1) When capturing videos, a camera builds sparse yet accurate landmark frames, from which it learns reliable knowledge for accelerating future queries. (2) When executing a query, a camera processes frames in multiple passes with increasingly more expensive operators. As such, DIVA presents and keeps refining inexact query results throughout the query's execution. On diverse queries over 15 videos lasting 720 hours in total, DIVA runs at more than 100x video realtime and outperforms competitive alternative designs. To our knowledge, DIVA is the first system for querying large videos stored on low-cost remote cameras.



### Domain Agnostic Learning with Disentangled Representations
- **Arxiv ID**: http://arxiv.org/abs/1904.12347v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1904.12347v1)
- **Published**: 2019-04-28 17:07:10+00:00
- **Updated**: 2019-04-28 17:07:10+00:00
- **Authors**: Xingchao Peng, Zijun Huang, Ximeng Sun, Kate Saenko
- **Comment**: None
- **Journal**: Proceedings of the 36th International Conference on Machine
  Learning, Long Beach, California, PMLR 97, 2019
- **Summary**: Unsupervised model transfer has the potential to greatly improve the generalizability of deep models to novel domains. Yet the current literature assumes that the separation of target data into distinct domains is known as a priori. In this paper, we propose the task of Domain-Agnostic Learning (DAL): How to transfer knowledge from a labeled source domain to unlabeled data from arbitrary target domains? To tackle this problem, we devise a novel Deep Adversarial Disentangled Autoencoder (DADA) capable of disentangling domain-specific features from class identity. We demonstrate experimentally that when the target domain labels are unknown, DADA leads to state-of-the-art performance on several image classification datasets.



### Deferred Neural Rendering: Image Synthesis using Neural Textures
- **Arxiv ID**: http://arxiv.org/abs/1904.12356v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1904.12356v1)
- **Published**: 2019-04-28 18:00:08+00:00
- **Updated**: 2019-04-28 18:00:08+00:00
- **Authors**: Justus Thies, Michael Zollhöfer, Matthias Nießner
- **Comment**: Video: https://youtu.be/z-pVip6WeyY SIGGRAPH 2019
- **Journal**: None
- **Summary**: The modern computer graphics pipeline can synthesize images at remarkable visual quality; however, it requires well-defined, high-quality 3D content as input. In this work, we explore the use of imperfect 3D content, for instance, obtained from photo-metric reconstructions with noisy and incomplete surface geometry, while still aiming to produce photo-realistic (re-)renderings. To address this challenging problem, we introduce Deferred Neural Rendering, a new paradigm for image synthesis that combines the traditional graphics pipeline with learnable components. Specifically, we propose Neural Textures, which are learned feature maps that are trained as part of the scene capture process. Similar to traditional textures, neural textures are stored as maps on top of 3D mesh proxies; however, the high-dimensional feature maps contain significantly more information, which can be interpreted by our new deferred neural rendering pipeline. Both neural textures and deferred neural renderer are trained end-to-end, enabling us to synthesize photo-realistic images even when the original 3D content was imperfect. In contrast to traditional, black-box 2D generative neural networks, our 3D representation gives us explicit control over the generated output, and allows for a wide range of application domains. For instance, we can synthesize temporally-consistent video re-renderings of recorded 3D scenes as our representation is inherently embedded in 3D space. This way, neural textures can be utilized to coherently re-render or manipulate existing video content in both static and dynamic environments at real-time rates. We show the effectiveness of our approach in several experiments on novel view synthesis, scene editing, and facial reenactment, and compare to state-of-the-art approaches that leverage the standard graphics pipeline as well as conventional generative neural networks.



### Unsupervised Feature Learning for Point Cloud by Contrasting and Clustering With Graph Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1904.12359v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1904.12359v3)
- **Published**: 2019-04-28 18:21:13+00:00
- **Updated**: 2019-08-13 01:47:15+00:00
- **Authors**: Ling Zhang, Zhigang Zhu
- **Comment**: Accepted by 3DV 2019
- **Journal**: None
- **Summary**: To alleviate the cost of collecting and annotating large-scale point cloud datasets, we propose an unsupervised learning approach to learn features from unlabeled point cloud "3D object" dataset by using part contrasting and object clustering with deep graph neural networks (GNNs). In the contrast learning step, all the samples in the 3D object dataset are cut into two parts and put into a "part" dataset. Then a contrast learning GNN (ContrastNet) is trained to verify whether two randomly sampled parts from the part dataset belong to the same object. In the cluster learning step, the trained ContrastNet is applied to all the samples in the original 3D object dataset to extract features, which are used to group the samples into clusters. Then another GNN for clustering learning (ClusterNet) is trained to predict the cluster ID of all the training samples. The contrasting learning forces the ContrastNet to learn high-level semantic features of objects but probably ignores low-level features, while the ClusterNet improves the quality of learned features by being trained to discover objects that probably belong to the same semantic categories by the use of cluster IDs. We have conducted extensive experiments to evaluate the proposed framework on point cloud classification tasks. The proposed unsupervised learning approach obtained comparable performance to the state-of-the-art unsupervised learning methods that used much more complicated network structures. The code of this work is publicly available via: https://github.com/lingzhang1/ContrastNet.



### Towards Efficient Model Compression via Learned Global Ranking
- **Arxiv ID**: http://arxiv.org/abs/1904.12368v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1904.12368v2)
- **Published**: 2019-04-28 18:51:26+00:00
- **Updated**: 2020-03-14 05:53:58+00:00
- **Authors**: Ting-Wu Chin, Ruizhou Ding, Cha Zhang, Diana Marculescu
- **Comment**: CVPR 2020 Oral
- **Journal**: None
- **Summary**: Pruning convolutional filters has demonstrated its effectiveness in compressing ConvNets. Prior art in filter pruning requires users to specify a target model complexity (e.g., model size or FLOP count) for the resulting architecture. However, determining a target model complexity can be difficult for optimizing various embodied AI applications such as autonomous robots, drones, and user-facing applications. First, both the accuracy and the speed of ConvNets can affect the performance of the application. Second, the performance of the application can be hard to assess without evaluating ConvNets during inference. As a consequence, finding a sweet-spot between the accuracy and speed via filter pruning, which needs to be done in a trial-and-error fashion, can be time-consuming. This work takes a first step toward making this process more efficient by altering the goal of model compression to producing a set of ConvNets with various accuracy and latency trade-offs instead of producing one ConvNet targeting some pre-defined latency constraint. To this end, we propose to learn a global ranking of the filters across different layers of the ConvNet, which is used to obtain a set of ConvNet architectures that have different accuracy/latency trade-offs by pruning the bottom-ranked filters. Our proposed algorithm, LeGR, is shown to be 2x to 3x faster than prior work while having comparable or better performance when targeting seven pruned ResNet-56 with different accuracy/FLOPs profiles on the CIFAR-100 dataset. Additionally, we have evaluated LeGR on ImageNet and Bird-200 with ResNet-50 and MobileNetV2 to demonstrate its effectiveness. Code available at https://github.com/cmu-enyac/LeGR.



### Dynamic Environment Prediction in Urban Scenes using Recurrent Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1904.12374v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1904.12374v2)
- **Published**: 2019-04-28 19:41:59+00:00
- **Updated**: 2019-08-18 20:24:45+00:00
- **Authors**: Masha Itkina, Katherine Driggs-Campbell, Mykel J. Kochenderfer
- **Comment**: 8 pages, updated final draft, accepted into Intelligent
  Transportation Systems Conference (ITSC) 2019
- **Journal**: None
- **Summary**: A key challenge for autonomous driving is safe trajectory planning in cluttered, urban environments with dynamic obstacles, such as pedestrians, bicyclists, and other vehicles. A reliable prediction of the future environment, including the behavior of dynamic agents, would allow planning algorithms to proactively generate a trajectory in response to a rapidly changing environment. We present a novel framework that predicts the future occupancy state of the local environment surrounding an autonomous agent by learning a motion model from occupancy grid data using a neural network. We take advantage of the temporal structure of the grid data by utilizing a convolutional long-short term memory network in the form of the PredNet architecture. This method is validated on the KITTI dataset and demonstrates higher accuracy and better predictive power than baseline methods.



### TMIXT: A process flow for Transcribing MIXed handwritten and machine-printed Text
- **Arxiv ID**: http://arxiv.org/abs/1904.12387v1
- **DOI**: 10.1109/BigData.2018.8622136
- **Categories**: **cs.LG**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1904.12387v1)
- **Published**: 2019-04-28 21:46:39+00:00
- **Updated**: 2019-04-28 21:46:39+00:00
- **Authors**: Fady Medhat, Mahnaz Mohammadi, Sardar Jaf, Chris G. Willcocks, Toby P. Breckon, Peter Matthews, Andrew Stephen McGough, Georgios Theodoropoulos, Boguslaw Obara
- **Comment**: big data, unstructured data, Optical Character Recognition (OCR),
  Handwritten Text Recognition (HTR), machine-printed text recognition, IAM
  handwriting database, TMIXT
- **Journal**: IEEE International Conference on Big Data (Big Data) 2018
- **Summary**: Handling large corpuses of documents is of significant importance in many fields, no more so than in the areas of crime investigation and defence, where an organisation may be presented with a large volume of scanned documents which need to be processed in a finite time. However, this problem is exacerbated both by the volume, in terms of scanned documents and the complexity of the pages, which need to be processed. Often containing many different elements, which each need to be processed and understood. Text recognition, which is a primary task of this process, is usually dependent upon the type of text, being either handwritten or machine-printed. Accordingly, the recognition involves prior classification of the text category, before deciding on the recognition method to be applied. This poses a more challenging task if a document contains both handwritten and machine-printed text. In this work, we present a generic process flow for text recognition in scanned documents containing mixed handwritten and machine-printed text without the need to classify text in advance. We realize the proposed process flow using several open-source image processing and text recognition packages1. The evaluation is performed using a specially developed variant, presented in this work, of the IAM handwriting database, where we achieve an average transcription accuracy of nearly 80% for pages containing both printed and handwritten text.



