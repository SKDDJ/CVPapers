# Arxiv Papers in cs.CV on 2019-06-26
### Topology Maintained Structure Encoding
- **Arxiv ID**: http://arxiv.org/abs/1906.10823v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10823v1)
- **Published**: 2019-06-26 02:59:24+00:00
- **Updated**: 2019-06-26 02:59:24+00:00
- **Authors**: Qing Fang
- **Comment**: 7 pages, 8 figures
- **Journal**: None
- **Summary**: Deep learning has been used as a powerful tool for various tasks in computer vision, such as image segmentation, object recognition and data generation. A key part of end-to-end training is designing the appropriate encoder to extract specific features from the input data. However, few encoders maintain the topological properties of data, such as connection structures and global contours. In this paper, we introduce a Voronoi Diagram encoder based on convex set distance (CSVD) and apply it in edge encoding. The boundaries of Voronoi cells is related to detected edges of structures and contours. The CSVD model improves contour extraction in CNN and structure generation in GAN. We also show the experimental results and demonstrate that the proposed model has great potentiality in different visual problems where topology information should be involved.



### Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs
- **Arxiv ID**: http://arxiv.org/abs/1906.10842v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10842v2)
- **Published**: 2019-06-26 04:30:55+00:00
- **Updated**: 2020-05-15 02:52:42+00:00
- **Authors**: Soheil Kolouri, Aniruddha Saha, Hamed Pirsiavash, Heiko Hoffmann
- **Comment**: CVPR 2020 Oral
- **Journal**: None
- **Summary**: The unprecedented success of deep neural networks in many applications has made these networks a prime target for adversarial exploitation. In this paper, we introduce a benchmark technique for detecting backdoor attacks (aka Trojan attacks) on deep convolutional neural networks (CNNs). We introduce the concept of Universal Litmus Patterns (ULPs), which enable one to reveal backdoor attacks by feeding these universal patterns to the network and analyzing the output (i.e., classifying the network as `clean' or `corrupted'). This detection is fast because it requires only a few forward passes through a CNN. We demonstrate the effectiveness of ULPs for detecting backdoor attacks on thousands of networks with different architectures trained on four benchmark datasets, namely the German Traffic Sign Recognition Benchmark (GTSRB), MNIST, CIFAR10, and Tiny-ImageNet. The codes and train/test models for this paper can be found here https://umbcvision.github.io/Universal-Litmus-Patterns/.



### Gray Level Image Threshold Using Neutrosophic Shannon Entropy
- **Arxiv ID**: http://arxiv.org/abs/1906.12167v1
- **DOI**: 10.20944/preprints201906.0248.v1
- **Categories**: **cs.CV**, 68U10, 62H35
- **Links**: [PDF](http://arxiv.org/pdf/1906.12167v1)
- **Published**: 2019-06-26 05:30:40+00:00
- **Updated**: 2019-06-26 05:30:40+00:00
- **Authors**: Vasile Patrascu
- **Comment**: The 3rd Conference on Recent Advances in Artificial Intelligence,
  RAAI 2019, Bucharest, Romania, June 28-30, 2019
- **Journal**: None
- **Summary**: This article presents a new method of segmenting grayscale images by minimizing Shannon's neutrosophic entropy. For the proposed segmentation method, the neutrosophic information components, i.e., the degree of truth, the degree of neutrality and the degree of falsity are defined taking into account the belonging to the segmented regions and at the same time to the separation threshold area. The principle of the method is simple and easy to understand and can lead to multiple thresholds. The efficacy of the method is illustrated using some test gray level images. The experimental results show that the proposed method has good performance for segmentation with optimal gray level thresholds.



### On the Role of Geometry in Geo-Localization
- **Arxiv ID**: http://arxiv.org/abs/1906.10855v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10855v1)
- **Published**: 2019-06-26 05:47:21+00:00
- **Updated**: 2019-06-26 05:47:21+00:00
- **Authors**: Moti Kadosh, Yael Moses, Ariel Shamir
- **Comment**: None
- **Journal**: None
- **Summary**: Humans can build a mental map of a geographical area to find their way and recognize places. The basic task we consider is geo-localization - finding the pose (position & orientation) of a camera in a large 3D scene from a single image. We aim to experimentally explore the role of geometry in geo-localization in a convolutional neural network (CNN) solution. We do so by ignoring the often available texture of the scene. We therefore deliberately avoid using texture or rich geometric details and use images projected from a simple 3D model of a city, which we term lean images. Lean images contain solely information that relates to the geometry of the area viewed (edges, faces, or relative depth). We find that the network is capable of estimating the camera pose from the lean images, and it does so not by memorization but by some measure of geometric learning of the geographical area. The main contributions of this paper are: (i) providing insight into the role of geometry in the CNN learning process; and (ii) demonstrating the power of CNNs for recovering camera pose using lean images.



### Automatic Hierarchical Classification of Kelps using Deep Residual Features
- **Arxiv ID**: http://arxiv.org/abs/1906.10881v2
- **DOI**: 10.3390/s20020447
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10881v2)
- **Published**: 2019-06-26 07:29:18+00:00
- **Updated**: 2020-01-23 06:45:18+00:00
- **Authors**: Ammar Mahmood, Ana Giraldo Ospina, Mohammed Bennamoun, Senjian An, Ferdous Sohel, Farid Boussaid, Renae Hovey, Robert B. Fisher, Gary Kendrick
- **Comment**: MDPI Sensors
- **Journal**: Sensors 2020, 20, 447
- **Summary**: Across the globe, remote image data is rapidly being collected for the assessment of benthic communities from shallow to extremely deep waters on continental slopes to the abyssal seas. Exploiting this data is presently limited by the time it takes for experts to identify organisms found in these images. With this limitation in mind, a large effort has been made globally to introduce automation and machine learning algorithms to accelerate both classification and assessment of marine benthic biota. One major issue lies with organisms that move with swell and currents, like kelps. This paper presents an automatic hierarchical classification method (local binary classification as opposed to the conventional flat classification) to classify kelps in images collected by autonomous underwater vehicles. The proposed kelp classification approach exploits learned feature representations extracted from deep residual networks. We show that these generic features outperform the traditional off-the-shelf CNN features and the conventional hand-crafted features. Experiments also demonstrate that the hierarchical classification method outperforms the traditional parallel multi-class classifications by a significant margin (90.0% vs 57.6% and 77.2% vs 59.0%) on Benthoz15 and Rottnest datasets respectively. Furthermore, we compare different hierarchical classification approaches and experimentally show that the sibling hierarchical training approach outperforms the inclusive hierarchical approach by a significant margin. We also report an application of our proposed method to study the change in kelp cover over time for annually repeated AUV surveys.



### Automatic Co-Registration of Aerial Imagery and Untextured Model Data Utilizing Average Shading Gradients
- **Arxiv ID**: http://arxiv.org/abs/1906.10882v2
- **DOI**: 10.5194/isprs-archives-XLII-2-W13-581-2019
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10882v2)
- **Published**: 2019-06-26 07:29:36+00:00
- **Updated**: 2019-09-21 20:20:25+00:00
- **Authors**: Sylvia Schmitz, Martin Weinmann, Boitumelo Ruf
- **Comment**: None
- **Journal**: Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W13,
  581-588, 2019
- **Summary**: The comparison of current image data with existing 3D model data of a scene provides an efficient method to keep models up to date. In order to transfer information between 2D and 3D data, a preliminary co-registration is necessary. In this paper, we present a concept to automatically co-register aerial imagery and untextured 3D model data. To refine a given initial camera pose, our algorithm computes dense correspondence fields using SIFT flow between gradient representations of the model and camera image, from which 2D-3D correspondences are obtained. These correspondences are then used in an iterative optimization scheme to refine the initial camera pose by minimizing the reprojection error. Since it is assumed that the model does not contain texture information, our algorithm is built up on an existing method based on Average Shading Gradients (ASG) to generate gradient images based on raw geometry information only. We apply our algorithm for the co-registering of aerial photographs to an untextured, noisy mesh model. We have investigated different magnitudes of input error and show that the proposed approach can reduce the final reprojection error to a minimum of 1.27 plus-minus 0.54 pixels, which is less than 10 % of its initial value. Furthermore, our evaluation shows that our approach outperforms the accuracy of a standard Iterative Closest Point (ICP) implementation.



### Joint Multi-frame Detection and Segmentation for Multi-cell Tracking
- **Arxiv ID**: http://arxiv.org/abs/1906.10886v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.10886v1)
- **Published**: 2019-06-26 07:41:11+00:00
- **Updated**: 2019-06-26 07:41:11+00:00
- **Authors**: Zibin Zhou, Fei Wang, Wenjuan Xi, Huaying Chen, Peng Gao, Chengkang He
- **Comment**: Accepted by International Conference on Image and Graphics (ICIG
  2019)
- **Journal**: None
- **Summary**: Tracking living cells in video sequence is difficult, because of cell morphology and high similarities between cells. Tracking-by-detection methods are widely used in multi-cell tracking. We perform multi-cell tracking based on the cell centroid detection, and the performance of the detector has high impact on tracking performance. In this paper, UNet is utilized to extract inter-frame and intra-frame spatio-temporal information of cells. Detection performance of cells in mitotic phase is improved by multi-frame input. Good detection results facilitate multi-cell tracking. A mitosis detection algorithm is proposed to detect cell mitosis and the cell lineage is built up. Another UNet is utilized to acquire primary segmentation. Jointly using detection and primary segmentation, cells can be fine segmented in highly dense cell population. Experiments are conducted to evaluate the effectiveness of our method, and results show its state-of-the-art performance.



### Spatial Transformer for 3D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/1906.10887v4
- **DOI**: 10.1109/TPAMI.2021.3070341
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.10887v4)
- **Published**: 2019-06-26 07:41:13+00:00
- **Updated**: 2021-03-30 03:22:54+00:00
- **Authors**: Jiayun Wang, Rudrasis Chakraborty, Stella X. Yu
- **Comment**: To appear in IEEE Transactions on PAMI, 2021
- **Journal**: None
- **Summary**: Deep neural networks are widely used for understanding 3D point clouds. At each point convolution layer, features are computed from local neighborhoods of 3D points and combined for subsequent processing in order to extract semantic information. Existing methods adopt the same individual point neighborhoods throughout the network layers, defined by the same metric on the fixed input point coordinates. This common practice is easy to implement but not necessarily optimal. Ideally, local neighborhoods should be different at different layers, as more latent information is extracted at deeper layers. We propose a novel end-to-end approach to learn different non-rigid transformations of the input point cloud so that optimal local neighborhoods can be adopted at each layer. We propose both linear (affine) and non-linear (projective and deformable) spatial transformers for 3D point clouds. With spatial transformers on the ShapeNet part segmentation dataset, the network achieves higher accuracy for all categories, with 8\% gain on earphones and rockets in particular. Our method also outperforms the state-of-the-art on other point cloud tasks such as classification, detection, and semantic segmentation. Visualizations show that spatial transformers can learn features more efficiently by dynamically altering local neighborhoods according to the geometry and semantics of 3D shapes in spite of their within-category variations. Our code is publicly available at https://github.com/samaonline/spatial-transformer-for-3d-point-clouds.



### Prediction Poisoning: Towards Defenses Against DNN Model Stealing Attacks
- **Arxiv ID**: http://arxiv.org/abs/1906.10908v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10908v2)
- **Published**: 2019-06-26 08:32:37+00:00
- **Updated**: 2020-03-03 10:51:12+00:00
- **Authors**: Tribhuvanesh Orekondy, Bernt Schiele, Mario Fritz
- **Comment**: ICLR 2020, Project page:
  https://resources.mpi-inf.mpg.de/d2/orekondy/predpoison/
- **Journal**: None
- **Summary**: High-performance Deep Neural Networks (DNNs) are increasingly deployed in many real-world applications e.g., cloud prediction APIs. Recent advances in model functionality stealing attacks via black-box access (i.e., inputs in, predictions out) threaten the business model of such applications, which require a lot of time, money, and effort to develop. Existing defenses take a passive role against stealing attacks, such as by truncating predicted information. We find such passive defenses ineffective against DNN stealing attacks. In this paper, we propose the first defense which actively perturbs predictions targeted at poisoning the training objective of the attacker. We find our defense effective across a wide range of challenging datasets and DNN model stealing attacks, and additionally outperforms existing defenses. Our defense is the first that can withstand highly accurate model stealing attacks for tens of thousands of queries, amplifying the attacker's error rate up to a factor of 85$\times$ with minimal impact on the utility for benign users.



### FA-Harris: A Fast and Asynchronous Corner Detector for Event Cameras
- **Arxiv ID**: http://arxiv.org/abs/1906.10925v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1906.10925v4)
- **Published**: 2019-06-26 09:12:40+00:00
- **Updated**: 2019-08-28 02:35:09+00:00
- **Authors**: Ruoxiang Li, Dianxi Shi, Yongjun Zhang, Kaiyue Li, Ruihao Li
- **Comment**: 7 pages, 3 figures, Accepted by IROS 2019. Video:
  https://www.youtube.com/watch?v=v5CcBVkmI6w&feature=youtu.be
- **Journal**: None
- **Summary**: Recently, the emerging bio-inspired event cameras have demonstrated potentials for a wide range of robotic applications in dynamic environments. In this paper, we propose a novel fast and asynchronous event-based corner detection method which is called FA-Harris. FA-Harris consists of several components, including an event filter, a Global Surface of Active Events (G-SAE) maintaining unit, a corner candidate selecting unit, and a corner candidate refining unit. The proposed G-SAE maintenance algorithm and corner candidate selection algorithm greatly enhance the real-time performance for corner detection, while the corner candidate refinement algorithm maintains the accuracy of performance by using an improved event-based Harris detector. Additionally, FA-Harris does not require artificially synthesized event-frames and can operate on asynchronous events directly. We implement the proposed method in C++ and evaluate it on public Event Camera Datasets. The results show that our method achieves approximately 8x speed-up when compared with previously reported event-based Harris detector, and with no compromise on the accuracy of performance.



### End-to-End 3D-PointCloud Semantic Segmentation for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/1906.10964v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.10964v1)
- **Published**: 2019-06-26 10:45:50+00:00
- **Updated**: 2019-06-26 10:45:50+00:00
- **Authors**: Mohammed Abdou, Mahmoud Elkhateeb, Ibrahim Sobh, Ahmad Elsallab
- **Comment**: 6 pages, 3 figures
- **Journal**: None
- **Summary**: 3D semantic scene labeling is a fundamental task for Autonomous Driving. Recent work shows the capability of Deep Neural Networks in labeling 3D point sets provided by sensors like LiDAR, and Radar. Imbalanced distribution of classes in the dataset is one of the challenges that face 3D semantic scene labeling task. This leads to misclassifying for the non-dominant classes which suffer from two main problems: a) rare appearance in the dataset, and b) few sensor points reflected from one object of these classes. This paper proposes a Weighted Self-Incremental Transfer Learning as a generalized methodology that solves the imbalanced training dataset problems. It re-weights the components of the loss function computed from individual classes based on their frequencies in the training dataset, and applies Self-Incremental Transfer Learning by running the Neural Network model on non-dominant classes first, then dominant classes one-by-one are added. The experimental results introduce a new 3D point cloud semantic segmentation benchmark for KITTI dataset.



### Defending Adversarial Attacks by Correcting logits
- **Arxiv ID**: http://arxiv.org/abs/1906.10973v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.10973v1)
- **Published**: 2019-06-26 11:07:29+00:00
- **Updated**: 2019-06-26 11:07:29+00:00
- **Authors**: Yifeng Li, Lingxi Xie, Ya Zhang, Rui Zhang, Yanfeng Wang, Qi Tian
- **Comment**: None
- **Journal**: None
- **Summary**: Generating and eliminating adversarial examples has been an intriguing topic in the field of deep learning. While previous research verified that adversarial attacks are often fragile and can be defended via image-level processing, it remains unclear how high-level features are perturbed by such attacks. We investigate this issue from a new perspective, which purely relies on logits, the class scores before softmax, to detect and defend adversarial attacks. Our defender is a two-layer network trained on a mixed set of clean and perturbed logits, with the goal being recovering the original prediction. Upon a wide range of adversarial attacks, our simple approach shows promising results with relatively high accuracy in defense, and the defender can transfer across attackers with similar properties. More importantly, our defender can work in the scenarios that image data are unavailable, and enjoys high interpretability especially at the semantic level.



### Learning Soft-Attention Models for Tempo-invariant Audio-Sheet Music Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1906.10996v1
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, cs.LG, cs.SD, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/1906.10996v1)
- **Published**: 2019-06-26 11:52:49+00:00
- **Updated**: 2019-06-26 11:52:49+00:00
- **Authors**: Stefan Balke, Matthias Dorfer, Luis Carvalho, Andreas Arzt, Gerhard Widmer
- **Comment**: Accepted for publication at ISMIR 2019
- **Journal**: None
- **Summary**: Connecting large libraries of digitized audio recordings to their corresponding sheet music images has long been a motivation for researchers to develop new cross-modal retrieval systems. In recent years, retrieval systems based on embedding space learning with deep neural networks got a step closer to fulfilling this vision. However, global and local tempo deviations in the music recordings still require careful tuning of the amount of temporal context given to the system. In this paper, we address this problem by introducing an additional soft-attention mechanism on the audio input. Quantitative and qualitative results on synthesized piano data indicate that this attention increases the robustness of the retrieval system by focusing on different parts of the input representation based on the tempo of the audio. Encouraged by these results, we argue for the potential of attention models as a very general tool for many MIR tasks.



### Generalized Median Graph via Iterative Alternate Minimizations
- **Arxiv ID**: http://arxiv.org/abs/1906.11009v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1906.11009v1)
- **Published**: 2019-06-26 12:04:55+00:00
- **Updated**: 2019-06-26 12:04:55+00:00
- **Authors**: Nicolas Boria, S'ebastien Bougleux, Benoit Gaüzère, Luc Brun
- **Comment**: None
- **Journal**: IAPR International workshop on Graph-Based Representation in
  Pattern Recognition, Donatello Conte, Jean-Yves Ramel,, Jun 2019, Tours,
  France. pp.99-109
- **Summary**: Computing a graph prototype may constitute a core element for clustering or classification tasks. However, its computation is an NP-Hard problem, even for simple classes of graphs. In this paper, we propose an efficient approach based on block coordinate descent to compute a generalized median graph from a set of graphs. This approach relies on a clear definition of the optimization process and handles labeling on both edges and nodes. This iterative process optimizes the edit operations to perform on a graph alternatively on nodes and edges. Several experiments on different datasets show the efficiency of our approach.



### Color Texture Classification Based on Proposed Impulse-Noise Resistant Color Local Binary Patterns and Significant Points Selection Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1906.11010v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11010v1)
- **Published**: 2019-06-26 12:10:01+00:00
- **Updated**: 2019-06-26 12:10:01+00:00
- **Authors**: Shervan Fekri-Ershad, Farshad Tajeripour
- **Comment**: 10 pages, 7 figures, 9 tables
- **Journal**: None
- **Summary**: The main aim of this paper is to propose a color texture classification approach which uses color sensor information and texture features jointly. High accuracy, low noise sensitivity and low computational complexity are specified aims for our proposed approach. One of the efficient texture analysis operations is local binary patterns. The proposed approach includes two steps. First, a noise resistant version of color local binary patterns is proposed to decrease sensitivity to noise of LBP. This step is evaluated based on combination of color sensor information using AND operation. In second step, a significant points selection algorithm is proposed to select significant LBP. This phase decreases final computational complexity along with increasing accuracy rate. The Proposed approach is evaluated using Vistex, Outex, and KTH TIPS2a data sets. Our approach has been compared with some state of the art methods. It is experimentally demonstrated that the proposed approach achieves highest accuracy. In two other experiments, result show low noise sensitivity and low computational complexity of the proposed approach in comparison with previous versions of LBP. Rotation invariant, multi resolution, general usability are other advantages of our proposed approach. In the present paper, a new version of LBP is proposed originally, which is called Hybrid color local binary patterns. It can be used in many image processing applications to extract color and texture features jointly. Also, a significant point selection algorithm is proposed for the first time to select key points of images.



### Evaluation of head segmentation quality for treatment planning of tumor treating fields in brain tumors
- **Arxiv ID**: http://arxiv.org/abs/1906.11014v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1906.11014v1)
- **Published**: 2019-06-26 12:17:00+00:00
- **Updated**: 2019-06-26 12:17:00+00:00
- **Authors**: Reuben R Shamir, Zeev Bomzon
- **Comment**: published as a long abstract in IPCAI 2019
- **Journal**: None
- **Summary**: Tumor treating fields (TTFields) is an FDA approved therapy for the treatment of Gliobastoma Multiform (GBM) and currently being investigated for additional tumor types. TTFields are delivered to the tumor through the placement of transducer arrays (TAs) placed on the patient scalp. The positions of the TAs are associated with treatment outcomes via simulations of the electric fields. Therefore, we are currently developing a method for recommending optimal placement of TAs. A key step to achieve this goal is to correctly segment the head into tissues of similar electrical properties. Visual inspection of segmentation quality is invaluable but time-consuming. Automatic quality assessment can assist in automatic refinement of the segmentation parameters, suggest flaw points to the user and indicate if the segmented method is of sufficient accuracy for TTFields simulation. As a first step in this direction, we identified a set of features that are relevant to atlas-based segmentation and show that these are significantly correlated (p < 0.05) with a similarity measure between validated and automatically computed segmentations. Furthermore, we incorporated these features in a decision tree regressor to predict the similarity of the validated and computed segmentations of 20 TTFields patients using a leave-one-out approach. The predicted similarity measures were highly correlated with the actual ones (average abs. difference 3% (SD = 3%); r = 0.92, p < 0.001). We conclude that quality estimation of segmentations is feasible by incorporating machine learning and segmentation-relevant features.



### Continuous Dice Coefficient: a Method for Evaluating Probabilistic Segmentations
- **Arxiv ID**: http://arxiv.org/abs/1906.11031v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.11031v1)
- **Published**: 2019-06-26 12:35:00+00:00
- **Updated**: 2019-06-26 12:35:00+00:00
- **Authors**: Reuben R Shamir, Yuval Duchin, Jinyoung Kim, Guillermo Sapiro, Noam Harel
- **Comment**: None
- **Journal**: None
- **Summary**: Objective: Overlapping measures are often utilized to quantify the similarity between two binary regions. However, modern segmentation algorithms output a probability or confidence map with continuous values in the zero-to-one interval. Moreover, these binary overlapping measures are biased to structure size. Addressing these challenges is the objective of this work. Methods: We extend the definition of the classical Dice coefficient (DC) overlap to facilitate the direct comparison of a ground truth binary image with a probabilistic map. We call the extended method continuous Dice coefficient (cDC) and show that 1) cDC is less or equal to 1 and cDC = 1 if-and-only-if the structures overlap is complete, and, 2) cDC is monotonically decreasing with the amount of overlap. We compare the classical DC and the cDC in a simulation of partial volume effects that incorporates segmentations of common targets for deep-brainstimulation. Lastly, we investigate the cDC for an automatic segmentation of the subthalamic-nucleus. Results: Partial volume effect simulation on thalamus (large structure) resulted with DC and cDC averages (SD) of 0.98 (0.006) and 0.99 (0.001), respectively. For subthalamic-nucleus (small structure) DC and cDC were 0.86 (0.025) and 0.97 (0.006), respectively. The DC and cDC for automatic STN segmentation were 0.66 and 0.80, respectively. Conclusion: The cDC is well defined for probabilistic segmentation, less biased to structure size and more robust to partial volume effects in comparison to DC. Significance: The proposed method facilitates a better evaluation of segmentation algorithms. As a better measurement tool, it opens the door for the development of better segmentation methods.



### Further advantages of data augmentation on convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1906.11052v1
- **DOI**: 10.1007/978-3-030-01418-6_10
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.11052v1)
- **Published**: 2019-06-26 12:50:13+00:00
- **Updated**: 2019-06-26 12:50:13+00:00
- **Authors**: Alex Hernández-García, Peter König
- **Comment**: Preprint of the manuscript accepted for presentation at the
  International Conference on Artificial Neural Networks (ICANN) 2018. Best
  Paper Award
- **Journal**: Artificial Neural Networks and Machine Learning - ICANN 2018.
  ICANN 2018. Lecture Notes in Computer Science, vol 11139. Springer, Cham
- **Summary**: Data augmentation is a popular technique largely used to enhance the training of convolutional neural networks. Although many of its benefits are well known by deep learning researchers and practitioners, its implicit regularization effects, as compared to popular explicit regularization techniques, such as weight decay and dropout, remain largely unstudied. As a matter of fact, convolutional neural networks for image object classification are typically trained with both data augmentation and explicit regularization, assuming the benefits of all techniques are complementary. In this paper, we systematically analyze these techniques through ablation studies of different network architectures trained with different amounts of training data. Our results unveil a largely ignored advantage of data augmentation: networks trained with just data augmentation more easily adapt to different architectures and amount of training data, as opposed to weight decay and dropout, which require specific fine-tuning of their hyperparameters.



### Deep Radar Detector
- **Arxiv ID**: http://arxiv.org/abs/1906.12187v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.SP, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.12187v1)
- **Published**: 2019-06-26 13:30:45+00:00
- **Updated**: 2019-06-26 13:30:45+00:00
- **Authors**: Daniel Brodeski, Igal Bilik, Raja Giryes
- **Comment**: Accepted to RadarConf 2019
- **Journal**: None
- **Summary**: While camera and LiDAR processing have been revolutionized since the introduction of deep learning, radar processing still relies on classical tools. In this paper, we introduce a deep learning approach for radar processing, working directly with the radar complex data. To overcome the lack of radar labeled data, we rely in training only on the radar calibration data and introduce new radar augmentation techniques. We evaluate our method on the radar 4D detection task and demonstrate superior performance compared to the classical approaches while keeping real-time performance. Applying deep learning on radar data has several advantages such as eliminating the need for an expensive radar calibration process each time and enabling classification of the detected objects with almost zero-overhead.



### Mapped Convolutions
- **Arxiv ID**: http://arxiv.org/abs/1906.11096v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11096v1)
- **Published**: 2019-06-26 13:44:40+00:00
- **Updated**: 2019-06-26 13:44:40+00:00
- **Authors**: Marc Eder, True Price, Thanh Vu, Akash Bapat, Jan-Michael Frahm
- **Comment**: None
- **Journal**: None
- **Summary**: We present a versatile formulation of the convolution operation that we term a "mapped convolution." The standard convolution operation implicitly samples the pixel grid and computes a weighted sum. Our mapped convolution decouples these two components, freeing the operation from the confines of the image grid and allowing the kernel to process any type of structured data. As a test case, we demonstrate its use by applying it to dense inference on spherical data. We perform an in-depth study of existing spherical image convolution methods and propose an improved sampling method for equirectangular images. Then, we discuss the impact of data discretization when deriving a sampling function, highlighting drawbacks of the cube map representation for spherical data. Finally, we illustrate how mapped convolutions enable us to convolve directly on a mesh by projecting the spherical image onto a geodesic grid and training on the textured mesh. This method exceeds the state of the art for spherical depth estimation by nearly 17%. Our findings suggest that mapped convolutions can be instrumental in expanding the application scope of convolutional neural networks.



### A Deep Decoder Structure Based on WordEmbedding Regression for An Encoder-Decoder Based Model for Image Captioning
- **Arxiv ID**: http://arxiv.org/abs/1906.12188v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1906.12188v1)
- **Published**: 2019-06-26 13:51:59+00:00
- **Updated**: 2019-06-26 13:51:59+00:00
- **Authors**: Ahmad Asadi, Reza Safabakhsh
- **Comment**: 19 pages, 5 figures
- **Journal**: None
- **Summary**: Generating textual descriptions for images has been an attractive problem for the computer vision and natural language processing researchers in recent years. Dozens of models based on deep learning have been proposed to solve this problem. The existing approaches are based on neural encoder-decoder structures equipped with the attention mechanism. These methods strive to train decoders to minimize the log likelihood of the next word in a sentence given the previous ones, which results in the sparsity of the output space. In this work, we propose a new approach to train decoders to regress the word embedding of the next word with respect to the previous ones instead of minimizing the log likelihood. The proposed method is able to learn and extract long-term information and can generate longer fine-grained captions without introducing any external memory cell. Furthermore, decoders trained by the proposed technique can take the importance of the generated words into consideration while generating captions. In addition, a novel semantic attention mechanism is proposed that guides attention points through the image, taking the meaning of the previously generated word into account. We evaluate the proposed approach with the MS-COCO dataset. The proposed model outperformed the state of the art models especially in generating longer captions. It achieved a CIDEr score equal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of the state of the art models are 117.1 and 48.0, respectively.



### Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth
- **Arxiv ID**: http://arxiv.org/abs/1906.11109v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11109v2)
- **Published**: 2019-06-26 13:58:45+00:00
- **Updated**: 2019-08-02 12:24:44+00:00
- **Authors**: Davy Neven, Bert De Brabandere, Marc Proesmans, Luc Van Gool
- **Comment**: added references
- **Journal**: None
- **Summary**: Current state-of-the-art instance segmentation methods are not suited for real-time applications like autonomous driving, which require fast execution times at high accuracy. Although the currently dominant proposal-based methods have high accuracy, they are slow and generate masks at a fixed and low resolution. Proposal-free methods, by contrast, can generate masks at high resolution and are often faster, but fail to reach the same accuracy as the proposal-based methods. In this work we propose a new clustering loss function for proposal-free instance segmentation. The loss function pulls the spatial embeddings of pixels belonging to the same instance together and jointly learns an instance-specific clustering bandwidth, maximizing the intersection-over-union of the resulting instance mask. When combined with a fast architecture, the network can perform instance segmentation in real-time while maintaining a high accuracy. We evaluate our method on the challenging Cityscapes benchmark and achieve top results (5\% improvement over Mask R-CNN) at more than 10 fps on 2MP images. Code will be available at https://github.com/davyneven/SpatialEmbeddings .



### DASGAN -- Joint Domain Adaptation and Segmentation for the Analysis of Epithelial Regions in Histopathology PD-L1 Images
- **Arxiv ID**: http://arxiv.org/abs/1906.11118v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1906.11118v1)
- **Published**: 2019-06-26 14:23:50+00:00
- **Updated**: 2019-06-26 14:23:50+00:00
- **Authors**: Ansh Kapil, Tobias Wiestler, Simon Lanzmich, Abraham Silva, Keith Steele, Marlon Rebelatto, Guenter Schmidt, Nicolas Brieu
- **Comment**: None
- **Journal**: None
- **Summary**: The analysis of the tumor environment on digital histopathology slides is becoming key for the understanding of the immune response against cancer, supporting the development of novel immuno-therapies. We introduce here a novel deep learning solution to the related problem of tumor epithelium segmentation. While most existing deep learning segmentation approaches are trained on time-consuming and costly manual annotation on single stain domain (PD-L1), we leverage here semi-automatically labeled images from a second stain domain (Cytokeratin-CK). We introduce an end-to-end trainable network that jointly segment tumor epithelium on PD-L1 while leveraging unpaired image-to-image translation between CK and PD-L1, therefore completely bypassing the need for serial sections or re-staining of slides. Extending the method to differentiate between PD-L1 positive and negative tumor epithelium regions enables the automated estimation of the PD-L1 Tumor Cell (TC) score. Quantitative experimental results demonstrate the accuracy of our approach against state-of-the-art segmentation methods.



### Boundary and Entropy-driven Adversarial Learning for Fundus Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1906.11143v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11143v2)
- **Published**: 2019-06-26 14:59:40+00:00
- **Updated**: 2019-07-26 09:14:28+00:00
- **Authors**: Shujun Wang, Lequan Yu, Kang Li, Xin Yang, Chi-Wing Fu, Pheng-Ann Heng
- **Comment**: Accepted at MICCAI 2019
- **Journal**: None
- **Summary**: Accurate segmentation of the optic disc (OD) and cup (OC)in fundus images from different datasets is critical for glaucoma disease screening. The cross-domain discrepancy (domain shift) hinders the generalization of deep neural networks to work on different domain datasets.In this work, we present an unsupervised domain adaptation framework,called Boundary and Entropy-driven Adversarial Learning (BEAL), to improve the OD and OC segmentation performance, especially on the ambiguous boundary regions. In particular, our proposed BEAL frame-work utilizes the adversarial learning to encourage the boundary prediction and mask probability entropy map (uncertainty map) of the target domain to be similar to the source ones, generating more accurate boundaries and suppressing the high uncertainty predictions of OD and OC segmentation. We evaluate the proposed BEAL framework on two public retinal fundus image datasets (Drishti-GS and RIM-ONE-r3), and the experiment results demonstrate that our method outperforms the state-of-the-art unsupervised domain adaptation methods. Codes will be available at https://github.com/EmmaW8/BEAL.



### Learning Data Augmentation Strategies for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1906.11172v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.11172v1)
- **Published**: 2019-06-26 15:39:40+00:00
- **Updated**: 2019-06-26 15:39:40+00:00
- **Authors**: Barret Zoph, Ekin D. Cubuk, Golnaz Ghiasi, Tsung-Yi Lin, Jonathon Shlens, Quoc V. Le
- **Comment**: None
- **Journal**: None
- **Summary**: Data augmentation is a critical component of training deep learning models. Although data augmentation has been shown to significantly improve image classification, its potential has not been thoroughly investigated for object detection. Given the additional cost for annotating images for object detection, data augmentation may be of even greater importance for this computer vision task. In this work, we study the impact of data augmentation on object detection. We first demonstrate that data augmentation operations borrowed from image classification may be helpful for training detection models, but the improvement is limited. Thus, we investigate how learned, specialized data augmentation policies improve generalization performance for detection models. Importantly, these augmentation policies only affect training and leave a trained model unchanged during evaluation. Experiments on the COCO dataset indicate that an optimized data augmentation policy improves detection accuracy by more than +2.3 mAP, and allow a single inference model to achieve a state-of-the-art accuracy of 50.7 mAP. Importantly, the best policy found on COCO may be transferred unchanged to other detection datasets and models to improve predictive accuracy. For example, the best augmentation policy identified with COCO improves a strong baseline on PASCAL-VOC by +2.7 mAP. Our results also reveal that a learned augmentation policy is superior to state-of-the-art architecture regularization methods for object detection, even when considering strong baselines. Code for training with the learned policy is available online at https://github.com/tensorflow/tpu/tree/master/models/official/detection



### PyRep: Bringing V-REP to Deep Robot Learning
- **Arxiv ID**: http://arxiv.org/abs/1906.11176v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.11176v1)
- **Published**: 2019-06-26 15:43:41+00:00
- **Updated**: 2019-06-26 15:43:41+00:00
- **Authors**: Stephen James, Marc Freese, Andrew J. Davison
- **Comment**: None
- **Journal**: None
- **Summary**: PyRep is a toolkit for robot learning research, built on top of the virtual robotics experimentation platform (V-REP). Through a series of modifications and additions, we have created a tailored version of V-REP built with robot learning in mind. The new PyRep toolkit offers three improvements: (1) a simple and flexible API for robot control and scene manipulation, (2) a new rendering engine, and (3) speed boosts upwards of 10,000x in comparison to the previous Python Remote API. With these improvements, we believe PyRep is the ideal toolkit to facilitate rapid prototyping of learning algorithms in the areas of reinforcement learning, imitation learning, state estimation, mapping, and computer vision.



### Bayesian Inference of Spacecraft Pose using Particle Filtering
- **Arxiv ID**: http://arxiv.org/abs/1906.11182v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11182v1)
- **Published**: 2019-06-26 16:02:44+00:00
- **Updated**: 2019-06-26 16:02:44+00:00
- **Authors**: Maxim Bazik, Brien Flewelling, Manoranjan Majji, Joseph Mundy
- **Comment**: None
- **Journal**: Proc. AMOS Technical Conf. (2018) 757-762
- **Summary**: Automated 3D pose estimation of satellites and other known space objects is a critical component of space situational awareness. Ground-based imagery offers a convenient data source for satellite characterization; however, analysis algorithms must contend with atmospheric distortion, variable lighting, and unknown reflectance properties. Traditional feature-based pose estimation approaches are unable to discover an accurate correlation between a known 3D model and imagery given this challenging image environment. This paper presents an innovative method for automated 3D pose estimation of known space objects in the absence of satisfactory texture. The proposed approach fits the silhouette of a known satellite model to ground-based imagery via particle filtering. Each particle contains enough information (orientation, position, scale, model articulation) to generate an accurate object silhouette. The silhouette of individual particles is compared to an observed image. Comparison is done probabilistically by calculating the joint probability that pixels inside the silhouette belong to the foreground distribution and that pixels outside the silhouette belong to the background distribution. Both foreground and background distributions are computed by observing empty space. The population of particles are resampled at each new image observation, with the probability of a particle being resampled proportional to how the particle's silhouette matches the observation image. The resampling process maintains multiple pose estimates which is beneficial in preventing and escaping local minimums. Experiments were conducted on both commercial imagery and on LEO satellite imagery. Imagery from the commercial experiments are shown in this paper.



### Detection of small changes in medical and random-dot images comparing self-organizing map performance to human detection
- **Arxiv ID**: http://arxiv.org/abs/1906.11675v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.11675v1)
- **Published**: 2019-06-26 16:42:19+00:00
- **Updated**: 2019-06-26 16:42:19+00:00
- **Authors**: John Wandeto, Henry Nyongesa, Yves Remond, Birgitta Dresp-Langley
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1709.02292
- **Journal**: Informatics in Medecine Unlocked, 2017, 7, 39-45
- **Summary**: Radiologists use time series of medical images to monitor the progression of a patient condition. They compare information gleaned from sequences of images to gain insight on progression or remission of the lesions, thus evaluating the progress of a patient condition or response to therapy. Visual methods of determining differences between one series of images to another can be subjective or fail to detect very small differences. We propose the use of quantization errors obtained from Self Organizing Maps for image content analysis. We tested this technique with MRI images to which we progressively added synthetic lesions. We have used a global approach that considers changes on the entire image as opposed to changes in segmented lesion regions only. We claim that this approach does not suffer from the limitations imposed by segmentation, which may compromise the results. Results show quantization errors increased with the increase in lesions on the images. The results are also consistent with previous studies using alternative approaches. We then compared the detectability ability of our method to that of human novice observers having to detect very small local differences in random-dot images. The quantization errors of the SOM outputs compared with correct positive rates, after subtraction of false positive rates (guess rates), increased noticeably and consistently with small increases in local dot size that were not detectable by humans. We conclude that our method detects very small changes in complex images and suggest that it could be implemented to assist human operators in image based decision making.



### Invariance-inducing regularization using worst-case transformations suffices to boost accuracy and spatial robustness
- **Arxiv ID**: http://arxiv.org/abs/1906.11235v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.11235v1)
- **Published**: 2019-06-26 17:57:10+00:00
- **Updated**: 2019-06-26 17:57:10+00:00
- **Authors**: Fanny Yang, Zuowen Wang, Christina Heinze-Deml
- **Comment**: None
- **Journal**: None
- **Summary**: This work provides theoretical and empirical evidence that invariance-inducing regularizers can increase predictive accuracy for worst-case spatial transformations (spatial robustness). Evaluated on these adversarially transformed examples, we demonstrate that adding regularization on top of standard or adversarial training reduces the relative error by 20% for CIFAR10 without increasing the computational cost. This outperforms handcrafted networks that were explicitly designed to be spatial-equivariant. Furthermore, we observe for SVHN, known to have inherent variance in orientation, that robust training also improves standard accuracy on the test set. We prove that this no-trade-off phenomenon holds for adversarial examples from transformation groups in the infinite data limit.



### Developing an App to interpret Chest X-rays to support the diagnosis of respiratory pathology with Artificial Intelligence
- **Arxiv ID**: http://arxiv.org/abs/1906.11282v1
- **DOI**: None
- **Categories**: **cs.CV**, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1906.11282v1)
- **Published**: 2019-06-26 18:14:18+00:00
- **Updated**: 2019-06-26 18:14:18+00:00
- **Authors**: Andrew Elkins, Felipe F. Freitas, Veronica Sanz
- **Comment**: 28 pages, 23 figures
- **Journal**: None
- **Summary**: In this paper we present our work to improve access to diagnosis in remote areas where good quality medical services may be lacking. We develop new Machine Learning methodologies for deployment onto mobile devices to help the early diagnosis of a number of life-threatening conditions using X-ray images. By using the latest developments in fast and portable Artificial Intelligence environments, we develop a smartphone app using an Artificial Neural Network to assist physicians in their diagnostic.



### One Size Does Not Fit All: Quantifying and Exposing the Accuracy-Latency Trade-off in Machine Learning Cloud Service APIs via Tolerance Tiers
- **Arxiv ID**: http://arxiv.org/abs/1906.11307v1
- **DOI**: 10.1109/ISPASS.2019.00012
- **Categories**: **cs.LG**, cs.CV, cs.PF
- **Links**: [PDF](http://arxiv.org/pdf/1906.11307v1)
- **Published**: 2019-06-26 19:35:59+00:00
- **Updated**: 2019-06-26 19:35:59+00:00
- **Authors**: Matthew Halpern, Behzad Boroujerdian, Todd Mummert, Evelyn Duesterwald, Vijay Janapa Reddi
- **Comment**: 2019 IEEE International Symposium on Performance Analysis of Systems
  and Software (ISPASS)
- **Journal**: None
- **Summary**: Today's cloud service architectures follow a "one size fits all" deployment strategy where the same service version instantiation is provided to the end users. However, consumers are broad and different applications have different accuracy and responsiveness requirements, which as we demonstrate renders the "one size fits all" approach inefficient in practice. We use a production-grade speech recognition engine, which serves several thousands of users, and an open source computer vision based system, to explain our point. To overcome the limitations of the "one size fits all" approach, we recommend Tolerance Tiers where each MLaaS tier exposes an accuracy/responsiveness characteristic, and consumers can programmatically select a tier. We evaluate our proposal on the CPU-based automatic speech recognition (ASR) engine and cutting-edge neural networks for image classification deployed on both CPUs and GPUs. The results show that our proposed approach provides an MLaaS cloud service architecture that can be tuned by the end API user or consumer to outperform the conventional "one size fits all" approach.



### Large-scale 3D point cloud representations via graph inception networks with applications to autonomous driving
- **Arxiv ID**: http://arxiv.org/abs/1906.11359v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1906.11359v1)
- **Published**: 2019-06-26 21:54:53+00:00
- **Updated**: 2019-06-26 21:54:53+00:00
- **Authors**: Siheng Chen, Sufeng. Niu, Tian Lan, Baoan Liu
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel graph-neural-network-based system to effectively represent large-scale 3D point clouds with the applications to autonomous driving. Many previous works studied the representations of 3D point clouds based on two approaches, voxelization, which causes discretization errors and learning, which is hard to capture huge variations in large-scale scenarios. In this work, we combine voxelization and learning: we discretize the 3D space into voxels and propose novel graph inception networks to represent 3D points in each voxel. This combination makes the system avoid discretization errors and work for large-scale scenarios. The entire system for large-scale 3D point clouds acts like the blocked discrete cosine transform for 2D images; we thus call it the point cloud neural transform (PCT). We further apply the proposed PCT to represent real-time LiDAR sweeps produced by self-driving cars and the PCT with graph inception networks significantly outperforms its competitors.



### Accelerating Large-Kernel Convolution Using Summed-Area Tables
- **Arxiv ID**: http://arxiv.org/abs/1906.11367v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.11367v1)
- **Published**: 2019-06-26 22:24:56+00:00
- **Updated**: 2019-06-26 22:24:56+00:00
- **Authors**: Linguang Zhang, Maciej Halber, Szymon Rusinkiewicz
- **Comment**: None
- **Journal**: None
- **Summary**: Expanding the receptive field to capture large-scale context is key to obtaining good performance in dense prediction tasks, such as human pose estimation. While many state-of-the-art fully-convolutional architectures enlarge the receptive field by reducing resolution using strided convolution or pooling layers, the most straightforward strategy is adopting large filters. This, however, is costly because of the quadratic increase in the number of parameters and multiply-add operations. In this work, we explore using learnable box filters to allow for convolution with arbitrarily large kernel size, while keeping the number of parameters per filter constant. In addition, we use precomputed summed-area tables to make the computational cost of convolution independent of the filter size. We adapt and incorporate the box filter as a differentiable module in a fully-convolutional neural network, and demonstrate its competitive performance on popular benchmarks for the task of human pose estimation.



