# Arxiv Papers in cs.CV on 2019-06-22
### Baidu-UTS Submission to the EPIC-Kitchens Action Recognition Challenge 2019
- **Arxiv ID**: http://arxiv.org/abs/1906.09383v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.09383v1)
- **Published**: 2019-06-22 03:45:41+00:00
- **Updated**: 2019-06-22 03:45:41+00:00
- **Authors**: Xiaohan Wang, Yu Wu, Linchao Zhu, Yi Yang
- **Comment**: None
- **Journal**: None
- **Summary**: In this report, we present the Baidu-UTS submission to the EPIC-Kitchens Action Recognition Challenge in CVPR 2019. This is the winning solution to this challenge. In this task, the goal is to predict verbs, nouns, and actions from the vocabulary for each video segment. The EPIC-Kitchens dataset contains various small objects, intense motion blur, and occlusions. It is challenging to locate and recognize the object that an actor interacts with. To address these problems, we utilize object detection features to guide the training of 3D Convolutional Neural Networks (CNN), which can significantly improve the accuracy of noun prediction. Specifically, we introduce a Gated Feature Aggregator module to learn from the clip feature and the object feature. This module can strengthen the interaction between the two kinds of activations and avoid gradient exploding. Experimental results demonstrate our approach outperforms other methods on both seen and unseen test set.



### Deep Single Image Deraining Via Estimating Transmission and Atmospheric Light in rainy Scenes
- **Arxiv ID**: http://arxiv.org/abs/1906.09433v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.09433v1)
- **Published**: 2019-06-22 10:58:27+00:00
- **Updated**: 2019-06-22 10:58:27+00:00
- **Authors**: Yinglong Wang, Qinfeng Shi, Ehsan Abbasnejad, Chao Ma, Xiaoping Ma, Bing Zeng
- **Comment**: 10 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: Rain removal in images/videos is still an important task in computer vision field and attracting attentions of more and more people. Traditional methods always utilize some incomplete priors or filters (e.g. guided filter) to remove rain effect. Deep learning gives more probabilities to better solve this task. However, they remove rain either by evaluating background from rainy image directly or learning a rain residual first then subtracting the residual to obtain a clear background. No other models are used in deep learning based de-raining methods to remove rain and obtain other information about rainy scenes. In this paper, we utilize an extensively-used image degradation model which is derived from atmospheric scattering principles to model the formation of rainy images and try to learn the transmission, atmospheric light in rainy scenes and remove rain further. To reach this goal, we propose a robust evaluation method of global atmospheric light in a rainy scene. Instead of using the estimated atmospheric light directly to learn a network to calculate transmission, we utilize it as ground truth and design a simple but novel triangle-shaped network structure to learn atmospheric light for every rainy image, then fine-tune the network to obtain a better estimation of atmospheric light during the training of transmission network. Furthermore, more efficient ShuffleNet Units are utilized in transmission network to learn transmission map and the de-raining image is then obtained by the image degradation model. By subjective and objective comparisons, our method outperforms the selected state-of-the-art works.



### Adaptive Period Embedding for Representing Oriented Objects in Aerial Images
- **Arxiv ID**: http://arxiv.org/abs/1906.09447v1
- **DOI**: 10.1109/TGRS.2020.2981203
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.09447v1)
- **Published**: 2019-06-22 13:40:43+00:00
- **Updated**: 2019-06-22 13:40:43+00:00
- **Authors**: Yixing Zhu, Xueqing Wu, Jun Du
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel method for representing oriented objects in aerial images named Adaptive Period Embedding (APE). While traditional object detection methods represent object with horizontal bounding boxes, the objects in aerial images are oritented. Calculating the angle of object is an yet challenging task. While almost all previous object detectors for aerial images directly regress the angle of objects, they use complex rules to calculate the angle, and their performance is limited by the rule design. In contrast, our method is based on the angular periodicity of oriented objects. The angle is represented by two two-dimensional periodic vectors whose periods are different, the vector is continuous as shape changes. The label generation rule is more simple and reasonable compared with previous methods. The proposed method is general and can be applied to other oriented detector. Besides, we propose a novel IoU calculation method for long objects named length independent IoU (LIIoU). We intercept part of the long side of the target box to get the maximum IoU between the proposed box and the intercepted target box. Thereby, some long boxes will have corresponding positive samples. Our method reaches the 1st place of DOAI2019 competition task1 (oriented object) held in workshop on Detecting Objects in Aerial Images in conjunction with IEEE CVPR 2019.



### Deep learning approach to description and classification of fungi microscopic images
- **Arxiv ID**: http://arxiv.org/abs/1906.09449v3
- **DOI**: 10.1371/journal.pone.0234806
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1906.09449v3)
- **Published**: 2019-06-22 14:00:51+00:00
- **Updated**: 2020-01-28 14:30:00+00:00
- **Authors**: Bartosz Zieliński, Agnieszka Sroka-Oleksiak, Dawid Rymarczyk, Adam Piekarczyk, Monika Brzychczy-Włoch
- **Comment**: None
- **Journal**: None
- **Summary**: Diagnosis of fungal infections can rely on microscopic examination, however, in many cases, it does not allow unambiguous identification of the species due to their visual similarity. Therefore, it is usually necessary to use additional biochemical tests. That involves additional costs and extends the identification process up to 10 days. Such a delay in the implementation of targeted treatment is grave in consequences as the mortality rate for immunosuppressed patients is high. In this paper, we apply machine learning approach based on deep learning and bag-of-words to classify microscopic images of various fungi species. Our approach makes the last stage of biochemical identification redundant, shortening the identification process by 2-3 days and reducing the cost of the diagnostic examination.



### Iris Verification with Convolutional Neural Network and Unit-Circle Layer
- **Arxiv ID**: http://arxiv.org/abs/1906.09472v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.09472v2)
- **Published**: 2019-06-22 17:11:15+00:00
- **Updated**: 2019-09-17 14:57:36+00:00
- **Authors**: Radim Spetlik, Ivan Razumenic
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel convolutional neural network to verify a~match between two normalized images of the human iris. The network is trained end-to-end and validated on three publicly available datasets yielding state-of-the-art results against four baseline methods. The network performs better by a 10% margin to the state-of-the-art method on the CASIA.v4 dataset. In the network, we use a novel Unit-Circle Layer layer which replaces the Gabor-filtering step in a common iris-verification pipeline. We show that the layer improves the performance of the model up to 15% on previously-unseen data.



### Image Retrieval and Pattern Spotting using Siamese Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1906.09513v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1906.09513v1)
- **Published**: 2019-06-22 22:33:44+00:00
- **Updated**: 2019-06-22 22:33:44+00:00
- **Authors**: Kelly L. Wiggers, Alceu S. Britto Jr., Laurent Heutte, Alessandro L. Koerich, Luiz S. Oliveira
- **Comment**: Accepted for IJCNN 2019
- **Journal**: None
- **Summary**: This paper presents a novel approach for image retrieval and pattern spotting in document image collections. The manual feature engineering is avoided by learning a similarity-based representation using a Siamese Neural Network trained on a previously prepared subset of image pairs from the ImageNet dataset. The learned representation is used to provide the similarity-based feature maps used to find relevant image candidates in the data collection given an image query. A robust experimental protocol based on the public Tobacco800 document image collection shows that the proposed method compares favorably against state-of-the-art document image retrieval methods, reaching 0.94 and 0.83 of mean average precision (mAP) for retrieval and pattern spotting (IoU=0.7), respectively. Besides, we have evaluated the proposed method considering feature maps of different sizes, showing the impact of reducing the number of features in the retrieval performance and time-consuming.



