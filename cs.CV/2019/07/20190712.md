# Arxiv Papers in cs.CV on 2019-07-12
### MLR (Memory, Learning and Recognition): A General Cognitive Model -- applied to Intelligent Robots and Systems Control
- **Arxiv ID**: http://arxiv.org/abs/1907.05553v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1907.05553v1)
- **Published**: 2019-07-12 02:40:37+00:00
- **Updated**: 2019-07-12 02:40:37+00:00
- **Authors**: Aras R. Dargazany
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a new perspective of intelligent robots and systems control. The presented and proposed cognitive model: Memory, Learning and Recognition (MLR), is an effort to bridge the gap between Robotics, AI, Cognitive Science, and Neuroscience. The currently existing gap prevents us from integrating the current advancement and achievements of these four research fields which are actively trying to define intelligence in either application-based way or in generic way. This cognitive model defines intelligence more specifically, parametrically and detailed. The proposed MLR model helps us create a general control model for robots and systems independent of their application domains and platforms since it is mainly based on the dataset provided for robots and systems controls. This paper is mainly proposing and introducing this concept and trying to prove this concept in a small scale, firstly through experimentation. The proposed concept is also applicable to other different platforms in real-time as well as in simulation.



### Dual Adversarial Semantics-Consistent Network for Generalized Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1907.05570v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05570v1)
- **Published**: 2019-07-12 03:53:08+00:00
- **Updated**: 2019-07-12 03:53:08+00:00
- **Authors**: Jian Ni, Shanghang Zhang, Haiyong Xie
- **Comment**: 10 pages, 5 figures,
- **Journal**: None
- **Summary**: Generalized zero-shot learning (GZSL) is a challenging class of vision and knowledge transfer problems in which both seen and unseen classes appear during testing. Existing GZSL approaches either suffer from semantic loss and discard discriminative information at the embedding stage, or cannot guarantee the visual-semantic interactions. To address these limitations, we propose the Dual Adversarial Semantics-Consistent Network (DASCN), which learns primal and dual Generative Adversarial Networks (GANs) in a unified framework for GZSL. In particular, the primal GAN learns to synthesize inter-class discriminative and semantics-preserving visual features from both the semantic representations of seen/unseen classes and the ones reconstructed by the dual GAN. The dual GAN enforces the synthetic visual features to represent prior semantic knowledge well via semantics-consistent adversarial learning. To the best of our knowledge, this is the first work that employs a novel dual-GAN mechanism for GZSL. Extensive experiments show that our approach achieves significant improvements over the state-of-the-art approaches.



### R-Transformer: Recurrent Neural Network Enhanced Transformer
- **Arxiv ID**: http://arxiv.org/abs/1907.05572v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/1907.05572v1)
- **Published**: 2019-07-12 04:01:57+00:00
- **Updated**: 2019-07-12 04:01:57+00:00
- **Authors**: Zhiwei Wang, Yao Ma, Zitao Liu, Jiliang Tang
- **Comment**: None
- **Journal**: None
- **Summary**: Recurrent Neural Networks have long been the dominating choice for sequence modeling. However, it severely suffers from two issues: impotent in capturing very long-term dependencies and unable to parallelize the sequential computation procedure. Therefore, many non-recurrent sequence models that are built on convolution and attention operations have been proposed recently. Notably, models with multi-head attention such as Transformer have demonstrated extreme effectiveness in capturing long-term dependencies in a variety of sequence modeling tasks. Despite their success, however, these models lack necessary components to model local structures in sequences and heavily rely on position embeddings that have limited effects and require a considerable amount of design efforts. In this paper, we propose the R-Transformer which enjoys the advantages of both RNNs and the multi-head attention mechanism while avoids their respective drawbacks. The proposed model can effectively capture both local structures and global long-term dependencies in sequences without any use of position embeddings. We evaluate R-Transformer through extensive experiments with data from a wide range of domains and the empirical results show that R-Transformer outperforms the state-of-the-art methods by a large margin in most of the tasks. We have made the code publicly available at \url{https://github.com/DSE-MSU/R-transformer}.



### Boosting Scene Character Recognition by Learning Canonical Forms of Glyphs
- **Arxiv ID**: http://arxiv.org/abs/1907.05577v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05577v2)
- **Published**: 2019-07-12 04:55:03+00:00
- **Updated**: 2019-07-25 09:42:53+00:00
- **Authors**: Yizhi Wang, Zhouhui Lian, Yingmin Tang, Jianguo Xiao
- **Comment**: Accepted by International Journal on Document Analysis and
  Recognition (IJDAR), will appear in ICDAR 2019. Code:
  https://github.com/Actasidiot/CGRN
- **Journal**: None
- **Summary**: As one of the fundamental problems in document analysis, scene character recognition has attracted considerable interests in recent years. But the problem is still considered to be extremely challenging due to many uncontrollable factors including glyph transformation, blur, noisy background, uneven illumination, etc. In this paper, we propose a novel methodology for boosting scene character recognition by learning canonical forms of glyphs, based on the fact that characters appearing in scene images are all derived from their corresponding canonical forms. Our key observation is that more discriminative features can be learned by solving specially-designed generative tasks compared to traditional classification-based feature learning frameworks. Specifically, we design a GAN-based model to make the learned deep feature of a given scene character be capable of reconstructing corresponding glyphs in a number of standard font styles. In this manner, we obtain deep features for scene characters that are more discriminative in recognition and less sensitive against the above-mentioned factors. Our experiments conducted on several publicly-available databases demonstrate the superiority of our method compared to the state of the art.



### Jointly Adversarial Network to Wavelength Compensation and Dehazing of Underwater Images
- **Arxiv ID**: http://arxiv.org/abs/1907.05595v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1907.05595v1)
- **Published**: 2019-07-12 07:08:11+00:00
- **Updated**: 2019-07-12 07:08:11+00:00
- **Authors**: Xueyan Ding, Yafei Wang, Yang Yan, Zheng Liang, Zetian Mi, Xianping Fu
- **Comment**: None
- **Journal**: None
- **Summary**: Severe color casts, low contrast and blurriness of underwater images caused by light absorption and scattering result in a difficult task for exploring underwater environments. Different from most of previous underwater image enhancement methods that compute light attenuation along object-camera path through hazy image formation model, we propose a novel jointly wavelength compensation and dehazing network (JWCDN) that takes into account the wavelength attenuation along surface-object path and the scattering along object-camera path simultaneously. By embedding a simplified underwater formation model into generative adversarial network, we can jointly estimates the transmission map, wavelength attenuation and background light via different network modules, and uses the simplified underwater image formation model to recover degraded underwater images. Especially, a multi-scale densely connected encoder-decoder network is proposed to leverage features from multiple layers for estimating the transmission map. To further improve the recovered image, we use an edge preserving network module to enhance the detail of the recovered image. Moreover, to train the proposed network, we propose a novel underwater image synthesis method that generates underwater images with inherent optical properties of different water types. The synthesis method can simulate the color, contrast and blurriness appearance of real-world underwater environments simultaneously. Extensive experiments on synthetic and real-world underwater images demonstrate that the proposed method yields comparable or better results on both subjective and objective assessments, compared with several state-of-the-art methods.



### Coupled-Projection Residual Network for MRI Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1907.05598v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1907.05598v1)
- **Published**: 2019-07-12 07:30:46+00:00
- **Updated**: 2019-07-12 07:30:46+00:00
- **Authors**: Chun-Mei Feng, Kai Wang, Shijian Lu, Yong Xu, Heng Kong, Ling Shao
- **Comment**: Our source code will be publicly available at
  http://www.yongxu.org/lunwen.html
- **Journal**: None
- **Summary**: Magnetic Resonance Imaging(MRI) has been widely used in clinical application and pathology research by helping doctors make more accurate diagnoses. On the other hand, accurate diagnosis by MRI remains a great challenge as images obtained via present MRI techniques usually have low resolutions. Improving MRI image quality and resolution thus becomes a critically important task. This paper presents an innovative Coupled-Projection Residual Network (CPRN) for MRI super-resolution. The CPRN consists of two complementary sub-networks: a shallow network and a deep network that keep the content consistency while learning high frequency differences between low-resolution and high-resolution images. The shallow sub-network employs coupled-projection for better retaining the MRI image details, where a novel feedback mechanism is introduced to guide the reconstruction of high-resolution images. The deep sub-network learns from the residuals of the high-frequency image information, where multiple residual blocks are cascaded to magnify the MRI images at the last network layer. Finally, the features from the shallow and deep sub-networks are fused for the reconstruction of high-resolution MRI images. For effective fusion of features from the deep and shallow sub-networks, a step-wise connection (CPRN S) is designed as inspired by the human cognitive processes (from simple to complex). Experiments over three public MRI datasets show that our proposed CPRN achieves superior MRI super-resolution performance as compared with the state-of-the-art. Our source code will be publicly available at http://www.yongxu.org/lunwen.html.



### Tiny-Inception-ResNet-v2: Using Deep Learning for Eliminating Bonded Labors of Brick Kilns in South Asia
- **Arxiv ID**: http://arxiv.org/abs/1907.05552v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1907.05552v1)
- **Published**: 2019-07-12 07:43:42+00:00
- **Updated**: 2019-07-12 07:43:42+00:00
- **Authors**: Usman Nazir, Numan Khurshid, Muhammad Ahmed Bhimra, Murtaza Taj
- **Comment**: None
- **Journal**: CVPR 2019 workshop
- **Summary**: This paper proposes to employ a Inception-ResNet inspired deep learning architecture called Tiny-Inception-ResNet-v2 to eliminate bonded labor by identifying brick kilns within "Brick-Kiln-Belt" of South Asia. The framework is developed by training a network on the satellite imagery consisting of 11 different classes of South Asian region. The dataset developed during the process includes the geo-referenced images of brick kilns, houses, roads, tennis courts, farms, sparse trees, dense trees, orchards, parking lots, parks and barren lands. The dataset is made publicly available for further research. Our proposed network architecture with very fewer learning parameters outperforms all state-of-the-art architectures employed for recognition of brick kilns. Our proposed solution would enable regional monitoring and evaluation mechanisms for the Sustainable Development Goals.



### Sparsely Activated Networks
- **Arxiv ID**: http://arxiv.org/abs/1907.06592v9
- **DOI**: 10.1109/TNNLS.2020.2984514
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1907.06592v9)
- **Published**: 2019-07-12 08:01:47+00:00
- **Updated**: 2022-05-16 18:27:36+00:00
- **Authors**: Paschalis Bizopoulos, Dimitrios Koutsouris
- **Comment**: 10 pages, 5 figures, 4 algorithms, 4 tables, submission to IEEE
  Transactions on Neural Networks and Learning Systems
- **Journal**: None
- **Summary**: Previous literature on unsupervised learning focused on designing structural priors with the aim of learning meaningful features. However, this was done without considering the description length of the learned representations which is a direct and unbiased measure of the model complexity. In this paper, first we introduce the $\varphi$ metric that evaluates unsupervised models based on their reconstruction accuracy and the degree of compression of their internal representations. We then present and define two activation functions (Identity, ReLU) as base of reference and three sparse activation functions (top-k absolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize the previously defined $\varphi$. We lastly present Sparsely Activated Networks (SANs) that consist of kernels with shared weights that, during encoding, are convolved with the input and then passed through a sparse activation function. During decoding, the same weights are convolved with the sparse activation map and subsequently the partial reconstructions from each weight are summed to reconstruct the input. We compare SANs using the five previously defined activation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST, FMNIST) and show that models that are selected using $\varphi$ have small description representation length and consist of interpretable kernels.



### CoachAI: A Project for Microscopic Badminton Match Data Collection and Tactical Analysis
- **Arxiv ID**: http://arxiv.org/abs/1907.12888v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1907.12888v1)
- **Published**: 2019-07-12 08:33:00+00:00
- **Updated**: 2019-07-12 08:33:00+00:00
- **Authors**: Tzu-Han Hsu, Ching-Hsuan Chen, Nyan Ping Ju, Tsì-Uí İk, Wen-Chih Peng, Chih-Chuan Wang, Yu-Shuen Wang, Yuan-Hsiang Lin, Yu-Chee Tseng, Jiun-Long Huang, Yu-Tai Ching
- **Comment**: None
- **Journal**: None
- **Summary**: Computer vision based object tracking has been used to annotate and augment sports video. For sports learning and training, video replay is often used in post-match review and training review for tactical analysis and movement analysis. For automatically and systematically competition data collection and tactical analysis, a project called CoachAI has been supported by the Ministry of Science and Technology, Taiwan. The proposed project also includes research of data visualization, connected training auxiliary devices, and data warehouse. Deep learning techniques will be used to develop video-based real-time microscopic competition data collection based on broadcast competition video. Machine learning techniques will be used to develop a tactical analysis. To reveal data in more understandable forms and to help in pre-match training, AR/VR techniques will be used to visualize data, tactics, and so on. In addition, training auxiliary devices including smart badminton rackets and connected serving machines will be developed based on the IoT technology to further utilize competition data and tactical data and boost training efficiency. Especially, the connected serving machines will be developed to perform specified tactics and to interact with players in their training.



### AVD: Adversarial Video Distillation
- **Arxiv ID**: http://arxiv.org/abs/1907.05640v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05640v1)
- **Published**: 2019-07-12 09:23:32+00:00
- **Updated**: 2019-07-12 09:23:32+00:00
- **Authors**: Mohammad Tavakolian, Mohammad Sabokrou, Abdenour Hadid
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a simple yet efficient approach for video representation, called Adversarial Video Distillation (AVD). The key idea is to represent videos by compressing them in the form of realistic images, which can be used in a variety of video-based scene analysis applications. Representing a video as a single image enables us to address the problem of video analysis by image analysis techniques. To this end, we exploit a 3D convolutional encoder-decoder network to encode the input video as an image by minimizing the reconstruction error. Furthermore, weak supervision by an adversarial training procedure is imposed on the output of the encoder to generate semantically realistic images. The encoder learns to extract semantically meaningful representations from a given input video by mapping the 3D input into a 2D latent representation. The obtained representation can be simply used as the input of deep models pre-trained on images for video classification. We evaluated the effectiveness of our proposed method for video-based activity recognition on three standard and challenging benchmark datasets, i.e. UCF101, HMDB51, and Kinetics. The experimental results demonstrate that AVD achieves interesting performance, outperforming the state-of-the-art methods for video classification.



### Neural Epitome Search for Architecture-Agnostic Network Compression
- **Arxiv ID**: http://arxiv.org/abs/1907.05642v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05642v3)
- **Published**: 2019-07-12 09:38:52+00:00
- **Updated**: 2019-12-28 13:26:40+00:00
- **Authors**: Daquan Zhou, Xiaojie Jin, Qibin Hou, Kaixin Wang, Jianchao Yang, Jiashi Feng
- **Comment**: None
- **Journal**: None
- **Summary**: The recent WSNet [1] is a new model compression method through sampling filterweights from a compact set and has demonstrated to be effective for 1D convolutionneural networks (CNNs). However, the weights sampling strategy of WSNet ishandcrafted and fixed which may severely limit the expression ability of the resultedCNNs and weaken its compression ability. In this work, we present a novel auto-sampling method that is applicable to both 1D and 2D CNNs with significantperformance improvement over WSNet. Specifically, our proposed auto-samplingmethod learns the sampling rules end-to-end instead of being independent of thenetwork architecture design. With such differentiable weight sampling rule learning,the sampling stride and channel selection from the compact set are optimized toachieve better trade-off between model compression rate and performance. Wedemonstrate that at the same compression ratio, our method outperforms WSNetby6.5% on 1D convolution. Moreover, on ImageNet, our method outperformsMobileNetV2 full model by1.47%in classification accuracy with25%FLOPsreduction. With the same backbone architecture as baseline models, our methodeven outperforms some neural architecture search (NAS) based methods such asAMC [2] and MNasNet [3].



### VarGNet: Variable Group Convolutional Neural Network for Efficient Embedded Computing
- **Arxiv ID**: http://arxiv.org/abs/1907.05653v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05653v2)
- **Published**: 2019-07-12 10:08:44+00:00
- **Updated**: 2020-04-30 00:49:23+00:00
- **Authors**: Qian Zhang, Jianjun Li, Meng Yao, Liangchen Song, Helong Zhou, Zhichao Li, Wenming Meng, Xuezhi Zhang, Guoli Wang
- **Comment**: Technical report
- **Journal**: None
- **Summary**: In this paper, we propose a novel network design mechanism for efficient embedded computing. Inspired by the limited computing patterns, we propose to fix the number of channels in a group convolution, instead of the existing practice that fixing the total group numbers. Our solution based network, named Variable Group Convolutional Network (VarGNet), can be optimized easier on hardware side, due to the more unified computing schemes among the layers. Extensive experiments on various vision tasks, including classification, detection, pixel-wise parsing and face recognition, have demonstrated the practical value of our VarGNet.



### Adversarial Lipschitz Regularization
- **Arxiv ID**: http://arxiv.org/abs/1907.05681v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1907.05681v3)
- **Published**: 2019-07-12 11:41:18+00:00
- **Updated**: 2020-01-03 09:11:31+00:00
- **Authors**: Dávid Terjék
- **Comment**: ICLR 2020
- **Journal**: None
- **Summary**: Generative adversarial networks (GANs) are one of the most popular approaches when it comes to training generative models, among which variants of Wasserstein GANs are considered superior to the standard GAN formulation in terms of learning stability and sample quality. However, Wasserstein GANs require the critic to be 1-Lipschitz, which is often enforced implicitly by penalizing the norm of its gradient, or by globally restricting its Lipschitz constant via weight normalization techniques. Training with a regularization term penalizing the violation of the Lipschitz constraint explicitly, instead of through the norm of the gradient, was found to be practically infeasible in most situations. Inspired by Virtual Adversarial Training, we propose a method called Adversarial Lipschitz Regularization, and show that using an explicit Lipschitz penalty is indeed viable and leads to competitive performance when applied to Wasserstein GANs, highlighting an important connection between Lipschitz regularization and adversarial training.



### And the Bit Goes Down: Revisiting the Quantization of Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1907.05686v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05686v5)
- **Published**: 2019-07-12 11:52:54+00:00
- **Updated**: 2020-11-09 10:11:15+00:00
- **Authors**: Pierre Stock, Armand Joulin, Rémi Gribonval, Benjamin Graham, Hervé Jégou
- **Comment**: ICLR 2020 camera-ready
- **Journal**: None
- **Summary**: In this paper, we address the problem of reducing the memory footprint of convolutional network architectures. We introduce a vector quantization method that aims at preserving the quality of the reconstruction of the network outputs rather than its weights. The principle of our approach is that it minimizes the loss reconstruction error for in-domain inputs. Our method only requires a set of unlabelled data at quantization time and allows for efficient inference on CPU by using byte-aligned codebooks to store the compressed weights. We validate our approach by quantizing a high performing ResNet-50 model to a memory size of 5MB (20x compression factor) while preserving a top-1 accuracy of 76.1% on ImageNet object classification and by compressing a Mask R-CNN with a 26x factor.



### PC-DARTS: Partial Channel Connections for Memory-Efficient Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/1907.05737v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1907.05737v4)
- **Published**: 2019-07-12 13:26:09+00:00
- **Updated**: 2020-04-07 06:20:35+00:00
- **Authors**: Yuhui Xu, Lingxi Xie, Xiaopeng Zhang, Xin Chen, Guo-Jun Qi, Qi Tian, Hongkai Xiong
- **Comment**: Accepted by ICLR2020
- **Journal**: None
- **Summary**: Differentiable architecture search (DARTS) provided a fast solution in finding effective network architectures, but suffered from large memory and computing overheads in jointly training a super-network and searching for an optimal architecture. In this paper, we present a novel approach, namely, Partially-Connected DARTS, by sampling a small part of super-network to reduce the redundancy in exploring the network space, thereby performing a more efficient search without comprising the performance. In particular, we perform operation search in a subset of channels while bypassing the held out part in a shortcut. This strategy may suffer from an undesired inconsistency on selecting the edges of super-net caused by sampling different channels. We alleviate it using edge normalization, which adds a new set of edge-level parameters to reduce uncertainty in search. Thanks to the reduced memory cost, PC-DARTS can be trained with a larger batch size and, consequently, enjoys both faster speed and higher training stability. Experimental results demonstrate the effectiveness of the proposed method. Specifically, we achieve an error rate of 2.57% on CIFAR10 with merely 0.1 GPU-days for architecture search, and a state-of-the-art top-1 error rate of 24.2% on ImageNet (under the mobile setting) using 3.8 GPU-days for search. Our code has been made available at: https://github.com/yuhuixu1993/PC-DARTS.



### Learning a Curve Guardian for Motorcycles
- **Arxiv ID**: http://arxiv.org/abs/1907.05738v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO, cs.SY, eess.SY
- **Links**: [PDF](http://arxiv.org/pdf/1907.05738v1)
- **Published**: 2019-07-12 13:26:42+00:00
- **Updated**: 2019-07-12 13:26:42+00:00
- **Authors**: Simon Hecker, Alexander Liniger, Henrik Maurenbrecher, Dengxin Dai, Luc Van Gool
- **Comment**: 8 pages, to be presented at IEEE-ITSC 2019
- **Journal**: None
- **Summary**: Up to 17% of all motorcycle accidents occur when the rider is maneuvering through a curve and the main cause of curve accidents can be attributed to inappropriate speed and wrong intra-lane position of the motorcycle. Existing curve warning systems lack crucial state estimation components and do not scale well. We propose a new type of road curvature warning system for motorcycles, combining the latest advances in computer vision, optimal control and mapping technologies to alleviate these shortcomings. Our contributes are fourfold: 1) we predict the motorcycle's intra-lane position using a convolutional neural network (CNN), 2) we predict the motorcycle roll angle using a CNN, 3) we use an upgraded controller model that incorporates road incline for a more realistic model and prediction, 4) we design a scale-able system by utilizing HERE Technologies map database to obtain the accurate road geometry of the future path. In addition, we present two datasets that are used for training and evaluating of our system respectively, both datasets will be made publicly available. We test our system on a diverse set of real world scenarios and present a detailed case-study. We show that our system is able to predict more accurate and safer curve trajectories, and consequently warn and improve the safety for motorcyclists.



### Gated-SCNN: Gated Shape CNNs for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1907.05740v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1907.05740v1)
- **Published**: 2019-07-12 13:37:46+00:00
- **Updated**: 2019-07-12 13:37:46+00:00
- **Authors**: Towaki Takikawa, David Acuna, Varun Jampani, Sanja Fidler
- **Comment**: Project Website: https://nv-tlabs.github.io/GSCNN/
- **Journal**: None
- **Summary**: Current state-of-the-art methods for image segmentation form a dense image representation where the color, shape and texture information are all processed together inside a deep CNN. This however may not be ideal as they contain very different type of information relevant for recognition. Here, we propose a new two-stream CNN architecture for semantic segmentation that explicitly wires shape information as a separate processing branch, i.e. shape stream, that processes information in parallel to the classical stream. Key to this architecture is a new type of gates that connect the intermediate layers of the two streams. Specifically, we use the higher-level activations in the classical stream to gate the lower-level activations in the shape stream, effectively removing noise and helping the shape stream to only focus on processing the relevant boundary-related information. This enables us to use a very shallow architecture for the shape stream that operates on the image-level resolution. Our experiments show that this leads to a highly effective architecture that produces sharper predictions around object boundaries and significantly boosts performance on thinner and smaller objects. Our method achieves state-of-the-art performance on the Cityscapes benchmark, in terms of both mask (mIoU) and boundary (F-score) quality, improving by 2% and 4% over strong baselines.



### Visual Tracking via Dynamic Memory Networks
- **Arxiv ID**: http://arxiv.org/abs/1907.07613v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.07613v3)
- **Published**: 2019-07-12 14:07:24+00:00
- **Updated**: 2019-11-29 06:21:40+00:00
- **Authors**: Tianyu Yang, Antoni B. Chan
- **Comment**: accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI), 2019. arXiv admin note: substantial text overlap with
  arXiv:1803.07268
- **Journal**: None
- **Summary**: Template-matching methods for visual tracking have gained popularity recently due to their good performance and fast speed. However, they lack effective ways to adapt to changes in the target object's appearance, making their tracking accuracy still far from state-of-the-art. In this paper, we propose a dynamic memory network to adapt the template to the target's appearance variations during tracking. The reading and writing process of the external memory is controlled by an LSTM network with the search feature map as input. A spatial attention mechanism is applied to concentrate the LSTM input on the potential target as the location of the target is at first unknown. To prevent aggressive model adaptivity, we apply gated residual template learning to control the amount of retrieved memory that is used to combine with the initial template. In order to alleviate the drift problem, we also design a "negative" memory unit that stores templates for distractors, which are used to cancel out wrong responses from the object template. To further boost the tracking performance, an auxiliary classification loss is added after the feature extractor part. Unlike tracking-by-detection methods where the object's information is maintained by the weight parameters of neural networks, which requires expensive online fine-tuning to be adaptable, our tracker runs completely feed-forward and adapts to the target's appearance changes by updating the external memory. Moreover, the capacity of our model is not determined by the network size as with other trackers --- the capacity can be easily enlarged as the memory requirements of a task increase, which is favorable for memorizing long-term object information. Extensive experiments on the OTB and VOT datasets demonstrate that our trackers perform favorably against state-of-the-art tracking methods while retaining real-time speed.



### Unsupervised Adversarial Attacks on Deep Feature-based Retrieval with GAN
- **Arxiv ID**: http://arxiv.org/abs/1907.05793v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05793v1)
- **Published**: 2019-07-12 15:23:36+00:00
- **Updated**: 2019-07-12 15:23:36+00:00
- **Authors**: Guoping Zhao, Mingyu Zhang, Jiajun Liu, Ji-Rong Wen
- **Comment**: None
- **Journal**: None
- **Summary**: Studies show that Deep Neural Network (DNN)-based image classification models are vulnerable to maliciously constructed adversarial examples. However, little effort has been made to investigate how DNN-based image retrieval models are affected by such attacks. In this paper, we introduce Unsupervised Adversarial Attacks with Generative Adversarial Networks (UAA-GAN) to attack deep feature-based image retrieval systems. UAA-GAN is an unsupervised learning model that requires only a small amount of unlabeled data for training. Once trained, it produces query-specific perturbations for query images to form adversarial queries. The core idea is to ensure that the attached perturbation is barely perceptible to human yet effective in pushing the query away from its original position in the deep feature space. UAA-GAN works with various application scenarios that are based on deep features, including image retrieval, person Re-ID and face search. Empirical results show that UAA-GAN cripples retrieval performance without significant visual changes in the query images. UAA-GAN generated adversarial examples are less distinguishable because they tend to incorporate subtle perturbations in textured or salient areas of the images, such as key body parts of human, dominant structural patterns/textures or edges, rather than in visually insignificant areas (e.g., background and sky). Such tendency indicates that the model indeed learned how to toy with both image retrieval systems and human eyes.



### ACTNET: end-to-end learning of feature activations and multi-stream aggregation for effective instance image retrieval
- **Arxiv ID**: http://arxiv.org/abs/1907.05794v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05794v3)
- **Published**: 2019-07-12 15:24:40+00:00
- **Updated**: 2020-10-23 16:04:46+00:00
- **Authors**: Syed Sameed Husain, Eng-Jon Ong, Miroslaw Bober
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel CNN architecture called ACTNET for robust instance image retrieval from large-scale datasets. Our key innovation is a learnable activation layer designed to improve the signal-to-noise ratio (SNR) of deep convolutional feature maps. Further, we introduce a controlled multi-stream aggregation, where complementary deep features from different convolutional layers are optimally transformed and balanced using our novel activation layers, before aggregation into a global descriptor. Importantly, the learnable parameters of our activation blocks are explicitly trained, together with the CNN parameters, in an end-to-end manner minimising triplet loss. This means that our network jointly learns the CNN filters and their optimal activation and aggregation for retrieval tasks. To our knowledge, this is the first time parametric functions have been used to control and learn optimal aggregation. We conduct an in-depth experimental study on three non-linear activation functions: Sine-Hyperbolic, Exponential and modified Weibull, showing that while all bring significant gains the Weibull function performs best thanks to its ability to equalise strong activations. The results clearly demonstrate that our ACTNET architecture significantly enhances the discriminative power of deep features, improving significantly over the state-of-the-art retrieval results on all datasets.



### Automated Real-time Anomaly Detection in Human Trajectories using Sequence to Sequence Networks
- **Arxiv ID**: http://arxiv.org/abs/1907.05813v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1907.05813v2)
- **Published**: 2019-07-12 16:04:32+00:00
- **Updated**: 2019-07-15 14:14:51+00:00
- **Authors**: Giorgos Bouritsas, Stelios Daveas, Antonios Danelakis, Constantinos Rizogiannis, Stelios C. A. Thomopoulos
- **Comment**: AVSS 2019
- **Journal**: None
- **Summary**: Detection of anomalous trajectories is an important problem with potential applications to various domains, such as video surveillance, risk assessment, vessel monitoring and high-energy physics. Modeling the distribution of trajectories with statistical approaches has been a challenging task due to the fact that such time series are usually non stationary and highly dimensional. However, modern machine learning techniques provide robust approaches for data-driven modeling and critical information extraction. In this paper, we propose a Sequence to Sequence architecture for real-time detection of anomalies in human trajectories, in the context of risk-based security. Our detection scheme is tested on a synthetic dataset of diverse and realistic trajectories generated by the ISL iCrowd simulator. The experimental results indicate that our scheme accurately detects motion patterns that deviate from normal behaviors and is promising for future real-world applications.



### Self-supervised Learning with Geometric Constraints in Monocular Video: Connecting Flow, Depth, and Camera
- **Arxiv ID**: http://arxiv.org/abs/1907.05820v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.05820v2)
- **Published**: 2019-07-12 16:18:16+00:00
- **Updated**: 2019-09-09 17:36:43+00:00
- **Authors**: Yuhua Chen, Cordelia Schmid, Cristian Sminchisescu
- **Comment**: ICCV'19 camera ready
- **Journal**: None
- **Summary**: We present GLNet, a self-supervised framework for learning depth, optical flow, camera pose and intrinsic parameters from monocular video - addressing the difficulty of acquiring realistic ground-truth for such tasks. We propose three contributions: 1) we design new loss functions that capture multiple geometric constraints (eg. epipolar geometry) as well as an adaptive photometric loss that supports multiple moving objects, rigid and non-rigid, 2) we extend the model such that it predicts camera intrinsics, making it applicable to uncalibrated video, and 3) we propose several online refinement strategies that rely on the symmetry of our self-supervised loss in training and testing, in particular optimizing model parameters and/or the output of different tasks, thus leveraging their mutual interactions. The idea of jointly optimizing the system output, under all geometric and photometric constraints can be viewed as a dense generalization of classical bundle adjustment. We demonstrate the effectiveness of our method on KITTI and Cityscapes, where we outperform previous self-supervised approaches on multiple tasks. We also show good generalization for transfer learning in YouTube videos.



### Vector Quantized Bayesian Neural Network Inference for Data Streams
- **Arxiv ID**: http://arxiv.org/abs/1907.05911v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1907.05911v3)
- **Published**: 2019-07-12 18:15:56+00:00
- **Updated**: 2021-01-25 07:15:21+00:00
- **Authors**: Namuk Park, Taekyu Lee, Songkuk Kim
- **Comment**: AAAI 2021
- **Journal**: None
- **Summary**: Bayesian neural networks (BNN) can estimate the uncertainty in predictions, as opposed to non-Bayesian neural networks (NNs). However, BNNs have been far less widely used than non-Bayesian NNs in practice since they need iterative NN executions to predict a result for one data, and it gives rise to prohibitive computational cost. This computational burden is a critical problem when processing data streams with low-latency. To address this problem, we propose a novel model VQ-BNN, which approximates BNN inference for data streams. In order to reduce the computational burden, VQ-BNN inference predicts NN only once and compensates the result with previously memorized predictions. To be specific, VQ-BNN inference for data streams is given by temporal exponential smoothing of recent predictions. The computational cost of this model is almost the same as that of non-Bayesian NNs. Experiments including semantic segmentation on real-world data show that this model performs significantly faster than BNNs while estimating predictive results comparable to or superior to the results of BNNs.



### Gesture-to-Gesture Translation in the Wild via Category-Independent Conditional Maps
- **Arxiv ID**: http://arxiv.org/abs/1907.05916v3
- **DOI**: 10.1145/3343031.3351020
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1907.05916v3)
- **Published**: 2019-07-12 18:39:27+00:00
- **Updated**: 2019-07-31 08:55:11+00:00
- **Authors**: Yahui Liu, Marco De Nadai, Gloria Zen, Nicu Sebe, Bruno Lepri
- **Comment**: 15 pages, 12 figures
- **Journal**: 27th ACM International Conference on Multimedia, 2019
- **Summary**: Recent works have shown Generative Adversarial Networks (GANs) to be particularly effective in image-to-image translations. However, in tasks such as body pose and hand gesture translation, existing methods usually require precise annotations, e.g. key-points or skeletons, which are time-consuming to draw. In this work, we propose a novel GAN architecture that decouples the required annotations into a category label - that specifies the gesture type - and a simple-to-draw category-independent conditional map - that expresses the location, rotation and size of the hand gesture. Our architecture synthesizes the target gesture while preserving the background context, thus effectively dealing with gesture translation in the wild. To this aim, we use an attention module and a rolling guidance approach, which loops the generated images back into the network and produces higher quality images compared to competing works. Thus, our GAN learns to generate new images from simple annotations without requiring key-points or skeleton labels. Results on two public datasets show that our method outperforms state of the art approaches both quantitatively and qualitatively. To the best of our knowledge, no work so far has addressed the gesture-to-gesture translation in the wild by requiring user-friendly annotations.



### End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction with Relational Reasoning
- **Arxiv ID**: http://arxiv.org/abs/1907.12887v5
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.RO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1907.12887v5)
- **Published**: 2019-07-12 22:40:13+00:00
- **Updated**: 2020-09-28 14:25:23+00:00
- **Authors**: Fabian B. Fuchs, Adam R. Kosiorek, Li Sun, Oiwi Parker Jones, Ingmar Posner
- **Comment**: None
- **Journal**: None
- **Summary**: The majority of contemporary object-tracking approaches do not model interactions between objects. This contrasts with the fact that objects' paths are not independent: a cyclist might abruptly deviate from a previously planned trajectory in order to avoid colliding with a car. Building upon HART, a neural class-agnostic single-object tracker, we introduce a multi-object tracking method MOHART capable of relational reasoning. Importantly, the entire system, including the understanding of interactions and relations between objects, is class-agnostic and learned simultaneously in an end-to-end fashion. We explore a number of relational reasoning architectures and show that permutation-invariant models outperform non-permutation-invariant alternatives. We also find that architectures using a single permutation invariant operation like DeepSets, despite, in theory, being universal function approximators, are nonetheless outperformed by a more complex architecture based on multi-headed attention. The latter better accounts for complex physical interactions in a challenging toy experiment. Further, we find that modelling interactions leads to consistent performance gains in tracking as well as future trajectory prediction on three real-world datasets (MOTChallenge, UA-DETRAC, and Stanford Drone dataset), particularly in the presence of ego-motion, occlusions, crowded scenes, and faulty sensor inputs.



### Deep Learning For Face Recognition: A Critical Analysis
- **Arxiv ID**: http://arxiv.org/abs/1907.12739v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1907.12739v1)
- **Published**: 2019-07-12 22:55:49+00:00
- **Updated**: 2019-07-12 22:55:49+00:00
- **Authors**: Andrew Jason Shepley
- **Comment**: None
- **Journal**: None
- **Summary**: Face recognition is a rapidly developing and widely applied aspect of biometric technologies. Its applications are broad, ranging from law enforcement to consumer applications, and industry efficiency and monitoring solutions. The recent advent of affordable, powerful GPUs and the creation of huge face databases has drawn research focus primarily on the development of increasingly deep neural networks designed for all aspects of face recognition tasks, ranging from detection and preprocessing to feature representation and classification in verification and identification solutions. However, despite these improvements, real-time, accurate face recognition is still a challenge, primarily due to the high computational cost associated with the use of Deep Convolutions Neural Networks (DCNN), and the need to balance accuracy requirements with time and resource constraints. Other significant issues affecting face recognition relate to occlusion, illumination and pose invariance, which causes a notable decline in accuracy in both traditional handcrafted solutions and deep neural networks. This survey will provide a critical analysis and comparison of modern state of the art methodologies, their benefits, and their limitations. It provides a comprehensive coverage of both deep and shallow solutions, as they stand today, and highlight areas requiring future development and improvement. This review is aimed at facilitating research into novel approaches, and further development of current methodologies by scientists and engineers, whilst imparting an informative and analytical perspective on currently available solutions to end users in industry, government and consumer contexts.



### Face Recognition in Unconstrained Conditions: A Systematic Review
- **Arxiv ID**: http://arxiv.org/abs/1908.04404v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1908.04404v1)
- **Published**: 2019-07-12 23:54:50+00:00
- **Updated**: 2019-07-12 23:54:50+00:00
- **Authors**: Andrew Jason Shepley
- **Comment**: None
- **Journal**: None
- **Summary**: Face recognition is a biometric which is attracting significant research, commercial and government interest, as it provides a discreet, non-intrusive way of detecting, and recognizing individuals, without need for the subject's knowledge or consent. This is due to reduced cost, and evolution in hardware and algorithms which have improved their ability to handle unconstrained conditions. Evidently affordable and efficient applications are required. However, there is much debate over which methods are most appropriate, particularly in the context of the growing importance of deep neural network-based face recognition systems. This systematic review attempts to provide clarity on both issues by organizing the plethora of research and data in this field to clarify current research trends, state-of-the-art methods, and provides an outline of their benefits and shortcomings. Overall, this research covered 1,330 relevant studies, showing an increase of over 200% in research interest in the field of face recognition over the past 6 years. Our results also demonstrated that deep learning methods are the prime focus of modern research due to improvements in hardware databases and increasing understanding of neural networks. In contrast, traditional methods have lost favor amongst researchers due to their inherent limitations in accuracy, and lack of efficiency when handling large amounts of data.



