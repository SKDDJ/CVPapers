# Arxiv Papers in cs.CV on 2019-12-22
### Neural Shape Parsers for Constructive Solid Geometry
- **Arxiv ID**: http://arxiv.org/abs/1912.11393v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11393v1)
- **Published**: 2019-12-22 00:08:13+00:00
- **Updated**: 2019-12-22 00:08:13+00:00
- **Authors**: Gopal Sharma, Rishabh Goyal, Difan Liu, Evangelos Kalogerakis, Subhransu Maji
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1712.08290
- **Journal**: None
- **Summary**: Constructive Solid Geometry (CSG) is a geometric modeling technique that defines complex shapes by recursively applying boolean operations on primitives such as spheres and cylinders. We present CSGNe, a deep network architecture that takes as input a 2D or 3D shape and outputs a CSG program that models it. Parsing shapes into CSG programs is desirable as it yields a compact and interpretable generative model. However, the task is challenging since the space of primitives and their combinations can be prohibitively large. CSGNe uses a convolutional encoder and recurrent decoder based on deep networks to map shapes to modeling instructions in a feed-forward manner and is significantly faster than bottom-up approaches. We investigate two architectures for this task --- a vanilla encoder (CNN) - decoder (RNN) and another architecture that augments the encoder with an explicit memory module based on the program execution stack. The stack augmentation improves the reconstruction quality of the generated shape and learning efficiency. Our approach is also more effective as a shape primitive detector compared to a state-of-the-art object detector. Finally, we demonstrate CSGNet can be trained on novel datasets without program annotations through policy gradient techniques.



### Learning to Impute: A General Framework for Semi-supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1912.10364v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1912.10364v3)
- **Published**: 2019-12-22 00:27:21+00:00
- **Updated**: 2020-09-24 13:53:04+00:00
- **Authors**: Wei-Hong Li, Chuan-Sheng Foo, Hakan Bilen
- **Comment**: Semi-supervised Learning, Meta-Learning, Learning to impute
- **Journal**: None
- **Summary**: Recent semi-supervised learning methods have shown to achieve comparable results to their supervised counterparts while using only a small portion of labels in image classification tasks thanks to their regularization strategies. In this paper, we take a more direct approach for semi-supervised learning and propose learning to impute the labels of unlabeled samples such that a network achieves better generalization when it is trained on these labels. We pose the problem in a learning-to-learn formulation which can easily be incorporated to the state-of-the-art semi-supervised techniques and boost their performance especially when the labels are limited. We demonstrate that our method is applicable to both classification and regression problems including image classification and facial landmark detection tasks.



### Robust Pose Invariant Shape and Texture based Hand Recognition
- **Arxiv ID**: http://arxiv.org/abs/1912.10373v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.10373v1)
- **Published**: 2019-12-22 02:19:02+00:00
- **Updated**: 2019-12-22 02:19:02+00:00
- **Authors**: F. Sohel, A. El-Sallam, M. Bennamoun
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a novel personal identification and verification system using information extracted from the hand shape and texture. The system has two major constituent modules: a fully automatic and robust peg free segmentation and pose normalisation module, and a recognition module. In the first module, the hand is segmented from its background using a thresholding technique based on Otsu`s method combined with a skin colour detector. A set of fully automatic algorithms are then proposed to segment the palm and fingers. In these algorithms, the skeleton and the contour of the hand and fingers are estimated and used to determine the global pose of the hand and the pose of each individual finger. Finally the palm and fingers are cropped, pose corrected and normalised. In the recognition module, various shape and texture based features are extracted and used for matching purposes. The modified Hausdorff distance, the Iterative Closest Point (ICP) and Independent Component Analysis (ICA) algorithms are used for shape and texture features of the fingers. For the palmprints, we use the Discrete Cosine Transform (DCT), directional line features and ICA. Recognition (identification and verification) tests were performed using fusion strategies based on the similarity scores of the fingers and the palm. Experimental results show that the proposed system exhibits a superior performance over existing systems with an accuracy of over 98\% for hand identification and verification (at equal error rate) in a database of 560 different subjects.



### A Deep Neuro-Fuzzy Network for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/2001.01686v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2001.01686v1)
- **Published**: 2019-12-22 03:28:05+00:00
- **Updated**: 2019-12-22 03:28:05+00:00
- **Authors**: Omolbanin Yazdanbakhsh, Scott Dick
- **Comment**: None
- **Journal**: None
- **Summary**: The combination of neural network and fuzzy systems into neuro-fuzzy systems integrates fuzzy reasoning rules into the connectionist networks. However, the existing neuro-fuzzy systems are developed under shallow structures having lower generalization capacity. We propose the first end-to-end deep neuro-fuzzy network and investigate its application for image classification. Two new operations are developed based on definitions of Takagi-Sugeno-Kang (TSK) fuzzy model namely fuzzy inference operation and fuzzy pooling operations; stacks of these operations comprise the layers in this network. We evaluate the network on MNIST, CIFAR-10 and CIFAR-100 datasets, finding that the network has a reasonable accuracy in these benchmarks.



### Patch-based Generative Adversarial Network Towards Retinal Vessel Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1912.10377v1
- **DOI**: 10.1007/978-3-030-36808-1_6
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1912.10377v1)
- **Published**: 2019-12-22 03:33:31+00:00
- **Updated**: 2019-12-22 03:33:31+00:00
- **Authors**: Waseem Abbas, Muhammad Haroon Shakeel, Numan Khurshid, Murtaza Taj
- **Comment**: None
- **Journal**: Neural Information Processing. ICONIP 2019
- **Summary**: Retinal blood vessels are considered to be the reliable diagnostic biomarkers of ophthalmologic and diabetic retinopathy. Monitoring and diagnosis totally depends on expert analysis of both thin and thick retinal vessels which has recently been carried out by various artificial intelligent techniques. Existing deep learning methods attempt to segment retinal vessels using a unified loss function optimized for both thin and thick vessels with equal importance. Due to variable thickness, biased distribution, and difference in spatial features of thin and thick vessels, unified loss function are more influential towards identification of thick vessels resulting in weak segmentation. To address this problem, a conditional patch-based generative adversarial network is proposed which utilizes a generator network and a patch-based discriminator network conditioned on the sample data with an additional loss function to learn both thin and thick vessels. Experiments are conducted on publicly available STARE and DRIVE datasets which show that the proposed model outperforms the state-of-the-art methods.



### Unsupervised Representation Learning by Predicting Random Distances
- **Arxiv ID**: http://arxiv.org/abs/1912.12186v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1912.12186v2)
- **Published**: 2019-12-22 05:09:11+00:00
- **Updated**: 2020-07-19 11:57:46+00:00
- **Authors**: Hu Wang, Guansong Pang, Chunhua Shen, Congbo Ma
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have gained tremendous success in a broad range of machine learning tasks due to its remarkable capability to learn semantic-rich features from high-dimensional data. However, they often require large-scale labelled data to successfully learn such features, which significantly hinders their adaption into unsupervised learning tasks, such as anomaly detection and clustering, and limits their applications into critical domains where obtaining massive labelled data is prohibitively expensive. To enable unsupervised learning on those domains, in this work we propose to learn features without using any labelled data by training neural networks to predict data distances in a randomly projected space. Random mapping is a theoretically proven approach to obtain approximately preserved distances. To well predict these random distances, the representation learner is optimised to learn genuine class structures that are implicitly embedded in the randomly projected space. Empirical results on 19 real-world datasets show that our learned representations substantially outperform a few state-of-the-art competing methods in both anomaly detection and clustering tasks. Code is available at https://git.io/RDP



### Adversarial Cross-Domain Action Recognition with Co-Attention
- **Arxiv ID**: http://arxiv.org/abs/1912.10405v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1912.10405v1)
- **Published**: 2019-12-22 09:39:15+00:00
- **Updated**: 2019-12-22 09:39:15+00:00
- **Authors**: Boxiao Pan, Zhangjie Cao, Ehsan Adeli, Juan Carlos Niebles
- **Comment**: AAAI 2020
- **Journal**: None
- **Summary**: Action recognition has been a widely studied topic with a heavy focus on supervised learning involving sufficient labeled videos. However, the problem of cross-domain action recognition, where training and testing videos are drawn from different underlying distributions, remains largely under-explored. Previous methods directly employ techniques for cross-domain image recognition, which tend to suffer from the severe temporal misalignment problem. This paper proposes a Temporal Co-attention Network (TCoN), which matches the distributions of temporally aligned action features between source and target domains using a novel cross-domain co-attention mechanism. Experimental results on three cross-domain action recognition datasets demonstrate that TCoN improves both previous single-domain and cross-domain methods significantly under the cross-domain setting.



### Rethinking Temporal Object Detection from Robotic Perspectives
- **Arxiv ID**: http://arxiv.org/abs/1912.10406v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1912.10406v2)
- **Published**: 2019-12-22 09:50:06+00:00
- **Updated**: 2020-03-04 06:35:15+00:00
- **Authors**: Xingyu Chen, Zhengxing Wu, Junzhi Yu, Li Wen
- **Comment**: None
- **Journal**: None
- **Summary**: Video object detection (VID) has been vigorously studied for years but almost all literature adopts a static accuracy-based evaluation, i.e., average precision (AP). From a robotic perspective, the importance of recall continuity and localization stability is equal to that of accuracy, but the AP is insufficient to reflect detectors' performance across time. In this paper, non-reference assessments are proposed for continuity and stability based on object tracklets. These temporal evaluations can serve as supplements to static AP. Further, we develop an online tracklet refinement for improving detectors' temporal performance through short tracklet suppression, fragment filling, and temporal location fusion.   In addition, we propose a small-overlap suppression to extend VID methods to single object tracking (SOT) task so that a flexible SOT-by-detection framework is then formed.   Extensive experiments are conducted on ImageNet VID dataset and real-world robotic tasks, where the superiority of our proposed approaches are validated and verified. Codes will be publicly available.



### Joint Face Super-Resolution and Deblurring Using a Generative Adversarial Network
- **Arxiv ID**: http://arxiv.org/abs/1912.10427v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.10427v1)
- **Published**: 2019-12-22 12:03:45+00:00
- **Updated**: 2019-12-22 12:03:45+00:00
- **Authors**: Jung Un Yun, In Kyu Park
- **Comment**: None
- **Journal**: None
- **Summary**: Facial image super-resolution (SR) is an important preprocessing for facial image analysis, face recognition, and image-based 3D face reconstruction. Recent convolutional neural network (CNN) based method has shown excellent performance by learning mapping relation using pairs of low-resolution (LR) and high-resolution (HR) facial images. However, since the HR facial image reconstruction using CNN is conventionally aimed to increase the PSNR and SSIM metrics, the reconstructed HR image might not be realistic even with high scores. An adversarial framework is proposed in this study to reconstruct the HR facial image by simultaneously generating an HR image with and without blur. First, the spatial resolution of the LR facial image is increased by eight times using a five-layer CNN. Then, the encoder extracts the features of the up-scaled image. These features are finally sent to two branches (decoders) to generate an HR facial image with and without blur. In addition, local and global discriminators are combined to focus on the reconstruction of HR facial structures. Experiment results show that the proposed algorithm generates a realistic HR facial image. Furthermore, the proposed method can generate a variety of different facial images.



### Adversarial Feature Distribution Alignment for Semi-Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1912.10428v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.10428v1)
- **Published**: 2019-12-22 12:07:30+00:00
- **Updated**: 2019-12-22 12:07:30+00:00
- **Authors**: Christoph Mayer, Matthieu Paul, Radu Timofte
- **Comment**: None
- **Journal**: None
- **Summary**: Training deep neural networks with only a few labeled samples can lead to overfitting. This is problematic in semi-supervised learning where only a few labeled samples are available. In this paper, we show that a consequence of overfitting in SSL is feature distribution misalignment between labeled and unlabeled samples. Hence, we propose a new feature distribution alignment method. Our method is particularly effective when using only a small amount of labeled samples. We test our method on CIFAR10 and SVHN. On SVHN we achieve a test error of 3.88% (250 labeled samples) and 3.39% (1000 labeled samples) which is close to the fully supervised model 2.89% (73k labeled samples). In comparison, the current SOTA achieves only 4.29% and 3.74%. Finally, we provide a theoretical insight why feature distribution alignment occurs and show that our method reduces it.



### On the Initialization of Long Short-Term Memory Networks
- **Arxiv ID**: http://arxiv.org/abs/1912.10454v1
- **DOI**: 10.1007/978-3-030-36708-4_23
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1912.10454v1)
- **Published**: 2019-12-22 14:19:43+00:00
- **Updated**: 2019-12-22 14:19:43+00:00
- **Authors**: Mostafa Mehdipour Ghazi, Mads Nielsen, Akshay Pai, Marc Modat, M. Jorge Cardoso, Sebastien Ourselin, Lauge Sorensen
- **Comment**: None
- **Journal**: None
- **Summary**: Weight initialization is important for faster convergence and stability of deep neural networks training. In this paper, a robust initialization method is developed to address the training instability in long short-term memory (LSTM) networks. It is based on a normalized random initialization of the network weights that aims at preserving the variance of the network input and output in the same range. The method is applied to standard LSTMs for univariate time series regression and to LSTMs robust to missing values for multivariate disease progression modeling. The results show that in all cases, the proposed initialization method outperforms the state-of-the-art initialization techniques in terms of training convergence and generalization performance of the obtained solution.



### Active Learning for Segmentation Based on Bayesian Sample Queries
- **Arxiv ID**: http://arxiv.org/abs/1912.10493v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.10493v1)
- **Published**: 2019-12-22 17:49:30+00:00
- **Updated**: 2019-12-22 17:49:30+00:00
- **Authors**: Firat Ozdemir, Zixuan Peng, Philipp Fuernstahl, Christine Tanner, Orcun Goksel
- **Comment**: 10 pages, 7 figures
- **Journal**: None
- **Summary**: Segmentation of anatomical structures is a fundamental image analysis task for many applications in the medical field. Deep learning methods have been shown to perform well, but for this purpose large numbers of manual annotations are needed in the first place, which necessitate prohibitive levels of resources that are often unavailable. In an active learning framework of selecting informed samples for manual labeling, expert clinician time for manual annotation can be optimally utilized, enabling the establishment of large labeled datasets for machine learning. In this paper, we propose a novel method that combines representativeness with uncertainty in order to estimate ideal samples to be annotated, iteratively from a given dataset. Our novel representativeness metric is based on Bayesian sampling, by using information-maximizing autoencoders. We conduct experiments on a shoulder magnetic resonance imaging (MRI) dataset for the segmentation of four musculoskeletal tissue classes. Quantitative results show that the annotation of representative samples selected by our proposed querying method yields an improved segmentation performance at each active learning iteration, compared to a baseline method that also employs uncertainty and representativeness metrics. For instance, with only 10% of the dataset annotated, our method reaches within 5% of Dice score expected from the upper bound scenario of all the dataset given as annotated (an impractical scenario due to resource constraints), and this gap drops down to a mere 2% when less than a fifth of the dataset samples are annotated. Such active learning approach to selecting samples to annotate enables an optimal use of the expert clinician time, being often the bottleneck in realizing machine learning solutions in medicine.



### Re-Identification and Growth Detection of Pulmonary Nodules without Image Registration Using 3D Siamese Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1912.10525v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1912.10525v1)
- **Published**: 2019-12-22 20:09:44+00:00
- **Updated**: 2019-12-22 20:09:44+00:00
- **Authors**: Xavier Rafael-Palou, Anton Aubanell, Ilaria Bonavita, Mario Ceresa, Gemma Piella, Vicent Ribas, Miguel Ángel González Ballester
- **Comment**: 14 pages, 8 figures
- **Journal**: None
- **Summary**: Lung cancer follow-up is a complex, error prone, and time consuming task for clinical radiologists. Several lung CT scan images taken at different time points of a given patient need to be individually inspected, looking for possible cancerogenous nodules. Radiologists mainly focus their attention in nodule size, density, and growth to assess the existence of malignancy. In this study, we present a novel method based on a 3D siamese neural network, for the re-identification of nodules in a pair of CT scans of the same patient without the need for image registration. The network was integrated into a two-stage automatic pipeline to detect, match, and predict nodule growth given pairs of CT scans. Results on an independent test set reported a nodule detection sensitivity of 94.7%, an accuracy for temporal nodule matching of 88.8%, and a sensitivity of 92.0% with a precision of 88.4% for nodule growth detection.



### Learning to Generate Dense Point Clouds with Textures on Multiple Categories
- **Arxiv ID**: http://arxiv.org/abs/1912.10545v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.10545v1)
- **Published**: 2019-12-22 21:40:48+00:00
- **Updated**: 2019-12-22 21:40:48+00:00
- **Authors**: Tao Hu, Geng Lin, Zhizhong Han, Matthias Zwicker
- **Comment**: None
- **Journal**: None
- **Summary**: 3D reconstruction from images is a core problem in computer vision. With recent advances in deep learning, it has become possible to recover plausible 3D shapes even from single RGB images for the first time. However, obtaining detailed geometry and texture for objects with arbitrary topology remains challenging. In this paper, we propose a novel approach for reconstructing point clouds from RGB images. Unlike other methods, we can recover dense point clouds with hundreds of thousands of points, and we also include RGB textures. In addition, we train our model on multiple categories which leads to superior generalization to unseen categories compared to previous techniques. We achieve this using a two-stage approach, where we first infer an object coordinate map from the input RGB image, and then obtain the final point cloud using a reprojection and completion step. We show results on standard benchmarks that demonstrate the advantages of our technique. Code is available at https://github.com/TaoHuUMD/3D-Reconstruction.



### Atmospheric turbulence removal using convolutional neural network
- **Arxiv ID**: http://arxiv.org/abs/1912.11350v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1912.11350v1)
- **Published**: 2019-12-22 22:22:55+00:00
- **Updated**: 2019-12-22 22:22:55+00:00
- **Authors**: Jing Gao, N. Anantrasirichai, David Bull
- **Comment**: None
- **Journal**: None
- **Summary**: This paper describes a novel deep learning-based method for mitigating the effects of atmospheric distortion. We have built an end-to-end supervised convolutional neural network (CNN) to reconstruct turbulence-corrupted video sequence. Our framework has been developed on the residual learning concept, where the spatio-temporal distortions are learnt and predicted. Our experiments demonstrate that the proposed method can deblur, remove ripple effect and enhance contrast of the video sequences simultaneously. Our model was trained and tested with both simulated and real distortions. Experimental results of the real distortions show that our method outperforms the existing ones by up to 3.8% in term of the quality of restored images, and it achieves faster speed than the state-of-the-art methods by up to 23 times with GPU implementation.



### Finding and Removing Clever Hans: Using Explanation Methods to Debug and Improve Deep Models
- **Arxiv ID**: http://arxiv.org/abs/1912.11425v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1912.11425v2)
- **Published**: 2019-12-22 22:40:27+00:00
- **Updated**: 2020-12-18 20:13:21+00:00
- **Authors**: Christopher J. Anders, Leander Weber, David Neumann, Wojciech Samek, Klaus-Robert Müller, Sebastian Lapuschkin
- **Comment**: 47 pages, 21 figures
- **Journal**: None
- **Summary**: Contemporary learning models for computer vision are typically trained on very large (benchmark) datasets with millions of samples. These may, however, contain biases, artifacts, or errors that have gone unnoticed and are exploitable by the model. In the worst case, the trained model does not learn a valid and generalizable strategy to solve the problem it was trained for, and becomes a 'Clever-Hans' (CH) predictor that bases its decisions on spurious correlations in the training data, potentially yielding an unrepresentative or unfair, and possibly even hazardous predictor. In this paper, we contribute by providing a comprehensive analysis framework based on a scalable statistical analysis of attributions from explanation methods for large data corpora. Based on a recent technique - Spectral Relevance Analysis - we propose the following technical contributions and resulting findings: (a) a scalable quantification of artifactual and poisoned classes where the machine learning models under study exhibit CH behavior, (b) several approaches denoted as Class Artifact Compensation (ClArC), which are able to effectively and significantly reduce a model's CH behavior. I.e., we are able to un-Hans models trained on (poisoned) datasets, such as the popular ImageNet data corpus. We demonstrate that ClArC, defined in a simple theoretical framework, may be implemented as part of a Neural Network's training or fine-tuning process, or in a post-hoc manner by injecting additional layers, preventing any further propagation of undesired CH features, into the network architecture. Using our proposed methods, we provide qualitative and quantitative analyses of the biases and artifacts in various datasets. We demonstrate that these insights can give rise to improved, more representative and fairer models operating on implicitly cleaned data corpora.



### Algorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1912.10557v3
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1912.10557v3)
- **Published**: 2019-12-22 23:02:18+00:00
- **Updated**: 2020-08-07 05:37:40+00:00
- **Authors**: Vishal Monga, Yuelong Li, Yonina C. Eldar
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks provide unprecedented performance gains in many real world problems in signal and image processing. Despite these gains, future development and practical deployment of deep networks is hindered by their blackbox nature, i.e., lack of interpretability, and by the need for very large training sets. An emerging technique called algorithm unrolling or unfolding offers promise in eliminating these issues by providing a concrete and systematic connection between iterative algorithms that are used widely in signal processing and deep neural networks. Unrolling methods were first proposed to develop fast neural network approximations for sparse coding. More recently, this direction has attracted enormous attention and is rapidly growing both in theoretic investigations and practical applications. The growing popularity of unrolled deep networks is due in part to their potential in developing efficient, high-performance and yet interpretable network architectures from reasonable size training sets. In this article, we review algorithm unrolling for signal and image processing. We extensively cover popular techniques for algorithm unrolling in various domains of signal and image processing including imaging, vision and recognition, and speech processing. By reviewing previous works, we reveal the connections between iterative algorithms and neural networks and present recent theoretical results. Finally, we provide a discussion on current limitations of unrolling and suggest possible future research directions.



