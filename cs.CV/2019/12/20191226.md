# Arxiv Papers in cs.CV on 2019-12-26
### Planar Prior Assisted PatchMatch Multi-View Stereo
- **Arxiv ID**: http://arxiv.org/abs/1912.11744v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11744v1)
- **Published**: 2019-12-26 01:34:05+00:00
- **Updated**: 2019-12-26 01:34:05+00:00
- **Authors**: Qingshan Xu, Wenbing Tao
- **Comment**: Accepted by AAAI-2020
- **Journal**: None
- **Summary**: The completeness of 3D models is still a challenging problem in multi-view stereo (MVS) due to the unreliable photometric consistency in low-textured areas. Since low-textured areas usually exhibit strong planarity, planar models are advantageous to the depth estimation of low-textured areas. On the other hand, PatchMatch multi-view stereo is very efficient for its sampling and propagation scheme. By taking advantage of planar models and PatchMatch multi-view stereo, we propose a planar prior assisted PatchMatch multi-view stereo framework in this paper. In detail, we utilize a probabilistic graphical model to embed planar models into PatchMatch multi-view stereo and contribute a novel multi-view aggregated matching cost. This novel cost takes both photometric consistency and planar compatibility into consideration, making it suited for the depth estimation of both non-planar and planar regions. Experimental results demonstrate that our method can efficiently recover the depth information of extremely low-textured areas, thus obtaining high complete 3D models and achieving state-of-the-art performance.



### Learning Inverse Depth Regression for Multi-View Stereo with Correlation Cost Volume
- **Arxiv ID**: http://arxiv.org/abs/1912.11746v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11746v1)
- **Published**: 2019-12-26 01:40:44+00:00
- **Updated**: 2019-12-26 01:40:44+00:00
- **Authors**: Qingshan Xu, Wenbing Tao
- **Comment**: Accepted by AAAI-2020
- **Journal**: None
- **Summary**: Deep learning has shown to be effective for depth inference in multi-view stereo (MVS). However, the scalability and accuracy still remain an open problem in this domain. This can be attributed to the memory-consuming cost volume representation and inappropriate depth inference. Inspired by the group-wise correlation in stereo matching, we propose an average group-wise correlation similarity measure to construct a lightweight cost volume. This can not only reduce the memory consumption but also reduce the computational burden in the cost volume filtering. Based on our effective cost volume representation, we propose a cascade 3D U-Net module to regularize the cost volume to further boost the performance. Unlike the previous methods that treat multi-view depth inference as a depth regression problem or an inverse depth classification problem, we recast multi-view depth inference as an inverse depth regression task. This allows our network to achieve sub-pixel estimation and be applicable to large-scale scenes. Through extensive experiments on DTU dataset and Tanks and Temples dataset, we show that our proposed network with Correlation cost volume and Inverse DEpth Regression (CIDER), achieves state-of-the-art results, demonstrating its superior performance on scalability and accuracy.



### PI-GAN: Learning Pose Independent representations for multiple profile face synthesis
- **Arxiv ID**: http://arxiv.org/abs/2001.00645v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2001.00645v1)
- **Published**: 2019-12-26 02:51:24+00:00
- **Updated**: 2019-12-26 02:51:24+00:00
- **Authors**: Hamed Alqahtani
- **Comment**: 8 pages, 2 figures
- **Journal**: None
- **Summary**: Generating a pose-invariant representation capable of synthesizing multiple face pose views from a single pose is still a difficult problem. The solution is demanded in various areas like multimedia security, computer vision, robotics, etc. Generative adversarial networks (GANs) have encoder-decoder structures possessing the capability to learn pose-independent representation incorporated with discriminator network for realistic face synthesis. We present PIGAN, a cyclic shared encoder-decoder framework, in an attempt to solve the problem. As compared to traditional GAN, it consists of secondary encoder-decoder framework sharing weights from the primary structure and reconstructs the face with the original pose. The primary framework focuses on creating disentangle representation, and secondary framework aims to restore the original face. We use CFP high-resolution, realistic dataset to check the performance.



### Autonomous Removal of Perspective Distortion for Robotic Elevator Button Recognition
- **Arxiv ID**: http://arxiv.org/abs/1912.11774v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1912.11774v1)
- **Published**: 2019-12-26 04:23:51+00:00
- **Updated**: 2019-12-26 04:23:51+00:00
- **Authors**: Delong Zhu, Jianbang Liu, Nachuan Ma, Zhe Min, Max Q. -H. Meng
- **Comment**: None
- **Journal**: None
- **Summary**: Elevator button recognition is considered an indispensable function for enabling the autonomous elevator operation of mobile robots. However, due to unfavorable image conditions and various image distortions, the recognition accuracy remains to be improved. In this paper, we present a novel algorithm that can autonomously correct perspective distortions of elevator panel images. The algorithm first leverages the Gaussian Mixture Model (GMM) to conduct a grid fitting process based on button recognition results, then utilizes the estimated grid centers as reference features to estimate camera motions for correcting perspective distortions. The algorithm performs on a single image autonomously and does not need explicit feature detection or feature matching procedure, which is much more robust to noises and outliers than traditional feature-based geometric approaches. To verify the effectiveness of the algorithm, we collect an elevator panel dataset of 50 images captured from different angles of view. Experimental results show that the proposed algorithm can accurately estimate camera motions and effectively remove perspective distortions.



### SESS: Self-Ensembling Semi-Supervised 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1912.11803v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11803v3)
- **Published**: 2019-12-26 08:48:04+00:00
- **Updated**: 2021-03-17 14:32:55+00:00
- **Authors**: Na Zhao, Tat-Seng Chua, Gim Hee Lee
- **Comment**: CVPR 2020 Oral
- **Journal**: None
- **Summary**: The performance of existing point cloud-based 3D object detection methods heavily relies on large-scale high-quality 3D annotations. However, such annotations are often tedious and expensive to collect. Semi-supervised learning is a good alternative to mitigate the data annotation issue, but has remained largely unexplored in 3D object detection. Inspired by the recent success of self-ensembling technique in semi-supervised image classification task, we propose SESS, a self-ensembling semi-supervised 3D object detection framework. Specifically, we design a thorough perturbation scheme to enhance generalization of the network on unlabeled and new unseen data. Furthermore, we propose three consistency losses to enforce the consistency between two sets of predicted 3D object proposals, to facilitate the learning of structure and semantic invariances of objects. Extensive experiments conducted on SUN RGB-D and ScanNet datasets demonstrate the effectiveness of SESS in both inductive and transductive semi-supervised 3D object detection. Our SESS achieves competitive performance compared to the state-of-the-art fully-supervised method by using only 50% labeled data. Our code is available at https://github.com/Na-Z/sess.



### An Ensemble Rate Adaptation Framework for Dynamic Adaptive Streaming Over HTTP
- **Arxiv ID**: http://arxiv.org/abs/1912.11822v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM, cs.SY, eess.IV, eess.SY
- **Links**: [PDF](http://arxiv.org/pdf/1912.11822v1)
- **Published**: 2019-12-26 09:54:18+00:00
- **Updated**: 2019-12-26 09:54:18+00:00
- **Authors**: Hui Yuan, Xiaoqian Hu, Junhui Hou, Xuekai Wei, Sam Kwong
- **Comment**: This article has been accepted by IEEE Transactions on Broadcasting
- **Journal**: None
- **Summary**: Rate adaptation is one of the most important issues in dynamic adaptive streaming over HTTP (DASH). Due to the frequent fluctuations of the network bandwidth and complex variations of video content, it is difficult to deal with the varying network conditions and video content perfectly by using a single rate adaptation method. In this paper, we propose an ensemble rate adaptation framework for DASH, which aims to leverage the advantages of multiple methods involved in the framework to improve the quality of experience (QoE) of users. The proposed framework is simple yet very effective. Specifically, the proposed framework is composed of two modules, i.e., the method pool and method controller. In the method pool, several rate adap tation methods are integrated. At each decision time, only the method that can achieve the best QoE is chosen to determine the bitrate of the requested video segment. Besides, we also propose two strategies for switching methods, i.e., InstAnt Method Switching, and InterMittent Method Switching, for the method controller to determine which method can provide the best QoEs. Simulation results demonstrate that, the proposed framework always achieves the highest QoE for the change of channel environment and video complexity, compared with state-of-the-art rate adaptation methods.



### History-based Anomaly Detector: an Adversarial Approach to Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/1912.11843v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11843v2)
- **Published**: 2019-12-26 11:41:17+00:00
- **Updated**: 2020-03-14 15:41:03+00:00
- **Authors**: Pierrick Chatillon, Coloma Ballester
- **Comment**: None
- **Journal**: None
- **Summary**: Anomaly detection is a difficult problem in many areas and has recently been subject to a lot of attention. Classifying unseen data as anomalous is a challenging matter. Latest proposed methods rely on Generative Adversarial Networks (GANs) to estimate the normal data distribution, and produce an anomaly score prediction for any given data. In this article, we propose a simple yet new adversarial method to tackle this problem, denoted as History-based anomaly detector (HistoryAD). It consists of a self-supervised model, trained to recognize 'normal' samples by comparing them to samples based on the training history of a previously trained GAN. Quantitative and qualitative results are presented evaluating its performance. We also present a comparison to several state-of-the-art methods for anomaly detection showing that our proposal achieves top-tier results on several datasets.



### Efficient Video Semantic Segmentation with Labels Propagation and Refinement
- **Arxiv ID**: http://arxiv.org/abs/1912.11844v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11844v1)
- **Published**: 2019-12-26 11:45:15+00:00
- **Updated**: 2019-12-26 11:45:15+00:00
- **Authors**: Matthieu Paul, Christoph Mayer, Luc Van Gool, Radu Timofte
- **Comment**: Accepted at WACV2020
- **Journal**: None
- **Summary**: This paper tackles the problem of real-time semantic segmentation of high definition videos using a hybrid GPU / CPU approach. We propose an Efficient Video Segmentation(EVS) pipeline that combines:   (i) On the CPU, a very fast optical flow method, that is used to exploit the temporal aspect of the video and propagate semantic information from one frame to the next. It runs in parallel with the GPU.   (ii) On the GPU, two Convolutional Neural Networks: A main segmentation network that is used to predict dense semantic labels from scratch, and a Refiner that is designed to improve predictions from previous frames with the help of a fast Inconsistencies Attention Module (IAM). The latter can identify regions that cannot be propagated accurately.   We suggest several operating points depending on the desired frame rate and accuracy. Our pipeline achieves accuracy levels competitive to the existing real-time methods for semantic image segmentation(mIoU above 60%), while achieving much higher frame rates. On the popular Cityscapes dataset with high resolution frames (2048 x 1024), the proposed operating points range from 80 to 1000 Hz on a single GPU and CPU.



### Graph Embedded Pose Clustering for Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/1912.11850v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11850v2)
- **Published**: 2019-12-26 12:11:08+00:00
- **Updated**: 2020-04-10 13:57:19+00:00
- **Authors**: Amir Markovitz, Gilad Sharir, Itamar Friedman, Lihi Zelnik-Manor, Shai Avidan
- **Comment**: Code is available at https://github.com/amirmk89/gepc. CVPR 2020
- **Journal**: None
- **Summary**: We propose a new method for anomaly detection of human actions. Our method works directly on human pose graphs that can be computed from an input video sequence. This makes the analysis independent of nuisance parameters such as viewpoint or illumination. We map these graphs to a latent space and cluster them. Each action is then represented by its soft-assignment to each of the clusters. This gives a kind of "bag of words" representation to the data, where every action is represented by its similarity to a group of base action-words. Then, we use a Dirichlet process based mixture, that is useful for handling proportional data such as our soft-assignment vectors, to determine if an action is normal or not.   We evaluate our method on two types of data sets. The first is a fine-grained anomaly detection data set (e.g. ShanghaiTech) where we wish to detect unusual variations of some action. The second is a coarse-grained anomaly detection data set (e.g., a Kinetics-based data set) where few actions are considered normal, and every other action should be considered abnormal.   Extensive experiments on the benchmarks show that our method performs considerably better than other state of the art methods.



### Benchmarking Adversarial Robustness
- **Arxiv ID**: http://arxiv.org/abs/1912.11852v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1912.11852v1)
- **Published**: 2019-12-26 12:37:01+00:00
- **Updated**: 2019-12-26 12:37:01+00:00
- **Authors**: Yinpeng Dong, Qi-An Fu, Xiao Yang, Tianyu Pang, Hang Su, Zihao Xiao, Jun Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks are vulnerable to adversarial examples, which becomes one of the most important research problems in the development of deep learning. While a lot of efforts have been made in recent years, it is of great significance to perform correct and complete evaluations of the adversarial attack and defense algorithms. In this paper, we establish a comprehensive, rigorous, and coherent benchmark to evaluate adversarial robustness on image classification tasks. After briefly reviewing plenty of representative attack and defense methods, we perform large-scale experiments with two robustness curves as the fair-minded evaluation criteria to fully understand the performance of these methods. Based on the evaluation results, we draw several important findings and provide insights for future research.



### Domain Adaptation Regularization for Spectral Pruning
- **Arxiv ID**: http://arxiv.org/abs/1912.11853v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1912.11853v3)
- **Published**: 2019-12-26 12:38:13+00:00
- **Updated**: 2020-08-25 09:08:08+00:00
- **Authors**: Laurent Dillard, Yosuke Shinya, Taiji Suzuki
- **Comment**: BMVC 2020
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) have recently been achieving state-of-the-art performance on a variety of computer vision related tasks. However, their computational cost limits their ability to be implemented in embedded systems with restricted resources or strict latency constraints. Model compression has therefore been an active field of research to overcome this issue. Additionally, DNNs typically require massive amounts of labeled data to be trained. This represents a second limitation to their deployment. Domain Adaptation (DA) addresses this issue by allowing knowledge learned on one labeled source distribution to be transferred to a target distribution, possibly unlabeled. In this paper, we investigate on possible improvements of compression methods in DA setting. We focus on a compression method that was previously developed in the context of a single data distribution and show that, with a careful choice of data to use during compression and additional regularization terms directly related to DA objectives, it is possible to improve compression results. We also show that our method outperforms an existing compression method studied in the DA setting by a large margin for high compression rates. Although our work is based on one specific compression method, we also outline some general guidelines for improving compression in DA setting.



### Deep Learning Training with Simulated Approximate Multipliers
- **Arxiv ID**: http://arxiv.org/abs/2001.00060v2
- **DOI**: 10.1109/ROBIO49542.2019.8961780
- **Categories**: **cs.LG**, cs.CV, cs.PF, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2001.00060v2)
- **Published**: 2019-12-26 12:50:06+00:00
- **Updated**: 2020-04-18 13:22:32+00:00
- **Authors**: Issam Hammad, Kamal El-Sankary, Jason Gu
- **Comment**: Presented at: IEEE International Conference on Robotics and
  Biomimetics (ROBIO) 2019, Dali, China, December 2019. WINNER OF THE MOZI BEST
  PAPER IN AI AWARD
- **Journal**: 2019 IEEE International Conference on Robotics and Biomimetics
  (ROBIO)
- **Summary**: This paper presents by simulation how approximate multipliers can be utilized to enhance the training performance of convolutional neural networks (CNNs). Approximate multipliers have significantly better performance in terms of speed, power, and area compared to exact multipliers. However, approximate multipliers have an inaccuracy which is defined in terms of the Mean Relative Error (MRE). To assess the applicability of approximate multipliers in enhancing CNN training performance, a simulation for the impact of approximate multipliers error on CNN training is presented. The paper demonstrates that using approximate multipliers for CNN training can significantly enhance the performance in terms of speed, power, and area at the cost of a small negative impact on the achieved accuracy. Additionally, the paper proposes a hybrid training method which mitigates this negative impact on the accuracy. Using the proposed hybrid method, the training can start using approximate multipliers then switches to exact multipliers for the last few epochs. Using this method, the performance benefits of approximate multipliers in terms of speed, power, and area can be attained for a large portion of the training stage. On the other hand, the negative impact on the accuracy is diminished by using the exact multipliers for the last epochs of training.



### A Comparative Study on Machine Learning Algorithms for the Control of a Wall Following Robot
- **Arxiv ID**: http://arxiv.org/abs/1912.11856v2
- **DOI**: 10.1109/ROBIO49542.2019.8961836
- **Categories**: **cs.LG**, cs.CV, cs.RO, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1912.11856v2)
- **Published**: 2019-12-26 13:05:05+00:00
- **Updated**: 2020-04-18 13:27:19+00:00
- **Authors**: Issam Hammad, Kamal El-Sankary, Jason Gu
- **Comment**: Accepted and presented at IEEE International Conference on Robotics
  and Biomimetics (ROBIO) -2019
- **Journal**: IEEE International Conference on Robotics and Biomimetics (ROBIO)
  2019
- **Summary**: A comparison of the performance of various machine learning models to predict the direction of a wall following robot is presented in this paper. The models were trained using an open-source dataset that contains 24 ultrasound sensors readings and the corresponding direction for each sample. This dataset was captured using SCITOS G5 mobile robot by placing the sensors on the robot waist. In addition to the full format with 24 sensors per record, the dataset has two simplified formats with 4 and 2 input sensor readings per record. Several control models were proposed previously for this dataset using all three dataset formats. In this paper, two primary research contributions are presented. First, presenting machine learning models with accuracies higher than all previously proposed models for this dataset using all three formats. A perfect solution for the 4 and 2 inputs sensors formats is presented using Decision Tree Classifier by achieving a mean accuracy of 100%. On the other hand, a mean accuracy of 99.82% was achieves using the 24 sensor inputs by employing the Gradient Boost Classifier. Second, presenting a comparative study on the performance of different machine learning and deep learning algorithms on this dataset. Therefore, providing an overall insight on the performance of these algorithms for similar sensor fusion problems. All the models in this paper were evaluated using Monte-Carlo cross-validation.



### A Review on Intelligent Object Perception Methods Combining Knowledge-based Reasoning and Machine Learning
- **Arxiv ID**: http://arxiv.org/abs/1912.11861v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1912.11861v2)
- **Published**: 2019-12-26 13:26:49+00:00
- **Updated**: 2020-03-17 14:50:43+00:00
- **Authors**: Filippos Gouidis, Alexandros Vassiliades, Theodore Patkos, Antonis Argyros, Nick Bassiliades, Dimitris Plexousakis
- **Comment**: None
- **Journal**: None
- **Summary**: Object perception is a fundamental sub-field of Computer Vision, covering a multitude of individual areas and having contributed high-impact results. While Machine Learning has been traditionally applied to address related problems, recent works also seek ways to integrate knowledge engineering in order to expand the level of intelligence of the visual interpretation of objects, their properties and their relations with their environment. In this paper, we attempt a systematic investigation of how knowledge-based methods contribute to diverse object perception tasks. We review the latest achievements and identify prominent research directions.



### Hyperspectral and multispectral image fusion under spectrally varying spatial blurs -- Application to high dimensional infrared astronomical imaging
- **Arxiv ID**: http://arxiv.org/abs/1912.11868v1
- **DOI**: None
- **Categories**: **cs.CV**, astro-ph.IM, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1912.11868v1)
- **Published**: 2019-12-26 13:58:40+00:00
- **Updated**: 2019-12-26 13:58:40+00:00
- **Authors**: Claire Guilloteau, Thomas Oberlin, Olivier Berné, Nicolas Dobigeon
- **Comment**: None
- **Journal**: None
- **Summary**: Hyperspectral imaging has become a significant source of valuable data for astronomers over the past decades. Current instrumental and observing time constraints allow direct acquisition of multispectral images, with high spatial but low spectral resolution, and hyperspectral images, with low spatial but high spectral resolution. To enhance scientific interpretation of the data, we propose a data fusion method which combines the benefits of each image to recover a high spatio-spectral resolution datacube. The proposed inverse problem accounts for the specificities of astronomical instruments, such as spectrally variant blurs. We provide a fast implementation by solving the problem in the frequency domain and in a low-dimensional subspace to efficiently handle the convolution operators as well as the high dimensionality of the data. We conduct experiments on a realistic synthetic dataset of simulated observation of the upcoming James Webb Space Telescope, and we show that our fusion algorithm outperforms state-of-the-art methods commonly used in remote sensing for Earth observation.



### Vision and Language: from Visual Perception to Content Creation
- **Arxiv ID**: http://arxiv.org/abs/1912.11872v1
- **DOI**: 10.1017/ATSIP.2020.10
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11872v1)
- **Published**: 2019-12-26 14:07:20+00:00
- **Updated**: 2019-12-26 14:07:20+00:00
- **Authors**: Tao Mei, Wei Zhang, Ting Yao
- **Comment**: None
- **Journal**: APSIPA Transactions on Signal and Information Processing 9 (2020)
  e11
- **Summary**: Vision and language are two fundamental capabilities of human intelligence. Humans routinely perform tasks through the interactions between vision and language, supporting the uniquely human capacity to talk about what they see or hallucinate a picture on a natural-language description. The valid question of how language interacts with vision motivates us researchers to expand the horizons of computer vision area. In particular, "vision to language" is probably one of the most popular topics in the past five years, with a significant growth in both volume of publications and extensive applications, e.g., captioning, visual question answering, visual dialog, language navigation, etc. Such tasks boost visual perception with more comprehensive understanding and diverse linguistic representations. Going beyond the progresses made in "vision to language," language can also contribute to vision understanding and offer new possibilities of visual content creation, i.e., "language to vision." The process performs as a prism through which to create visual content conditioning on the language inputs. This paper reviews the recent advances along these two dimensions: "vision to language" and "language to vision." More concretely, the former mainly focuses on the development of image/video captioning, as well as typical encoder-decoder structures and benchmarks, while the latter summarizes the technologies of visual content creation. The real-world deployment or services of vision and language are elaborated as well.



### W-PoseNet: Dense Correspondence Regularized Pixel Pair Pose Regression
- **Arxiv ID**: http://arxiv.org/abs/1912.11888v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1912.11888v2)
- **Published**: 2019-12-26 15:51:29+00:00
- **Updated**: 2021-03-04 09:22:26+00:00
- **Authors**: Zelin Xu, Ke Chen, Kui Jia
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible. Submitted to IROS 2021
- **Journal**: None
- **Summary**: Solving 6D pose estimation is non-trivial to cope with intrinsic appearance and shape variation and severe inter-object occlusion, and is made more challenging in light of extrinsic large illumination changes and low quality of the acquired data under an uncontrolled environment. This paper introduces a novel pose estimation algorithm W-PoseNet, which densely regresses from input data to 6D pose and also 3D coordinates in model space. In other words, local features learned for pose regression in our deep network are regularized by explicitly learning pixel-wise correspondence mapping onto 3D pose-sensitive coordinates as an auxiliary task. Moreover, a sparse pair combination of pixel-wise features and soft voting on pixel-pair pose predictions are designed to improve robustness to inconsistent and sparse local features. Experiment results on the popular YCB-Video and LineMOD benchmarks show that the proposed W-PoseNet consistently achieves superior performance to the state-of-the-art algorithms.



### 3DFR: A Swift 3D Feature Reductionist Framework for Scene Independent Change Detection
- **Arxiv ID**: http://arxiv.org/abs/1912.11891v1
- **DOI**: 10.1109/LSP.2019.2952253
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11891v1)
- **Published**: 2019-12-26 16:05:43+00:00
- **Updated**: 2019-12-26 16:05:43+00:00
- **Authors**: Murari Mandal, Vansh Dhar, Abhishek Mishra, Santosh Kumar Vipparthi
- **Comment**: IEEE Signal Processing Letters
- **Journal**: IEEE Signal Process. Letters, vol. 26, no. 12, pp. 1882-1886, 2019
- **Summary**: In this paper we propose an end-to-end swift 3D feature reductionist framework (3DFR) for scene independent change detection. The 3DFR framework consists of three feature streams: a swift 3D feature reductionist stream (AvFeat), a contemporary feature stream (ConFeat) and a temporal median feature map. These multilateral foreground/background features are further refined through an encoder-decoder network. As a result, the proposed framework not only detects temporal changes but also learns high-level appearance features. Thus, it incorporates the object semantics for effective change detection. Furthermore, the proposed framework is validated through a scene independent evaluation scheme in order to demonstrate the robustness and generalization capability of the network. The performance of the proposed method is evaluated on the benchmark CDnet 2014 dataset. The experimental results show that the proposed 3DFR network outperforms the state-of-the-art approaches.



### A simple baseline for domain adaptation using rotation prediction
- **Arxiv ID**: http://arxiv.org/abs/1912.11903v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1912.11903v1)
- **Published**: 2019-12-26 17:32:04+00:00
- **Updated**: 2019-12-26 17:32:04+00:00
- **Authors**: Ajinkya Tejankar, Hamed Pirsiavash
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, domain adaptation has become a hot research area with lots of applications. The goal is to adapt a model trained in one domain to another domain with scarce annotated data. We propose a simple yet effective method based on self-supervised learning that outperforms or is on par with most state-of-the-art algorithms, e.g. adversarial domain adaptation. Our method involves two phases: predicting random rotations (self-supervised) on the target domain along with correct labels for the source domain (supervised), and then using self-distillation on the target domain. Our simple method achieves state-of-the-art results on semi-supervised domain adaptation on DomainNet dataset.   Further, we observe that the unlabeled target datasets of popular domain adaptation benchmarks do not contain any categories apart from testing categories. We believe this introduces a bias that does not exist in many real applications. We show that removing this bias from the unlabeled data results in a large drop in performance of state-of-the-art methods, while our simple method is relatively robust.



### Category-Level Articulated Object Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1912.11913v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1912.11913v2)
- **Published**: 2019-12-26 18:34:37+00:00
- **Updated**: 2020-04-08 19:46:04+00:00
- **Authors**: Xiaolong Li, He Wang, Li Yi, Leonidas Guibas, A. Lynn Abbott, Shuran Song
- **Comment**: 14 pages, 8 figures
- **Journal**: None
- **Summary**: This project addresses the task of category-level pose estimation for articulated objects from a single depth image. We present a novel category-level approach that correctly accommodates object instances previously unseen during training. We introduce Articulation-aware Normalized Coordinate Space Hierarchy (ANCSH) - a canonical representation for different articulated objects in a given category. As the key to achieve intra-category generalization, the representation constructs a canonical object space as well as a set of canonical part spaces. The canonical object space normalizes the object orientation,scales and articulations (e.g. joint parameters and states) while each canonical part space further normalizes its part pose and scale. We develop a deep network based on PointNet++ that predicts ANCSH from a single depth point cloud, including part segmentation, normalized coordinates, and joint parameters in the canonical object space. By leveraging the canonicalized joints, we demonstrate: 1) improved performance in part pose and scale estimations using the induced kinematic constraints from joints; 2) high accuracy for joint parameter estimation in camera space.



### Skeleton Extraction from 3D Point Clouds by Decomposing the Object into Parts
- **Arxiv ID**: http://arxiv.org/abs/1912.11932v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1912.11932v1)
- **Published**: 2019-12-26 20:52:57+00:00
- **Updated**: 2019-12-26 20:52:57+00:00
- **Authors**: Vijai Jayadevan, Edward Delp, Zygmunt Pizlo
- **Comment**: None
- **Journal**: None
- **Summary**: Decomposing a point cloud into its components and extracting curve skeletons from point clouds are two related problems. Decomposition of a shape into its components is often obtained as a byproduct of skeleton extraction. In this work, we propose to extract curve skeletons, from unorganized point clouds, by decomposing the object into its parts, identifying part skeletons and then linking these part skeletons together to obtain the complete skeleton. We believe it is the most natural way to extract skeletons in the sense that this would be the way a human would approach the problem. Our parts are generalized cylinders (GCs). Since, the axis of a GC is an integral part of its definition, the parts have natural skeletal representations. We use translational symmetry, the fundamental property of GCs, to extract parts from point clouds. We demonstrate how this method can handle a large variety of shapes. We compare our method with state of the art methods and show how a part based approach can deal with some of the limitations of other methods. We present an improved version of an existing point set registration algorithm and demonstrate its utility in extracting parts from point clouds. We also show how this method can be used to extract skeletons from and identify parts of noisy point clouds. A part based approach also provides a natural and intuitive interface for user interaction. We demonstrate the ease with which mistakes, if any, can be fixed with minimal user interaction with the help of a graphical user interface.



### Colorectal Polyp Segmentation by U-Net with Dilation Convolution
- **Arxiv ID**: http://arxiv.org/abs/1912.11947v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1912.11947v1)
- **Published**: 2019-12-26 23:27:18+00:00
- **Updated**: 2019-12-26 23:27:18+00:00
- **Authors**: Xinzi Sun, Pengfei Zhang, Dechun Wang, Yu Cao, Benyuan Liu
- **Comment**: 8 pages. ICMLA (International Conference on Machine Learning and
  Applications)
- **Journal**: None
- **Summary**: Colorectal cancer (CRC) is one of the most commonly diagnosed cancers and a leading cause of cancer deaths in the United States. Colorectal polyps that grow on the intima of the colon or rectum is an important precursor for CRC. Currently, the most common way for colorectal polyp detection and precancerous pathology is the colonoscopy. Therefore, accurate colorectal polyp segmentation during the colonoscopy procedure has great clinical significance in CRC early detection and prevention. In this paper, we propose a novel end-to-end deep learning framework for the colorectal polyp segmentation. The model we design consists of an encoder to extract multi-scale semantic features and a decoder to expand the feature maps to a polyp segmentation map. We improve the feature representation ability of the encoder by introducing the dilated convolution to learn high-level semantic features without resolution reduction. We further design a simplified decoder which combines multi-scale semantic features with fewer parameters than the traditional architecture. Furthermore, we apply three post processing techniques on the output segmentation map to improve colorectal polyp detection performance. Our method achieves state-of-the-art results on CVC-ClinicDB and ETIS-Larib Polyp DB.



