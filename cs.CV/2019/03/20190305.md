# Arxiv Papers in cs.CV on 2019-03-05
### Unsupervised Domain-Specific Deblurring via Disentangled Representations
- **Arxiv ID**: http://arxiv.org/abs/1903.01594v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01594v2)
- **Published**: 2019-03-05 00:00:27+00:00
- **Updated**: 2019-08-05 08:13:18+00:00
- **Authors**: Boyu Lu, Jun-Cheng Chen, Rama Chellappa
- **Comment**: Accepted by CVPR 2019. Code is released at:
  https://github.com/ustclby/Unsupervised-Domain-Specific-Deblurring/
- **Journal**: None
- **Summary**: Image deblurring aims to restore the latent sharp images from the corresponding blurred ones. In this paper, we present an unsupervised method for domain-specific single-image deblurring based on disentangled representations. The disentanglement is achieved by splitting the content and blur features in a blurred image using content encoders and blur encoders. We enforce a KL divergence loss to regularize the distribution range of extracted blur attributes such that little content information is contained. Meanwhile, to handle the unpaired training data, a blurring branch and the cycle-consistency loss are added to guarantee that the content structures of the deblurred results match the original images. We also add an adversarial loss on deblurred results to generate visually realistic images and a perceptual loss to further mitigate the artifacts. We perform extensive experiments on the tasks of face and text deblurring using both synthetic datasets and real images, and achieve improved results compared to recent state-of-the-art deblurring methods.



### The Regretful Agent: Heuristic-Aided Navigation through Progress Estimation
- **Arxiv ID**: http://arxiv.org/abs/1903.01602v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1903.01602v1)
- **Published**: 2019-03-05 00:17:12+00:00
- **Updated**: 2019-03-05 00:17:12+00:00
- **Authors**: Chih-Yao Ma, Zuxuan Wu, Ghassan AlRegib, Caiming Xiong, Zsolt Kira
- **Comment**: CVPR 2019 (Oral), our code is available at
  https://github.com/chihyaoma/regretful-agent
- **Journal**: None
- **Summary**: As deep learning continues to make progress for challenging perception tasks, there is increased interest in combining vision, language, and decision-making. Specifically, the Vision and Language Navigation (VLN) task involves navigating to a goal purely from language instructions and visual information without explicit knowledge of the goal. Recent successful approaches have made in-roads in achieving good success rates for this task but rely on beam search, which thoroughly explores a large number of trajectories and is unrealistic for applications such as robotics. In this paper, inspired by the intuition of viewing the problem as search on a navigation graph, we propose to use a progress monitor developed in prior work as a learnable heuristic for search. We then propose two modules incorporated into an end-to-end architecture: 1) A learned mechanism to perform backtracking, which decides whether to continue moving forward or roll back to a previous state (Regret Module) and 2) A mechanism to help the agent decide which direction to go next by showing directions that are visited and their associated progress estimate (Progress Marker). Combined, the proposed approach significantly outperforms current state-of-the-art methods using greedy action selection, with 5% absolute improvement on the test server in success rates, and more importantly 8% on success rates normalized by the path length. Our code is available at https://github.com/chihyaoma/regretful-agent .



### Stabilizing the Lottery Ticket Hypothesis
- **Arxiv ID**: http://arxiv.org/abs/1903.01611v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1903.01611v3)
- **Published**: 2019-03-05 00:52:12+00:00
- **Updated**: 2020-07-20 16:50:33+00:00
- **Authors**: Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M. Roy, Michael Carbin
- **Comment**: This article has been subsumed by "Linear Mode Connectivity and the
  Lottery Ticket Hypothesis" (arXiv:1912.05671, ICML 2020). Please read/cite
  that article instead
- **Journal**: None
- **Summary**: Pruning is a well-established technique for removing unnecessary structure from neural networks after training to improve the performance of inference. Several recent results have explored the possibility of pruning at initialization time to provide similar benefits during training. In particular, the "lottery ticket hypothesis" conjectures that typical neural networks contain small subnetworks that can train to similar accuracy in a commensurate number of steps. The evidence for this claim is that a procedure based on iterative magnitude pruning (IMP) reliably finds such subnetworks retroactively on small vision tasks. However, IMP fails on deeper networks, and proposed methods to prune before training or train pruned networks encounter similar scaling limitations. In this paper, we argue that these efforts have struggled on deeper networks because they have focused on pruning precisely at initialization. We modify IMP to search for subnetworks that could have been obtained by pruning early in training (0.1% to 7% through) rather than at iteration 0. With this change, it finds small subnetworks of deeper networks (e.g., 80% sparsity on Resnet-50) that can complete the training process to match the accuracy of the original network on more challenging tasks (e.g., ImageNet). In situations where IMP fails at iteration 0, the accuracy benefits of delaying pruning accrue rapidly over the earliest iterations of training. To explain these behaviors, we study subnetwork "stability," finding that - as accuracy improves in this fashion - IMP subnetworks train to parameters closer to those of the full network and do so with improved consistency in the face of gradient noise. These results offer new insights into the opportunity to prune large-scale networks early in training and the behaviors underlying the lottery ticket hypothesis



### Defense Against Adversarial Images using Web-Scale Nearest-Neighbor Search
- **Arxiv ID**: http://arxiv.org/abs/1903.01612v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.01612v2)
- **Published**: 2019-03-05 00:53:56+00:00
- **Updated**: 2019-05-04 20:34:14+00:00
- **Authors**: Abhimanyu Dubey, Laurens van der Maaten, Zeki Yalniz, Yixuan Li, Dhruv Mahajan
- **Comment**: CVPR 2019 Oral presentation; camera-ready with supplement (14 pages).
  v1 updated from error in Table 2, row 10
- **Journal**: None
- **Summary**: A plethora of recent work has shown that convolutional networks are not robust to adversarial images: images that are created by perturbing a sample from the data distribution as to maximize the loss on the perturbed example. In this work, we hypothesize that adversarial perturbations move the image away from the image manifold in the sense that there exists no physical process that could have produced the adversarial image. This hypothesis suggests that a successful defense mechanism against adversarial images should aim to project the images back onto the image manifold. We study such defense mechanisms, which approximate the projection onto the unknown image manifold by a nearest-neighbor search against a web-scale image database containing tens of billions of images. Empirical evaluations of this defense strategy on ImageNet suggest that it is very effective in attack settings in which the adversary does not have access to the image database. We also propose two novel attack methods to break nearest-neighbor defenses, and demonstrate conditions under which nearest-neighbor defense fails. We perform a series of ablation experiments, which suggest that there is a trade-off between robustness and accuracy in our defenses, that a large image database (with hundreds of millions of images) is crucial to get good performance, and that careful construction the image database is important to be robust against attacks tailored to circumvent our defenses.



### Integrating NVIDIA Deep Learning Accelerator (NVDLA) with RISC-V SoC on FireSim
- **Arxiv ID**: http://arxiv.org/abs/1903.06495v2
- **DOI**: None
- **Categories**: **cs.DC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1903.06495v2)
- **Published**: 2019-03-05 01:35:31+00:00
- **Updated**: 2019-12-06 21:52:55+00:00
- **Authors**: Farzad Farshchi, Qijing Huang, Heechul Yun
- **Comment**: Presented at the 2nd Workshop on Energy Efficient Machine Learning
  and Cognitive Computing for Embedded Applications (EMC2'19)
- **Journal**: None
- **Summary**: NVDLA is an open-source deep neural network (DNN) accelerator which has received a lot of attention by the community since its introduction by Nvidia. It is a full-featured hardware IP and can serve as a good reference for conducting research and development of SoCs with integrated accelerators. However, an expensive FPGA board is required to do experiments with this IP in a real SoC. Moreover, since NVDLA is clocked at a lower frequency on an FPGA, it would be hard to do accurate performance analysis with such a setup. To overcome these limitations, we integrate NVDLA into a real RISC-V SoC on the Amazon cloud FPGA using FireSim, a cycle-exact FPGA-accelerated simulator. We then evaluate the performance of NVDLA by running YOLOv3 object-detection algorithm. Our results show that NVDLA can sustain 7.5 fps when running YOLOv3. We further analyze the performance by showing that sharing the last-level cache with NVDLA can result in up to 1.56x speedup. We then identify that sharing the memory system with the accelerator can result in unpredictable execution time for the real-time tasks running on this platform. We believe this is an important issue that must be addressed in order for on-chip DNN accelerators to be incorporated in real-time embedded systems.



### A DenseNet Based Approach for Multi-Frame In-Loop Filter in HEVC
- **Arxiv ID**: http://arxiv.org/abs/1903.01648v1
- **DOI**: 10.1109/TIP.2019.2921877
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01648v1)
- **Published**: 2019-03-05 03:43:10+00:00
- **Updated**: 2019-03-05 03:43:10+00:00
- **Authors**: Tianyi Li, Mai Xu, Ren Yang, Xiaoming Tao
- **Comment**: 10 pages, 4 figures. Accepted by Data Compression Conference 2019
- **Journal**: Data Compression Conference 2019
- **Summary**: High efficiency video coding (HEVC) has brought outperforming efficiency for video compression. To reduce the compression artifacts of HEVC, we propose a DenseNet based approach as the in-loop filter of HEVC, which leverages multiple adjacent frames to enhance the quality of each encoded frame. Specifically, the higher-quality frames are found by a reference frame selector (RFS). Then, a deep neural network for multi-frame in-loop filter (named MIF-Net) is developed to enhance the quality of each encoded frame by utilizing the spatial information of this frame and the temporal information of its neighboring higher-quality frames. The MIF-Net is built on the recently developed DenseNet, benefiting from the improved generalization capacity and computational efficiency. Finally, experimental results verify the effectiveness of our multi-frame in-loop filter, outperforming the HM baseline and other state-of-the-art approaches.



### Visual-Thermal Landmarks and Inertial Fusion for Navigation in Degraded Visual Environments
- **Arxiv ID**: http://arxiv.org/abs/1903.01656v1
- **DOI**: 10.1109/AERO.2019.8741787
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1903.01656v1)
- **Published**: 2019-03-05 04:08:14+00:00
- **Updated**: 2019-03-05 04:08:14+00:00
- **Authors**: Shehryar Khattak, Christos Papachristos, Kostas Alexis
- **Comment**: 9 pages, 11 figures, Accepted at IEEE Aerospace Conference (AeroConf)
  2019
- **Journal**: None
- **Summary**: With an ever-widening domain of aerial robotic applications, including many mission critical tasks such as disaster response operations, search and rescue missions and infrastructure inspections taking place in GPS-denied environments, the need for reliable autonomous operation of aerial robots has become crucial. Operating in GPS-denied areas aerial robots rely on a multitude of sensors to localize and navigate. Visible spectrum cameras are the most commonly used sensors due to their low cost and weight. However, in environments that are visually-degraded such as in conditions of poor illumination, low texture, or presence of obscurants including fog, smoke and dust, the reliability of visible light cameras deteriorates significantly. Nevertheless, maintaining reliable robot navigation in such conditions is essential. In contrast to visible light cameras, thermal cameras offer visibility in the infrared spectrum and can be used in a complementary manner with visible spectrum cameras for robot localization and navigation tasks, without paying the significant weight and power penalty typically associated with carrying other sensors. Exploiting this fact, in this work we present a multi-sensor fusion algorithm for reliable odometry estimation in GPS-denied and degraded visual environments. The proposed method utilizes information from both the visible and thermal spectra for landmark selection and prioritizes feature extraction from informative image regions based on a metric over spatial entropy. Furthermore, inertial sensing cues are integrated to improve the robustness of the odometry estimation process. To verify our solution, a set of challenging experiments were conducted inside a) an obscurant filed machine shop-like industrial environment, as well as b) a dark subterranean mine in the presence of heavy airborne dust.



### Vision-Depth Landmarks and Inertial Fusion for Navigation in Degraded Visual Environments
- **Arxiv ID**: http://arxiv.org/abs/1903.01659v1
- **DOI**: 10.1007/978-3-030-03801-4_46
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1903.01659v1)
- **Published**: 2019-03-05 04:25:26+00:00
- **Updated**: 2019-03-05 04:25:26+00:00
- **Authors**: Shehryar Khattak, Christos Papachristos, Kostas Alexis
- **Comment**: 11 pages, 6 figures, Published in International Symposium on Visual
  Computing (ISVC) 2018
- **Journal**: None
- **Summary**: This paper proposes a method for tight fusion of visual, depth and inertial data in order to extend robotic capabilities for navigation in GPS-denied, poorly illuminated, and texture-less environments. Visual and depth information are fused at the feature detection and descriptor extraction levels to augment one sensing modality with the other. These multimodal features are then further integrated with inertial sensor cues using an extended Kalman filter to estimate the robot pose, sensor bias terms, and landmark positions simultaneously as part of the filter state. As demonstrated through a set of hand-held and Micro Aerial Vehicle experiments, the proposed algorithm is shown to perform reliably in challenging visually-degraded environments using RGB-D information from a lightweight and low-cost sensor and data from an IMU.



### Distinguishing mirror from glass: A 'big data' approach to material perception
- **Arxiv ID**: http://arxiv.org/abs/1903.01671v1
- **DOI**: 10.1167/jov.22.4.4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01671v1)
- **Published**: 2019-03-05 05:05:05+00:00
- **Updated**: 2019-03-05 05:05:05+00:00
- **Authors**: Hideki Tamura, Konrad E. Prokott, Roland W. Fleming
- **Comment**: 40 pages, 5 figures, 7 supplement figures
- **Journal**: Journal of Vision (2022) 22(4):4
- **Summary**: Visually identifying materials is crucial for many tasks, yet material perception remains poorly understood. Distinguishing mirror from glass is particularly challenging as both materials derive their appearance from their surroundings, yet we rarely experience difficulties telling them apart. Here we took a 'big data' approach to uncovering the underlying visual cues and processes, leveraging recent advances in neural network models of vision. We trained thousands of convolutional neural networks on >750,000 simulated mirror and glass objects, and compared their performance with human judgments, as well as alternative classifiers based on 'hand-engineered' image features. For randomly chosen images, all classifiers and humans performed with high accuracy, and therefore correlated highly with one another. To tease the models apart, we then painstakingly assembled a diagnostic image set for which humans make highly systematic errors, allowing us to decouple accuracy from human-like performance. A large-scale, systematic search through feedforward neural architectures revealed that relatively shallow networks predicted human judgments better than any other models. However, surprisingly, no network correlated better than 0.6 with humans (below inter-human correlations). Thus, although the model sets new standards for simulating human vision in a challenging material perception task, the results cast doubt on recent claims that such architectures are generally good models of human vision.



### Using Big Five Personality Model to Detect Cultural Aspects in Crowds
- **Arxiv ID**: http://arxiv.org/abs/1903.01688v1
- **DOI**: 10.1109/SIBGRAPI.2017.36
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1903.01688v1)
- **Published**: 2019-03-05 06:04:11+00:00
- **Updated**: 2019-03-05 06:04:11+00:00
- **Authors**: Rodolfo Migon Favaretto, Leandro Dihl, Soraia Raupp Musse, Felipe Vilanova, Angelo Brandelli Costa
- **Comment**: None
- **Journal**: None
- **Summary**: The use of information technology in the study of human behavior is a subject of great scientific interest. Cultural and personality aspects are factors that influence how people interact with one another in a crowd. This paper presents a methodology to detect cultural characteristics of crowds in video sequences. Based on filmed sequences, pedestrians are detected, tracked and characterized. Such information is then used to find out cultural differences in those videos, based on the Big-five personality model. Regarding cultural differences of each country, results indicate that this model generates coherent information when compared to data provided in literature.



### Real-time Multiple People Hand Localization in 4D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/1903.01695v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01695v1)
- **Published**: 2019-03-05 06:46:35+00:00
- **Updated**: 2019-03-05 06:46:35+00:00
- **Authors**: Hao Jiang, Quanzeng You
- **Comment**: None
- **Journal**: None
- **Summary**: We propose novel real-time algorithm to localize hands and find their associations with multiple people in the cluttered 4D volumetric data (dynamic 3D volumes). Different from the traditional multiple view approaches, which find key points in 2D and then triangulate to recover the 3D locations, our method directly processes the dynamic 3D data that involve both clutter and crowd. The volumetric representation is more desirable than the partial observations from different view points and enables more robust and accurate results. However, due to the large amount of data in the volumetric representation brute force 3D schemes are slow. In this paper, we propose novel real-time methods to tackle the problem to achieve both higher accuracy and faster speed than previous approaches. Our method detects the 3D bounding box of each subject and localizes the hands of each person. We develop new 2D features for fast candidate proposals and optimize the trajectory linking using a new max-covering bipartite matching formulation, which is critical for robust performance. We propose a novel decomposition method to reduce the key point localization in each person 3D volume to a sequence of efficient 2D problems. Our experiments show that the proposed method is faster than different competing methods and it gives almost half the localization error.



### EdgeStereo: An Effective Multi-Task Learning Network for Stereo Matching and Edge Detection
- **Arxiv ID**: http://arxiv.org/abs/1903.01700v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01700v2)
- **Published**: 2019-03-05 07:00:40+00:00
- **Updated**: 2019-12-11 05:55:13+00:00
- **Authors**: Xiao Song, Xu Zhao, Liangji Fang, Hanwen Hu
- **Comment**: Accepted for publication in International Journal of Computer Vision
  (IJCV)
- **Journal**: None
- **Summary**: Recently, leveraging on the development of end-to-end convolutional neural networks (CNNs), deep stereo matching networks have achieved remarkable performance far exceeding traditional approaches. However, state-of-the-art stereo frameworks still have difficulties at finding correct correspondences in texture-less regions, detailed structures, small objects and near boundaries, which could be alleviated by geometric clues such as edge contours and corresponding constraints. To improve the quality of disparity estimates in these challenging areas, we propose an effective multi-task learning network, EdgeStereo, composed of a disparity estimation branch and an edge detection branch, which enables end-to-end predictions of both disparity map and edge map. To effectively incorporate edge cues, we propose the edge-aware smoothness loss and edge feature embedding for inter-task interactions. It is demonstrated that based on our unified model, edge detection task and stereo matching task can promote each other. In addition, we design a compact module called residual pyramid to replace the commonly-used multi-stage cascaded structures or 3-D convolution based regularization modules in current stereo matching networks. By the time of the paper submission, EdgeStereo achieves state-of-art performance on the FlyingThings3D dataset, KITTI 2012 and KITTI 2015 stereo benchmarks, outperforming other published stereo matching methods by a noteworthy margin. EdgeStereo also achieves comparable generalization performance for disparity estimation because of the incorporation of edge cues.



### Deep Learning Based Motion Planning For Autonomous Vehicle Using Spatiotemporal LSTM Network
- **Arxiv ID**: http://arxiv.org/abs/1903.01712v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1903.01712v1)
- **Published**: 2019-03-05 07:46:47+00:00
- **Updated**: 2019-03-05 07:46:47+00:00
- **Authors**: Zhengwei Bai, Baigen Cai, Wei Shangguan, Linguo Chai
- **Comment**: 5 pages, 8 figures, Accepted to 2018 Chinese Automation Congress
  (CAC)
- **Journal**: None
- **Summary**: Motion Planning, as a fundamental technology of automatic navigation for the autonomous vehicle, is still an open challenging issue in the real-life traffic situation and is mostly applied by the model-based approaches. However, due to the complexity of the traffic situations and the uncertainty of the edge cases, it is hard to devise a general motion planning system for the autonomous vehicle. In this paper, we proposed a motion planning model based on deep learning (named as spatiotemporal LSTM network), which is able to generate a real-time reflection based on spatiotemporal information extraction. To be specific, the model based on spatiotemporal LSTM network has three main structure. Firstly, the Convolutional Long-short Term Memory (Conv-LSTM) is used to extract hidden features through sequential image data. Then, the 3D Convolutional Neural Network(3D-CNN) is applied to extract the spatiotemporal information from the multi-frame feature information. Finally, the fully connected neural networks are used to construct a control model for autonomous vehicle steering angle. The experiments demonstrated that the proposed method can generate a robust and accurate visual motion planning results for the autonomous vehicle.



### Improve Object Detection by Data Enhancement based on Generative Adversarial Nets
- **Arxiv ID**: http://arxiv.org/abs/1903.01716v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01716v1)
- **Published**: 2019-03-05 08:05:29+00:00
- **Updated**: 2019-03-05 08:05:29+00:00
- **Authors**: Wei Jiang, Na Ying
- **Comment**: None
- **Journal**: None
- **Summary**: The accuracy of the object detection model depends on whether the anchor boxes effectively trained. Because of the small number of GT boxes or object target is invariant in the training phase, cannot effectively train anchor boxes. Improving detection accuracy by extending the dataset is an effective way. We propose a data enhancement method based on the foreground-background separation model. While this model uses a binary image of object target random perturb original dataset image. Perturbation methods include changing the color channel of the object, adding salt noise to the object, and enhancing contrast. The main contribution of this paper is to propose a data enhancement method based on GAN and improve detection accuracy of DSSD. Results are shown on both PASCAL VOC2007 and PASCAL VOC2012 dataset. Our model with 321x321 input achieves 78.7% mAP on the VOC2007 test, 76.6% mAP on the VOC2012 test.



### Hue Modification Localization By Pair Matching
- **Arxiv ID**: http://arxiv.org/abs/1903.01735v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01735v1)
- **Published**: 2019-03-05 09:08:21+00:00
- **Updated**: 2019-03-05 09:08:21+00:00
- **Authors**: Quoc-Tin Phan, Michele Vascotto, Giulia Boato
- **Comment**: None
- **Journal**: None
- **Summary**: Hue modification is the adjustment of hue property on color images. Conducting hue modification on an image is trivial, and it can be abused to falsify opinions of viewers. Since shapes, edges or textural information remains unchanged after hue modification, this type of manipulation is relatively hard to be detected and localized. Since small patches inherit the same Color Filter Array (CFA) configuration and demosaicing, any distortion made by local hue modification can be detected by patch matching within the same image. In this paper, we propose to localize hue modification by means of a Siamese neural network specifically designed for matching two inputs. By crafting the network outputs, we are able to form a heatmap which potentially highlights malicious regions. Our proposed method deals well not only with uncompressed images but also with the presence of JPEG compression, an operation usually hindering the exploitation of CFA and demosaicing artifacts. Experimental evidences corroborate the effectiveness of the proposed method.



### Leveraging Shape Completion for 3D Siamese Tracking
- **Arxiv ID**: http://arxiv.org/abs/1903.01784v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01784v2)
- **Published**: 2019-03-05 12:29:10+00:00
- **Updated**: 2019-03-28 13:03:45+00:00
- **Authors**: Silvio Giancola, Jesus Zarzar, Bernard Ghanem
- **Comment**: Accepted in CVPR19
- **Journal**: None
- **Summary**: Point clouds are challenging to process due to their sparsity, therefore autonomous vehicles rely more on appearance attributes than pure geometric features. However, 3D LIDAR perception can provide crucial information for urban navigation in challenging light or weather conditions. In this paper, we investigate the versatility of Shape Completion for 3D Object Tracking in LIDAR point clouds. We design a Siamese tracker that encodes model and candidate shapes into a compact latent representation. We regularize the encoding by enforcing the latent representation to decode into an object model shape. We observe that 3D object tracking and 3D shape completion complement each other. Learning a more meaningful latent representation shows better discriminatory capabilities, leading to improved tracking performance. We test our method on the KITTI Tracking set using car 3D bounding boxes. Our model reaches a 76.94% Success rate and 81.38% Precision for 3D Object Tracking, with the shape completion regularization leading to an improvement of 3% in both metrics.



### Robot Localization in Floor Plans Using a Room Layout Edge Extraction Network
- **Arxiv ID**: http://arxiv.org/abs/1903.01804v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.01804v2)
- **Published**: 2019-03-05 13:09:18+00:00
- **Updated**: 2019-07-12 10:59:11+00:00
- **Authors**: Federico Boniardi, Abhinav Valada, Rohit Mohan, Tim Caselitz, Wolfram Burgard
- **Comment**: Accepted for IROS 2019
- **Journal**: None
- **Summary**: Indoor localization is one of the crucial enablers for deployment of service robots. Although several successful techniques for indoor localization have been proposed, the majority of them relies on maps generated from data gathered with the same sensor modality used for localization. Typically, tedious labor by experts is needed to acquire this data, thus limiting the readiness of the system as well as its ease of installation for inexperienced operators. In this paper, we propose a memory and computationally efficient monocular camera-based localization system that allows a robot to estimate its pose given an architectural floor plan. Our method employs a convolutional neural network to predict room layout edges from a single camera image and estimates the robot pose using a particle filter that matches the extracted edges to the given floor plan. We evaluate our localization system using multiple real-world experiments and demonstrate that it has the robustness and accuracy required for reliable indoor navigation.



### Towards Design Space Exploration and Optimization of Fast Algorithms for Convolutional Neural Networks (CNNs) on FPGAs
- **Arxiv ID**: http://arxiv.org/abs/1903.01811v1
- **DOI**: None
- **Categories**: **eess.SP**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1903.01811v1)
- **Published**: 2019-03-05 13:28:07+00:00
- **Updated**: 2019-03-05 13:28:07+00:00
- **Authors**: Afzal Ahmad, Muhammad Adeel Pasha
- **Comment**: Preprint: Accepted in 22nd IEEE Design, Automation & Test in Europe
  Conference and Exhibition (DATE'19), Florence, Italy, March 2019
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) have gained widespread popularity in the field of computer vision and image processing. Due to huge computational requirements of CNNs, dedicated hardware-based implementations are being explored to improve their performance. Hardware platforms such as Field Programmable Gate Arrays (FPGAs) are widely being used to design parallel architectures for this purpose. In this paper, we analyze Winograd minimal filtering or fast convolution algorithms to reduce the arithmetic complexity of convolutional layers of CNNs. We explore a complex design space to find the sets of parameters that result in improved throughput and power-efficiency. We also design a pipelined and parallel Winograd convolution engine that improves the throughput and power-efficiency while reducing the computational complexity of the overall system. Our proposed designs show up to 4.75$\times$ and 1.44$\times$ improvements in throughput and power-efficiency, respectively, in comparison to the state-of-the-art design while using approximately 2.67$\times$ more multipliers. Furthermore, we obtain savings of up to 53.6\% in logic resources compared with the state-of-the-art implementation.



### HexagDLy - Processing hexagonally sampled data with CNNs in PyTorch
- **Arxiv ID**: http://arxiv.org/abs/1903.01814v1
- **DOI**: 10.1016/j.softx.2019.02.010
- **Categories**: **cs.CV**, astro-ph.IM
- **Links**: [PDF](http://arxiv.org/pdf/1903.01814v1)
- **Published**: 2019-03-05 13:32:03+00:00
- **Updated**: 2019-03-05 13:32:03+00:00
- **Authors**: Constantin Steppa, Tim Lukas Holch
- **Comment**: None
- **Journal**: SoftwareX, 9, 193-198, 2019
- **Summary**: HexagDLy is a Python-library extending the PyTorch deep learning framework with convolution and pooling operations on hexagonal grids. It aims to ease the access to convolutional neural networks for applications that rely on hexagonally sampled data as, for example, commonly found in ground-based astroparticle physics experiments.



### Virtual Ground Truth, and Pre-selection of 3D Interest Points for Improved Repeatability Evaluation of 2D Detectors
- **Arxiv ID**: http://arxiv.org/abs/1903.01828v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01828v1)
- **Published**: 2019-03-05 14:03:13+00:00
- **Updated**: 2019-03-05 14:03:13+00:00
- **Authors**: Simon R Lang, Martin H Luerssen, David M Powers
- **Comment**: Accepted for publication in CCVPR 2018 Conference Proceedings,
  Wellington, New Zealand. 11 pages, 5 figures
- **Journal**: None
- **Summary**: In Computer Vision, finding simple features is performed using classifiers called interest point (IP) detectors, which are often utilised to track features as the scene changes. For 2D based classifiers it has been intuitive to measure repeated point reliability using 2D metrics given the difficulty to establish ground truth beyond 2D. The aim is to bridge the gap between 2D classifiers and 3D environments, and improve performance analysis of 2D IP classification on 3D objects. This paper builds on existing work with 3D scanned and artificial models to test conventional 2D feature detectors with the assistance of virtualised 3D scenes. Virtual space depth is leveraged in tests to perform pre-selection of closest repeatable points in both 2D and 3D contexts before repeatability is measured. This more reliable ground truth is used to analyse testing configurations with a singular and 12 model dataset across affine transforms in x, y and z rotation, as well as x,y scaling with 9 well known IP detectors. The virtual scene's ground truth demonstrates that 3D pre-selection eliminates a large portion of false positives that are normally considered repeated in 2D configurations. The results indicate that 3D virtual environments can provide assistance in comparing the performance of conventional detectors when extending their applications to 3D environments, and can result in better classification of features when testing prospective classifiers' performance. A ROC based informedness measure also highlights tradeoffs in 2D/3D performance compared to conventional repeatability measures.



### Frustum ConvNet: Sliding Frustums to Aggregate Local Point-Wise Features for Amodal 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1903.01864v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01864v2)
- **Published**: 2019-03-05 14:46:58+00:00
- **Updated**: 2019-08-14 12:38:26+00:00
- **Authors**: Zhixin Wang, Kui Jia
- **Comment**: IROS 2019
- **Journal**: None
- **Summary**: In this work, we propose a novel method termed \emph{Frustum ConvNet (F-ConvNet)} for amodal 3D object detection from point clouds. Given 2D region proposals in an RGB image, our method first generates a sequence of frustums for each region proposal, and uses the obtained frustums to group local points. F-ConvNet aggregates point-wise features as frustum-level feature vectors, and arrays these feature vectors as a feature map for use of its subsequent component of fully convolutional network (FCN), which spatially fuses frustum-level features and supports an end-to-end and continuous estimation of oriented boxes in the 3D space. We also propose component variants of F-ConvNet, including an FCN variant that extracts multi-resolution frustum features, and a refined use of F-ConvNet over a reduced 3D space. Careful ablation studies verify the efficacy of these component variants. F-ConvNet assumes no prior knowledge of the working 3D environment and is thus dataset-agnostic. We present experiments on both the indoor SUN-RGBD and outdoor KITTI datasets. F-ConvNet outperforms all existing methods on SUN-RGBD, and at the time of submission it outperforms all published works on the KITTI benchmark. Code has been made available at: {\url{https://github.com/zhixinwang/frustum-convnet}.}



### TinBiNN: Tiny Binarized Neural Network Overlay in about 5,000 4-LUTs and 5mW
- **Arxiv ID**: http://arxiv.org/abs/1903.06630v1
- **DOI**: None
- **Categories**: **cs.DC**, cs.CV, cs.OH
- **Links**: [PDF](http://arxiv.org/pdf/1903.06630v1)
- **Published**: 2019-03-05 14:51:36+00:00
- **Updated**: 2019-03-05 14:51:36+00:00
- **Authors**: Guy G. F. Lemieux, Joe Edwards, Joel Vandergriendt, Aaron Severance, Ryan De Iaco, Abdullah Raouf, Hussein Osman, Tom Watzka, Satwant Singh
- **Comment**: Presented at 3rd International Workshop on Overlay Architectures for
  FPGAs (OLAF 2017) arXiv:1704.08802
- **Journal**: None
- **Summary**: Reduced-precision arithmetic improves the size, cost, power and performance of neural networks in digital logic. In convolutional neural networks, the use of 1b weights can achieve state-of-the-art error rates while eliminating multiplication, reducing storage and improving power efficiency. The BinaryConnect binary-weighted system, for example, achieves 9.9% error using floating-point activations on the CIFAR-10 dataset. In this paper, we introduce TinBiNN, a lightweight vector processor overlay for accelerating inference computations with 1b weights and 8b activations. The overlay is very small -- it uses about 5,000 4-input LUTs and fits into a low cost iCE40 UltraPlus FPGA from Lattice Semiconductor. To show this can be useful, we build two embedded 'person detector' systems by shrinking the original BinaryConnect network. The first is a 10-category classifier with a 89% smaller network that runs in 1,315ms and achieves 13.6% error. The other is a 1-category classifier that is even smaller, runs in 195ms, and has only 0.4% error. In both classifiers, the error can be attributed entirely to training and not reduced precision.



### Learning a smooth kernel regularizer for convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1903.01882v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1903.01882v1)
- **Published**: 2019-03-05 15:07:29+00:00
- **Updated**: 2019-03-05 15:07:29+00:00
- **Authors**: Reuben Feinman, Brenden M. Lake
- **Comment**: Submitted to CogSci 2019
- **Journal**: None
- **Summary**: Modern deep neural networks require a tremendous amount of data to train, often needing hundreds or thousands of labeled examples to learn an effective representation. For these networks to work with less data, more structure must be built into their architectures or learned from previous experience. The learned weights of convolutional neural networks (CNNs) trained on large datasets for object recognition contain a substantial amount of structure. These representations have parallels to simple cells in the primary visual cortex, where receptive fields are smooth and contain many regularities. Incorporating smoothness constraints over the kernel weights of modern CNN architectures is a promising way to improve their sample complexity. We propose a smooth kernel regularizer that encourages spatial correlations in convolution kernel weights. The correlation parameters of this regularizer are learned from previous experience, yielding a method with a hierarchical Bayesian interpretation. We show that our correlated regularizer can help constrain models for visual recognition, improving over an L2 regularization baseline.



### FastReg: Fast Non-Rigid Registration via Accelerated Optimisation on the Manifold of Diffeomorphisms
- **Arxiv ID**: http://arxiv.org/abs/1903.01905v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01905v3)
- **Published**: 2019-03-05 15:41:47+00:00
- **Updated**: 2019-04-24 10:02:27+00:00
- **Authors**: Daniel Grzech, Loïc le Folgoc, Mattias P. Heinrich, Bishesh Khanal, Jakub Moll, Julia A. Schnabel, Ben Glocker, Bernhard Kainz
- **Comment**: There is an ongoing dispute about the presentation of this paper. It
  will be withdrawn until the dispute is resoved
- **Journal**: None
- **Summary**: We present an implementation of a new approach to diffeomorphic non-rigid registration of medical images. The method is based on optical flow and warps images via gradient flow with the standard $L^2$ inner product. To compute the transformation, we rely on accelerated optimisation on the manifold of diffeomorphisms. We achieve regularity properties of Sobolev gradient flows, which are expensive to compute, owing to a novel method of averaging the gradients in time rather than space. We successfully register brain MRI and challenging abdominal CT scans at speeds orders of magnitude faster than previous approaches. We make our code available in a public repository: https://github.com/dgrzech/fastreg



### O-GAN: Extremely Concise Approach for Auto-Encoding Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1903.01931v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.01931v1)
- **Published**: 2019-03-05 17:01:49+00:00
- **Updated**: 2019-03-05 17:01:49+00:00
- **Authors**: Jianlin Su
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose Orthogonal Generative Adversarial Networks (O-GANs). We decompose the network of discriminator orthogonally and add an extra loss into the objective of common GANs, which can enforce discriminator become an effective encoder. The same extra loss can be embedded into any kind of GANs and there is almost no increase in computation. Furthermore, we discuss the principle of our method, which is relative to the fully-exploiting of the remaining degrees of freedom of discriminator. As we know, our solution is the simplest approach to train a generative adversarial network with auto-encoding ability.



### MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1903.01945v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01945v2)
- **Published**: 2019-03-05 17:29:37+00:00
- **Updated**: 2019-04-02 15:35:40+00:00
- **Authors**: Yazan Abu Farha, Juergen Gall
- **Comment**: CVPR 2019 Camera Ready
- **Journal**: None
- **Summary**: Temporally locating and classifying action segments in long untrimmed videos is of particular interest to many applications like surveillance and robotics. While traditional approaches follow a two-step pipeline, by generating frame-wise probabilities and then feeding them to high-level temporal models, recent approaches use temporal convolutions to directly classify the video frames. In this paper, we introduce a multi-stage architecture for the temporal action segmentation task. Each stage features a set of dilated temporal convolutions to generate an initial prediction that is refined by the next one. This architecture is trained using a combination of a classification loss and a proposed smoothing loss that penalizes over-segmentation errors. Extensive evaluation shows the effectiveness of the proposed model in capturing long-range dependencies and recognizing action segments. Our model achieves state-of-the-art results on three challenging datasets: 50Salads, Georgia Tech Egocentric Activities (GTEA), and the Breakfast dataset.



### TableBank: A Benchmark Dataset for Table Detection and Recognition
- **Arxiv ID**: http://arxiv.org/abs/1903.01949v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.01949v2)
- **Published**: 2019-03-05 17:34:21+00:00
- **Updated**: 2020-07-06 09:19:56+00:00
- **Authors**: Minghao Li, Lei Cui, Shaohan Huang, Furu Wei, Ming Zhou, Zhoujun Li
- **Comment**: LREC 2020
- **Journal**: None
- **Summary**: We present TableBank, a new image-based table detection and recognition dataset built with novel weak supervision from Word and Latex documents on the internet. Existing research for image-based table detection and recognition usually fine-tunes pre-trained models on out-of-domain data with a few thousand human-labeled examples, which is difficult to generalize on real-world applications. With TableBank that contains 417K high quality labeled tables, we build several strong baselines using state-of-the-art models with deep neural networks. We make TableBank publicly available and hope it will empower more deep learning approaches in the table detection and recognition task. The dataset and models are available at \url{https://github.com/doc-analysis/TableBank}.



### Statistical Guarantees for the Robustness of Bayesian Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1903.01980v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1903.01980v1)
- **Published**: 2019-03-05 18:49:40+00:00
- **Updated**: 2019-03-05 18:49:40+00:00
- **Authors**: Luca Cardelli, Marta Kwiatkowska, Luca Laurenti, Nicola Paoletti, Andrea Patane, Matthew Wicker
- **Comment**: 9 pages, 6 figures
- **Journal**: None
- **Summary**: We introduce a probabilistic robustness measure for Bayesian Neural Networks (BNNs), defined as the probability that, given a test point, there exists a point within a bounded set such that the BNN prediction differs between the two. Such a measure can be used, for instance, to quantify the probability of the existence of adversarial examples. Building on statistical verification techniques for probabilistic models, we develop a framework that allows us to estimate probabilistic robustness for a BNN with statistical guarantees, i.e., with a priori error and confidence bounds. We provide experimental comparison for several approximate BNN inference techniques on image classification tasks associated to MNIST and a two-class subset of the GTSRB dataset. Our results enable quantification of uncertainty of BNN predictions in adversarial settings.



### Crowd Counting Using Scale-Aware Attention Networks
- **Arxiv ID**: http://arxiv.org/abs/1903.02025v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.02025v1)
- **Published**: 2019-03-05 19:36:21+00:00
- **Updated**: 2019-03-05 19:36:21+00:00
- **Authors**: Mohammad Asiful Hossain, Mehrdad Hosseinzadeh, Omit Chanda, Yang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we consider the problem of crowd counting in images. Given an image of a crowded scene, our goal is to estimate the density map of this image, where each pixel value in the density map corresponds to the crowd density at the corresponding location in the image. Given the estimated density map, the final crowd count can be obtained by summing over all values in the density map. One challenge of crowd counting is the scale variation in images. In this work, we propose a novel scale-aware attention network to address this challenge. Using the attention mechanism popular in recent deep learning architectures, our model can automatically focus on certain global and local scales appropriate for the image. By combining these global and local scale attention, our model outperforms other state-of-the-art methods for crowd counting on several benchmark datasets.



### Deep Learning in Medical Image Registration: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1903.02026v2
- **DOI**: 10.1007/s00138-020-01060-x
- **Categories**: **q-bio.QM**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1903.02026v2)
- **Published**: 2019-03-05 19:37:51+00:00
- **Updated**: 2020-01-21 14:58:06+00:00
- **Authors**: Grant Haskins, Uwe Kruger, Pingkun Yan
- **Comment**: Accepted for publication by Machine Vision and Applications on
  January 8, 2020
- **Journal**: None
- **Summary**: The establishment of image correspondence through robust image registration is critical to many clinical tasks such as image fusion, organ atlas creation, and tumor growth monitoring, and is a very challenging problem. Since the beginning of the recent deep learning renaissance, the medical imaging research community has developed deep learning based approaches and achieved the state-of-the-art in many applications, including image registration. The rapid adoption of deep learning for image registration applications over the past few years necessitates a comprehensive summary and outlook, which is the main scope of this survey. This requires placing a focus on the different research areas as well as highlighting challenges that practitioners face. This survey, therefore, outlines the evolution of deep learning based medical image registration in the context of both research challenges and relevant innovations in the past few years. Further, this survey highlights future research directions to show how this field may be possibly moved forward to the next level.



### Abnormal Chest X-ray Identification With Generative Adversarial One-Class Classifier
- **Arxiv ID**: http://arxiv.org/abs/1903.02040v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.02040v1)
- **Published**: 2019-03-05 20:24:23+00:00
- **Updated**: 2019-03-05 20:24:23+00:00
- **Authors**: Yuxing Tang, Youbao Tang, Mei Han, Jing Xiao, Ronald M. Summers
- **Comment**: Accepted as an oral presentation in IEEE International Symposium on
  Biomedical Imaging (ISBI) 2019
- **Journal**: None
- **Summary**: Being one of the most common diagnostic imaging tests, chest radiography requires timely reporting of potential findings in the images. In this paper, we propose an end-to-end architecture for abnormal chest X-ray identification using generative adversarial one-class learning. Unlike previous approaches, our method takes only normal chest X-ray images as input. The architecture is composed of three deep neural networks, each of which learned by competing while collaborating among them to model the underlying content structure of the normal chest X-rays. Given a chest X-ray image in the testing phase, if it is normal, the learned architecture can well model and reconstruct the content; if it is abnormal, since the content is unseen in the training phase, the model would perform poorly in its reconstruction. It thus enables distinguishing abnormal chest X-rays from normal ones. Quantitative and qualitative experiments demonstrate the effectiveness and efficiency of our approach, where an AUC of 0.841 is achieved on the challenging NIH Chest X-ray dataset in a one-class learning setting, with the potential in reducing the workload for radiologists.



### Defining Image Memorability using the Visual Memory Schema
- **Arxiv ID**: http://arxiv.org/abs/1903.02056v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.02056v1)
- **Published**: 2019-03-05 21:12:27+00:00
- **Updated**: 2019-03-05 21:12:27+00:00
- **Authors**: Erdem Akagunduz, Adrian G. Bors, Karla K. Evans
- **Comment**: Submitted to TPAMI on Aug 4, 2017
- **Journal**: None
- **Summary**: Memorability of an image is a characteristic determined by the human observers' ability to remember images they have seen. Yet recent work on image memorability defines it as an intrinsic property that can be obtained independent of the observer. {The current study aims to enhance our understanding and prediction of image memorability, improving upon existing approaches by incorporating the properties of cumulative human annotations.} We propose a new concept called the Visual Memory Schema (VMS) referring to an organisation of image components human observers share when encoding and recognising images. The concept of VMS is operationalised by asking human observers to define memorable regions of images they were asked to remember during an episodic memory test. We then statistically assess the consistency of VMSs across observers for either correctly or incorrectly recognised images. The associations of the VMSs with eye fixations and saliency are analysed separately as well. Lastly, we adapt various deep learning architectures for the reconstruction and prediction of memorable regions in images and analyse the results when using transfer learning at the outputs of different convolutional network layers.



### Viewpoint Optimization for Autonomous Strawberry Harvesting with Deep Reinforcement Learning
- **Arxiv ID**: http://arxiv.org/abs/1903.02074v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.02074v2)
- **Published**: 2019-03-05 21:54:46+00:00
- **Updated**: 2019-05-02 05:01:24+00:00
- **Authors**: Jonathon Sather, Xiaozheng Jane Zhang
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Autonomous harvesting may provide a viable solution to mounting labor pressures in the United States's strawberry industry. However, due to bottlenecks in machine perception and economic viability, a profitable and commercially adopted strawberry harvesting system remains elusive. In this research, we explore the feasibility of using deep reinforcement learning to overcome these bottlenecks and develop a practical algorithm to address the sub-objective of viewpoint optimization, or the development of a control policy to direct a camera to favorable vantage points for autonomous harvesting. We evaluate the algorithm's performance in a custom, open-source simulated environment and observe encouraging results. Our trained agent yields 8.7 times higher returns than random actions and 8.8 percent faster exploration than our best baseline policy, which uses visual servoing. Visual investigation shows the agent is able to fixate on favorable viewpoints, despite having no explicit means to propagate information through time. Overall, we conclude that deep reinforcement learning is a promising area of research to advance the state of the art in autonomous strawberry harvesting.



### Bounded Residual Gradient Networks (BReG-Net) for Facial Affect Computing
- **Arxiv ID**: http://arxiv.org/abs/1903.02110v1
- **DOI**: 10.1109/FG.2019.8756587
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.02110v1)
- **Published**: 2019-03-05 23:31:20+00:00
- **Updated**: 2019-03-05 23:31:20+00:00
- **Authors**: Behzad Hasani, Pooran Singh Negi, Mohammad H. Mahoor
- **Comment**: To appear in 14th IEEE International Conference on Automatic Face &
  Gesture Recognition (FG 2019)
- **Journal**: 2019 14th IEEE International Conference on Automatic Face &
  Gesture Recognition (FG 2019)
- **Summary**: Residual-based neural networks have shown remarkable results in various visual recognition tasks including Facial Expression Recognition (FER). Despite the tremendous efforts have been made to improve the performance of FER systems using DNNs, existing methods are not generalizable enough for practical applications. This paper introduces Bounded Residual Gradient Networks (BReG-Net) for facial expression recognition, in which the shortcut connection between the input and the output of the ResNet module is replaced with a differentiable function with a bounded gradient. This configuration prevents the network from facing the vanishing or exploding gradient problem. We show that utilizing such non-linear units will result in shallower networks with better performance. Further, by using a weighted loss function which gives a higher priority to less represented categories, we can achieve an overall better recognition rate. The results of our experiments show that BReG-Nets outperform state-of-the-art methods on three publicly available facial databases in the wild, on both the categorical and dimensional models of affect.



### Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation
- **Arxiv ID**: http://arxiv.org/abs/1903.02120v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.02120v3)
- **Published**: 2019-03-05 23:59:41+00:00
- **Updated**: 2019-04-05 01:27:46+00:00
- **Authors**: Zhi Tian, Tong He, Chunhua Shen, Youliang Yan
- **Comment**: Accepted to Proc. IEEE Conf. Computer Vision and Pattern Recognition
  (CVPR), 2019. Content may change prior to final publication
- **Journal**: None
- **Summary**: Recent semantic segmentation methods exploit encoder-decoder architectures to produce the desired pixel-wise segmentation prediction. The last layer of the decoders is typically a bilinear upsampling procedure to recover the final pixel-wise prediction. We empirically show that this oversimple and data-independent bilinear upsampling may lead to sub-optimal results.   In this work, we propose a data-dependent upsampling (DUpsampling) to replace bilinear, which takes advantages of the redundancy in the label space of semantic segmentation and is able to recover the pixel-wise prediction from low-resolution outputs of CNNs. The main advantage of the new upsampling layer lies in that with a relatively lower-resolution feature map such as $\frac{1}{16}$ or $\frac{1}{32}$ of the input size, we can achieve even better segmentation accuracy, significantly reducing computation complexity. This is made possible by 1) the new upsampling layer's much improved reconstruction capability; and more importantly 2) the DUpsampling based decoder's flexibility in leveraging almost arbitrary combinations of the CNN encoders' features. Experiments demonstrate that our proposed decoder outperforms the state-of-the-art decoder, with only $\sim$20\% of computation. Finally, without any post-processing, the framework equipped with our proposed decoder achieves new state-of-the-art performance on two datasets: 88.1\% mIOU on PASCAL VOC with 30\% computation of the previously best model; and 52.5\% mIOU on PASCAL Context.



