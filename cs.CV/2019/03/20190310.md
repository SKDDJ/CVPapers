# Arxiv Papers in cs.CV on 2019-03-10
### Fast Single Image Reflection Suppression via Convex Optimization
- **Arxiv ID**: http://arxiv.org/abs/1903.03889v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.03889v3)
- **Published**: 2019-03-10 00:01:36+00:00
- **Updated**: 2019-05-10 00:55:21+00:00
- **Authors**: Yang Yang, Wenye Ma, Yin Zheng, Jian-Feng Cai, Weiyu Xu
- **Comment**: 9 pages, 8 figures, IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR) 2019
- **Journal**: None
- **Summary**: Removing undesired reflections from images taken through the glass is of great importance in computer vision. It serves as a means to enhance the image quality for aesthetic purposes as well as to preprocess images in machine learning and pattern recognition applications. We propose a convex model to suppress the reflection from a single input image. Our model implies a partial differential equation with gradient thresholding, which is solved efficiently using Discrete Cosine Transform. Extensive experiments on synthetic and real-world images demonstrate that our approach achieves desirable reflection suppression results and dramatically reduces the execution time.



### A Hybrid GA-PSO Method for Evolving Architecture and Short Connections of Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1903.03893v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1903.03893v1)
- **Published**: 2019-03-10 00:51:19+00:00
- **Updated**: 2019-03-10 00:51:19+00:00
- **Authors**: Bin Wang, Yanan Sun, Bing Xue, Mengjie Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Image classification is a difficult machine learning task, where Convolutional Neural Networks (CNNs) have been applied for over 20 years in order to solve the problem. In recent years, instead of the traditional way of only connecting the current layer with its next layer, shortcut connections have been proposed to connect the current layer with its forward layers apart from its next layer, which has been proved to be able to facilitate the training process of deep CNNs. However, there are various ways to build the shortcut connections, it is hard to manually design the best shortcut connections when solving a particular problem, especially given the design of the network architecture is already very challenging.   In this paper, a hybrid evolutionary computation (EC) method is proposed to \textit{automatically} evolve both the architecture of deep CNNs and the shortcut connections. Three major contributions of this work are: Firstly, a new encoding strategy is proposed to encode a CNN, where the architecture and the shortcut connections are encoded separately; Secondly, a hybrid two-level EC method, which combines particle swarm optimisation and genetic algorithms, is developed to search for the optimal CNNs; Lastly, an adjustable learning rate is introduced for the fitness evaluations, which provides a better learning rate for the training process given a fixed number of epochs. The proposed algorithm is evaluated on three widely used benchmark datasets of image classification and compared with 12 peer Non-EC based competitors and one EC based competitor. The experimental results demonstrate that the proposed method outperforms all of the peer competitors in terms of classification accuracy.



### Multiview 2D/3D Rigid Registration via a Point-Of-Interest Network for Tracking and Triangulation ($\text{POINT}^2$)
- **Arxiv ID**: http://arxiv.org/abs/1903.03896v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.03896v4)
- **Published**: 2019-03-10 01:03:46+00:00
- **Updated**: 2020-12-22 21:05:40+00:00
- **Authors**: Haofu Liao, Wei-An Lin, Jiarui Zhang, Jingdan Zhang, Jiebo Luo, S. Kevin Zhou
- **Comment**: This work has been accepted to CVPR 2019
- **Journal**: None
- **Summary**: We propose to tackle the problem of multiview 2D/3D rigid registration for intervention via a Point-Of-Interest Network for Tracking and Triangulation ($\text{POINT}^2$). $\text{POINT}^2$ learns to establish 2D point-to-point correspondences between the pre- and intra-intervention images by tracking a set of random POIs. The 3D pose of the pre-intervention volume is then estimated through a triangulation layer. In $\text{POINT}^2$, the unified framework of the POI tracker and the triangulation layer enables learning informative 2D features and estimating 3D pose jointly. In contrast to existing approaches, $\text{POINT}^2$ only requires a single forward-pass to achieve a reliable 2D/3D registration. As the POI tracker is shift-invariant, $\text{POINT}^2$ is more robust to the initial pose of the 3D pre-intervention image. Extensive experiments on a large-scale clinical cone-beam CT (CBCT) dataset show that the proposed $\text{POINT}^2$ method outperforms the existing learning-based method in terms of accuracy, robustness and running time. Furthermore, when used as an initial pose estimator, our method also improves the robustness and speed of the state-of-the-art optimization-based approaches by ten folds.



### Shape2Motion: Joint Analysis of Motion Parts and Attributes from 3D Shapes
- **Arxiv ID**: http://arxiv.org/abs/1903.03911v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1903.03911v2)
- **Published**: 2019-03-10 03:24:30+00:00
- **Updated**: 2019-03-12 13:58:58+00:00
- **Authors**: Xiaogang Wang, Bin Zhou, Yahao Shi, Xiaowu Chen, Qinping Zhao, Kai Xu
- **Comment**: CVPR 2019 (oral presentation); Corresponding author: Kai Xu
  (kevin.kai.xu@gmail.com); Project page:
  www.kevinkaixu.net/projects/shape2motion.html
- **Journal**: None
- **Summary**: For the task of mobility analysis of 3D shapes, we propose joint analysis for simultaneous motion part segmentation and motion attribute estimation, taking a single 3D model as input. The problem is significantly different from those tackled in the existing works which assume the availability of either a pre-existing shape segmentation or multiple 3D models in different motion states. To that end, we develop Shape2Motion which takes a single 3D point cloud as input, and jointly computes a mobility-oriented segmentation and the associated motion attributes. Shape2Motion is comprised of two deep neural networks designed for mobility proposal generation and mobility optimization, respectively. The key contribution of these networks is the novel motion-driven features and losses used in both motion part segmentation and motion attribute estimation. This is based on the observation that the movement of a functional part preserves the shape structure. We evaluate Shape2Motion with a newly proposed benchmark for mobility analysis of 3D shapes. Results demonstrate that our method achieves the state-of-the-art performance both in terms of motion part segmentation and motion attribute estimation.



### Learning-Based Cost Functions for 3D and 4D Multi-Surface Multi-Object Segmentation of Knee MRI: Data from the Osteoarthritis Initiative
- **Arxiv ID**: http://arxiv.org/abs/1903.03927v1
- **DOI**: 10.1109/TMI.2017.2781541
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.03927v1)
- **Published**: 2019-03-10 05:48:53+00:00
- **Updated**: 2019-03-10 05:48:53+00:00
- **Authors**: Satyananda Kashyap, Honghai Zhang, Karan Rao, Milan Sonka
- **Comment**: IEEE Transactions in Medical Imaging, 11 pages
- **Journal**: Published in: IEEE Transactions on Medical Imaging ( Volume: 37 ,
  Issue: 5 , May 2018 )
- **Summary**: A fully automated knee MRI segmentation method to study osteoarthritis (OA) was developed using a novel hierarchical set of random forests (RF) classifiers to learn the appearance of cartilage regions and their boundaries. A neighborhood approximation forest is used first to provide contextual feature to the second-level RF classifier that also considers local features and produces location-specific costs for the layered optimal graph image segmentation of multiple objects and surfaces (LOGISMOS) framework. Double echo steady state (DESS) MRIs used in this work originated from the Osteoarthritis Initiative (OAI) study. Trained on 34 MRIs with varying degrees of OA, the performance of the learning-based method tested on 108 MRIs showed a significant reduction in segmentation errors (\emph{p}$<$0.05) compared with the conventional gradient-based and single-stage RF-learned costs. The 3D LOGISMOS was extended to longitudinal-3D (4D) to simultaneously segment multiple follow-up visits of the same patient. As such, data from all time-points of the temporal sequence contribute information to a single optimal solution that utilizes both spatial 3D and temporal contexts. 4D LOGISMOS validation on 108 MRIs from baseline and 12 month follow-up scans of 54 patients showed a significant reduction in segmentation errors (\emph{p}$<$0.01) compared to 3D. Finally, the potential of 4D LOGISMOS was further explored on the same 54 patients using 5 annual follow-up scans demonstrating a significant improvement of measuring cartilage thickness (\emph{p}$<$0.01) compared to the sequential 3D approach.



### Automated Segmentation of Knee MRI Using Hierarchical Classifiers and Just Enough Interaction Based Learning: Data from Osteoarthritis Initiative
- **Arxiv ID**: http://arxiv.org/abs/1903.03929v1
- **DOI**: 10.1007/978-3-319-46723-8_40
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.03929v1)
- **Published**: 2019-03-10 06:01:23+00:00
- **Updated**: 2019-03-10 06:01:23+00:00
- **Authors**: Satyananda Kashyap, Ipek Oguz, Honghai Zhang, Milan Sonka
- **Comment**: KEYWORDS: Graph based segmentation; Just enough interaction;
  LOGISMOS; Neighborhood approximation forests; Osteoarthritis; Random forest
  classifier; knee MRI PMID: 28626842 PMCID: PMC5471813
- **Journal**: Med Image Comput Comput Assist Interv. 2016 Oct;9901:344-351. doi:
  10.1007/978-3-319-46723-8_40. Epub 2016 Oct 2
- **Summary**: We present a fully automated learning-based approach for segmenting knee cartilage in the presence of osteoarthritis (OA). The algorithm employs a hierarchical set of two random forest classifiers. The first is a neighborhood approximation forest, the output probability map of which is utilized as a feature set for the second random forest (RF) classifier. The output probabilities of the hierarchical approach are used as cost functions in a Layered Optimal Graph Segmentation of Multiple Objects and Surfaces (LOGISMOS). In this work, we highlight a novel post-processing interaction called just-enough interaction (JEI) which enables quick and accurate generation of a large set of training examples. Disjoint sets of 15 and 13 subjects were used for training and tested on another disjoint set of 53 knee datasets. All images were acquired using a double echo steady state (DESS) MRI sequence and are from the osteoarthritis initiative (OAI) database. Segmentation performance using the learning-based cost function showed significant reduction in segmentation errors ($p< 0.05$) in comparison with conventional gradient-based cost functions.



### Rolling-Shutter-Aware Differential SfM and Image Rectification
- **Arxiv ID**: http://arxiv.org/abs/1903.03943v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.03943v2)
- **Published**: 2019-03-10 07:29:25+00:00
- **Updated**: 2019-08-04 03:34:59+00:00
- **Authors**: Bingbing Zhuang, Loong-Fah Cheong, Gim Hee Lee
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we develop a modified differential Structure from Motion (SfM) algorithm that can estimate relative pose from two consecutive frames despite of Rolling Shutter (RS) artifacts. In particular, we show that under constant velocity assumption, the errors induced by the rolling shutter effect can be easily rectified by a linear scaling operation on each optical flow. We further propose a 9-point algorithm to recover the relative pose of a rolling shutter camera that undergoes constant acceleration motion. We demonstrate that the dense depth maps recovered from the relative pose of the RS camera can be used in a RS-aware warping for image rectification to recover high-quality Global Shutter (GS) images. Experiments on both synthetic and real RS images show that our RS-aware differential SfM algorithm produces more accurate results on relative pose estimation and 3D reconstruction from images distorted by RS effect compared to standard SfM algorithms that assume a GS camera model. We also demonstrate that our RS-aware warping for image rectification method outperforms state-of-the-art commercial software products, i.e. Adobe After Effects and Apple Imovie, at removing RS artifacts.



### Domain Randomization for Active Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1903.03953v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.03953v1)
- **Published**: 2019-03-10 08:33:14+00:00
- **Updated**: 2019-03-10 08:33:14+00:00
- **Authors**: Xinyi Ren, Jianlan Luo, Eugen Solowjow, Juan Aparicio Ojea, Abhishek Gupta, Aviv Tamar, Pieter Abbeel
- **Comment**: Accepted at International Conference on Robotics and Automation
  (ICRA) 2019
- **Journal**: None
- **Summary**: Accurate state estimation is a fundamental component of robotic control. In robotic manipulation tasks, as is our focus in this work, state estimation is essential for identifying the positions of objects in the scene, forming the basis of the manipulation plan. However, pose estimation typically requires expensive 3D cameras or additional instrumentation such as fiducial markers to perform accurately. Recently, Tobin et al.~introduced an approach to pose estimation based on domain randomization, where a neural network is trained to predict pose directly from a 2D image of the scene. The network is trained on computer-generated images with a high variation in textures and lighting, thereby generalizing to real-world images. In this work, we investigate how to improve the accuracy of domain randomization based pose estimation. Our main idea is that active perception -- moving the robot to get a better estimate of pose -- can be trained in simulation and transferred to real using domain randomization. In our approach, the robot trains in a domain-randomized simulation how to estimate pose from a \emph{sequence} of images. We show that our approach can significantly improve the accuracy of standard pose estimation in several scenarios: when the robot holding an object moves, when reference objects are moved in the scene, or when the camera is moved around the object.



### Deep Robust Subjective Visual Property Prediction in Crowdsourcing
- **Arxiv ID**: http://arxiv.org/abs/1903.03956v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.03956v1)
- **Published**: 2019-03-10 09:29:53+00:00
- **Updated**: 2019-03-10 09:29:53+00:00
- **Authors**: Qianqian Xu, Zhiyong Yang, Yangbangyan Jiang, Xiaochun Cao, Qingming Huang, Yuan Yao
- **Comment**: 9 pages, accepted by CVPR 2019 (Poster)
- **Journal**: None
- **Summary**: The problem of estimating subjective visual properties (SVP) of images (e.g., Shoes A is more comfortable than B) is gaining rising attention. Due to its highly subjective nature, different annotators often exhibit different interpretations of scales when adopting absolute value tests. Therefore, recent investigations turn to collect pairwise comparisons via crowdsourcing platforms. However, crowdsourcing data usually contains outliers. For this purpose, it is desired to develop a robust model for learning SVP from crowdsourced noisy annotations. In this paper, we construct a deep SVP prediction model which not only leads to better detection of annotation outliers but also enables learning with extremely sparse annotations. Specifically, we construct a comparison multi-graph based on the collected annotations, where different labeling results correspond to edges with different directions between two vertexes. Then, we propose a generalized deep probabilistic framework which consists of an SVP prediction module and an outlier modeling module that work collaboratively and are optimized jointly. Extensive experiments on various benchmark datasets demonstrate that our new approach guarantees promising results.



### Uncertainty Propagation in Deep Neural Network Using Active Subspace
- **Arxiv ID**: http://arxiv.org/abs/1903.03989v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1903.03989v2)
- **Published**: 2019-03-10 13:38:43+00:00
- **Updated**: 2020-01-11 22:34:28+00:00
- **Authors**: Weiqi Ji, Zhuyin Ren, Chung K. Law
- **Comment**: Add link to github repo
- **Journal**: None
- **Summary**: The inputs of deep neural network (DNN) from real-world data usually come with uncertainties. Yet, it is challenging to propagate the uncertainty in the input features to the DNN predictions at a low computational cost. This work employs a gradient-based subspace method and response surface technique to accelerate the uncertainty propagation in DNN. Specifically, the active subspace method is employed to identify the most important subspace in the input features using the gradient of the DNN output to the inputs. Then the response surface within that low-dimensional subspace can be efficiently built, and the uncertainty of the prediction can be acquired by evaluating the computationally cheap response surface instead of the DNN models. In addition, the subspace can help explain the adversarial examples. The approach is demonstrated in MNIST datasets with a convolutional neural network. Code is available at: https://github.com/jiweiqi/nnsubspace.



### Deep Reinforcement Learning of Volume-guided Progressive View Inpainting for 3D Point Scene Completion from a Single Depth Image
- **Arxiv ID**: http://arxiv.org/abs/1903.04019v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.04019v2)
- **Published**: 2019-03-10 16:25:03+00:00
- **Updated**: 2019-03-12 03:23:49+00:00
- **Authors**: Xiaoguang Han, Zhaoxuan Zhang, Dong Du, Mingdai Yang, Jingming Yu, Pan Pan, Xin Yang, Ligang Liu, Zixiang Xiong, Shuguang Cui
- **Comment**: Accepted as CVPR 2019 Oral
- **Journal**: None
- **Summary**: We present a deep reinforcement learning method of progressive view inpainting for 3D point scene completion under volume guidance, achieving high-quality scene reconstruction from only a single depth image with severe occlusion. Our approach is end-to-end, consisting of three modules: 3D scene volume reconstruction, 2D depth map inpainting, and multi-view selection for completion. Given a single depth image, our method first goes through the 3D volume branch to obtain a volumetric scene reconstruction as a guide to the next view inpainting step, which attempts to make up the missing information; the third step involves projecting the volume under the same view of the input, concatenating them to complete the current view depth, and integrating all depth into the point cloud. Since the occluded areas are unavailable, we resort to a deep Q-Network to glance around and pick the next best view for large hole completion progressively until a scene is adequately reconstructed while guaranteeing validity. All steps are learned jointly to achieve robust and consistent results. We perform qualitative and quantitative evaluations with extensive experiments on the SUNCG data, obtaining better results than the state of the art.



### Group-wise Correlation Stereo Network
- **Arxiv ID**: http://arxiv.org/abs/1903.04025v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.04025v1)
- **Published**: 2019-03-10 17:34:54+00:00
- **Updated**: 2019-03-10 17:34:54+00:00
- **Authors**: Xiaoyang Guo, Kai Yang, Wukui Yang, Xiaogang Wang, Hongsheng Li
- **Comment**: accepted to CVPR 2019
- **Journal**: None
- **Summary**: Stereo matching estimates the disparity between a rectified image pair, which is of great importance to depth sensing, autonomous driving, and other related tasks. Previous works built cost volumes with cross-correlation or concatenation of left and right features across all disparity levels, and then a 2D or 3D convolutional neural network is utilized to regress the disparity maps. In this paper, we propose to construct the cost volume by group-wise correlation. The left features and the right features are divided into groups along the channel dimension, and correlation maps are computed among each group to obtain multiple matching cost proposals, which are then packed into a cost volume. Group-wise correlation provides efficient representations for measuring feature similarities and will not lose too much information like full correlation. It also preserves better performance when reducing parameters compared with previous methods. The 3D stacked hourglass network proposed in previous works is improved to boost the performance and decrease the inference computational cost. Experiment results show that our method outperforms previous methods on Scene Flow, KITTI 2012, and KITTI 2015 datasets. The code is available at https://github.com/xy-guo/GwcNet



### Just-Enough Interaction Approach to Knee MRI Segmentation: Data from the Osteoarthritis Initiative
- **Arxiv ID**: http://arxiv.org/abs/1903.04027v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1903.04027v1)
- **Published**: 2019-03-10 17:55:47+00:00
- **Updated**: 2019-03-10 17:55:47+00:00
- **Authors**: Satyananda Kashyap, Honghai Zhang, Milan Sonka
- **Comment**: Proceedings of the 3rd International Workshop on Interactive Medical
  Image Computing (IMIC), Held in Conjunction with MICCAI, 2016
- **Journal**: None
- **Summary**: State-of-the-art automated segmentation algorithms are not 100\% accurate especially when segmenting difficult to interpret datasets like those with severe osteoarthritis (OA). We present a novel interactive method called just-enough interaction (JEI), which adds a fast correction step to the automated layered optimal graph segmentation of multiple objects and surfaces (LOGISMOS). After LOGISMOS segmentation in knee MRI, the JEI user interaction does not modify boundary surfaces of the bones and cartilages directly. Local costs of underlying graph nodes are modified instead and the graph is re-optimized, providing globally optimal corrected results. Significant performance improvement ($p \ll 0.001$) was observed when comparing JEI-corrected results to the automated. The algorithm was extended from 3D JEI to longitudinal multi-3D (4D) JEI allowing simultaneous visualization and interaction of multiple-time points of the same patient.



### Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1903.04064v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1903.04064v1)
- **Published**: 2019-03-10 21:56:45+00:00
- **Updated**: 2019-03-10 21:56:45+00:00
- **Authors**: Chen-Yu Lee, Tanmay Batra, Mohammad Haris Baig, Daniel Ulbricht
- **Comment**: Accepted at CVPR 2019
- **Journal**: None
- **Summary**: In this work, we connect two distinct concepts for unsupervised domain adaptation: feature distribution alignment between domains by utilizing the task-specific decision boundary and the Wasserstein metric. Our proposed sliced Wasserstein discrepancy (SWD) is designed to capture the natural notion of dissimilarity between the outputs of task-specific classifiers. It provides a geometrically meaningful guidance to detect target samples that are far from the support of the source and enables efficient distribution alignment in an end-to-end trainable fashion. In the experiments, we validate the effectiveness and genericness of our method on digit and sign recognition, image classification, semantic segmentation, and object detection.



