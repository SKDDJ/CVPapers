# Arxiv Papers in cs.CV on 2019-02-22
### On the Sensitivity of Adversarial Robustness to Input Data Distributions
- **Arxiv ID**: http://arxiv.org/abs/1902.08336v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1902.08336v1)
- **Published**: 2019-02-22 02:03:17+00:00
- **Updated**: 2019-02-22 02:03:17+00:00
- **Authors**: Gavin Weiguang Ding, Kry Yik Chau Lui, Xiaomeng Jin, Luyu Wang, Ruitong Huang
- **Comment**: ICLR 2019, Seventh International Conference on Learning
  Representations
- **Journal**: None
- **Summary**: Neural networks are vulnerable to small adversarial perturbations. Existing literature largely focused on understanding and mitigating the vulnerability of learned models. In this paper, we demonstrate an intriguing phenomenon about the most popular robust training method in the literature, adversarial training: Adversarial robustness, unlike clean accuracy, is sensitive to the input data distribution. Even a semantics-preserving transformations on the input data distribution can cause a significantly different robustness for the adversarial trained model that is both trained and evaluated on the new distribution. Our discovery of such sensitivity on data distribution is based on a study which disentangles the behaviors of clean accuracy and robust accuracy of the Bayes classifier. Empirical investigations further confirm our finding. We construct semantically-identical variants for MNIST and CIFAR10 respectively, and show that standardly trained models achieve comparable clean accuracies on them, but adversarially trained models achieve significantly different robustness accuracies. This counter-intuitive phenomenon indicates that input data distribution alone can affect the adversarial robustness of trained neural networks, not necessarily the tasks themselves. Lastly, we discuss the practical implications on evaluating adversarial robustness, and make initial attempts to understand this complex phenomenon.



### A laboratory-created dataset with ground-truth for hyperspectral unmixing evaluation
- **Arxiv ID**: http://arxiv.org/abs/1902.08347v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.08347v1)
- **Published**: 2019-02-22 02:51:12+00:00
- **Updated**: 2019-02-22 02:51:12+00:00
- **Authors**: Min Zhao, Jie Chen, Zhe He
- **Comment**: 13 pages, 13 figures, submitted for publication
- **Journal**: None
- **Summary**: Spectral unmixing is an important and challenging problem in hyperspectral data processing. This topic has been extensively studied and a variety of unmixing algorithms have been proposed in the literature. However, the lack of publicly available dataset with ground-truth makes it difficult to evaluate and compare the performance of unmixing algorithms in a quantitative and objective manner. Most of the existing works rely on the use of numerical synthetic data and an intuitive inspection of the results of real data. To alleviate this dilemma, in this study, we design several experimental scenes in our laboratory, including printed checkerboards, mixed quartz sands, and reflection with a vertical board. A dataset is then created by imaging these scenes with the hyperspectral camera in our laboratory, providing 36 mixtures with more than 130, 000 pixels with 256 wavelength bands ranging from 400nm to 1000nm. The experimental settings are strictly controlled so that pure material spectral signatures and material compositions are known. To the best of our knowledge, this dataset is the first publicly available dataset created in a systematic manner with ground-truth for spectral unmixing. Some typical linear and nonlinear unmixing algorithms are also tested with this dataset and lead to meaningful results.



### Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation
- **Arxiv ID**: http://arxiv.org/abs/1902.08355v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.08355v1)
- **Published**: 2019-02-22 03:46:53+00:00
- **Updated**: 2019-02-22 03:46:53+00:00
- **Authors**: Sang-Woo Lee, Tong Gao, Sohee Yang, Jaejun Yoo, Jung-Woo Ha
- **Comment**: Accepted for ICLR 2019. Camera ready version. Our code is publically
  available: https://github.com/naver/aqm-plus
- **Journal**: None
- **Summary**: Answerer in Questioner's Mind (AQM) is an information-theoretic framework that has been recently proposed for task-oriented dialog systems. AQM benefits from asking a question that would maximize the information gain when it is asked. However, due to its intrinsic nature of explicitly calculating the information gain, AQM has a limitation when the solution space is very large. To address this, we propose AQM+ that can deal with a large-scale problem and ask a question that is more coherent to the current context of the dialog. We evaluate our method on GuessWhich, a challenging task-oriented visual dialog problem, where the number of candidate classes is near 10K. Our experimental results and ablation studies show that AQM+ outperforms the state-of-the-art models by a remarkable margin with a reasonable approximation. In particular, the proposed AQM+ reduces more than 60% of error as the dialog proceeds, while the comparative algorithms diminish the error by less than 6%. Based on our results, we argue that AQM+ is a general task-oriented dialog algorithm that can be applied for non-yes-or-no responses.



### Deep Learning in Cardiology
- **Arxiv ID**: http://arxiv.org/abs/1902.11122v3
- **DOI**: 10.1109/RBME.2018.2885714
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.11122v3)
- **Published**: 2019-02-22 10:09:11+00:00
- **Updated**: 2021-02-03 16:43:32+00:00
- **Authors**: Paschalis Bizopoulos, Dimitrios Koutsouris
- **Comment**: 27 pages, 2 figures, 10 tables
- **Journal**: IEEE Reviews in Biomedical Engineering 12 (2019): 168-193
- **Summary**: The medical field is creating large amount of data that physicians are unable to decipher and use efficiently. Moreover, rule-based expert systems are inefficient in solving complicated medical tasks or for creating insights using big data. Deep learning has emerged as a more accurate and effective technology in a wide range of medical problems such as diagnosis, prediction and intervention. Deep learning is a representation learning method that consists of layers that transform the data non-linearly, thus, revealing hierarchical relationships and structures. In this review we survey deep learning application papers that use structured data, signal and imaging modalities from cardiology. We discuss the advantages and limitations of applying deep learning in cardiology that also apply in medicine in general, while proposing certain directions as the most viable for clinical use.



### The Multi-Lane Capsule Network (MLCN)
- **Arxiv ID**: http://arxiv.org/abs/1902.08431v1
- **DOI**: 10.1109/LSP.2019.2915661
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1902.08431v1)
- **Published**: 2019-02-22 10:44:55+00:00
- **Updated**: 2019-02-22 10:44:55+00:00
- **Authors**: Vanderson Martins do Rosario, Edson Borin, Mauricio Breternitz Jr
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce Multi-Lane Capsule Networks (MLCN), which are a separable and resource efficient organization of Capsule Networks (CapsNet) that allows parallel processing, while achieving high accuracy at reduced cost. A MLCN is composed of a number of (distinct) parallel lanes, each contributing to a dimension of the result, trained using the routing-by-agreement organization of CapsNet. Our results indicate similar accuracy with a much reduced cost in number of parameters for the Fashion-MNIST and Cifar10 datsets. They also indicate that the MLCN outperforms the original CapsNet when using a proposed novel configuration for the lanes. MLCN also has faster training and inference times, being more than two-fold faster than the original CapsNet in the same accelerator.



### Effective 3D Humerus and Scapula Extraction using Low-contrast and High-shape-variability MR Data
- **Arxiv ID**: http://arxiv.org/abs/1902.08527v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.08527v1)
- **Published**: 2019-02-22 15:16:25+00:00
- **Updated**: 2019-02-22 15:16:25+00:00
- **Authors**: Xiaoxiao He, Chaowei Tan, Yuting Qiao, Virak Tan, Dimitris Metaxas, Kang Li
- **Comment**: None
- **Journal**: None
- **Summary**: For the initial shoulder preoperative diagnosis, it is essential to obtain a three-dimensional (3D) bone mask from medical images, e.g., magnetic resonance (MR). However, obtaining high-resolution and dense medical scans is both costly and time-consuming. In addition, the imaging parameters for each 3D scan may vary from time to time and thus increase the variance between images. Therefore, it is practical to consider the bone extraction on low-resolution data which may influence imaging contrast and make the segmentation work difficult. In this paper, we present a joint segmentation for the humerus and scapula bones on a small dataset with low-contrast and high-shape-variability 3D MR images. The proposed network has a deep end-to-end architecture to obtain the initial 3D bone masks. Because the existing scarce and inaccurate human-labeled ground truth, we design a self-reinforced learning strategy to increase performance. By comparing with the non-reinforced segmentation and a classical multi-atlas method with joint label fusion, the proposed approach obtains better results.



### Image Aesthetics Assessment Using Composite Features from off-the-Shelf Deep Models
- **Arxiv ID**: http://arxiv.org/abs/1902.08546v1
- **DOI**: 10.1109/ICIP.2018.8451133
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.08546v1)
- **Published**: 2019-02-22 16:14:53+00:00
- **Updated**: 2019-02-22 16:14:53+00:00
- **Authors**: Xin Fu, Jia Yan, Cien Fan
- **Comment**: Accepted by ICIP 2018
- **Journal**: None
- **Summary**: Deep convolutional neural networks have recently achieved great success on image aesthetics assessment task. In this paper, we propose an efficient method which takes the global, local and scene-aware information of images into consideration and exploits the composite features extracted from corresponding pretrained deep learning models to classify the derived features with support vector machine. Contrary to popular methods that require fine-tuning or training a new model from scratch, our training-free method directly takes the deep features generated by off-the-shelf models for image classification and scene recognition. Also, we analyzed the factors that could influence the performance from two aspects: the architecture of the deep neural network and the contribution of local and scene-aware information. It turns out that deep residual network could produce more aesthetics-aware image representation and composite features lead to the improvement of overall performance. Experiments on common large-scale aesthetics assessment benchmarks demonstrate that our method outperforms the state-of-the-art results in photo aesthetics assessment.



### Towards end-to-end pulsed eddy current classification and regression with CNN
- **Arxiv ID**: http://arxiv.org/abs/1902.08553v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.08553v1)
- **Published**: 2019-02-22 16:39:20+00:00
- **Updated**: 2019-02-22 16:39:20+00:00
- **Authors**: Xin Fu, Chengkai Zhang, Xiang Peng, Lihua Jian, Zheng Liu
- **Comment**: Accepted by IEEE I2MTC 2019
- **Journal**: None
- **Summary**: Pulsed eddy current (PEC) is an effective electromagnetic non-destructive inspection (NDI) technique for metal materials, which has already been widely adopted in detecting cracking and corrosion in some multi-layer structures. Automatically inspecting the defects in these structures would be conducive to further analysis and treatment of them. In this paper, we propose an effective end-to-end model using convolutional neural networks (CNN) to learn effective features from PEC data. Specifically, we construct a multi-task generic model, based on 1D CNN, to predict both the class and depth of flaws simultaneously. Extensive experiments demonstrate our model is capable of handling both classification and regression tasks on PEC data. Our proposed model obtains higher accuracy and lower error compared to other standard methods.



### ParticleNet: Jet Tagging via Particle Clouds
- **Arxiv ID**: http://arxiv.org/abs/1902.08570v3
- **DOI**: 10.1103/PhysRevD.101.056019
- **Categories**: **hep-ph**, cs.CV, hep-ex
- **Links**: [PDF](http://arxiv.org/pdf/1902.08570v3)
- **Published**: 2019-02-22 17:26:39+00:00
- **Updated**: 2020-03-30 15:57:41+00:00
- **Authors**: Huilin Qu, Loukas Gouskos
- **Comment**: 11 pages, 4 figures; v3: updated to match the version published in
  PRD; Code available at https://github.com/hqucms/ParticleNet
- **Journal**: Phys. Rev. D 101, 056019 (2020)
- **Summary**: How to represent a jet is at the core of machine learning on jet physics. Inspired by the notion of point clouds, we propose a new approach that considers a jet as an unordered set of its constituent particles, effectively a "particle cloud". Such a particle cloud representation of jets is efficient in incorporating raw information of jets and also explicitly respects the permutation symmetry. Based on the particle cloud representation, we propose ParticleNet, a customized neural network architecture using Dynamic Graph Convolutional Neural Network for jet tagging problems. The ParticleNet architecture achieves state-of-the-art performance on two representative jet tagging benchmarks and is improved significantly over existing methods.



### Discriminative Pattern Mining for Breast Cancer Histopathology Image Classification via Fully Convolutional Autoencoder
- **Arxiv ID**: http://arxiv.org/abs/1902.08670v3
- **DOI**: 10.1109/ACCESS.2019.2904245
- **Categories**: **cs.CV**, cs.LG, eess.IV, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1902.08670v3)
- **Published**: 2019-02-22 21:22:52+00:00
- **Updated**: 2020-05-05 15:35:08+00:00
- **Authors**: Xingyu Li, Marko Radulovic, Ksenija Kanjer, Konstantinos N. Plataniotis
- **Comment**: None
- **Journal**: IEEE Access, vol. 7, 2019
- **Summary**: Accurate diagnosis of breast cancer in histopathology images is challenging due to the heterogeneity of cancer cell growth as well as of a variety of benign breast tissue proliferative lesions. In this paper, we propose a practical and self-interpretable invasive cancer diagnosis solution. With minimum annotation information, the proposed method mines contrast patterns between normal and malignant images in unsupervised manner and generates a probability map of abnormalities to verify its reasoning. Particularly, a fully convolutional autoencoder is used to learn the dominant structural patterns among normal image patches. Patches that do not share the characteristics of this normal population are detected and analyzed by one-class support vector machine and 1-layer neural network. We apply the proposed method to a public breast cancer image set. Our results, in consultation with a senior pathologist, demonstrate that the proposed method outperforms existing methods. The obtained probability map could benefit the pathology practice by providing visualized verification data and potentially leads to a better understanding of data-driven diagnosis solutions.



