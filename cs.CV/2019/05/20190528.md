# Arxiv Papers in cs.CV on 2019-05-28
### Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1905.13540v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.13540v1)
- **Published**: 2019-05-28 01:46:20+00:00
- **Updated**: 2019-05-28 01:46:20+00:00
- **Authors**: Junyeong Kim, Minuk Ma, Kyungsu Kim, Sungjin Kim, Chang D. Yoo
- **Comment**: Accepted to IJCNN2019, oral
- **Journal**: None
- **Summary**: This paper proposes a method to gain extra supervision via multi-task learning for multi-modal video question answering. Multi-modal video question answering is an important task that aims at the joint understanding of vision and language. However, establishing large scale dataset for multi-modal video question answering is expensive and the existing benchmarks are relatively small to provide sufficient supervision. To overcome this challenge, this paper proposes a multi-task learning method which is composed of three main components: (1) multi-modal video question answering network that answers the question based on the both video and subtitle feature, (2) temporal retrieval network that predicts the time in the video clip where the question was generated from and (3) modality alignment network that solves metric learning problem to find correct association of video and subtitle modalities. By simultaneously solving related auxiliary tasks with hierarchically shared intermediate layers, the extra synergistic supervisions are provided. Motivated by curriculum learning, multi task ratio scheduling is proposed to learn easier task earlier to set inductive bias at the beginning of the training. The experiments on publicly available dataset TVQA shows state-of-the-art results, and ablation studies are conducted to prove the statistical validity.



### Case-Based Histopathological Malignancy Diagnosis using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11567v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11567v1)
- **Published**: 2019-05-28 01:49:34+00:00
- **Updated**: 2019-05-28 01:49:34+00:00
- **Authors**: Qicheng Lao, Thomas Fevens
- **Comment**: None
- **Journal**: British Machine Vision Conference (BMVC) 2017
- **Summary**: In practice, histopathological diagnosis of tumor malignancy often requires a human expert to scan through histopathological images at multiple magnification levels, after which a final diagnosis can be accurately determined. However, previous research on such classification tasks using convolutional neural networks primarily determine a diagnosis for a single magnification level. In this paper, we propose a case-based approach using deep residual neural networks for histopathological malignancy diagnosis, where a case is defined as a sequence of images from the patient at all available levels of magnification. Effectively, through mimicking what a human expert would actually do, our approach makes a diagnosis decision based on features learned in combination at multiple magnification levels. Our results show that the case-based approach achieves better performance than the state-of-the-art methods when evaluated on BreaKHis, a histopathological image dataset for breast tumors.



### JGAN: A Joint Formulation of GAN for Synthesizing Images and Labels
- **Arxiv ID**: http://arxiv.org/abs/1905.11574v5
- **DOI**: 10.1109/ACCESS.2020.3031292
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11574v5)
- **Published**: 2019-05-28 02:19:42+00:00
- **Updated**: 2020-10-21 01:17:36+00:00
- **Authors**: Minje Park
- **Comment**: To be published in IEEE Access
- **Journal**: None
- **Summary**: Image generation with explicit condition or label generally works better than unconditional methods. In modern GAN frameworks, both generator and discriminator are formulated to model the conditional distribution of images given with labels. In this paper, we provide an alternative formulation of GAN which models the joint distribution of images and labels. There are two advantages in this joint formulation over conditional approaches. The first advantage is that the joint formulation is more robust to label noises if it's properly modeled. This alleviates the burden of making noise-free labels and allows the use of weakly-supervised labels in image generation. The second is that we can use any kinds of weak labels or image features that have correlations with the original image data to enhance unconditional image generation. We will show the effectiveness of our joint formulation on CIFAR10, CIFAR100, and STL dataset with the state-of-the-art GAN architecture.



### Improving Action Localization by Progressive Cross-stream Cooperation
- **Arxiv ID**: http://arxiv.org/abs/1905.11575v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11575v1)
- **Published**: 2019-05-28 02:29:12+00:00
- **Updated**: 2019-05-28 02:29:12+00:00
- **Authors**: Rui Su, Wanli Ouyang, Luping Zhou, Dong Xu
- **Comment**: CVPR2019
- **Journal**: None
- **Summary**: Spatio-temporal action localization consists of three levels of tasks: spatial localization, action classification, and temporal segmentation. In this work, we propose a new Progressive Cross-stream Cooperation (PCSC) framework to use both region proposals and features from one stream (i.e. Flow/RGB) to help another stream (i.e. RGB/Flow) to iteratively improve action localization results and generate better bounding boxes in an iterative fashion. Specifically, we first generate a larger set of region proposals by combining the latest region proposals from both streams, from which we can readily obtain a larger set of labelled training samples to help learn better action detection models. Second, we also propose a new message passing approach to pass information from one stream to another stream in order to learn better representations, which also leads to better action detection models. As a result, our iterative framework progressively improves action localization results at the frame level. To improve action localization results at the video level, we additionally propose a new strategy to train class-specific actionness detectors for better temporal segmentation, which can be readily learnt by focusing on "confusing" samples from the same action class. Comprehensive experiments on two benchmark datasets UCF-101-24 and J-HMDB demonstrate the effectiveness of our newly proposed approaches for spatio-temporal action localization in realistic scenarios.



### Local Label Propagation for Large-Scale Semi-Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.11581v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11581v1)
- **Published**: 2019-05-28 02:57:42+00:00
- **Updated**: 2019-05-28 02:57:42+00:00
- **Authors**: Chengxu Zhuang, Xuehao Ding, Divyanshu Murli, Daniel Yamins
- **Comment**: None
- **Journal**: None
- **Summary**: A significant issue in training deep neural networks to solve supervised learning tasks is the need for large numbers of labelled datapoints. The goal of semi-supervised learning is to leverage ubiquitous unlabelled data, together with small quantities of labelled data, to achieve high task performance. Though substantial recent progress has been made in developing semi-supervised algorithms that are effective for comparatively small datasets, many of these techniques do not scale readily to the large (unlaballed) datasets characteristic of real-world applications. In this paper we introduce a novel approach to scalable semi-supervised learning, called Local Label Propagation (LLP). Extending ideas from recent work on unsupervised embedding learning, LLP first embeds datapoints, labelled and otherwise, in a common latent space using a deep neural network. It then propagates pseudolabels from known to unknown datapoints in a manner that depends on the local geometry of the embedding, taking into account both inter-point distance and local data density as a weighting on propagation likelihood. The parameters of the deep embedding are then trained to simultaneously maximize pseudolabel categorization performance as well as a metric of the clustering of datapoints within each psuedo-label group, iteratively alternating stages of network training and label propagation. We illustrate the utility of the LLP method on the ImageNet dataset, achieving results that outperform previous state-of-the-art scalable semi-supervised learning algorithms by large margins, consistently across a wide variety of training regimes. We also show that the feature representation learned with LLP transfers well to scene recognition in the Places 205 dataset.



### Adaptive Lighting for Data-Driven Non-Line-of-Sight 3D Localization and Object Identification
- **Arxiv ID**: http://arxiv.org/abs/1905.11595v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11595v2)
- **Published**: 2019-05-28 03:40:19+00:00
- **Updated**: 2019-07-26 23:57:04+00:00
- **Authors**: Sreenithy Chandran, Suren Jayasuriya
- **Comment**: None
- **Journal**: None
- **Summary**: Non-line-of-sight (NLOS) imaging of objects not visible to either the camera or illumination source is a challenging task with vital applications including surveillance and robotics. Recent NLOS reconstruction advances have been achieved using time-resolved measurements which requires expensive and specialized detectors and laser sources. In contrast, we propose a data-driven approach for NLOS 3D localization and object identification requiring only a conventional camera and projector. To generalize to complex line-of-sight (LOS) scenes with non-planar surfaces and occlusions, we introduce an adaptive lighting algorithm. This algorithm, based on radiosity, identifies and illuminates scene patches in the LOS which most contribute to the NLOS light paths, and can factor in system power constraints. We achieve an average identification of 87.1% object identification for four classes of objects, and average localization of the NLOS object's centroid with a mean-squared error (MSE) of 1.97 cm in the occluded region for real data taken from a hardware prototype. These results demonstrate the advantage of combining the physics of light transport with active illumination for data-driven NLOS imaging.



### Contextual Translation Embedding for Visual Relationship Detection and Scene Graph Generation
- **Arxiv ID**: http://arxiv.org/abs/1905.11624v3
- **DOI**: 10.1109/TPAMI.2020.2992222
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11624v3)
- **Published**: 2019-05-28 06:10:02+00:00
- **Updated**: 2020-02-06 06:53:33+00:00
- **Authors**: Zih-Siou Hung, Arun Mallya, Svetlana Lazebnik
- **Comment**: None
- **Journal**: None
- **Summary**: Relations amongst entities play a central role in image understanding. Due to the complexity of modeling (subject, predicate, object) relation triplets, it is crucial to develop a method that can not only recognize seen relations, but also generalize to unseen cases. Inspired by a previously proposed visual translation embedding model, or VTransE, we propose a context-augmented translation embedding model that can capture both common and rare relations. The previous VTransE model maps entities and predicates into a low-dimensional embedding vector space where the predicate is interpreted as a translation vector between the embedded features of the bounding box regions of the subject and the object. Our model additionally incorporates the contextual information captured by the bounding box of the union of the subject and the object, and learns the embeddings guided by the constraint predicate $\approx$ union (subject, object) $-$ subject $-$ object. In a comprehensive evaluation on multiple challenging benchmarks, our approach outperforms previous translation-based models and comes close to or exceeds the state of the art across a range of settings, from small-scale to large-scale datasets, from common to previously unseen relations. It also achieves promising results for the recently introduced task of scene graph generation.



### DDPNAS: Efficient Neural Architecture Search via Dynamic Distribution Pruning
- **Arxiv ID**: http://arxiv.org/abs/1905.13543v3
- **DOI**: 10.1007/s11263-023-01753-6
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.13543v3)
- **Published**: 2019-05-28 06:35:52+00:00
- **Updated**: 2023-03-10 18:30:42+00:00
- **Authors**: Xiawu Zheng, Chenyi Yang, Shaokun Zhang, Yan Wang, Baochang Zhang, Yongjian Wu, Yunsheng Wu, Ling Shao, Rongrong Ji
- **Comment**: A update version of this work. 19 pages
- **Journal**: International Journal of Computer Vision, 1-16 (2023)
- **Summary**: Neural Architecture Search (NAS) has demonstrated state-of-the-art performance on various computer vision tasks. Despite the superior performance achieved, the efficiency and generality of existing methods are highly valued due to their high computational complexity and low generality. In this paper, we propose an efficient and unified NAS framework termed DDPNAS via dynamic distribution pruning, facilitating a theoretical bound on accuracy and efficiency. In particular, we first sample architectures from a joint categorical distribution. Then the search space is dynamically pruned and its distribution is updated every few epochs. With the proposed efficient network generation method, we directly obtain the optimal neural architectures on given constraints, which is practical for on-device models across diverse search spaces and constraints. The architectures searched by our method achieve remarkable top-1 accuracies, 97.56 and 77.2 on CIFAR-10 and ImageNet (mobile settings), respectively, with the fastest search process, i.e., only 1.8 GPU hours on a Tesla V100. Codes for searching and network generation are available at: https://openi.pcl.ac.cn/PCL AutoML/XNAS.



### LatentGNN: Learning Efficient Non-local Relations for Visual Recognition
- **Arxiv ID**: http://arxiv.org/abs/1905.11634v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11634v1)
- **Published**: 2019-05-28 06:42:23+00:00
- **Updated**: 2019-05-28 06:42:23+00:00
- **Authors**: Songyang Zhang, Shipeng Yan, Xuming He
- **Comment**: ICML 2019
- **Journal**: None
- **Summary**: Capturing long-range dependencies in feature representations is crucial for many visual recognition tasks. Despite recent successes of deep convolutional networks, it remains challenging to model non-local context relations between visual features. A promising strategy is to model the feature context by a fully-connected graph neural network (GNN), which augments traditional convolutional features with an estimated non-local context representation. However, most GNN-based approaches require computing a dense graph affinity matrix and hence have difficulty in scaling up to tackle complex real-world visual problems. In this work, we propose an efficient and yet flexible non-local relation representation based on a novel class of graph neural networks. Our key idea is to introduce a latent space to reduce the complexity of graph, which allows us to use a low-rank representation for the graph affinity matrix and to achieve a linear complexity in computation. Extensive experimental evaluations on three major visual recognition tasks show that our method outperforms the prior works with a large margin while maintaining a low computation cost.



### Image Deformation Meta-Networks for One-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.11641v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11641v2)
- **Published**: 2019-05-28 06:56:52+00:00
- **Updated**: 2019-07-18 03:51:34+00:00
- **Authors**: Zitian Chen, Yanwei Fu, Yu-Xiong Wang, Lin Ma, Wei Liu, Martial Hebert
- **Comment**: Oral at CVPR2019. Code is available at
  https://github.com/tankche1/IDeMe-Net
- **Journal**: None
- **Summary**: Humans can robustly learn novel visual concepts even when images undergo various deformations and lose certain information. Mimicking the same behavior and synthesizing deformed instances of new concepts may help visual recognition systems perform better one-shot learning, i.e., learning concepts from one or few examples. Our key insight is that, while the deformed images may not be visually realistic, they still maintain critical semantic information and contribute significantly to formulating classifier decision boundaries. Inspired by the recent progress of meta-learning, we combine a meta-learner with an image deformation sub-network that produces additional training examples, and optimize both models in an end-to-end manner. The deformation sub-network learns to deform images by fusing a pair of images --- a probe image that keeps the visual content and a gallery image that diversifies the deformations. We demonstrate results on the widely used one-shot learning benchmarks (miniImageNet and ImageNet 1K Challenge datasets), which significantly outperform state-of-the-art approaches. Code is available at https://github.com/tankche1/IDeMe-Net.



### The Nipple-Areola Complex for Criminal Identification
- **Arxiv ID**: http://arxiv.org/abs/1905.11651v1
- **DOI**: 10.1109/ICB45273.2019.8987341
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11651v1)
- **Published**: 2019-05-28 07:27:06+00:00
- **Updated**: 2019-05-28 07:27:06+00:00
- **Authors**: Wojciech Michal Matkowski, Krzysztof Matkowski, Adams Wai-Kin Kong, Cory Lloyd Hall
- **Comment**: Accepted in the International Conference on Biometrics (ICB 2019),
  scheduled for 4-7 June 2019 in Crete, Greece
- **Journal**: None
- **Summary**: In digital and multimedia forensics, identification of child sexual offenders based on digital evidence images is highly challenging due to the fact that the offender's face or other obvious characteristics such as tattoos are occluded, covered, or not visible at all. Nevertheless, other naked body parts, e.g., chest are still visible. Some researchers proposed skin marks, skin texture, vein or androgenic hair patterns for criminal and victim identification. There are no available studies of nipple-areola complex (NAC) for offender identification. In this paper, we present a study of offender identification based on the NAC, and we present NTU-Nipple-v1 dataset, which contains 2732 images of 428 different male nipple-areolae. Popular deep learning and hand-crafted recognition methods are evaluated on the provided dataset. The results indicate that the NAC can be a useful characteristic for offender identification.



### Discrete Infomax Codes for Supervised Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.11656v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11656v2)
- **Published**: 2019-05-28 07:38:35+00:00
- **Updated**: 2020-02-24 04:21:53+00:00
- **Authors**: Yoonho Lee, Wonjae Kim, Wonpyo Park, Seungjin Choi
- **Comment**: 19 pages
- **Journal**: None
- **Summary**: Learning compact discrete representations of data is a key task on its own or for facilitating subsequent processing of data. In this paper we present a model that produces Discrete InfoMax Codes (DIMCO); we learn a probabilistic encoder that yields k-way d-dimensional codes associated with input data. Our model's learning objective is to maximize the mutual information between codes and labels with a regularization, which enforces entries of a codeword to be as independent as possible. We show that the infomax principle also justifies previous loss functions (e.g., cross-entropy) as its special cases. Our analysis also shows that using shorter codes, as DIMCO does, reduces overfitting in the context of few-shot classification. Through experiments in various domains, we observe this implicit meta-regularization effect of DIMCO. Furthermore, we show that the codes learned by DIMCO are efficient in terms of both memory and retrieval time compared to previous methods.



### OICSR: Out-In-Channel Sparsity Regularization for Compact Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11664v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11664v5)
- **Published**: 2019-05-28 08:09:04+00:00
- **Updated**: 2019-07-01 03:53:23+00:00
- **Authors**: Jiashi Li, Qi Qi, Jingyu Wang, Ce Ge, Yujian Li, Zhangzhang Yue, Haifeng Sun
- **Comment**: Accepted to CVPR 2019, the pruned ResNet-50 model has be released at:
  https://github.com/dsfour/OICSR
- **Journal**: None
- **Summary**: Channel pruning can significantly accelerate and compress deep neural networks. Many channel pruning works utilize structured sparsity regularization to zero out all the weights in some channels and automatically obtain structure-sparse network in training stage. However, these methods apply structured sparsity regularization on each layer separately where the correlations between consecutive layers are omitted. In this paper, we first combine one out-channel in current layer and the corresponding in-channel in next layer as a regularization group, namely out-in-channel. Our proposed Out-In-Channel Sparsity Regularization (OICSR) considers correlations between successive layers to further retain predictive power of the compact network. Training with OICSR thoroughly transfers discriminative features into a fraction of out-in-channels. Correspondingly, OICSR measures channel importance based on statistics computed from two consecutive layers, not individual layer. Finally, a global greedy pruning algorithm is designed to remove redundant out-in-channels in an iterative way. Our method is comprehensively evaluated with various CNN architectures including CifarNet, AlexNet, ResNet, DenseNet and PreActSeNet on CIFAR-10, CIFAR-100 and ImageNet-1K datasets. Notably, on ImageNet-1K, we reduce 37.2% FLOPs on ResNet-50 while outperforming the original model by 0.22% top-1 accuracy.



### Learning Dynamics of Attention: Human Prior for Interpretable Machine Reasoning
- **Arxiv ID**: http://arxiv.org/abs/1905.11666v3
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11666v3)
- **Published**: 2019-05-28 08:13:37+00:00
- **Updated**: 2019-12-23 05:37:28+00:00
- **Authors**: Wonjae Kim, Yoonho Lee
- **Comment**: 20 pages, 18 figures, 2 tables
- **Journal**: None
- **Summary**: Without relevant human priors, neural networks may learn uninterpretable features. We propose Dynamics of Attention for Focus Transition (DAFT) as a human prior for machine reasoning. DAFT is a novel method that regularizes attention-based reasoning by modelling it as a continuous dynamical system using neural ordinary differential equations. As a proof of concept, we augment a state-of-the-art visual reasoning model with DAFT. Our experiments reveal that applying DAFT yields similar performance to the original model while using fewer reasoning steps, showing that it implicitly learns to skip unnecessary steps. We also propose a new metric, Total Length of Transition (TLT), which represents the effective reasoning step size by quantifying how much a given model's focus drifts while reasoning about a question. We show that adding DAFT results in lower TLT, demonstrating that our method indeed obeys the human prior towards shorter reasoning paths in addition to producing more interpretable attention maps. Our code is available at https://github.com/kakao/DAFT.



### Invertible generative models for inverse problems: mitigating representation error and dataset bias
- **Arxiv ID**: http://arxiv.org/abs/1905.11672v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11672v4)
- **Published**: 2019-05-28 08:27:53+00:00
- **Updated**: 2020-07-12 22:27:29+00:00
- **Authors**: Muhammad Asim, Max Daniels, Oscar Leong, Ali Ahmed, Paul Hand
- **Comment**: Camera ready version for ICML 2020, paper 2655
- **Journal**: None
- **Summary**: Trained generative models have shown remarkable performance as priors for inverse problems in imaging -- for example, Generative Adversarial Network priors permit recovery of test images from 5-10x fewer measurements than sparsity priors. Unfortunately, these models may be unable to represent any particular image because of architectural choices, mode collapse, and bias in the training dataset. In this paper, we demonstrate that invertible neural networks, which have zero representation error by design, can be effective natural signal priors at inverse problems such as denoising, compressive sensing, and inpainting. Given a trained generative model, we study the empirical risk formulation of the desired inverse problem under a regularization that promotes high likelihood images, either directly by penalization or algorithmically by initialization. For compressive sensing, invertible priors can yield higher accuracy than sparsity priors across almost all undersampling ratios, and due to their lack of representation error, invertible priors can yield better reconstructions than GAN priors for images that have rare features of variation within the biased training set, including out-of-distribution natural images. We additionally compare performance for compressive sensing to unlearned methods, such as the deep decoder, and we establish theoretical bounds on expected recovery error in the case of a linear invertible model.



### Deep Scale-spaces: Equivariance Over Scale
- **Arxiv ID**: http://arxiv.org/abs/1905.11697v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11697v1)
- **Published**: 2019-05-28 09:16:56+00:00
- **Updated**: 2019-05-28 09:16:56+00:00
- **Authors**: Daniel E. Worrall, Max Welling
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce deep scale-spaces (DSS), a generalization of convolutional neural networks, exploiting the scale symmetry structure of conventional image recognition tasks. Put plainly, the class of an image is invariant to the scale at which it is viewed. We construct scale equivariant cross-correlations based on a principled extension of convolutions, grounded in the theory of scale-spaces and semigroups. As a very basic operation, these cross-correlations can be used in almost any modern deep learning architecture in a plug-and-play manner. We demonstrate our networks on the Patch Camelyon and Cityscapes datasets, to prove their utility and perform introspective studies to further understand their properties.



### Integrated Neural Network and Machine Vision Approach For Leather Defect Classification
- **Arxiv ID**: http://arxiv.org/abs/1905.11731v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11731v1)
- **Published**: 2019-05-28 10:37:58+00:00
- **Updated**: 2019-05-28 10:37:58+00:00
- **Authors**: Sze-Teng Liong, Y. S. Gan, Yen-Chang Huang, Kun-Hong Liu, Wei-Chuen Yau
- **Comment**: 12 pages, 8 tables, 9 figures
- **Journal**: None
- **Summary**: Leather is a type of natural, durable, flexible, soft, supple and pliable material with smooth texture. It is commonly used as a raw material to manufacture luxury consumer goods for high-end customers. To ensure good quality control on the leather products, one of the critical processes is the visual inspection step to spot the random defects on the leather surfaces and it is usually conducted by experienced experts. This paper presents an automatic mechanism to perform the leather defect classification. In particular, we focus on detecting tick-bite defects on a specific type of calf leather. Both the handcrafted feature extractors (i.e., edge detectors and statistical approach) and data-driven (i.e., artificial neural network) methods are utilized to represent the leather patches. Then, multiple classifiers (i.e., decision trees, Support Vector Machines, nearest neighbour and ensemble classifiers) are exploited to determine whether the test sample patches contain defective segments. Using the proposed method, we managed to get a classification accuracy rate of 84% from a sample of approximately 2500 pieces of 400 * 400 leather patches.



### Cross-Domain Transferability of Adversarial Perturbations
- **Arxiv ID**: http://arxiv.org/abs/1905.11736v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11736v5)
- **Published**: 2019-05-28 11:00:34+00:00
- **Updated**: 2019-10-14 19:13:37+00:00
- **Authors**: Muzammal Naseer, Salman H. Khan, Harris Khan, Fahad Shahbaz Khan, Fatih Porikli
- **Comment**: Accepted at NeurIPS 2019 (Camera Ready). Source Code along with
  pretrained adversarial generators is available at
  https://github.com/Muzammal-Naseer/Cross-domain-perturbations
- **Journal**: None
- **Summary**: Adversarial examples reveal the blind spots of deep neural networks (DNNs) and represent a major concern for security-critical applications. The transferability of adversarial examples makes real-world attacks possible in black-box settings, where the attacker is forbidden to access the internal parameters of the model. The underlying assumption in most adversary generation methods, whether learning an instance-specific or an instance-agnostic perturbation, is the direct or indirect reliance on the original domain-specific data distribution. In this work, for the first time, we demonstrate the existence of domain-invariant adversaries, thereby showing common adversarial space among different datasets and models. To this end, we propose a framework capable of launching highly transferable attacks that crafts adversarial patterns to mislead networks trained on wholly different domains. For instance, an adversarial function learned on Paintings, Cartoons or Medical images can successfully perturb ImageNet samples to fool the classifier, with success rates as high as $\sim$99\% ($\ell_{\infty} \le 10$). The core of our proposed adversarial function is a generative network that is trained using a relativistic supervisory signal that enables domain-invariant perturbations. Our approach sets the new state-of-the-art for fooling rates, both under the white-box and black-box scenarios. Furthermore, despite being an instance-agnostic perturbation function, our attack outperforms the conventionally much stronger instance-specific attack methods.



### A Cost Efficient Approach to Correct OCR Errors in Large Document Collections
- **Arxiv ID**: http://arxiv.org/abs/1905.11739v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11739v1)
- **Published**: 2019-05-28 11:11:57+00:00
- **Updated**: 2019-05-28 11:11:57+00:00
- **Authors**: Deepayan Das, Jerin Philip, Minesh Mathew, C. V. Jawahar
- **Comment**: None
- **Journal**: None
- **Summary**: Word error rate of an ocr is often higher than its character error rate. This is especially true when ocrs are designed by recognizing characters. High word accuracies are critical to tasks like the creation of content in digital libraries and text-to-speech applications. In order to detect and correct the misrecognised words, it is common for an ocr module to employ a post-processor to further improve the word accuracy. However, conventional approaches to post-processing like looking up a dictionary or using a statistical language model (slm), are still limited. In many such scenarios, it is often required to remove the outstanding errors manually. We observe that the traditional post-processing schemes look at error words sequentially since ocrs process documents one at a time. We propose a cost-efficient model to address the error words in batches rather than correcting them individually. We exploit the fact that a collection of documents, unlike a single document, has a structure leading to repetition of words. Such words, if efficiently grouped together and corrected as a whole can lead to a significant reduction in the cost. Correction can be fully automatic or with a human in the loop. Towards this, we employ a novel clustering scheme to obtain fairly homogeneous clusters. We compare the performance of our model with various baseline approaches including the case where all the errors are removed by a human. We demonstrate the efficacy of our solution empirically by reporting more than 70% reduction in the human effort with near perfect error correction. We validate our method on Books from multiple languages.



### PHT-bot: Deep-Learning based system for automatic risk stratification of COPD patients based upon signs of Pulmonary Hypertension
- **Arxiv ID**: http://arxiv.org/abs/1905.11773v1
- **DOI**: 10.1117/12.2512469
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11773v1)
- **Published**: 2019-05-28 12:39:05+00:00
- **Updated**: 2019-05-28 12:39:05+00:00
- **Authors**: David Chettrit, Orna Bregman Amitai, Itamar Tamir, Amir Bar, Eldad Elnekave
- **Comment**: None
- **Journal**: Proc. SPIE 10950, Medical Imaging 2019: Computer-Aided Diagnosis,
  109500O
- **Summary**: Chronic Obstructive Pulmonary Disease (COPD) is a leading cause of morbidity and mortality worldwide. Identifying those at highest risk of deterioration would allow more effective distribution of preventative and surveillance resources. Secondary pulmonary hypertension is a manifestation of advanced COPD, which can be reliably diagnosed by the main Pulmonary Artery (PA) to Ascending Aorta (Ao) ratio. In effect, a PA diameter to Ao diameter ratio of greater than 1 has been demonstrated to be a reliable marker of increased pulmonary arterial pressure. Although clinically valuable and readily visualized, the manual assessment of the PA and the Ao diameters is time consuming and under-reported. The present study describes a non invasive method to measure the diameters of both the Ao and the PA from contrast-enhanced chest Computed Tomography (CT). The solution applies deep learning techniques in order to select the correct axial slice to measure, and to segment both arteries. The system achieves test Pearson correlation coefficient scores of 93% for the Ao and 92% for the PA. To the best of our knowledge, it is the first such fully automated solution.



### Importance of user inputs while using incremental learning to personalize human activity recognition models
- **Arxiv ID**: http://arxiv.org/abs/1905.11775v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.HC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11775v1)
- **Published**: 2019-05-28 12:41:02+00:00
- **Updated**: 2019-05-28 12:41:02+00:00
- **Authors**: Pekka Siirtola, Heli Koskimäki, Juha Röning
- **Comment**: European Symposium on Artificial Neural Networks, Computational
  Intelligence and Machine Learning (ESANN) 2019, pages 449-454
- **Journal**: None
- **Summary**: In this study, importance of user inputs is studied in the context of personalizing human activity recognition models using incremental learning. Inertial sensor data from three body positions are used, and the classification is based on Learn++ ensemble method. Three different approaches to update models are compared: non-supervised, semi-supervised and supervised. Non-supervised approach relies fully on predicted labels, supervised fully on user labeled data, and the proposed method for semi-supervised learning, is a combination of these two. In fact, our experiments show that by relying on predicted labels with high confidence, and asking the user to label only uncertain observations (from 12% to 26% of the observations depending on the used base classifier), almost as low error rates can be achieved as by using supervised approach. In fact, the difference was less than 2%-units. Moreover, unlike non-supervised approach, semi-supervised approach does not suffer from drastic concept drift, and thus, the error rate of the non-supervised approach is over 5%-units higher than using semi-supervised approach.



### Effect of context in swipe gesture-based continuous authentication on smartphones
- **Arxiv ID**: http://arxiv.org/abs/1905.11780v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11780v1)
- **Published**: 2019-05-28 12:49:55+00:00
- **Updated**: 2019-05-28 12:49:55+00:00
- **Authors**: Pekka Siirtola, Jukka Komulainen, Vili Kellokumpu
- **Comment**: European Symposium on Artificial Neural Networks, Computational
  Intelligence and Machine Learning (ESANN) 2018, pages 639-644
- **Journal**: None
- **Summary**: This work investigates how context should be taken into account when performing continuous authentication of a smartphone user based on touchscreen and accelerometer readings extracted from swipe gestures. The study is conducted on the publicly available HMOG dataset consisting of 100 study subjects performing pre-defined reading and navigation tasks while sitting and walking. It is shown that context-specific models are needed for different smartphone usage and human activity scenarios to minimize authentication error. Also, the experimental results suggests that utilization of phone movement improves swipe gesture-based verification performance only when the user is moving.



### Progressive Learning of Low-Precision Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11781v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11781v1)
- **Published**: 2019-05-28 12:50:01+00:00
- **Updated**: 2019-05-28 12:50:01+00:00
- **Authors**: Zhengguang Zhou, Wengang Zhou, Xutao Lv, Xuan Huang, Xiaoyu Wang, Houqiang Li
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: Recent years have witnessed the great advance of deep learning in a variety of vision tasks. Many state-of-the-art deep neural networks suffer from large size and high complexity, which makes it difficult to deploy in resource-limited platforms such as mobile devices.   To this end, low-precision neural networks are widely studied which quantize weights or activations into the low-bit format.   Though being efficient, low-precision networks are usually hard to train and encounter severe accuracy degradation.   In this paper, we propose a new training strategy through expanding low-precision networks during training and removing the expanded parts for network inference.   First, we equip each low-precision convolutional layer with an ancillary full-precision convolutional layer based on a low-precision network structure, which could guide the network to good local minima.   Second, a decay method is introduced to reduce the output of the added full-precision convolution gradually, which keeps the resulted topology structure the same to the original low-precision one.   Experiments on SVHN, CIFAR and ILSVRC-2012 datasets prove that the proposed method can bring faster convergence and higher accuracy for low-precision neural networks.



### SizeNet: Weakly Supervised Learning of Visual Size and Fit in Fashion Images
- **Arxiv ID**: http://arxiv.org/abs/1905.11784v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11784v1)
- **Published**: 2019-05-28 12:58:06+00:00
- **Updated**: 2019-05-28 12:58:06+00:00
- **Authors**: Nour Karessli, Romain Guigourès, Reza Shirvany
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition Workshop
  (CVPRW) 2019 Focus on Fashion and Subjective Search - Understanding
  Subjective Attributes of Data (FFSS-USAD)
- **Journal**: None
- **Summary**: Finding clothes that fit is a hot topic in the e-commerce fashion industry. Most approaches addressing this problem are based on statistical methods relying on historical data of articles purchased and returned to the store. Such approaches suffer from the cold start problem for the thousands of articles appearing on the shopping platforms every day, for which no prior purchase history is available. We propose to employ visual data to infer size and fit characteristics of fashion articles. We introduce SizeNet, a weakly-supervised teacher-student training framework that leverages the power of statistical models combined with the rich visual information from article images to learn visual cues for size and fit characteristics, capable of tackling the challenging cold start problem. Detailed experiments are performed on thousands of textile garments, including dresses, trousers, knitwear, tops, etc. from hundreds of different brands.



### Online Filter Clustering and Pruning for Efficient Convnets
- **Arxiv ID**: http://arxiv.org/abs/1905.11787v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11787v1)
- **Published**: 2019-05-28 13:01:39+00:00
- **Updated**: 2019-05-28 13:01:39+00:00
- **Authors**: Zhengguang Zhou, Wengang Zhou, Richang Hong, Houqiang Li
- **Comment**: 5 pages, 4 figures
- **Journal**: 2018 IEEE International Conference on Image Processing
- **Summary**: Pruning filters is an effective method for accelerating deep neural networks (DNNs), but most existing approaches prune filters on a pre-trained network directly which limits in acceleration. Although each filter has its own effect in DNNs, but if two filters are the same with each other, we could prune one safely. In this paper, we add an extra cluster loss term in the loss function which can force filters in each cluster to be similar online. After training, we keep one filter in each cluster and prune others and fine-tune the pruned network to compensate for the loss. Particularly, the clusters in every layer can be defined firstly which is effective for pruning DNNs within residual blocks. Extensive experiments on CIFAR10 and CIFAR100 benchmarks demonstrate the competitive performance of our proposed filter pruning method.



### Hallucinating Optical Flow Features for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1905.11799v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11799v2)
- **Published**: 2019-05-28 13:25:40+00:00
- **Updated**: 2019-06-21 04:40:06+00:00
- **Authors**: Yongyi Tang, Lin Ma, Lianqiang Zhou
- **Comment**: Accepted by IJCAI 2019
- **Journal**: None
- **Summary**: Appearance and motion are two key components to depict and characterize the video content. Currently, the two-stream models have achieved state-of-the-art performances on video classification. However, extracting motion information, specifically in the form of optical flow features, is extremely computationally expensive, especially for large-scale video classification. In this paper, we propose a motion hallucination network, namely MoNet, to imagine the optical flow features from the appearance features, with no reliance on the optical flow computation. Specifically, MoNet models the temporal relationships of the appearance features and exploits the contextual relationships of the optical flow features with concurrent connections. Extensive experimental results demonstrate that the proposed MoNet can effectively and efficiently hallucinate the optical flow features, which together with the appearance features consistently improve the video classification performances. Moreover, MoNet can help cutting down almost a half of computational and data-storage burdens for the two-stream video classification. Our code is available at: https://github.com/YongyiTang92/MoNet-Features.



### FReeNet: Multi-Identity Face Reenactment
- **Arxiv ID**: http://arxiv.org/abs/1905.11805v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11805v2)
- **Published**: 2019-05-28 13:34:57+00:00
- **Updated**: 2020-05-16 07:29:20+00:00
- **Authors**: Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu, Yu Ding, Changjie Fan
- **Comment**: Add more experiments; Revise the paper carefully;
- **Journal**: None
- **Summary**: This paper presents a novel multi-identity face reenactment framework, named FReeNet, to transfer facial expressions from an arbitrary source face to a target face with a shared model. The proposed FReeNet consists of two parts: Unified Landmark Converter (ULC) and Geometry-aware Generator (GAG). The ULC adopts an encode-decoder architecture to efficiently convert expression in a latent landmark space, which significantly narrows the gap of the face contour between source and target identities. The GAG leverages the converted landmark to reenact the photorealistic image with a reference image of the target person. Moreover, a new triplet perceptual loss is proposed to force the GAG module to learn appearance and geometry information simultaneously, which also enriches facial details of the reenacted images. Further experiments demonstrate the superiority of our approach for generating photorealistic and expression-alike faces, as well as the flexibility for transferring facial expressions between identities.



### Combining Compositional Models and Deep Networks For Robust Object Classification under Occlusion
- **Arxiv ID**: http://arxiv.org/abs/1905.11826v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11826v4)
- **Published**: 2019-05-28 14:03:46+00:00
- **Updated**: 2020-01-29 14:42:08+00:00
- **Authors**: Adam Kortylewski, Qing Liu, Huiyu Wang, Zhishuai Zhang, Alan Yuille
- **Comment**: WACV 2020
- **Journal**: None
- **Summary**: Deep convolutional neural networks (DCNNs) are powerful models that yield impressive results at object classification. However, recent work has shown that they do not generalize well to partially occluded objects and to mask attacks. In contrast to DCNNs, compositional models are robust to partial occlusion, however, they are not as discriminative as deep models. In this work, we combine DCNNs and compositional object models to retain the best of both approaches: a discriminative model that is robust to partial occlusion and mask attacks. Our model is learned in two steps. First, a standard DCNN is trained for image classification. Subsequently, we cluster the DCNN features into dictionaries. We show that the dictionary components resemble object part detectors and learn the spatial distribution of parts for each object class. We propose mixtures of compositional models to account for large changes in the spatial activation patterns (e.g. due to changes in the 3D pose of an object). At runtime, an image is first classified by the DCNN in a feedforward manner. The prediction uncertainty is used to detect partially occluded objects, which in turn are classified by the compositional model. Our experimental results demonstrate that combining compositional models and DCNNs resolves a fundamental problem of current deep learning approaches to computer vision: The combined model recognizes occluded objects, even when it has not been exposed to occluded objects during training, while at the same time maintaining high discriminative performance for non-occluded objects.



### Snooping Attacks on Deep Reinforcement Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.11832v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11832v2)
- **Published**: 2019-05-28 14:11:16+00:00
- **Updated**: 2020-01-15 23:59:17+00:00
- **Authors**: Matthew Inkawhich, Yiran Chen, Hai Li
- **Comment**: 13 pages, 12 figures
- **Journal**: None
- **Summary**: Adversarial attacks have exposed a significant security vulnerability in state-of-the-art machine learning models. Among these models include deep reinforcement learning agents. The existing methods for attacking reinforcement learning agents assume the adversary either has access to the target agent's learned parameters or the environment that the agent interacts with. In this work, we propose a new class of threat models, called snooping threat models, that are unique to reinforcement learning. In these snooping threat models, the adversary does not have the ability to interact with the target agent's environment, and can only eavesdrop on the action and reward signals being exchanged between agent and environment. We show that adversaries operating in these highly constrained threat models can still launch devastating attacks against the target agent by training proxy models on related tasks and leveraging the transferability of adversarial examples.



### Video-based Person Re-identification with Two-stream Convolutional Network and Co-attentive Snippet Embedding
- **Arxiv ID**: http://arxiv.org/abs/1905.11862v1
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11862v1)
- **Published**: 2019-05-28 14:47:33+00:00
- **Updated**: 2019-05-28 14:47:33+00:00
- **Authors**: Peixian Chen, Pingyang Dai, Qiong Wu, Yuyu Huang
- **Comment**: 5 pages, 2 figures
- **Journal**: None
- **Summary**: Recently, the applications of person re-identification in visual surveillance and human-computer interaction are sharply increasing, which signifies the critical role of such a problem. In this paper, we propose a two-stream convolutional network (ConvNet) based on the competitive similarity aggregation scheme and co-attentive embedding strategy for video-based person re-identification. By dividing the long video sequence into multiple short video snippets, we manage to utilize every snippet's RGB frames, optical flow maps and pose maps to facilitate residual networks, e.g., ResNet, for feature extraction in the two-stream ConvNet. The extracted features are embedded by the co-attentive embedding method, which allows for the reduction of the effects of noisy frames. Finally, we fuse the outputs of both streams as the embedding of a snippet, and apply competitive snippet-similarity aggregation to measure the similarity between two sequences. Our experiments show that the proposed method significantly outperforms current state-of-the-art approaches on multiple datasets.



### BreizhCrops: A Time Series Dataset for Crop Type Mapping
- **Arxiv ID**: http://arxiv.org/abs/1905.11893v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11893v2)
- **Published**: 2019-05-28 15:40:18+00:00
- **Updated**: 2020-05-10 19:01:27+00:00
- **Authors**: Marc Rußwurm, Charlotte Pelletier, Maximilian Zollner, Sébastien Lefèvre, Marco Körner
- **Comment**: accepted to ISPRS Archives 2020
- **Journal**: None
- **Summary**: We present Breizhcrops, a novel benchmark dataset for the supervised classification of field crops from satellite time series. We aggregated label data and Sentinel-2 top-of-atmosphere as well as bottom-of-atmosphere time series in the region of Brittany (Breizh in local language), north-east France. We compare seven recently proposed deep neural networks along with a Random Forest baseline. The dataset, model (re-)implementations and pre-trained model weights are available at the associated GitHub repository (https://github.com/dl4sits/BreizhCrops) that has been designed with applicability for practitioners in mind. We plan to maintain the repository with additional data and welcome contributions of novel methods to build a state-of-the-art benchmark on methods for crop type mapping.



### Efficient Object Embedding for Spliced Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1905.11903v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11903v2)
- **Published**: 2019-05-28 16:02:51+00:00
- **Updated**: 2021-04-28 03:23:16+00:00
- **Authors**: Bor-Chun Chen, Zuxuan Wu, Larry S. Davis, Ser-Nam Lim
- **Comment**: None
- **Journal**: None
- **Summary**: Detecting spliced images is one of the emerging challenges in computer vision. Unlike prior methods that focus on detecting low-level artifacts generated during the manipulation process, we use an image retrieval approach to tackle this problem. When given a spliced query image, our goal is to retrieve the original image from a database of authentic images. To achieve this goal, we propose representing an image by its constituent objects based on the intuition that the finest granularity of manipulations is oftentimes at the object-level. We introduce a framework, object embeddings for spliced image retrieval (OE-SIR), that utilizes modern object detectors to localize object regions. Each region is then embedded and collectively used to represent the image. Further, we propose a student-teacher training paradigm for learning discriminative embeddings within object regions to avoid expensive multiple forward passes. Detailed analysis of the efficacy of different feature embedding models is also provided in this study. Extensive experimental results show that the OE-SIR achieves state-of-the-art performance in spliced image retrieval.



### FireNet: A Specialized Lightweight Fire & Smoke Detection Model for Real-Time IoT Applications
- **Arxiv ID**: http://arxiv.org/abs/1905.11922v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11922v2)
- **Published**: 2019-05-28 16:31:52+00:00
- **Updated**: 2019-09-04 04:09:37+00:00
- **Authors**: Arpit Jadon, Mohd. Omama, Akshay Varshney, Mohammad Samar Ansari, Rishabh Sharma
- **Comment**: To be submitted to a conference in the future
- **Journal**: None
- **Summary**: Fire disasters typically result in lot of loss to life and property. It is therefore imperative that precise, fast, and possibly portable solutions to detect fire be made readily available to the masses at reasonable prices. There have been several research attempts to design effective and appropriately priced fire detection systems with varying degrees of success. However, most of them demonstrate a trade-off between performance and model size (which decides the model's ability to be installed on portable devices). The work presented in this paper is an attempt to deal with both the performance and model size issues in one design. Toward that end, a `designed-from-scratch' neural network, named FireNet, is proposed which is worthy on both the counts: (i) it has better performance than existing counterparts, and (ii) it is lightweight enough to be deploy-able on embedded platforms like Raspberry Pi. Performance evaluations on a standard dataset, as well as our own newly introduced custom-compiled fire dataset, are extremely encouraging.



### Network Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/1905.11926v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11926v4)
- **Published**: 2019-05-28 16:38:34+00:00
- **Updated**: 2020-02-25 20:48:22+00:00
- **Authors**: Chengxi Ye, Matthew Evanusa, Hua He, Anton Mitrokhin, Tom Goldstein, James A. Yorke, Cornelia Fermüller, Yiannis Aloimonos
- **Comment**: ICLR 2020
- **Journal**: None
- **Summary**: Convolution is a central operation in Convolutional Neural Networks (CNNs), which applies a kernel to overlapping regions shifted across the image. However, because of the strong correlations in real-world image data, convolutional kernels are in effect re-learning redundant data. In this work, we show that this redundancy has made neural network training challenging, and propose network deconvolution, a procedure which optimally removes pixel-wise and channel-wise correlations before the data is fed into each layer. Network deconvolution can be efficiently calculated at a fraction of the computational cost of a convolution layer. We also show that the deconvolution filters in the first layer of the network resemble the center-surround structure found in biological neurons in the visual regions of the brain. Filtering with such kernels results in a sparse representation, a desired property that has been missing in the training of neural networks. Learning from the sparse representation promotes faster convergence and superior results without the use of batch normalization. We apply our network deconvolution operation to 10 modern neural network models by replacing batch normalization within each. Extensive experiments show that the network deconvolution operation is able to deliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST, Fashion-MNIST, Cityscapes, and ImageNet datasets.



### Adversarial Domain Adaptation Being Aware of Class Relationships
- **Arxiv ID**: http://arxiv.org/abs/1905.11931v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11931v2)
- **Published**: 2019-05-28 16:52:08+00:00
- **Updated**: 2020-03-30 00:52:54+00:00
- **Authors**: Zeya Wang, Baoyu Jing, Yang Ni, Nanqing Dong, Pengtao Xie, Eric P. Xing
- **Comment**: None
- **Journal**: 24th European Conference on Artificial Intelligence (ECAI), 2020
- **Summary**: Adversarial training is a useful approach to promote the learning of transferable representations across the source and target domains, which has been widely applied for domain adaptation (DA) tasks based on deep neural networks. Until very recently, existing adversarial domain adaptation (ADA) methods ignore the useful information from the label space, which is an important factor accountable for the complicated data distributions associated with different semantic classes. Especially, the inter-class semantic relationships have been rarely considered and discussed in the current work of transfer learning. In this paper, we propose a novel relationship-aware adversarial domain adaptation (RADA) algorithm, which first utilizes a single multi-class domain discriminator to enforce the learning of inter-class dependency structure during domain-adversarial training and then aligns this structure with the inter-class dependencies that are characterized from training the label predictor on source domain. Specifically, we impose a regularization term to penalize the structure discrepancy between the inter-class dependencies respectively estimated from domain discriminator and label predictor. Through this alignment, our proposed method makes the adversarial domain adaptation aware of the class relationships. Empirical studies show that the incorporation of class relationships significantly improves the performance on benchmark datasets.



### Cerberus: A Multi-headed Derenderer
- **Arxiv ID**: http://arxiv.org/abs/1905.11940v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11940v1)
- **Published**: 2019-05-28 17:00:03+00:00
- **Updated**: 2019-05-28 17:00:03+00:00
- **Authors**: Boyang Deng, Simon Kornblith, Geoffrey Hinton
- **Comment**: None
- **Journal**: None
- **Summary**: To generalize to novel visual scenes with new viewpoints and new object poses, a visual system needs representations of the shapes of the parts of an object that are invariant to changes in viewpoint or pose. 3D graphics representations disentangle visual factors such as viewpoints and lighting from object structure in a natural way. It is possible to learn to invert the process that converts 3D graphics representations into 2D images, provided the 3D graphics representations are available as labels. When only the unlabeled images are available, however, learning to derender is much harder. We consider a simple model which is just a set of free floating parts. Each part has its own relation to the camera and its own triangular mesh which can be deformed to model the shape of the part. At test time, a neural network looks at a single image and extracts the shapes of the parts and their relations to the camera. Each part can be viewed as one head of a multi-headed derenderer. During training, the extracted parts are used as input to a differentiable 3D renderer and the reconstruction error is backpropagated to train the neural net. We make the learning task easier by encouraging the deformations of the part meshes to be invariant to changes in viewpoint and invariant to the changes in the relative positions of the parts that occur when the pose of an articulated body changes. Cerberus, our multi-headed derenderer, outperforms previous methods for extracting 3D parts from single images without part annotations, and it does quite well at extracting natural parts of human figures.



### A Compact Representation of Histopathology Images using Digital Stain Separation & Frequency-Based Encoded Local Projections
- **Arxiv ID**: http://arxiv.org/abs/1905.11945v1
- **DOI**: 10.1007/978-3-030-27272-2_13
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11945v1)
- **Published**: 2019-05-28 17:04:35+00:00
- **Updated**: 2019-05-28 17:04:35+00:00
- **Authors**: Alison K. Cheeseman, Hamid Tizhoosh, Edward R. Vrscay
- **Comment**: Accepted for publication in the International Conference on Image
  Analysis and Recognition (ICIAR 2019)
- **Journal**: None
- **Summary**: In recent years, histopathology images have been increasingly used as a diagnostic tool in the medical field. The process of accurately diagnosing a biopsy sample requires significant expertise in the field, and as such can be time-consuming and is prone to uncertainty and error. With the advent of digital pathology, using image recognition systems to highlight problem areas or locate similar images can aid pathologists in making quick and accurate diagnoses. In this paper, we specifically consider the encoded local projections (ELP) algorithm, which has previously shown some success as a tool for classification and recognition of histopathology images. We build on the success of the ELP algorithm as a means for image classification and recognition by proposing a modified algorithm which captures the local frequency information of the image. The proposed algorithm estimates local frequencies by quantifying the changes in multiple projections in local windows of greyscale images. By doing so we remove the need to store the full projections, thus significantly reducing the histogram size, and decreasing computation time for image retrieval and classification tasks. Furthermore, we investigate the effectiveness of applying our method to histopathology images which have been digitally separated into their hematoxylin and eosin stain components. The proposed algorithm is tested on the publicly available invasive ductal carcinoma (IDC) data set. The histograms are used to train an SVM to classify the data. The experiments showed that the proposed method outperforms the original ELP algorithm in image retrieval tasks. On classification tasks, the results are found to be comparable to state-of-the-art deep learning methods and better than many handcrafted features from the literature.



### EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11946v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11946v5)
- **Published**: 2019-05-28 17:05:32+00:00
- **Updated**: 2020-09-11 05:08:01+00:00
- **Authors**: Mingxing Tan, Quoc V. Le
- **Comment**: ICML 2019
- **Journal**: International Conference on Machine Learning, 2019
- **Summary**: Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.   To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.3% top-1 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet.



### Unsupervised Learning from Video with Deep Neural Embeddings
- **Arxiv ID**: http://arxiv.org/abs/1905.11954v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11954v2)
- **Published**: 2019-05-28 17:24:48+00:00
- **Updated**: 2020-03-10 21:57:55+00:00
- **Authors**: Chengxu Zhuang, Tianwei She, Alex Andonian, Max Sobol Mark, Daniel Yamins
- **Comment**: To appear in CVPR 2020
- **Journal**: None
- **Summary**: Because of the rich dynamical structure of videos and their ubiquity in everyday life, it is a natural idea that video data could serve as a powerful unsupervised learning signal for training visual representations in deep neural networks. However, instantiating this idea, especially at large scale, has remained a significant artificial intelligence challenge. Here we present the Video Instance Embedding (VIE) framework, which extends powerful recent unsupervised loss functions for learning deep nonlinear embeddings to multi-stream temporal processing architectures on large-scale video datasets. We show that VIE-trained networks substantially advance the state of the art in unsupervised learning from video datastreams, both for action recognition in the Kinetics dataset, and object recognition in the ImageNet dataset. We show that a hybrid model with both static and dynamic processing pathways is optimal for both transfer tasks, and provide analyses indicating how the pathways differ. Taken in context, our results suggest that deep neural embeddings are a promising approach to unsupervised visual learning across a wide variety of domains.



### ME-Net: Towards Effective Adversarial Robustness with Matrix Estimation
- **Arxiv ID**: http://arxiv.org/abs/1905.11971v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11971v1)
- **Published**: 2019-05-28 17:47:33+00:00
- **Updated**: 2019-05-28 17:47:33+00:00
- **Authors**: Yuzhe Yang, Guo Zhang, Dina Katabi, Zhi Xu
- **Comment**: ICML 2019
- **Journal**: None
- **Summary**: Deep neural networks are vulnerable to adversarial attacks. The literature is rich with algorithms that can easily craft successful adversarial examples. In contrast, the performance of defense techniques still lags behind. This paper proposes ME-Net, a defense method that leverages matrix estimation (ME). In ME-Net, images are preprocessed using two steps: first pixels are randomly dropped from the image; then, the image is reconstructed using ME. We show that this process destroys the adversarial structure of the noise, while re-enforcing the global structure in the original image. Since humans typically rely on such global structures in classifying images, the process makes the network mode compatible with human perception. We conduct comprehensive experiments on prevailing benchmarks such as MNIST, CIFAR-10, SVHN, and Tiny-ImageNet. Comparing ME-Net with state-of-the-art defense mechanisms shows that ME-Net consistently outperforms prior techniques, improving robustness against both black-box and white-box attacks.



### Texture CNN for Thermoelectric Metal Pipe Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1905.12003v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.12003v1)
- **Published**: 2019-05-28 18:02:00+00:00
- **Updated**: 2019-05-28 18:02:00+00:00
- **Authors**: Daniel Vriesman, Alessandro Zimmer, Alceu S. Britto Jr., Alessandro L. Koerich
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, the concept of representation learning based on deep neural networks is applied as an alternative to the use of handcrafted features in a method for automatic visual inspection of corroded thermoelectric metallic pipes. A texture convolutional neural network (TCNN) replaces handcrafted features based on Local Phase Quantization (LPQ) and Haralick descriptors (HD) with the advantage of learning an appropriate textural representation and the decision boundaries into a single optimization process. Experimental results have shown that it is possible to reach the accuracy of 99.20% in the task of identifying different levels of corrosion in the internal surface of thermoelectric pipe walls, while using a compact network that requires much less effort in tuning parameters when compared to the handcrafted approach since the TCNN architecture is compact regarding the number of layers and connections. The observed results open up the possibility of using deep neural networks in real-time applications such as the automatic inspection of thermoelectric metal pipes.



### Texture CNN for Histopathological Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1905.12005v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.12005v1)
- **Published**: 2019-05-28 18:04:19+00:00
- **Updated**: 2019-05-28 18:04:19+00:00
- **Authors**: Jonathan de Matos, Alceu de S. Britto Jr., Luiz E. S. de Oliveira, Alessandro L. Koerich
- **Comment**: None
- **Journal**: None
- **Summary**: Biopsies are the gold standard for breast cancer diagnosis. This task can be improved by the use of Computer Aided Diagnosis (CAD) systems, reducing the time of diagnosis and reducing the inter and intra-observer variability. The advances in computing have brought this type of system closer to reality. However, datasets of Histopathological Images (HI) from biopsies are quite small and unbalanced what makes difficult to use modern machine learning techniques such as deep learning. In this paper we propose a compact architecture based on texture filters that has fewer parameters than traditional deep models but is able to capture the difference between malignant and benign tissues with relative accuracy. The experimental results on the BreakHis dataset have show that the proposed texture CNN achieves almost 90% of accuracy for classifying benign and malignant tissues.



### Leveraging Medical Visual Question Answering with Supporting Facts
- **Arxiv ID**: http://arxiv.org/abs/1905.12008v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.12008v1)
- **Published**: 2019-05-28 18:15:52+00:00
- **Updated**: 2019-05-28 18:15:52+00:00
- **Authors**: Tomasz Kornuta, Deepta Rajan, Chaitanya Shivade, Alexis Asseman, Ahmet S. Ozcan
- **Comment**: Working notes from the ImageCLEF 2019 VQA-Med competition
- **Journal**: None
- **Summary**: In this working notes paper, we describe IBM Research AI (Almaden) team's participation in the ImageCLEF 2019 VQA-Med competition. The challenge consists of four question-answering tasks based on radiology images. The diversity of imaging modalities, organs and disease types combined with a small imbalanced training set made this a highly complex problem. To overcome these difficulties, we implemented a modular pipeline architecture that utilized transfer learning and multi-task learning. Our findings led to the development of a novel model called Supporting Facts Network (SFN). The main idea behind SFN is to cross-utilize information from upstream tasks to improve the accuracy on harder downstream ones. This approach significantly improved the scores achieved in the validation set (18 point improvement in F-1 score). Finally, we submitted four runs to the competition and were ranked seventh.



### Unified Probabilistic Deep Continual Learning through Generative Replay and Open Set Recognition
- **Arxiv ID**: http://arxiv.org/abs/1905.12019v5
- **DOI**: 10.3390/jimaging8040093
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.12019v5)
- **Published**: 2019-05-28 18:26:04+00:00
- **Updated**: 2022-04-01 10:33:08+00:00
- **Authors**: Martin Mundt, Iuliia Pliushch, Sagnik Majumder, Yongwon Hong, Visvanathan Ramesh
- **Comment**: Special Issue on Continual Learning in Computer Vision: Theory and
  Applications
- **Journal**: Journal of Imaging. 2022; 8(4):93
- **Summary**: Modern deep neural networks are well known to be brittle in the face of unknown data instances and recognition of the latter remains a challenge. Although it is inevitable for continual-learning systems to encounter such unseen concepts, the corresponding literature appears to nonetheless focus primarily on alleviating catastrophic interference with learned representations. In this work, we introduce a probabilistic approach that connects these perspectives based on variational inference in a single deep autoencoder model. Specifically, we propose to bound the approximate posterior by fitting regions of high density on the basis of correctly classified data points. These bounds are shown to serve a dual purpose: unseen unknown out-of-distribution data can be distinguished from already trained known tasks towards robust application. Simultaneously, to retain already acquired knowledge, a generative replay process can be narrowed to strictly in-distribution samples, in order to significantly alleviate catastrophic interference.



### Domain Generalization via Universal Non-volume Preserving Models
- **Arxiv ID**: http://arxiv.org/abs/1905.13040v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.13040v2)
- **Published**: 2019-05-28 18:31:25+00:00
- **Updated**: 2020-04-10 18:39:22+00:00
- **Authors**: Thanh-Dat Truong, Chi Nhan Duong, Khoa Luu, Minh-Triet Tran, Ngan Le
- **Comment**: Accepted to Computer and Robot Vision 2020. arXiv admin note:
  substantial text overlap with arXiv:1812.03407
- **Journal**: None
- **Summary**: Recognition across domains has recently become an active topic in the research community. However, it has been largely overlooked in the problem of recognition in new unseen domains. Under this condition, the delivered deep network models are unable to be updated, adapted, or fine-tuned. Therefore, recent deep learning techniques, such as domain adaptation, feature transferring, and fine-tuning, cannot be applied. This paper presents a novel approach to the problem of domain generalization in the context of deep learning. The proposed method is evaluated on different datasets in various problems, i.e. (i) digit recognition on MNIST, SVHN, and MNIST-M, (ii) face recognition on Extended Yale-B, CMU-PIE and CMU-MPIE, and (iii) pedestrian recognition on RGB and Thermal image datasets. The experimental results show that our proposed method consistently improves performance accuracy. It can also be easily incorporated with any other CNN frameworks within an end-to-end deep network design for object detection and recognition problems to improve their performance.



### Image Alignment in Unseen Domains via Domain Deep Generalization
- **Arxiv ID**: http://arxiv.org/abs/1905.12028v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.12028v2)
- **Published**: 2019-05-28 18:47:21+00:00
- **Updated**: 2019-05-31 16:11:00+00:00
- **Authors**: Thanh-Dat Truong, Khoa Luu, Chi Nhan Duong, Ngan Le, Minh-Triet Tran
- **Comment**: None
- **Journal**: None
- **Summary**: Image alignment across domains has recently become one of the realistic and popular topics in the research community. In this problem, a deep learning-based image alignment method is usually trained on an available largescale database. During the testing steps, this trained model is deployed on unseen images collected under different camera conditions and modalities. The delivered deep network models are unable to be updated, adapted or fine-tuned in these scenarios. Thus, recent deep learning techniques, e.g. domain adaptation, feature transferring, and fine-tuning, are unable to be deployed. This paper presents a novel deep learning based approach to tackle the problem of across unseen modalities. The proposed network is then applied to image alignment as an illustration. The proposed approach is designed as an end-to-end deep convolutional neural network to optimize the deep models to improve the performance. The proposed network has been evaluated in digit recognition when the model is trained on MNIST and then tested on unseen domain MNIST-M. Finally, the proposed method is benchmarked in image alignment problem when training on RGB images and testing on Depth and X-Ray images.



### Fault Sneaking Attack: a Stealthy Framework for Misleading Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.12032v1
- **DOI**: 10.1145/3316781.3317825
- **Categories**: **cs.LG**, cs.CR, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.12032v1)
- **Published**: 2019-05-28 18:56:44+00:00
- **Updated**: 2019-05-28 18:56:44+00:00
- **Authors**: Pu Zhao, Siyue Wang, Cheng Gongye, Yanzhi Wang, Yunsi Fei, Xue Lin
- **Comment**: Accepted by the 56th Design Automation Conference (DAC 2019)
- **Journal**: None
- **Summary**: Despite the great achievements of deep neural networks (DNNs), the vulnerability of state-of-the-art DNNs raises security concerns of DNNs in many application domains requiring high reliability.We propose the fault sneaking attack on DNNs, where the adversary aims to misclassify certain input images into any target labels by modifying the DNN parameters. We apply ADMM (alternating direction method of multipliers) for solving the optimization problem of the fault sneaking attack with two constraints: 1) the classification of the other images should be unchanged and 2) the parameter modifications should be minimized. Specifically, the first constraint requires us not only to inject designated faults (misclassifications), but also to hide the faults for stealthy or sneaking considerations by maintaining model accuracy. The second constraint requires us to minimize the parameter modifications (using L0 norm to measure the number of modifications and L2 norm to measure the magnitude of modifications). Comprehensive experimental evaluation demonstrates that the proposed framework can inject multiple sneaking faults without losing the overall test accuracy performance.



### Image classification using quantum inference on the D-Wave 2X
- **Arxiv ID**: http://arxiv.org/abs/1905.13215v1
- **DOI**: 10.1109/ICRC.2018.8638596
- **Categories**: **quant-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.13215v1)
- **Published**: 2019-05-28 19:21:24+00:00
- **Updated**: 2019-05-28 19:21:24+00:00
- **Authors**: Nga T. T. Nguyen, Garrett T. Kenyon
- **Comment**: 7 pages, 6 figures
- **Journal**: IEEE Proceedings of the 3rd International Conference on Rebooting
  Computing (ICRC), November, 2018
- **Summary**: We use a quantum annealing D-Wave 2X computer to obtain solutions to NP-hard sparse coding problems. To reduce the dimensionality of the sparse coding problem to fit on the quantum D-Wave 2X hardware, we passed downsampled MNIST images through a bottleneck autoencoder. To establish a benchmark for classification performance on this reduced dimensional data set, we used an AlexNet-like architecture implemented in TensorFlow, obtaining a classification score of $94.54 \pm 0.7 \%$. As a control, we showed that the same AlexNet-like architecture produced near-state-of-the-art classification performance $(\sim 99\%)$ on the original MNIST images. To obtain a set of optimized features for inferring sparse representations of the reduced dimensional MNIST dataset, we imprinted on a random set of $47$ image patches followed by an off-line unsupervised learning algorithm using stochastic gradient descent to optimize for sparse coding. Our single-layer of sparse coding matched the stride and patch size of the first convolutional layer of the AlexNet-like deep neural network and contained $47$ fully-connected features, $47$ being the maximum number of dictionary elements that could be embedded onto the D-Wave $2$X hardware. Recent work suggests that the optimal level of sparsity corresponds to a critical value of the trade-off parameter associated with a putative second order phase transition, an observation supported by a free energy analysis of D-Wave energy states. When the sparse representations inferred by the D-Wave $2$X were passed to a linear support vector machine, we obtained a classification score of $95.68\%$. Thus, on this problem, we find that a single-layer of quantum inference is able to outperform a standard deep neural network architecture.



### Blocksworld Revisited: Learning and Reasoning to Generate Event-Sequences from Image Pairs
- **Arxiv ID**: http://arxiv.org/abs/1905.12042v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1905.12042v1)
- **Published**: 2019-05-28 19:26:19+00:00
- **Updated**: 2019-05-28 19:26:19+00:00
- **Authors**: Tejas Gokhale, Shailaja Sampat, Zhiyuan Fang, Yezhou Yang, Chitta Baral
- **Comment**: 10 pages, 5 figures, for associated dataset, see
  https://asu-active-perception-group.github.io/bird_dataset_web/
- **Journal**: None
- **Summary**: The process of identifying changes or transformations in a scene along with the ability of reasoning about their causes and effects, is a key aspect of intelligence. In this work we go beyond recent advances in computational perception, and introduce a more challenging task, Image-based Event-Sequencing (IES). In IES, the task is to predict a sequence of actions required to rearrange objects from the configuration in an input source image to the one in the target image. IES also requires systems to possess inductive generalizability. Motivated from evidence in cognitive development, we compile the first IES dataset, the Blocksworld Image Reasoning Dataset (BIRD) which contains images of wooden blocks in different configurations, and the sequence of moves to rearrange one configuration to the other. We first explore the use of existing deep learning architectures and show that these end-to-end methods under-perform in inferring temporal event-sequences and fail at inductive generalization. We then propose a modular two-step approach: Visual Perception followed by Event-Sequencing, and demonstrate improved performance by combining learning and reasoning. Finally, by showing an extension of our approach on natural images, we seek to pave the way for future research on event sequencing for real world scenes.



### Video-to-Video Translation for Visual Speech Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1905.12043v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.12043v1)
- **Published**: 2019-05-28 19:27:39+00:00
- **Updated**: 2019-05-28 19:27:39+00:00
- **Authors**: Michail C. Doukas, Viktoriia Sharmanska, Stefanos Zafeiriou
- **Comment**: None
- **Journal**: None
- **Summary**: Despite remarkable success in image-to-image translation that celebrates the advancements of generative adversarial networks (GANs), very limited attempts are known for video domain translation. We study the task of video-to-video translation in the context of visual speech generation, where the goal is to transform an input video of any spoken word to an output video of a different word. This is a multi-domain translation, where each word forms a domain of videos uttering this word. Adaptation of the state-of-the-art image-to-image translation model (StarGAN) to this setting falls short with a large vocabulary size. Instead we propose to use character encodings of the words and design a novel character-based GANs architecture for video-to-video translation called Visual Speech GAN (ViSpGAN). We are the first to demonstrate video-to-video translation with a vocabulary of 500 words.



### High Frequency Component Helps Explain the Generalization of Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.13545v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.13545v3)
- **Published**: 2019-05-28 19:42:04+00:00
- **Updated**: 2020-03-24 20:22:59+00:00
- **Authors**: Haohan Wang, Xindi Wu, Zeyi Huang, Eric P. Xing
- **Comment**: To appear at CVPR 2020 as an Oral paper
- **Journal**: None
- **Summary**: We investigate the relationship between the frequency spectrum of image data and the generalization behavior of convolutional neural networks (CNN). We first notice CNN's ability in capturing the high-frequency components of images. These high-frequency components are almost imperceptible to a human. Thus the observation leads to multiple hypotheses that are related to the generalization behaviors of CNN, including a potential explanation for adversarial examples, a discussion of CNN's trade-off between robustness and accuracy, and some evidence in understanding training heuristics.



### Information-Theoretic Registration with Explicit Reorientation of Diffusion-Weighted Images
- **Arxiv ID**: http://arxiv.org/abs/1905.12056v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.12056v4)
- **Published**: 2019-05-28 19:59:30+00:00
- **Updated**: 2021-07-09 13:58:21+00:00
- **Authors**: Henrik Grønholt Jensen, François Lauze, Sune Darkner
- **Comment**: 16 pages, 19 figures
- **Journal**: None
- **Summary**: We present an information-theoretic approach to the registration of images with directional information, and especially for diffusion-Weighted Images (DWI), with explicit optimization over the directional scale. We call it Locally Orderless Registration with Directions (LORD). We focus on normalized mutual information as a robust information-theoretic similarity measure for DWI. The framework is an extension of the LOR-DWI density-based hierarchical scale-space model that varies and optimizes the integration, spatial, directional, and intensity scales. As affine transformations are insufficient for inter-subject registration, we extend the model to non-rigid deformations. We illustrate that the proposed model deforms orientation distribution functions (ODFs) correctly and is capable of handling the classic complex challenges in DWI-registrations, such as the registration of fiber-crossings along with kissing, fanning, and interleaving fibers. Our experimental results clearly illustrate a novel promising regularizing effect, that comes from the nonlinear orientation-based cost function. We show the properties of the different image scales and, we show that including orientational information in our model makes the model better at retrieving deformations in contrast to standard scalar-based registration.



### Probabilistic Category-Level Pose Estimation via Segmentation and Predicted-Shape Priors
- **Arxiv ID**: http://arxiv.org/abs/1905.12079v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1905.12079v1)
- **Published**: 2019-05-28 20:37:00+00:00
- **Updated**: 2019-05-28 20:37:00+00:00
- **Authors**: Benjamin Burchfiel, George Konidaris
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a new method for category-level pose estimation which produces a distribution over predicted poses by integrating 3D shape estimates from a generative object model with segmentation information. Given an input depth-image of an object, our variable-time method uses a mixture density network architecture to produce a multi-modal distribution over 3DOF poses; this distribution is then combined with a prior probability encouraging silhouette agreement between the observed input and predicted object pose. Our approach significantly outperforms the current state-of-the-art in category-level 3DOF pose estimation---which outputs a point estimate and does not explicitly incorporate shape and segmentation information---as measured on the Pix3D and ShapeNet datasets.



### Memory Integrity of CNNs for Cross-Dataset Facial Expression Recognition
- **Arxiv ID**: http://arxiv.org/abs/1905.12082v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.12082v1)
- **Published**: 2019-05-28 20:55:57+00:00
- **Updated**: 2019-05-28 20:55:57+00:00
- **Authors**: Dylan C. Tannugi, Alceu S. Britto Jr., Alessandro L. Koerich
- **Comment**: None
- **Journal**: None
- **Summary**: Facial expression recognition is a major problem in the domain of artificial intelligence. One of the best ways to solve this problem is the use of convolutional neural networks (CNNs). However, a large amount of data is required to train properly these networks but most of the datasets available for facial expression recognition are relatively small. A common way to circumvent the lack of data is to use CNNs trained on large datasets of different domains and fine-tuning the layers of such networks to the target domain. However, the fine-tuning process does not preserve the memory integrity as CNNs have the tendency to forget patterns they have learned. In this paper, we evaluate different strategies of fine-tuning a CNN with the aim of assessing the memory integrity of such strategies in a cross-dataset scenario. A CNN pre-trained on a source dataset is used as the baseline and four adaptation strategies have been evaluated: fine-tuning its fully connected layers; fine-tuning its last convolutional layer and its fully connected layers; retraining the CNN on a target dataset; and the fusion of the source and target datasets and retraining the CNN. Experimental results on four datasets have shown that the fusion of the source and the target datasets provides the best trade-off between accuracy and memory integrity.



### LeagueAI: Improving object detector performance and flexibility through automatically generated training data and domain randomization
- **Arxiv ID**: http://arxiv.org/abs/1905.13546v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.13546v1)
- **Published**: 2019-05-28 21:07:22+00:00
- **Updated**: 2019-05-28 21:07:22+00:00
- **Authors**: Oliver Struckmeier
- **Comment**: None
- **Journal**: None
- **Summary**: In this technical report I present my method for automatic synthetic dataset generation for object detection and demonstrate it on the video game League of Legends. This report furthermore serves as a handbook on how to automatically generate datasets and as an introduction on the dataset generation part of the LeagueAI framework. The LeagueAI framework is a software framework that provides detailed information about the game League of Legends based on the same input a human player would have, namely vision. The framework allows researchers and enthusiasts to develop their own intelligent agents or to extract detailed information about the state of the game. A big problem of machine vision applications usually is the laborious work of gathering large amounts of hand labeled data. Thus, a crucial part of the vision pipeline of the LeagueAI framework, the dataset generation, is presented in this report. The method involves extracting image raw data from the game's 3D models and combining them with the game background to create game-like synthetic images and to generate the corresponding labels automatically. In an experiment I compared a model trained on synthetic data to a model trained on hand labeled data and a model trained on a combined dataset. The model trained on the synthetic data showed higher detection precision on more classes and more reliable tracking performance of the player character. The model trained on the combined dataset did not perform better because of the different formats of the older hand labeled dataset and the synthetic data.



### SpArSe: Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers
- **Arxiv ID**: http://arxiv.org/abs/1905.12107v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.12107v1)
- **Published**: 2019-05-28 21:52:08+00:00
- **Updated**: 2019-05-28 21:52:08+00:00
- **Authors**: Igor Fedorov, Ryan P. Adams, Matthew Mattina, Paul N. Whatmough
- **Comment**: None
- **Journal**: None
- **Summary**: The vast majority of processors in the world are actually microcontroller units (MCUs), which find widespread use performing simple control tasks in applications ranging from automobiles to medical devices and office equipment. The Internet of Things (IoT) promises to inject machine learning into many of these every-day objects via tiny, cheap MCUs. However, these resource-impoverished hardware platforms severely limit the complexity of machine learning models that can be deployed. For example, although convolutional neural networks (CNNs) achieve state-of-the-art results on many visual recognition tasks, CNN inference on MCUs is challenging due to severe finite memory limitations. To circumvent the memory challenge associated with CNNs, various alternatives have been proposed that do fit within the memory budget of an MCU, albeit at the cost of prediction accuracy. This paper challenges the idea that CNNs are not suitable for deployment on MCUs. We demonstrate that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs. Our Sparse Architecture Search method combines neural architecture search with pruning in a single, unified approach, which learns superior models on four popular IoT datasets. The CNNs we find are more accurate and up to $4.35\times$ smaller than previous approaches, while meeting the strict MCU working memory constraint.



### Deep Dilated Convolutional Nets for the Automatic Segmentation of Retinal Vessels
- **Arxiv ID**: http://arxiv.org/abs/1905.12120v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.12120v2)
- **Published**: 2019-05-28 22:37:00+00:00
- **Updated**: 2019-07-21 00:41:47+00:00
- **Authors**: Ali Hatamizadeh, Hamid Hosseini, Zhengyuan Liu, Steven D. Schwartz, Demetri Terzopoulos
- **Comment**: None
- **Journal**: None
- **Summary**: The reliable segmentation of retinal vasculature can provide the means to diagnose and monitor the progression of a variety of diseases affecting the blood vessel network, including diabetes and hypertension. We leverage the power of convolutional neural networks to devise a reliable and fully automated method that can accurately detect, segment, and analyze retinal vessels. In particular, we propose a novel, fully convolutional deep neural network with an encoder-decoder architecture that employs dilated spatial pyramid pooling with multiple dilation rates to recover the lost content in the encoder and add multiscale contextual information to the decoder. We also propose a simple yet effective way of quantifying and tracking the widths of retinal vessels through direct use of the segmentation predictions. Unlike previous deep-learning-based approaches to retinal vessel segmentation that mainly rely on patch-wise analysis, our proposed method leverages a whole-image approach during training and inference, resulting in more efficient training and faster inference through the access of global content in the image. We have tested our method on two publicly available datasets, and our state-of-the-art results on both the DRIVE and CHASE-DB1 datasets attest to the effectiveness of our approach.



### Autonomous Human Activity Classification from Ego-vision Camera and Accelerometer Data
- **Arxiv ID**: http://arxiv.org/abs/1905.13533v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.13533v1)
- **Published**: 2019-05-28 22:56:41+00:00
- **Updated**: 2019-05-28 22:56:41+00:00
- **Authors**: Yantao Lu, Senem Velipasalar
- **Comment**: Accepted for presentation at EPIC@CVPR2019 workshop
- **Journal**: None
- **Summary**: There has been significant amount of research work on human activity classification relying either on Inertial Measurement Unit (IMU) data or data from static cameras providing a third-person view. Using only IMU data limits the variety and complexity of the activities that can be detected. For instance, the sitting activity can be detected by IMU data, but it cannot be determined whether the subject has sat on a chair or a sofa, or where the subject is. To perform fine-grained activity classification from egocentric videos, and to distinguish between activities that cannot be differentiated by only IMU data, we present an autonomous and robust method using data from both ego-vision cameras and IMUs. In contrast to convolutional neural network-based approaches, we propose to employ capsule networks to obtain features from egocentric video data. Moreover, Convolutional Long Short Term Memory framework is employed both on egocentric videos and IMU data to capture temporal aspect of actions. We also propose a genetic algorithm-based approach to autonomously and systematically set various network parameters, rather than using manual settings. Experiments have been performed to perform 9- and 26-label activity classification, and the proposed method, using autonomously set network parameters, has provided very promising results, achieving overall accuracies of 86.6\% and 77.2\%, respectively. The proposed approach combining both modalities also provides increased accuracy compared to using only egovision data and only IMU data.



