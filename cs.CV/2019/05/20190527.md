# Arxiv Papers in cs.CV on 2019-05-27
### SpecNet: Spectral Domain Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1905.10915v6
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.10915v6)
- **Published**: 2019-05-27 00:44:14+00:00
- **Updated**: 2021-02-08 23:36:39+00:00
- **Authors**: Bochen Guan, Jinnian Zhang, William A. Sethares, Richard Kijowski, Fang Liu
- **Comment**: Accepted by ICASSP 21. Contact author: Bochen Guan
  (bochen.guan@gmail.com)
- **Journal**: None
- **Summary**: The memory consumption of most Convolutional Neural Network (CNN) architectures grows rapidly with increasing depth of the network, which is a major constraint for efficient network training on modern GPUs with limited memory, embedded systems, and mobile devices. Several studies show that the feature maps (as generated after the convolutional layers) are the main bottleneck in this memory problem. Often, these feature maps mimic natural photographs in the sense that their energy is concentrated in the spectral domain. Although embedding CNN architectures in the spectral domain is widely exploited to accelerate the training process, we demonstrate that it is also possible to use the spectral domain to reduce the memory footprint, a method we call Spectral Domain Convolutional Neural Network (SpecNet) that performs both the convolution and the activation operations in the spectral domain. The performance of SpecNet is evaluated on three competitive object recognition benchmark tasks (CIFAR-10, SVHN, and ImageNet), and compared with several state-of-the-art implementations. Overall, SpecNet is able to reduce memory consumption by about 60% without significant loss of performance for all tested networks.



### PNUNet: Anomaly Detection using Positive-and-Negative Noise based on Self-Training Procedure
- **Arxiv ID**: http://arxiv.org/abs/1905.10939v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.10939v1)
- **Published**: 2019-05-27 02:22:16+00:00
- **Updated**: 2019-05-27 02:22:16+00:00
- **Authors**: Masanari Kimura
- **Comment**: None
- **Journal**: None
- **Summary**: We propose the novel framework for anomaly detection in images. Our new framework, PNUNet, is based on many normal data and few anomalous data. We assume that some noises are added to the input images and learn to remove the noise. In addition, the proposed method achieves significant performance improvement by updating the noise assumed in the inputs using a self-training framework. The experimental results for the benchmark datasets show the usefulness of our new anomaly detection framework.



### Identity Connections in Residual Nets Improve Noise Stability
- **Arxiv ID**: http://arxiv.org/abs/1905.10944v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.10944v1)
- **Published**: 2019-05-27 02:52:46+00:00
- **Updated**: 2019-05-27 02:52:46+00:00
- **Authors**: Shuzhi Yu, Carlo Tomasi
- **Comment**: ICML 2019 Workshop on Understanding and Improving Generalization in
  Deep Learning, additional analysis on a property called Dominant Gradient
  Flow of Residual Nets in Appendix D
- **Journal**: None
- **Summary**: Residual Neural Networks (ResNets) achieve state-of-the-art performance in many computer vision problems. Compared to plain networks without residual connections (PlnNets), ResNets train faster, generalize better, and suffer less from the so-called degradation problem. We introduce simplified (but still nonlinear) versions of ResNets and PlnNets for which these discrepancies still hold, although to a lesser degree. We establish a 1-1 mapping between simplified ResNets and simplified PlnNets, and show that they are exactly equivalent to each other in expressive power for the same computational complexity. We conjecture that ResNets generalize better because they have better noise stability, and empirically support it for both simplified and fully-fledged networks.



### Transcribing Content from Structural Images with Spotlight Mechanism
- **Arxiv ID**: http://arxiv.org/abs/1905.10954v1
- **DOI**: 10.1145/3219819.3219962
- **Categories**: **cs.LG**, cs.CV, cs.SD, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.10954v1)
- **Published**: 2019-05-27 03:25:29+00:00
- **Updated**: 2019-05-27 03:25:29+00:00
- **Authors**: Yu Yin, Zhenya Huang, Enhong Chen, Qi Liu, Fuzheng Zhang, Xing Xie, Guoping Hu
- **Comment**: Accepted by KDD2018 Research Track. In proceedings of the 24th ACM
  SIGKDD International Conference on Knowledge Discovery and Data Mining
  (KDD'18)
- **Journal**: None
- **Summary**: Transcribing content from structural images, e.g., writing notes from music scores, is a challenging task as not only the content objects should be recognized, but the internal structure should also be preserved. Existing image recognition methods mainly work on images with simple content (e.g., text lines with characters), but are not capable to identify ones with more complex content (e.g., structured symbols), which often follow a fine-grained grammar. To this end, in this paper, we propose a hierarchical Spotlight Transcribing Network (STN) framework followed by a two-stage "where-to-what" solution. Specifically, we first decide "where-to-look" through a novel spotlight mechanism to focus on different areas of the original image following its structure. Then, we decide "what-to-write" by developing a GRU based network with the spotlight areas for transcribing the content accordingly. Moreover, we propose two implementations on the basis of STN, i.e., STNM and STNR, where the spotlight movement follows the Markov property and Recurrent modeling, respectively. We also design a reinforcement method to refine the framework by self-improving the spotlight mechanism. We conduct extensive experiments on many structural image datasets, where the results clearly demonstrate the effectiveness of STN framework.



### Computer-aided Detection of Squamous Carcinoma of the Cervix in Whole Slide Images
- **Arxiv ID**: http://arxiv.org/abs/1905.10959v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.10959v1)
- **Published**: 2019-05-27 03:53:18+00:00
- **Updated**: 2019-05-27 03:53:18+00:00
- **Authors**: Ye Tian, Li Yang, Wei Wang, Jing Zhang, Qing Tang, Mili Ji, Yang Yu, Yu Li, Hong Yang, Airong Qian
- **Comment**: 8 pages, 5figures
- **Journal**: None
- **Summary**: Goal: Squamous cell carcinoma of cervix is one of the most prevalent cancer worldwide in females. Traditionally, the most indispensable diagnosis of cervix squamous carcinoma is histopathological assessment which is achieved under microscope by pathologist. However, human evaluation of pathology slide is highly depending on the experience of pathologist, thus big inter- and intra-observer variability exists. Digital pathology, in combination with deep learning provides an opportunity to improve the objectivity and efficiency of histopathologic slide analysis. Methods: In this study, we obtained 800 haematoxylin and eosin stained slides from 300 patients suffered from cervix squamous carcinoma. Based on information from morphological heterogeneity in the tumor and its adjacent area, we established deep learning models using popular convolution neural network architectures (inception-v3, InceptionResnet-v2 and Resnet50). Then random forest was introduced to feature extractions and slide-based classification. Results: The overall performance of our proposed models on slide-based tumor discrimination were outstanding with an AUC scores > 0.94. While, location identifications of lesions in whole slide images were mediocre (FROC scores > 0.52) duo to the extreme complexity of tumor tissues. Conclusion: For the first time, our analysis workflow highlighted a quantitative visual-based slide analysis of cervix squamous carcinoma. Significance: This study demonstrates a pathway to assist pathologist and accelerate the diagnosis of patients by utilizing new computational approaches.



### Style transfer-based image synthesis as an efficient regularization technique in deep learning
- **Arxiv ID**: http://arxiv.org/abs/1905.10974v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.10974v1)
- **Published**: 2019-05-27 04:56:39+00:00
- **Updated**: 2019-05-27 04:56:39+00:00
- **Authors**: Agnieszka Mikołajczyk, Michał Grochowski
- **Comment**: 6 pages, 4 figures, accepted to the 24th International Conference on
  Methods and Models in Automation and Robotics (MMAR 2019)
- **Journal**: None
- **Summary**: These days deep learning is the fastest-growing area in the field of Machine Learning. Convolutional Neural Networks are currently the main tool used for image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is relatively poor generalization abilities. Partial remedies for this are regularization techniques e.g. dropout, batch normalization, weight decay, transfer learning, early stopping and data augmentation. In this paper, we have focused on data augmentation. We propose to use a method based on a neural style transfer, which allows generating new unlabeled images of a high perceptual quality that combine the content of a base image with the appearance of another one. In a proposed approach, the newly created images are described with pseudo-labels, and then used as a training dataset. Real, labeled images are divided into the validation and test set. We validated the proposed method on a challenging skin lesion classification case study. Four representative neural architectures are examined. Obtained results show the strong potential of the proposed approach.



### Deep Multi-Index Hashing for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1905.10980v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.10980v1)
- **Published**: 2019-05-27 05:26:59+00:00
- **Updated**: 2019-05-27 05:26:59+00:00
- **Authors**: Ming-Wei Li, Qing-Yuan Jiang, Wu-Jun Li
- **Comment**: 10 pages, 6 figures, 2 tables
- **Journal**: None
- **Summary**: Traditional person re-identification (ReID) methods typically represent person images as real-valued features, which makes ReID inefficient when the gallery set is extremely large. Recently, some hashing methods have been proposed to make ReID more efficient. However, these hashing methods will deteriorate the accuracy in general, and the efficiency of them is still not high enough. In this paper, we propose a novel hashing method, called deep multi-index hashing (DMIH), to improve both efficiency and accuracy for ReID. DMIH seamlessly integrates multi-index hashing and multi-branch based networks into the same framework. Furthermore, a novel block-wise multi-index hashing table construction approach and a search-aware multi-index (SAMI) loss are proposed in DMIH to improve the search efficiency. Experiments on three widely used datasets show that DMIH can outperform other state-of-the-art baselines, including both hashing methods and real-valued methods, in terms of both efficiency and accuracy.



### An Intelligent Monitoring System of Vehicles on Highway Traffic
- **Arxiv ID**: http://arxiv.org/abs/1905.10982v1
- **DOI**: 10.1109/ICOSST.2018.8632192
- **Categories**: **cs.CV**, cs.AI, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1905.10982v1)
- **Published**: 2019-05-27 05:45:56+00:00
- **Updated**: 2019-05-27 05:45:56+00:00
- **Authors**: Sulaiman Khan, Hazrat Ali, Zia Ullah, Mohammad Farhad Bulbul
- **Comment**: 5 pages
- **Journal**: 2018 12th International Conference on Open Source Systems and
  Technologies (ICOSST), Lahore, Pakistan, 2018, pp. 71-75
- **Summary**: Vehicle speed monitoring and management of highways is the critical problem of the road in this modern age of growing technology and population. A poor management results in frequent traffic jam, traffic rules violation and fatal road accidents. Using traditional techniques of RADAR, LIDAR and LASAR to address this problem is time-consuming, expensive and tedious. This paper presents an efficient framework to produce a simple, cost efficient and intelligent system for vehicle speed monitoring. The proposed method uses an HD (High Definition) camera mounted on the road side either on a pole or on a traffic signal for recording video frames. On the basis of these frames, a vehicle can be tracked by using radius growing method, and its speed can be calculated by calculating vehicle mask and its displacement in consecutive frames. The method uses pattern recognition, digital image processing and mathematical techniques for vehicle detection, tracking and speed calculation. The validity of the proposed model is proved by testing it on different highways.



### Ordinal Distribution Regression for Gait-based Age Estimation
- **Arxiv ID**: http://arxiv.org/abs/1905.11005v4
- **DOI**: 10.1007/s11432-019-2733-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11005v4)
- **Published**: 2019-05-27 07:07:56+00:00
- **Updated**: 2020-01-31 04:20:07+00:00
- **Authors**: Haiping Zhu, Yuheng Zhang, Guohao Li, Junping Zhang, Hongming Shan
- **Comment**: Accepted by the journal of "SCIENCE CHINA Information Sciences"
- **Journal**: Haiping Z, Yuheng Z, Guohao L, et al. Ordinal distribution
  regression for gait-based age estimation[J]. SCIENCE CHINA Information
  Sciences, 2020
- **Summary**: Computer vision researchers prefer to estimate age from face images because facial features provide useful information. However, estimating age from face images becomes challenging when people are distant from the camera or occluded. A person's gait is a unique biometric feature that can be perceived efficiently even at a distance. Thus, gait can be used to predict age when face images are not available. However, existing gait-based classification or regression methods ignore the ordinal relationship of different ages, which is an important clue for age estimation. This paper proposes an ordinal distribution regression with a global and local convolutional neural network for gait-based age estimation. Specifically, we decompose gait-based age regression into a series of binary classifications to incorporate the ordinal age information. Then, an ordinal distribution loss is proposed to consider the inner relationships among these classifications by penalizing the distribution discrepancy between the estimated value and the ground truth. In addition, our neural network comprises a global and three local sub-networks, and thus, is capable of learning the global structure and local details from the head, body, and feet. Experimental results indicate that the proposed approach outperforms state-of-the-art gait-based age estimation methods on the OULP-Age dataset.



### Fooling Detection Alone is Not Enough: First Adversarial Attack against Multiple Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1905.11026v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1905.11026v2)
- **Published**: 2019-05-27 07:55:05+00:00
- **Updated**: 2019-05-30 06:29:59+00:00
- **Authors**: Yunhan Jia, Yantao Lu, Junjie Shen, Qi Alfred Chen, Zhenyu Zhong, Tao Wei
- **Comment**: None
- **Journal**: None
- **Summary**: Recent work in adversarial machine learning started to focus on the visual perception in autonomous driving and studied Adversarial Examples (AEs) for object detection models. However, in such visual perception pipeline the detected objects must also be tracked, in a process called Multiple Object Tracking (MOT), to build the moving trajectories of surrounding obstacles. Since MOT is designed to be robust against errors in object detection, it poses a general challenge to existing attack techniques that blindly target objection detection: we find that a success rate of over 98% is needed for them to actually affect the tracking results, a requirement that no existing attack technique can satisfy. In this paper, we are the first to study adversarial machine learning attacks against the complete visual perception pipeline in autonomous driving, and discover a novel attack technique, tracker hijacking, that can effectively fool MOT using AEs on object detection. Using our technique, successful AEs on as few as one single frame can move an existing object in to or out of the headway of an autonomous vehicle to cause potential safety hazards. We perform evaluation using the Berkeley Deep Drive dataset and find that on average when 3 frames are attacked, our attack can have a nearly 100% success rate while attacks that blindly target object detection only have up to 25%.



### Unsupervised Learning of Anomaly Detection from Contaminated Image Data using Simultaneous Encoder Training
- **Arxiv ID**: http://arxiv.org/abs/1905.11034v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11034v2)
- **Published**: 2019-05-27 08:22:55+00:00
- **Updated**: 2019-11-20 12:49:09+00:00
- **Authors**: Amanda Berg, Jörgen Ahlberg, Michael Felsberg
- **Comment**: None
- **Journal**: None
- **Summary**: Unsupervised learning of anomaly detection in high-dimensional data, such as images, is a challenging problem recently subject to intense research. Through careful modelling of the data distribution of normal samples, it is possible to detect deviant samples, so called anomalies. Generative Adversarial Networks (GANs) can model the highly complex, high-dimensional data distribution of normal image samples, and have shown to be a suitable approach to the problem. Previously published GAN-based anomaly detection methods often assume that anomaly-free data is available for training. However, this assumption is not valid in most real-life scenarios, a.k.a. in the wild. In this work, we evaluate the effects of anomaly contaminations in the training data on state-of-the-art GAN-based anomaly detection methods. As expected, detection performance deteriorates. To address this performance drop, we propose to add an additional encoder network already at training time and show that joint generator-encoder training stratifies the latent space, mitigating the problem with contaminated data. We show experimentally that the norm of a query image in this stratified latent space becomes a highly significant cue to discriminate anomalies from normal data. The proposed method achieves state-of-the-art performance on CIFAR-10 as well as on a large, previously untested dataset with cell images.



### Attention Based Image Compression Post-Processing Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1905.11045v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11045v1)
- **Published**: 2019-05-27 08:49:10+00:00
- **Updated**: 2019-05-27 08:49:10+00:00
- **Authors**: Yuyang Xue, Jiannan Su
- **Comment**: 4 pages, 2 figures, CVPR Compression Workshop
- **Journal**: None
- **Summary**: The traditional image compressors, e.g., BPG and H.266, have achieved great image and video compression quality. Recently, Convolutional Neural Network has been used widely in image compression. We proposed an attention-based convolutional neural network for low bit-rate compression to post-process the output of traditional image compression decoder. Across the experimental results on validation sets, the post-processing module trained by MAE and MS-SSIM losses yields the highest PSNR of 32.10 on average at the bit-rate of 0.15.



### Learning to Auto Weight: Entirely Data-driven and Highly Efficient Weighting Framework
- **Arxiv ID**: http://arxiv.org/abs/1905.11058v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11058v3)
- **Published**: 2019-05-27 09:05:28+00:00
- **Updated**: 2019-11-26 05:39:17+00:00
- **Authors**: Zhenmao Li, Yichao Wu, Ken Chen, Yudong Wu, Shunfeng Zhou, Jiaheng Liu, Junjie Yan
- **Comment**: Accepted by AAAI 2020
- **Journal**: None
- **Summary**: Example weighting algorithm is an effective solution to the training bias problem, however, most previous typical methods are usually limited to human knowledge and require laborious tuning of hyperparameters. In this paper, we propose a novel example weighting framework called Learning to Auto Weight (LAW). The proposed framework finds step-dependent weighting policies adaptively, and can be jointly trained with target networks without any assumptions or prior knowledge about the dataset. It consists of three key components: Stage-based Searching Strategy (3SM) is adopted to shrink the huge searching space in a complete training process; Duplicate Network Reward (DNR) gives more accurate supervision by removing randomness during the searching process; Full Data Update (FDU) further improves the updating efficiency. Experimental results demonstrate the superiority of weighting policy explored by LAW over standard training pipeline. Compared with baselines, LAW can find a better weighting schedule which achieves much more superior accuracy on both biased CIFAR and ImageNet.



### Fourier-based Rotation-invariant Feature Boosting: An Efficient Framework for Geospatial Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1905.11074v1
- **DOI**: 10.1109/LGRS.2019.2919755
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11074v1)
- **Published**: 2019-05-27 09:25:47+00:00
- **Updated**: 2019-05-27 09:25:47+00:00
- **Authors**: Xin Wu, Danfeng Hong, Jocelyn Chanussot, Yang Xu, Ran Tao, Yue Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Geospatial object detection of remote sensing imagery has been attracting an increasing interest in recent years, due to the rapid development in spaceborne imaging. Most of previously proposed object detectors are very sensitive to object deformations, such as scaling and rotation. To this end, we propose a novel and efficient framework for geospatial object detection in this letter, called Fourier-based rotation-invariant feature boosting (FRIFB). A Fourier-based rotation-invariant feature is first generated in polar coordinate. Then, the extracted features can be further structurally refined using aggregate channel features. This leads to a faster feature computation and more robust feature representation, which is good fitting for the coming boosting learning. Finally, in the test phase, we achieve a fast pyramid feature extraction by estimating a scale factor instead of directly collecting all features from image pyramid. Extensive experiments are conducted on two subsets of NWPU VHR-10 dataset, demonstrating the superiority and effectiveness of the FRIFB compared to previous state-of-the-art methods.



### Cumulative link models for deep ordinal classification
- **Arxiv ID**: http://arxiv.org/abs/1905.13392v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.13392v2)
- **Published**: 2019-05-27 10:21:47+00:00
- **Updated**: 2019-10-10 11:46:18+00:00
- **Authors**: Víctor-Manuel Vargas, Pedro-Antonio Gutiérrez, César Hervás-Martínez
- **Comment**: 24 pages, 3 figures. Submitted to Neurocomputing
- **Journal**: None
- **Summary**: This paper proposes a deep convolutional neural network model for ordinal regression by considering a family of probabilistic ordinal link functions in the output layer. The link functions are those used for cumulative link models, which are traditional statistical linear models based on projecting each pattern into a 1-dimensional space. A set of ordered thresholds splits this space into the different classes of the problem. In our case, the projections are estimated by a non-linear deep neural network. To further improve the results, we combine these ordinal models with a loss function that takes into account the distance between the categories, based on the weighted Kappa index. Three different link functions are studied in the experimental study, and the results are contrasted with statistical analysis. The experiments run over two different ordinal classification problems and the statistical tests confirm that these models improve the results of a nominal model and outperform other robust proposals considered in the literature.



### FUNSD: A Dataset for Form Understanding in Noisy Scanned Documents
- **Arxiv ID**: http://arxiv.org/abs/1905.13538v2
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.13538v2)
- **Published**: 2019-05-27 10:40:40+00:00
- **Updated**: 2019-10-29 15:46:39+00:00
- **Authors**: Guillaume Jaume, Hazim Kemal Ekenel, Jean-Philippe Thiran
- **Comment**: ICDAR'19 OST workshop
- **Journal**: None
- **Summary**: We present a new dataset for form understanding in noisy scanned documents (FUNSD) that aims at extracting and structuring the textual content of forms. The dataset comprises 199 real, fully annotated, scanned forms. The documents are noisy and vary widely in appearance, making form understanding (FoUn) a challenging task. The proposed dataset can be used for various tasks, including text detection, optical character recognition, spatial layout analysis, and entity labeling/linking. To the best of our knowledge, this is the first publicly available dataset with comprehensive annotations to address FoUn task. We also present a set of baselines and introduce metrics to evaluate performance on the FUNSD dataset, which can be downloaded at https://guillaumejaume.github.io/FUNSD/.



### Finding Task-Relevant Features for Few-Shot Learning by Category Traversal
- **Arxiv ID**: http://arxiv.org/abs/1905.11116v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1905.11116v1)
- **Published**: 2019-05-27 10:55:51+00:00
- **Updated**: 2019-05-27 10:55:51+00:00
- **Authors**: Hongyang Li, David Eigen, Samuel Dodge, Matthew Zeiler, Xiaogang Wang
- **Comment**: CVPR 2019
- **Journal**: None
- **Summary**: Few-shot learning is an important area of research. Conceptually, humans are readily able to understand new concepts given just a few examples, while in more pragmatic terms, limited-example training situations are common in practice. Recent effective approaches to few-shot learning employ a metric-learning framework to learn a feature similarity comparison between a query (test) example, and the few support (training) examples. However, these approaches treat each support class independently from one another, never looking at the entire task as a whole. Because of this, they are constrained to use a single set of features for all possible test-time tasks, which hinders the ability to distinguish the most relevant dimensions for the task at hand. In this work, we introduce a Category Traversal Module that can be inserted as a plug-and-play module into most metric-learning based few-shot learners. This component traverses across the entire support set at once, identifying task-relevant features based on both intra-class commonality and inter-class uniqueness in the feature space. Incorporating our module improves performance considerably (5%-10% relative) over baseline systems on both mini-ImageNet and tieredImageNet benchmarks, with overall performance competitive with recent state-of-the-art systems.



### SCAN: A Scalable Neural Networks Framework Towards Compact and Efficient Models
- **Arxiv ID**: http://arxiv.org/abs/1906.03951v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1906.03951v1)
- **Published**: 2019-05-27 11:11:01+00:00
- **Updated**: 2019-05-27 11:11:01+00:00
- **Authors**: Linfeng Zhang, Zhanhong Tan, Jiebo Song, Jingwei Chen, Chenglong Bao, Kaisheng Ma
- **Comment**: None
- **Journal**: None
- **Summary**: Remarkable achievements have been attained by deep neural networks in various applications. However, the increasing depth and width of such models also lead to explosive growth in both storage and computation, which has restricted the deployment of deep neural networks on resource-limited edge devices. To address this problem, we propose the so-called SCAN framework for networks training and inference, which is orthogonal and complementary to existing acceleration and compression methods. The proposed SCAN firstly divides neural networks into multiple sections according to their depth and constructs shallow classifiers upon the intermediate features of different sections. Moreover, attention modules and knowledge distillation are utilized to enhance the accuracy of shallow classifiers. Based on this architecture, we further propose a threshold controlled scalable inference mechanism to approach human-like sample-specific inference. Experimental results show that SCAN can be easily equipped on various neural networks without any adjustment on hyper-parameters or neural networks architectures, yielding significant performance gain on CIFAR100 and ImageNet. Codes will be released on github soon.



### Learning to Detect and Retrieve Objects from Unlabeled Videos
- **Arxiv ID**: http://arxiv.org/abs/1905.11137v2
- **DOI**: None
- **Categories**: **cs.CV**, I.2.10; I.4; I.5
- **Links**: [PDF](http://arxiv.org/pdf/1905.11137v2)
- **Published**: 2019-05-27 11:36:32+00:00
- **Updated**: 2019-10-19 07:26:57+00:00
- **Authors**: Elad Amrani, Rami Ben-Ari, Tal Hakim, Alex Bronstein
- **Comment**: ICCV 2019 Workshop on Multi-modal Video Analysis and Moments in Time
  Challenge
- **Journal**: None
- **Summary**: Learning an object detector or retrieval requires a large data set with manual annotations. Such data sets are expensive and time consuming to create and therefore difficult to obtain on a large scale. In this work, we propose to exploit the natural correlation in narrations and the visual presence of objects in video, to learn an object detector and retrieval without any manual labeling involved. We pose the problem as weakly supervised learning with noisy labels, and propose a novel object detection paradigm under these constraints. We handle the background rejection by using contrastive samples and confront the high level of label noise with a new clustering score. Our evaluation is based on a set of 11 manually annotated objects in over 5000 frames. We show comparison to a weakly-supervised approach as baseline and provide a strongly labeled upper bound.



### Label Prediction Framework for Semi-Supervised Cross-Modal Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1905.11139v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1905.11139v1)
- **Published**: 2019-05-27 11:39:15+00:00
- **Updated**: 2019-05-27 11:39:15+00:00
- **Authors**: Devraj Mandal, Pramod Rao, Soma Biswas
- **Comment**: 12 pages, 3 tables, 2 figures, 1 algorithm flowchart
- **Journal**: None
- **Summary**: Cross-modal data matching refers to retrieval of data from one modality, when given a query from another modality. In general, supervised algorithms achieve better retrieval performance compared to their unsupervised counterpart, as they can learn better representative features by leveraging the available label information. However, this comes at the cost of requiring huge amount of labeled examples, which may not always be available. In this work, we propose a novel framework in a semi-supervised setting, which can predict the labels of the unlabeled data using complementary information from different modalities. The proposed framework can be used as an add-on with any baseline crossmodal algorithm to give significant performance improvement, even in case of limited labeled data. Finally, we analyze the challenging scenario where the unlabeled examples can even come from classes not in the training data and evaluate the performance of our algorithm under such setting. Extensive evaluation using several baseline algorithms across three different datasets shows the effectiveness of our label prediction framework.



### Audio2Face: Generating Speech/Face Animation from Single Audio with Attention-Based Bidirectional LSTM Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11142v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.SD, eess.AS, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11142v1)
- **Published**: 2019-05-27 11:40:21+00:00
- **Updated**: 2019-05-27 11:40:21+00:00
- **Authors**: Guanzhong Tian, Yi Yuan, Yong liu
- **Comment**: None
- **Journal**: None
- **Summary**: We propose an end to end deep learning approach for generating real-time facial animation from just audio. Specifically, our deep architecture employs deep bidirectional long short-term memory network and attention mechanism to discover the latent representations of time-varying contextual information within the speech and recognize the significance of different information contributed to certain face status. Therefore, our model is able to drive different levels of facial movements at inference and automatically keep up with the corresponding pitch and latent speaking style in the input audio, with no assumption or further human intervention. Evaluation results show that our method could not only generate accurate lip movements from audio, but also successfully regress the speaker's time-varying facial movements.



### Breast mass classification in ultrasound based on Kendall's shape manifold
- **Arxiv ID**: http://arxiv.org/abs/1905.11159v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1905.11159v1)
- **Published**: 2019-05-27 12:15:43+00:00
- **Updated**: 2019-05-27 12:15:43+00:00
- **Authors**: Michal Byra, Michael Andre
- **Comment**: 4 pages, 3 figures
- **Journal**: None
- **Summary**: Morphological features play an important role in breast mass classification in sonography. While benign breast masses tend to have a well-defined ellipsoidal contour, shape of malignant breast masses is commonly ill-defined and highly variable. Various handcrafted morphological features have been developed over the years to assess this phenomenon and help the radiologists differentiate benign and malignant masses. In this paper we propose an automatic approach to morphology analysis, we express shapes of breast masses as points on the Kendall's shape manifold. Next, we use the full Procrustes distance to develop support vector machine classifiers for breast mass differentiation. The usefulness of our method is demonstrated using a dataset of B-mode images collected from 163 breast masses. Our method achieved area under the receiver operating characteristic curve of 0.81. The proposed method can be used to assess shapes of breast masses in ultrasound without any feature engineering.



### Giant Panda Face Recognition Using Small Dataset
- **Arxiv ID**: http://arxiv.org/abs/1905.11163v1
- **DOI**: 10.1109/ICIP.2019.8803125
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11163v1)
- **Published**: 2019-05-27 12:22:31+00:00
- **Updated**: 2019-05-27 12:22:31+00:00
- **Authors**: Wojciech Michal Matkowski, Adams Wai Kin Kong, Han Su, Peng Chen, Rong Hou, Zhihe Zhang
- **Comment**: Accepted in the IEEE 2019 International Conference on Image
  Processing (ICIP 2019), scheduled for 22-25 September 2019 in Taipei, Taiwan
- **Journal**: 2019 IEEE International Conference on Image Processing (ICIP)
- **Summary**: Giant panda (panda) is a highly endangered animal. Significant efforts and resources have been put on panda conservation. To measure effectiveness of conservation schemes, estimating its population size in wild is an important task. The current population estimation approaches, including capture-recapture, human visual identification and collection of DNA from hair or feces, are invasive, subjective, costly or even dangerous to the workers who perform these tasks in wild. Cameras have been widely installed in the regions where pandas live. It opens a new possibility for non-invasive image based panda recognition. Panda face recognition is naturally a small dataset problem, because of the number of pandas in the world and the number of qualified images captured by the cameras in each encounter. In this paper, a panda face recognition algorithm, which includes alignment, large feature set extraction and matching is proposed and evaluated on a dataset consisting of 163 images. The experimental results are encouraging.



### Unsupervised Object Segmentation by Redrawing
- **Arxiv ID**: http://arxiv.org/abs/1905.13539v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.13539v4)
- **Published**: 2019-05-27 12:34:55+00:00
- **Updated**: 2019-11-29 17:00:48+00:00
- **Authors**: Mickaël Chen, Thierry Artières, Ludovic Denoyer
- **Comment**: Presented at NeurIPS 2019
- **Journal**: None
- **Summary**: Object segmentation is a crucial problem that is usually solved by using supervised learning approaches over very large datasets composed of both images and corresponding object masks. Since the masks have to be provided at pixel level, building such a dataset for any new domain can be very time-consuming. We present ReDO, a new model able to extract objects from images without any annotation in an unsupervised way. It relies on the idea that it should be possible to change the textures or colors of the objects without changing the overall distribution of the dataset. Following this assumption, our approach is based on an adversarial architecture where the generator is guided by an input sample: given an image, it extracts the object mask, then redraws a new object at the same location. The generator is controlled by a discriminator that ensures that the distribution of generated images is aligned to the original one. We experiment with this method on different datasets and demonstrate the good quality of extracted masks.



### Physics-as-Inverse-Graphics: Unsupervised Physical Parameter Estimation from Video
- **Arxiv ID**: http://arxiv.org/abs/1905.11169v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11169v2)
- **Published**: 2019-05-27 12:37:14+00:00
- **Updated**: 2020-04-21 12:14:26+00:00
- **Authors**: Miguel Jaques, Michael Burke, Timothy Hospedales
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: We propose a model that is able to perform unsupervised physical parameter estimation of systems from video, where the differential equations governing the scene dynamics are known, but labeled states or objects are not available. Existing physical scene understanding methods require either object state supervision, or do not integrate with differentiable physics to learn interpretable system parameters and states. We address this problem through a physics-as-inverse-graphics approach that brings together vision-as-inverse-graphics and differentiable physics engines, enabling objects and explicit state and velocity representations to be discovered. This framework allows us to perform long term extrapolative video prediction, as well as vision-based model-predictive control. Our approach significantly outperforms related unsupervised methods in long-term future frame prediction of systems with interacting objects (such as ball-spring or 3-body gravitational systems), due to its ability to build dynamics into the model as an inductive bias. We further show the value of this tight vision-physics integration by demonstrating data-efficient learning of vision-actuated model-based control for a pendulum system. We also show that the controller's interpretability provides unique capabilities in goal-driven control and physical reasoning for zero-data adaptation.



### GRDN:Grouped Residual Dense Network for Real Image Denoising and GAN-based Real-world Noise Modeling
- **Arxiv ID**: http://arxiv.org/abs/1905.11172v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1905.11172v1)
- **Published**: 2019-05-27 12:39:32+00:00
- **Updated**: 2019-05-27 12:39:32+00:00
- **Authors**: Dong-Wook Kim, Jae Ryun Chung, Seung-Won Jung
- **Comment**: To appear in CVPR 2019 workshop. The winners of the NTIRE2019
  Challenge on Image Denoising Challenge: Track 2 sRGB
- **Journal**: None
- **Summary**: Recent research on image denoising has progressed with the development of deep learning architectures, especially convolutional neural networks. However, real-world image denoising is still very challenging because it is not possible to obtain ideal pairs of ground-truth images and real-world noisy images. Owing to the recent release of benchmark datasets, the interest of the image denoising community is now moving toward the real-world denoising problem. In this paper, we propose a grouped residual dense network (GRDN), which is an extended and generalized architecture of the state-of-the-art residual dense network (RDN). The core part of RDN is defined as grouped residual dense block (GRDB) and used as a building module of GRDN. We experimentally show that the image denoising performance can be significantly improved by cascading GRDBs. In addition to the network architecture design, we also develop a new generative adversarial network-based real-world noise modeling method. We demonstrate the superiority of the proposed methods by achieving the highest score in terms of both the peak signal-to-noise ratio and the structural similarity in the NTIRE2019 Real Image Denoising Challenge - Track 2:sRGB.



### The Chan-Vese Model with Elastica and Landmark Constraints for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1905.11192v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11192v2)
- **Published**: 2019-05-27 13:29:59+00:00
- **Updated**: 2019-08-07 05:43:31+00:00
- **Authors**: Jintao Song, Huizhu Pan, Wuanquan Liu, Zisen Xu, Zhenkuan Pan
- **Comment**: 17pages,9figure
- **Journal**: None
- **Summary**: In order to completely separate objects with large sections of occluded boundaries in an image, we devise a new variational level set model for image segmentation combining the Chan-Vese model with elastica and landmark constraints. For computational efficiency, we design its Augmented Lagrangian Method (ALM) or Alternating Direction Method of Multiplier (ADMM) method by introducing some auxiliary variables, Lagrange multipliers, and penalty parameters. In each loop of alternating iterative optimization, the sub-problems of minimization can be easily solved via the Gauss-Seidel iterative method and generalized soft thresholding formulas with projection, respectively. Numerical experiments show that the proposed model can not only recover larger broken boundaries but can also improve segmentation efficiency, as well as decrease the dependence of segmentation on parameter tuning and initialization.



### Derivative Manipulation for General Example Weighting
- **Arxiv ID**: http://arxiv.org/abs/1905.11233v10
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11233v10)
- **Published**: 2019-05-27 13:59:08+00:00
- **Updated**: 2020-10-03 19:00:18+00:00
- **Authors**: Xinshao Wang, Elyor Kodirov, Yang Hua, Neil M. Robertson
- **Comment**: None
- **Journal**: None
- **Summary**: Real-world large-scale datasets usually contain noisy labels and are imbalanced. Therefore, we propose derivative manipulation (DM), a novel and general example weighting approach for training robust deep models under these adverse conditions.   DM has two main merits. First, loss function and example weighting are common techniques in the literature. DM reveals their connection (a loss function does example weighting) and is a replacement of both. Second, despite that a loss defines an example weighting scheme by its derivative, in the loss design, we need to consider whether it is differentiable. Instead, DM is more flexible by directly modifying the derivative so that a loss can be a non-elementary format too. Technically, DM defines an emphasis density function by a derivative magnitude function. DM is generic in that diverse weighting schemes can be derived.   Extensive experiments on both vision and language tasks prove DM's effectiveness.



### Learning Occlusion-Aware View Synthesis for Light Fields
- **Arxiv ID**: http://arxiv.org/abs/1905.11271v1
- **DOI**: 10.1007/s10044-021-00956-2
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11271v1)
- **Published**: 2019-05-27 14:41:47+00:00
- **Updated**: 2019-05-27 14:41:47+00:00
- **Authors**: Julia Navarro, Neus Sabater
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we present a novel learning-based approach to synthesize new views of a light field image. In particular, given the four corner views of a light field, the presented method estimates any in-between view. We use three sequential convolutional neural networks for feature extraction, scene geometry estimation and view selection. Compared to state-of-the-art approaches, in order to handle occlusions we propose to estimate a different disparity map per view. Jointly with the view selection network, this strategy shows to be the most important to have proper reconstructions near object boundaries. Ablation studies and comparison against the state of the art on Lytro light fields show the superior performance of the proposed method. Furthermore, the method is adapted and tested on light fields with wide baselines acquired with a camera array and, in spite of having to deal with large occluded areas, the proposed approach yields very promising results.



### ImgSensingNet: UAV Vision Guided Aerial-Ground Air Quality Sensing System
- **Arxiv ID**: http://arxiv.org/abs/1905.11299v1
- **DOI**: None
- **Categories**: **cs.SY**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11299v1)
- **Published**: 2019-05-27 15:32:59+00:00
- **Updated**: 2019-05-27 15:32:59+00:00
- **Authors**: Yuzhe Yang, Zhiwen Hu, Kaigui Bian, Lingyang Song
- **Comment**: Preliminary version published in INFOCOM 2019. Code available at
  https://github.com/YyzHarry/ImgSensingNet
- **Journal**: None
- **Summary**: Given the increasingly serious air pollution problem, the monitoring of air quality index (AQI) in urban areas has drawn considerable attention. This paper presents ImgSensingNet, a vision guided aerial-ground sensing system, for fine-grained air quality monitoring and forecasting using the fusion of haze images taken by the unmanned-aerial-vehicle (UAV) and the AQI data collected by an on-ground three-dimensional (3D) wireless sensor network (WSN). Specifically, ImgSensingNet first leverages the computer vision technique to tell the AQI scale in different regions from the taken haze images, where haze-relevant features and a deep convolutional neural network (CNN) are designed for direct learning between haze images and corresponding AQI scale. Based on the learnt AQI scale, ImgSensingNet determines whether to wake up on-ground wireless sensors for small-scale AQI monitoring and inference, which can greatly reduce the energy consumption of the system. An entropy-based model is employed for accurate real-time AQI inference at unmeasured locations and future air quality distribution forecasting. We implement and evaluate ImgSensingNet on two university campuses since Feb. 2018, and has collected 17,630 photos and 2.6 millions of AQI data samples. Experimental results confirm that ImgSensingNet can achieve higher inference accuracy while greatly reduce the energy consumption, compared to state-of-the-art AQI monitoring approaches.



### Straight to Shapes++: Real-time Instance Segmentation Made More Accurate
- **Arxiv ID**: http://arxiv.org/abs/1905.11358v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11358v2)
- **Published**: 2019-05-27 17:35:19+00:00
- **Updated**: 2019-07-30 11:09:15+00:00
- **Authors**: Laurynas Miksys, Saumya Jetley, Michael Sapienza, Stuart Golodetz, Philip H. S. Torr
- **Comment**: Technical report, 27 pages (12 main, 15 supplementary), 17 figures,
  14 tables
- **Journal**: None
- **Summary**: Instance segmentation is an important problem in computer vision, with applications in autonomous driving, drone navigation and robotic manipulation. However, most existing methods are not real-time, complicating their deployment in time-sensitive contexts. In this work, we extend an existing approach to real-time instance segmentation, called `Straight to Shapes' (STS), which makes use of low-dimensional shape embedding spaces to directly regress to object shape masks. The STS model can run at 35 FPS on a high-end desktop, but its accuracy is significantly worse than that of offline state-of-the-art methods. We leverage recent advances in the design and training of deep instance segmentation models to improve the performance accuracy of the STS model whilst keeping its real-time capabilities intact. In particular, we find that parameter sharing, more aggressive data augmentation and the use of structured loss for shape mask prediction all provide a useful boost to the network performance. Our proposed approach, `Straight to Shapes++', achieves a remarkable 19.7 point improvement in mAP (at IOU of 0.5) over the original method as evaluated on the PASCAL VOC dataset, thus redefining the accuracy frontier at real-time speeds. Since the accuracy of instance segmentation is closely tied to that of object bounding box prediction, we also study the error profile of the latter and examine the failure modes of our method for future improvements.



### Object Discovery with a Copy-Pasting GAN
- **Arxiv ID**: http://arxiv.org/abs/1905.11369v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11369v1)
- **Published**: 2019-05-27 17:55:05+00:00
- **Updated**: 2019-05-27 17:55:05+00:00
- **Authors**: Relja Arandjelović, Andrew Zisserman
- **Comment**: None
- **Journal**: None
- **Summary**: We tackle the problem of object discovery, where objects are segmented for a given input image, and the system is trained without using any direct supervision whatsoever. A novel copy-pasting GAN framework is proposed, where the generator learns to discover an object in one image by compositing it into another image such that the discriminator cannot tell that the resulting image is fake. After carefully addressing subtle issues, such as preventing the generator from `cheating', this game results in the generator learning to select objects, as copy-pasting objects is most likely to fool the discriminator. The system is shown to work well on four very different datasets, including large object appearance variations in challenging cluttered backgrounds.



### Equivalent and Approximate Transformations of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11428v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11428v1)
- **Published**: 2019-05-27 18:05:28+00:00
- **Updated**: 2019-05-27 18:05:28+00:00
- **Authors**: Abhinav Kumar, Thiago Serra, Srikumar Ramalingam
- **Comment**: None
- **Journal**: None
- **Summary**: Two networks are equivalent if they produce the same output for any given input. In this paper, we study the possibility of transforming a deep neural network to another network with a different number of units or layers, which can be either equivalent, a local exact approximation, or a global linear approximation of the original network. On the practical side, we show that certain rectified linear units (ReLUs) can be safely removed from a network if they are always active or inactive for any valid input. If we only need an equivalent network for a smaller domain, then more units can be removed and some layers collapsed. On the theoretical side, we constructively show that for any feed-forward ReLU network, there exists a global linear approximation to a 2-hidden-layer shallow network with a fixed number of units. This result is a balance between the increasing number of units for arbitrary approximation with a single layer and the known upper bound of $\lceil log(n_0+1)\rceil +1$ layers for exact representation, where $n_0$ is the input dimension. While the transformed network may require an exponential number of units to capture the activation patterns of the original network, we show that it can be made substantially smaller by only accounting for the patterns that define linear regions. Based on experiments with ReLU networks on the MNIST dataset, we found that $l_1$-regularization and adversarial training reduces the number of linear regions significantly as the number of stable units increases due to weight sparsity. Therefore, we can also intentionally train ReLU networks to allow for effective loss-less compression and approximation.



### A Symmetric Encoder-Decoder with Residual Block for Infrared and Visible Image Fusion
- **Arxiv ID**: http://arxiv.org/abs/1905.11447v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11447v1)
- **Published**: 2019-05-27 18:51:23+00:00
- **Updated**: 2019-05-27 18:51:23+00:00
- **Authors**: Lihua Jian, Xiaomin Yang, Zheng Liu, Gwanggil Jeon, Mingliang Gao, David Chisholm
- **Comment**: None
- **Journal**: None
- **Summary**: In computer vision and image processing tasks, image fusion has evolved into an attractive research field. However, recent existing image fusion methods are mostly built on pixel-level operations, which may produce unacceptable artifacts and are time-consuming. In this paper, a symmetric encoder-decoder with a residual block (SEDR) for infrared and visible image fusion is proposed. For the training stage, the SEDR network is trained with a new dataset to obtain a fixed feature extractor. For the fusion stage, first, the trained model is utilized to extract the intermediate features and compensation features of two source images. Then, extracted intermediate features are used to generate two attention maps, which are multiplied to the input features for refinement. In addition, the compensation features generated by the first two convolutional layers are merged and passed to the corresponding deconvolutional layers. At last, the refined features are fused for decoding to reconstruct the final fused image. Experimental results demonstrate that the proposed fusion method (named as SEDRFuse) outperforms the state-of-the-art fusion methods in terms of both subjective and objective evaluations.



### Mixed Precision DNNs: All you need is a good parametrization
- **Arxiv ID**: http://arxiv.org/abs/1905.11452v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11452v3)
- **Published**: 2019-05-27 19:03:40+00:00
- **Updated**: 2020-05-22 17:02:41+00:00
- **Authors**: Stefan Uhlich, Lukas Mauch, Fabien Cardinaux, Kazuki Yoshiyama, Javier Alonso Garcia, Stephen Tiedemann, Thomas Kemp, Akira Nakamura
- **Comment**: International Conference on Learning Representations (ICLR) 2020;
  Source code at https://github.com/sony/ai-research-code
- **Journal**: None
- **Summary**: Efficient deep neural network (DNN) inference on mobile or embedded devices typically involves quantization of the network parameters and activations. In particular, mixed precision networks achieve better performance than networks with homogeneous bitwidth for the same size constraint. Since choosing the optimal bitwidths is not straight forward, training methods, which can learn them, are desirable. Differentiable quantization with straight-through gradients allows to learn the quantizer's parameters using gradient methods. We show that a suited parametrization of the quantizer is the key to achieve a stable training and a good final performance. Specifically, we propose to parametrize the quantizer with the step size and dynamic range. The bitwidth can then be inferred from them. Other parametrizations, which explicitly use the bitwidth, consistently perform worse. We confirm our findings with experiments on CIFAR-10 and ImageNet and we obtain mixed precision DNNs with learned quantization parameters, achieving state-of-the-art performance.



### Capsule Routing via Variational Bayes
- **Arxiv ID**: http://arxiv.org/abs/1905.11455v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11455v3)
- **Published**: 2019-05-27 19:08:42+00:00
- **Updated**: 2019-12-03 16:49:01+00:00
- **Authors**: Fabio De Sousa Ribeiro, Georgios Leontidis, Stefanos Kollias
- **Comment**: AAAI 2020 Accepted Paper
- **Journal**: None
- **Summary**: Capsule networks are a recently proposed type of neural network shown to outperform alternatives in challenging shape recognition tasks. In capsule networks, scalar neurons are replaced with capsule vectors or matrices, whose entries represent different properties of objects. The relationships between objects and their parts are learned via trainable viewpoint-invariant transformation matrices, and the presence of a given object is decided by the level of agreement among votes from its parts. This interaction occurs between capsule layers and is a process called routing-by-agreement. In this paper, we propose a new capsule routing algorithm derived from Variational Bayes for fitting a mixture of transforming gaussians, and show it is possible transform our capsule network into a Capsule-VAE. Our Bayesian approach addresses some of the inherent weaknesses of MLE based models such as the variance-collapse by modelling uncertainty over capsule pose parameters. We outperform the state-of-the-art on smallNORB using 50% fewer capsules than previously reported, achieve competitive performances on CIFAR-10, Fashion-MNIST, SVHN, and demonstrate significant improvement in MNIST to affNIST generalisation over previous works.



### Scaleable input gradient regularization for adversarial robustness
- **Arxiv ID**: http://arxiv.org/abs/1905.11468v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CR, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11468v2)
- **Published**: 2019-05-27 19:40:52+00:00
- **Updated**: 2019-10-04 14:12:34+00:00
- **Authors**: Chris Finlay, Adam M Oberman
- **Comment**: None
- **Journal**: None
- **Summary**: In this work we revisit gradient regularization for adversarial robustness with some new ingredients. First, we derive new per-image theoretical robustness bounds based on local gradient information. These bounds strongly motivate input gradient regularization. Second, we implement a scaleable version of input gradient regularization which avoids double backpropagation: adversarially robust ImageNet models are trained in 33 hours on four consumer grade GPUs. Finally, we show experimentally and through theoretical certification that input gradient regularization is competitive with adversarial training. Moreover we demonstrate that gradient regularization does not lead to gradient obfuscation or gradient masking.



### End-to-End Pore Extraction and Matching in Latent Fingerprints: Going Beyond Minutiae
- **Arxiv ID**: http://arxiv.org/abs/1905.11472v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11472v2)
- **Published**: 2019-05-27 19:44:51+00:00
- **Updated**: 2019-05-30 02:26:14+00:00
- **Authors**: Dinh-Luan Nguyen, Anil K. Jain
- **Comment**: Technical report
- **Journal**: None
- **Summary**: Latent fingerprint recognition is not a new topic but it has attracted a lot of attention from researchers in both academia and industry over the past 50 years. With the rapid development of pattern recognition techniques, automated fingerprint identification systems (AFIS) have become more and more ubiquitous. However, most AFIS are utilized for live-scan or rolled/slap prints while only a few systems can work on latent fingerprints with reasonable accuracy. The question of whether taking higher resolution scans of latent fingerprints and their rolled/slap mate prints could help improve the identification accuracy still remains an open question in the forensic community. Because pores are one of the most reliable features besides minutiae to identify latent fingerprints, we propose an end-to-end automatic pore extraction and matching system to analyze the utility of pores in latent fingerprint identification. Hence, this paper answers two questions in the latent fingerprint domain: (i) does the incorporation of pores as level-3 features improve the system performance significantly? and (ii) does the 1,000 ppi image resolution improve the recognition results? We believe that our proposed end-to-end pore extraction and matching system will be a concrete baseline for future latent AFIS development.



### FAN: Focused Attention Networks
- **Arxiv ID**: http://arxiv.org/abs/1905.11498v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11498v3)
- **Published**: 2019-05-27 20:41:53+00:00
- **Updated**: 2019-10-03 19:55:42+00:00
- **Authors**: Chu Wang, Babak Samari, Vladimir Kim, Siddhartha Chaudhuri, Kaleem Siddiqi
- **Comment**: None
- **Journal**: None
- **Summary**: Attention networks show promise for both vision and language tasks, by emphasizing relationships between constituent elements through weighting functions. Such elements could be regions in an image output by a region proposal network, or words in a sentence, represented by word embedding. Thus far the learning of attention weights has been driven solely by the minimization of task specific loss functions. We introduce a method for learning attention weights to better emphasize informative pair-wise relations between entities. The key component is a novel center-mass cross entropy loss, which can be applied in conjunction with the task specific ones. We further introduce a focused attention backbone to learn these attention weights for general tasks. We demonstrate that the focused supervision leads to improved attention distribution across meaningful entities, and that it enhances the representation by aggregating features from them. Our focused attention module leads to state-of-the-art recovery of relations in a relationship proposal task and boosts performance for various vision and language tasks.



### Body Shape Privacy in Images: Understanding Privacy and Preventing Automatic Shape Extraction
- **Arxiv ID**: http://arxiv.org/abs/1905.11503v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11503v3)
- **Published**: 2019-05-27 20:57:52+00:00
- **Updated**: 2020-10-22 11:15:45+00:00
- **Authors**: Hosnieh Sattar, Katharina Krombholz, Gerard Pons-Moll, Mario Fritz
- **Comment**: None
- **Journal**: Proc. of the IEEE European Conference on Computer Vision Workshops
  (ECCVW), CV-COPS@ECCV2020
- **Summary**: Modern approaches to pose and body shape estimation have recently achieved strong performance even under challenging real-world conditions. Even from a single image of a clothed person, a realistic looking body shape can be inferred that captures a users' weight group and body shape type well. This opens up a whole spectrum of applications -- in particular in fashion -- where virtual try-on and recommendation systems can make use of these new and automatized cues. However, a realistic depiction of the undressed body is regarded highly private and therefore might not be consented by most people. Hence, we ask if the automatic extraction of such information can be effectively evaded. While adversarial perturbations have been shown to be effective for manipulating the output of machine learning models -- in particular, end-to-end deep learning approaches -- state of the art shape estimation methods are composed of multiple stages. We perform the first investigation of different strategies that can be used to effectively manipulate the automatic shape estimation while preserving the overall appearance of the original image.



### Enhancing Salient Object Segmentation Through Attention
- **Arxiv ID**: http://arxiv.org/abs/1905.11522v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11522v1)
- **Published**: 2019-05-27 21:50:54+00:00
- **Updated**: 2019-05-27 21:50:54+00:00
- **Authors**: Anuj Pahuja, Avishek Majumder, Anirban Chakraborty, R. Venkatesh Babu
- **Comment**: CVPRW - Deep Vision 2019
- **Journal**: None
- **Summary**: Segmenting salient objects in an image is an important vision task with ubiquitous applications. The problem becomes more challenging in the presence of a cluttered and textured background, low resolution and/or low contrast images. Even though existing algorithms perform well in segmenting most of the object(s) of interest, they often end up segmenting false positives due to resembling salient objects in the background. In this work, we tackle this problem by iteratively attending to image patches in a recurrent fashion and subsequently enhancing the predicted segmentation mask. Saliency features are estimated independently for every image patch, which are further combined using an aggregation strategy based on a Convolutional Gated Recurrent Unit (ConvGRU) network. The proposed approach works in an end-to-end manner, removing background noise and false positives incrementally. Through extensive evaluation on various benchmark datasets, we show superior performance to the existing approaches without any post-processing.



### Improved Training Speed, Accuracy, and Data Utilization Through Loss Function Optimization
- **Arxiv ID**: http://arxiv.org/abs/1905.11528v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1905.11528v3)
- **Published**: 2019-05-27 22:24:21+00:00
- **Updated**: 2020-04-27 16:31:53+00:00
- **Authors**: Santiago Gonzalez, Risto Miikkulainen
- **Comment**: None
- **Journal**: Proceedings of the 2020 IEEE Congress on Evolutionary Computation
- **Summary**: As the complexity of neural network models has grown, it has become increasingly important to optimize their design automatically through metalearning. Methods for discovering hyperparameters, topologies, and learning rate schedules have lead to significant increases in performance. This paper shows that loss functions can be optimized with metalearning as well, and result in similar improvements. The method, Genetic Loss-function Optimization (GLO), discovers loss functions de novo, and optimizes them for a target task. Leveraging techniques from genetic programming, GLO builds loss functions hierarchically from a set of operators and leaf nodes. These functions are repeatedly recombined and mutated to find an optimal structure, and then a covariance-matrix adaptation evolutionary strategy (CMA-ES) is used to find optimal coefficients. Networks trained with GLO loss functions are found to outperform the standard cross-entropy loss on standard image classification tasks. Training with these new loss functions requires fewer steps, results in lower test error, and allows for smaller datasets to be used. Loss-function optimization thus provides a new dimension of metalearning, and constitutes an important step towards AutoML.



### CGaP: Continuous Growth and Pruning for Efficient Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1905.11533v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11533v2)
- **Published**: 2019-05-27 22:54:59+00:00
- **Updated**: 2019-05-29 17:07:50+00:00
- **Authors**: Xiaocong Du, Zheng Li, Yu Cao
- **Comment**: None
- **Journal**: None
- **Summary**: Today a canonical approach to reduce the computation cost of Deep Neural Networks (DNNs) is to pre-define an over-parameterized model before training to guarantee the learning capacity, and then prune unimportant learning units (filters and neurons) during training to improve model compactness. We argue it is unnecessary to introduce redundancy at the beginning of the training but then reduce redundancy for the ultimate inference model. In this paper, we propose a Continuous Growth and Pruning (CGaP) scheme to minimize the redundancy from the beginning. CGaP starts the training from a small network seed, then expands the model continuously by reinforcing important learning units, and finally prunes the network to obtain a compact and accurate model. As the growth phase favors important learning units, CGaP provides a clear learning purpose to the pruning phase. Experimental results on representative datasets and DNN architectures demonstrate that CGaP outperforms previous pruning-only approaches that deal with pre-defined structures. For VGG-19 on CIFAR-100 and SVHN datasets, CGaP reduces the number of parameters by 78.9% and 85.8%, FLOPs by 53.2% and 74.2%, respectively; For ResNet-110 On CIFAR-10, CGaP reduces 64.0% number of parameters and 63.3% FLOPs.



### Semantic Fisher Scores for Task Transfer: Using Objects to Classify Scenes
- **Arxiv ID**: http://arxiv.org/abs/1905.11539v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11539v1)
- **Published**: 2019-05-27 23:15:26+00:00
- **Updated**: 2019-05-27 23:15:26+00:00
- **Authors**: Mandar Dixit, Yunsheng Li, Nuno Vasconcelos
- **Comment**: 16 pages, 11 figures, accepted by TPAMI
- **Journal**: None
- **Summary**: The transfer of a neural network (CNN) trained to recognize objects to the task of scene classification is considered. A Bag-of-Semantics (BoS) representation is first induced, by feeding scene image patches to the object CNN, and representing the scene image by the ensuing bag of posterior class probability vectors (semantic posteriors). The encoding of the BoS with a Fisher vector(FV) is then studied. A link is established between the FV of any probabilistic model and the Q-function of the expectation-maximization(EM) algorithm used to estimate its parameters by maximum likelihood. A network implementation of the MFA Fisher Score (MFA-FS), denoted as the MFAFSNet, is finally proposed to enable end-to-end training. Experiments with various object CNNs and datasets show that the approach has state-of-the-art transfer performance. Somewhat surprisingly, the scene classification results are superior to those of a CNN explicitly trained for scene classification, using a large scene dataset (Places). This suggests that holistic analysis is insufficient for scene classification. The modeling of local object semantics appears to be at least equally important. The two approaches are also shown to be strongly complementary, leading to very large scene classification gains when combined, and outperforming all previous scene classification approaches by a sizeable margin



### Jointly Learning Structured Analysis Discriminative Dictionary and Analysis Multiclass Classifier
- **Arxiv ID**: http://arxiv.org/abs/1905.11543v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1905.11543v1)
- **Published**: 2019-05-27 23:52:46+00:00
- **Updated**: 2019-05-27 23:52:46+00:00
- **Authors**: Zhao Zhang, Weiming Jiang, Jie Qin, Li Zhang, Fanzhang Li, Min Zhang, Shuicheng Yan
- **Comment**: Accepted by IEEE TNNLS
- **Journal**: None
- **Summary**: In this paper, we propose an analysis mechanism based structured Analysis Discriminative Dictionary Learning (ADDL) framework. ADDL seamlessly integrates the analysis discriminative dictionary learning, analysis representation and analysis classifier training into a unified model. The applied analysis mechanism can make sure that the learnt dictionaries, representations and linear classifiers over different classes are independent and discriminating as much as possible. The dictionary is obtained by minimizing a reconstruction error and an analytical incoherence promoting term that encourages the sub-dictionaries associated with different classes to be independent. To obtain the representation coefficients, ADDL imposes a sparse l2,1-norm constraint on the coding coefficients instead of using l0 or l1-norm, since the l0 or l1-norm constraint applied in most existing DL criteria makes the training phase time consuming. The codes-extraction projection that bridges data with the sparse codes by extracting special features from the given samples is calculated via minimizing a sparse codes approximation term. Then we compute a linear classifier based on the approximated sparse codes by an analysis mechanism to simultaneously consider the classification and representation powers. Thus, the classification approach of our model is very efficient, because it can avoid the extra time-consuming sparse reconstruction process with trained dictionary for each new test data as most existing DL algorithms. Simulations on real image databases demonstrate that our ADDL model can obtain superior performance over other state-of-the-arts.



### Label Universal Targeted Attack
- **Arxiv ID**: http://arxiv.org/abs/1905.11544v2
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1905.11544v2)
- **Published**: 2019-05-27 23:53:00+00:00
- **Updated**: 2019-06-01 05:11:50+00:00
- **Authors**: Naveed Akhtar, Mohammad A. A. K. Jalwana, Mohammed Bennamoun, Ajmal Mian
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce Label Universal Targeted Attack (LUTA) that makes a deep model predict a label of attacker's choice for `any' sample of a given source class with high probability. Our attack stochastically maximizes the log-probability of the target label for the source class with first order gradient optimization, while accounting for the gradient moments. It also suppresses the leakage of attack information to the non-source classes for avoiding the attack suspicions. The perturbations resulting from our attack achieve high fooling ratios on the large-scale ImageNet and VGGFace models, and transfer well to the Physical World. Given full control over the perturbation scope in LUTA, we also demonstrate it as a tool for deep model autopsy. The proposed attack reveals interesting perturbation patterns and observations regarding the deep models.



