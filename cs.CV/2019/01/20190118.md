# Arxiv Papers in cs.CV on 2019-01-18
### SAML-QC: a Stochastic Assessment and Machine Learning based QC technique for Industrial Printing
- **Arxiv ID**: http://arxiv.org/abs/1901.07370v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.07370v1)
- **Published**: 2019-01-18 00:53:39+00:00
- **Updated**: 2019-01-18 00:53:39+00:00
- **Authors**: Azhar Hussain
- **Comment**: 7 Pages, 10 figures, 6 Tables
- **Journal**: None
- **Summary**: Recently, the advancement in industrial automation and high-speed printing has raised numerous challenges related to the printing quality inspection of final products. This paper proposes a machine vision based technique to assess the printing quality of text on industrial objects. The assessment is based on three quality defects such as text misalignment, varying printing shades, and misprinted text. The proposed scheme performs the quality inspection through stochastic assessment technique based on the second-order statistics of printing. First: the text-containing area on printed product is identified through image processing techniques. Second: the alignment testing of the identified text-containing area is performed. Third: optical character recognition is performed to divide the text into different small boxes and only the intensity value of each text-containing box is taken as a random variable and second-order statistics are estimated to determine the varying printing defects in the text under one, two and three sigma thresholds. Fourth: the K-Nearest Neighbors based supervised machine learning is performed to provide the stochastic process for misprinted text detection. Finally, the technique is deployed on an industrial image for the printing quality assessment with varying values of n and m. The results have shown that the proposed SAML-QC technique can perform real-time automated inspection for industrial printing.



### Good Similar Patches for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1901.06046v1
- **DOI**: 10.1109/WACV.2019.00205
- **Categories**: **cs.CV**, cs.GR, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1901.06046v1)
- **Published**: 2019-01-18 01:04:01+00:00
- **Updated**: 2019-01-18 01:04:01+00:00
- **Authors**: Si Lu
- **Comment**: 10 pages, 13 figures, 6 tables, IEEE WACV 2019
- **Journal**: None
- **Summary**: Patch-based denoising algorithms like BM3D have achieved outstanding performance. An important idea for the success of these methods is to exploit the recurrence of similar patches in an input image to estimate the underlying image structures. However, in these algorithms, the similar patches used for denoising are obtained via Nearest Neighbour Search (NNS) and are sometimes not optimal. First, due to the existence of noise, NNS can select similar patches with similar noise patterns to the reference patch. Second, the unreliable noisy pixels in digital images can bring a bias to the patch searching process and result in a loss of color fidelity in the final denoising result. We observe that given a set of good similar patches, their distribution is not necessarily centered at the noisy reference patch and can be approximated by a Gaussian component. Based on this observation, we present a patch searching method that clusters similar patch candidates into patch groups using Gaussian Mixture Model-based clustering, and selects the patch group that contains the reference patch as the final patches for denoising. We also use an unreliable pixel estimation algorithm to pre-process the input noisy images to further improve the patch searching. Our experiments show that our approach can better capture the underlying patch structures and can consistently enable the state-of-the-art patch-based denoising algorithms, such as BM3D, LPCA and PLOW, to better denoise images by providing them with patches found by our approach while without modifying these algorithms.



### Learning Mutually Local-global U-nets For High-resolution Retinal Lesion Segmentation in Fundus Images
- **Arxiv ID**: http://arxiv.org/abs/1901.06047v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06047v1)
- **Published**: 2019-01-18 01:05:48+00:00
- **Updated**: 2019-01-18 01:05:48+00:00
- **Authors**: Zizheng Yan, Xiaoguang Han, Changmiao Wang, Yuda Qiu, Zixiang Xiong, Shuguang Cui
- **Comment**: 4 pages, Accepted by ISBI 2019
- **Journal**: None
- **Summary**: Diabetic retinopathy is the most important complication of diabetes. Early diagnosis of retinal lesions helps to avoid visual loss or blindness. Due to high-resolution and small-size lesion regions, applying existing methods, such as U-Nets, to perform segmentation on fundus photography is very challenging. Although downsampling the input images could simplify the problem, it loses detailed information. Conducting patch-level analysis helps reaching fine-scale segmentation yet usually leads to misunderstanding as the lack of context information. In this paper, we propose an efficient network that combines them together, not only being aware of local details but also taking fully use of the context perceptions. This is implemented by integrating the decoder parts of a global-level U-net and a patch-level one. The two streams are jointly optimized, ensuring that they are enhanced mutually. Experimental results demonstrate our new framework significantly outperforms existing patch-based and global-based methods, especially when the lesion regions are scattered and small-scaled.



### IoT Device Fingerprint using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1902.01926v1
- **DOI**: 10.1109/IOTAIS.2018.8600824
- **Categories**: **cs.NI**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1902.01926v1)
- **Published**: 2019-01-18 03:28:44+00:00
- **Updated**: 2019-01-18 03:28:44+00:00
- **Authors**: Sandhya Aneja, Nagender Aneja, Md Shohidul Islam
- **Comment**: None
- **Journal**: None
- **Summary**: Device Fingerprinting (DFP) is the identification of a device without using its network or other assigned identities including IP address, Medium Access Control (MAC) address, or International Mobile Equipment Identity (IMEI) number. DFP identifies a device using information from the packets which the device uses to communicate over the network. Packets are received at a router and processed to extract the information. In this paper, we worked on the DFP using Inter Arrival Time (IAT). IAT is the time interval between the two consecutive packets received. This has been observed that the IAT is unique for a device because of different hardware and the software used for the device. The existing work on the DFP uses the statistical techniques to analyze the IAT and to further generate the information using which a device can be identified uniquely. This work presents a novel idea of DFP by plotting graphs of IAT for packets with each graph plotting 100 IATs and subsequently processing the resulting graphs for the identification of the device. This approach improves the efficiency to identify a device DFP due to achieved benchmark of the deep learning libraries in the image processing. We configured Raspberry Pi to work as a router and installed our packet sniffer application on the Raspberry Pi . The packet sniffer application captured the packet information from the connected devices in a log file. We connected two Apple devices iPad4 and iPhone 7 Plus to the router and created IAT graphs for these two devices. We used Convolution Neural Network (CNN) to identify the devices and observed the accuracy of 86.7%.



### DeepOtsu: Document Enhancement and Binarization using Iterative Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1901.06081v1
- **DOI**: 10.1016/j.patcog.2019.01.025
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06081v1)
- **Published**: 2019-01-18 04:23:51+00:00
- **Updated**: 2019-01-18 04:23:51+00:00
- **Authors**: Sheng He, Lambert Schomaker
- **Comment**: Accepted by Pattern Recognition
- **Journal**: None
- **Summary**: This paper presents a novel iterative deep learning framework and apply it for document enhancement and binarization. Unlike the traditional methods which predict the binary label of each pixel on the input image, we train the neural network to learn the degradations in document images and produce the uniform images of the degraded input images, which allows the network to refine the output iteratively. Two different iterative methods have been studied in this paper: recurrent refinement (RR) which uses the same trained neural network in each iteration for document enhancement and stacked refinement (SR) which uses a stack of different neural networks for iterative output refinement. Given the learned uniform and enhanced image, the binarization map can be easy to obtain by a global or local threshold. The experimental results on several public benchmark data sets show that our proposed methods provide a new clean version of the degraded image which is suitable for visualization and promising results of binarization using the global Otsu's threshold based on the enhanced images learned iteratively by the neural network.



### Linearized ADMM and Fast Nonlocal Denoising for Efficient Plug-and-Play Restoration
- **Arxiv ID**: http://arxiv.org/abs/1901.06110v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06110v1)
- **Published**: 2019-01-18 07:20:32+00:00
- **Updated**: 2019-01-18 07:20:32+00:00
- **Authors**: Unni V. S., Sanjay Ghosh, Kunal N. Chaudhury
- **Comment**: None
- **Journal**: None
- **Summary**: In plug-and-play image restoration, the regularization is performed using powerful denoisers such as nonlocal means (NLM) or BM3D. This is done within the framework of alternating direction method of multipliers (ADMM), where the regularization step is formally replaced by an off-the-shelf denoiser. Each plug-and-play iteration involves the inversion of the forward model followed by a denoising step. In this paper, we present a couple of ideas for improving the efficiency of the inversion and denoising steps. First, we propose to use linearized ADMM, which generally allows us to perform the inversion at a lower cost than standard ADMM. Moreover, we can easily incorporate hard constraints into the optimization framework as a result. Second, we develop a fast algorithm for doubly stochastic NLM, originally proposed by Sreehari et al. (IEEE TCI, 2016), which is about 80x faster than brute-force computation. This particular denoiser can be expressed as the proximal map of a convex regularizer and, as a consequence, we can guarantee convergence for linearized plug-and-play ADMM. We demonstrate the effectiveness of our proposals for super-resolution and single-photon imaging.



### CRDN: Cascaded Residual Dense Networks for Dynamic MR Imaging with Edge-enhanced Loss Constraint
- **Arxiv ID**: http://arxiv.org/abs/1901.06111v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06111v1)
- **Published**: 2019-01-18 07:22:48+00:00
- **Updated**: 2019-01-18 07:22:48+00:00
- **Authors**: Ziwen Ke, Shanshan Wang, Huitao Cheng, Leslie Ying, Qiegen Liu, Hairong Zheng, Dong Liang
- **Comment**: None
- **Journal**: None
- **Summary**: Dynamic magnetic resonance (MR) imaging has generated great research interest, as it can provide both spatial and temporal information for clinical diagnosis. However, slow imaging speed or long scanning time is still one of the challenges for dynamic MR imaging. Most existing methods reconstruct Dynamic MR images from incomplete k-space data under the guidance of compressed sensing (CS) or low rank theory, which suffer from long iterative reconstruction time. Recently, deep learning has shown great potential in accelerating dynamic MR. Our previous work proposed a dynamic MR imaging method with both k-space and spatial prior knowledge integrated via multi-supervised network training. Nevertheless, there was still a certain degree of smooth in the reconstructed images at high acceleration factors. In this work, we propose cascaded residual dense networks for dynamic MR imaging with edge-enhance loss constraint, dubbed as CRDN. Specifically, the cascaded residual dense networks fully exploit the hierarchical features from all the convolutional layers with both local and global feature fusion. We further utilize the total variation (TV) loss function, which has the edge enhancement properties, for training the networks.



### Fast High-Dimensional Kernel Filtering
- **Arxiv ID**: http://arxiv.org/abs/1901.06112v1
- **DOI**: 10.1109/LSP.2019.2891879
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06112v1)
- **Published**: 2019-01-18 07:24:28+00:00
- **Updated**: 2019-01-18 07:24:28+00:00
- **Authors**: Pravin Nair, Kunal N. Chaudhury
- **Comment**: None
- **Journal**: IEEE Signal Processing Letters 2019
- **Summary**: The bilateral and nonlocal means filters are instances of kernel-based filters that are popularly used in image processing. It was recently shown that fast and accurate bilateral filtering of grayscale images can be performed using a low-rank approximation of the kernel matrix. More specifically, based on the eigendecomposition of the kernel matrix, the overall filtering was approximated using spatial convolutions, for which efficient algorithms are available. Unfortunately, this technique cannot be scaled to high-dimensional data such as color and hyperspectral images. This is simply because one needs to compute/store a large matrix and perform its eigendecomposition in this case. We show how this problem can be solved using the Nystr\"om method, which is generally used for approximating the eigendecomposition of large matrices. The resulting algorithm can also be used for nonlocal means filtering. We demonstrate the effectiveness of our proposal for bilateral and nonlocal means filtering of color and hyperspectral images. In particular, our method is shown to be competitive with state-of-the-art fast algorithms, and moreover it comes with a theoretical guarantee on the approximation error.



### Multi-Object Tracking with Multiple Cues and Switcher-Aware Classification
- **Arxiv ID**: http://arxiv.org/abs/1901.06129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06129v1)
- **Published**: 2019-01-18 08:44:01+00:00
- **Updated**: 2019-01-18 08:44:01+00:00
- **Authors**: Weitao Feng, Zhihao Hu, Wei Wu, Junjie Yan, Wanli Ouyang
- **Comment**: 10 pages, 7 figures
- **Journal**: None
- **Summary**: In this paper, we propose a unified Multi-Object Tracking (MOT) framework learning to make full use of long term and short term cues for handling complex cases in MOT scenes. Besides, for better association, we propose switcher-aware classification (SAC), which takes the potential identity-switch causer (switcher) into consideration. Specifically, the proposed framework includes a Single Object Tracking (SOT) sub-net to capture short term cues, a re-identification (ReID) sub-net to extract long term cues and a switcher-aware classifier to make matching decisions using extracted features from the main target and the switcher. Short term cues help to find false negatives, while long term cues avoid critical mistakes when occlusion happens, and the SAC learns to combine multiple cues in an effective way and improves robustness. The method is evaluated on the challenging MOT benchmarks and achieves the state-of-the-art results.



### Backbone Can Not be Trained at Once: Rolling Back to Pre-trained Network for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1901.06140v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06140v1)
- **Published**: 2019-01-18 09:08:53+00:00
- **Updated**: 2019-01-18 09:08:53+00:00
- **Authors**: Youngmin Ro, Jongwon Choi, Dae Ung Jo, Byeongho Heo, Jongin Lim, Jin Young Choi
- **Comment**: Accepted to AAAI 2019
- **Journal**: None
- **Summary**: In person re-identification (ReID) task, because of its shortage of trainable dataset, it is common to utilize fine-tuning method using a classification network pre-trained on a large dataset. However, it is relatively difficult to sufficiently fine-tune the low-level layers of the network due to the gradient vanishing problem. In this work, we propose a novel fine-tuning strategy that allows low-level layers to be sufficiently trained by rolling back the weights of high-level layers to their initial pre-trained weights. Our strategy alleviates the problem of gradient vanishing in low-level layers and robustly trains the low-level layers to fit the ReID dataset, thereby increasing the performance of ReID tasks. The improved performance of the proposed strategy is validated via several experiments. Furthermore, without any add-ons such as pose estimation or segmentation, our strategy exhibits state-of-the-art performance using only vanilla deep convolutional neural network architecture.



### Generative Adversarial Classifier for Handwriting Characters Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1901.06199v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.06199v1)
- **Published**: 2019-01-18 12:10:50+00:00
- **Updated**: 2019-01-18 12:10:50+00:00
- **Authors**: Zhuang Qian, Kaizhu Huang, Qiufeng Wang, Jimin Xiao, Rui Zhang
- **Comment**: 7 pages, 4 figures
- **Journal**: None
- **Summary**: Generative Adversarial Networks (GAN) receive great attentions recently due to its excellent performance in image generation, transformation, and super-resolution. However, GAN has rarely been studied and trained for classification, leading that the generated images may not be appropriate for classification. In this paper, we propose a novel Generative Adversarial Classifier (GAC) particularly for low-resolution Handwriting Character Recognition. Specifically, involving additionally a classifier in the training process of normal GANs, GAC is calibrated for learning suitable structures and restored characters images that benefits the classification. Experimental results show that our proposed method can achieve remarkable performance in handwriting characters 8x super-resolution, approximately 10% and 20% higher than the present state-of-the-art methods respectively on benchmark data CASIA-HWDB1.1 and MNIST.



### Red blood cell image generation for data augmentation using Conditional Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.06219v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06219v2)
- **Published**: 2019-01-18 13:23:41+00:00
- **Updated**: 2019-03-08 10:08:18+00:00
- **Authors**: Oleksandr Bailo, DongShik Ham, Young Min Shin
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we describe how to apply image-to-image translation techniques to medical blood smear data to generate new data samples and meaningfully increase small datasets. Specifically, given the segmentation mask of the microscopy image, we are able to generate photorealistic images of blood cells which are further used alongside real data during the network training for segmentation and object detection tasks. This image data generation approach is based on conditional generative adversarial networks which have proven capabilities to high-quality image synthesis. In addition to synthesizing blood images, we synthesize segmentation mask as well which leads to a diverse variety of generated samples. The effectiveness of the technique is thoroughly analyzed and quantified through a number of experiments on a manually collected and annotated dataset of blood smear taken under a microscope.



### A Recent Survey on the Applications of Genetic Programming in Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1901.07387v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1901.07387v3)
- **Published**: 2019-01-18 14:12:32+00:00
- **Updated**: 2020-06-25 20:42:22+00:00
- **Authors**: Asifullah Khan, Aqsa Saeed Qureshi, Noorul Wahab, Mutawara Hussain, Muhammad Yousaf Hamza
- **Comment**: 31 pages, 12 figures, and 1 table
- **Journal**: None
- **Summary**: Genetic Programming (GP) has been primarily used to tackle optimization, classification, and feature selection related tasks. The widespread use of GP is due to its flexible and comprehensible tree-type structure. Similarly, research is also gaining momentum in the field of Image Processing, because of its promising results over vast areas of applications ranging from medical Image Processing to multispectral imaging. Image Processing is mainly involved in applications such as computer vision, pattern recognition, image compression, storage, and medical diagnostics. This universal nature of images and their associated algorithm, i.e., complexities, gave an impetus to the exploration of GP. GP has thus been used in different ways for Image Processing since its inception. Many interesting GP techniques have been developed and employed in the field of Image Processing, and consequently, we aim to provide the research community an extensive view of these techniques. This survey thus presents the diverse applications of GP in Image Processing and provides useful resources for further research. Also, the comparison of different parameters used in different applications of Image Processing is summarized in tabular form. Moreover, analysis of the different parameters used in Image Processing related tasks is carried-out to save the time needed in the future for evaluating the parameters of GP. As more advancement is made in GP methodologies, its success in solving complex tasks, not only in Image Processing but also in other fields, may increase. Additionally, guidelines are provided for applying GP in Image Processing related tasks, the pros and cons of GP techniques are discussed, and some future directions are also set.



### Physics-Constrained Deep Learning for High-dimensional Surrogate Modeling and Uncertainty Quantification without Labeled Data
- **Arxiv ID**: http://arxiv.org/abs/1901.06314v1
- **DOI**: 10.1016/j.jcp.2019.05.024
- **Categories**: **physics.comp-ph**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.06314v1)
- **Published**: 2019-01-18 15:59:30+00:00
- **Updated**: 2019-01-18 15:59:30+00:00
- **Authors**: Yinhao Zhu, Nicholas Zabaras, Phaedon-Stelios Koutsourelakis, Paris Perdikaris
- **Comment**: 51 pages, 18 figures, submitted to Journal of Computational Physics
- **Journal**: None
- **Summary**: Surrogate modeling and uncertainty quantification tasks for PDE systems are most often considered as supervised learning problems where input and output data pairs are used for training. The construction of such emulators is by definition a small data problem which poses challenges to deep learning approaches that have been developed to operate in the big data regime. Even in cases where such models have been shown to have good predictive capability in high dimensions, they fail to address constraints in the data implied by the PDE model. This paper provides a methodology that incorporates the governing equations of the physical model in the loss/likelihood functions. The resulting physics-constrained, deep learning models are trained without any labeled data (e.g. employing only input data) and provide comparable predictive responses with data-driven models while obeying the constraints of the problem at hand. This work employs a convolutional encoder-decoder neural network approach as well as a conditional flow-based generative model for the solution of PDEs, surrogate model construction, and uncertainty quantification tasks. The methodology is posed as a minimization problem of the reverse Kullback-Leibler (KL) divergence between the model predictive density and the reference conditional density, where the later is defined as the Boltzmann-Gibbs distribution at a given inverse temperature with the underlying potential relating to the PDE system of interest. The generalization capability of these models to out-of-distribution input is considered. Quantification and interpretation of the predictive uncertainty is provided for a number of problems.



### Learning Spatial Pyramid Attentive Pooling in Image Synthesis and Image-to-Image Translation
- **Arxiv ID**: http://arxiv.org/abs/1901.06322v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.06322v1)
- **Published**: 2019-01-18 16:23:37+00:00
- **Updated**: 2019-01-18 16:23:37+00:00
- **Authors**: Wei Sun, Tianfu Wu
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: Image synthesis and image-to-image translation are two important generative learning tasks. Remarkable progress has been made by learning Generative Adversarial Networks (GANs)~\cite{goodfellow2014generative} and cycle-consistent GANs (CycleGANs)~\cite{zhu2017unpaired} respectively. This paper presents a method of learning Spatial Pyramid Attentive Pooling (SPAP) which is a novel architectural unit and can be easily integrated into both generators and discriminators in GANs and CycleGANs. The proposed SPAP integrates Atrous spatial pyramid~\cite{chen2018deeplab}, a proposed cascade attention mechanism and residual connections~\cite{he2016deep}. It leverages the advantages of the three components to facilitate effective end-to-end generative learning: (i) the capability of fusing multi-scale information by ASPP; (ii) the capability of capturing relative importance between both spatial locations (especially multi-scale context) or feature channels by attention; (iii) the capability of preserving information and enhancing optimization feasibility by residual connections. Coarse-to-fine and fine-to-coarse SPAP are studied and intriguing attention maps are observed in both tasks. In experiments, the proposed SPAP is tested in GANs on the Celeba-HQ-128 dataset~\cite{karras2017progressive}, and tested in CycleGANs on the Image-to-Image translation datasets including the Cityscape dataset~\cite{cordts2016cityscapes}, Facade and Aerial Maps dataset~\cite{zhu2017unpaired}, both obtaining better performance.



### Feature Pyramid and Hierarchical Boosting Network for Pavement Crack Detection
- **Arxiv ID**: http://arxiv.org/abs/1901.06340v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06340v2)
- **Published**: 2019-01-18 16:58:59+00:00
- **Updated**: 2019-01-25 02:14:41+00:00
- **Authors**: Fan Yang, Lei Zhang, Sijia Yu, Danil Prokhorov, Xue Mei, Haibin Ling
- **Comment**: None
- **Journal**: None
- **Summary**: Pavement crack detection is a critical task for insuring road safety. Manual crack detection is extremely time-consuming. Therefore, an automatic road crack detection method is required to boost this progress. However, it remains a challenging task due to the intensity inhomogeneity of cracks and complexity of the background, e.g., the low contrast with surrounding pavements and possible shadows with similar intensity. Inspired by recent advances of deep learning in computer vision, we propose a novel network architecture, named Feature Pyramid and Hierarchical Boosting Network (FPHBN), for pavement crack detection. The proposed network integrates semantic information to low-level features for crack detection in a feature pyramid way. And, it balances the contribution of both easy and hard samples to loss by nested sample reweighting in a hierarchical way. To demonstrate the superiority and generality of the proposed method, we evaluate the proposed method on five crack datasets and compare it with state-of-the-art crack detection, edge detection, semantic segmentation methods. Extensive experiments show that the proposed method outperforms these state-of-the-art methods in terms of accuracy and generality.



### Adapting Convolutional Neural Networks for Geographical Domain Shift
- **Arxiv ID**: http://arxiv.org/abs/1901.06345v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06345v1)
- **Published**: 2019-01-18 17:19:37+00:00
- **Updated**: 2019-01-18 17:19:37+00:00
- **Authors**: Pavel Ostyakov, Sergey I. Nikolenko
- **Comment**: None
- **Journal**: None
- **Summary**: We present the winning solution for the Inclusive Images Competition organized as part of the Conference on Neural Information Processing Systems (NeurIPS 2018) Competition Track. The competition was organized to study ways to cope with domain shift in image processing, specifically geographical shift: the training and two test sets in the competition had different geographical distributions. Our solution has proven to be relatively straightforward and simple: it is an ensemble of several CNNs where only the last layer is fine-tuned with the help of a small labeled set of tuning labels made available by the organizers. We believe that while domain shift remains a formidable problem, our approach opens up new possibilities for alleviating this problem in practice, where small labeled datasets from the target domain are usually either available or can be obtained and labeled cheaply.



### Robust Anomaly Detection in Images using Adversarial Autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1901.06355v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.06355v1)
- **Published**: 2019-01-18 17:48:15+00:00
- **Updated**: 2019-01-18 17:48:15+00:00
- **Authors**: Laura Beggel, Michael Pfeiffer, Bernd Bischl
- **Comment**: None
- **Journal**: None
- **Summary**: Reliably detecting anomalies in a given set of images is a task of high practical relevance for visual quality inspection, surveillance, or medical image analysis. Autoencoder neural networks learn to reconstruct normal images, and hence can classify those images as anomalies, where the reconstruction error exceeds some threshold. Here we analyze a fundamental problem of this approach when the training set is contaminated with a small fraction of outliers. We find that continued training of autoencoders inevitably reduces the reconstruction error of outliers, and hence degrades the anomaly detection performance. In order to counteract this effect, an adversarial autoencoder architecture is adapted, which imposes a prior distribution on the latent representation, typically placing anomalies into low likelihood-regions. Utilizing the likelihood model, potential anomalies can be identified and rejected already during training, which results in an anomaly detector that is significantly more robust to the presence of outliers during training.



### Embedded CNN based vehicle classification and counting in non-laned road traffic
- **Arxiv ID**: http://arxiv.org/abs/1901.06358v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06358v1)
- **Published**: 2019-01-18 17:59:36+00:00
- **Updated**: 2019-01-18 17:59:36+00:00
- **Authors**: Mayank Singh Chauhan, Arshdeep Singh, Mansi Khemka, Arneish Prateek, Rijurekha Sen
- **Comment**: *These authors contributed equally
- **Journal**: None
- **Summary**: Classifying and counting vehicles in road traffic has numerous applications in the transportation engineering domain. However, the wide variety of vehicles (two-wheelers, three-wheelers, cars, buses, trucks etc.) plying on roads of developing regions without any lane discipline, makes vehicle classification and counting a hard problem to automate. In this paper, we use state of the art Convolutional Neural Network (CNN) based object detection models and train them for multiple vehicle classes using data from Delhi roads. We get upto 75% MAP on an 80-20 train-test split using 5562 video frames from four different locations. As robust network connectivity is scarce in developing regions for continuous video transmissions from the road to cloud servers, we also evaluate the latency, energy and hardware cost of embedded implementations of our CNN model based inferences.



### ULDor: A Universal Lesion Detector for CT Scans with Pseudo Masks and Hard Negative Example Mining
- **Arxiv ID**: http://arxiv.org/abs/1901.06359v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06359v1)
- **Published**: 2019-01-18 17:59:47+00:00
- **Updated**: 2019-01-18 17:59:47+00:00
- **Authors**: Youbao Tang, Ke Yan, Yuxing Tang, Jiamin Liu, Jing Xiao, Ronald M. Summers
- **Comment**: None
- **Journal**: IEEE International Symposium on Biomedical Imaging (ISBI) 2019
- **Summary**: Automatic lesion detection from computed tomography (CT) scans is an important task in medical imaging analysis. It is still very challenging due to similar appearances (e.g. intensity and texture) between lesions and other tissues, making it especially difficult to develop a universal lesion detector. Instead of developing a specific-type lesion detector, this work builds a Universal Lesion Detector (ULDor) based on Mask R-CNN, which is able to detect all different kinds of lesions from whole body parts. As a state-of-the-art object detector, Mask R-CNN adds a branch for predicting segmentation masks on each Region of Interest (RoI) to improve the detection performance. However, it is almost impossible to manually annotate a large-scale dataset with pixel-level lesion masks to train the Mask R-CNN for lesion detection. To address this problem, this work constructs a pseudo mask for each lesion region that can be considered as a surrogate of the real mask, based on which the Mask R-CNN is employed for lesion detection. On the other hand, this work proposes a hard negative example mining strategy to reduce the false positives for improving the detection performance. Experimental results on the NIH DeepLesion dataset demonstrate that the ULDor is enhanced using pseudo masks and the proposed hard negative example mining strategy and achieves a sensitivity of 86.21% with five false positives per image.



### Multisource Region Attention Network for Fine-Grained Object Recognition in Remote Sensing Imagery
- **Arxiv ID**: http://arxiv.org/abs/1901.06403v1
- **DOI**: 10.1109/TGRS.2019.2894425
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06403v1)
- **Published**: 2019-01-18 19:43:33+00:00
- **Updated**: 2019-01-18 19:43:33+00:00
- **Authors**: Gencer Sumbul, Ramazan Gokberk Cinbis, Selim Aksoy
- **Comment**: G. Sumbul, R. G. Cinbis, S. Aksoy, "Multisource Region Attention
  Network for Fine-Grained Object Recognition in Remote Sensing Imagery", IEEE
  Transactions on Geoscience and Remote Sensing (TGRS), in press, 2019
- **Journal**: None
- **Summary**: Fine-grained object recognition concerns the identification of the type of an object among a large number of closely related sub-categories. Multisource data analysis, that aims to leverage the complementary spectral, spatial, and structural information embedded in different sources, is a promising direction towards solving the fine-grained recognition problem that involves low between-class variance, small training set sizes for rare classes, and class imbalance. However, the common assumption of co-registered sources may not hold at the pixel level for small objects of interest. We present a novel methodology that aims to simultaneously learn the alignment of multisource data and the classification model in a unified framework. The proposed method involves a multisource region attention network that computes per-source feature representations, assigns attention scores to candidate regions sampled around the expected object locations by using these representations, and classifies the objects by using an attention-driven multisource representation that combines the feature representations and the attention scores from all sources. All components of the model are realized using deep neural networks and are learned in an end-to-end fashion. Experiments using RGB, multispectral, and LiDAR elevation data for classification of street trees showed that our approach achieved 64.2% and 47.3% accuracies for the 18-class and 40-class settings, respectively, which correspond to 13% and 14.3% improvement relative to the commonly used feature concatenation approach from multiple sources.



### Learning a Deep Convolution Network with Turing Test Adversaries for Microscopy Image Super Resolution
- **Arxiv ID**: http://arxiv.org/abs/1901.06405v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.06405v1)
- **Published**: 2019-01-18 19:55:19+00:00
- **Updated**: 2019-01-18 19:55:19+00:00
- **Authors**: Francis Tom, Himanshu Sharma, Dheeraj Mundhra, Tathagato Rai Dastidar, Debdoot Sheet
- **Comment**: To appear in the Proceedings of the 2019 IEEE International Symposium
  on Biomedical Imaging (ISBI 2019)
- **Journal**: None
- **Summary**: Adversarially trained deep neural networks have significantly improved performance of single image super resolution, by hallucinating photorealistic local textures, thereby greatly reducing the perception difference between a real high resolution image and its super resolved (SR) counterpart. However, application to medical imaging requires preservation of diagnostically relevant features while refraining from introducing any diagnostically confusing artifacts. We propose using a deep convolutional super resolution network (SRNet) trained for (i) minimising reconstruction loss between the real and SR images, and (ii) maximally confusing learned relativistic visual Turing test (rVTT) networks to discriminate between (a) pair of real and SR images (T1) and (b) pair of patches in real and SR selected from region of interest (T2). The adversarial loss of T1 and T2 while backpropagated through SRNet helps it learn to reconstruct pathorealism in the regions of interest such as white blood cells (WBC) in peripheral blood smears or epithelial cells in histopathology of cancerous biopsy tissues, which are experimentally demonstrated here. Experiments performed for measuring signal distortion loss using peak signal to noise ratio (pSNR) and structural similarity (SSIM) with variation of SR scale factors, impact of rVTT adversarial losses, and impact on reporting using SR on a commercially available artificial intelligence (AI) digital pathology system substantiate our claims.



### Machine Learning with Clos Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.06433v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1901.06433v1)
- **Published**: 2019-01-18 22:17:32+00:00
- **Updated**: 2019-01-18 22:17:32+00:00
- **Authors**: Timothy Whithing, Thiam Khean Hah
- **Comment**: None
- **Journal**: None
- **Summary**: We present a new methodology for improving the accuracy of small neural networks by applying the concept of a clos network to achieve maximum expression in a smaller network. We explore the design space to show that more layers is beneficial, given the same number of parameters. We also present findings on how the relu nonlinearity ffects accuracy in separable networks. We present results on early work with Cifar-10 dataset.



