# Arxiv Papers in cs.CV on 2019-01-07
### Blind Motion Deblurring with Cycle Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.01641v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01641v2)
- **Published**: 2019-01-07 01:52:21+00:00
- **Updated**: 2019-01-08 08:24:40+00:00
- **Authors**: Quan Yuan, Junxia Li, Lingwei Zhang, Zhefu Wu, Guangyu Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Blind motion deblurring is one of the most basic and challenging problems in image processing and computer vision. It aims to recover a sharp image from its blurred version knowing nothing about the blur process. Many existing methods use Maximum A Posteriori (MAP) or Expectation Maximization (EM) frameworks to deal with this kind of problems, but they cannot handle well the figh frequency features of natural images. Most recently, deep neural networks have been emerging as a powerful tool for image deblurring. In this paper, we prove that encoder-decoder architecture gives better results for image deblurring tasks. In addition, we propose a novel end-to-end learning model which refines generative adversarial network by many novel training strategies so as to tackle the problem of deblurring. Experimental results show that our model can capture high frequency features well, and the results on benchmark dataset show that proposed model achieves the competitive performance.



### Better Guider Predicts Future Better: Difference Guided Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.01649v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01649v1)
- **Published**: 2019-01-07 02:42:57+00:00
- **Updated**: 2019-01-07 02:42:57+00:00
- **Authors**: Guohao Ying, Yingtian Zou, Lin Wan, Yiming Hu, Jiashi Feng
- **Comment**: To appear in ACCV 2018
- **Journal**: None
- **Summary**: Predicting the future is a fantasy but practicality work. It is the key component to intelligent agents, such as self-driving vehicles, medical monitoring devices and robotics. In this work, we consider generating unseen future frames from previous obeservations, which is notoriously hard due to the uncertainty in frame dynamics. While recent works based on generative adversarial networks (GANs) made remarkable progress, there is still an obstacle for making accurate and realistic predictions. In this paper, we propose a novel GAN based on inter-frame difference to circumvent the difficulties. More specifically, our model is a multi-stage generative network, which is named the Difference Guided Generative Adversarial Netwok (DGGAN). The DGGAN learns to explicitly enforce future-frame predictions that is guided by synthetic inter-frame difference. Given a sequence of frames, DGGAN first uses dual paths to generate meta information. One path, called Coarse Frame Generator, predicts the coarse details about future frames, and the other path, called Difference Guide Generator, generates the difference image which include complementary fine details. Then our coarse details will then be refined via guidance of difference image under the support of GANs. With this model and novel architecture, we achieve state-of-the-art performance for future video prediction on UCF-101, KITTI.



### Tooth morphometry using quasi-conformal theory
- **Arxiv ID**: http://arxiv.org/abs/1901.01651v1
- **DOI**: 10.1016/j.patcog.2019.107064
- **Categories**: **cs.CV**, cs.CG, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1901.01651v1)
- **Published**: 2019-01-07 03:00:12+00:00
- **Updated**: 2019-01-07 03:00:12+00:00
- **Authors**: Gary P. T. Choi, Hei Long Chan, Robin Yong, Sarbin Ranjitkar, Alan Brook, Grant Townsend, Ke Chen, Lok Ming Lui
- **Comment**: None
- **Journal**: Pattern Recognition 99, 107064 (2020)
- **Summary**: Shape analysis is important in anthropology, bioarchaeology and forensic science for interpreting useful information from human remains. In particular, teeth are morphologically stable and hence well-suited for shape analysis. In this work, we propose a framework for tooth morphometry using quasi-conformal theory. Landmark-matching Teichm\"uller maps are used for establishing a 1-1 correspondence between tooth surfaces with prescribed anatomical landmarks. Then, a quasi-conformal statistical shape analysis model based on the Teichm\"uller mapping results is proposed for building a tooth classification scheme. We deploy our framework on a dataset of human premolars to analyze the tooth shape variation among genders and ancestries. Experimental results show that our method achieves much higher classification accuracy with respect to both gender and ancestry when compared to the existing methods. Furthermore, our model reveals the underlying tooth shape difference between different genders and ancestries in terms of the local geometric distortion and curvatures.



### Deeper and Wider Siamese Networks for Real-Time Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1901.01660v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01660v3)
- **Published**: 2019-01-07 04:17:43+00:00
- **Updated**: 2019-03-28 13:07:52+00:00
- **Authors**: Zhipeng Zhang, Houwen Peng
- **Comment**: have been accepted by CVPR2019
- **Journal**: None
- **Summary**: Siamese networks have drawn great attention in visual tracking because of their balanced accuracy and speed. However, the backbone networks used in Siamese trackers are relatively shallow, such as AlexNet [18], which does not fully take advantage of the capability of modern deep neural networks. In this paper, we investigate how to leverage deeper and wider convolutional neural networks to enhance tracking robustness and accuracy. We observe that direct replacement of backbones with existing powerful architectures, such as ResNet [14] and Inception [33], does not bring improvements. The main reasons are that 1)large increases in the receptive field of neurons lead to reduced feature discriminability and localization precision; and 2) the network padding for convolutions induces a positional bias in learning. To address these issues, we propose new residual modules to eliminate the negative impact of padding, and further design new architectures using these modules with controlled receptive field size and network stride. The designed architectures are lightweight and guarantee real-time tracking speed when applied to SiamFC [2] and SiamRPN [20]. Experiments show that solely due to the proposed network architectures, our SiamFC+ and SiamRPN+ obtain up to 9.8%/5.7% (AUC), 23.3%/8.8% (EAO) and 24.4%/25.0% (EAO) relative improvements over the original versions [2, 20] on the OTB-15, VOT-16 and VOT-17 datasets, respectively.



### Image Super-Resolution as a Defense Against Adversarial Attacks
- **Arxiv ID**: http://arxiv.org/abs/1901.01677v2
- **DOI**: 10.1109/TIP.2019.2940533
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01677v2)
- **Published**: 2019-01-07 06:43:23+00:00
- **Updated**: 2019-09-02 05:46:23+00:00
- **Authors**: Aamir Mustafa, Salman H. Khan, Munawar Hayat, Jianbing Shen, Ling Shao
- **Comment**: Published in IEEE Transactions in Image Processing
- **Journal**: None
- **Summary**: Convolutional Neural Networks have achieved significant success across multiple computer vision tasks. However, they are vulnerable to carefully crafted, human-imperceptible adversarial noise patterns which constrain their deployment in critical security-sensitive systems. This paper proposes a computationally efficient image enhancement approach that provides a strong defense mechanism to effectively mitigate the effect of such adversarial perturbations. We show that deep image restoration networks learn mapping functions that can bring off-the-manifold adversarial samples onto the natural image manifold, thus restoring classification towards correct classes. A distinguishing feature of our approach is that, in addition to providing robustness against attacks, it simultaneously enhances image quality and retains models performance on clean images. Furthermore, the proposed method does not modify the classifier or requires a separate mechanism to detect adversarial images. The effectiveness of the scheme has been demonstrated through extensive experiments, where it has proven a strong defense in gray-box settings. The proposed scheme is simple and has the following advantages: (1) it does not require any model training or parameter optimization, (2) it complements other existing defense mechanisms, (3) it is agnostic to the attacked model and attack type and (4) it provides superior performance across all popular attack algorithms. Our codes are publicly available at https://github.com/aamir-mustafa/super-resolution-adversarial-defense.



### Truncated nuclear norm regularization for low-rank tensor completion
- **Arxiv ID**: http://arxiv.org/abs/1901.01997v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01997v1)
- **Published**: 2019-01-07 08:21:47+00:00
- **Updated**: 2019-01-07 08:21:47+00:00
- **Authors**: Shengke Xue, Wenyuan Qiu, Fan Liu, Xinyu Jin
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1712.00704
- **Journal**: None
- **Summary**: Recently, low-rank tensor completion has become increasingly attractive in recovering incomplete visual data. Considering a color image or video as a three-dimensional (3D) tensor, existing studies have put forward several definitions of tensor nuclear norm. However, they are limited and may not accurately approximate the real rank of a tensor, and they do not explicitly use the low-rank property in optimization. It is proved that the recently proposed truncated nuclear norm (TNN) can replace the traditional nuclear norm, as an improved approximation to the rank of a matrix. In this paper, we propose a new method called the tensor truncated nuclear norm (T-TNN), which suggests a new definition of tensor nuclear norm. The truncated nuclear norm is generalized from the matrix case to the tensor case. With the help of the low rankness of TNN, our approach improves the efficacy of tensor completion. We adopt the definition of the previously proposed tensor singular value decomposition, the alternating direction method of multipliers, and the accelerated proximal gradient line search method in our algorithm. Substantial experiments on real-world videos and images illustrate that the performance of our approach is better than those of previous methods.



### Tencent ML-Images: A Large-Scale Multi-Label Image Database for Visual Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1901.01703v7
- **DOI**: 10.1109/ACCESS.2019.2956775
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01703v7)
- **Published**: 2019-01-07 08:35:15+00:00
- **Updated**: 2020-02-09 14:06:39+00:00
- **Authors**: Baoyuan Wu, Weidong Chen, Yanbo Fan, Yong Zhang, Jinlong Hou, Jie Liu, Tong Zhang
- **Comment**: This work is accepted to IEEE Access
- **Journal**: None
- **Summary**: In existing visual representation learning tasks, deep convolutional neural networks (CNNs) are often trained on images annotated with single tags, such as ImageNet. However, a single tag cannot describe all important contents of one image, and some useful visual information may be wasted during training. In this work, we propose to train CNNs from images annotated with multiple tags, to enhance the quality of visual representation of the trained CNN model. To this end, we build a large-scale multi-label image database with 18M images and 11K categories, dubbed Tencent ML-Images. We efficiently train the ResNet-101 model with multi-label outputs on Tencent ML-Images, taking 90 hours for 60 epochs, based on a large-scale distributed deep learning framework,i.e.,TFplus. The good quality of the visual representation of the Tencent ML-Images checkpoint is verified through three transfer learning tasks, including single-label image classification on ImageNet and Caltech-256, object detection on PASCAL VOC 2007, and semantic segmentation on PASCAL VOC 2012. The Tencent ML-Images database, the checkpoints of ResNet-101, and all the training codehave been released at https://github.com/Tencent/tencent-ml-images. It is expected to promote other vision tasks in the research and industry community.



### Universal Deep Beamformer for Variable Rate Ultrasound Imaging
- **Arxiv ID**: http://arxiv.org/abs/1901.01706v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.01706v1)
- **Published**: 2019-01-07 08:52:02+00:00
- **Updated**: 2019-01-07 08:52:02+00:00
- **Authors**: Shujaat Khan, Jaeyoung Huh, Jong Chul Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Ultrasound (US) imaging is based on the time-reversal principle, in which individual channel RF measurements are back-propagated and accumulated to form an image after applying specific delays. While this time reversal is usually implemented as a delay-and-sum (DAS) beamformer, the image quality quickly degrades as the number of measurement channels decreases. To address this problem, various types of adaptive beamforming techniques have been proposed using predefined models of the signals. However, the performance of these adaptive beamforming approaches degrade when the underlying model is not sufficiently accurate. Here, we demonstrate for the first time that a single universal deep beamformer trained using a purely data-driven way can generate significantly improved images over widely varying aperture and channel subsampling patterns. In particular, we design an end-to-end deep learning framework that can directly process sub-sampled RF data acquired at different subsampling rate and detector configuration to generate high quality ultrasound images using a single beamformer. Experimental results using B-mode focused ultrasound confirm the efficacy of the proposed methods.



### Post-mortem Iris Recognition with Deep-Learning-based Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1901.01708v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01708v2)
- **Published**: 2019-01-07 08:57:35+00:00
- **Updated**: 2019-10-08 09:42:08+00:00
- **Authors**: Mateusz Trokielewicz, Adam Czajka, Piotr Maciejewicz
- **Comment**: Paper submitted for the Elsevier Image and Vision Computing Journal
  on Jan 5th, 2019, revised version
- **Journal**: None
- **Summary**: This paper proposes the first known to us iris recognition methodology designed specifically for post-mortem samples. We propose to use deep learning-based iris segmentation models to extract highly irregular iris texture areas in post-mortem iris images. We show how to use segmentation masks predicted by neural networks in conventional, Gabor-based iris recognition method, which employs circular approximations of the pupillary and limbic iris boundaries. As a whole, this method allows for a significant improvement in post-mortem iris recognition accuracy over the methods designed only for ante-mortem irises, including the academic OSIRIS and commercial IriCore implementations. The proposed method reaches the EER less than 1% for samples collected up to 10 hours after death, when compared to 16.89% and 5.37% of EER observed for OSIRIS and IriCore, respectively. For samples collected up to 369 hours post-mortem, the proposed method achieves the EER 21.45%, while 33.59% and 25.38% are observed for OSIRIS and IriCore, respectively. Additionally, the method is tested on a database of iris images collected from ophthalmology clinic patients, for which it also offers an advantage over the two other algorithms. This work is the first step towards post-mortem-specific iris recognition, which increases the chances of identification of deceased subjects in forensic investigations. The new database of post-mortem iris images acquired from 42 subjects, as well as the deep learning-based segmentation models are made available along with the paper, to ensure all the results presented in this manuscript are reproducible.



### Double Weighted Truncated Nuclear Norm Regularization for Low-Rank Matrix Completion
- **Arxiv ID**: http://arxiv.org/abs/1901.01711v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01711v1)
- **Published**: 2019-01-07 09:04:37+00:00
- **Updated**: 2019-01-07 09:04:37+00:00
- **Authors**: Shengke Xue, Wenyuan Qiu, Fan Liu, Xinyu Jin
- **Comment**: None
- **Journal**: None
- **Summary**: Matrix completion focuses on recovering a matrix from a small subset of its observed elements, and has already gained cumulative attention in computer vision. Many previous approaches formulate this issue as a low-rank matrix approximation problem. Recently, a truncated nuclear norm has been presented as a surrogate of traditional nuclear norm, for better estimation to the rank of a matrix. The truncated nuclear norm regularization (TNNR) method is applicable in real-world scenarios. However, it is sensitive to the selection of the number of truncated singular values and requires numerous iterations to converge. Hereby, this paper proposes a revised approach called the double weighted truncated nuclear norm regularization (DW-TNNR), which assigns different weights to the rows and columns of a matrix separately, to accelerate the convergence with acceptable performance. The DW-TNNR is more robust to the number of truncated singular values than the TNNR. Instead of the iterative updating scheme in the second step of TNNR, this paper devises an efficient strategy that uses a gradient descent manner in a concise form, with a theoretical guarantee in optimization. Sufficient experiments conducted on real visual data prove that DW-TNNR has promising performance and holds the superiority in both speed and accuracy for matrix completion.



### Forecasting People Trajectories and Head Poses by Jointly Reasoning on Tracklets and Vislets
- **Arxiv ID**: http://arxiv.org/abs/1901.02000v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.02000v2)
- **Published**: 2019-01-07 10:15:17+00:00
- **Updated**: 2019-10-15 09:46:17+00:00
- **Authors**: Irtiza Hasan, Francesco Setti, Theodore Tsesmelis, Vasileios Belagiannis, Sikandar Amin, Alessio Del Bue, Marco Cristani, Fabio Galasso
- **Comment**: Accepted at IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE
  INTELLIGENCE 2019. arXiv admin note: text overlap with arXiv:1805.00652
- **Journal**: None
- **Summary**: In this work, we explore the correlation between people trajectories and their head orientations. We argue that people trajectory and head pose forecasting can be modelled as a joint problem. Recent approaches on trajectory forecasting leverage short-term trajectories (aka tracklets) of pedestrians to predict their future paths. In addition, sociological cues, such as expected destination or pedestrian interaction, are often combined with tracklets. In this paper, we propose MiXing-LSTM (MX-LSTM) to capture the interplay between positions and head orientations (vislets) thanks to a joint unconstrained optimization of full covariance matrices during the LSTM backpropagation. We additionally exploit the head orientations as a proxy for the visual attention, when modeling social interactions. MX-LSTM predicts future pedestrians location and head pose, increasing the standard capabilities of the current approaches on long-term trajectory forecasting. Compared to the state-of-the-art, our approach shows better performances on an extensive set of public benchmarks. MX-LSTM is particularly effective when people move slowly, i.e. the most challenging scenario for all other models. The proposed approach also allows for accurate predictions on a longer time horizon.



### Human Pose Estimation with Spatial Contextual Information
- **Arxiv ID**: http://arxiv.org/abs/1901.01760v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01760v1)
- **Published**: 2019-01-07 11:58:10+00:00
- **Updated**: 2019-01-07 11:58:10+00:00
- **Authors**: Hong Zhang, Hao Ouyang, Shu Liu, Xiaojuan Qi, Xiaoyong Shen, Ruigang Yang, Jiaya Jia
- **Comment**: None
- **Journal**: None
- **Summary**: We explore the importance of spatial contextual information in human pose estimation. Most state-of-the-art pose networks are trained in a multi-stage manner and produce several auxiliary predictions for deep supervision. With this principle, we present two conceptually simple and yet computational efficient modules, namely Cascade Prediction Fusion (CPF) and Pose Graph Neural Network (PGNN), to exploit underlying contextual information. Cascade prediction fusion accumulates prediction maps from previous stages to extract informative signals. The resulting maps also function as a prior to guide prediction at following stages. To promote spatial correlation among joints, our PGNN learns a structured representation of human pose as a graph. Direct message passing between different joints is enabled and spatial relation is captured. These two modules require very limited computational complexity. Experimental results demonstrate that our method consistently outperforms previous methods on MPII and LSP benchmark.



### Fusing Body Posture with Facial Expressions for Joint Recognition of Affect in Child-Robot Interaction
- **Arxiv ID**: http://arxiv.org/abs/1901.01805v3
- **DOI**: 10.1109/LRA.2019.2930434
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01805v3)
- **Published**: 2019-01-07 13:50:49+00:00
- **Updated**: 2019-09-05 14:53:15+00:00
- **Authors**: Panagiotis P. Filntisis, Niki Efthymiou, Petros Koutras, Gerasimos Potamianos, Petros Maragos
- **Comment**: To be presented in IROS 2019
- **Journal**: IEEE Robotics and Automation Letters, 4(4), 4011-4018, 2019
- **Summary**: In this paper we address the problem of multi-cue affect recognition in challenging scenarios such as child-robot interaction. Towards this goal we propose a method for automatic recognition of affect that leverages body expressions alongside facial ones, as opposed to traditional methods that typically focus only on the latter. Our deep-learning based method uses hierarchical multi-label annotations and multi-stage losses, can be trained both jointly and separately, and offers us computational models for both individual modalities, as well as for the whole body emotion. We evaluate our method on a challenging child-robot interaction database of emotional expressions collected by us, as well as on the GEMEP public database of acted emotions by adults, and show that the proposed method achieves significantly better results than facial-only expression baselines.



### Self-Supervised Learning from Web Data for Multimodal Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1901.02004v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.02004v1)
- **Published**: 2019-01-07 14:34:49+00:00
- **Updated**: 2019-01-07 14:34:49+00:00
- **Authors**: Raul Gomez, Lluis Gomez, Jaume Gibert, Dimosthenis Karatzas
- **Comment**: Submitted to Multi-Modal Scene Understanding. arXiv admin note:
  substantial text overlap with arXiv:1808.06368
- **Journal**: None
- **Summary**: Self-Supervised learning from multimodal image and text data allows deep neural networks to learn powerful features with no need of human annotated data. Web and Social Media platforms provide a virtually unlimited amount of this multimodal data. In this work we propose to exploit this free available data to learn a multimodal image and text embedding, aiming to leverage the semantic knowledge learnt in the text domain and transfer it to a visual model for semantic image retrieval. We demonstrate that the proposed pipeline can learn from images with associated textwithout supervision and analyze the semantic structure of the learnt joint image and text embedding space. We perform a thorough analysis and performance comparison of five different state of the art text embeddings in three different benchmarks. We show that the embeddings learnt with Web and Social Media data have competitive performances over supervised methods in the text based image retrieval task, and we clearly outperform state of the art in the MIRFlickr dataset when training in the target data. Further, we demonstrate how semantic multimodal image retrieval can be performed using the learnt embeddings, going beyond classical instance-level retrieval problems. Finally, we present a new dataset, InstaCities1M, composed by Instagram images and their associated texts that can be used for fair comparison of image-text embeddings.



### Mutual Context Network for Jointly Estimating Egocentric Gaze and Actions
- **Arxiv ID**: http://arxiv.org/abs/1901.01874v4
- **DOI**: 10.1109/TIP.2020.3007841
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01874v4)
- **Published**: 2019-01-07 15:10:07+00:00
- **Updated**: 2020-06-30 02:08:22+00:00
- **Authors**: Yifei Huang, Zhenqiang Li, Minjie Cai, Yoichi Sato
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we address two coupled tasks of gaze prediction and action recognition in egocentric videos by exploring their mutual context. Our assumption is that in the procedure of performing a manipulation task, what a person is doing determines where the person is looking at, and the gaze point reveals gaze and non-gaze regions which contain important and complementary information about the undergoing action. We propose a novel mutual context network (MCN) that jointly learns action-dependent gaze prediction and gaze-guided action recognition in an end-to-end manner. Experiments on public egocentric video datasets demonstrate that our MCN achieves state-of-the-art performance of both gaze prediction and action recognition.



### Monocular Neural Image Based Rendering with Continuous View Control
- **Arxiv ID**: http://arxiv.org/abs/1901.01880v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01880v2)
- **Published**: 2019-01-07 15:24:25+00:00
- **Updated**: 2019-09-09 08:23:05+00:00
- **Authors**: Xu Chen, Jie Song, Otmar Hilliges
- **Comment**: The first two authors contributed equally to this paper. ICCV
  camera-ready version
- **Journal**: None
- **Summary**: We present an approach that learns to synthesize high-quality, novel views of 3D objects or scenes, while providing fine-grained and precise control over the 6-DOF viewpoint. The approach is self-supervised and only requires 2D images and associated view transforms for training. Our main contribution is a network architecture that leverages a transforming auto-encoder in combination with a depth-guided warping procedure to predict geometrically accurate unseen views. Leveraging geometric constraints renders direct supervision via depth or flow maps unnecessary. If large parts of the object are occluded in the source view, a purely learning based prior is used to predict the values for dis-occluded pixels. Our network furthermore predicts a per-pixel mask, used to fuse depth-guided and pixel-based predictions. The resulting images reflect the desired 6-DOF transformation and details are preserved. We thoroughly evaluate our architecture on synthetic and real scenes and under fine-grained and fixed-view settings. Finally, we demonstrate that the approach generalizes to entirely unseen images such as product images downloaded from the internet.



### Scale-Aware Trident Networks for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1901.01892v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01892v2)
- **Published**: 2019-01-07 16:08:37+00:00
- **Updated**: 2019-08-20 03:17:44+00:00
- **Authors**: Yanghao Li, Yuntao Chen, Naiyan Wang, Zhaoxiang Zhang
- **Comment**: ICCV 2019 camera ready
- **Journal**: None
- **Summary**: Scale variation is one of the key challenges in object detection. In this work, we first present a controlled experiment to investigate the effect of receptive fields for scale variation in object detection. Based on the findings from the exploration experiments, we propose a novel Trident Network (TridentNet) aiming to generate scale-specific feature maps with a uniform representational power. We construct a parallel multi-branch architecture in which each branch shares the same transformation parameters but with different receptive fields. Then, we adopt a scale-aware training scheme to specialize each branch by sampling object instances of proper scales for training. As a bonus, a fast approximation version of TridentNet could achieve significant improvements without any additional parameters and computational cost compared with the vanilla detector. On the COCO dataset, our TridentNet with ResNet-101 backbone achieves state-of-the-art single-model results of 48.4 mAP. Codes are available at https://git.io/fj5vR.



### On the Global Geometry of Sphere-Constrained Sparse Blind Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/1901.01913v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.01913v1)
- **Published**: 2019-01-07 16:42:46+00:00
- **Updated**: 2019-01-07 16:42:46+00:00
- **Authors**: Yuqian Zhang, Yenson Lau, Han-Wen Kuo, Sky Cheung, Abhay Pasupathy, John Wright
- **Comment**: None
- **Journal**: None
- **Summary**: Blind deconvolution is the problem of recovering a convolutional kernel $\boldsymbol a_0$ and an activation signal $\boldsymbol x_0$ from their convolution $\boldsymbol y = \boldsymbol a_0 \circledast \boldsymbol x_0$. This problem is ill-posed without further constraints or priors. This paper studies the situation where the nonzero entries in the activation signal are sparsely and randomly populated. We normalize the convolution kernel to have unit Frobenius norm and cast the sparse blind deconvolution problem as a nonconvex optimization problem over the sphere. With this spherical constraint, every spurious local minimum turns out to be close to some signed shift truncation of the ground truth, under certain hypotheses. This benign property motivates an effective two stage algorithm that recovers the ground truth from the partial information offered by a suboptimal local minimum. This geometry-inspired algorithm recovers the ground truth for certain microscopy problems, also exhibits promising performance in the more challenging image deblurring problem. Our insights into the global geometry and the two stage algorithm extend to the convolutional dictionary learning problem, where a superposition of multiple convolution signals is observed.



### DSConv: Efficient Convolution Operator
- **Arxiv ID**: http://arxiv.org/abs/1901.01928v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01928v2)
- **Published**: 2019-01-07 17:18:16+00:00
- **Updated**: 2019-11-07 14:03:41+00:00
- **Authors**: Marcelo Gennari, Roger Fawcett, Victor Adrian Prisacariu
- **Comment**: None
- **Journal**: The IEEE International Conference on Computer Vision (ICCV), 2019,
  pp. 5148-5157
- **Summary**: Quantization is a popular way of increasing the speed and lowering the memory usage of Convolution Neural Networks (CNNs). When labelled training data is available, network weights and activations have successfully been quantized down to 1-bit. The same cannot be said about the scenario when labelled training data is not available, e.g. when quantizing a pre-trained model, where current approaches show, at best, no loss of accuracy at 8-bit quantizations. We introduce DSConv, a flexible quantized convolution operator that replaces single-precision operations with their far less expensive integer counterparts, while maintaining the probability distributions over both the kernel weights and the outputs. We test our model as a plug-and-play replacement for standard convolution on most popular neural network architectures, ResNet, DenseNet, GoogLeNet, AlexNet and VGG-Net and demonstrate state-of-the-art results, with less than 1% loss of accuracy, without retraining, using only 4-bit quantization. We also show how a distillation-based adaptation stage with unlabelled data can improve results even further.



### GASL: Guided Attention for Sparsity Learning in Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.01939v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01939v2)
- **Published**: 2019-01-07 17:43:08+00:00
- **Updated**: 2019-01-15 19:15:36+00:00
- **Authors**: Amirsina Torfi, Rouzbeh A. Shirvani, Sobhan Soleymani, Naser M. Nasrabadi
- **Comment**: None
- **Journal**: None
- **Summary**: The main goal of network pruning is imposing sparsity on the neural network by increasing the number of parameters with zero value in order to reduce the architecture size and the computational speedup. In most of the previous research works, sparsity is imposed stochastically without considering any prior knowledge of the weights distribution or other internal network characteristics. Enforcing too much sparsity may induce accuracy drop due to the fact that a lot of important elements might have been eliminated. In this paper, we propose Guided Attention for Sparsity Learning (GASL) to achieve (1) model compression by having less number of elements and speed-up; (2) prevent the accuracy drop by supervising the sparsity operation via a guided attention mechanism and (3) introduce a generic mechanism that can be adapted for any type of architecture; Our work is aimed at providing a framework based on interpretable attention mechanisms for imposing structured and non-structured sparsity in deep neural networks. For Cifar-100 experiments, we achieved the state-of-the-art sparsity level and 2.91x speedup with competitive accuracy compared to the best method. For MNIST and LeNet architecture we also achieved the highest sparsity and speedup level.



### Graph- and finite element-based total variation models for the inverse problem in diffuse optical tomography
- **Arxiv ID**: http://arxiv.org/abs/1901.01969v2
- **DOI**: None
- **Categories**: **cs.CV**, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1901.01969v2)
- **Published**: 2019-01-07 18:52:32+00:00
- **Updated**: 2019-04-05 11:51:46+00:00
- **Authors**: Wenqi Lu, Jinming Duan, David Orive-Miguel, Lionel Herve, Iain B Styles
- **Comment**: 24 pages, 11 figures. Reviced version includes revised figures and
  improved clarity
- **Journal**: None
- **Summary**: Total variation (TV) is a powerful regularization method that has been widely applied in different imaging applications, but is difficult to apply to diffuse optical tomography (DOT) image reconstruction (inverse problem) due to complex and unstructured geometries, non-linearity of the data fitting and regularization terms, and non-differentiability of the regularization term. We develop several approaches to overcome these difficulties by: i) defining discrete differential operators for unstructured geometries using both finite element and graph representations; ii) developing an optimization algorithm based on the alternating direction method of multipliers (ADMM) for the non-differentiable and non-linear minimization problem; iii) investigating isotropic and anisotropic variants of TV regularization, and comparing their finite element- and graph-based implementations. These approaches are evaluated on experiments on simulated data and real data acquired from a tissue phantom. Our results show that both FEM and graph-based TV regularization is able to accurately reconstruct both sparse and non-sparse distributions without the over-smoothing effect of Tikhonov regularization and the over-sparsifying effect of L$_1$ regularization. The graph representation was found to out-perform the FEM method for low-resolution meshes, and the FEM method was found to be more accurate for high-resolution meshes.



### Learning Independent Object Motion from Unlabelled Stereoscopic Videos
- **Arxiv ID**: http://arxiv.org/abs/1901.01971v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.01971v2)
- **Published**: 2019-01-07 18:58:11+00:00
- **Updated**: 2019-01-08 10:27:40+00:00
- **Authors**: Zhe Cao, Abhishek Kar, Christian Haene, Jitendra Malik
- **Comment**: None
- **Journal**: None
- **Summary**: We present a system for learning motion of independently moving objects from stereo videos. The only human annotation used in our system are 2D object bounding boxes which introduce the notion of objects to our system. Unlike prior learning based work which has focused on predicting dense pixel-wise optical flow field and/or a depth map for each image, we propose to predict object instance specific 3D scene flow maps and instance masks from which we are able to derive the motion direction and speed for each object instance. Our network takes the 3D geometry of the problem into account which allows it to correlate the input images. We present experiments evaluating the accuracy of our 3D flow vectors, as well as depth maps and projected 2D optical flow where our jointly learned system outperforms earlier approaches trained for each task independently.



### Spherical CNNs on Unstructured Grids
- **Arxiv ID**: http://arxiv.org/abs/1901.02039v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.02039v1)
- **Published**: 2019-01-07 19:56:19+00:00
- **Updated**: 2019-01-07 19:56:19+00:00
- **Authors**: Chiyu "Max" Jiang, Jingwei Huang, Karthik Kashinath, Prabhat, Philip Marcus, Matthias Niessner
- **Comment**: Accepted as a conference paper at ICLR 2019. Codes available at
  https://github.com/maxjiang93/ugscnn
- **Journal**: None
- **Summary**: We present an efficient convolution kernel for Convolutional Neural Networks (CNNs) on unstructured grids using parameterized differential operators while focusing on spherical signals such as panorama images or planetary signals. To this end, we replace conventional convolution kernels with linear combinations of differential operators that are weighted by learnable parameters. Differential operators can be efficiently estimated on unstructured grids using one-ring neighbors, and learnable parameters can be optimized through standard back-propagation. As a result, we obtain extremely efficient neural networks that match or outperform state-of-the-art network architectures in terms of performance but with a significantly lower number of network parameters. We evaluate our algorithm in an extensive series of experiments on a variety of computer vision and climate science tasks, including shape classification, climate pattern segmentation, and omnidirectional image semantic segmentation. Overall, we present (1) a novel CNN approach on unstructured grids using parameterized differential operators for spherical signals, and (2) we show that our unique kernel parameterization allows our model to achieve the same or higher accuracy with significantly fewer network parameters.



### Reproducibility Evaluation of SLANT Whole Brain Segmentation Across Clinical Magnetic Resonance Imaging Protocols
- **Arxiv ID**: http://arxiv.org/abs/1901.02040v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.02040v1)
- **Published**: 2019-01-07 19:57:07+00:00
- **Updated**: 2019-01-07 19:57:07+00:00
- **Authors**: Yunxi Xiong, Yuankai Huo, Jiachen Wang, L. Taylor Davis, Maureen McHugo, Bennett A. Landman
- **Comment**: To appear in SPIE Medical Imaging 2019
- **Journal**: None
- **Summary**: Whole brain segmentation on structural magnetic resonance imaging (MRI) is essential for understanding neuroanatomical-functional relationships. Traditionally, multi-atlas segmentation has been regarded as the standard method for whole brain segmentation. In past few years, deep convolutional neural network (DCNN) segmentation methods have demonstrated their advantages in both accuracy and computational efficiency. Recently, we proposed the spatially localized atlas network tiles (SLANT) method, which is able to segment a 3D MRI brain scan into 132 anatomical regions. Commonly, DCNN segmentation methods yield inferior performance under external validations, especially when the testing patterns were not presented in the training cohorts. Recently, we obtained a clinically acquired, multi-sequence MRI brain cohort with 1480 clinically acquired, de-identified brain MRI scans on 395 patients using seven different MRI protocols. Moreover, each subject has at least two scans from different MRI protocols. Herein, we assess the SLANT method's intra- and inter-protocol reproducibility. SLANT achieved less than 0.05 coefficient of variation (CV) for intra-protocol experiments and less than 0.15 CV for inter-protocol experiments. The results show that the SLANT method achieved high intra- and inter- protocol reproducibility.



### Convolutional Neural Networks on non-uniform geometrical signals using Euclidean spectral transformation
- **Arxiv ID**: http://arxiv.org/abs/1901.02070v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CG, cs.LG, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/1901.02070v1)
- **Published**: 2019-01-07 21:23:33+00:00
- **Updated**: 2019-01-07 21:23:33+00:00
- **Authors**: Chiyu "Max" Jiang, Dequan Wang, Jingwei Huang, Philip Marcus, Matthias Nießner
- **Comment**: Accepted as a conference paper at ICLR 2019
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNN) have been successful in processing data signals that are uniformly sampled in the spatial domain (e.g., images). However, most data signals do not natively exist on a grid, and in the process of being sampled onto a uniform physical grid suffer significant aliasing error and information loss. Moreover, signals can exist in different topological structures as, for example, points, lines, surfaces and volumes. It has been challenging to analyze signals with mixed topologies (for example, point cloud with surface mesh). To this end, we develop mathematical formulations for Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample nonuniform data signals of different topologies defined on a simplex mesh into the spectral domain with no spatial sampling error. The spectral transform is performed in the Euclidean space, which removes the translation ambiguity from works on the graph spectrum. Our representation has four distinct advantages: (1) the process causes no spatial sampling error during the initial sampling, (2) the generality of this approach provides a unified framework for using CNNs to analyze signals of mixed topologies, (3) it allows us to leverage state-of-the-art backbone CNN architectures for effective learning without having to design a particular architecture for a particular data structure in an ad-hoc fashion, and (4) the representation allows weighted meshes where each element has a different weight (i.e., texture) indicating local properties. We achieve results on par with the state-of-the-art for the 3D shape retrieval task, and a new state-of-the-art for the point cloud to surface reconstruction task.



### All Graphs Lead to Rome: Learning Geometric and Cycle-Consistent Representations with Graph Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.02078v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.02078v1)
- **Published**: 2019-01-07 21:35:20+00:00
- **Updated**: 2019-01-07 21:35:20+00:00
- **Authors**: Stephen Phillips, Kostas Daniilidis
- **Comment**: 9 pages, 7 figures, 2 tables, 2 supplemental figures
- **Journal**: None
- **Summary**: Image feature matching is a fundamental part of many geometric computer vision applications, and using multiple images can improve performance. In this work, we formulate multi-image matching as a graph embedding problem then use a Graph Convolutional Network to learn an appropriate embedding function for aligning image features. We use cycle consistency to train our network in an unsupervised fashion, since ground truth correspondence is difficult or expensive to aquire. In addition, geometric consistency losses can be added at training time, even if the information is not available in the test set, unlike previous approaches that optimize cycle consistency directly. To the best of our knowledge, no other works have used learning for multi-image feature matching. Our experiments show that our method is competitive with other optimization based approaches.



### On the Dimensionality of Embeddings for Sparse Features and Data
- **Arxiv ID**: http://arxiv.org/abs/1901.02103v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.IT, math.IT, stat.ML, 68T05, I.2.6; I.5.0
- **Links**: [PDF](http://arxiv.org/pdf/1901.02103v1)
- **Published**: 2019-01-07 23:30:14+00:00
- **Updated**: 2019-01-07 23:30:14+00:00
- **Authors**: Maxim Naumov
- **Comment**: 8 pages, 2 figures
- **Journal**: None
- **Summary**: In this note we discuss a common misconception, namely that embeddings are always used to reduce the dimensionality of the item space. We show that when we measure dimensionality in terms of information entropy then the embedding of sparse probability distributions, that can be used to represent sparse features or data, may or not reduce the dimensionality of the item space. However, the embeddings do provide a different and often more meaningful representation of the items for a particular task at hand. Also, we give upper bounds and more precise guidelines for choosing the embedding dimension.



### Dynamics are Important for the Recognition of Equine Pain in Video
- **Arxiv ID**: http://arxiv.org/abs/1901.02106v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.02106v2)
- **Published**: 2019-01-07 23:47:11+00:00
- **Updated**: 2019-05-24 14:01:59+00:00
- **Authors**: Sofia Broomé, Karina Bech Gleerup, Pia Haubro Andersen, Hedvig Kjellström
- **Comment**: CVPR 2019: IEEE Conference on Computer Vision and Pattern Recognition
- **Journal**: None
- **Summary**: A prerequisite to successfully alleviate pain in animals is to recognize it, which is a great challenge in non-verbal species. Furthermore, prey animals such as horses tend to hide their pain. In this study, we propose a deep recurrent two-stream architecture for the task of distinguishing pain from non-pain in videos of horses. Different models are evaluated on a unique dataset showing horses under controlled trials with moderate pain induction, which has been presented in earlier work. Sequential models are experimentally compared to single-frame models, showing the importance of the temporal dimension of the data, and are benchmarked against a veterinary expert classification of the data. We additionally perform baseline comparisons with generalized versions of state-of-the-art human pain recognition methods. While equine pain detection in machine learning is a novel field, our results surpass veterinary expert performance and outperform pain detection results reported for other larger non-human species.



