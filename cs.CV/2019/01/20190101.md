# Arxiv Papers in cs.CV on 2019-01-01
### LiSHT: Non-Parametric Linearly Scaled Hyperbolic Tangent Activation Function for Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.05894v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.05894v4)
- **Published**: 2019-01-01 02:24:06+00:00
- **Updated**: 2023-02-17 01:49:12+00:00
- **Authors**: Swalpa Kumar Roy, Suvojit Manna, Shiv Ram Dubey, Bidyut Baran Chaudhuri
- **Comment**: Accepted in 7th International Conference on Computer Vision and Image
  Processing (CVIP), 2022
- **Journal**: None
- **Summary**: The activation function in neural network introduces the non-linearity required to deal with the complex tasks. Several activation/non-linearity functions are developed for deep learning models. However, most of the existing activation functions suffer due to the dying gradient problem and non-utilization of the large negative input values. In this paper, we propose a Linearly Scaled Hyperbolic Tangent (LiSHT) for Neural Networks (NNs) by scaling the Tanh linearly. The proposed LiSHT is non-parametric and tackles the dying gradient problem. We perform the experiments on benchmark datasets of different type, such as vector data, image data and natural language data. We observe the superior performance using Multi-layer Perceptron (MLP), Residual Network (ResNet) and Long-short term memory (LSTM) for data classification, image classification and tweets classification tasks, respectively. The accuracy on CIFAR100 dataset using ResNet model with LiSHT is improved by 9.48, 3.40, 3.16, 4.26, and 1.17\% as compared to Tanh, ReLU, PReLU, LReLU, and Swish, respectively. We also show the qualitative results using loss landscape, weight distribution and activations maps in support of the proposed activation function.



### A Performance Comparison of Loss Functions for Deep Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1901.05903v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.05903v2)
- **Published**: 2019-01-01 03:00:10+00:00
- **Updated**: 2019-11-06 08:49:18+00:00
- **Authors**: Yash Srivastava, Vaishnav Murali, Shiv Ram Dubey
- **Comment**: Accepted in NCVPRIPG 2019 Conference
- **Journal**: None
- **Summary**: Face recognition is one of the most widely publicized feature in the devices today and hence represents an important problem that should be studied with the utmost priority. As per the recent trends, the Convolutional Neural Network (CNN) based approaches are highly successful in many tasks of Computer Vision including face recognition. The loss function is used on the top of CNN to judge the goodness of any network. In this paper, we present a performance comparison of different loss functions such as Cross-Entropy, Angular Softmax, Additive-Margin Softmax, ArcFace and Marginal Loss for face recognition. The experiments are conducted with two CNN architectures namely, ResNet and MobileNet. Two widely used face datasets namely, CASIA-Webface and MS-Celeb-1M are used for the training and benchmark Labeled Faces in the Wild (LFW) face dataset is used for the testing.



### Not All Words are Equal: Video-specific Information Loss for Video Captioning
- **Arxiv ID**: http://arxiv.org/abs/1901.00097v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00097v1)
- **Published**: 2019-01-01 05:19:02+00:00
- **Updated**: 2019-01-01 05:19:02+00:00
- **Authors**: Jiarong Dong, Ke Gao, Xiaokai Chen, Junbo Guo, Juan Cao, Yongdong Zhang
- **Comment**: BMVC2018 accepted
- **Journal**: None
- **Summary**: An ideal description for a given video should fix its gaze on salient and representative content, which is capable of distinguishing this video from others. However, the distribution of different words is unbalanced in video captioning datasets, where distinctive words for describing video-specific salient objects are far less than common words such as 'a' 'the' and 'person'. The dataset bias often results in recognition error or detail deficiency of salient but unusual objects. To address this issue, we propose a novel learning strategy called Information Loss, which focuses on the relationship between the video-specific visual content and corresponding representative words. Moreover, a framework with hierarchical visual representations and an optimized hierarchical attention mechanism is established to capture the most salient spatial-temporal visual information, which fully exploits the potential strength of the proposed learning strategy. Extensive experiments demonstrate that the ingenious guidance strategy together with the optimized architecture outperforms state-of-the-art video captioning methods on MSVD with CIDEr score 87.5, and achieves superior CIDEr score 47.7 on MSR-VTT. We also show that our Information Loss is generic which improves various models by significant margins.



### Training with the Invisibles: Obfuscating Images to Share Safely for Learning Visual Recognition Models
- **Arxiv ID**: http://arxiv.org/abs/1901.00098v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.00098v2)
- **Published**: 2019-01-01 05:39:05+00:00
- **Updated**: 2019-06-21 15:12:43+00:00
- **Authors**: Tae-hoon Kim, Dongmin Kang, Kari Pulli, Jonghyun Choi
- **Comment**: The logical flow and the experimental validations have to be
  significantly revised
- **Journal**: None
- **Summary**: High-performance visual recognition systems generally require a large collection of labeled images to train. The expensive data curation can be an obstacle for improving recognition performance. Sharing more data allows training for better models. But personal and private information in the data prevent such sharing. To promote sharing visual data for learning a recognition model, we propose to obfuscate the images so that humans are not able to recognize their detailed contents, while machines can still utilize them to train new models. We validate our approach by comprehensive experiments on three challenging visual recognition tasks; image classification, attribute classification, and facial landmark detection on several datasets including SVHN, CIFAR10, Pascal VOC 2012, CelebA, and MTFL. Our method successfully obfuscates the images from humans recognition, but a machine model trained with them performs within about 1% margin (up to 0.48%) of the performance of a model trained with the original, non-obfuscated data.



### A Noise-Sensitivity-Analysis-Based Test Prioritization Technique for Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.00054v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.00054v3)
- **Published**: 2019-01-01 06:42:59+00:00
- **Updated**: 2019-01-20 02:12:25+00:00
- **Authors**: Long Zhang, Xuechao Sun, Yong Li, Zhenyu Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have been widely used in the fields such as natural language processing, computer vision and image recognition. But several studies have been shown that deep neural networks can be easily fooled by artificial examples with some perturbations, which are widely known as adversarial examples. Adversarial examples can be used to attack deep neural networks or to improve the robustness of deep neural networks. A common way of generating adversarial examples is to first generate some noises and then add them into original examples. In practice, different examples have different noise-sensitive. To generate an effective adversarial example, it may be necessary to add a lot of noise to low noise-sensitive example, which may make the adversarial example meaningless. In this paper, we propose a noise-sensitivity-analysis-based test prioritization technique to pick out examples by their noise sensitivity. We construct an experiment to validate our approach on four image sets and two DNN models, which shows that examples are sensitive to noise and our method can effectively pick out examples by their noise sensitivity.



### Morphological Network: How Far Can We Go with Morphological Neurons?
- **Arxiv ID**: http://arxiv.org/abs/1901.00109v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.00109v4)
- **Published**: 2019-01-01 07:52:24+00:00
- **Updated**: 2022-12-14 04:48:24+00:00
- **Authors**: Ranjan Mondal, Sanchayan Santra, Soumendu Sundar Mukherjee, Bhabatosh Chanda
- **Comment**: Accepted at BMVC 2022
- **Journal**: None
- **Summary**: Morphological neurons, that is morphological operators such as dilation and erosion with learnable structuring elements, have intrigued researchers for quite some time because of the power these operators bring to the table despite their simplicity. These operators are known to be powerful nonlinear tools, but for a given problem coming up with a sequence of operations and their structuring element is a non-trivial task. So, the existing works have mainly focused on this part of the problem without delving deep into their applicability as generic operators. A few works have tried to utilize morphological neurons as a part of classification (and regression) networks when the input is a feature vector. However, these methods mainly focus on a specific problem, without going into generic theoretical analysis. In this work, we have theoretically analyzed morphological neurons and have shown that these are far more powerful than previously anticipated. Our proposed morphological block, containing dilation and erosion followed by their linear combination, represents a sum of hinge functions. Existing works show that hinge functions perform quite well in classification and regression problems. Two morphological blocks can even approximate any continuous function. However, to facilitate the theoretical analysis that we have done in this paper, we have restricted ourselves to the 1D version of the operators, where the structuring element operates on the whole input. Experimental evaluations also indicate the effectiveness of networks built with morphological neurons, over similarly structured neural networks.



### Gated-Dilated Networks for Lung Nodule Classification in CT scans
- **Arxiv ID**: http://arxiv.org/abs/1901.00120v2
- **DOI**: 10.1109/ACCESS.2019.2958663
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.00120v2)
- **Published**: 2019-01-01 09:13:17+00:00
- **Updated**: 2019-12-14 10:47:42+00:00
- **Authors**: Mundher Al-Shabi, Hwee Kuan Lee, Maxine Tan
- **Comment**: Published in IEEE Access
- **Journal**: None
- **Summary**: Different types of Convolutional Neural Networks (CNNs) have been applied to detect cancerous lung nodules from computed tomography (CT) scans. However, the size of a nodule is very diverse and can range anywhere between 3 and 30 millimeters. The high variation of nodule sizes makes classifying them a difficult and challenging task. In this study, we propose a novel CNN architecture called Gated-Dilated (GD) networks to classify nodules as malignant or benign. Unlike previous studies, the GD network uses multiple dilated convolutions instead of max-poolings to capture the scale variations. Moreover, the GD network has a Context-Aware sub-network that analyzes the input features and guides the features to a suitable dilated convolution. We evaluated the proposed network on more than 1,000 CT scans from the LIDC-LDRI dataset. Our proposed network outperforms state-of-the-art baseline models including Multi-Crop, Resnet, and Densenet, with an AUC of >0.95. Compared to the baseline models, the GD network improves the classification accuracies of mid-range sized nodules. Furthermore, we observe a relationship between the size of the nodule and the attention signal generated by the Context-Aware sub-network, which validates our new network architecture.



### FPGA-based Accelerators of Deep Learning Networks for Learning and Classification: A Review
- **Arxiv ID**: http://arxiv.org/abs/1901.00121v1
- **DOI**: 10.1109/ACCESS.2018.2890150
- **Categories**: **cs.NE**, cs.AR, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.00121v1)
- **Published**: 2019-01-01 09:17:51+00:00
- **Updated**: 2019-01-01 09:17:51+00:00
- **Authors**: Ahmad Shawahna, Sadiq M. Sait, Aiman El-Maleh
- **Comment**: This article has been accepted for publication in IEEE Access
  (December, 2018)
- **Journal**: None
- **Summary**: Due to recent advances in digital technologies, and availability of credible data, an area of artificial intelligence, deep learning, has emerged, and has demonstrated its ability and effectiveness in solving complex learning problems not possible before. In particular, convolution neural networks (CNNs) have demonstrated their effectiveness in image detection and recognition applications. However, they require intensive CPU operations and memory bandwidth that make general CPUs fail to achieve desired performance levels. Consequently, hardware accelerators that use application specific integrated circuits (ASICs), field programmable gate arrays (FPGAs), and graphic processing units (GPUs) have been employed to improve the throughput of CNNs. More precisely, FPGAs have been recently adopted for accelerating the implementation of deep learning networks due to their ability to maximize parallelism as well as due to their energy efficiency. In this paper, we review recent existing techniques for accelerating deep learning networks on FPGAs. We highlight the key features employed by the various techniques for improving the acceleration performance. In addition, we provide recommendations for enhancing the utilization of FPGAs for CNNs acceleration. The techniques investigated in this paper represent the recent trends in FPGA-based accelerators of deep learning networks. Thus, this review is expected to direct the future advances on efficient hardware accelerators and to be useful for deep learning researchers.



### Rethinking on Multi-Stage Networks for Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1901.00148v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00148v4)
- **Published**: 2019-01-01 12:52:37+00:00
- **Updated**: 2019-05-30 01:30:32+00:00
- **Authors**: Wenbo Li, Zhicheng Wang, Binyi Yin, Qixiang Peng, Yuming Du, Tianzi Xiao, Gang Yu, Hongtao Lu, Yichen Wei, Jian Sun
- **Comment**: None
- **Journal**: None
- **Summary**: Existing pose estimation approaches fall into two categories: single-stage and multi-stage methods. While multi-stage methods are seemingly more suited for the task, their performance in current practice is not as good as single-stage methods. This work studies this issue. We argue that the current multi-stage methods' unsatisfactory performance comes from the insufficiency in various design choices. We propose several improvements, including the single-stage module design, cross stage feature aggregation, and coarse-to-fine supervision. The resulting method establishes the new state-of-the-art on both MS COCO and MPII Human Pose dataset, justifying the effectiveness of a multi-stage architecture. The source code is publicly available for further research.



### Handwritten Indic Character Recognition using Capsule Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.00166v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00166v1)
- **Published**: 2019-01-01 15:33:13+00:00
- **Updated**: 2019-01-01 15:33:13+00:00
- **Authors**: Bodhisatwa Mandal, Suvam Dubey, Swarnendu Ghosh, Ritesh Sarkhel, Nibaran Das
- **Comment**: Accepted in IEEE Applied Signal Processing Conference 2018(ASPCON
  2018 ) held on December 7-9, 2018 at Jadavpur University, Kolkata, India
- **Journal**: None
- **Summary**: Convolutional neural networks(CNNs) has become one of the primary algorithms for various computer vision tasks. Handwritten character recognition is a typical example of such task that has also attracted attention. CNN architectures such as LeNet and AlexNet have become very prominent over the last two decades however the spatial invariance of the different kernels has been a prominent issue till now. With the introduction of capsule networks, kernels can work together in consensus with one another with the help of dynamic routing, that combines individual opinions of multiple groups of kernels called capsules to employ equivariance among kernels. In the current work, we have implemented capsule network on handwritten Indic digits and character datasets to show its superiority over networks like LeNet. Furthermore, it has also been shown that they can boost the performance of other networks like LeNet and AlexNet.



### Nasal Patches and Curves for Expression-robust 3D Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1901.00206v1
- **DOI**: 10.1109/TPAMI.2016.2565473
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00206v1)
- **Published**: 2019-01-01 20:05:44+00:00
- **Updated**: 2019-01-01 20:05:44+00:00
- **Authors**: Mehryar Emambakhsh, Adrian Evans
- **Comment**: None
- **Journal**: IEEE Transactions on Pattern Analysis and Machine Intelligence
  (PAMI), vol. 39, no. 5, pp. 995-1007, 2017
- **Summary**: The potential of the nasal region for expression robust 3D face recognition is thoroughly investigated by a novel five-step algorithm. First, the nose tip location is coarsely detected and the face is segmented, aligned and the nasal region cropped. Then, a very accurate and consistent nasal landmarking algorithm detects seven keypoints on the nasal region. In the third step, a feature extraction algorithm based on the surface normals of Gabor-wavelet filtered depth maps is utilised and, then, a set of spherical patches and curves are localised over the nasal region to provide the feature descriptors. The last step applies a genetic algorithm-based feature selector to detect the most stable patches and curves over different facial expressions. The algorithm provides the highest reported nasal region-based recognition ranks on the FRGC, Bosphorus and BU-3DFE datasets. The results are comparable with, and in many cases better than, many state-of-the-art 3D face recognition algorithms, which use the whole facial domain. The proposed method does not rely on sophisticated alignment or denoising steps, is very robust when only one sample per subject is used in the gallery, and does not require a training step for the landmarking algorithm. https://github.com/mehryaragha/NoseBiometrics



### Mapping Areas using Computer Vision Algorithms and Drones
- **Arxiv ID**: http://arxiv.org/abs/1901.00211v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00211v1)
- **Published**: 2019-01-01 21:24:07+00:00
- **Updated**: 2019-01-01 21:24:07+00:00
- **Authors**: Bashar Alhafni, Saulo Fernando Guedes, Lays Cavalcante Ribeiro, Juhyun Park, Jeongkyu Lee
- **Comment**: 7 pages, 12 figures. This work was presented at the American Society
  for Engineering Education (ASEE) Northeast Conference in 2016
- **Journal**: None
- **Summary**: The goal of this paper is to implement a system, titled as Drone Map Creator (DMC) using Computer Vision techniques. DMC can process visual information from an HD camera in a drone and automatically create a map by stitching together visual information captured by a drone. The proposed approach employs the Speeded up robust features (SURF) method to detect the key points for each image frame; then the corresponding points between the frames are identified by maximizing the determinant of a Hessian matrix. Finally, two images are stitched together by using the identified points. Our results show that despite some limitations from the external environment, we could have successfully stitched images together along video sequences.



### EdgeConnect: Generative Image Inpainting with Adversarial Edge Learning
- **Arxiv ID**: http://arxiv.org/abs/1901.00212v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.00212v3)
- **Published**: 2019-01-01 21:38:40+00:00
- **Updated**: 2019-01-11 18:31:31+00:00
- **Authors**: Kamyar Nazeri, Eric Ng, Tony Joseph, Faisal Z. Qureshi, Mehran Ebrahimi
- **Comment**: Code and data: https://github.com/knazeri/edge-connect
- **Journal**: None
- **Summary**: Over the last few years, deep learning techniques have yielded significant improvements in image inpainting. However, many of these techniques fail to reconstruct reasonable structures as they are commonly over-smoothed and/or blurry. This paper develops a new approach for image inpainting that does a better job of reproducing filled regions exhibiting fine details. We propose a two-stage adversarial model EdgeConnect that comprises of an edge generator followed by an image completion network. The edge generator hallucinates edges of the missing region (both regular and irregular) of the image, and the image completion network fills in the missing regions using hallucinated edges as a priori. We evaluate our model end-to-end over the publicly available datasets CelebA, Places2, and Paris StreetView, and show that it outperforms current state-of-the-art techniques quantitatively and qualitatively. Code and models available at: https://github.com/knazeri/edge-connect



