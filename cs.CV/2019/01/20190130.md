# Arxiv Papers in cs.CV on 2019-01-30
### Robust X-ray Sparse-view Phase Tomography via Hierarchical Synthesis Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.10644v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10644v1)
- **Published**: 2019-01-30 02:14:15+00:00
- **Updated**: 2019-01-30 02:14:15+00:00
- **Authors**: Ziling Wu, Abdulaziz Alorf, Ting Yang, Ling Li, Yunhui Zhu
- **Comment**: 9 pages, 6 figures, 2 tables
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNN) based image reconstruction methods have been intensely used for X-ray computed tomography (CT) reconstruction applications. Despite great success, good performance of this data-based approach critically relies on a representative big training data set and a dense convoluted deep network. The indiscriminating convolution connections over all dense layers could be prone to over-fitting, where sampling biases are wrongly integrated as features for the reconstruction. In this paper, we report a robust hierarchical synthesis reconstruction approach, where training data is pre-processed to separate the information on the domains where sampling biases are suspected. These split bands are then trained separately and combined successively through a hierarchical synthesis network. We apply the hierarchical synthesis reconstruction for two important and classical tomography reconstruction scenarios: the spares-view reconstruction and the phase reconstruction. Our simulated and experimental results show that comparable or improved performances are achieved with a dramatic reduction of network complexity and computational cost. This method can be generalized to a wide range of applications including material characterization, in-vivo monitoring and dynamic 4D imaging.



### Adversarial Metric Attack and Defense for Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1901.10650v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10650v3)
- **Published**: 2019-01-30 02:41:50+00:00
- **Updated**: 2020-10-10 14:50:18+00:00
- **Authors**: Song Bai, Yingwei Li, Yuyin Zhou, Qizhu Li, Philip H. S. Torr
- **Comment**: Accepted by IEEE Transactions on Pattern Analysis and Machine
  Intelligence (TPAMI)
- **Journal**: None
- **Summary**: Person re-identification (re-ID) has attracted much attention recently due to its great importance in video surveillance. In general, distance metrics used to identify two person images are expected to be robust under various appearance changes. However, our work observes the extreme vulnerability of existing distance metrics to adversarial examples, generated by simply adding human-imperceptible perturbations to person images. Hence, the security danger is dramatically increased when deploying commercial re-ID systems in video surveillance. Although adversarial examples have been extensively applied for classification analysis, it is rarely studied in metric analysis like person re-identification. The most likely reason is the natural gap between the training and testing of re-ID networks, that is, the predictions of a re-ID network cannot be directly used during testing without an effective metric. In this work, we bridge the gap by proposing Adversarial Metric Attack, a parallel methodology to adversarial classification attacks. Comprehensive experiments clearly reveal the adversarial effects in re-ID systems. Meanwhile, we also present an early attempt of training a metric-preserving network, thereby defending the metric against adversarial attacks. At last, by benchmarking various adversarial settings, we expect that our work can facilitate the development of adversarial attack and defense in metric-based applications.



### A Mobile Robot Generating Video Summaries of Seniors' Indoor Activities
- **Arxiv ID**: http://arxiv.org/abs/1901.10713v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10713v2)
- **Published**: 2019-01-30 08:54:31+00:00
- **Updated**: 2019-07-23 04:35:57+00:00
- **Authors**: Chih-Yuan Yang, Heeseung Yun, Srenavis Varadaraj, Jane Yung-jen Hsu
- **Comment**: accepted by MobileHCI'19
- **Journal**: None
- **Summary**: We develop a system which generates summaries from seniors' indoor-activity videos captured by a social robot to help remote family members know their seniors' daily activities at home. Unlike the traditional video summarization datasets, indoor videos captured from a moving robot poses additional challenges, namely, (i) the video sequences are very long (ii) a significant number of video-frames contain no-subject or with subjects at ill-posed locations and scales (iii) most of the well-posed frames contain highly redundant information. To address this problem, we propose to \hl{exploit} pose estimation \hl{for detecting} people in frames\hl{. This guides the robot} to follow the user and capture effective videos. We use person identification to distinguish a target senior from other people. We \hl{also make use of} action recognition to analyze seniors' major activities at different moments, and develop a video summarization method to select diverse and representative keyframes as summaries.



### A study for Image compression using Re-Pair algorithm
- **Arxiv ID**: http://arxiv.org/abs/1901.10744v3
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1901.10744v3)
- **Published**: 2019-01-30 10:17:52+00:00
- **Updated**: 2019-02-13 11:36:43+00:00
- **Authors**: Pasquale De Luca, Vincenzo Maria Russiello, Raffaele Ciro Sannino, Lorenzo Valente
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: The compression is an important topic in computer science which allows we to storage more amount of data on our data storage. There are several techniques to compress any file. In this manuscript will be described the most important algorithm to compress images such as JPEG and it will be compared with another method to retrieve good reason to not use this method on images. So to compress the text the most encoding technique known is the Huffman Encoding which it will be explained in exhaustive way. In this manuscript will showed how to compute a text compression method on images in particular the method and the reason to choice a determinate image format against the other. The method studied and analyzed in this manuscript is the Re-Pair algorithm which is purely for grammatical context to be compress. At the and it will be showed the good result of this application.



### Autonomous Cars: Vision based Steering Wheel Angle Estimation
- **Arxiv ID**: http://arxiv.org/abs/1901.10747v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10747v1)
- **Published**: 2019-01-30 10:22:37+00:00
- **Updated**: 2019-01-30 10:22:37+00:00
- **Authors**: Kemal Alkin Gunbay, Mert Arikan, Mehmet Turkan
- **Comment**: 5 pages, 6 figures
- **Journal**: None
- **Summary**: Machine learning models, which are frequently used in self-driving cars, are trained by matching the captured images of the road and the measured angle of the steering wheel. The angle of the steering wheel is generally fetched from steering angle sensor, which is tightly-coupled to the physical aspects of the vehicle at hand. Therefore, a model-agnostic autonomous car-kit is very difficult to be developed and autonomous vehicles need more training data. The proposed vision based steering angle estimation system argues a new approach which basically matches the images of the road captured by an outdoor camera and the images of the steering wheel from an onboard camera, avoiding the burden of collecting model-dependent training data and the use of any other electromechanical hardware.



### Medical Image Super-Resolution Using a Generative Adversarial Network
- **Arxiv ID**: http://arxiv.org/abs/1902.00369v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.NA, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1902.00369v3)
- **Published**: 2019-01-30 11:14:55+00:00
- **Updated**: 2019-11-21 03:55:07+00:00
- **Authors**: Yongpei Zhu, Xuesheng Zhang, Kehong Yuan
- **Comment**: 5 pages,2 figures
- **Journal**: None
- **Summary**: During the growing popularity of electronic medical records, electronic medical record (EMR) data has exploded increasingly. It is very meaningful to retrieve high quality EMR in mass data. In this paper, an EMR value network with retrieval function is constructed by taking stroke disease as the research object. It mainly includes: 1) It establishes the electronic medical record database and corresponding stroke knowledge graph. 2) The strategy of similarity measurement is included three parts(patients' chief complaint, pathology results and medical images). Patients' chief complaints are text data, mainly describing patients' symptoms and expressed in words or phrases, and patients' chief complaints are input in independent tick of various symptoms. The data of the pathology results is a structured and digitized expression, so the input method is the same as the patient's chief complaint; Image similarity adopts content-based image retrieval(CBIR) technology. 3) The analytic hierarchy process (AHP) is used to establish the weights of the three types of data and then synthesize them into an indicator. The accuracy rate of similarity in top 5 was more than 85\% based on EMR database with more 200 stroke records using leave-one-out method. It will be the good tool for assistant diagnosis and doctor training, as good quality records are colleted into the databases, like Doctor Watson, in the future.



### Human-centric light sensing and estimation from RGBD images: The invisible light switch
- **Arxiv ID**: http://arxiv.org/abs/1901.10772v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10772v1)
- **Published**: 2019-01-30 11:37:17+00:00
- **Updated**: 2019-01-30 11:37:17+00:00
- **Authors**: Theodore Tsesmelis, Irtiza Hasan, Marco Cristani, Alessio Del Bue, Fabio Galasso
- **Comment**: None
- **Journal**: None
- **Summary**: Lighting design in indoor environments is of primary importance for at least two reasons: 1) people should perceive an adequate light; 2) an effective lighting design means consistent energy saving. We present the Invisible Light Switch (ILS) to address both aspects. ILS dynamically adjusts the room illumination level to save energy while maintaining constant the light level perception of the users. So the energy saving is invisible to them. Our proposed ILS leverages a radiosity model to estimate the light level which is perceived by a person within an indoor environment, taking into account the person position and her/his viewing frustum (head pose). ILS may therefore dim those luminaires, which are not seen by the user, resulting in an effective energy saving, especially in large open offices (where light may otherwise be ON everywhere for a single person). To quantify the system performance, we have collected a new dataset where people wear luxmeter devices while working in office rooms. The luxmeters measure the amount of light (in Lux) reaching the people gaze, which we consider a proxy to their illumination level perception. Our initial results are promising: in a room with 8 LED luminaires, the energy consumption in a day may be reduced from 18585 to 6206 watts with ILS (currently needing 1560 watts for operations). While doing so, the drop in perceived lighting decreases by just 200 lux, a value considered negligible when the original illumination level is above 1200 lux, as is normally the case in offices.



### Blurred Images Lead to Bad Local Minima
- **Arxiv ID**: http://arxiv.org/abs/1901.10788v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10788v1)
- **Published**: 2019-01-30 12:47:44+00:00
- **Updated**: 2019-01-30 12:47:44+00:00
- **Authors**: Gal Katzhendler, Daphna Weinshall
- **Comment**: None
- **Journal**: None
- **Summary**: Blurred Images Lead to Bad Local Minima



### Deep Archetypal Analysis
- **Arxiv ID**: http://arxiv.org/abs/1901.10799v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.10799v2)
- **Published**: 2019-01-30 13:04:53+00:00
- **Updated**: 2020-01-24 16:37:27+00:00
- **Authors**: Sebastian Mathias Keller, Maxim Samarin, Mario Wieser, Volker Roth
- **Comment**: Published at the German Conference on Pattern Recognition 2019 (GCPR)
- **Journal**: 41th German Conference on Pattern Recognition, GCPR 2019
- **Summary**: "Deep Archetypal Analysis" generates latent representations of high-dimensional datasets in terms of fractions of intuitively understandable basic entities called archetypes. The proposed method is an extension of linear "Archetypal Analysis" (AA), an unsupervised method to represent multivariate data points as sparse convex combinations of extremal elements of the dataset. Unlike the original formulation of AA, "Deep AA" can also handle side information and provides the ability for data-driven representation learning which reduces the dependence on expert knowledge. Our method is motivated by studies of evolutionary trade-offs in biology where archetypes are species highly adapted to a single task. Along these lines, we demonstrate that "Deep AA" also lends itself to the supervised exploration of chemical space, marking a distinct starting point for de novo molecular design. In the unsupervised setting we show how "Deep AA" is used on CelebA to identify archetypal faces. These can then be superimposed in order to generate new faces which inherit dominant traits of the archetypes they are based on.



### Automated Skin Lesion Classification Using Ensemble of Deep Neural Networks in ISIC 2018: Skin Lesion Analysis Towards Melanoma Detection Challenge
- **Arxiv ID**: http://arxiv.org/abs/1901.10802v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1901.10802v1)
- **Published**: 2019-01-30 13:10:11+00:00
- **Updated**: 2019-01-30 13:10:11+00:00
- **Authors**: Md Ashraful Alam Milton
- **Comment**: ISIC 2018
- **Journal**: None
- **Summary**: In this paper, we studied extensively on different deep learning based methods to detect melanoma and skin lesion cancers. Melanoma, a form of malignant skin cancer is very threatening to health. Proper diagnosis of melanoma at an earlier stage is crucial for the success rate of complete cure. Dermoscopic images with Benign and malignant forms of skin cancer can be analyzed by computer vision system to streamline the process of skin cancer detection. In this study, we experimented with various neural networks which employ recent deep learning based models like PNASNet-5-Large, InceptionResNetV2, SENet154, InceptionV4. Dermoscopic images are properly processed and augmented before feeding them into the network. We tested our methods on International Skin Imaging Collaboration (ISIC) 2018 challenge dataset. Our system has achieved best validation score of 0.76 for PNASNet-5-Large model. Further improvement and optimization of the proposed methods with a bigger training dataset and carefully chosen hyper-parameter could improve the performances. The code available for download at https://github.com/miltonbd/ISIC_2018_classification



### Diversity Regularized Adversarial Learning
- **Arxiv ID**: http://arxiv.org/abs/1901.10824v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.10824v1)
- **Published**: 2019-01-30 13:44:08+00:00
- **Updated**: 2019-01-30 13:44:08+00:00
- **Authors**: Babajide O. Ayinde, Keishin Nishihama, Jacek M. Zurada
- **Comment**: None
- **Journal**: None
- **Summary**: The two key players in Generative Adversarial Networks (GANs), the discriminator and generator, are usually parameterized as deep neural networks (DNNs). On many generative tasks, GANs achieve state-of-the-art performance but are often unstable to train and sometimes miss modes. A typical failure mode is the collapse of the generator to a single parameter configuration where its outputs are identical. When this collapse occurs, the gradient of the discriminator may point in similar directions for many similar points. We hypothesize that some of these shortcomings are in part due to primitive and redundant features extracted by discriminator and this can easily make the training stuck. We present a novel approach for regularizing adversarial models by enforcing diverse feature learning. In order to do this, both generator and discriminator are regularized by penalizing both negatively and positively correlated features according to their differentiation and based on their relative cosine distances. In addition to the gradient information from the adversarial loss made available by the discriminator, diversity regularization also ensures that a more stable gradient is provided to update both the generator and discriminator. Results indicate our regularizer enforces diverse features, stabilizes training, and improves image synthesis.



### View Invariant 3D Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1901.10841v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10841v1)
- **Published**: 2019-01-30 14:20:31+00:00
- **Updated**: 2019-01-30 14:20:31+00:00
- **Authors**: Guoqiang Wei, Cuiling Lan, Wenjun Zeng, Zhibo Chen
- **Comment**: None
- **Journal**: None
- **Summary**: The recent success of deep networks has significantly advanced 3D human pose estimation from 2D images. The diversity of capturing viewpoints and the flexibility of the human poses, however, remain some significant challenges. In this paper, we propose a view invariant 3D human pose estimation module to alleviate the effects of viewpoint diversity. The framework consists of a base network, which provides an initial estimation of a 3D pose, a view-invariant hierarchical correction network (VI-HC) on top of that to learn the 3D pose refinement under consistent views, and a view-invariant discriminative network (VID) to enforce high-level constraints over body configurations. In VI-HC, the initial 3D pose inputs are automatically transformed to consistent views for further refinements at the global body and local body parts level, respectively. For the VID, under consistent viewpoints, we use adversarial learning to differentiate between estimated poses and real poses to avoid implausible 3D poses. Experimental results demonstrate that the consistent viewpoints can dramatically enhance the performance. Our module shows robustness for different 3D pose base networks and achieves a significant improvement (about 9%) over a powerful baseline on the public 3D pose estimation benchmark Human3.6M.



### On Correlation of Features Extracted by Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1901.10900v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.10900v1)
- **Published**: 2019-01-30 15:31:35+00:00
- **Updated**: 2019-01-30 15:31:35+00:00
- **Authors**: Babajide O. Ayinde, Tamer Inanc, Jacek M. Zurada
- **Comment**: None
- **Journal**: None
- **Summary**: Redundancy in deep neural network (DNN) models has always been one of their most intriguing and important properties. DNNs have been shown to overparameterize, or extract a lot of redundant features. In this work, we explore the impact of size (both width and depth), activation function, and weight initialization on the susceptibility of deep neural network models to extract redundant features. To estimate the number of redundant features in each layer, all the features of a given layer are hierarchically clustered according to their relative cosine distances in feature space and a set threshold. It is shown that both network size and activation function are the two most important components that foster the tendency of DNNs to extract redundant features. The concept is illustrated using deep multilayer perceptron and convolutional neural networks on MNIST digits recognition and CIFAR-10 dataset, respectively.



### Characterization of migrated seismic volumes using texture attributes: a comparative study
- **Arxiv ID**: http://arxiv.org/abs/1901.10909v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10909v1)
- **Published**: 2019-01-30 15:42:19+00:00
- **Updated**: 2019-01-30 15:42:19+00:00
- **Authors**: Zhiling Long, Yazeed Alaudah, Muhammad Ali Qureshi, Motaz Al Farraj, Zhen Wang, Asjad Amin, Mohamed Deriche, Ghassan AlRegib
- **Comment**: None
- **Journal**: Proceedings of the SEG 85th Annual Meeting, New Orleans, LA, Oct.
  2015
- **Summary**: In this paper, we examine several typical texture attributes developed in the image processing community in recent years with respect to their capability of characterizing a migrated seismic volume. These attributes are generated in either frequency or space domain, including steerable pyramid, curvelet, local binary pattern, and local radius index. The comparative study is performed within an image retrieval framework. We evaluate these attributes in terms of retrieval accuracy. It is our hope that this comparative study will help acquaint the seismic interpretation community with the many available powerful image texture analysis techniques, providing more alternative attributes for their seismic exploration.



### Benchmarking Classic and Learned Navigation in Complex 3D Environments
- **Arxiv ID**: http://arxiv.org/abs/1901.10915v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1901.10915v2)
- **Published**: 2019-01-30 15:50:54+00:00
- **Updated**: 2019-03-28 11:58:29+00:00
- **Authors**: Dmytro Mishkin, Alexey Dosovitskiy, Vladlen Koltun
- **Comment**: Added CNN-Monodepth and OpenCV Stereo agents
- **Journal**: None
- **Summary**: Navigation research is attracting renewed interest with the advent of learning-based methods. However, this new line of work is largely disconnected from well-established classic navigation approaches. In this paper, we take a step towards coordinating these two directions of research. We set up classic and learning-based navigation systems in common simulated environments and thoroughly evaluate them in indoor spaces of varying complexity, with access to different sensory modalities. Additionally, we measure human performance in the same environments. We find that a classic pipeline, when properly tuned, can perform very well in complex cluttered environments. On the other hand, learned systems can operate more robustly with a limited sensor suite. Overall, both approaches are still far from human-level performance.



### Understanding spatial correlation in eye-fixation maps for visual attention in videos
- **Arxiv ID**: http://arxiv.org/abs/1901.10957v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.10957v1)
- **Published**: 2019-01-30 17:13:21+00:00
- **Updated**: 2019-01-30 17:13:21+00:00
- **Authors**: Tariq Alshawi, Zhiling Long, Ghassan AlRegib
- **Comment**: Proceedings of IEEE International Conference on Multimedia and Expo
  (ICME), Seattle, WA, Nov. 2016
- **Journal**: None
- **Summary**: In this paper, we present an analysis of recorded eye-fixation data from human subjects viewing video sequences. The purpose is to better understand visual attention for videos. Utilizing the eye-fixation data provided in the CRCNS (Collaborative Research in Computational Neuroscience) dataset, this paper focuses on the relation between the saliency of a pixel and that of its direct neighbors, without making any assumption about the structure of the eye-fixation maps. By employing some basic concepts from information theory, the analysis shows substantial correlation between the saliency of a pixel and the saliency of its neighborhood. The analysis also provides insights into the structure and dynamics of the eye-fixation maps, which can be very useful in understanding video saliency and its applications.



### New insights on Multi-Solution Distribution of the P3P Problem
- **Arxiv ID**: http://arxiv.org/abs/1901.11464v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.11464v1)
- **Published**: 2019-01-30 17:34:49+00:00
- **Updated**: 2019-01-30 17:34:49+00:00
- **Authors**: Bo Wang, Hao Hu, Caixia Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Traditionally, the P3P problem is solved by firstly transforming its 3 quadratic equations into a quartic one, then by locating the roots of the resulting quartic equation and verifying whether a root does really correspond to a true solution of the P3P problem itself. However, a root of the quartic equation does not always correspond to a solution of the P3P problem. In this work, we show that when the optical center is outside of all the 6 toroids defined by the control point triangle, each positive root of the Grunert's quartic equation must correspond to a true solution of the P3P problem, and the corresponding P3P problem cannot have a unique solution, it must have either 2 positive solutions or 4 positive solutions. In addition, we show that when the optical center passes through any one of the 3 toroids among these 6 toroids ( except possibly for two concentric circles) , the number of the solutions of the corresponding P3P problem always changes by 1, either increased by 1 or decreased by 1.Furthermore we show that such changed solutions always locate in a small neighborhood of control points, hence the 3 toroids are critical surfaces of the P3P problem and the 3 control points are 3 singular points of solutions. A notable example is that when the optical center passes through the outer surface of the union of the 6 toroids from the outside to inside, the number of the solutions must always decrease by 1. Our results are the first to give an explicit and geometrically intuitive relationship between the P3P solutions and the roots of its quartic equation. It could act as some theoretical guidance for P3P practitioners to properly arrange their control points to avoid undesirable solutions.



### Bootstrapping Robotic Ecological Perception from a Limited Set of Hypotheses Through Interactive Perception
- **Arxiv ID**: http://arxiv.org/abs/1901.10968v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1901.10968v1)
- **Published**: 2019-01-30 17:35:42+00:00
- **Updated**: 2019-01-30 17:35:42+00:00
- **Authors**: Léni K. Le Goff, Ghanim Mukhtar, Alexandre Coninx, Stéphane Doncieux
- **Comment**: 21 pages, 21 figures
- **Journal**: None
- **Summary**: To solve its task, a robot needs to have the ability to interpret its perceptions. In vision, this interpretation is particularly difficult and relies on the understanding of the structure of the scene, at least to the extent of its task and sensorimotor abilities. A robot with the ability to build and adapt this interpretation process according to its own tasks and capabilities would push away the limits of what robots can achieve in a non controlled environment. A solution is to provide the robot with processes to build such representations that are not specific to an environment or a situation. A lot of works focus on objects segmentation, recognition and manipulation. Defining an object solely on the basis of its visual appearance is challenging given the wide range of possible objects and environments. Therefore, current works make simplifying assumptions about the structure of a scene. Such assumptions reduce the adaptivity of the object extraction process to the environments in which the assumption holds. To limit such assumptions, we introduce an exploration method aimed at identifying moveable elements in a scene without considering the concept of object. By using the interactive perception framework, we aim at bootstrapping the acquisition process of a representation of the environment with a minimum of context specific assumptions. The robotic system builds a perceptual map called relevance map which indicates the moveable parts of the current scene. A classifier is trained online to predict the category of each region (moveable or non-moveable). It is also used to select a region with which to interact, with the goal of minimizing the uncertainty of the classification. A specific classifier is introduced to fit these needs: the collaborative mixture models classifier. The method is tested on a set of scenarios of increasing complexity, using both simulations and a PR2 robot.



### Noise2Self: Blind Denoising by Self-Supervision
- **Arxiv ID**: http://arxiv.org/abs/1901.11365v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.11365v2)
- **Published**: 2019-01-30 18:05:47+00:00
- **Updated**: 2019-06-08 23:46:25+00:00
- **Authors**: Joshua Batson, Loic Royer
- **Comment**: 10 pages, 6 figures, and supplement
- **Journal**: None
- **Summary**: We propose a general framework for denoising high-dimensional measurements which requires no prior on the signal, no estimate of the noise, and no clean training data. The only assumption is that the noise exhibits statistical independence across different dimensions of the measurement, while the true signal exhibits some correlation. For a broad class of functions ("$\mathcal{J}$-invariant"), it is then possible to estimate the performance of a denoiser from noisy data alone. This allows us to calibrate $\mathcal{J}$-invariant versions of any parameterised denoising algorithm, from the single hyperparameter of a median filter to the millions of weights of a deep neural network. We demonstrate this on natural image and microscopy data, where we exploit noise independence between pixels, and on single-cell gene expression data, where we exploit independence between detections of individual molecules. This framework generalizes recent work on training neural nets from noisy images and on cross-validation for matrix factorization.



### A Convolutional Neural Network for the Automatic Diagnosis of Collagen VI related Muscular Dystrophies
- **Arxiv ID**: http://arxiv.org/abs/1901.11074v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.11074v1)
- **Published**: 2019-01-30 19:59:33+00:00
- **Updated**: 2019-01-30 19:59:33+00:00
- **Authors**: Adrián Bazaga, Mònica Roldán, Carmen Badosa, Cecilia Jiménez-Mallebrera, Josep M. Porta
- **Comment**: Submitted for review to Expert Systems With Applications
- **Journal**: None
- **Summary**: The development of machine learning systems for the diagnosis of rare diseases is challenging mainly due the lack of data to study them. Despite this challenge, this paper proposes a system for the Computer Aided Diagnosis (CAD) of low-prevalence, congenital muscular dystrophies from confocal microscopy images. The proposed CAD system relies on a Convolutional Neural Network (CNN) which performs an independent classification for non-overlapping patches tiling the input image, and generates an overall decision summarizing the individual decisions for the patches on the query image. This decision scheme points to the possibly problematic areas in the input images and provides a global quantitative evaluation of the state of the patients, which is fundamental for diagnosis and to monitor the efficiency of therapies.



### Real-world Mapping of Gaze Fixations Using Instance Segmentation for Road Construction Safety Applications
- **Arxiv ID**: http://arxiv.org/abs/1901.11078v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1901.11078v2)
- **Published**: 2019-01-30 20:02:27+00:00
- **Updated**: 2019-02-01 19:47:25+00:00
- **Authors**: Idris Jeelani, Khashayar Asadi, Hariharan Ramshankar, Kevin Han, Alex Albert
- **Comment**: 2019 TRB Annual meeting
- **Journal**: None
- **Summary**: Research studies have shown that a large proportion of hazards remain unrecognized, which expose construction workers to unanticipated safety risks. Recent studies have also found that a strong correlation exists between viewing patterns of workers, captured using eye-tracking devices, and their hazard recognition performance. Therefore, it is important to analyze the viewing patterns of workers to gain a better understanding of their hazard recognition performance. This paper proposes a method that can automatically map the gaze fixations collected using a wearable eye-tracker to the predefined areas of interests. The proposed method detects these areas or objects (i.e., hazards) of interests through a computer vision-based segmentation technique and transfer learning. The mapped fixation data is then used to analyze the viewing behaviors of workers and compute their attention distribution. The proposed method is implemented on an under construction road as a case study to evaluate the performance of the proposed method.



### DDSL: Deep Differentiable Simplex Layer for Learning Geometric Signals
- **Arxiv ID**: http://arxiv.org/abs/1901.11082v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG
- **Links**: [PDF](http://arxiv.org/pdf/1901.11082v3)
- **Published**: 2019-01-30 20:17:50+00:00
- **Updated**: 2019-08-14 22:28:26+00:00
- **Authors**: Chiyu "Max" Jiang, Dana Lynn Ona Lansigan, Philip Marcus, Matthias Nießner
- **Comment**: None
- **Journal**: None
- **Summary**: We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for geometric deep learning. The DDSL is a differentiable layer compatible with deep neural networks for bridging simplex mesh-based geometry representations (point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images (e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to perform differentiable, efficient, anti-aliased rasterization of simplex-based signals. We present a complete theoretical framework for the process as well as an efficient backpropagation algorithm. Compared to previous differentiable renderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees and dimensions. In particular, we explore its applications to 2D shapes and illustrate two applications of this method: (1) mesh editing and optimization guided by neural network outputs, and (2) using DDSL for a differentiable rasterization loss to facilitate end-to-end training of polygon generators. We are able to validate the effectiveness of gradient-based shape optimization with the example of airfoil optimization, and using the differentiable rasterization loss to facilitate end-to-end training, we surpass state of the art for polygonal image segmentation given ground-truth bounding boxes.



### Resolution enhancement in scanning electron microscopy using deep learning
- **Arxiv ID**: http://arxiv.org/abs/1901.11094v1
- **DOI**: 10.1038/s41598-019-48444-2
- **Categories**: **cs.CV**, cs.LG, physics.app-ph
- **Links**: [PDF](http://arxiv.org/pdf/1901.11094v1)
- **Published**: 2019-01-30 20:48:59+00:00
- **Updated**: 2019-01-30 20:48:59+00:00
- **Authors**: Kevin de Haan, Zachary S. Ballard, Yair Rivenson, Yichen Wu, Aydogan Ozcan
- **Comment**: 8 pages, 4 figures
- **Journal**: Scientific Reports (2019)
- **Summary**: We report resolution enhancement in scanning electron microscopy (SEM) images using a generative adversarial network. We demonstrate the veracity of this deep learning-based super-resolution technique by inferring unresolved features in low-resolution SEM images and comparing them with the accurately co-registered high-resolution SEM images of the same samples. Through spatial frequency analysis, we also report that our method generates images with frequency spectra matching higher resolution SEM images of the same fields-of-view. By using this technique, higher resolution SEM images can be taken faster, while also reducing both electron charging and damage to the samples.



### Saliency detection for seismic applications using multi-dimensional spectral projections and directional comparisons
- **Arxiv ID**: http://arxiv.org/abs/1901.11095v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.11095v1)
- **Published**: 2019-01-30 20:49:26+00:00
- **Updated**: 2019-01-30 20:49:26+00:00
- **Authors**: Muhammad Amir Shafiq, Zhiling Long, Tariq Alshawi, Ghassan AlRegib
- **Comment**: None
- **Journal**: Proceedings of IEEE International Conference on Image Processing
  (ICIP), Beijing, China, Sep. 2017
- **Summary**: In this paper, we propose a novel approach for saliency detection for seismic applications using 3D-FFT local spectra and multi-dimensional plane projections. We develop a projection scheme by dividing a 3D-FFT local spectrum of a data volume into three distinct components, each depicting changes along a different dimension of the data. The saliency detection results obtained using each projected component are then combined to yield a saliency map. To accommodate the directional nature of seismic data, in this work, we modify the center-surround model, proven to be biologically plausible for visual attention, to incorporate directional comparisons around each voxel in a 3D volume. Experimental results on real seismic dataset from the F3 block in Netherlands offshore in the North Sea prove that the proposed algorithm is effective, efficient, and scalable. Furthermore, a subjective comparison of the results shows that it outperforms the state-of-the-art methods for saliency detection.



### Texture-Aware Superpixel Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1901.11111v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1901.11111v3)
- **Published**: 2019-01-30 21:37:35+00:00
- **Updated**: 2019-02-09 19:16:45+00:00
- **Authors**: Remi Giraud, Vinh-Thong Ta, Nicolas Papadakis, Yannick Berthoumieu
- **Comment**: None
- **Journal**: None
- **Summary**: Most superpixel algorithms compute a trade-off between spatial and color features at the pixel level. Hence, they may need fine parameter tuning to balance the two measures, and highly fail to group pixels with similar local texture properties. In this paper, we address these issues with a new Texture-Aware SuperPixel (TASP) method. To accurately segment textured and smooth areas, TASP automatically adjusts its spatial constraint according to the local feature variance. Then, to ensure texture homogeneity within superpixels, a new pixel to superpixel patch-based distance is proposed. TASP outperforms the segmentation accuracy of the state-of-the-art methods on texture and also natural color image datasets.



### Similar Image Search for Histopathology: SMILY
- **Arxiv ID**: http://arxiv.org/abs/1901.11112v3
- **DOI**: 10.1038/s41746-019-0131-z
- **Categories**: **cs.CV**, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1901.11112v3)
- **Published**: 2019-01-30 21:41:14+00:00
- **Updated**: 2019-02-06 02:15:17+00:00
- **Authors**: Narayan Hegde, Jason D. Hipp, Yun Liu, Michael E. Buck, Emily Reif, Daniel Smilkov, Michael Terry, Carrie J. Cai, Mahul B. Amin, Craig H. Mermel, Phil Q. Nelson, Lily H. Peng, Greg S. Corrado, Martin C. Stumpe
- **Comment**: 23 Pages with 6 figures and 3 tables. The file also has 6 pages of
  supplemental material. Improved figure resolution, edited metadata
- **Journal**: Nature Partner Journal Digital Medicine (2019)
- **Summary**: The increasing availability of large institutional and public histopathology image datasets is enabling the searching of these datasets for diagnosis, research, and education. Though these datasets typically have associated metadata such as diagnosis or clinical notes, even carefully curated datasets rarely contain annotations of the location of regions of interest on each image. Because pathology images are extremely large (up to 100,000 pixels in each dimension), further laborious visual search of each image may be needed to find the feature of interest. In this paper, we introduce a deep learning based reverse image search tool for histopathology images: Similar Medical Images Like Yours (SMILY). We assessed SMILY's ability to retrieve search results in two ways: using pathologist-provided annotations, and via prospective studies where pathologists evaluated the quality of SMILY search results. As a negative control in the second evaluation, pathologists were blinded to whether search results were retrieved by SMILY or randomly. In both types of assessments, SMILY was able to retrieve search results with similar histologic features, organ site, and prostate cancer Gleason grade compared with the original query. SMILY may be a useful general-purpose tool in the pathologist's arsenal, to improve the efficiency of searching large archives of histopathology images, without the need to develop and implement specific tools for each application.



### Understanding Beauty via Deep Facial Features
- **Arxiv ID**: http://arxiv.org/abs/1902.05380v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1902.05380v2)
- **Published**: 2019-01-30 22:51:21+00:00
- **Updated**: 2019-04-17 03:44:24+00:00
- **Authors**: Xudong Liu, Tao Li, Hao Peng, Iris Chuoying Ouyang, Taehwan Kim, Ruizhe Wang
- **Comment**: None
- **Journal**: None
- **Summary**: The concept of beauty has been debated by philosophers and psychologists for centuries, but most definitions are subjective and metaphysical, and deficit in accuracy, generality, and scalability. In this paper, we present a novel study on mining beauty semantics of facial attributes based on big data, with an attempt to objectively construct descriptions of beauty in a quantitative manner. We first deploy a deep convolutional neural network (CNN) to extract facial attributes, and then investigate correlations between these features and attractiveness on two large-scale datasets labelled with beauty scores. Not only do we discover the secrets of beauty verified by statistical significance tests, our findings also align perfectly with existing psychological studies that, e.g., small nose, high cheekbones, and femininity contribute to attractiveness. We further leverage these high-level representations to original images by a generative adversarial network (GAN). Beauty enhancements after synthesis are visually compelling and statistically convincing verified by a user survey of 10,000 data points.



