# Arxiv Papers in cs.CV on 2001-01-29
### The Generalized Universal Law of Generalization
- **Arxiv ID**: http://arxiv.org/abs/cs/0101036v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, math.PR, physics.soc-ph, J.4
- **Links**: [PDF](http://arxiv.org/pdf/cs/0101036v1)
- **Published**: 2001-01-29 17:54:50+00:00
- **Updated**: 2001-01-29 17:54:50+00:00
- **Authors**: Nick Chater, Paul Vitanyi
- **Comment**: 17 pages LaTeX, Submitted
- **Journal**: None
- **Summary**: It has been argued by Shepard that there is a robust psychological law that relates the distance between a pair of items in psychological space and the probability that they will be confused with each other. Specifically, the probability of confusion is a negative exponential function of the distance between the pair of items. In experimental contexts, distance is typically defined in terms of a multidimensional Euclidean space-but this assumption seems unlikely to hold for complex stimuli. We show that, nonetheless, the Universal Law of Generalization can be derived in the more complex setting of arbitrary stimuli, using a much more universal measure of distance. This universal distance is defined as the length of the shortest program that transforms the representations of the two items of interest into one another: the algorithmic information distance. It is universal in the sense that it minorizes every computable distance: it is the smallest computable distance. We show that the universal law of generalization holds with probability going to one-provided the confusion probabilities are computable. We also give a mathematically more appealing form



