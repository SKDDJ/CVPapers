# Arxiv Papers in cs.CV on 2012-08-21
### An Online Character Recognition System to Convert Grantha Script to Malayalam
- **Arxiv ID**: http://arxiv.org/abs/1208.4316v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1208.4316v1)
- **Published**: 2012-08-21 17:40:15+00:00
- **Updated**: 2012-08-21 17:40:15+00:00
- **Authors**: Sreeraj. M, Sumam Mary Idicula
- **Comment**: 6 pages, 6 figures
- **Journal**: International Journal of Advanced Computer Science and
  Applications(IJACSA, Volume 3 Issue 7, 2012
- **Summary**: This paper presents a novel approach to recognize Grantha, an ancient script in South India and converting it to Malayalam, a prevalent language in South India using online character recognition mechanism. The motivation behind this work owes its credit to (i) developing a mechanism to recognize Grantha script in this modern world and (ii) affirming the strong connection among Grantha and Malayalam. A framework for the recognition of Grantha script using online character recognition is designed and implemented. The features extracted from the Grantha script comprises mainly of time-domain features based on writing direction and curvature. The recognized characters are mapped to corresponding Malayalam characters. The framework was tested on a bed of medium length manuscripts containing 9-12 sample lines and printed pages of a book titled Soundarya Lahari writtenin Grantha by Sri Adi Shankara to recognize the words and sentences. The manuscript recognition rates with the system are for Grantha as 92.11%, Old Malayalam 90.82% and for new Malayalam script 89.56%. The recognition rates of pages of the printed book are for Grantha as 96.16%, Old Malayalam script 95.22% and new Malayalam script as 92.32% respectively. These results show the efficiency of the developed system.



### Iterative graph cuts for image segmentation with a nonlinear statistical shape prior
- **Arxiv ID**: http://arxiv.org/abs/1208.4384v2
- **DOI**: 10.1007/s10851-013-0440-9
- **Categories**: **cs.CV**, math.OC, physics.data-an, q-bio.QM, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1208.4384v2)
- **Published**: 2012-08-21 20:50:40+00:00
- **Updated**: 2013-02-22 13:13:49+00:00
- **Authors**: Joshua C. Chang, Tom Chou
- **Comment**: Revision submitted to JMIV (02/24/13)
- **Journal**: None
- **Summary**: Shape-based regularization has proven to be a useful method for delineating objects within noisy images where one has prior knowledge of the shape of the targeted object. When a collection of possible shapes is available, the specification of a shape prior using kernel density estimation is a natural technique. Unfortunately, energy functionals arising from kernel density estimation are of a form that makes them impossible to directly minimize using efficient optimization algorithms such as graph cuts. Our main contribution is to show how one may recast the energy functional into a form that is minimizable iteratively and efficiently using graph cuts.



### Shape Tracking With Occlusions via Coarse-To-Fine Region-Based Sobolev Descent
- **Arxiv ID**: http://arxiv.org/abs/1208.4391v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.SY
- **Links**: [PDF](http://arxiv.org/pdf/1208.4391v2)
- **Published**: 2012-08-21 21:37:15+00:00
- **Updated**: 2013-12-18 16:48:57+00:00
- **Authors**: Yanchao Yang, Ganesh Sundaramoorthi
- **Comment**: Extension of ICCV paper, added coarse-to-fine optimization based on
  new Riemannian manifold of parameterized regions
- **Journal**: None
- **Summary**: We present a method to track the precise shape of an object in video based on new modeling and optimization on a new Riemannian manifold of parameterized regions.   Joint dynamic shape and appearance models, in which a template of the object is propagated to match the object shape and radiance in the next frame, are advantageous over methods employing global image statistics in cases of complex object radiance and cluttered background. In cases of 3D object motion and viewpoint change, self-occlusions and dis-occlusions of the object are prominent, and current methods employing joint shape and appearance models are unable to adapt to new shape and appearance information, leading to inaccurate shape detection. In this work, we model self-occlusions and dis-occlusions in a joint shape and appearance tracking framework.   Self-occlusions and the warp to propagate the template are coupled, thus a joint problem is formulated. We derive a coarse-to-fine optimization scheme, advantageous in object tracking, that initially perturbs the template by coarse perturbations before transitioning to finer-scale perturbations, traversing all scales, seamlessly and automatically. The scheme is a gradient descent on a novel infinite-dimensional Riemannian manifold that we introduce. The manifold consists of planar parameterized regions, and the metric that we introduce is a novel Sobolev-type metric defined on infinitesimal vector fields on regions. The metric has the property of resulting in a gradient descent that automatically favors coarse-scale deformations (when they reduce the energy) before moving to finer-scale deformations.   Experiments on video exhibiting occlusion/dis-occlusion, complex radiance and background show that occlusion/dis-occlusion modeling leads to superior shape accuracy compared to recent methods employing joint shape/appearance models or employing global statistics.



### A Unified Approach for Modeling and Recognition of Individual Actions and Group Activities
- **Arxiv ID**: http://arxiv.org/abs/1208.4398v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1208.4398v1)
- **Published**: 2012-08-21 22:40:16+00:00
- **Updated**: 2012-08-21 22:40:16+00:00
- **Authors**: Qiang Qiu, Rama Chellappa
- **Comment**: None
- **Journal**: None
- **Summary**: Recognizing group activities is challenging due to the difficulties in isolating individual entities, finding the respective roles played by the individuals and representing the complex interactions among the participants. Individual actions and group activities in videos can be represented in a common framework as they share the following common feature: both are composed of a set of low-level features describing motions, e.g., optical flow for each pixel or a trajectory for each feature point, according to a set of composition constraints in both temporal and spatial dimensions. In this paper, we present a unified model to assess the similarity between two given individual or group activities. Our approach avoids explicit extraction of individual actors, identifying and representing the inter-person interactions. With the proposed approach, retrieval from a video database can be performed through Query-by-Example; and activities can be recognized by querying videos containing known activities. The suggested video matching process can be performed in an unsupervised manner. We demonstrate the performance of our approach by recognizing a set of human actions and football plays.



