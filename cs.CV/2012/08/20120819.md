# Arxiv Papers in cs.CV on 2012-08-19
### Joint-ViVo: Selecting and Weighting Visual Words Jointly for Bag-of-Features based Tissue Classification in Medical Images
- **Arxiv ID**: http://arxiv.org/abs/1208.3822v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1208.3822v2)
- **Published**: 2012-08-19 11:12:44+00:00
- **Updated**: 2013-04-05 07:30:44+00:00
- **Authors**: Jingyan Wang
- **Comment**: This paper has been withdrawn by the author due to the terrible
  writing
- **Journal**: None
- **Summary**: Automatically classifying the tissues types of Region of Interest (ROI) in medical imaging has been an important application in Computer-Aided Diagnosis (CAD), such as classification of breast parenchymal tissue in the mammogram, classify lung disease patterns in High-Resolution Computed Tomography (HRCT) etc. Recently, bag-of-features method has shown its power in this field, treating each ROI as a set of local features. In this paper, we investigate using the bag-of-features strategy to classify the tissue types in medical imaging applications. Two important issues are considered here: the visual vocabulary learning and weighting. Although there are already plenty of algorithms to deal with them, all of them treat them independently, namely, the vocabulary learned first and then the histogram weighted. Inspired by Auto-Context who learns the features and classifier jointly, we try to develop a novel algorithm that learns the vocabulary and weights jointly. The new algorithm, called Joint-ViVo, works in an iterative way. In each iteration, we first learn the weights for each visual word by maximizing the margin of ROI triplets, and then select the most discriminate visual words based on the learned weights for the next iteration. We test our algorithm on three tissue classification tasks: identifying brain tissue type in magnetic resonance imaging (MRI), classifying lung tissue in HRCT images, and classifying breast tissue density in mammograms. The results show that Joint-ViVo can perform effectively for classifying tissues.



### Discriminative Sparse Coding on Multi-Manifold for Data Representation and Classification
- **Arxiv ID**: http://arxiv.org/abs/1208.3839v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1208.3839v2)
- **Published**: 2012-08-19 14:49:27+00:00
- **Updated**: 2013-04-03 14:21:40+00:00
- **Authors**: Jing-Yan Wang
- **Comment**: This paper has been withdrawn by the author due to the terrible
  writing
- **Journal**: None
- **Summary**: Sparse coding has been popularly used as an effective data representation method in various applications, such as computer vision, medical imaging and bioinformatics, etc. However, the conventional sparse coding algorithms and its manifold regularized variants (graph sparse coding and Laplacian sparse coding), learn the codebook and codes in a unsupervised manner and neglect the class information available in the training set. To address this problem, in this paper we propose a novel discriminative sparse coding method based on multi-manifold, by learning discriminative class-conditional codebooks and sparse codes from both data feature space and class labels. First, the entire training set is partitioned into multiple manifolds according to the class labels. Then, we formulate the sparse coding as a manifold-manifold matching problem and learn class-conditional codebooks and codes to maximize the manifold margins of different classes. Lastly, we present a data point-manifold matching error based strategy to classify the unlabeled data point. Experimental results on somatic mutations identification and breast tumors classification in ultrasonic images tasks demonstrate the efficacy of the proposed data representation-classification approach.



### Adaptive Graph via Multiple Kernel Learning for Nonnegative Matrix Factorization
- **Arxiv ID**: http://arxiv.org/abs/1208.3845v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1208.3845v3)
- **Published**: 2012-08-19 15:21:09+00:00
- **Updated**: 2013-04-03 14:21:50+00:00
- **Authors**: Jing-Yan Wang, Mustafa AbdulJabbar
- **Comment**: This paper has been withdrawn by the author due to the terrible
  writing
- **Journal**: None
- **Summary**: Nonnegative Matrix Factorization (NMF) has been continuously evolving in several areas like pattern recognition and information retrieval methods. It factorizes a matrix into a product of 2 low-rank non-negative matrices that will define parts-based, and linear representation of nonnegative data. Recently, Graph regularized NMF (GrNMF) is proposed to find a compact representation,which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. In GNMF, an affinity graph is constructed from the original data space to encode the geometrical information. In this paper, we propose a novel idea which engages a Multiple Kernel Learning approach into refining the graph structure that reflects the factorization of the matrix and the new data space. The GrNMF is improved by utilizing the graph refined by the kernel learning, and then a novel kernel learning method is introduced under the GrNMF framework. Our approach shows encouraging results of the proposed algorithm in comparison to the state-of-the-art clustering algorithms like NMF, GrNMF, SVD etc.



### Trace transform based method for color image domain identification
- **Arxiv ID**: http://arxiv.org/abs/1208.3901v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1208.3901v3)
- **Published**: 2012-08-19 22:21:19+00:00
- **Updated**: 2019-03-25 12:48:59+00:00
- **Authors**: Igor G. Olaizola, Marco Quartulli, Julian Florez, Basilio Sierra
- **Comment**: This paper has been momentaneously withdrawn
- **Journal**: None
- **Summary**: Context categorization is a fundamental pre-requisite for multi-domain multimedia content analysis applications in order to manage contextual information in an efficient manner. In this paper, we introduce a new color image context categorization method (DITEC) based on the trace transform. The problem of dimensionality reduction of the obtained trace transform signal is addressed through statistical descriptors that keep the underlying information. These extracted features offer a highly discriminant behavior for content categorization. The theoretical properties of the method are analyzed and validated experimentally through two different datasets.



