# Arxiv Papers in cs.CV on 2012-04-19
### Speech Recognition: Increasing Efficiency of Support Vector Machines
- **Arxiv ID**: http://arxiv.org/abs/1204.4257v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1204.4257v1)
- **Published**: 2012-04-19 06:10:02+00:00
- **Updated**: 2012-04-19 06:10:02+00:00
- **Authors**: Aamir Khan, Muhammad Farhan, Asar Ali
- **Comment**: 5 pages, 11 figures. arXiv admin note: text overlap with
  arXiv:1201.3720 and arXiv:1204.1177
- **Journal**: International Journal of Computer Applications 35(7):17-21,
  December 2011
- **Summary**: With the advancement of communication and security technologies, it has become crucial to have robustness of embedded biometric systems. This paper presents the realization of such technologies which demands reliable and error-free biometric identity verification systems. High dimensional patterns are not permitted due to eigen-decomposition in high dimensional feature space and degeneration of scattering matrices in small size sample. Generalization, dimensionality reduction and maximizing the margins are controlled by minimizing weight vectors. Results show good pattern by multimodal biometric system proposed in this paper. This paper is aimed at investigating a biometric identity system using Support Vector Machines(SVMs) and Lindear Discriminant Analysis(LDA) with MFCCs and implementing such system in real-time using SignalWAVE.



### Learning in Riemannian Orbifolds
- **Arxiv ID**: http://arxiv.org/abs/1204.4294v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1204.4294v1)
- **Published**: 2012-04-19 09:29:10+00:00
- **Updated**: 2012-04-19 09:29:10+00:00
- **Authors**: Brijnesh J. Jain, Klaus Obermayer
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1001.0921
- **Journal**: None
- **Summary**: Learning in Riemannian orbifolds is motivated by existing machine learning algorithms that directly operate on finite combinatorial structures such as point patterns, trees, and graphs. These methods, however, lack statistical justification. This contribution derives consistency results for learning problems in structured domains and thereby generalizes learning in vector spaces and manifolds.



### Dynamic Template Tracking and Recognition
- **Arxiv ID**: http://arxiv.org/abs/1204.4476v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.SY
- **Links**: [PDF](http://arxiv.org/pdf/1204.4476v1)
- **Published**: 2012-04-19 21:17:08+00:00
- **Updated**: 2012-04-19 21:17:08+00:00
- **Authors**: Rizwan Chaudhry, Gregory Hager, Rene Vidal
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we address the problem of tracking non-rigid objects whose local appearance and motion changes as a function of time. This class of objects includes dynamic textures such as steam, fire, smoke, water, etc., as well as articulated objects such as humans performing various actions. We model the temporal evolution of the object's appearance/motion using a Linear Dynamical System (LDS). We learn such models from sample videos and use them as dynamic templates for tracking objects in novel videos. We pose the problem of tracking a dynamic non-rigid object in the current frame as a maximum a-posteriori estimate of the location of the object and the latent state of the dynamical system, given the current image features and the best estimate of the state in the previous frame. The advantage of our approach is that we can specify a-priori the type of texture to be tracked in the scene by using previously trained models for the dynamics of these textures. Our framework naturally generalizes common tracking methods such as SSD and kernel-based tracking from static templates to dynamic templates. We test our algorithm on synthetic as well as real examples of dynamic textures and show that our simple dynamics-based trackers perform at par if not better than the state-of-the-art. Since our approach is general and applicable to any image feature, we also apply it to the problem of human action tracking and build action-specific optical flow trackers that perform better than the state-of-the-art when tracking a human performing a particular action. Finally, since our approach is generative, we can use a-priori trained trackers for different texture or action classes to simultaneously track and recognize the texture or action in the video.



