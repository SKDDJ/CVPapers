# Arxiv Papers in cs.CV on 2012-03-05
### Online Discriminative Dictionary Learning for Image Classification Based on Block-Coordinate Descent Method
- **Arxiv ID**: http://arxiv.org/abs/1203.0856v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1203.0856v1)
- **Published**: 2012-03-05 10:43:15+00:00
- **Updated**: 2012-03-05 10:43:15+00:00
- **Authors**: Shu Kong, Donghui Wang
- **Comment**: This paper was completed in Dec 2010, and submitted (unsuccessfully)
  to ICCV2011
- **Journal**: None
- **Summary**: Previous researches have demonstrated that the framework of dictionary learning with sparse coding, in which signals are decomposed as linear combinations of a few atoms of a learned dictionary, is well adept to reconstruction issues. This framework has also been used for discrimination tasks such as image classification. To achieve better performances of classification, experts develop several methods to learn a discriminative dictionary in a supervised manner. However, another issue is that when the data become extremely large in scale, these methods will be no longer effective as they are all batch-oriented approaches. For this reason, we propose a novel online algorithm for discriminative dictionary learning, dubbed \textbf{ODDL} in this paper. First, we introduce a linear classifier into the conventional dictionary learning formulation and derive a discriminative dictionary learning problem. Then, we exploit an online algorithm to solve the derived problem. Unlike the most existing approaches which update dictionary and classifier alternately via iteratively solving sub-problems, our approach directly explores them jointly. Meanwhile, it can largely shorten the runtime for training and is also particularly suitable for large-scale classification issues. To evaluate the performance of the proposed ODDL approach in image recognition, we conduct some experiments on three well-known benchmarks, and the experimental results demonstrate ODDL is fairly promising for image classification tasks.



### An MLP based Approach for Recognition of Handwritten `Bangla' Numerals
- **Arxiv ID**: http://arxiv.org/abs/1203.0876v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1203.0876v1)
- **Published**: 2012-03-05 12:06:54+00:00
- **Updated**: 2012-03-05 12:06:54+00:00
- **Authors**: Subhadip Basu, Nibaran Das, Ram Sarkar, Mahantapas Kundu, Mita Nasipuri, Dipak Kumar Basu
- **Comment**: None
- **Journal**: Proc. 2nd Indian International Conference on Artificial
  Intelligence, pp. 407-417, Dec. 2005, Pune
- **Summary**: The work presented here involves the design of a Multi Layer Perceptron (MLP) based pattern classifier for recognition of handwritten Bangla digits using a 76 element feature vector. Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten Bangla numerals here includes 24 shadow features, 16 centroid features and 36 longest-run features. On experimentation with a database of 6000 samples, the technique yields an average recognition rate of 96.67% evaluated after three-fold cross validation of results. It is useful for applications related to OCR of handwritten Bangla Digit and can also be extended to include OCR of handwritten characters of Bangla alphabet.



### Handwritten Bangla Alphabet Recognition using an MLP Based Classifier
- **Arxiv ID**: http://arxiv.org/abs/1203.0882v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1203.0882v1)
- **Published**: 2012-03-05 12:22:23+00:00
- **Updated**: 2012-03-05 12:22:23+00:00
- **Authors**: Subhadip Basu, Nibaran Das, Ram Sarkar, Mahantapas Kundu, Mita Nasipuri, Dipak Kumar Basu
- **Comment**: None
- **Journal**: Proc. of the 2nd National Conf. on Computer Processing of Bangla,
  pp. 285-291, Feb-2005, Dhaka
- **Summary**: The work presented here involves the design of a Multi Layer Perceptron (MLP) based classifier for recognition of handwritten Bangla alphabet using a 76 element feature set Bangla is the second most popular script and language in the Indian subcontinent and the fifth most popular language in the world. The feature set developed for representing handwritten characters of Bangla alphabet includes 24 shadow features, 16 centroid features and 36 longest-run features. Recognition performances of the MLP designed to work with this feature set are experimentally observed as 86.46% and 75.05% on the samples of the training and the test sets respectively. The work has useful application in the development of a complete OCR system for handwritten Bangla text.



### Autocalibration with the Minimum Number of Cameras with Known Pixel Shape
- **Arxiv ID**: http://arxiv.org/abs/1203.0905v2
- **DOI**: 10.1007/s10851-014-0492-5
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1203.0905v2)
- **Published**: 2012-03-05 13:18:44+00:00
- **Updated**: 2014-01-10 23:55:00+00:00
- **Authors**: José I. Ronda, Antonio Valdés, Guillermo Gallego
- **Comment**: 19 pages, 14 figures, 7 tables, J. Math. Imaging Vis
- **Journal**: Journal of Mathematical Imaging and Vision, Vol. 50, No. 3, pp.
  179-198, Nov. 2014
- **Summary**: In 3D reconstruction, the recovery of the calibration parameters of the cameras is paramount since it provides metric information about the observed scene, e.g., measures of angles and ratios of distances. Autocalibration enables the estimation of the camera parameters without using a calibration device, but by enforcing simple constraints on the camera parameters. In the absence of information about the internal camera parameters such as the focal length and the principal point, the knowledge of the camera pixel shape is usually the only available constraint. Given a projective reconstruction of a rigid scene, we address the problem of the autocalibration of a minimal set of cameras with known pixel shape and otherwise arbitrarily varying intrinsic and extrinsic parameters. We propose an algorithm that only requires 5 cameras (the theoretical minimum), thus halving the number of cameras required by previous algorithms based on the same constraint. To this purpose, we introduce as our basic geometric tool the six-line conic variety (SLCV), consisting in the set of planes intersecting six given lines of 3D space in points of a conic. We show that the set of solutions of the Euclidean upgrading problem for three cameras with known pixel shape can be parameterized in a computationally efficient way. This parameterization is then used to solve autocalibration from five or more cameras, reducing the three-dimensional search space to a two-dimensional one. We provide experiments with real images showing the good performance of the technique.



### Invariant Scattering Convolution Networks
- **Arxiv ID**: http://arxiv.org/abs/1203.1513v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1203.1513v2)
- **Published**: 2012-03-05 17:12:42+00:00
- **Updated**: 2012-03-08 10:29:32+00:00
- **Authors**: Joan Bruna, Stéphane Mallat
- **Comment**: 15 pages double column, 9 figures
- **Journal**: None
- **Summary**: A wavelet scattering network computes a translation invariant image representation, which is stable to deformations and preserves high frequency information for classification. It cascades wavelet transform convolutions with non-linear modulus and averaging operators. The first network layer outputs SIFT-type descriptors whereas the next layers provide complementary invariant information which improves classification. The mathematical analysis of wavelet scattering networks explains important properties of deep convolution networks for classification.   A scattering representation of stationary processes incorporates higher order moments and can thus discriminate textures having the same Fourier power spectrum. State of the art classification results are obtained for handwritten digits and texture discrimination, using a Gaussian kernel SVM and a generative PCA classifier.



### Sparse Subspace Clustering: Algorithm, Theory, and Applications
- **Arxiv ID**: http://arxiv.org/abs/1203.1005v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.IT, cs.LG, math.IT, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1203.1005v3)
- **Published**: 2012-03-05 18:58:32+00:00
- **Updated**: 2013-02-05 03:22:00+00:00
- **Authors**: Ehsan Elhamifar, Rene Vidal
- **Comment**: None
- **Journal**: None
- **Summary**: In many real-world problems, we are dealing with collections of high-dimensional data, such as images, videos, text and web documents, DNA microarray data, and more. Often, high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories the data belongs to. In this paper, we propose and study an algorithm, called Sparse Subspace Clustering (SSC), to cluster data points that lie in a union of low-dimensional subspaces. The key idea is that, among infinitely many possible representations of a data point in terms of other points, a sparse representation corresponds to selecting a few points from the same subspace. This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of data into subspaces. Since solving the sparse optimization program is in general NP-hard, we consider a convex relaxation and show that, under appropriate conditions on the arrangement of subspaces and the distribution of data, the proposed minimization program succeeds in recovering the desired sparse representations. The proposed algorithm can be solved efficiently and can handle data points near the intersections of subspaces. Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal with data nuisances, such as noise, sparse outlying entries, and missing entries, directly by incorporating the model of the data into the sparse optimization program. We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering.



