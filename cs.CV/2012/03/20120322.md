# Arxiv Papers in cs.CV on 2012-03-22
### A Co-Prime Blur Scheme for Data Security in Video Surveillance
- **Arxiv ID**: http://arxiv.org/abs/1203.4874v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1203.4874v1)
- **Published**: 2012-03-22 02:57:53+00:00
- **Updated**: 2012-03-22 02:57:53+00:00
- **Authors**: Christopher Thorpe, Feng Li, Zijia Li, Zhan Yu, David Saunders, Jingyi Yu
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a novel Coprime Blurred Pair (CBP) model for visual data-hiding for security in camera surveillance. While most previous approaches have focused on completely encrypting the video stream, we introduce a spatial encryption scheme by blurring the image/video contents to create a CBP. Our goal is to obscure detail in public video streams by blurring while allowing behavior to be recognized and to quickly deblur the stream so that details are available if behavior is recognized as suspicious. We create a CBP by blurring the same latent image with two unknown kernels. The two kernels are coprime when mapped to bivariate polynomials in the z domain. To deblur the CBP we first use the coprime constraint to approximate the kernels and sample the bivariate CBP polynomials in one dimension on the unit circle. At each sample point, we factor the 1D polynomial pair and compose the results into a 2D kernel matrix. Finally, we compute the inverse Fast Fourier Transform (FFT) of the kernel matrices to recover the coprime kernels and then the latent video stream. It is therefore only possible to deblur the video stream if a user has access to both streams. To improve the practicability of our algorithm, we implement our algorithm using a graphics processing unit (GPU) to decrypt the blurred video streams in real-time, and extensive experimental results demonstrate that our new scheme can effectively protect sensitive identity information in surveillance videos and faithfully reconstruct the unblurred video stream when two blurred sequences are available.



### Kernel Density Feature Points Estimator for Content-Based Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1203.5078v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1203.5078v1)
- **Published**: 2012-03-22 18:47:57+00:00
- **Updated**: 2012-03-22 18:47:57+00:00
- **Authors**: Tranos Zuva, Oludayo O. Olugbara, Sunday O. Ojo, Seleman M. Ngwira
- **Comment**: ISSN 0975-5578 (Online) 0975-5934 (Print)
- **Journal**: Signal & Image Processing: An International Journal (SIPIJ), Vol.4
  No 1, February 2012, Pages: 103-111
- **Summary**: Research is taking place to find effective algorithms for content-based image representation and description. There is a substantial amount of algorithms available that use visual features (color, shape, texture). Shape feature has attracted much attention from researchers that there are many shape representation and description algorithms in literature. These shape image representation and description algorithms are usually not application independent or robust, making them undesirable for generic shape description. This paper presents an object shape representation using Kernel Density Feature Points Estimator (KDFPE). In this method, the density of feature points within defined rings around the centroid of the image is obtained. The KDFPE is then applied to the vector of the image. KDFPE is invariant to translation, scale and rotation. This method of image representation shows improved retrieval rate when compared to Density Histogram Feature Points (DHFP) method. Analytic analysis is done to justify our method, which was compared with the DHFP to prove its robustness.



### Acceleration of the shiftable O(1) algorithm for bilateral filtering and non-local means
- **Arxiv ID**: http://arxiv.org/abs/1203.5128v2
- **DOI**: 10.1109/TIP.2012.2222903
- **Categories**: **cs.CV**, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/1203.5128v2)
- **Published**: 2012-03-22 21:09:37+00:00
- **Updated**: 2012-08-07 18:57:45+00:00
- **Authors**: Kunal N. Chaudhury
- **Comment**: 10 figures, 6 tables
- **Journal**: IEEE Transactions on Image Processing, vol. 22(4), pp. 1291- 1300,
  2013
- **Summary**: A direct implementation of the bilateral filter [1] requires O(\sigma_s^2) operations per pixel, where \sigma_s is the (effective) width of the spatial kernel. A fast implementation of the bilateral filter was recently proposed in [2] that required O(1) operations per pixel with respect to \sigma_s. This was done by using trigonometric functions for the range kernel of the bilateral filter, and by exploiting their so-called shiftability property. In particular, a fast implementation of the Gaussian bilateral filter was realized by approximating the Gaussian range kernel using raised cosines. Later, it was demonstrated in [3] that this idea could be extended to a larger class of filters, including the popular non-local means filter [4]. As already observed in [2], a flip side of this approach was that the run time depended on the width \sigma_r of the range kernel. For an image with (local) intensity variations in the range [0,T], the run time scaled as O(T^2/\sigma^2_r) with \sigma_r. This made it difficult to implement narrow range kernels, particularly for images with large dynamic range. We discuss this problem in this note, and propose some simple steps to accelerate the implementation in general, and for small \sigma_r in particular.   [1] C. Tomasi and R. Manduchi, "Bilateral filtering for gray and color images", Proc. IEEE International Conference on Computer Vision, 1998.   [2] K.N. Chaudhury, Daniel Sage, and M. Unser, "Fast O(1) bilateral filtering using trigonometric range kernels", IEEE Transactions on Image Processing, 2011.   [3] K.N. Chaudhury, "Constant-time filtering using shiftable kernels", IEEE Signal Processing Letters, 2011.   [4] A. Buades, B. Coll, and J.M. Morel, "A review of image denoising algorithms, with a new one", Multiscale Modeling and Simulation, 2005.



