# Arxiv Papers in cs.CV on 2012-10-04
### Learning Human Activities and Object Affordances from RGB-D Videos
- **Arxiv ID**: http://arxiv.org/abs/1210.1207v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1210.1207v2)
- **Published**: 2012-10-04 04:53:42+00:00
- **Updated**: 2013-05-06 01:13:39+00:00
- **Authors**: Hema Swetha Koppula, Rudhir Gupta, Ashutosh Saxena
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1208.0967
- **Journal**: None
- **Summary**: Understanding human activities and object affordances are two very important skills, especially for personal robots which operate in human environments. In this work, we consider the problem of extracting a descriptive labeling of the sequence of sub-activities being performed by a human, and more importantly, of their interactions with the objects in the form of associated affordances. Given a RGB-D video, we jointly model the human activities and object affordances as a Markov random field where the nodes represent objects and sub-activities, and the edges represent the relationships between object affordances, their relations with sub-activities, and their evolution over time. We formulate the learning problem using a structural support vector machine (SSVM) approach, where labelings over various alternate temporal segmentations are considered as latent variables. We tested our method on a challenging dataset comprising 120 activity videos collected from 4 subjects, and obtained an accuracy of 79.4% for affordance, 63.4% for sub-activity and 75.0% for high-level activity labeling. We then demonstrate the use of such descriptive labeling in performing assistive tasks by a PR2 robot.



### Learning Locality-Constrained Collaborative Representation for Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1210.1316v2
- **DOI**: 10.1016/j.patcog.2014.03.013
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1210.1316v2)
- **Published**: 2012-10-04 07:12:49+00:00
- **Updated**: 2013-03-30 07:12:30+00:00
- **Authors**: Xi Peng, Lei Zhang, Zhang Yi, Kok Kiong Tan
- **Comment**: 16 pages, v2
- **Journal**: Pattern Recognition, 47 (9), 2794-2806, 2014
- **Summary**: The model of low-dimensional manifold and sparse representation are two well-known concise models that suggest each data can be described by a few characteristics. Manifold learning is usually investigated for dimension reduction by preserving some expected local geometric structures from the original space to a low-dimensional one. The structures are generally determined by using pairwise distance, e.g., Euclidean distance. Alternatively, sparse representation denotes a data point as a linear combination of the points from the same subspace. In practical applications, however, the nearby points in terms of pairwise distance may not belong to the same subspace, and vice versa. Consequently, it is interesting and important to explore how to get a better representation by integrating these two models together. To this end, this paper proposes a novel coding algorithm, called Locality-Constrained Collaborative Representation (LCCR), which improves the robustness and discrimination of data representation by introducing a kind of local consistency. The locality term derives from a biologic observation that the similar inputs have similar code. The objective function of LCCR has an analytical solution, and it does not involve local minima. The empirical studies based on four public facial databases, ORL, AR, Extended Yale B, and Multiple PIE, show that LCCR is promising in recognizing human faces from frontal views with varying expression and illumination, as well as various corruptions and occlusions.



