# Arxiv Papers in cs.CV on 2012-10-01
### Intra-Retinal Layer Segmentation of 3D Optical Coherence Tomography Using Coarse Grained Diffusion Map
- **Arxiv ID**: http://arxiv.org/abs/1210.0310v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1210.0310v2)
- **Published**: 2012-10-01 08:52:29+00:00
- **Updated**: 2012-10-08 11:05:28+00:00
- **Authors**: Raheleh Kafieh, Hossein Rabbani, Michael D. Abramoff, Milan Sonka
- **Comment**: 30 pages,32 figures
- **Journal**: None
- **Summary**: Optical coherence tomography (OCT) is a powerful and noninvasive method for retinal imaging. In this paper, we introduce a fast segmentation method based on a new variant of spectral graph theory named diffusion maps. The research is performed on spectral domain (SD) OCT images depicting macular and optic nerve head appearance. The presented approach does not require edge-based image information and relies on regional image texture. Consequently, the proposed method demonstrates robustness in situations of low image contrast or poor layer-to-layer image gradients. Diffusion mapping is applied to 2D and 3D OCT datasets composed of two steps, one for partitioning the data into important and less important sections, and another one for localization of internal layers.In the first step, the pixels/voxels are grouped in rectangular/cubic sets to form a graph node.The weights of a graph are calculated based on geometric distances between pixels/voxels and differences of their mean intensity.The first diffusion map clusters the data into three parts, the second of which is the area of interest. The other two sections are eliminated from the remaining calculations. In the second step, the remaining area is subjected to another diffusion map assessment and the internal layers are localized based on their textural similarities.The proposed method was tested on 23 datasets from two patient groups (glaucoma and normals). The mean unsigned border positioning errors(mean - SD) was 8.52 - 3.13 and 7.56 - 2.95 micrometer for the 2D and 3D methods, respectively.



### Enhanced Techniques for PDF Image Segmentation and Text Extraction
- **Arxiv ID**: http://arxiv.org/abs/1210.0347v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1210.0347v1)
- **Published**: 2012-10-01 10:38:08+00:00
- **Updated**: 2012-10-01 10:38:08+00:00
- **Authors**: D. Sasirekha, E. Chandra
- **Comment**: 5 pages, 5 figures
- **Journal**: None
- **Summary**: Extracting text objects from the PDF images is a challenging problem. The text data present in the PDF images contain certain useful information for automatic annotation, indexing etc. However variations of the text due to differences in text style, font, size, orientation, alignment as well as complex structure make the problem of automatic text extraction extremely difficult and challenging job. This paper presents two techniques under block-based classification. After a brief introduction of the classification methods, two methods were enhanced and results were evaluated. The performance metrics for segmentation and time consumption are tested for both the models.



### Combined Descriptors in Spatial Pyramid Domain for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1210.0386v3
- **DOI**: None
- **Categories**: **cs.CV**, I.4.9; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1210.0386v3)
- **Published**: 2012-10-01 13:05:20+00:00
- **Updated**: 2012-10-03 02:48:47+00:00
- **Authors**: Junlin Hu, Ping Guo
- **Comment**: 9 pages, 5 figures
- **Journal**: None
- **Summary**: Recently spatial pyramid matching (SPM) with scale invariant feature transform (SIFT) descriptor has been successfully used in image classification. Unfortunately, the codebook generation and feature quantization procedures using SIFT feature have the high complexity both in time and space. To address this problem, in this paper, we propose an approach which combines local binary patterns (LBP) and three-patch local binary patterns (TPLBP) in spatial pyramid domain. The proposed method does not need to learn the codebook and feature quantization processing, hence it becomes very efficient. Experiments on two popular benchmark datasets demonstrate that the proposed method always significantly outperforms the very popular SPM based SIFT descriptor method both in time and classification accuracy.



### Super-resolution using Sparse Representations over Learned Dictionaries: Reconstruction of Brain Structure using Electron Microscopy
- **Arxiv ID**: http://arxiv.org/abs/1210.0564v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1210.0564v1)
- **Published**: 2012-10-01 20:30:36+00:00
- **Updated**: 2012-10-01 20:30:36+00:00
- **Authors**: Tao Hu, Juan Nunez-Iglesias, Shiv Vitaladevuni, Lou Scheffer, Shan Xu, Mehdi Bolorizadeh, Harald Hess, Richard Fetter, Dmitri Chklovskii
- **Comment**: 12 pages, 11 figures
- **Journal**: None
- **Summary**: A central problem in neuroscience is reconstructing neuronal circuits on the synapse level. Due to a wide range of scales in brain architecture such reconstruction requires imaging that is both high-resolution and high-throughput. Existing electron microscopy (EM) techniques possess required resolution in the lateral plane and either high-throughput or high depth resolution but not both. Here, we exploit recent advances in unsupervised learning and signal processing to obtain high depth-resolution EM images computationally without sacrificing throughput. First, we show that the brain tissue can be represented as a sparse linear combination of localized basis functions that are learned using high-resolution datasets. We then develop compressive sensing-inspired techniques that can reconstruct the brain tissue from very few (typically 5) tomographic views of each section. This enables tracing of neuronal processes and, hence, high throughput reconstruction of neural circuits on the level of individual synapses.



