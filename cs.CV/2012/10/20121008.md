# Arxiv Papers in cs.CV on 2012-10-08
### Epitome for Automatic Image Colorization
- **Arxiv ID**: http://arxiv.org/abs/1210.4481v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1210.4481v1)
- **Published**: 2012-10-08 06:35:04+00:00
- **Updated**: 2012-10-08 06:35:04+00:00
- **Authors**: Yingzhen Yang, Xinqi Chu, Tian-Tsong Ng, Alex Yong-Sang Chia, Shuicheng Yan, Thomas S. Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Image colorization adds color to grayscale images. It not only increases the visual appeal of grayscale images, but also enriches the information contained in scientific images that lack color information. Most existing methods of colorization require laborious user interaction for scribbles or image segmentation. To eliminate the need for human labor, we develop an automatic image colorization method using epitome. Built upon a generative graphical model, epitome is a condensed image appearance and shape model which also proves to be an effective summary of color information for the colorization task. We train the epitome from the reference images and perform inference in the epitome to colorize grayscale images, rendering better colorization results than previous method in our experiments.



### Semisupervised Classifier Evaluation and Recalibration
- **Arxiv ID**: http://arxiv.org/abs/1210.2162v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1210.2162v1)
- **Published**: 2012-10-08 07:15:57+00:00
- **Updated**: 2012-10-08 07:15:57+00:00
- **Authors**: Peter Welinder, Max Welling, Pietro Perona
- **Comment**: None
- **Journal**: None
- **Summary**: How many labeled examples are needed to estimate a classifier's performance on a new dataset? We study the case where data is plentiful, but labels are expensive. We show that by making a few reasonable assumptions on the structure of the data, it is possible to estimate performance curves, with confidence bounds, using a small number of ground truth labels. Our approach, which we call Semisupervised Performance Evaluation (SPE), is based on a generative model for the classifier's confidence scores. In addition to estimating the performance of classifiers on new datasets, SPE can be used to recalibrate a classifier by re-estimating the class-conditional confidence distributions.



### A notion of continuity in discrete spaces and applications
- **Arxiv ID**: http://arxiv.org/abs/1210.2352v2
- **DOI**: None
- **Categories**: **math.MG**, cs.CV, math.CO, math.GN
- **Links**: [PDF](http://arxiv.org/pdf/1210.2352v2)
- **Published**: 2012-10-08 17:33:46+00:00
- **Updated**: 2013-09-17 05:39:19+00:00
- **Authors**: Valerio Capraro
- **Comment**: arXiv admin note: text overlap with arXiv:1111.0268
- **Journal**: Applied General Topology 14 (1) (2013) 61-72
- **Summary**: We propose a notion of continuous path for locally finite metric spaces, taking inspiration from the recent development of A-theory for locally finite connected graphs. We use this notion of continuity to derive an analogue in Z^2 of the Jordan curve theorem and to extend to a quite large class of locally finite metric spaces (containing all finite metric spaces) an inequality for the \ell^p-distortion of a metric space that has been recently proved by Pierre-Nicolas Jolissaint and Alain Valette for finite connected graphs.



### Stable and robust sampling strategies for compressive imaging
- **Arxiv ID**: http://arxiv.org/abs/1210.2380v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT, math.NA, 94A08, 68U10, 65D18, 92C55
- **Links**: [PDF](http://arxiv.org/pdf/1210.2380v3)
- **Published**: 2012-10-08 19:00:39+00:00
- **Updated**: 2013-10-21 13:30:40+00:00
- **Authors**: Felix Krahmer, Rachel Ward
- **Comment**: 17 pages, 4 figures
- **Journal**: None
- **Summary**: In many signal processing applications, one wishes to acquire images that are sparse in transform domains such as spatial finite differences or wavelets using frequency domain samples. For such applications, overwhelming empirical evidence suggests that superior image reconstruction can be obtained through variable density sampling strategies that concentrate on lower frequencies. The wavelet and Fourier transform domains are not incoherent because low-order wavelets and low-order frequencies are correlated, so compressive sensing theory does not immediately imply sampling strategies and reconstruction guarantees. In this paper we turn to a more refined notion of coherence -- the so-called local coherence -- measuring for each sensing vector separately how correlated it is to the sparsity basis. For Fourier measurements and Haar wavelet sparsity, the local coherence can be controlled and bounded explicitly, so for matrices comprised of frequencies sampled from a suitable inverse square power-law density, we can prove the restricted isometry property with near-optimal embedding dimensions. Consequently, the variable-density sampling strategy we provide allows for image reconstructions that are stable to sparsity defects and robust to measurement noise. Our results cover both reconstruction by $\ell_1$-minimization and by total variation minimization. The local coherence framework developed in this paper should be of independent interest in sparse recovery problems more generally, as it implies that for optimal sparse recovery results, it suffices to have bounded \emph{average} coherence from sensing basis to sparsity basis -- as opposed to bounded maximal coherence -- as long as the sampling strategy is adapted accordingly.



### Video De-fencing
- **Arxiv ID**: http://arxiv.org/abs/1210.2388v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1210.2388v1)
- **Published**: 2012-10-08 19:58:59+00:00
- **Updated**: 2012-10-08 19:58:59+00:00
- **Authors**: Yadong Mu, Wei Liu, Shuicheng Yan
- **Comment**: To appear in IEEE transactions on Circuits and Systems for Video
  Technology (T-CSVT)
- **Journal**: None
- **Summary**: This paper describes and provides an initial solution to a novel video editing task, i.e., video de-fencing. It targets automatic restoration of the video clips that are corrupted by fence-like occlusions during capture. Our key observation lies in the visual parallax between fences and background scenes, which is caused by the fact that the former are typically closer to the camera. Unlike in traditional image inpainting, fence-occluded pixels in the videos tend to appear later in the temporal dimension and are therefore recoverable via optimized pixel selection from relevant frames. To eventually produce fence-free videos, major challenges include cross-frame sub-pixel image alignment under diverse scene depth, and "correct" pixel selection that is robust to dominating fence pixels. Several novel tools are developed in this paper, including soft fence detection, weighted truncated optical flow method and robust temporal median filter. The proposed algorithm is validated on several real-world video clips with fences.



