# Arxiv Papers in cs.CV on 2012-10-25
### Extended object reconstruction in adaptive-optics imaging: the multiresolution approach
- **Arxiv ID**: http://arxiv.org/abs/1210.6649v1
- **DOI**: 10.1051/0004-6361/201219489
- **Categories**: **astro-ph.IM**, cs.CV, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1210.6649v1)
- **Published**: 2012-10-25 10:08:00+00:00
- **Updated**: 2012-10-25 10:08:00+00:00
- **Authors**: Roberto Baena Gallé, Jorge Núñez, Szymon Gladysz
- **Comment**: In revision in Astronomy & Astrophysics. 19 pages, 13 figures
- **Journal**: None
- **Summary**: We propose the application of multiresolution transforms, such as wavelets (WT) and curvelets (CT), to the reconstruction of images of extended objects that have been acquired with adaptive optics (AO) systems. Such multichannel approaches normally make use of probabilistic tools in order to distinguish significant structures from noise and reconstruction residuals. Furthermore, we aim to check the historical assumption that image-reconstruction algorithms using static PSFs are not suitable for AO imaging. We convolve an image of Saturn taken with the Hubble Space Telescope (HST) with AO PSFs from the 5-m Hale telescope at the Palomar Observatory and add both shot and readout noise. Subsequently, we apply different approaches to the blurred and noisy data in order to recover the original object. The approaches include multi-frame blind deconvolution (with the algorithm IDAC), myopic deconvolution with regularization (with MISTRAL) and wavelets- or curvelets-based static PSF deconvolution (AWMLE and ACMLE algorithms). We used the mean squared error (MSE) and the structural similarity index (SSIM) to compare the results. We discuss the strengths and weaknesses of the two metrics. We found that CT produces better results than WT, as measured in terms of MSE and SSIM. Multichannel deconvolution with a static PSF produces results which are generally better than the results obtained with the myopic/blind approaches (for the images we tested) thus showing that the ability of a method to suppress the noise and to track the underlying iterative process is just as critical as the capability of the myopic/blind approaches to update the PSF.



### Computer vision tools for the non-invasive assessment of autism-related behavioral markers
- **Arxiv ID**: http://arxiv.org/abs/1210.7014v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1210.7014v2)
- **Published**: 2012-10-25 22:30:40+00:00
- **Updated**: 2012-11-08 03:03:45+00:00
- **Authors**: Jordan Hashemi, Thiago Vallin Spina, Mariano Tepper, Amy Esler, Vassilios Morellas, Nikolaos Papanikolopoulos, Guillermo Sapiro
- **Comment**: None
- **Journal**: None
- **Summary**: The early detection of developmental disorders is key to child outcome, allowing interventions to be initiated that promote development and improve prognosis. Research on autism spectrum disorder (ASD) suggests behavioral markers can be observed late in the first year of life. Many of these studies involved extensive frame-by-frame video observation and analysis of a child's natural behavior. Although non-intrusive, these methods are extremely time-intensive and require a high level of observer training; thus, they are impractical for clinical and large population research purposes. Diagnostic measures for ASD are available for infants but are only accurate when used by specialists experienced in early diagnosis. This work is a first milestone in a long-term multidisciplinary project that aims at helping clinicians and general practitioners accomplish this early detection/measurement task automatically. We focus on providing computer vision tools to measure and identify ASD behavioral markers based on components of the Autism Observation Scale for Infants (AOSI). In particular, we develop algorithms to measure three critical AOSI activities that assess visual attention. We augment these AOSI activities with an additional test that analyzes asymmetrical patterns in unsupported gait. The first set of algorithms involves assessing head motion by tracking facial features, while the gait analysis relies on joint foreground segmentation and 2D body pose estimation in video. We show results that provide insightful knowledge to augment the clinician's behavioral observations obtained from real in-clinic assessments.



### Performance Evaluation of Random Set Based Pedestrian Tracking Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1211.0191v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.0191v1)
- **Published**: 2012-10-25 23:21:46+00:00
- **Updated**: 2012-10-25 23:21:46+00:00
- **Authors**: Branko Ristic, Jamie Sherrah, Ángel F. García-Fernández
- **Comment**: 6 pages, 3 figures
- **Journal**: None
- **Summary**: The paper evaluates the error performance of three random finite set based multi-object trackers in the context of pedestrian video tracking. The evaluation is carried out using a publicly available video dataset of 4500 frames (town centre street) for which the ground truth is available. The input to all pedestrian tracking algorithms is an identical set of head and body detections, obtained using the Histogram of Oriented Gradients (HOG) detector. The tracking error is measured using the recently proposed OSPA metric for tracks, adopted as the only known mathematically rigorous metric for measuring the distance between two sets of tracks. A comparative analysis is presented under various conditions.



