# Arxiv Papers in cs.CV on 2012-12-03
### An Image Based Technique for Enhancement of Underwater Images
- **Arxiv ID**: http://arxiv.org/abs/1212.0291v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.0291v1)
- **Published**: 2012-12-03 05:57:46+00:00
- **Updated**: 2012-12-03 05:57:46+00:00
- **Authors**: C. J. Prabhakar, P. U. Praveen Kumar
- **Comment**: None
- **Journal**: International Journal of Machine Intelligence, Volume 3, Issue 4,
  pages 217-224, 2011
- **Summary**: The underwater images usually suffers from non-uniform lighting, low contrast, blur and diminished colors. In this paper, we proposed an image based preprocessing technique to enhance the quality of the underwater images. The proposed technique comprises a combination of four filters such as homomorphic filtering, wavelet denoising, bilateral filter and contrast equalization. These filters are applied sequentially on degraded underwater images. The literature survey reveals that image based preprocessing algorithms uses standard filter techniques with various combinations. For smoothing the image, the image based preprocessing algorithms uses the anisotropic filter. The main drawback of the anisotropic filter is that iterative in nature and computation time is high compared to bilateral filter. In the proposed technique, in addition to other three filters, we employ a bilateral filter for smoothing the image. The experimentation is carried out in two stages. In the first stage, we have conducted various experiments on captured images and estimated optimal parameters for bilateral filter. Similarly, optimal filter bank and optimal wavelet shrinkage function are estimated for wavelet denoising. In the second stage, we conducted the experiments using estimated optimal parameters, optimal filter bank and optimal wavelet shrinkage function for evaluating the proposed technique. We evaluated the technique using quantitative based criteria such as a gradient magnitude histogram and Peak Signal to Noise Ratio (PSNR). Further, the results are qualitatively evaluated based on edge detection results. The proposed technique enhances the quality of the underwater images and can be employed prior to apply computer vision techniques.



### Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its Applications
- **Arxiv ID**: http://arxiv.org/abs/1212.0318v1
- **DOI**: 10.5120/6222-8800
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.0318v1)
- **Published**: 2012-12-03 08:55:52+00:00
- **Updated**: 2012-12-03 08:55:52+00:00
- **Authors**: D. Srinivasa Rao, M. Seetha, M. H. M. Krishna Prasad
- **Comment**: (0975 8887). arXiv admin note: text overlap with arXiv:1209.4535 by
  other authors
- **Journal**: International Journal of Computer Applications Volume 43, No.20,
  2012, pages: 31 - 37
- **Summary**: Image fusion is the process of integrating multiple images of the same scene into a single fused image to reduce uncertainty and minimizing redundancy while extracting all the useful information from the source images. Image fusion process is required for different applications like medical imaging, remote sensing, medical imaging, machine vision, biometrics and military applications where quality and critical information is required. In this paper, image fusion using fuzzy and neuro fuzzy logic approaches utilized to fuse images from different sensors, in order to enhance visualization. The proposed work further explores comparison between fuzzy based image fusion and neuro fuzzy fusion technique along with quality evaluation indices for image fusion like image quality index, mutual information measure, fusion factor, fusion symmetry, fusion index, root mean square error, peak signal to noise ratio, entropy, correlation coefficient and spatial frequency. Experimental results obtained from fusion process prove that the use of the neuro fuzzy based image fusion approach shows better performance in first two test cases while in the third test case fuzzy based image fusion technique gives better results.



### GLCM-based chi-square histogram distance for automatic detection of defects on patterned textures
- **Arxiv ID**: http://arxiv.org/abs/1212.0383v1
- **DOI**: 10.1504/IJCVR.2011.045267
- **Categories**: **cs.CV**, 65D19, 11K70, 76M55, 93B17, 62H30, I.0; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1212.0383v1)
- **Published**: 2012-12-03 13:40:41+00:00
- **Updated**: 2012-12-03 13:40:41+00:00
- **Authors**: V. Asha, N. U. Bhajantri, P. Nagabhushan
- **Comment**: IJCVR, Vol. 2, No. 4, 2011, pp. 302-313
- **Journal**: IJCVR, Vol. 2, No. 4, 2011, pp. 302-313
- **Summary**: Chi-square histogram distance is one of the distance measures that can be used to find dissimilarity between two histograms. Motivated by the fact that texture discrimination by human vision system is based on second-order statistics, we make use of histogram of gray-level co-occurrence matrix (GLCM) that is based on second-order statistics and propose a new machine vision algorithm for automatic defect detection on patterned textures. Input defective images are split into several periodic blocks and GLCMs are computed after quantizing the gray levels from 0-255 to 0-63 to keep the size of GLCM compact and to reduce computation time. Dissimilarity matrix derived from chi-square distances of the GLCMs is subjected to hierarchical clustering to automatically identify defective and defect-free blocks. Effectiveness of the proposed method is demonstrated through experiments on defective real-fabric images of 2 major wallpaper groups (pmm and p4m groups).



### UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild
- **Arxiv ID**: http://arxiv.org/abs/1212.0402v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.0402v1)
- **Published**: 2012-12-03 14:45:31+00:00
- **Updated**: 2012-12-03 14:45:31+00:00
- **Authors**: Khurram Soomro, Amir Roshan Zamir, Mubarak Shah
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce UCF101 which is currently the largest dataset of human actions. It consists of 101 action classes, over 13k clips and 27 hours of video data. The database consists of realistic user uploaded videos containing camera motion and cluttered background. Additionally, we provide baseline action recognition results on this new dataset using standard bag of words approach with overall performance of 44.5%. To the best of our knowledge, UCF101 is currently the most challenging dataset of actions due to its large number of classes, large number of clips and also unconstrained nature of such clips.



### Compressive Schlieren Deflectometry
- **Arxiv ID**: http://arxiv.org/abs/1212.0433v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.0433v1)
- **Published**: 2012-12-03 16:21:07+00:00
- **Updated**: 2012-12-03 16:21:07+00:00
- **Authors**: Prasad Sudhakar, Laurent Jacques, Xavier Dubois, Philippe Antoine, Luc Joannes
- **Comment**: 9 pages, 7 figures
- **Journal**: None
- **Summary**: Schlieren deflectometry aims at characterizing the deflections undergone by refracted incident light rays at any surface point of a transparent object. For smooth surfaces, each surface location is actually associated with a sparse deflection map (or spectrum). This paper presents a novel method to compressively acquire and reconstruct such spectra. This is achieved by altering the way deflection information is captured in a common Schlieren Deflectometer, i.e., the deflection spectra are indirectly observed by the principle of spread spectrum compressed sensing. These observations are realized optically using a 2-D Spatial Light Modulator (SLM) adjusted to the corresponding sensing basis and whose modulations encode the light deviation subsequently recorded by a CCD camera. The efficiency of this approach is demonstrated experimentally on the observation of few test objects. Further, using a simple parametrization of the deflection spectra we show that relevant key parameters can be directly computed using the measurements, avoiding full reconstruction.



