# Arxiv Papers in cs.CV on 2012-12-12
### Enhanced skin colour classifier using RGB Ratio model
- **Arxiv ID**: http://arxiv.org/abs/1212.2692v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T10
- **Links**: [PDF](http://arxiv.org/pdf/1212.2692v1)
- **Published**: 2012-12-12 03:01:00+00:00
- **Updated**: 2012-12-12 03:01:00+00:00
- **Authors**: Ghazali Osman, Muhammad Suzuri Hitam, Mohd Nasir Ismail
- **Comment**: 14 pages; International Journal on Soft Computing (IJSC) Vol.3, No.4,
  November 2012
- **Journal**: None
- **Summary**: Skin colour detection is frequently been used for searching people, face detection, pornographic filtering and hand tracking. The presence of skin or non-skin in digital image can be determined by manipulating pixels colour or pixels texture. The main problem in skin colour detection is to represent the skin colour distribution model that is invariant or least sensitive to changes in illumination condition. Another problem comes from the fact that many objects in the real world may possess almost similar skin-tone colour such as wood, leather, skin-coloured clothing, hair and sand. Moreover, skin colour is different between races and can be different from a person to another, even with people of the same ethnicity. Finally, skin colour will appear a little different when different types of camera are used to capture the object or scene. The objective in this study is to develop a skin colour classifier based on pixel-based using RGB ratio model. The RGB ratio model is a newly proposed method that belongs under the category of an explicitly defined skin region model. This skin classifier was tested with SIdb dataset and two benchmark datasets; UChile and TDSD datasets to measure classifier performance. The performance of skin classifier was measured based on true positive (TF) and false positive (FP) indicator. This newly proposed model was compared with Kovac, Saleh and Swift models. The experimental results showed that the RGB ratio model outperformed all the other models in term of detection rate. The RGB ratio model is able to reduce FP detection that caused by reddish objects colour as well as be able to detect darkened skin and skin covered by shadow.



### Tracking Revisited using RGBD Camera: Baseline and Benchmark
- **Arxiv ID**: http://arxiv.org/abs/1212.2823v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.2823v1)
- **Published**: 2012-12-12 14:02:41+00:00
- **Updated**: 2012-12-12 14:02:41+00:00
- **Authors**: Shuran Song, Jianxiong Xiao
- **Comment**: None
- **Journal**: None
- **Summary**: Although there has been significant progress in the past decade,tracking is still a very challenging computer vision task, due to problems such as occlusion and model drift.Recently, the increased popularity of depth sensors e.g. Microsoft Kinect has made it easy to obtain depth data at low cost.This may be a game changer for tracking, since depth information can be used to prevent model drift and handle occlusion.In this paper, we construct a benchmark dataset of 100 RGBD videos with high diversity, including deformable objects, various occlusion conditions and moving cameras. We propose a very simple but strong baseline model for RGBD tracking, and present a quantitative comparison of several state-of-the-art tracking algorithms.Experimental results show that including depth information and reasoning about occlusion significantly improves tracking performance. The datasets, evaluation details, source code for the baseline algorithm, and instructions for submitting new models will be made available online after acceptance.



### Adaptive Foreground and Shadow Detection inImage Sequences
- **Arxiv ID**: http://arxiv.org/abs/1301.0612v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.0612v1)
- **Published**: 2012-12-12 15:59:10+00:00
- **Updated**: 2012-12-12 15:59:10+00:00
- **Authors**: Yang Wang, Tele Tan
- **Comment**: Appears in Proceedings of the Eighteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2002)
- **Journal**: None
- **Summary**: This paper presents a novel method of foreground segmentation that distinguishes moving objects from their moving cast shadows in monocular image sequences. The models of background, edge information, and shadow are set up and adaptively updated. A Bayesian belief network is proposed to describe the relationships among the segmentation label, background, intensity, and edge information. The notion of Markov random field is used to encourage the spatial connectivity of the segmented regions. The solution is obtained by maximizing the posterior possibility density of the segmentation field.



### Pituitary Adenoma Volumetry with 3D Slicer
- **Arxiv ID**: http://arxiv.org/abs/1212.2860v1
- **DOI**: 10.1371/journal.pone.0051788
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1212.2860v1)
- **Published**: 2012-12-12 16:12:32+00:00
- **Updated**: 2012-12-12 16:12:32+00:00
- **Authors**: Jan Egger, Tina Kapur, Christopher Nimsky, Ron Kikinis
- **Comment**: 7 pages, 5 figures, 2 tables, 30 references
- **Journal**: (2012) PLoS ONE 7(12): e51788
- **Summary**: In this study, we present pituitary adenoma volumetry using the free and open source medical image computing platform for biomedical research: (3D) Slicer. Volumetric changes in cerebral pathologies like pituitary adenomas are a critical factor in treatment decisions by physicians and in general the volume is acquired manually. Therefore, manual slice-by-slice segmentations in magnetic resonance imaging (MRI) data, which have been obtained at regular intervals, are performed. In contrast to this manual time consuming slice-by-slice segmentation process Slicer is an alternative which can be significantly faster and less user intensive. In this contribution, we compare pure manual segmentations of ten pituitary adenomas with semi-automatic segmentations under Slicer. Thus, physicians drew the boundaries completely manually on a slice-by-slice basis and performed a Slicer-enhanced segmentation using the competitive region-growing based module of Slicer named GrowCut. Results showed that the time and user effort required for GrowCut-based segmentations were on average about thirty percent less than the pure manual segmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC) between the manual and the Slicer-based segmentations to proof that the two are comparable yielding an average DSC of 81.97\pm3.39%.



