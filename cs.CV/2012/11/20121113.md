# Arxiv Papers in cs.CV on 2012-11-13
### Multi-Sensor Fusion via Reduction of Dimensionality
- **Arxiv ID**: http://arxiv.org/abs/1211.2863v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.2863v1)
- **Published**: 2012-11-13 01:05:42+00:00
- **Updated**: 2012-11-13 01:05:42+00:00
- **Authors**: Alon Schclar
- **Comment**: PhD Thesis, Tel Aviv Univ, 2008
- **Journal**: None
- **Summary**: Large high-dimensional datasets are becoming more and more popular in an increasing number of research areas. Processing the high dimensional data incurs a high computational cost and is inherently inefficient since many of the values that describe a data object are redundant due to noise and inner correlations. Consequently, the dimensionality, i.e. the number of values that are used to describe a data object, needs to be reduced prior to any other processing of the data. The dimensionality reduction removes, in most cases, noise from the data and reduces substantially the computational cost of algorithms that are applied to the data.   In this thesis, a novel coherent integrated methodology is introduced (theory, algorithm and applications) to reduce the dimensionality of high-dimensional datasets. The method constructs a diffusion process among the data coordinates via a random walk. The dimensionality reduction is obtained based on the eigen-decomposition of the Markov matrix that is associated with the random walk. The proposed method is utilized for: (a) segmentation and detection of anomalies in hyper-spectral images; (b) segmentation of multi-contrast MRI images; and (c) segmentation of video sequences.   We also present algorithms for: (a) the characterization of materials using their spectral signatures to enable their identification; (b) detection of vehicles according to their acoustic signatures; and (c) classification of vascular vessels recordings to detect hyper-tension and cardio-vascular diseases.   The proposed methodology and algorithms produce excellent results that successfully compete with current state-of-the-art algorithms.



### Deep Attribute Networks
- **Arxiv ID**: http://arxiv.org/abs/1211.2881v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1211.2881v3)
- **Published**: 2012-11-13 03:41:31+00:00
- **Updated**: 2012-11-28 08:39:03+00:00
- **Authors**: Junyoung Chung, Donghoon Lee, Youngjoo Seo, Chang D. Yoo
- **Comment**: This paper has been withdrawn by the author due to a crucial
  grammatical errors
- **Journal**: None
- **Summary**: Obtaining compact and discriminative features is one of the major challenges in many of the real-world image classification tasks such as face verification and object recognition. One possible approach is to represent input image on the basis of high-level features that carry semantic meaning which humans can understand. In this paper, a model coined deep attribute network (DAN) is proposed to address this issue. For an input image, the model outputs the attributes of the input image without performing any classification. The efficacy of the proposed model is evaluated on unconstrained face verification and real-world object recognition tasks using the LFW and the a-PASCAL datasets. We demonstrate the potential of deep learning for attribute-based classification by showing comparable results with existing state-of-the-art results. Once properly trained, the DAN is fast and does away with calculating low-level features which are maybe unreliable and computationally expensive.



