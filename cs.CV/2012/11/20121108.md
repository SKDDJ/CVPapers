# Arxiv Papers in cs.CV on 2012-11-08
### 3D Scene Grammar for Parsing RGB-D Pointclouds
- **Arxiv ID**: http://arxiv.org/abs/1211.1752v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.1752v1)
- **Published**: 2012-11-08 03:11:53+00:00
- **Updated**: 2012-11-08 03:11:53+00:00
- **Authors**: Abhishek Anand, Sherwin Li
- **Comment**: None
- **Journal**: None
- **Summary**: We pose 3D scene-understanding as a problem of parsing in a grammar. A grammar helps us capture the compositional structure of real-word objects, e.g., a chair is composed of a seat, a back-rest and some legs. Having multiple rules for an object helps us capture structural variations in objects, e.g., a chair can optionally also have arm-rests. Finally, having rules to capture composition at different levels helps us formulate the entire scene-processing pipeline as a single problem of finding most likely parse-tree---small segments combine to form parts of objects, parts to objects and objects to a scene. We attach a generative probability model to our grammar by having a feature-dependent probability function for every rule. We evaluated it by extracting labels for every segment and comparing the results with the state-of-the-art segment-labeling algorithm. Our algorithm was outperformed by the state-or-the-art method. But, Our model can be trained very efficiently (within seconds), and it scales only linearly in with the number of rules in the grammar. Also, we think that this is an important problem for the 3D vision community. So, we are releasing our dataset and related code.



### A Comparative study of Arabic handwritten characters invariant feature
- **Arxiv ID**: http://arxiv.org/abs/1211.1800v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.1800v1)
- **Published**: 2012-11-08 09:24:21+00:00
- **Updated**: 2012-11-08 09:24:21+00:00
- **Authors**: Hamdi Hassen, Maher khemakhem
- **Comment**: None
- **Journal**: (IJACSA) International Journal of Advanced Computer Science and
  Applications, Vol. 2, No. 12, 2011
- **Summary**: This paper is practically interested in the unchangeable feature of Arabic handwritten character. It presents results of comparative study achieved on certain features extraction techniques of handwritten character, based on Hough transform, Fourier transform, Wavelet transform and Gabor Filter. Obtained results show that Hough Transform and Gabor filter are insensible to the rotation and translation, Fourier Transform is sensible to the rotation but insensible to the translation, in contrast to Hough Transform and Gabor filter, Wavelets Transform is sensitive to the rotation as well as to the translation.



### Fourier-Bessel rotational invariant eigenimages
- **Arxiv ID**: http://arxiv.org/abs/1211.1968v2
- **DOI**: 10.1364/JOSAA.30.000871
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.1968v2)
- **Published**: 2012-11-08 20:59:49+00:00
- **Updated**: 2013-02-16 20:29:22+00:00
- **Authors**: Zhizhen Zhao, Amit Singer
- **Comment**: 7 pages
- **Journal**: JOSA A, Vol. 30, Issue 5, pp. 871-877 (2013)
- **Summary**: We present an efficient and accurate algorithm for principal component analysis (PCA) of a large set of two dimensional images, and, for each image, the set of its uniform rotations in the plane and its reflection. The algorithm starts by expanding each image, originally given on a Cartesian grid, in the Fourier-Bessel basis for the disk. Because the images are bandlimited in the Fourier domain, we use a sampling criterion to truncate the Fourier-Bessel expansion such that the maximum amount of information is preserved without the effect of aliasing. The constructed covariance matrix is invariant to rotation and reflection and has a special block diagonal structure. PCA is efficiently done for each block separately. This Fourier-Bessel based PCA detects more meaningful eigenimages and has improved denoising capability compared to traditional PCA for a finite number of noisy images.



### Multi-input Multi-output Beta Wavelet Network: Modeling of Acoustic Units for Speech Recognition
- **Arxiv ID**: http://arxiv.org/abs/1211.2007v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1211.2007v1)
- **Published**: 2012-11-08 22:23:54+00:00
- **Updated**: 2012-11-08 22:23:54+00:00
- **Authors**: Ridha Ejbali, Mourad Zaied, Chokri Ben Amar
- **Comment**: 7 pages, 10 figures
- **Journal**: (IJACSA) International Journal of Advanced Computer Science and
  Applications,Vol. 3, No.4, 2012, 38-44
- **Summary**: In this paper, we propose a novel architecture of wavelet network called Multi-input Multi-output Wavelet Network MIMOWN as a generalization of the old architecture of wavelet network. This newel prototype was applied to speech recognition application especially to model acoustic unit of speech. The originality of our work is the proposal of MIMOWN to model acoustic unit of speech. This approach was proposed to overcome limitation of old wavelet network model. The use of the multi-input multi-output architecture will allows training wavelet network on various examples of acoustic units.



