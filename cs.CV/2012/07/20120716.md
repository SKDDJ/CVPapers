# Arxiv Papers in cs.CV on 2012-07-16
### Designing various component analysis at will
- **Arxiv ID**: http://arxiv.org/abs/1207.3554v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NA, stat.ME, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1207.3554v2)
- **Published**: 2012-07-16 00:07:44+00:00
- **Updated**: 2012-10-05 23:45:32+00:00
- **Authors**: Akisato Kimura, Masashi Sugiyama, Sakano Hitoshi, Hirokazu Kameoka
- **Comment**: Accepted to IAPR International Conference on Pattern Recognition,
  submitted to IPSJ Transactions on Mathematical Modeling and its Applications
  (TOM). Just only one-page abstract for new due to novelty violation for
  journal submission. The details will be disclosed in late September
- **Journal**: None
- **Summary**: This paper provides a generic framework of component analysis (CA) methods introducing a new expression for scatter matrices and Gram matrices, called Generalized Pairwise Expression (GPE). This expression is quite compact but highly powerful: The framework includes not only (1) the standard CA methods but also (2) several regularization techniques, (3) weighted extensions, (4) some clustering methods, and (5) their semi-supervised extensions. This paper also presents quite a simple methodology for designing a desired CA method from the proposed framework: Adopting the known GPEs as templates, and generating a new method by combining these templates appropriately.



### Hierarchical Approach for Total Variation Digital Image Inpainting
- **Arxiv ID**: http://arxiv.org/abs/1207.3576v2
- **DOI**: 10.5121/ijcsea.2012.2316
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1207.3576v2)
- **Published**: 2012-07-16 04:51:07+00:00
- **Updated**: 2013-07-12 04:25:46+00:00
- **Authors**: S. Padmavathi, N. Archana, K. P. Soman
- **Comment**: 7 pages, 7 figures; International Journal of Computer Science,
  Engineering and Applications (IJCSEA), Voulume 2, Number 3, June 2012, ISSN :
  2230 - 9616 [Online] ; 2231 - 0088 [Print]
- **Journal**: None
- **Summary**: The art of recovering an image from damage in an undetectable form is known as inpainting. The manual work of inpainting is most often a very time consuming process. Due to digitalization of this technique, it is automatic and faster. In this paper, after the user selects the regions to be reconstructed, the algorithm automatically reconstruct the lost regions with the help of the information surrounding them. The existing methods perform very well when the region to be reconstructed is very small, but fails in proper reconstruction as the area increases. This paper describes a Hierarchical method by which the area to be inpainted is reduced in multiple levels and Total Variation(TV) method is used to inpaint in each level. This algorithm gives better performance when compared with other existing algorithms such as nearest neighbor interpolation, Inpainting through Blurring and Sobolev Inpainting.



### Autofocus Correction of Azimuth Phase Error and Residual Range Cell Migration in Spotlight SAR Polar Format Imagery
- **Arxiv ID**: http://arxiv.org/abs/1207.7245v1
- **DOI**: 10.1109/TAES.2013.6621846
- **Categories**: **astro-ph.IM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1207.7245v1)
- **Published**: 2012-07-16 06:25:30+00:00
- **Updated**: 2012-07-16 06:25:30+00:00
- **Authors**: Xinhua Mao, Daiyin Zhu, Zhaoda Zhu
- **Comment**: 29 pages, 14 figures
- **Journal**: Aerospace and Electronic Systems, IEEE Transactions on (Volume:49
  , Issue: 4 ), 2013
- **Summary**: Synthetic aperture radar (SAR) images are often blurred by phase perturbations induced by uncompensated sensor motion and /or unknown propagation effects caused by turbulent media. To get refocused images, autofocus proves to be useful post-processing technique applied to estimate and compensate the unknown phase errors. However, a severe drawback of the conventional autofocus algorithms is that they are only capable of removing one-dimensional azimuth phase errors (APE). As the resolution becomes finer, residual range cell migration (RCM), which makes the defocus inherently two-dimensional, becomes a new challenge. In this paper, correction of APE and residual RCM are presented in the framework of polar format algorithm (PFA). First, an insight into the underlying mathematical mechanism of polar reformatting is presented. Then based on this new formulation, the effect of polar reformatting on the uncompensated APE and residual RCM is investigated in detail. By using the derived analytical relationship between APE and residual RCM, an efficient two-dimensional (2-D) autofocus method is proposed. Experimental results indicate the effectiveness of the proposed method.



### Learning to rank from medical imaging data
- **Arxiv ID**: http://arxiv.org/abs/1207.3598v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1207.3598v2)
- **Published**: 2012-07-16 08:22:36+00:00
- **Updated**: 2012-09-30 17:04:22+00:00
- **Authors**: Fabian Pedregosa, Alexandre Gramfort, Gaël Varoquaux, Elodie Cauvet, Christophe Pallier, Bertrand Thirion
- **Comment**: None
- **Journal**: MLMI 2012 - 3rd International Workshop on Machine Learning in
  Medical Imaging (2012)
- **Summary**: Medical images can be used to predict a clinical score coding for the severity of a disease, a pain level or the complexity of a cognitive task. In all these cases, the predicted variable has a natural order. While a standard classifier discards this information, we would like to take it into account in order to improve prediction performance. A standard linear regression does model such information, however the linearity assumption is likely not be satisfied when predicting from pixel intensities in an image. In this paper we address these modeling challenges with a supervised learning procedure where the model aims to order or rank images. We use a linear model for its robustness in high dimension and its possible interpretation. We show on simulations and two fMRI datasets that this approach is able to predict the correct ordering on pairs of images, yielding higher prediction accuracy than standard regression and multiclass classification techniques.



### Qualitative Comparison of Community Detection Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1207.3603v1
- **DOI**: 10.1007/978-3-642-22027-2_23
- **Categories**: **cs.SI**, cs.CV, physics.soc-ph
- **Links**: [PDF](http://arxiv.org/pdf/1207.3603v1)
- **Published**: 2012-07-16 08:49:05+00:00
- **Updated**: 2012-07-16 08:49:05+00:00
- **Authors**: Günce Orman, Vincent Labatut, Hocine Cherifi
- **Comment**: DICTAP 2011, The International Conference on Digital Information and
  Communication Technology and its Applications, Dijon : France (2011)
- **Journal**: Communications in Computer and Information Science, 167:265-279,
  2011
- **Summary**: Community detection is a very active field in complex networks analysis, consisting in identifying groups of nodes more densely interconnected relatively to the rest of the network. The existing algorithms are usually tested and compared on real-world and artificial networks, their performance being assessed through some partition similarity measure. However, artificial networks realism can be questioned, and the appropriateness of those measures is not obvious. In this study, we take advantage of recent advances concerning the characterization of community structures to tackle these questions. We first generate networks thanks to the most realistic model available to date. Their analysis reveals they display only some of the properties observed in real-world community structures. We then apply five community detection algorithms on these networks and find out the performance assessed quantitatively does not necessarily agree with a qualitative analysis of the identified communities. It therefore seems both approaches should be applied to perform a relevant comparison of the algorithms.



### Fusing image representations for classification using support vector machines
- **Arxiv ID**: http://arxiv.org/abs/1207.3607v1
- **DOI**: 10.1109/IVCNZ.2009.5378367
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1207.3607v1)
- **Published**: 2012-07-16 09:23:06+00:00
- **Updated**: 2012-07-16 09:23:06+00:00
- **Authors**: Can Demirkesen, Hocine Cherifi
- **Comment**: Image and Vision Computing New Zealand, 2009. IVCNZ '09. 24th
  International Conference, Wellington : Nouvelle-Z\'elande (2009)
- **Journal**: None
- **Summary**: In order to improve classification accuracy different image representations are usually combined. This can be done by using two different fusing schemes. In feature level fusion schemes, image representations are combined before the classification process. In classifier fusion, the decisions taken separately based on individual representations are fused to make a decision. In this paper the main methods derived for both strategies are evaluated. Our experimental results show that classifier fusion performs better. Specifically Bayes belief integration is the best performing strategy for image classification task.



### Image Labeling on a Network: Using Social-Network Metadata for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1207.3809v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.SI, physics.soc-ph
- **Links**: [PDF](http://arxiv.org/pdf/1207.3809v1)
- **Published**: 2012-07-16 20:04:12+00:00
- **Updated**: 2012-07-16 20:04:12+00:00
- **Authors**: Julian McAuley, Jure Leskovec
- **Comment**: ECCV 2012; 14 pages, 4 figures
- **Journal**: None
- **Summary**: Large-scale image retrieval benchmarks invariably consist of images from the Web. Many of these benchmarks are derived from online photo sharing networks, like Flickr, which in addition to hosting images also provide a highly interactive social community. Such communities generate rich metadata that can naturally be harnessed for image classification and retrieval. Here we study four popular benchmark datasets, extending them with social-network metadata, such as the groups to which each image belongs, the comment thread associated with the image, who uploaded it, their location, and their network of friends. Since these types of data are inherently relational, we propose a model that explicitly accounts for the interdependencies between images sharing common properties. We model the task as a binary labeling problem on a network, and use structured learning techniques to learn model parameters. We find that social-network metadata are useful in a variety of classification tasks, in many cases outperforming methods based on image content.



