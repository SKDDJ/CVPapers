# Arxiv Papers in cs.CV on 2017-08-16
### DeepRebirth: Accelerating Deep Neural Network Execution on Mobile Devices
- **Arxiv ID**: http://arxiv.org/abs/1708.04728v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04728v2)
- **Published**: 2017-08-16 00:45:22+00:00
- **Updated**: 2018-01-10 23:41:57+00:00
- **Authors**: Dawei Li, Xiaolong Wang, Deguang Kong
- **Comment**: AAAI 2018
- **Journal**: None
- **Summary**: Deploying deep neural networks on mobile devices is a challenging task. Current model compression methods such as matrix decomposition effectively reduce the deployed model size, but still cannot satisfy real-time processing requirement. This paper first discovers that the major obstacle is the excessive execution time of non-tensor layers such as pooling and normalization without tensor-like trainable parameters. This motivates us to design a novel acceleration framework: DeepRebirth through "slimming" existing consecutive and parallel non-tensor and tensor layers. The layer slimming is executed at different substructures: (a) streamline slimming by merging the consecutive non-tensor and tensor layer vertically; (b) branch slimming by merging non-tensor and tensor branches horizontally. The proposed optimization operations significantly accelerate the model execution and also greatly reduce the run-time memory cost since the slimmed model architecture contains less hidden layers. To maximally avoid accuracy loss, the parameters in new generated layers are learned with layer-wise fine-tuning based on both theoretical analysis and empirical verification. As observed in the experiment, DeepRebirth achieves more than 3x speed-up and 2.5x run-time memory saving on GoogLeNet with only 0.4% drop of top-5 accuracy on ImageNet. Furthermore, by combining with other model compression techniques, DeepRebirth offers an average of 65ms inference time on the CPU of Samsung Galaxy S6 with 86.5% top-5 accuracy, 14% faster than SqueezeNet which only has a top-5 accuracy of 80.5%.



### Limiting the Reconstruction Capability of Generative Neural Network using Negative Learning
- **Arxiv ID**: http://arxiv.org/abs/1708.08985v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1708.08985v1)
- **Published**: 2017-08-16 01:16:14+00:00
- **Updated**: 2017-08-16 01:16:14+00:00
- **Authors**: Asim Munawar, Phongtharin Vinayavekhin, Giovanni De Magistris
- **Comment**: Conference: IEEE International Workshop on Machine Learning for
  Signal Processing (MLSP), Roppongi, Tokyo, Japan, September 25-28, 2017
- **Journal**: None
- **Summary**: Generative models are widely used for unsupervised learning with various applications, including data compression and signal restoration. Training methods for such systems focus on the generality of the network given limited amount of training data. A less researched type of techniques concerns generation of only a single type of input. This is useful for applications such as constraint handling, noise reduction and anomaly detection. In this paper we present a technique to limit the generative capability of the network using negative learning. The proposed method searches the solution in the gradient direction for the desired input and in the opposite direction for the undesired input. One of the application can be anomaly detection where the undesired inputs are the anomalous data. In the results section we demonstrate the features of the algorithm using MNIST handwritten digit dataset and latter apply the technique to a real-world obstacle detection problem. The results clearly show that the proposed learning technique can significantly improve the performance for anomaly detection.



### An Improved Neural Segmentation Method Based on U-NET
- **Arxiv ID**: http://arxiv.org/abs/1708.04747v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04747v1)
- **Published**: 2017-08-16 02:17:59+00:00
- **Updated**: 2017-08-16 02:17:59+00:00
- **Authors**: Chenyang Xu, Mengxin Li
- **Comment**: None
- **Journal**: None
- **Summary**: Neural segmentation has a great impact on the smooth implementation of local anesthesia surgery. At present, the network for the segmentation includes U-NET [1] and SegNet [2]. U-NET network has short training time and less training parameters, but the depth is not deep enough. SegNet network has deeper structure, but it needs longer training time, and more training samples. In this paper, we propose an improved U-NET neural network for the segmentation. This network deepens the original structure through importing residual network. Compared with U-NET and SegNet, the improved U-NET network has fewer training parameters, shorter training time and get a great improvement in segmentation effect. The improved U-NET network structure has a good application scene in neural segmentation.



### Driving Style Analysis Using Primitive Driving Patterns With Bayesian Nonparametric Approaches
- **Arxiv ID**: http://arxiv.org/abs/1708.08986v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.08986v1)
- **Published**: 2017-08-16 03:36:30+00:00
- **Updated**: 2017-08-16 03:36:30+00:00
- **Authors**: Wenshuo Wang, Junqiang Xi, Ding Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Analysis and recognition of driving styles are profoundly important to intelligent transportation and vehicle calibration. This paper presents a novel driving style analysis framework using the primitive driving patterns learned from naturalistic driving data. In order to achieve this, first, a Bayesian nonparametric learning method based on a hidden semi-Markov model (HSMM) is introduced to extract primitive driving patterns from time series driving data without prior knowledge of the number of these patterns. In the Bayesian nonparametric approach, we utilize a hierarchical Dirichlet process (HDP) instead of learning the unknown number of smooth dynamical modes of HSMM, thus generating the primitive driving patterns. Each primitive pattern is clustered and then labeled using behavioral semantics according to drivers' physical and psychological perception thresholds. For each driver, 75 primitive driving patterns in car-following scenarios are learned and semantically labeled. In order to show the HDP-HSMM's utility to learn primitive driving patterns, other two Bayesian nonparametric approaches, HDP-HMM and sticky HDP-HMM, are compared. The naturalistic driving data of 18 drivers were collected from the University of Michigan Safety Pilot Model Deployment (SPDM) database. The individual driving styles are discussed according to distribution characteristics of the learned primitive driving patterns and also the difference in driving styles among drivers are evaluated using the Kullback-Leibler divergence. The experiment results demonstrate that the proposed primitive pattern-based method can allow one to semantically understand driver behaviors and driving styles.



### Active Orthogonal Matching Pursuit for Sparse Subspace Clustering
- **Arxiv ID**: http://arxiv.org/abs/1708.04764v1
- **DOI**: 10.1109/LSP.2017.2741509
- **Categories**: **cs.LG**, cs.CV, cs.IT, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1708.04764v1)
- **Published**: 2017-08-16 04:15:37+00:00
- **Updated**: 2017-08-16 04:15:37+00:00
- **Authors**: Yanxi Chen, Gen Li, Yuantao Gu
- **Comment**: 14 pages, 5 figures, 1 table
- **Journal**: None
- **Summary**: Sparse Subspace Clustering (SSC) is a state-of-the-art method for clustering high-dimensional data points lying in a union of low-dimensional subspaces. However, while $\ell_1$ optimization-based SSC algorithms suffer from high computational complexity, other variants of SSC, such as Orthogonal Matching Pursuit-based SSC (OMP-SSC), lose clustering accuracy in pursuit of improving time efficiency. In this letter, we propose a novel Active OMP-SSC, which improves clustering accuracy of OMP-SSC by adaptively updating data points and randomly dropping data points in the OMP process, while still enjoying the low computational complexity of greedy pursuit algorithms. We provide heuristic analysis of our approach, and explain how these two active steps achieve a better tradeoff between connectivity and separation. Numerical results on both synthetic data and real-world data validate our analyses and show the advantages of the proposed active algorithm.



### Modality-specific Cross-modal Similarity Measurement with Recurrent Attention Network
- **Arxiv ID**: http://arxiv.org/abs/1708.04776v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1708.04776v1)
- **Published**: 2017-08-16 05:43:54+00:00
- **Updated**: 2017-08-16 05:43:54+00:00
- **Authors**: Yuxin Peng, Jinwei Qi, Yuxin Yuan
- **Comment**: 13 pages, submitted to IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: Nowadays, cross-modal retrieval plays an indispensable role to flexibly find information across different modalities of data. Effectively measuring the similarity between different modalities of data is the key of cross-modal retrieval. Different modalities such as image and text have imbalanced and complementary relationships, which contain unequal amount of information when describing the same semantics. For example, images often contain more details that cannot be demonstrated by textual descriptions and vice versa. Existing works based on Deep Neural Network (DNN) mostly construct one common space for different modalities to find the latent alignments between them, which lose their exclusive modality-specific characteristics. Different from the existing works, we propose modality-specific cross-modal similarity measurement (MCSM) approach by constructing independent semantic space for each modality, which adopts end-to-end framework to directly generate modality-specific cross-modal similarity without explicit common representation. For each semantic space, modality-specific characteristics within one modality are fully exploited by recurrent attention network, while the data of another modality is projected into this space with attention based joint embedding to utilize the learned attention weights for guiding the fine-grained cross-modal correlation learning, which can capture the imbalanced and complementary relationships between different modalities. Finally, the complementarity between the semantic spaces for different modalities is explored by adaptive fusion of the modality-specific cross-modal similarities to perform cross-modal retrieval. Experiments on the widely-used Wikipedia and Pascal Sentence datasets as well as our constructed large-scale XMediaNet dataset verify the effectiveness of our proposed approach, outperforming 9 state-of-the-art methods.



### Efficiently Tracking Homogeneous Regions in Multichannel Images
- **Arxiv ID**: http://arxiv.org/abs/1708.04804v1
- **DOI**: 10.1049/cp.2017.0143
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04804v1)
- **Published**: 2017-08-16 08:30:47+00:00
- **Updated**: 2017-08-16 08:30:47+00:00
- **Authors**: Tobias Böttger, Christina Eisenhofer
- **Comment**: to be published in ICPRS 2017 proceedings
- **Journal**: None
- **Summary**: We present a method for tracking Maximally Stable Homogeneous Regions (MSHR) in images with an arbitrary number of channels. MSHR are conceptionally very similar to Maximally Stable Extremal Regions (MSER) and Maximally Stable Color Regions (MSCR), but can also be applied to hyperspectral and color images while remaining extremely efficient. The presented approach makes use of the edge-based component-tree which can be calculated in linear time. In the tracking step, the MSHR are localized by matching them to the nodes in the component-tree. We use rotationally invariant region and gray-value features that can be calculated through first and second order moments at low computational complexity. Furthermore, we use a weighted feature vector to improve the data association in the tracking step. The algorithm is evaluated on a collection of different tracking scenes from the literature. Furthermore, we present two different applications: 2D object tracking and the 3D segmentation of organs.



### Language Identification Using Deep Convolutional Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1708.04811v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04811v1)
- **Published**: 2017-08-16 08:42:22+00:00
- **Updated**: 2017-08-16 08:42:22+00:00
- **Authors**: Christian Bartz, Tom Herold, Haojin Yang, Christoph Meinel
- **Comment**: to be presented at ICONIP 2017
- **Journal**: None
- **Summary**: Language Identification (LID) systems are used to classify the spoken language from a given audio sample and are typically the first step for many spoken language processing tasks, such as Automatic Speech Recognition (ASR) systems. Without automatic language detection, speech utterances cannot be parsed correctly and grammar rules cannot be applied, causing subsequent speech recognition steps to fail. We propose a LID system that solves the problem in the image domain, rather than the audio domain. We use a hybrid Convolutional Recurrent Neural Network (CRNN) that operates on spectrogram images of the provided audio snippets. In extensive experiments we show, that our model is applicable to a range of noisy scenarios and can easily be extended to previously unknown languages, while maintaining its classification accuracy. We release our code and a large scale training set for LID systems to the community.



### GSLAM: Initialization-robust Monocular Visual SLAM via Global Structure-from-Motion
- **Arxiv ID**: http://arxiv.org/abs/1708.04814v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04814v3)
- **Published**: 2017-08-16 08:53:16+00:00
- **Updated**: 2017-10-19 06:43:12+00:00
- **Authors**: Chengzhou Tang, Oliver Wang, Ping Tan
- **Comment**: 3DV 2017 Project Page: https://frobelbest.github.io/gslam
- **Journal**: None
- **Summary**: Many monocular visual SLAM algorithms are derived from incremental structure-from-motion (SfM) methods. This work proposes a novel monocular SLAM method which integrates recent advances made in global SfM. In particular, we present two main contributions to visual SLAM. First, we solve the visual odometry problem by a novel rank-1 matrix factorization technique which is more robust to the errors in map initialization. Second, we adopt a recent global SfM method for the pose-graph optimization, which leads to a multi-stage linear formulation and enables L1 optimization for better robustness to false loops. The combination of these two approaches generates more robust reconstruction and is significantly faster (4X) than recent state-of-the-art SLAM systems. We also present a new dataset recorded with ground truth camera motion in a Vicon motion capture room, and compare our method to prior systems on it and established benchmark datasets.



### A Generalised Directional Laplacian Distribution: Estimation, Mixture Models and Audio Source Separation
- **Arxiv ID**: http://arxiv.org/abs/1708.04816v1
- **DOI**: 10.1109/TASL.2012.2203804
- **Categories**: **cs.SD**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1708.04816v1)
- **Published**: 2017-08-16 08:56:51+00:00
- **Updated**: 2017-08-16 08:56:51+00:00
- **Authors**: Nikolaos Mitianoudis
- **Comment**: None
- **Journal**: IEEE Transactions on Audio, Speech and Language Processing, Vol.
  20, No. 9, pp. 2397- 2408 (2012)
- **Summary**: Directional or Circular statistics are pertaining to the analysis and interpretation of directions or rotations. In this work, a novel probability distribution is proposed to model multidimensional sparse directional data. The Generalised Directional Laplacian Distribution (DLD) is a hybrid between the Laplacian distribution and the von Mises-Fisher distribution. The distribution's parameters are estimated using Maximum-Likelihood Estimation over a set of training data points. Mixtures of Directional Laplacian Distributions (MDLD) are also introduced in order to model multiple concentrations of sparse directional data. The author explores the application of the derived DLD mixture model to cluster sound sources that exist in an underdetermined instantaneous sound mixture. The proposed model can solve the general K x L (K<L) underdetermined instantaneous source separation problem, offering a fast and stable solution.



### A deep architecture for unified aesthetic prediction
- **Arxiv ID**: http://arxiv.org/abs/1708.04890v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04890v1)
- **Published**: 2017-08-16 13:33:41+00:00
- **Updated**: 2017-08-16 13:33:41+00:00
- **Authors**: Naila Murray, Albert Gordo
- **Comment**: None
- **Journal**: None
- **Summary**: Image aesthetics has become an important criterion for visual content curation on social media sites and media content repositories. Previous work on aesthetic prediction models in the computer vision community has focused on aesthetic score prediction or binary image labeling. However, raw aesthetic annotations are in the form of score histograms and provide richer and more precise information than binary labels or mean scores. Consequently, in this work we focus on the rarely-studied problem of predicting aesthetic score distributions and propose a novel architecture and training procedure for our model. Our model achieves state-of-the-art results on the standard AVA large-scale benchmark dataset for three tasks: (i) aesthetic quality classification; (ii) aesthetic score regression; and (iii) aesthetic score distribution prediction, all while using one model trained only for the distribution prediction task. We also introduce a method to modify an image such that its predicted aesthetics changes, and use this modification to gain insight into our model.



### Random Erasing Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/1708.04896v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04896v2)
- **Published**: 2017-08-16 13:56:48+00:00
- **Updated**: 2017-11-16 10:05:35+00:00
- **Authors**: Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, Yi Yang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce Random Erasing, a new data augmentation method for training the convolutional neural network (CNN). In training, Random Erasing randomly selects a rectangle region in an image and erases its pixels with random values. In this process, training images with various levels of occlusion are generated, which reduces the risk of over-fitting and makes the model robust to occlusion. Random Erasing is parameter learning free, easy to implement, and can be integrated with most of the CNN-based recognition models. Albeit simple, Random Erasing is complementary to commonly used data augmentation techniques such as random cropping and flipping, and yields consistent improvement over strong baselines in image classification, object detection and person re-identification. Code is available at: https://github.com/zhunzhong07/Random-Erasing.



### Multi-View Stereo with Single-View Semantic Mesh Refinement
- **Arxiv ID**: http://arxiv.org/abs/1708.04907v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04907v2)
- **Published**: 2017-08-16 14:29:49+00:00
- **Updated**: 2017-08-24 20:12:42+00:00
- **Authors**: Andrea Romanoni, Marco Ciccone, Francesco Visin, Matteo Matteucci
- **Comment**: {\pounds}D Reconstruction Meets Semantic, ICCV workshop
- **Journal**: None
- **Summary**: While 3D reconstruction is a well-established and widely explored research topic, semantic 3D reconstruction has only recently witnessed an increasing share of attention from the Computer Vision community. Semantic annotations allow in fact to enforce strong class-dependent priors, as planarity for ground and walls, which can be exploited to refine the reconstruction often resulting in non-trivial performance improvements. State-of-the art methods propose volumetric approaches to fuse RGB image data with semantic labels; even if successful, they do not scale well and fail to output high resolution meshes. In this paper we propose a novel method to refine both the geometry and the semantic labeling of a given mesh. We refine the mesh geometry by applying a variational method that optimizes a composite energy made of a state-of-the-art pairwise photo-metric term and a single-view term that models the semantic consistency between the labels of the 3D mesh and those of the segmented images. We also update the semantic labeling through a novel Markov Random Field (MRF) formulation that, together with the classical data and smoothness terms, takes into account class-specific priors estimated directly from the annotated mesh. This is in contrast to state-of-the-art methods that are typically based on handcrafted or learned priors. We are the first, jointly with the very recent and seminal work of [M. Blaha et al arXiv:1706.08336, 2017], to propose the use of semantics inside a mesh refinement framework. Differently from [M. Blaha et al arXiv:1706.08336, 2017], which adopts a more classical pairwise comparison to estimate the flow of the mesh, we apply a single-view comparison between the semantically annotated image and the current 3D mesh labels; this improves the robustness in case of noisy segmentations.



### Stacked Deconvolutional Network for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1708.04943v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04943v1)
- **Published**: 2017-08-16 15:35:02+00:00
- **Updated**: 2017-08-16 15:35:02+00:00
- **Authors**: Jun Fu, Jing Liu, Yuhang Wang, Hanqing Lu
- **Comment**: None
- **Journal**: None
- **Summary**: Recent progress in semantic segmentation has been driven by improving the spatial resolution under Fully Convolutional Networks (FCNs). To address this problem, we propose a Stacked Deconvolutional Network (SDN) for semantic segmentation. In SDN, multiple shallow deconvolutional networks, which are called as SDN units, are stacked one by one to integrate contextual information and guarantee the fine recovery of localization information. Meanwhile, inter-unit and intra-unit connections are designed to assist network training and enhance feature fusion since the connections improve the flow of information and gradient propagation throughout the network. Besides, hierarchical supervision is applied during the upsampling process of each SDN unit, which guarantees the discrimination of feature representations and benefits the network optimization. We carry out comprehensive experiments and achieve the new state-of-the-art results on three datasets, including PASCAL VOC 2012, CamVid, GATECH. In particular, our best model without CRF post-processing achieves an intersection-over-union score of 86.6% in the test set.



### Training-image based geostatistical inversion using a spatial generative adversarial neural network
- **Arxiv ID**: http://arxiv.org/abs/1708.04975v2
- **DOI**: 10.1002/2017WR022148
- **Categories**: **stat.ML**, cs.CV, physics.geo-ph
- **Links**: [PDF](http://arxiv.org/pdf/1708.04975v2)
- **Published**: 2017-08-16 17:04:52+00:00
- **Updated**: 2019-01-08 14:44:42+00:00
- **Authors**: Eric Laloy, Romain Hérault, Diederik Jacques, Niklas Linde
- **Comment**: None
- **Journal**: Water Resources Research, 54, 381-406, 2018
- **Summary**: Probabilistic inversion within a multiple-point statistics framework is often computationally prohibitive for high-dimensional problems. To partly address this, we introduce and evaluate a new training-image based inversion approach for complex geologic media. Our approach relies on a deep neural network of the generative adversarial network (GAN) type. After training using a training image (TI), our proposed spatial GAN (SGAN) can quickly generate 2D and 3D unconditional realizations. A key characteristic of our SGAN is that it defines a (very) low-dimensional parameterization, thereby allowing for efficient probabilistic inversion using state-of-the-art Markov chain Monte Carlo (MCMC) methods. In addition, available direct conditioning data can be incorporated within the inversion. Several 2D and 3D categorical TIs are first used to analyze the performance of our SGAN for unconditional geostatistical simulation. Training our deep network can take several hours. After training, realizations containing a few millions of pixels/voxels can be produced in a matter of seconds. This makes it especially useful for simulating many thousands of realizations (e.g., for MCMC inversion) as the relative cost of the training per realization diminishes with the considered number of realizations. Synthetic inversion case studies involving 2D steady-state flow and 3D transient hydraulic tomography with and without direct conditioning data are used to illustrate the effectiveness of our proposed SGAN-based inversion. For the 2D case, the inversion rapidly explores the posterior model distribution. For the 3D case, the inversion recovers model realizations that fit the data close to the target level and visually resemble the true model well.



### Free Space Estimation using Occupancy Grids and Dynamic Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1708.04989v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.04989v1)
- **Published**: 2017-08-16 17:28:21+00:00
- **Updated**: 2017-08-16 17:28:21+00:00
- **Authors**: Raghavender Sahdev
- **Comment**: 10 pages, 10 figures
- **Journal**: None
- **Summary**: In this paper we present an approach to estimate Free Space from a Stereo image pair using stochastic occupancy grids. We do this in the domain of autonomous driving on the famous benchmark dataset KITTI. Later based on the generated occupancy grid we match 2 image sequences to compute the top view representation of the map. We do this to map the environment. We compute a transformation between the occupancy grids of two successive images and use it to compute the top view map. Two issues need to be addressed for mapping are discussed - computing a map and dealing with dynamic objects for computing the map. Dynamic Objects are detected in successive images based on an idea similar to tracking of foreground objects from the background objects based on motion flow. A novel RANSAC based segmentation approach has been proposed here to address this issue.



### Salt-n-pepper noise filtering using Cellular Automata
- **Arxiv ID**: http://arxiv.org/abs/1708.05019v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05019v1)
- **Published**: 2017-08-16 18:02:02+00:00
- **Updated**: 2017-08-16 18:02:02+00:00
- **Authors**: Dimitrios Tourtounis, Nikolaos Mitianoudis, Georgios Ch. Sirakoulis
- **Comment**: None
- **Journal**: Journal of Cellular Automata, Vol. 13, No. 1-2, pp. 81-101, 2018
- **Summary**: Cellular Automata (CA) have been considered one of the most pronounced parallel computational tools in the recent era of nature and bio-inspired computing. Taking advantage of their local connectivity, the simplicity of their design and their inherent parallelism, CA can be effectively applied to many image processing tasks. In this paper, a CA approach for efficient salt-n-pepper noise filtering in grayscale images is presented. Using a 2D Moore neighborhood, the classified "noisy" cells are corrected by averaging the non-noisy neighboring cells. While keeping the computational burden really low, the proposed approach succeeds in removing high-noise levels from various images and yields promising qualitative and quantitative results, compared to state-of-the-art techniques.



### Deep Neural Network Capacity
- **Arxiv ID**: http://arxiv.org/abs/1708.05029v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05029v3)
- **Published**: 2017-08-16 18:28:22+00:00
- **Updated**: 2018-02-18 18:42:40+00:00
- **Authors**: Aosen Wang, Hua Zhou, Wenyao Xu, Xin Chen
- **Comment**: There is an error in Average Valid Bits computation in figure 1 in
  page 2
- **Journal**: None
- **Summary**: In recent years, deep neural network exhibits its powerful superiority on information discrimination in many computer vision applications. However, the capacity of deep neural network architecture is still a mystery to the researchers. Intuitively, larger capacity of neural network can always deposit more information to improve the discrimination ability of the model. But, the learnable parameter scale is not feasible to estimate the capacity of deep neural network. Due to the overfitting, directly increasing hidden nodes number and hidden layer number are already demonstrated not necessary to effectively increase the network discrimination ability.   In this paper, we propose a novel measurement, named "total valid bits", to evaluate the capacity of deep neural networks for exploring how to quantitatively understand the deep learning and the insights behind its super performance. Specifically, our scheme to retrieve the total valid bits incorporates the skilled techniques in both training phase and inference phase. In the network training, we design decimal weight regularization and 8-bit forward quantization to obtain the integer-oriented network representations. Moreover, we develop adaptive-bitwidth and non-uniform quantization strategy in the inference phase to find the neural network capacity, total valid bits. By allowing zero bitwidth, our adaptive-bitwidth quantization can execute the model reduction and valid bits finding simultaneously. In our extensive experiments, we first demonstrate that our total valid bits is a good indicator of neural network capacity. We also analyze the impact on network capacity from the network architecture and advanced training skills, such as dropout and batch normalization.



### ConvNet Architecture Search for Spatiotemporal Feature Learning
- **Arxiv ID**: http://arxiv.org/abs/1708.05038v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05038v1)
- **Published**: 2017-08-16 18:54:39+00:00
- **Updated**: 2017-08-16 18:54:39+00:00
- **Authors**: Du Tran, Jamie Ray, Zheng Shou, Shih-Fu Chang, Manohar Paluri
- **Comment**: None
- **Journal**: None
- **Summary**: Learning image representations with ConvNets by pre-training on ImageNet has proven useful across many visual understanding tasks including object detection, semantic segmentation, and image captioning. Although any image representation can be applied to video frames, a dedicated spatiotemporal representation is still vital in order to incorporate motion patterns that cannot be captured by appearance based models alone. This paper presents an empirical ConvNet architecture search for spatiotemporal feature learning, culminating in a deep 3-dimensional (3D) Residual ConvNet. Our proposed architecture outperforms C3D by a good margin on Sports-1M, UCF101, HMDB51, THUMOS14, and ASLAN while being 2 times faster at inference time, 2 times smaller in model size, and having a more compact representation.



### Navigator-free EPI Ghost Correction with Structured Low-Rank Matrix Models: New Theory and Methods
- **Arxiv ID**: http://arxiv.org/abs/1708.05095v3
- **DOI**: 10.1109/TMI.2018.2822053
- **Categories**: **cs.CV**, cs.IT, math.IT, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1708.05095v3)
- **Published**: 2017-08-16 22:11:50+00:00
- **Updated**: 2018-03-06 01:41:59+00:00
- **Authors**: Rodrigo A. Lobos, Tae Hyung Kim, W. Scott Hoge, Justin P. Haldar
- **Comment**: 13 pages, 9 figures ; Submitted to IEEE Transactions on Medical
  Imaging
- **Journal**: None
- **Summary**: Structured low-rank matrix models have previously been introduced to enable calibrationless MR image reconstruction from sub-Nyquist data, and such ideas have recently been extended to enable navigator-free echo-planar imaging (EPI) ghost correction. This paper presents novel theoretical analysis which shows that, because of uniform subsampling, the structured low-rank matrix optimization problems for EPI data will always have either undesirable or non-unique solutions in the absence of additional constraints. This theory leads us to recommend and investigate problem formulations for navigator-free EPI that incorporate side information from either image-domain or k-space domain parallel imaging methods. The importance of using nonconvex low-rank matrix regularization is also identified. We demonstrate using phantom and \emph{in vivo} data that the proposed methods are able to eliminate ghost artifacts for several navigator-free EPI acquisition schemes, obtaining better performance in comparison to state-of-the-art methods across a range of different scenarios. Results are shown for both single-channel acquisition and highly accelerated multi-channel acquisition.



