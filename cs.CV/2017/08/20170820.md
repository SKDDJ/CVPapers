# Arxiv Papers in cs.CV on 2017-08-20
### Dual-fisheye lens stitching for 360-degree imaging
- **Arxiv ID**: http://arxiv.org/abs/1708.08988v1
- **DOI**: 10.1109/ICASSP.2017.7952541
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1708.08988v1)
- **Published**: 2017-08-20 03:23:48+00:00
- **Updated**: 2017-08-20 03:23:48+00:00
- **Authors**: Tuan Ho, Madhukar Budagavi
- **Comment**: ICASSP 17 preprint, Proc. of the 42nd IEEE International Conference
  on Acoustics, Speech and Signal Processing (ICASSP), New Orleans, USA, March
  2017
- **Journal**: None
- **Summary**: Dual-fisheye lens cameras have been increasingly used for 360-degree immersive imaging. However, the limited overlapping field of views and misalignment between the two lenses give rise to visible discontinuities in the stitching boundaries. This paper introduces a novel method for dual-fisheye camera stitching that adaptively minimizes the discontinuities in the overlapping regions to generate full spherical 360-degree images. Results show that this approach can produce good quality stitched images for Samsung Gear 360 -- a dual-fisheye camera, even with hard-to-stitch objects in the stitching borders.



### Incremental Import Vector Machines for Classifying Hyperspectral Data
- **Arxiv ID**: http://arxiv.org/abs/1708.05966v1
- **DOI**: 10.1109/TGRS.2012.2184292
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05966v1)
- **Published**: 2017-08-20 13:59:00+00:00
- **Updated**: 2017-08-20 13:59:00+00:00
- **Authors**: Ribana Roscher, Björn Waske, Wolfgang Förstner
- **Comment**: None
- **Journal**: IEEE Transactions on Geoscience and Remote Sensing, Vol.50, No.09,
  September 2012, 3463-3473
- **Summary**: In this paper we propose an incremental learning strategy for import vector machines (IVM), which is a sparse kernel logistic regression approach. We use the procedure for the concept of self-training for sequential classification of hyperspectral data. The strategy comprises the inclusion of new training samples to increase the classification accuracy and the deletion of non-informative samples to be memory- and runtime-efficient. Moreover, we update the parameters in the incremental IVM model without re-training from scratch. Therefore, the incremental classifier is able to deal with large data sets. The performance of the IVM in comparison to support vector machines (SVM) is evaluated in terms of accuracy and experiments are conducted to assess the potential of the probabilistic outputs of the IVM. Experimental results demonstrate that the IVM and SVM perform similar in terms of classification accuracy. However, the number of import vectors is significantly lower when compared to the number of support vectors and thus, the computation time during classification can be decreased. Moreover, the probabilities provided by IVM are more reliable, when compared to the probabilistic information, derived from an SVM's output. In addition, the proposed self-training strategy can increase the classification accuracy. Overall, the IVM and the its incremental version is worthwhile for the classification of hyperspectral data.



### Applying Data Augmentation to Handwritten Arabic Numeral Recognition Using Deep Learning Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1708.05969v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05969v5)
- **Published**: 2017-08-20 14:21:05+00:00
- **Updated**: 2022-09-08 13:50:55+00:00
- **Authors**: Akm Ashiquzzaman, Abdul Kawsar Tushar, Md Ashiqur Rahman
- **Comment**: 5 pages, 6 figures, 3 tables
- **Journal**: None
- **Summary**: Handwritten character recognition has been the center of research and a benchmark problem in the sector of pattern recognition and artificial intelligence, and it continues to be a challenging research topic. Due to its enormous application many works have been done in this field focusing on different languages. Arabic, being a diversified language has a huge scope of research with potential challenges. A convolutional neural network model for recognizing handwritten numerals in Arabic language is proposed in this paper, where the dataset is subject to various augmentation in order to add robustness needed for deep learning approach. The proposed method is empowered by the presence of dropout regularization to do away with the problem of data overfitting. Moreover, suitable change is introduced in activation function to overcome the problem of vanishing gradient. With these modifications, the proposed system achieves an accuracy of 99.4\% which performs better than every previous work on the dataset.



### Shapelet-based Sparse Representation for Landcover Classification of Hyperspectral Images
- **Arxiv ID**: http://arxiv.org/abs/1708.05974v1
- **DOI**: 10.1109/TGRS.2015.2484619
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05974v1)
- **Published**: 2017-08-20 14:36:11+00:00
- **Updated**: 2017-08-20 14:36:11+00:00
- **Authors**: Ribana Roscher, Björn Waske
- **Comment**: None
- **Journal**: IEEE Transactions on Geoscience and Remote Sensing, Volume: 54,
  Issue: 3, March 2016, 1623 - 1634
- **Summary**: This paper presents a sparse representation-based classification approach with a novel dictionary construction procedure. By using the constructed dictionary sophisticated prior knowledge about the spatial nature of the image can be integrated. The approach is based on the assumption that each image patch can be factorized into characteristic spatial patterns, also called shapelets, and patch-specific spectral information. A set of shapelets is learned in an unsupervised way and spectral information are embodied by training samples. A combination of shapelets and spectral information are represented in an undercomplete spatial-spectral dictionary for each individual patch, where the elements of the dictionary are linearly combined to a sparse representation of the patch. The patch-based classification is obtained by means of the representation error. Experiments are conducted on three well-known hyperspectral image datasets. They illustrate that our proposed approach shows superior results in comparison to sparse representation-based classifiers that use only limited spatial information and behaves competitively with or better than state-of-the-art classifiers utilizing spatial information and kernelized sparse representation-based classifiers.



### An Efficient Single Chord-based Accumulation Technique (SCA) to Detect More Reliable Corners
- **Arxiv ID**: http://arxiv.org/abs/1708.05979v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05979v1)
- **Published**: 2017-08-20 14:55:02+00:00
- **Updated**: 2017-08-20 14:55:02+00:00
- **Authors**: Mohammad Asiful Hossain, Abdul Kawsar Tushar, Shofiullah Babor
- **Comment**: 5 pages, 7 figures, 2 tables, Accepted on 4th International
  Conference on Advances in Electrical Engineering (ICAEE)
- **Journal**: None
- **Summary**: Corner detection is a vital operation in numerous computer vision applications. The Chord-to-Point Distance Accumulation (CPDA) detector is recognized as the contour-based corner detector producing the lowest localization error while localizing corners in an image. However, in our experiment part, we demonstrate that CPDA detector often misses some potential corners. Moreover, the detection algorithm of CPDA is computationally costly. In this paper, We focus on reducing localization error as well as increasing average repeatability. The preprocessing and refinements steps of proposed process are similar to CPDA. Our experimental results will show the effectiveness and robustness of proposed process over CPDA.



### Attentive Semantic Video Generation using Captions
- **Arxiv ID**: http://arxiv.org/abs/1708.05980v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05980v3)
- **Published**: 2017-08-20 14:55:19+00:00
- **Updated**: 2017-10-21 21:12:41+00:00
- **Authors**: Tanya Marwah, Gaurav Mittal, Vineeth N. Balasubramanian
- **Comment**: None
- **Journal**: Presented at ICCV 2017 (International Conference on Computer
  Vision)
- **Summary**: This paper proposes a network architecture to perform variable length semantic video generation using captions. We adopt a new perspective towards video generation where we allow the captions to be combined with the long-term and short-term dependencies between video frames and thus generate a video in an incremental manner. Our experiments demonstrate our network architecture's ability to distinguish between objects, actions and interactions in a video and combine them to generate videos for unseen captions. The network also exhibits the capability to perform spatio-temporal style transfer when asked to generate videos for a sequence of captions. We also show that the network's ability to learn a latent representation allows it generate videos in an unsupervised manner and perform other tasks such as action recognition. (Accepted in International Conference in Computer Vision (ICCV) 2017)



### Joint Multi-view Face Alignment in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1708.06023v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.06023v1)
- **Published**: 2017-08-20 21:20:18+00:00
- **Updated**: 2017-08-20 21:20:18+00:00
- **Authors**: Jiankang Deng, George Trigeorgis, Yuxiang Zhou, Stefanos Zafeiriou
- **Comment**: submit to IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: The de facto algorithm for facial landmark estimation involves running a face detector with a subsequent deformable model fitting on the bounding box. This encompasses two basic problems: i) the detection and deformable fitting steps are performed independently, while the detector might not provide best-suited initialisation for the fitting step, ii) the face appearance varies hugely across different poses, which makes the deformable face fitting very challenging and thus distinct models have to be used (\eg, one for profile and one for frontal faces). In this work, we propose the first, to the best of our knowledge, joint multi-view convolutional network to handle large pose variations across faces in-the-wild, and elegantly bridge face detection and facial landmark localisation tasks. Existing joint face detection and landmark localisation methods focus only on a very small set of landmarks. By contrast, our method can detect and align a large number of landmarks for semi-frontal (68 landmarks) and profile (39 landmarks) faces. We evaluate our model on a plethora of datasets including standard static image datasets such as IBUG, 300W, COFW, and the latest Menpo Benchmark for both semi-frontal and profile faces. Significant improvement over state-of-the-art methods on deformable face tracking is witnessed on 300VW benchmark. We also demonstrate state-of-the-art results for face detection on FDDB and MALF datasets.



### DeepBreath: Deep Learning of Breathing Patterns for Automatic Stress Recognition using Low-Cost Thermal Imaging in Unconstrained Settings
- **Arxiv ID**: http://arxiv.org/abs/1708.06026v1
- **DOI**: 10.1109/ACII.2017.8273639
- **Categories**: **cs.HC**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1708.06026v1)
- **Published**: 2017-08-20 21:36:30+00:00
- **Updated**: 2017-08-20 21:36:30+00:00
- **Authors**: Youngjun Cho, Nadia Bianchi-Berthouze, Simon J. Julier
- **Comment**: Submitted to "2017 7th International Conference on Affective
  Computing and Intelligent Interaction (ACII)" - ACII 2017
- **Journal**: None
- **Summary**: We propose DeepBreath, a deep learning model which automatically recognises people's psychological stress level (mental overload) from their breathing patterns. Using a low cost thermal camera, we track a person's breathing patterns as temperature changes around his/her nostril. The paper's technical contribution is threefold. First of all, instead of creating hand-crafted features to capture aspects of the breathing patterns, we transform the uni-dimensional breathing signals into two dimensional respiration variability spectrogram (RVS) sequences. The spectrograms easily capture the complexity of the breathing dynamics. Second, a spatial pattern analysis based on a deep Convolutional Neural Network (CNN) is directly applied to the spectrogram sequences without the need of hand-crafting features. Finally, a data augmentation technique, inspired from solutions for over-fitting problems in deep learning, is applied to allow the CNN to learn with a small-scale dataset from short-term measurements (e.g., up to a few hours). The model is trained and tested with data collected from people exposed to two types of cognitive tasks (Stroop Colour Word Test, Mental Computation test) with sessions of different difficulty levels. Using normalised self-report as ground truth, the CNN reaches 84.59% accuracy in discriminating between two levels of stress and 56.52% in discriminating between three levels. In addition, the CNN outperformed powerful shallow learning methods based on a single layer neural network. Finally, the dataset of labelled thermal images will be open to the community.



