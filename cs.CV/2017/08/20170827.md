# Arxiv Papers in cs.CV on 2017-08-27
### Imbalanced Malware Images Classification: a CNN based Approach
- **Arxiv ID**: http://arxiv.org/abs/1708.08042v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1708.08042v2)
- **Published**: 2017-08-27 02:27:59+00:00
- **Updated**: 2022-02-20 03:51:03+00:00
- **Authors**: Songqing Yue, Tianyang Wang
- **Comment**: updated version with typos fixed and corrected technical expressions
- **Journal**: None
- **Summary**: Deep convolutional neural networks (CNNs) can be applied to malware binary detection via image classification. The performance, however, is degraded due to the imbalance of malware families (classes). To mitigate this issue, we propose a simple yet effective weighted softmax loss which can be employed as the final layer of deep CNNs. The original softmax loss is weighted, and the weight value can be determined according to class size. A scaling parameter is also included in computing the weight. Proper selection of this parameter is studied and an empirical option is suggested. The weighted loss aims at alleviating the impact of data imbalance in an end-to-end learning fashion. To validate the efficacy, we deploy the proposed weighted loss in a pre-trained deep CNN model and fine-tune it to achieve promising results on malware images classification. Extensive experiments also demonstrate that the new loss function can well fit other typical CNNs, yielding an improved classification performance.



### Cross-view Asymmetric Metric Learning for Unsupervised Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1708.08062v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.08062v2)
- **Published**: 2017-08-27 07:59:29+00:00
- **Updated**: 2017-10-18 14:21:46+00:00
- **Authors**: Hong-Xing Yu, Ancong Wu, Wei-Shi Zheng
- **Comment**: None
- **Journal**: None
- **Summary**: While metric learning is important for Person re-identification (RE-ID), a significant problem in visual surveillance for cross-view pedestrian matching, existing metric models for RE-ID are mostly based on supervised learning that requires quantities of labeled samples in all pairs of camera views for training. However, this limits their scalabilities to realistic applications, in which a large amount of data over multiple disjoint camera views is available but not labelled. To overcome the problem, we propose unsupervised asymmetric metric learning for unsupervised RE-ID. Our model aims to learn an asymmetric metric, i.e., specific projection for each view, based on asymmetric clustering on cross-view person images. Our model finds a shared space where view-specific bias is alleviated and thus better matching performance can be achieved. Extensive experiments have been conducted on a baseline and five large-scale RE-ID datasets to demonstrate the effectiveness of the proposed model. Through the comparison, we show that our model works much more suitable for unsupervised RE-ID compared to classical unsupervised metric learning models. We also compare with existing unsupervised RE-ID methods, and our model outperforms them with notable margins. Specifically, we report the results on large-scale unlabelled RE-ID dataset, which is important but unfortunately less concerned in literatures.



### Part-to-whole Registration of Histology and MRI using Shape Elements
- **Arxiv ID**: http://arxiv.org/abs/1708.08117v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.08117v1)
- **Published**: 2017-08-27 18:01:41+00:00
- **Updated**: 2017-08-27 18:01:41+00:00
- **Authors**: Jonas Pichat, Juan Eugenio Iglesias, Sotiris Nousias, Tarek Yousry, Sebastien Ourselin, Marc Modat
- **Comment**: Paper accepted at ICCV Workshop (Bio-Image Computing)
- **Journal**: None
- **Summary**: Image registration between histology and magnetic resonance imaging (MRI) is a challenging task due to differences in structural content and contrast. Too thick and wide specimens cannot be processed all at once and must be cut into smaller pieces. This dramatically increases the complexity of the problem, since each piece should be individually and manually pre-aligned. To the best of our knowledge, no automatic method can reliably locate such piece of tissue within its respective whole in the MRI slice, and align it without any prior information. We propose here a novel automatic approach to the joint problem of multimodal registration between histology and MRI, when only a fraction of tissue is available from histology. The approach relies on the representation of images using their level lines so as to reach contrast invariance. Shape elements obtained via the extraction of bitangents are encoded in a projective-invariant manner, which permits the identification of common pieces of curves between two images. We evaluated the approach on human brain histology and compared resulting alignments against manually annotated ground truths. Considering the complexity of the brain folding patterns, preliminary results are promising and suggest the use of characteristic and meaningful shape elements for improved robustness and efficiency.



### A Machine Learning Approach For Identifying Patients with Mild Traumatic Brain Injury Using Diffusion MRI Modeling
- **Arxiv ID**: http://arxiv.org/abs/1708.09000v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.09000v1)
- **Published**: 2017-08-27 20:14:28+00:00
- **Updated**: 2017-08-27 20:14:28+00:00
- **Authors**: Shervin Minaee, Yao Wang, Sohae Chung, Xiuyuan Wang, Els Fieremans, Steven Flanagan, Joseph Rath, Yvonne W. Lui
- **Comment**: None
- **Journal**: None
- **Summary**: While diffusion MRI has been extremely promising in the study of MTBI, identifying patients with recent MTBI remains a challenge. The literature is mixed with regard to localizing injury in these patients, however, gray matter such as the thalamus and white matter including the corpus callosum and frontal deep white matter have been repeatedly implicated as areas at high risk for injury. The purpose of this study is to develop a machine learning framework to classify MTBI patients and controls using features derived from multi-shell diffusion MRI in the thalamus, frontal white matter and corpus callosum.



### One-Shot Concept Learning by Simulating Evolutionary Instinct Development
- **Arxiv ID**: http://arxiv.org/abs/1708.08141v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.08141v1)
- **Published**: 2017-08-27 21:15:23+00:00
- **Updated**: 2017-08-27 21:15:23+00:00
- **Authors**: Abrar Ahmed, Anish Bikmal
- **Comment**: None
- **Journal**: None
- **Summary**: Object recognition has become a crucial part of machine learning and computer vision recently. The current approach to object recognition involves Deep Learning and uses Convolutional Neural Networks to learn the pixel patterns of the objects implicitly through backpropagation. However, CNNs require thousands of examples in order to generalize successfully and often require heavy computing resources for training. This is considered rather sluggish when compared to the human ability to generalize and learn new categories given just a single example. Additionally, CNNs make it difficult to explicitly programmatically modify or intuitively interpret their learned representations.   We propose a computational model that can successfully learn an object category from as few as one example and allows its learning style to be tailored explicitly to a scenario. Our model decomposes each image into two attributes: shape and color distribution. We then use a Bayesian criterion to probabilistically determine the likelihood of each category. The model takes each factor into account based on importance and calculates the conditional probability of the object belonging to each learned category. Our model is not only applicable to visual scenarios, but can also be implemented in a broader and more practical scope of situations such as Natural Language Processing as well as other places where it is possible to retrieve and construct individual attributes. Because the only condition our model presents is the ability to retrieve and construct individual attributes such as shape and color, it can be applied to essentially any class of visual objects.



