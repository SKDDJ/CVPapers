# Arxiv Papers in cs.CV on 2017-08-19
### Discovery of Visual Semantics by Unsupervised and Self-Supervised Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1708.05812v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05812v1)
- **Published**: 2017-08-19 06:38:53+00:00
- **Updated**: 2017-08-19 06:38:53+00:00
- **Authors**: Gustav Larsson
- **Comment**: Ph.D. thesis
- **Journal**: None
- **Summary**: The success of deep learning in computer vision is rooted in the ability of deep networks to scale up model complexity as demanded by challenging visual tasks. As complexity is increased, so is the need for large amounts of labeled data to train the model. This is associated with a costly human annotation effort. To address this concern, with the long-term goal of leveraging the abundance of cheap unlabeled data, we explore methods of unsupervised "pre-training." In particular, we propose to use self-supervised automatic image colorization.   We show that traditional methods for unsupervised learning, such as layer-wise clustering or autoencoders, remain inferior to supervised pre-training. In search for an alternative, we develop a fully automatic image colorization method. Our method sets a new state-of-the-art in revitalizing old black-and-white photography, without requiring human effort or expertise. Additionally, it gives us a method for self-supervised representation learning. In order for the model to appropriately re-color a grayscale object, it must first be able to identify it. This ability, learned entirely self-supervised, can be used to improve other visual tasks, such as classification and semantic segmentation. As a future direction for self-supervision, we investigate if multiple proxy tasks can be combined to improve generalization. This turns out to be a challenging open problem. We hope that our contributions to this endeavor will provide a foundation for future efforts in making self-supervision compete with supervised pre-training.



### Visual Forecasting by Imitating Dynamics in Natural Sequences
- **Arxiv ID**: http://arxiv.org/abs/1708.05827v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05827v1)
- **Published**: 2017-08-19 09:45:52+00:00
- **Updated**: 2017-08-19 09:45:52+00:00
- **Authors**: Kuo-Hao Zeng, William B. Shen, De-An Huang, Min Sun, Juan Carlos Niebles
- **Comment**: 10 pages, 9 figures, accepted to ICCV 2017
- **Journal**: None
- **Summary**: We introduce a general framework for visual forecasting, which directly imitates visual sequences without additional supervision. As a result, our model can be applied at several semantic levels and does not require any domain knowledge or handcrafted features. We achieve this by formulating visual forecasting as an inverse reinforcement learning (IRL) problem, and directly imitate the dynamics in natural sequences from their raw pixel values. The key challenge is the high-dimensional and continuous state-action space that prohibits the application of previous IRL algorithms. We address this computational bottleneck by extending recent progress in model-free imitation with trainable deep feature representations, which (1) bypasses the exhaustive state-action pair visits in dynamic programming by using a dual formulation and (2) avoids explicit state sampling at gradient computation using a deep feature reparametrization. This allows us to apply IRL at scale and directly imitate the dynamics in high-dimensional continuous visual sequences from the raw pixel values. We evaluate our approach at three different level-of-abstraction, from low level pixels to higher level semantics: future frame generation, action anticipation, visual story forecasting. At all levels, our approach outperforms existing methods.



### High Voltage Insulator Surface Evaluation Using Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1708.05828v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05828v1)
- **Published**: 2017-08-19 10:10:24+00:00
- **Updated**: 2017-08-19 10:10:24+00:00
- **Authors**: Damira Pernebayeva, Mehdi Bagheri, Alex Pappachen James
- **Comment**: 2017 International Symposium on Electrical Insulating Materials,
  September 12-15, 2017
- **Journal**: None
- **Summary**: High voltage insulators are widely deployed in power systems to isolate the live- and dead-part of overhead lines as well as to support the power line conductors mechanically. Permanent, secure and safe operation of power transmission lines require that the high voltage insulators are inspected and monitor, regularly. Severe environment conditions will influence insulator surface and change creepage distance. Consequently, power utilities and transmission companies face significant problem in operation due to insulator damage or contamination. In this study, a new technique is developed for real-time inspection of insulator and estimating the snow, ice and water over the insulator surface which can be a potential risk of operation breakdown. To examine the proposed system, practical experiment is conducted using ceramic insulator for capturing the images with snow, ice and wet surface conditions. Gabor and Standard deviation filters are utilized for image feature extraction. The best achieved recognition accuracy rate was 87% using statistical approach the Standard deviation.



### A Data and Model-Parallel, Distributed and Scalable Framework for Training of Deep Networks in Apache Spark
- **Arxiv ID**: http://arxiv.org/abs/1708.05840v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.DC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1708.05840v1)
- **Published**: 2017-08-19 13:17:58+00:00
- **Updated**: 2017-08-19 13:17:58+00:00
- **Authors**: Disha Shrivastava, Santanu Chaudhury, Dr. Jayadeva
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: Training deep networks is expensive and time-consuming with the training period increasing with data size and growth in model parameters. In this paper, we provide a framework for distributed training of deep networks over a cluster of CPUs in Apache Spark. The framework implements both Data Parallelism and Model Parallelism making it suitable to use for deep networks which require huge training data and model parameters which are too big to fit into the memory of a single machine. It can be scaled easily over a cluster of cheap commodity hardware to attain significant speedup and obtain better results making it quite economical as compared to farm of GPUs and supercomputers. We have proposed a new algorithm for training of deep networks for the case when the network is partitioned across the machines (Model Parallelism) along with detailed cost analysis and proof of convergence of the same. We have developed implementations for Fully-Connected Feedforward Networks, Convolutional Neural Networks, Recurrent Neural Networks and Long Short-Term Memory architectures. We present the results of extensive simulations demonstrating the speedup and accuracy obtained by our framework for different sizes of the data and model parameters with variation in the number of worker cores/partitions; thereby showing that our proposed framework can achieve significant speedup (upto 11X for CNN) and is also quite scalable.



### Image2song: Song Retrieval via Bridging Image Content and Lyric Words
- **Arxiv ID**: http://arxiv.org/abs/1708.05851v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1708.05851v1)
- **Published**: 2017-08-19 14:17:44+00:00
- **Updated**: 2017-08-19 14:17:44+00:00
- **Authors**: Xuelong Li, Di Hu, Xiaoqiang Lu
- **Comment**: 13 pages, 13 figures, accepted by ICCV 2017
- **Journal**: None
- **Summary**: Image is usually taken for expressing some kinds of emotions or purposes, such as love, celebrating Christmas. There is another better way that combines the image and relevant song to amplify the expression, which has drawn much attention in the social network recently. Hence, the automatic selection of songs should be expected. In this paper, we propose to retrieve semantic relevant songs just by an image query, which is named as the image2song problem. Motivated by the requirements of establishing correlation in semantic/content, we build a semantic-based song retrieval framework, which learns the correlation between image content and lyric words. This model uses a convolutional neural network to generate rich tags from image regions, a recurrent neural network to model lyric, and then establishes correlation via a multi-layer perceptron. To reduce the content gap between image and lyric, we propose to make the lyric modeling focus on the main image content via a tag attention. We collect a dataset from the social-sharing multimodal data to study the proposed problem, which consists of (image, music clip, lyric) triplets. We demonstrate that our proposed model shows noticeable results in the image2song retrieval task and provides suitable songs. Besides, the song2image task is also performed.



### A Brief Survey of Deep Reinforcement Learning
- **Arxiv ID**: http://arxiv.org/abs/1708.05866v2
- **DOI**: 10.1109/MSP.2017.2743240
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1708.05866v2)
- **Published**: 2017-08-19 15:55:31+00:00
- **Updated**: 2017-09-28 21:51:43+00:00
- **Authors**: Kai Arulkumaran, Marc Peter Deisenroth, Miles Brundage, Anil Anthony Bharath
- **Comment**: IEEE Signal Processing Magazine, Special Issue on Deep Learning for
  Image Understanding (arXiv extended version)
- **Journal**: None
- **Summary**: Deep reinforcement learning is poised to revolutionise the field of AI and represents a step towards building autonomous systems with a higher level understanding of the visual world. Currently, deep learning is enabling reinforcement learning to scale to problems that were previously intractable, such as learning to play video games directly from pixels. Deep reinforcement learning algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of reinforcement learning, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep reinforcement learning, including the deep $Q$-network, trust region policy optimisation, and asynchronous advantage actor-critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via reinforcement learning. To conclude, we describe several current areas of research within the field.



### Sim4CV: A Photo-Realistic Simulator for Computer Vision Applications
- **Arxiv ID**: http://arxiv.org/abs/1708.05869v2
- **DOI**: 10.1007/s11263-018-1073-7
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05869v2)
- **Published**: 2017-08-19 16:09:06+00:00
- **Updated**: 2018-03-24 14:34:30+00:00
- **Authors**: Matthias Müller, Vincent Casser, Jean Lahoud, Neil Smith, Bernard Ghanem
- **Comment**: Published at the International Journal of Computer Vision (IJCV),
  2018
- **Journal**: None
- **Summary**: We present a photo-realistic training and evaluation simulator (Sim4CV) with extensive applications across various fields of computer vision. Built on top of the Unreal Engine, the simulator integrates full featured physics based cars, unmanned aerial vehicles (UAVs), and animated human actors in diverse urban and suburban 3D environments. We demonstrate the versatility of the simulator with two case studies: autonomous UAV-based tracking of moving objects and autonomous driving using supervised learning. The simulator fully integrates both several state-of-the-art tracking algorithms with a benchmark evaluation tool and a deep neural network (DNN) architecture for training vehicles to drive autonomously. It generates synthetic photo-realistic datasets with automatic ground truth annotations to easily extend existing real-world datasets and provides extensive synthetic data variety through its ability to reconfigure synthetic worlds on the fly using an automatic world generation tool. The supplementary video can be viewed a https://youtu.be/SqAxzsQ7qUU



### Teaching UAVs to Race: End-to-End Regression of Agile Controls in Simulation
- **Arxiv ID**: http://arxiv.org/abs/1708.05884v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05884v4)
- **Published**: 2017-08-19 18:13:23+00:00
- **Updated**: 2018-11-22 15:12:02+00:00
- **Authors**: Matthias Müller, Vincent Casser, Neil Smith, Dominik L. Michels, Bernard Ghanem
- **Comment**: Accepted at ECCVW'18
- **Journal**: None
- **Summary**: Automating the navigation of unmanned aerial vehicles (UAVs) in diverse scenarios has gained much attention in recent years. However, teaching UAVs to fly in challenging environments remains an unsolved problem, mainly due to the lack of training data. In this paper, we train a deep neural network to predict UAV controls from raw image data for the task of autonomous UAV racing in a photo-realistic simulation. Training is done through imitation learning with data augmentation to allow for the correction of navigation mistakes. Extensive experiments demonstrate that our trained network (when sufficient data augmentation is used) outperforms state-of-the-art methods and flies more consistently than many human pilots. Additionally, we show that our optimized network architecture can run in real-time on embedded hardware, allowing for efficient on-board processing critical for real-world deployment. From a broader perspective, our results underline the importance of extensive data augmentation techniques to improve robustness in end-to-end learning setups.



### Computer-aided diagnosis of lung nodule using gradient tree boosting and Bayesian optimization
- **Arxiv ID**: http://arxiv.org/abs/1708.05897v2
- **DOI**: 10.1371/journal.pone.0195875
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1708.05897v2)
- **Published**: 2017-08-19 20:20:34+00:00
- **Updated**: 2017-08-28 11:52:13+00:00
- **Authors**: Mizuho Nishio, Mitsuo Nishizawa, Osamu Sugiyama, Ryosuke Kojima, Masahiro Yakami, Tomohiro Kuroda, Kaori Togashi
- **Comment**: 29 pages, 4 figures
- **Journal**: None
- **Summary**: We aimed to evaluate computer-aided diagnosis (CADx) system for lung nodule classification focusing on (i) usefulness of gradient tree boosting (XGBoost) and (ii) effectiveness of parameter optimization using Bayesian optimization (Tree Parzen Estimator, TPE) and random search. 99 lung nodules (62 lung cancers and 37 benign lung nodules) were included from public databases of CT images. A variant of local binary pattern was used for calculating feature vectors. Support vector machine (SVM) or XGBoost was trained using the feature vectors and their labels. TPE or random search was used for parameter optimization of SVM and XGBoost. Leave-one-out cross-validation was used for optimizing and evaluating the performance of our CADx system. Performance was evaluated using area under the curve (AUC) of receiver operating characteristic analysis. AUC was calculated 10 times, and its average was obtained. The best averaged AUC of SVM and XGBoost were 0.850 and 0.896, respectively; both were obtained using TPE. XGBoost was generally superior to SVM. Optimal parameters for achieving high AUC were obtained with fewer numbers of trials when using TPE, compared with random search. In conclusion, XGBoost was better than SVM for classifying lung nodules. TPE was more efficient than random search for parameter optimization.



