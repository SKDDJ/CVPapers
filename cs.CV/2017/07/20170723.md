# Arxiv Papers in cs.CV on 2017-07-23
### A comment on the paper Prediction of Kidney Function from Biopsy Images using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1707.09869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09869v1)
- **Published**: 2017-07-23 01:35:55+00:00
- **Updated**: 2017-07-23 01:35:55+00:00
- **Authors**: Washington LC dos-Santos, Angelo A Duarte, Luiz AR de Freitas
- **Comment**: 2 pages, 1 figure
- **Journal**: None
- **Summary**: This letter presente a comment on the paper Prediction of Kidney Function from Biopsy Images using Convolutional Neural Networks by Ledbetter et al. (2017)



### Team Applied Robotics: A closer look at our robotic picking system
- **Arxiv ID**: http://arxiv.org/abs/1707.07244v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1707.07244v1)
- **Published**: 2017-07-23 04:19:52+00:00
- **Updated**: 2017-07-23 04:19:52+00:00
- **Authors**: Wim Abbeloos, Fabian Gouwens, Simon Jansen, Berend Küpers, Maurice Ramaker, Toon Goedemé
- **Comment**: IEEE International Conference on Robotics and Automation (ICRA),
  Warehouse Picking Automation Workshop, May 29 to June 3, 2017, Singapore
- **Journal**: None
- **Summary**: This paper describes the vision based robotic picking system that was developed by our team, Team Applied Robotics, for the Amazon Picking Challenge 2016. This competition challenged teams to develop a robotic system that is able to pick a large variety of products from a shelve or a tote. We discuss the design considerations and our strategy, the high resolution 3D vision system, the use of a combination of texture and shape-based object detection algorithms, the robot path planning and object manipulators that were developed.



### Towards Good Practices for Deep 3D Hand Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1707.07248v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07248v1)
- **Published**: 2017-07-23 05:14:31+00:00
- **Updated**: 2017-07-23 05:14:31+00:00
- **Authors**: Hengkai Guo, Guijin Wang, Xinghao Chen, Cairong Zhang
- **Comment**: Extended version of arXiv:1702.02447
- **Journal**: None
- **Summary**: 3D hand pose estimation from single depth image is an important and challenging problem for human-computer interaction. Recently deep convolutional networks (ConvNet) with sophisticated design have been employed to address it, but the improvement over traditional random forest based methods is not so apparent. To exploit the good practice and promote the performance for hand pose estimation, we propose a tree-structured Region Ensemble Network (REN) for directly 3D coordinate regression. It first partitions the last convolution outputs of ConvNet into several grid regions. The results from separate fully-connected (FC) regressors on each regions are then integrated by another FC layer to perform the estimation. By exploitation of several training strategies including data augmentation and smooth $L_1$ loss, proposed REN can significantly improve the performance of ConvNet to localize hand joints. The experimental results demonstrate that our approach achieves the best performance among state-of-the-art algorithms on three public hand pose datasets. We also experiment our methods on fingertip detection and human pose datasets and obtain state-of-the-art accuracy.



### Detecting and Grouping Identical Objects for Region Proposal and Classification
- **Arxiv ID**: http://arxiv.org/abs/1707.07255v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07255v1)
- **Published**: 2017-07-23 07:11:35+00:00
- **Updated**: 2017-07-23 07:11:35+00:00
- **Authors**: Wim Abbeloos, Sergio Caccamo, Esra Ataer-Cansizoglu, Yuichi Taguchi, Chen Feng, Teng-Yok Lee
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  Workshop Deep Learning for Robotic Vision, 21 July, 2017, Honolulu, Hawaii
- **Journal**: None
- **Summary**: Often multiple instances of an object occur in the same scene, for example in a warehouse. Unsupervised multi-instance object discovery algorithms are able to detect and identify such objects. We use such an algorithm to provide object proposals to a convolutional neural network (CNN) based classifier. This results in fewer regions to evaluate, compared to traditional region proposal algorithms. Additionally, it enables using the joint probability of multiple instances of an object, resulting in improved classification accuracy. The proposed technique can also split a single class into multiple sub-classes corresponding to the different object types, enabling hierarchical classification.



### Deeply-Learned Part-Aligned Representations for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1707.07256v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07256v1)
- **Published**: 2017-07-23 07:25:07+00:00
- **Updated**: 2017-07-23 07:25:07+00:00
- **Authors**: Liming Zhao, Xi Li, Jingdong Wang, Yueting Zhuang
- **Comment**: Accepted by ICCV 2017
- **Journal**: None
- **Summary**: In this paper, we address the problem of person re-identification, which refers to associating the persons captured from different cameras. We propose a simple yet effective human part-aligned representation for handling the body part misalignment problem. Our approach decomposes the human body into regions (parts) which are discriminative for person matching, accordingly computes the representations over the regions, and aggregates the similarities computed between the corresponding regions of a pair of probe and gallery images as the overall matching score. Our formulation, inspired by attention models, is a deep neural network modeling the three steps together, which is learnt through minimizing the triplet loss function without requiring body part labeling information. Unlike most existing deep learning algorithms that learn a global or spatial partition-based local representation, our approach performs human body partition, and thus is more robust to pose changes and various human spatial distributions in the person bounding box. Our approach shows state-of-the-art results over standard datasets, Market-$1501$, CUHK$03$, CUHK$01$ and VIPeR.



### Deep Optical Flow Estimation Via Multi-Scale Correspondence Structure Learning
- **Arxiv ID**: http://arxiv.org/abs/1707.07301v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07301v1)
- **Published**: 2017-07-23 14:08:54+00:00
- **Updated**: 2017-07-23 14:08:54+00:00
- **Authors**: Shanshan Zhao, Xi Li, Omar El Farouk Bourahla
- **Comment**: 7 pages, 3 figures, 2 tables
- **Journal**: None
- **Summary**: As an important and challenging problem in computer vision, learning based optical flow estimation aims to discover the intrinsic correspondence structure between two adjacent video frames through statistical learning. Therefore, a key issue to solve in this area is how to effectively model the multi-scale correspondence structure properties in an adaptive end-to-end learning fashion. Motivated by this observation, we propose an end-to-end multi-scale correspondence structure learning (MSCSL) approach for optical flow estimation. In principle, the proposed MSCSL approach is capable of effectively capturing the multi-scale inter-image-correlation correspondence structures within a multi-level feature space from deep learning. Moreover, the proposed MSCSL approach builds a spatial Conv-GRU neural network model to adaptively model the intrinsic dependency relationships among these multi-scale correspondence structures. Finally, the above procedures for correspondence structure learning and multi-scale dependency modeling are implemented in a unified end-to-end deep learning framework. Experimental results on several benchmark datasets demonstrate the effectiveness of the proposed approach.



### Robust Tracking and Behavioral Modeling of Movements of Biological Collectives from Ordinary Video Recordings
- **Arxiv ID**: http://arxiv.org/abs/1707.07310v2
- **DOI**: None
- **Categories**: **cs.MA**, cs.CV, nlin.AO, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1707.07310v2)
- **Published**: 2017-07-23 14:55:21+00:00
- **Updated**: 2017-09-30 13:48:00+00:00
- **Authors**: Hiroki Sayama, Farnaz Zamani Esfahlani, Ali Jazayeri, J. Scott Turner
- **Comment**: 8 pages, 14 figures; to be published in the Proceedings of the IEEE
  SSCI 2017
- **Journal**: None
- **Summary**: We propose a novel computational method to extract information about interactions among individuals with different behavioral states in a biological collective from ordinary video recordings. Assuming that individuals are acting as finite state machines, our method first detects discrete behavioral states of those individuals and then constructs a model of their state transitions, taking into account the positions and states of other individuals in the vicinity. We have tested the proposed method through applications to two real-world biological collectives: termites in an experimental setting and human pedestrians in a university campus. For each application, a robust tracking system was developed in-house, utilizing interactive human intervention (for termite tracking) or online agent-based simulation (for pedestrian tracking). In both cases, significant interactions were detected between nearby individuals with different states, demonstrating the effectiveness of the proposed method.



### A new take on measuring relative nutritional density: The feasibility of using a deep neural network to assess commercially-prepared pureed food concentrations
- **Arxiv ID**: http://arxiv.org/abs/1707.07312v2
- **DOI**: 10.1016/j.jfoodeng.2017.10.016
- **Categories**: **cs.CV**, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1707.07312v2)
- **Published**: 2017-07-23 14:57:23+00:00
- **Updated**: 2017-11-03 14:54:09+00:00
- **Authors**: Kaylen J. Pfisterer, Robert Amelard, Audrey G. Chung, Alexander Wong
- **Comment**: None
- **Journal**: None
- **Summary**: Dysphagia affects 590 million people worldwide and increases risk for malnutrition. Pureed food may reduce choking, however preparation differences impact nutrient density making quality assurance necessary. This paper is the first study to investigate the feasibility of computational pureed food nutritional density analysis using an imaging system. Motivated by a theoretical optical dilution model, a novel deep neural network (DNN) was evaluated using 390 samples from thirteen types of commercially prepared purees at five dilutions. The DNN predicted relative concentration of the puree sample (20%, 40%, 60%, 80%, 100% initial concentration). Data were captured using same-side reflectance of multispectral imaging data at different polarizations at three exposures. Experimental results yielded an average top-1 prediction accuracy of 92.2+/-0.41% with sensitivity and specificity of 83.0+/-15.0% and 95.0+/-4.8%, respectively. This DNN imaging system for nutrient density analysis of pureed food shows promise as a novel tool for nutrient quality assurance.



### Exploiting Deep Features for Remote Sensing Image Retrieval: A Systematic Investigation
- **Arxiv ID**: http://arxiv.org/abs/1707.07321v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07321v3)
- **Published**: 2017-07-23 16:57:56+00:00
- **Updated**: 2019-11-20 20:37:28+00:00
- **Authors**: Xin-Yi Tong, Gui-Song Xia, Fan Hu, Yanfei Zhong, Mihai Datcu, Liangpei Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Remote sensing (RS) image retrieval is of great significant for geological information mining. Over the past two decades, a large amount of research on this task has been carried out, which mainly focuses on the following three core issues: feature extraction, similarity metric and relevance feedback. Due to the complexity and multiformity of ground objects in high-resolution remote sensing (HRRS) images, there is still room for improvement in the current retrieval approaches. In this paper, we analyze the three core issues of RS image retrieval and provide a comprehensive review on existing methods. Furthermore, for the goal to advance the state-of-the-art in HRRS image retrieval, we focus on the feature extraction issue and delve how to use powerful deep representations to address this task. We conduct systematic investigation on evaluating correlative factors that may affect the performance of deep features. By optimizing each factor, we acquire remarkable retrieval results on publicly available HRRS datasets. Finally, we explain the experimental phenomenon in detail and draw conclusions according to our analysis. Our work can serve as a guiding role for the research of content-based RS image retrieval.



### Person Re-identification Using Visual Attention
- **Arxiv ID**: http://arxiv.org/abs/1707.07336v7
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07336v7)
- **Published**: 2017-07-23 19:36:39+00:00
- **Updated**: 2019-04-29 04:15:22+00:00
- **Authors**: Alireza Rahimpour, Liu Liu, Ali Taalimi, Yang Song, Hairong Qi
- **Comment**: Published at IEEE International Conference on Image Processing 2017
- **Journal**: None
- **Summary**: Despite recent attempts for solving the person re-identification problem, it remains a challenging task since a person's appearance can vary significantly when large variations in view angle, human pose, and illumination are involved. In this paper, we propose a novel approach based on using a gradient-based attention mechanism in deep convolution neural network for solving the person re-identification problem. Our model learns to focus selectively on parts of the input image for which the networks' output is most sensitive to and processes them with high resolution while perceiving the surrounding image in low resolution. Extensive comparative evaluations demonstrate that the proposed method outperforms state-of-the-art approaches on the challenging CUHK01, CUHK03, and Market 1501 datasets.



### Compact Model Representation for 3D Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1707.07360v1
- **DOI**: 10.1109/3DV.2017.00020
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.07360v1)
- **Published**: 2017-07-23 22:50:06+00:00
- **Updated**: 2017-07-23 22:50:06+00:00
- **Authors**: Jhony K. Pontes, Chen Kong, Anders Eriksson, Clinton Fookes, Sridha Sridharan, Simon Lucey
- **Comment**: 9 pages, 6 figures
- **Journal**: 2017 International Conference on 3D Vision (3DV)
- **Summary**: 3D reconstruction from 2D images is a central problem in computer vision. Recent works have been focusing on reconstruction directly from a single image. It is well known however that only one image cannot provide enough information for such a reconstruction. A prior knowledge that has been entertained are 3D CAD models due to its online ubiquity. A fundamental question is how to compactly represent millions of CAD models while allowing generalization to new unseen objects with fine-scaled geometry. We introduce an approach to compactly represent a 3D mesh. Our method first selects a 3D model from a graph structure by using a novel free-form deformation FFD 3D-2D registration, and then the selected 3D model is refined to best fit the image silhouette. We perform a comprehensive quantitative and qualitative analysis that demonstrates impressive dense and realistic 3D reconstruction from single images.



