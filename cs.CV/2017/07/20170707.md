# Arxiv Papers in cs.CV on 2017-07-07
### TasselNet: Counting maize tassels in the wild via local counts regression network
- **Arxiv ID**: http://arxiv.org/abs/1707.02290v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1707.02290v1)
- **Published**: 2017-07-07 02:47:06+00:00
- **Updated**: 2017-07-07 02:47:06+00:00
- **Authors**: Hao Lu, Zhiguo Cao, Yang Xiao, Bohan Zhuang, Chunhua Shen
- **Comment**: 14 pages
- **Journal**: None
- **Summary**: Accurately counting maize tassels is important for monitoring the growth status of maize plants. This tedious task, however, is still mainly done by manual efforts. In the context of modern plant phenotyping, automating this task is required to meet the need of large-scale analysis of genotype and phenotype. In recent years, computer vision technologies have experienced a significant breakthrough due to the emergence of large-scale datasets and increased computational resources. Naturally image-based approaches have also received much attention in plant-related studies. Yet a fact is that most image-based systems for plant phenotyping are deployed under controlled laboratory environment. When transferring the application scenario to unconstrained in-field conditions, intrinsic and extrinsic variations in the wild pose great challenges for accurate counting of maize tassels, which goes beyond the ability of conventional image processing techniques. This calls for further robust computer vision approaches to address in-field variations. This paper studies the in-field counting problem of maize tassels. To our knowledge, this is the first time that a plant-related counting problem is considered using computer vision technologies under unconstrained field-based environment.



### Automatic Classification of Bright Retinal Lesions via Deep Network Features
- **Arxiv ID**: http://arxiv.org/abs/1707.02022v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02022v3)
- **Published**: 2017-07-07 02:56:41+00:00
- **Updated**: 2017-07-28 06:32:15+00:00
- **Authors**: Ibrahim Sadek, Mohamed Elawady, Abd El Rahman Shabayek
- **Comment**: Preprint submitted to Journal of Medical Imaging | SPIE (Tue, Jul 28,
  2017)
- **Journal**: None
- **Summary**: The diabetic retinopathy is timely diagonalized through color eye fundus images by experienced ophthalmologists, in order to recognize potential retinal features and identify early-blindness cases. In this paper, it is proposed to extract deep features from the last fully-connected layer of, four different, pre-trained convolutional neural networks. These features are then feeded into a non-linear classifier to discriminate three-class diabetic cases, i.e., normal, exudates, and drusen. Averaged across 1113 color retinal images collected from six publicly available annotated datasets, the deep features approach perform better than the classical bag-of-words approach. The proposed approaches have an average accuracy between 91.23% and 92.00% with more than 13% improvement over the traditional state of art methods.



### Image Segmentation Algorithms Overview
- **Arxiv ID**: http://arxiv.org/abs/1707.02051v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02051v1)
- **Published**: 2017-07-07 06:27:54+00:00
- **Updated**: 2017-07-07 06:27:54+00:00
- **Authors**: Song Yuheng, Yan Hao
- **Comment**: None
- **Journal**: None
- **Summary**: The technology of image segmentation is widely used in medical image processing, face recognition pedestrian detection, etc. The current image segmentation techniques include region-based segmentation, edge detection segmentation, segmentation based on clustering, segmentation based on weakly-supervised learning in CNN, etc. This paper analyzes and summarizes these algorithms of image segmentation, and compares the advantages and disadvantages of different algorithms. Finally, we make a prediction of the development trend of image segmentation with the combination of these algorithms.



### A spatiotemporal model with visual attention for video classification
- **Arxiv ID**: http://arxiv.org/abs/1707.02069v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02069v2)
- **Published**: 2017-07-07 08:12:27+00:00
- **Updated**: 2017-07-24 01:53:20+00:00
- **Authors**: Mo Shan, Nikolay Atanasov
- **Comment**: Accepted by Robotics: Science and Systems 2017 Workshop on
  Articulated Model Tracking
- **Journal**: None
- **Summary**: High level understanding of sequential visual input is important for safe and stable autonomy, especially in localization and object detection. While traditional object classification and tracking approaches are specifically designed to handle variations in rotation and scale, current state-of-the-art approaches based on deep learning achieve better performance. This paper focuses on developing a spatiotemporal model to handle videos containing moving objects with rotation and scale changes. Built on models that combine Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) to classify sequential data, this work investigates the effectiveness of incorporating attention modules in the CNN stage for video classification. The superiority of the proposed spatiotemporal model is demonstrated on the Moving MNIST dataset augmented with rotation and scaling.



### Deep Discrete Hashing with Self-supervised Pairwise Labels
- **Arxiv ID**: http://arxiv.org/abs/1707.02112v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02112v1)
- **Published**: 2017-07-07 10:36:29+00:00
- **Updated**: 2017-07-07 10:36:29+00:00
- **Authors**: Jingkuan Song, Tao He, Hangbo Fan, Lianli Gao
- **Comment**: None
- **Journal**: None
- **Summary**: Hashing methods have been widely used for applications of large-scale image retrieval and classification. Non-deep hashing methods using handcrafted features have been significantly outperformed by deep hashing methods due to their better feature representation and end-to-end learning framework. However, the most striking successes in deep hashing have mostly involved discriminative models, which require labels. In this paper, we propose a novel unsupervised deep hashing method, named Deep Discrete Hashing (DDH), for large-scale image retrieval and classification. In the proposed framework, we address two main problems: 1) how to directly learn discrete binary codes? 2) how to equip the binary representation with the ability of accurate image retrieval and classification in an unsupervised way? We resolve these problems by introducing an intermediate variable and a loss function steering the learning process, which is based on the neighborhood structure in the original space. Experimental results on standard datasets (CIFAR-10, NUS-WIDE, and Oxford-17) demonstrate that our DDH significantly outperforms existing hashing methods by large margin in terms of~mAP for image retrieval and object recognition. Code is available at \url{https://github.com/htconquer/ddh}.



### Sparse Approximation of 3D Meshes using the Spectral Geometry of the Hamiltonian Operator
- **Arxiv ID**: http://arxiv.org/abs/1707.02120v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02120v2)
- **Published**: 2017-07-07 11:24:11+00:00
- **Updated**: 2018-05-12 20:20:59+00:00
- **Authors**: Yoni Choukroun, Gautam Pai, Ron Kimmel
- **Comment**: None
- **Journal**: None
- **Summary**: The discrete Laplace operator is ubiquitous in spectral shape analysis, since its eigenfunctions are provably optimal in representing smooth functions defined on the surface of the shape. Indeed, subspaces defined by its eigenfunctions have been utilized for shape compression, treating the coordinates as smooth functions defined on the given surface. However, surfaces of shapes in nature often contain geometric structures for which the general smoothness assumption may fail to hold. At the other end, some explicit mesh compression algorithms utilize the order by which vertices that represent the surface are traversed, a property which has been ignored in spectral approaches. Here, we incorporate the order of vertices into an operator that defines a novel spectral domain. We propose a method for representing 3D meshes using the spectral geometry of the Hamiltonian operator, integrated within a sparse approximation framework. We adapt the concept of a potential function from quantum physics and incorporate vertex ordering information into the potential, yielding a novel data-dependent operator. The potential function modifies the spectral geometry of the Laplacian to focus on regions with finer details of the given surface. By sparsely encoding the geometry of the shape using the proposed data-dependent basis, we improve compression performance compared to previous results that use the standard Laplacian basis and spectral graph wavelets.



### Mobile Quantification and Therapy Course Tracking for Gait Rehabilitation
- **Arxiv ID**: http://arxiv.org/abs/1707.03275v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1707.03275v1)
- **Published**: 2017-07-07 11:54:40+00:00
- **Updated**: 2017-07-07 11:54:40+00:00
- **Authors**: Javier Conte Alcaraz, Sanam Moghaddamnia, JÃ¼rgen Peissig
- **Comment**: 5 Pages
- **Journal**: None
- **Summary**: This paper presents a novel autonomous quality metric to quantify the rehabilitations progress of subjects with knee/hip operations. The presented method supports digital analysis of human gait patterns using smartphones. The algorithm related to the autonomous metric utilizes calibrated acceleration, gyroscope and magnetometer signals from seven Inertial Measurement Unit attached on the lower body in order to classify and generate the grading system values. The developed Android application connects the seven Inertial Measurement Units via Bluetooth and performs the data acquisition and processing in real-time. In total nine features per acceleration direction and lower body joint angle are calculated and extracted in real-time to achieve a fast feedback to the user. We compare the classification accuracy and quantification capabilities of Linear Discriminant Analysis, Principal Component Analysis and Naive Bayes algorithms. The presented system is able to classify patients and control subjects with an accuracy of up to 100\%. The outcomes can be saved on the device or transmitted to treating physicians for later control of the subject's improvements and the efficiency of physiotherapy treatments in motor rehabilitation. The proposed autonomous quality metric solution bears great potential to be used and deployed to support digital healthcare and therapy.



### SigNet: Convolutional Siamese Network for Writer Independent Offline Signature Verification
- **Arxiv ID**: http://arxiv.org/abs/1707.02131v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02131v2)
- **Published**: 2017-07-07 11:56:51+00:00
- **Updated**: 2017-09-30 17:13:46+00:00
- **Authors**: Sounak Dey, Anjan Dutta, J. Ignacio Toledo, Suman K. Ghosh, Josep Llados, Umapada Pal
- **Comment**: None
- **Journal**: None
- **Summary**: Offline signature verification is one of the most challenging tasks in biometrics and document forensics. Unlike other verification problems, it needs to model minute but critical details between genuine and forged signatures, because a skilled falsification might often resembles the real signature with small deformation. This verification task is even harder in writer independent scenarios which is undeniably fiscal for realistic cases. In this paper, we model an offline writer independent signature verification task with a convolutional Siamese network. Siamese networks are twin networks with shared weights, which can be trained to learn a feature space where similar observations are placed in proximity. This is achieved by exposing the network to a pair of similar and dissimilar observations and minimizing the Euclidean distance between similar pairs while simultaneously maximizing it between dissimilar pairs. Experiments conducted on cross-domain datasets emphasize the capability of our network to model forgery in different languages (scripts) and handwriting styles. Moreover, our designed Siamese network, named SigNet, exceeds the state-of-the-art results on most of the benchmark signature datasets, which paves the way for further research in this direction.



### Design and Processing of Invertible Orientation Scores of 3D Images for Enhancement of Complex Vasculature
- **Arxiv ID**: http://arxiv.org/abs/1707.02191v3
- **DOI**: None
- **Categories**: **cs.CV**, 62H35, 65T60, 58J65, 37L05
- **Links**: [PDF](http://arxiv.org/pdf/1707.02191v3)
- **Published**: 2017-07-07 14:22:26+00:00
- **Updated**: 2017-11-27 07:58:53+00:00
- **Authors**: M. H. J. Janssen, A. J. E. M. Janssen, E. J. Bekkers, J. Olivan Bescos, R. Duits
- **Comment**: None
- **Journal**: None
- **Summary**: The enhancement and detection of elongated structures in noisy image data is relevant for many biomedical imaging applications. To handle complex crossing structures in 2D images, 2D orientation scores $U: \mathbb{R} ^ 2\times S ^ 1 \rightarrow \mathbb{C}$ were introduced, which already showed their use in a variety of applications. Here we extend this work to 3D orientation scores $U: \mathbb{R} ^ 3 \times S ^ 2\rightarrow \mathbb{C}$. First, we construct the orientation score from a given dataset, which is achieved by an invertible coherent state type of transform. For this transformation we introduce 3D versions of the 2D cake-wavelets, which are complex wavelets that can simultaneously detect oriented structures and oriented edges. Here we introduce two types of cake-wavelets, the first uses a discrete Fourier transform, the second is designed in the 3D generalized Zernike basis, allowing us to calculate analytical expressions for the spatial filters. Finally, we show two applications of the orientation score transformation. In the first application we propose an extension of crossing-preserving coherence enhancing diffusion via our invertible orientation scores of 3D images which we apply to real medical image data. In the second one we develop a new tubularity measure using 3D orientation scores and apply the tubularity measure to both artificial and real medical data.



### A multi-layer image representation using Regularized Residual Quantization: application to compression and denoising
- **Arxiv ID**: http://arxiv.org/abs/1707.02194v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02194v1)
- **Published**: 2017-07-07 14:28:21+00:00
- **Updated**: 2017-07-07 14:28:21+00:00
- **Authors**: Sohrab Ferdowsi, Slava Voloshynovskiy, Dimche Kostadinov
- **Comment**: At the International Conference on Image Processing 2017 (ICIP'17),
  Beijing, China
- **Journal**: None
- **Summary**: A learning-based framework for representation of domain-specific images is proposed where joint compression and denoising can be done using a VQ-based multi-layer network. While it learns to compress the images from a training set, the compression performance is very well generalized on images from a test set. Moreover, when fed with noisy versions of the test set, since it has priors from clean images, the network also efficiently denoises the test images during the reconstruction. The proposed framework is a regularized version of the Residual Quantization (RQ) where at each stage, the quantization error from the previous stage is further quantized. Instead of codebook learning from the k-means which over-trains for high-dimensional vectors, we show that only generating the codewords from a random, but properly regularized distribution suffices to compress the images globally and without the need to resort to patch-based division of images. The experiments are done on the \textit{CroppedYale-B} set of facial images and the method is compared with the JPEG-2000 codec for compression and BM3D for denoising, showing promising results.



### The 2017 Hands in the Million Challenge on 3D Hand Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1707.02237v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02237v1)
- **Published**: 2017-07-07 15:46:58+00:00
- **Updated**: 2017-07-07 15:46:58+00:00
- **Authors**: Shanxin Yuan, Qi Ye, Guillermo Garcia-Hernando, Tae-Kyun Kim
- **Comment**: None
- **Journal**: None
- **Summary**: We present the 2017 Hands in the Million Challenge, a public competition designed for the evaluation of the task of 3D hand pose estimation. The goal of this challenge is to assess how far is the state of the art in terms of solving the problem of 3D hand pose estimation as well as detect major failure and strength modes of both systems and evaluation metrics that can help to identify future research directions. The challenge follows up the recent publication of BigHand2.2M and First-Person Hand Action datasets, which have been designed to exhaustively cover multiple hand, viewpoint, hand articulation, and occlusion. The challenge consists of a standardized dataset, an evaluation protocol for two different tasks, and a public competition. In this document we describe the different aspects of the challenge and, jointly with the results of the participants, it will be presented at the 3rd International Workshop on Observing and Understanding Hands in Action, HANDS 2017, with ICCV 2017.



### Generative Adversarial Models for People Attribute Recognition in Surveillance
- **Arxiv ID**: http://arxiv.org/abs/1707.02240v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02240v1)
- **Published**: 2017-07-07 15:51:51+00:00
- **Updated**: 2017-07-07 15:51:51+00:00
- **Authors**: Matteo Fabbri, Simone Calderara, Rita Cucchiara
- **Comment**: Accepted as oral presentation at AVSS 2017
- **Journal**: None
- **Summary**: In this paper we propose a deep architecture for detecting people attributes (e.g. gender, race, clothing ...) in surveillance contexts. Our proposal explicitly deal with poor resolution and occlusion issues that often occur in surveillance footages by enhancing the images by means of Deep Convolutional Generative Adversarial Networks (DCGAN). Experiments show that by combining both our Generative Reconstruction and Deep Attribute Classification Network we can effectively extract attributes even when resolution is poor and in presence of strong occlusions up to 80\% of the whole person figure.



### GPU-Accelerated Algorithms for Compressed Signals Recovery with Application to Astronomical Imagery Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1707.02244v1
- **DOI**: 10.1080/01431161.2017.1356489
- **Categories**: **cs.DC**, astro-ph.IM, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1707.02244v1)
- **Published**: 2017-07-07 15:55:28+00:00
- **Updated**: 2017-07-07 15:55:28+00:00
- **Authors**: Attilio Fiandrotti, Sophie M. Fosson, Chiara Ravazzi, Enrico Magli
- **Comment**: None
- **Journal**: None
- **Summary**: Compressive sensing promises to enable bandwidth-efficient on-board compression of astronomical data by lifting the encoding complexity from the source to the receiver. The signal is recovered off-line, exploiting GPUs parallel computation capabilities to speedup the reconstruction process. However, inherent GPU hardware constraints limit the size of the recoverable signal and the speedup practically achievable. In this work, we design parallel algorithms that exploit the properties of circulant matrices for efficient GPU-accelerated sparse signals recovery. Our approach reduces the memory requirements, allowing us to recover very large signals with limited memory. In addition, it achieves a tenfold signal recovery speedup thanks to ad-hoc parallelization of matrix-vector multiplications and matrix inversions. Finally, we practically demonstrate our algorithms in a typical application of circulant matrices: deblurring a sparse astronomical image in the compressed domain.



### Adaptive Correlation Filters with Long-Term and Short-Term Memory for Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1707.02309v2
- **DOI**: 10.1007/s11263-018-1076-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02309v2)
- **Published**: 2017-07-07 18:00:34+00:00
- **Updated**: 2018-03-23 09:39:10+00:00
- **Authors**: Chao Ma, Jia-Bin Huang, Xiaokang Yang, Ming-Hsuan Yang
- **Comment**: IJCV 2018, Project page:
  https://sites.google.com/site/chaoma99/cf-lstm
- **Journal**: None
- **Summary**: Object tracking is challenging as target objects often undergo drastic appearance changes over time. Recently, adaptive correlation filters have been successfully applied to object tracking. However, tracking algorithms relying on highly adaptive correlation filters are prone to drift due to noisy updates. Moreover, as these algorithms do not maintain long-term memory of target appearance, they cannot recover from tracking failures caused by heavy occlusion or target disappearance in the camera view. In this paper, we propose to learn multiple adaptive correlation filters with both long-term and short-term memory of target appearance for robust object tracking. First, we learn a kernelized correlation filter with an aggressive learning rate for locating target objects precisely. We take into account the appropriate size of surrounding context and the feature representations. Second, we learn a correlation filter over a feature pyramid centered at the estimated target position for predicting scale changes. Third, we learn a complementary correlation filter with a conservative learning rate to maintain long-term memory of target appearance. We use the output responses of this long-term filter to determine if tracking failure occurs. In the case of tracking failures, we apply an incrementally learned detector to recover the target position in a sliding window fashion. Extensive experimental results on large-scale benchmark datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods in terms of efficiency, accuracy, and robustness.



### Learning Efficient Image Representation for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1707.02319v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02319v1)
- **Published**: 2017-07-07 18:05:48+00:00
- **Updated**: 2017-07-07 18:05:48+00:00
- **Authors**: Yang Yang, Shengcai Liao, Zhen Lei, Stan Z. Li
- **Comment**: None
- **Journal**: None
- **Summary**: Color names based image representation is successfully used in person re-identification, due to the advantages of being compact, intuitively understandable as well as being robust to photometric variance. However, there exists the diversity between underlying distribution of color names' RGB values and that of image pixels' RGB values, which may lead to inaccuracy when directly comparing them in Euclidean space. In this paper, we propose a new method named soft Gaussian mapping (SGM) to address this problem. We model the discrepancies between color names and pixels using a Gaussian and utilize the inverse of covariance matrix to bridge the gap between them. Based on SGM, an image could be converted to several soft Gaussian maps. In each soft Gaussian map, we further seek to establish stable and robust descriptors within a local region through a max pooling operation. Then, a robust image representation based on color names is obtained by concatenating the statistical descriptors in each stripe. When labeled data are available, one discriminative subspace projection matrix is learned to build efficient representations of an image via cross-view coupling learning. Experiments on the public datasets - VIPeR, PRID450S and CUHK03, demonstrate the effectiveness of our method.



### Fast Stochastic Hierarchical Bayesian MAP for Tomographic Imaging
- **Arxiv ID**: http://arxiv.org/abs/1707.02336v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.02336v1)
- **Published**: 2017-07-07 18:55:57+00:00
- **Updated**: 2017-07-07 18:55:57+00:00
- **Authors**: John McKay, Raghu G. Raj, Vishal Monga
- **Comment**: 5 Pages, 4 Figures, Conference (Accepted to Asilomar 2017)
- **Journal**: None
- **Summary**: Any image recovery algorithm attempts to achieve the highest quality reconstruction in a timely manner. The former can be achieved in several ways, among which are by incorporating Bayesian priors that exploit natural image tendencies to cue in on relevant phenomena. The Hierarchical Bayesian MAP (HB-MAP) is one such approach which is known to produce compelling results albeit at a substantial computational cost. We look to provide further analysis and insights into what makes the HB-MAP work. While retaining the proficient nature of HB-MAP's Type-I estimation, we propose a stochastic approximation-based approach to Type-II estimation. The resulting algorithm, fast stochastic HB-MAP (fsHBMAP), takes dramatically fewer operations while retaining high reconstruction quality. We employ our fsHBMAP scheme towards the problem of tomographic imaging and demonstrate that fsHBMAP furnishes promising results when compared to many competing methods.



