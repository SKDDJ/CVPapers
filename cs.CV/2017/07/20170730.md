# Arxiv Papers in cs.CV on 2017-07-30
### Virtual PET Images from CT Data Using Deep Convolutional Networks: Initial Results
- **Arxiv ID**: http://arxiv.org/abs/1707.09585v1
- **DOI**: 10.1007/978-3-319-68127-6_6
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1707.09585v1)
- **Published**: 2017-07-30 06:43:42+00:00
- **Updated**: 2017-07-30 06:43:42+00:00
- **Authors**: Avi Ben-Cohen, Eyal Klang, Stephen P. Raskin, Michal Marianne Amitai, Hayit Greenspan
- **Comment**: To be presented at SASHIMI2017: Simulation and Synthesis in Medical
  Imaging, MICCAI 2017
- **Journal**: None
- **Summary**: In this work we present a novel system for PET estimation using CT scans. We explore the use of fully convolutional networks (FCN) and conditional generative adversarial networks (GAN) to export PET data from CT data. Our dataset includes 25 pairs of PET and CT scans where 17 were used for training and 8 for testing. The system was tested for detection of malignant tumors in the liver region. Initial results look promising showing high detection performance with a TPR of 92.3% and FPR of 0.25 per case. Future work entails expansion of the current system to the entire body using a much larger dataset. Such a system can be used for tumor detection and drug treatment evaluation in a CT-only environment instead of the expansive and radioactive PET-CT scan.



### Discover and Learn New Objects from Documentaries
- **Arxiv ID**: http://arxiv.org/abs/1707.09593v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09593v1)
- **Published**: 2017-07-30 07:52:29+00:00
- **Updated**: 2017-07-30 07:52:29+00:00
- **Authors**: Kai Chen, Hang Song, Chen Change Loy, Dahua Lin
- **Comment**: Published on CVPR 2017 (spotlight)
- **Journal**: None
- **Summary**: Despite the remarkable progress in recent years, detecting objects in a new context remains a challenging task. Detectors learned from a public dataset can only work with a fixed list of categories, while training from scratch usually requires a large amount of training data with detailed annotations. This work aims to explore a novel approach -- learning object detectors from documentary films in a weakly supervised manner. This is inspired by the observation that documentaries often provide dedicated exposition of certain object categories, where visual presentations are aligned with subtitles. We believe that object detectors can be learned from such a rich source of information. Towards this goal, we develop a joint probabilistic framework, where individual pieces of information, including video frames and subtitles, are brought together via both visual and linguistic links. On top of this formulation, we further derive a weakly supervised learning algorithm, where object model learning and training set mining are unified in an optimization procedure. Experimental results on a real world dataset demonstrate that this is an effective approach to learning new object detectors.



### ScanNet: A Fast and Dense Scanning Framework for Metastatic Breast Cancer Detection from Whole-Slide Images
- **Arxiv ID**: http://arxiv.org/abs/1707.09597v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09597v1)
- **Published**: 2017-07-30 08:51:32+00:00
- **Updated**: 2017-07-30 08:51:32+00:00
- **Authors**: Huangjing Lin, Hao Chen, Qi Dou, Liansheng Wang, Jing Qin, Pheng-Ann Heng
- **Comment**: None
- **Journal**: None
- **Summary**: Lymph node metastasis is one of the most significant diagnostic indicators in breast cancer, which is traditionally observed under the microscope by pathologists. In recent years, computerized histology diagnosis has become one of the most rapidly expanding fields in medical image computing, which alleviates pathologists' workload and reduces misdiagnosis rate. However, automatic detection of lymph node metastases from whole slide images remains a challenging problem, due to the large-scale data with enormous resolutions and existence of hard mimics. In this paper, we propose a novel framework by leveraging fully convolutional networks for efficient inference to meet the speed requirement for clinical practice, while reconstructing dense predictions under different offsets for ensuring accurate detection on both micro- and macro-metastases. Incorporating with the strategies of asynchronous sample prefetching and hard negative mining, the network can be effectively trained. Extensive experiments on the benchmark dataset of 2016 Camelyon Grand Challenge corroborated the efficacy of our method. Compared with the state-of-the-art methods, our method achieved superior performance with a faster speed on the tumor localization task and surpassed human performance on the WSI classification task.



### Occlusion Handling using Semantic Segmentation and Visibility-Based Rendering for Mixed Reality
- **Arxiv ID**: http://arxiv.org/abs/1707.09603v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09603v1)
- **Published**: 2017-07-30 10:01:57+00:00
- **Updated**: 2017-07-30 10:01:57+00:00
- **Authors**: Menandro Roxas, Tomoki Hori, Taiki Fukiage, Yasuhide Okamoto, Takeshi Oishi
- **Comment**: None
- **Journal**: None
- **Summary**: Real-time occlusion handling is a major problem in outdoor mixed reality system because it requires great computational cost mainly due to the complexity of the scene. Using only segmentation, it is difficult to accurately render a virtual object occluded by complex objects such as trees, bushes etc. In this paper, we propose a novel occlusion handling method for real-time, outdoor, and omni-directional mixed reality system using only the information from a monocular image sequence. We first present a semantic segmentation scheme for predicting the amount of visibility for different type of objects in the scene. We also simultaneously calculate a foreground probability map using depth estimation derived from optical flow. Finally, we combine the segmentation result and the probability map to render the computer generated object and the real scene using a visibility-based rendering method. Our results show great improvement in handling occlusions compared to existing blending based methods.



### CNN-based Cascaded Multi-task Learning of High-level Prior and Density Estimation for Crowd Counting
- **Arxiv ID**: http://arxiv.org/abs/1707.09605v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09605v2)
- **Published**: 2017-07-30 10:24:08+00:00
- **Updated**: 2017-08-16 06:32:00+00:00
- **Authors**: Vishwanath A. Sindagi, Vishal M. Patel
- **Comment**: Accepted at AVSS 2017 (14th International Conference on Advanced
  Video and Signal Based Surveillance)
- **Journal**: None
- **Summary**: Estimating crowd count in densely crowded scenes is an extremely challenging task due to non-uniform scale variations. In this paper, we propose a novel end-to-end cascaded network of CNNs to jointly learn crowd count classification and density map estimation. Classifying crowd count into various groups is tantamount to coarsely estimating the total count in the image thereby incorporating a high-level prior into the density estimation network. This enables the layers in the network to learn globally relevant discriminative features which aid in estimating highly refined density maps with lower count error. The joint training is performed in an end-to-end fashion. Extensive experiments on highly challenging publicly available datasets show that the proposed method achieves lower count error and better quality density maps as compared to the recent state-of-the-art methods.



### LEARN: Learned Experts' Assessment-based Reconstruction Network for Sparse-data CT
- **Arxiv ID**: http://arxiv.org/abs/1707.09636v3
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1707.09636v3)
- **Published**: 2017-07-30 15:53:08+00:00
- **Updated**: 2018-02-10 06:33:27+00:00
- **Authors**: Hu Chen, Yi Zhang, Yunjin Chen, Junfeng Zhang, Weihua Zhang, Huaiqiaing Sun, Yang Lv, Peixi Liao, Jiliu Zhou, Ge Wang
- **Comment**: 18 pages, 15 figures, accepted by IEEE TMI
- **Journal**: None
- **Summary**: Compressive sensing (CS) has proved effective for tomographic reconstruction from sparsely collected data or under-sampled measurements, which are practically important for few-view CT, tomosynthesis, interior tomography, and so on. To perform sparse-data CT, the iterative reconstruction commonly use regularizers in the CS framework. Currently, how to choose the parameters adaptively for regularization is a major open problem. In this paper, inspired by the idea of machine learning especially deep learning, we unfold a state-of-the-art "fields of experts" based iterative reconstruction scheme up to a number of iterations for data-driven training, construct a Learned Experts' Assessment-based Reconstruction Network ("LEARN") for sparse-data CT, and demonstrate the feasibility and merits of our LEARN network. The experimental results with our proposed LEARN network produces a competitive performance with the well-known Mayo Clinic Low-Dose Challenge Dataset relative to several state-of-the-art methods, in terms of artifact reduction, feature preservation, and computational speed. This is consistent to our insight that because all the regularization terms and parameters used in the iterative reconstruction are now learned from the training data, our LEARN network utilizes application-oriented knowledge more effectively and recovers underlying images more favorably than competing algorithms. Also, the number of layers in the LEARN network is only 12, reducing the computational complexity of typical iterative algorithms by orders of magnitude.



### A Novel Approach for Image Segmentation based on Histograms computed from Hue-data
- **Arxiv ID**: http://arxiv.org/abs/1707.09643v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09643v1)
- **Published**: 2017-07-30 17:23:56+00:00
- **Updated**: 2017-07-30 17:23:56+00:00
- **Authors**: Viraj Mavani, Ayesha Gurnani, Jhanvi Shah
- **Comment**: 4 pages
- **Journal**: International Journal for Scientific Research and Development
  [Conference 10 : NCACSET 2017] (2017): pg. 176-179
- **Summary**: Computer Vision is growing day by day in terms of user specific applications. The first step of any such application is segmenting an image. In this paper, we propose a novel and grass-root level image segmentation algorithm for cases in which the background has uniform color distribution. This algorithm can be used for images of flowers, birds, insects and many more where such background conditions occur. By image segmentation, the visualization of a computer increases manifolds and it can even attain near-human accuracy during classification.



### Scalable and Effective Deep CCA via Soft Decorrelation
- **Arxiv ID**: http://arxiv.org/abs/1707.09669v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.09669v2)
- **Published**: 2017-07-30 20:53:54+00:00
- **Updated**: 2018-03-24 14:58:58+00:00
- **Authors**: Xiaobin Chang, Tao Xiang, Timothy M. Hospedales
- **Comment**: To Appear at CVPR2018
- **Journal**: None
- **Summary**: Recently the widely used multi-view learning model, Canonical Correlation Analysis (CCA) has been generalised to the non-linear setting via deep neural networks. Existing deep CCA models typically first decorrelate the feature dimensions of each view before the different views are maximally correlated in a common latent space. This feature decorrelation is achieved by enforcing an exact decorrelation constraint; these models are thus computationally expensive due to the matrix inversion or SVD operations required for exact decorrelation at each training iteration. Furthermore, the decorrelation step is often separated from the gradient descent based optimisation, resulting in sub-optimal solutions. We propose a novel deep CCA model Soft CCA to overcome these problems. Specifically, exact decorrelation is replaced by soft decorrelation via a mini-batch based Stochastic Decorrelation Loss (SDL) to be optimised jointly with the other training objectives. Extensive experiments show that the proposed soft CCA is more effective and efficient than existing deep CCA models. In addition, our SDL loss can be applied to other deep models beyond multi-view learning, and obtains superior performance compared to existing decorrelation losses.



