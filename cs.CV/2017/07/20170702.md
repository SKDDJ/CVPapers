# Arxiv Papers in cs.CV on 2017-07-02
### Modulating early visual processing by language
- **Arxiv ID**: http://arxiv.org/abs/1707.00683v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1707.00683v3)
- **Published**: 2017-07-02 04:06:01+00:00
- **Updated**: 2017-12-18 20:04:53+00:00
- **Authors**: Harm de Vries, Florian Strub, Jérémie Mary, Hugo Larochelle, Olivier Pietquin, Aaron Courville
- **Comment**: Advances in Neural Information Processing Systems 30 (NIPS 2017)
- **Journal**: None
- **Summary**: It is commonly assumed that language refers to high-level visual concepts while leaving low-level visual processing unaffected. This view dominates the current literature in computational models for language-vision tasks, where visual and linguistic input are mostly processed independently before being fused into a single representation. In this paper, we deviate from this classic pipeline and propose to modulate the \emph{entire visual processing} by linguistic input. Specifically, we condition the batch normalization parameters of a pretrained residual network (ResNet) on a language embedding. This approach, which we call MOdulated RESnet (\MRN), significantly improves strong baselines on two visual question answering tasks. Our ablation study shows that modulating from the early stages of the visual processing is beneficial.



### Deep-learning-based data page classification for holographic memory
- **Arxiv ID**: http://arxiv.org/abs/1707.00684v1
- **DOI**: 10.1364/ao.56.007327
- **Categories**: **cs.CV**, cs.LG, cs.NE, physics.optics
- **Links**: [PDF](http://arxiv.org/pdf/1707.00684v1)
- **Published**: 2017-07-02 05:47:37+00:00
- **Updated**: 2017-07-02 05:47:37+00:00
- **Authors**: Tomoyoshi Shimobaba, Naoki Kuwata, Mizuha Homma, Takayuki Takahashi, Yuki Nagahama, Marie Sano, Satoki Hasegawa, Ryuji Hirayama, Takashi Kakue, Atsushi Shiraki, Naoki Takada, Tomoyoshi Ito
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a deep-learning-based classification of data pages used in holographic memory. We numerically investigated the classification performance of a conventional multi-layer perceptron (MLP) and a deep neural network, under the condition that reconstructed page data are contaminated by some noise and are randomly laterally shifted. The MLP was found to have a classification accuracy of 91.58%, whereas the deep neural network was able to classify data pages at an accuracy of 99.98%. The accuracy of the deep neural network is two orders of magnitude better than the MLP.



### Deep GrabCut for Object Selection
- **Arxiv ID**: http://arxiv.org/abs/1707.00243v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.00243v2)
- **Published**: 2017-07-02 05:53:49+00:00
- **Updated**: 2017-07-14 18:52:26+00:00
- **Authors**: Ning Xu, Brian Price, Scott Cohen, Jimei Yang, Thomas Huang
- **Comment**: BMVC 2017
- **Journal**: None
- **Summary**: Most previous bounding-box-based segmentation methods assume the bounding box tightly covers the object of interest. However it is common that a rectangle input could be too large or too small. In this paper, we propose a novel segmentation approach that uses a rectangle as a soft constraint by transforming it into an Euclidean distance map. A convolutional encoder-decoder network is trained end-to-end by concatenating images with these distance maps as inputs and predicting the object masks as outputs. Our approach gets accurate segmentation results given sloppy rectangles while being general for both interactive segmentation and instance segmentation. We show our network extends to curve-based input without retraining. We further apply our network to instance-level semantic segmentation and resolve any overlap using a conditional random field. Experiments on benchmark datasets demonstrate the effectiveness of the proposed approaches.



### Where to Play: Retrieval of Video Segments using Natural-Language Queries
- **Arxiv ID**: http://arxiv.org/abs/1707.00251v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.00251v1)
- **Published**: 2017-07-02 07:56:06+00:00
- **Updated**: 2017-07-02 07:56:06+00:00
- **Authors**: Sangkuk Lee, Daesik Kim, Myunggi Lee, Jihye Hwang, Nojun Kwak
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new approach for retrieval of video segments using natural language queries. Unlike most previous approaches such as concept-based methods or rule-based structured models, the proposed method uses image captioning model to construct sentential queries for visual information. In detail, our approach exploits multiple captions generated by visual features in each image with `Densecap'. Then, the similarities between captions of adjacent images are calculated, which is used to track semantically similar captions over multiple frames. Besides introducing this novel idea of 'tracking by captioning', the proposed method is one of the first approaches that uses a language generation model learned by neural networks to construct semantic query describing the relations and properties of visual information. To evaluate the effectiveness of our approach, we have created a new evaluation dataset, which contains about 348 segments of scenes in 20 movie-trailers. Through quantitative and qualitative evaluation, we show that our method is effective for retrieval of video segments using natural language queries.



### A Batch-Incremental Video Background Estimation Model using Weighted Low-Rank Approximation of Matrices
- **Arxiv ID**: http://arxiv.org/abs/1707.00281v1
- **DOI**: None
- **Categories**: **cs.CV**, math.NA, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1707.00281v1)
- **Published**: 2017-07-02 11:55:09+00:00
- **Updated**: 2017-07-02 11:55:09+00:00
- **Authors**: Aritra Dutta, Xin Li, Peter Richtárik
- **Comment**: None
- **Journal**: None
- **Summary**: Principal component pursuit (PCP) is a state-of-the-art approach for background estimation problems. Due to their higher computational cost, PCP algorithms, such as robust principal component analysis (RPCA) and its variants, are not feasible in processing high definition videos. To avoid the curse of dimensionality in those algorithms, several methods have been proposed to solve the background estimation problem in an incremental manner. We propose a batch-incremental background estimation model using a special weighted low-rank approximation of matrices. Through experiments with real and synthetic video sequences, we demonstrate that our method is superior to the state-of-the-art background estimation algorithms such as GRASTA, ReProCS, incPCP, and GFL.



### Automatic Trimap Generation for Image Matting
- **Arxiv ID**: http://arxiv.org/abs/1707.00333v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1707.00333v2)
- **Published**: 2017-07-02 18:37:53+00:00
- **Updated**: 2017-07-04 06:44:18+00:00
- **Authors**: Vikas Gupta, Shanmuganathan Raman
- **Comment**: None
- **Journal**: None
- **Summary**: Image matting is a longstanding problem in computational photography. Although, it has been studied for more than two decades, yet there is a challenge of developing an automatic matting algorithm which does not require any human efforts. Most of the state-of-the-art matting algorithms require human intervention in the form of trimap or scribbles to generate the alpha matte form the input image. In this paper, we present a simple and efficient approach to automatically generate the trimap from the input image and make the whole matting process free from human-in-the-loop. We use learning based matting method to generate the matte from the automatically generated trimap. Experimental results demonstrate that our method produces good quality trimap which results into accurate matte estimation. We validate our results by replacing the automatically generated trimap by manually created trimap while using the same image matting algorithm.



