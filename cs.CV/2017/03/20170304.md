# Arxiv Papers in cs.CV on 2017-03-04
### Multi-Scale Wavelet Domain Residual Learning for Limited-Angle CT Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1703.01382v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01382v1)
- **Published**: 2017-03-04 02:22:59+00:00
- **Updated**: 2017-03-04 02:22:59+00:00
- **Authors**: Jawook Gu, Jong Chul Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Limited-angle computed tomography (CT) is often used in clinical applications such as C-arm CT for interventional imaging. However, CT images from limited angles suffers from heavy artifacts due to incomplete projection data. Existing iterative methods require extensive calculations but can not deliver satisfactory results. Based on the observation that the artifacts from limited angles have some directional property and are globally distributed, we propose a novel multi-scale wavelet domain residual learning architecture, which compensates for the artifacts. Experiments have shown that the proposed method effectively eliminates artifacts, thereby preserving edge and global structures of the image.



### Wavelet Domain Residual Network (WavResNet) for Low-Dose X-ray CT Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1703.01383v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01383v1)
- **Published**: 2017-03-04 02:28:54+00:00
- **Updated**: 2017-03-04 02:28:54+00:00
- **Authors**: Eunhee Kang, junhong Min, Jong Chul Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Model based iterative reconstruction (MBIR) algorithms for low-dose X-ray CT are computationally complex because of the repeated use of the forward and backward projection. Inspired by this success of deep learning in computer vision applications, we recently proposed a deep convolutional neural network (CNN) for low-dose X-ray CT and won the second place in 2016 AAPM Low-Dose CT Grand Challenge. However, some of the texture are not fully recovered, which was unfamiliar to some radiologists. To cope with this problem, here we propose a direct residual learning approach on directional wavelet domain to solve this problem and to improve the performance against previous work. In particular, the new network estimates the noise of each input wavelet transform, and then the de-noised wavelet coefficients are obtained by subtracting the noise from the input wavelet transform bands. The experimental results confirm that the proposed network has significantly improved performance, preserving the detail texture of the original images.



### Looking at Outfit to Parse Clothing
- **Arxiv ID**: http://arxiv.org/abs/1703.01386v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01386v1)
- **Published**: 2017-03-04 03:09:36+00:00
- **Updated**: 2017-03-04 03:09:36+00:00
- **Authors**: Pongsate Tangseng, Zhipeng Wu, Kota Yamaguchi
- **Comment**: None
- **Journal**: None
- **Summary**: This paper extends fully-convolutional neural networks (FCN) for the clothing parsing problem. Clothing parsing requires higher-level knowledge on clothing semantics and contextual cues to disambiguate fine-grained categories. We extend FCN architecture with a side-branch network which we refer outfit encoder to predict a consistent set of clothing labels to encourage combinatorial preference, and with conditional random field (CRF) to explicitly consider coherent label assignment to the given image. The empirical results using Fashionista and CFPD datasets show that our model achieves state-of-the-art performance in clothing parsing, without additional supervision during training. We also study the qualitative influence of annotation on the current clothing parsing benchmarks, with our Web-based tool for multi-scale pixel-wise annotation and manual refinement effort to the Fashionista dataset. Finally, we show that the image representation of the outfit encoder is useful for dress-up image retrieval application.



### Stacking-based Deep Neural Network: Deep Analytic Network on Convolutional Spectral Histogram Features
- **Arxiv ID**: http://arxiv.org/abs/1703.01396v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01396v2)
- **Published**: 2017-03-04 04:31:43+00:00
- **Updated**: 2017-05-21 15:19:50+00:00
- **Authors**: Cheng-Yaw Low, Andrew Beng-Jin Teoh
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Stacking-based deep neural network (S-DNN), in general, denotes a deep neural network (DNN) resemblance in terms of its very deep, feedforward network architecture. The typical S-DNN aggregates a variable number of individually learnable modules in series to assemble a DNN-alike alternative to the targeted object recognition tasks. This work likewise devises an S-DNN instantiation, dubbed deep analytic network (DAN), on top of the spectral histogram (SH) features. The DAN learning principle relies on ridge regression, and some key DNN constituents, specifically, rectified linear unit, fine-tuning, and normalization. The DAN aptitude is scrutinized on three repositories of varying domains, including FERET (faces), MNIST (handwritten digits), and CIFAR10 (natural objects). The empirical results unveil that DAN escalates the SH baseline performance over a sufficiently deep layer.



### Sparse Depth Sensing for Resource-Constrained Robots
- **Arxiv ID**: http://arxiv.org/abs/1703.01398v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1703.01398v3)
- **Published**: 2017-03-04 05:20:30+00:00
- **Updated**: 2017-10-15 05:02:51+00:00
- **Authors**: Fangchang Ma, Luca Carlone, Ulas Ayaz, Sertac Karaman
- **Comment**: 35 pages, 31 figures, 2 tables; added new results
- **Journal**: None
- **Summary**: We consider the case in which a robot has to navigate in an unknown environment but does not have enough on-board power or payload to carry a traditional depth sensor (e.g., a 3D lidar) and thus can only acquire a few (point-wise) depth measurements. We address the following question: is it possible to reconstruct the geometry of an unknown environment using sparse and incomplete depth measurements? Reconstruction from incomplete data is not possible in general, but when the robot operates in man-made environments, the depth exhibits some regularity (e.g., many planar surfaces with only a few edges); we leverage this regularity to infer depth from a small number of measurements. Our first contribution is a formulation of the depth reconstruction problem that bridges robot perception with the compressive sensing literature in signal processing. The second contribution includes a set of formal results that ascertain the exactness and stability of the depth reconstruction in 2D and 3D problems, and completely characterize the geometry of the profiles that we can reconstruct. Our third contribution is a set of practical algorithms for depth reconstruction: our formulation directly translates into algorithms for depth estimation based on convex programming. In real-world problems, these convex programs are very large and general-purpose solvers are relatively slow. For this reason, we discuss ad-hoc solvers that enable fast depth reconstruction in real problems. The last contribution is an extensive experimental evaluation in 2D and 3D problems, including Monte Carlo runs on simulated instances and testing on multiple real datasets. Empirical results confirm that the proposed approach ensures accurate depth reconstruction, outperforms interpolation-based strategies, and performs well even when the assumption of structured environment is violated.



### Skin Lesion Classification Using Deep Multi-scale Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1703.01402v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01402v1)
- **Published**: 2017-03-04 06:32:15+00:00
- **Updated**: 2017-03-04 06:32:15+00:00
- **Authors**: Terrance DeVries, Dhanesh Ramachandram
- **Comment**: None
- **Journal**: None
- **Summary**: We present a deep learning approach to the ISIC 2017 Skin Lesion Classification Challenge using a multi-scale convolutional neural network. Our approach utilizes an Inception-v3 network pre-trained on the ImageNet dataset, which is fine-tuned for skin lesion classification using two different scales of input images.



### Deep Matching Prior Network: Toward Tighter Multi-oriented Text Detection
- **Arxiv ID**: http://arxiv.org/abs/1703.01425v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01425v1)
- **Published**: 2017-03-04 09:40:41+00:00
- **Updated**: 2017-03-04 09:40:41+00:00
- **Authors**: Yuliang Liu, Lianwen Jin
- **Comment**: 8 Pages, 7 figures. Accepted to appear in CVPR 2017
- **Journal**: None
- **Summary**: Detecting incidental scene text is a challenging task because of multi-orientation, perspective distortion, and variation of text size, color and scale. Retrospective research has only focused on using rectangular bounding box or horizontal sliding window to localize text, which may result in redundant background noise, unnecessary overlap or even information loss. To address these issues, we propose a new Convolutional Neural Networks (CNNs) based method, named Deep Matching Prior Network (DMPNet), to detect text with tighter quadrangle. First, we use quadrilateral sliding windows in several specific intermediate convolutional layers to roughly recall the text with higher overlapping area and then a shared Monte-Carlo method is proposed for fast and accurate computing of the polygonal areas. After that, we designed a sequential protocol for relative regression which can exactly predict text with compact quadrangle. Moreover, a auxiliary smooth Ln loss is also proposed for further regressing the position of text, which has better overall performance than L2 loss and smooth L1 loss in terms of robustness and stability. The effectiveness of our approach is evaluated on a public word-level, multi-oriented scene text database, ICDAR 2015 Robust Reading Competition Challenge 4 "Incidental scene text localization". The performance of our method is evaluated by using F-measure and found to be 70.64%, outperforming the existing state-of-the-art method with F-measure 63.76%.



### Automated Top View Registration of Broadcast Football Videos
- **Arxiv ID**: http://arxiv.org/abs/1703.01437v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01437v1)
- **Published**: 2017-03-04 10:51:09+00:00
- **Updated**: 2017-03-04 10:51:09+00:00
- **Authors**: Rahul Anand Sharma, Bharath Bhat, Vineet Gandhi, C. V. Jawahar
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel method to register football broadcast video frames on the static top view model of the playing surface. The proposed method is fully automatic in contrast to the current state of the art which requires manual initialization of point correspondences between the image and the static model. Automatic registration using existing approaches has been difficult due to the lack of sufficient point correspondences. We investigate an alternate approach exploiting the edge information from the line markings on the field. We formulate the registration problem as a nearest neighbour search over a synthetically generated dictionary of edge map and homography pairs. The synthetic dictionary generation allows us to exhaustively cover a wide variety of camera angles and positions and reduce this problem to a minimal per-frame edge map matching procedure. We show that the per-frame results can be improved in videos using an optimization framework for temporal camera stabilization. We demonstrate the efficacy of our approach by presenting extensive results on a dataset collected from matches of football World Cup 2014.



### Generative Compression
- **Arxiv ID**: http://arxiv.org/abs/1703.01467v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01467v2)
- **Published**: 2017-03-04 14:43:26+00:00
- **Updated**: 2017-06-04 23:31:42+00:00
- **Authors**: Shibani Santurkar, David Budden, Nir Shavit
- **Comment**: None
- **Journal**: None
- **Summary**: Traditional image and video compression algorithms rely on hand-crafted encoder/decoder pairs (codecs) that lack adaptability and are agnostic to the data being compressed. Here we describe the concept of generative compression, the compression of data using generative models, and suggest that it is a direction worth pursuing to produce more accurate and visually pleasing reconstructions at much deeper compression levels for both image and video data. We also demonstrate that generative compression is orders-of-magnitude more resilient to bit error rates (e.g. from noisy wireless channels) than traditional variable-length coding schemes.



### A Machine-Learning Framework for Design for Manufacturability
- **Arxiv ID**: http://arxiv.org/abs/1703.01499v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1703.01499v2)
- **Published**: 2017-03-04 17:37:32+00:00
- **Updated**: 2017-03-15 14:55:52+00:00
- **Authors**: Aditya Balu, Sambit Ghadai, Gavin Young, Soumik Sarkar, Adarsh Krishnamurthy
- **Comment**: this is a duplicate submission. Hence want to withdraw it
- **Journal**: None
- **Summary**: this is a duplicate submission(original is arXiv:1612.02141). Hence want to withdraw it



### Accelerating Permutation Testing in Voxel-wise Analysis through Subspace Tracking: A new plugin for SnPM
- **Arxiv ID**: http://arxiv.org/abs/1703.01506v2
- **DOI**: 10.1016/j.neuroimage.2017.07.025
- **Categories**: **stat.AP**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1703.01506v2)
- **Published**: 2017-03-04 19:07:42+00:00
- **Updated**: 2017-07-24 18:03:54+00:00
- **Authors**: Felipe Gutierrez-Barragan, Vamsi K. Ithapu, Chris Hinrichs, Camille Maumet, Sterling C. Johnson, Thomas E. Nichols, Vikas Singh, the ADNI
- **Comment**: 36 pages, 16 figures
- **Journal**: None
- **Summary**: Permutation testing is a non-parametric method for obtaining the max null distribution used to compute corrected $p$-values that provide strong control of false positives. In neuroimaging, however, the computational burden of running such an algorithm can be significant. We find that by viewing the permutation testing procedure as the construction of a very large permutation testing matrix, $T$, one can exploit structural properties derived from the data and the test statistics to reduce the runtime under certain conditions. In particular, we see that $T$ is low-rank plus a low-variance residual. This makes $T$ a good candidate for low-rank matrix completion, where only a very small number of entries of $T$ ($\sim0.35\%$ of all entries in our experiments) have to be computed to obtain a good estimate. Based on this observation, we present RapidPT, an algorithm that efficiently recovers the max null distribution commonly obtained through regular permutation testing in voxel-wise analysis. We present an extensive validation on a synthetic dataset and four varying sized datasets against two baselines: Statistical NonParametric Mapping (SnPM13) and a standard permutation testing implementation (referred as NaivePT). We find that RapidPT achieves its best runtime performance on medium sized datasets ($50 \leq n \leq 200$), with speedups of 1.5x - 38x (vs. SnPM13) and 20x-1000x (vs. NaivePT). For larger datasets ($n \geq 200$) RapidPT outperforms NaivePT (6x - 200x) on all datasets, and provides large speedups over SnPM13 when more than 10000 permutations (2x - 15x) are needed. The implementation is a standalone toolbox and also integrated within SnPM13, able to leverage multi-core architectures when available.



### Genetic CNN
- **Arxiv ID**: http://arxiv.org/abs/1703.01513v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01513v1)
- **Published**: 2017-03-04 19:44:16+00:00
- **Updated**: 2017-03-04 19:44:16+00:00
- **Authors**: Lingxi Xie, Alan Yuille
- **Comment**: Submitted to CVPR 2017 (10 pages, 5 figures)
- **Journal**: None
- **Summary**: The deep Convolutional Neural Network (CNN) is the state-of-the-art solution for large-scale visual recognition. Following basic principles such as increasing the depth and constructing highway connections, researchers have manually designed a lot of fixed network structures and verified their effectiveness.   In this paper, we discuss the possibility of learning deep network structures automatically. Note that the number of possible network structures increases exponentially with the number of layers in the network, which inspires us to adopt the genetic algorithm to efficiently traverse this large search space. We first propose an encoding method to represent each network structure in a fixed-length binary string, and initialize the genetic algorithm by generating a set of randomized individuals. In each generation, we define standard genetic operations, e.g., selection, mutation and crossover, to eliminate weak individuals and then generate more competitive ones. The competitiveness of each individual is defined as its recognition accuracy, which is obtained via training the network from scratch and evaluating it on a validation set. We run the genetic process on two small datasets, i.e., MNIST and CIFAR10, demonstrating its ability to evolve and find high-quality structures which are little studied before. These structures are also transferrable to the large-scale ILSVRC2012 dataset.



### CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos
- **Arxiv ID**: http://arxiv.org/abs/1703.01515v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.01515v2)
- **Published**: 2017-03-04 20:00:44+00:00
- **Updated**: 2017-06-13 04:14:57+00:00
- **Authors**: Zheng Shou, Jonathan Chan, Alireza Zareian, Kazuyuki Miyazawa, Shih-Fu Chang
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2017
- **Journal**: None
- **Summary**: Temporal action localization is an important yet challenging problem. Given a long, untrimmed video consisting of multiple action instances and complex background contents, we need not only to recognize their action categories, but also to localize the start time and end time of each instance. Many state-of-the-art systems use segment-level classifiers to select and rank proposal segments of pre-determined boundaries. However, a desirable model should move beyond segment-level and make dense predictions at a fine granularity in time to determine precise temporal boundaries. To this end, we design a novel Convolutional-De-Convolutional (CDC) network that places CDC filters on top of 3D ConvNets, which have been shown to be effective for abstracting action semantics but reduce the temporal length of the input data. The proposed CDC filter performs the required temporal upsampling and spatial downsampling operations simultaneously to predict actions at the frame-level granularity. It is unique in jointly modeling action semantics in space-time and fine-grained temporal dynamics. We train the CDC network in an end-to-end manner efficiently. Our model not only achieves superior performance in detecting actions in every frame, but also significantly boosts the precision of localizing temporal boundaries. Finally, the CDC network demonstrates a very high efficiency with the ability to process 500 frames per second on a single GPU server. We will update the camera-ready version and publish the source codes online soon.



### High Accuracy Classification of Parkinson's Disease through Shape Analysis and Surface Fitting in $^{123}$I-Ioflupane SPECT Imaging
- **Arxiv ID**: http://arxiv.org/abs/1703.01526v1
- **DOI**: 10.1109/JBHI.2016.2547901
- **Categories**: **stat.AP**, cs.CV, physics.data-an, stat.CO, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1703.01526v1)
- **Published**: 2017-03-04 21:50:25+00:00
- **Updated**: 2017-03-04 21:50:25+00:00
- **Authors**: R. Prashanth, Sumantra Dutta Roy, Pravat K. Mandal, Shantanu Ghosh
- **Comment**: 9 pages, 5 figures, Accepted in the IEEE Journal of Biomedical and
  Health Informatics, Additional supplementary documents available at
  http://ieeexplore.ieee.org/document/7442754/
- **Journal**: None
- **Summary**: Early and accurate identification of parkinsonian syndromes (PS) involving presynaptic degeneration from non-degenerative variants such as Scans Without Evidence of Dopaminergic Deficit (SWEDD) and tremor disorders, is important for effective patient management as the course, therapy and prognosis differ substantially between the two groups. In this study, we use Single Photon Emission Computed Tomography (SPECT) images from healthy normal, early PD and SWEDD subjects, as obtained from the Parkinson's Progression Markers Initiative (PPMI) database, and process them to compute shape- and surface fitting-based features for the three groups. We use these features to develop and compare various classification models that can discriminate between scans showing dopaminergic deficit, as in PD, from scans without the deficit, as in healthy normal or SWEDD. Along with it, we also compare these features with Striatal Binding Ratio (SBR)-based features, which are well-established and clinically used, by computing a feature importance score using Random forests technique. We observe that the Support Vector Machine (SVM) classifier gave the best performance with an accuracy of 97.29%. These features also showed higher importance than the SBR-based features. We infer from the study that shape analysis and surface fitting are useful and promising methods for extracting discriminatory features that can be used to develop diagnostic models that might have the potential to help clinicians in the diagnostic process.



