# Arxiv Papers in cs.CV on 2017-03-11
### Segmentation of skin lesions based on fuzzy classification of pixels and histogram thresholding
- **Arxiv ID**: http://arxiv.org/abs/1703.03888v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1703.03888v1)
- **Published**: 2017-03-11 01:18:14+00:00
- **Updated**: 2017-03-11 01:18:14+00:00
- **Authors**: Jose Luis Garcia-Arroyo, Begonya Garcia-Zapirain
- **Comment**: 5 pages, 6 figures
- **Journal**: None
- **Summary**: This paper proposes an innovative method for segmentation of skin lesions in dermoscopy images developed by the authors, based on fuzzy classification of pixels and histogram thresholding.



### Gait Pattern Recognition Using Accelerometers
- **Arxiv ID**: http://arxiv.org/abs/1703.03921v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1703.03921v1)
- **Published**: 2017-03-11 07:32:01+00:00
- **Updated**: 2017-03-11 07:32:01+00:00
- **Authors**: Vahid Alizadeh
- **Comment**: 6 pages, project report
- **Journal**: None
- **Summary**: Motion ability is one of the most important human properties, including gait as a basis of human transitional movement. Gait, as a biometric for recognizing human identities, can be non-intrusively captured signals using wearable or portable smart devices. In this study gait patterns is collected using a wireless platform of two sensors located at chest and right ankle of the subjects. Then the raw data has undergone some preprocessing methods and segmented into 5 seconds windows. Some time and frequency domain features is extracted and the performance evaluated by 5 different classifiers. Decision Tree (with all features) and K-Nearest Neighbors (with 10 selected features) classifiers reached 99.4% and 100% respectively.



### Viraliency: Pooling Local Virality
- **Arxiv ID**: http://arxiv.org/abs/1703.03937v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.03937v2)
- **Published**: 2017-03-11 10:01:11+00:00
- **Updated**: 2017-03-15 07:36:58+00:00
- **Authors**: Xavier Alameda-Pineda, Andrea Pilzer, Dan Xu, Nicu Sebe, Elisa Ricci
- **Comment**: Accepted at IEEE CVPR 2017
- **Journal**: None
- **Summary**: In our overly-connected world, the automatic recognition of virality - the quality of an image or video to be rapidly and widely spread in social networks - is of crucial importance, and has recently awaken the interest of the computer vision community. Concurrently, recent progress in deep learning architectures showed that global pooling strategies allow the extraction of activation maps, which highlight the parts of the image most likely to contain instances of a certain class. We extend this concept by introducing a pooling layer that learns the size of the support area to be averaged: the learned top-N average (LENA) pooling. We hypothesize that the latent concepts (feature maps) describing virality may require such a rich pooling strategy. We assess the effectiveness of the LENA layer by appending it on top of a convolutional siamese architecture and evaluate its performance on the task of predicting and localizing virality. We report experiments on two publicly available datasets annotated for virality and show that our method outperforms state-of-the-art approaches.



### A 3D Object Detection and Pose Estimation Pipeline Using RGB-D Images
- **Arxiv ID**: http://arxiv.org/abs/1703.03940v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1703.03940v1)
- **Published**: 2017-03-11 10:09:02+00:00
- **Updated**: 2017-03-11 10:09:02+00:00
- **Authors**: Ruotao He, Juan Rojas, Yisheng Guan
- **Comment**: None
- **Journal**: None
- **Summary**: 3D object detection and pose estimation has been studied extensively in recent decades for its potential applications in robotics. However, there still remains challenges when we aim at detecting multiple objects while retaining low false positive rate in cluttered environments. This paper proposes a robust 3D object detection and pose estimation pipeline based on RGB-D images, which can detect multiple objects simultaneously while reducing false positives. Detection begins with template matching and yields a set of template matches. A clustering algorithm then groups templates of similar spatial location and produces multiple-object hypotheses. A scoring function evaluates the hypotheses using their associated templates and non-maximum suppression is adopted to remove duplicate results based on the scores. Finally, a combination of point cloud processing algorithms are used to compute objects' 3D poses. Existing object hypotheses are verified by computing the overlap between model and scene points. Experiments demonstrate that our approach provides competitive results comparable to the state-of-the-arts and can be applied to robot random bin-picking.



### Web-based visualisation of head pose and facial expressions changes: monitoring human activity using depth data
- **Arxiv ID**: http://arxiv.org/abs/1703.03949v2
- **DOI**: 10.1109/CEEC.2016.7835887
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.03949v2)
- **Published**: 2017-03-11 11:07:22+00:00
- **Updated**: 2017-03-16 10:33:21+00:00
- **Authors**: Grigorios Kalliatakis, Nikolaos Vidakis, Georgios Triantafyllidis
- **Comment**: 8th Computer Science and Electronic Engineering, (CEEC 2016),
  University of Essex, UK, 6 pages
- **Journal**: None
- **Summary**: Despite significant recent advances in the field of head pose estimation and facial expression recognition, raising the cognitive level when analysing human activity presents serious challenges to current concepts. Motivated by the need of generating comprehensible visual representations from different sets of data, we introduce a system capable of monitoring human activity through head pose and facial expression changes, utilising an affordable 3D sensing technology (Microsoft Kinect sensor). An approach build on discriminative random regression forests was selected in order to rapidly and accurately estimate head pose changes in unconstrained environment. In order to complete the secondary process of recognising four universal dominant facial expressions (happiness, anger, sadness and surprise), emotion recognition via facial expressions (ERFE) was adopted. After that, a lightweight data exchange format (JavaScript Object Notation-JSON) is employed, in order to manipulate the data extracted from the two aforementioned settings. Such mechanism can yield a platform for objective and effortless assessment of human activity within the context of serious gaming and human-computer interaction.



### Neural method for Explicit Mapping of Quasi-curvature Locally Linear Embedding in image retrieval
- **Arxiv ID**: http://arxiv.org/abs/1703.03957v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.03957v1)
- **Published**: 2017-03-11 11:29:01+00:00
- **Updated**: 2017-03-11 11:29:01+00:00
- **Authors**: Shenglan Liu, Jun Wu, Lin Feng, Feilong Wang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposed a new explicit nonlinear dimensionality reduction using neural networks for image retrieval tasks. We first proposed a Quasi-curvature Locally Linear Embedding (QLLE) for training set. QLLE guarantees the linear criterion in neighborhood of each sample. Then, a neural method (NM) is proposed for out-of-sample problem. Combining QLLE and NM, we provide a explicit nonlinear dimensionality reduction approach for efficient image retrieval. The experimental results in three benchmark datasets illustrate that our method can get better performance than other state-of-the-art out-of-sample methods.



### Negentropic Planar Symmetry Detector
- **Arxiv ID**: http://arxiv.org/abs/1703.04019v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1703.04019v1)
- **Published**: 2017-03-11 19:16:38+00:00
- **Updated**: 2017-03-11 19:16:38+00:00
- **Authors**: Agata Migalska, JP Lewis
- **Comment**: 25 pages, 18 figures
- **Journal**: None
- **Summary**: In this paper we observe that information theoretical concepts are valuable tools for extracting information from images and, in particular, information on image symmetries. It is shown that the problem of detecting reflectional and rotational symmetries in a two-dimensional image can be reduced to the problem of detecting point-symmetry and periodicity in one-dimensional negentropy functions. Based on these findings a detector of reflectional and rotational global symmetries in greyscale images is constructed. We discuss the importance of high precision in symmetry detection in applications arising from quality control and illustrate how the proposed method satisfies this requirement. Finally, a superior performance of our method to other existing methods, demonstrated by the results of a rigorous experimental verification, is an indication that our approach rooted in information theory is a promising direction in a development of a robust and widely applicable symmetry detector.



### Colorization as a Proxy Task for Visual Understanding
- **Arxiv ID**: http://arxiv.org/abs/1703.04044v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.04044v3)
- **Published**: 2017-03-11 23:32:59+00:00
- **Updated**: 2017-08-13 17:40:29+00:00
- **Authors**: Gustav Larsson, Michael Maire, Gregory Shakhnarovich
- **Comment**: CVPR 2017 (Project page:
  http://people.cs.uchicago.edu/~larsson/color-proxy/)
- **Journal**: None
- **Summary**: We investigate and improve self-supervision as a drop-in replacement for ImageNet pretraining, focusing on automatic colorization as the proxy task. Self-supervised training has been shown to be more promising for utilizing unlabeled data than other, traditional unsupervised learning methods. We build on this success and evaluate the ability of our self-supervised network in several contexts. On VOC segmentation and classification tasks, we present results that are state-of-the-art among methods not using ImageNet labels for pretraining representations.   Moreover, we present the first in-depth analysis of self-supervision via colorization, concluding that formulation of the loss, training details and network architecture play important roles in its effectiveness. This investigation is further expanded by revisiting the ImageNet pretraining paradigm, asking questions such as: How much training data is needed? How many labels are needed? How much do features change when fine-tuned? We relate these questions back to self-supervision by showing that colorization provides a similarly powerful supervisory signal as various flavors of ImageNet pretraining.



