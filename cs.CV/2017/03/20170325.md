# Arxiv Papers in cs.CV on 2017-03-25
### More is Less: A More Complicated Network with Less Inference Complexity
- **Arxiv ID**: http://arxiv.org/abs/1703.08651v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.08651v2)
- **Published**: 2017-03-25 05:51:42+00:00
- **Updated**: 2017-05-15 07:56:20+00:00
- **Authors**: Xuanyi Dong, Junshi Huang, Yi Yang, Shuicheng Yan
- **Comment**: This paper has been accepted by the IEEE CVPR 2017
- **Journal**: None
- **Summary**: In this paper, we present a novel and general network structure towards accelerating the inference process of convolutional neural networks, which is more complicated in network structure yet with less inference complexity. The core idea is to equip each original convolutional layer with another low-cost collaborative layer (LCCL), and the element-wise multiplication of the ReLU outputs of these two parallel layers produces the layer-wise output. The combined layer is potentially more discriminative than the original convolutional layer, and its inference is faster for two reasons: 1) the zero cells of the LCCL feature maps will remain zero after element-wise multiplication, and thus it is safe to skip the calculation of the corresponding high-cost convolution in the original convolutional layer, 2) LCCL is very fast if it is implemented as a 1*1 convolution or only a single filter shared by all channels. Extensive experiments on the CIFAR-10, CIFAR-100 and ILSCRC-2012 benchmarks show that our proposed network structure can accelerate the inference process by 32\% on average with negligible performance drop.



### Gaussian Processes with Context-Supported Priors for Active Object Localization
- **Arxiv ID**: http://arxiv.org/abs/1703.08653v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.08653v3)
- **Published**: 2017-03-25 06:18:38+00:00
- **Updated**: 2017-09-20 06:47:26+00:00
- **Authors**: Anthony D. Rhodes, Jordan Witte, Melanie Mitchell, Bruno Jedynak
- **Comment**: 10 pages, 4 figures
- **Journal**: None
- **Summary**: We devise an algorithm using a Bayesian optimization framework in conjunction with contextual visual data for the efficient localization of objects in still images. Recent research has demonstrated substantial progress in object localization and related tasks for computer vision. However, many current state-of-the-art object localization procedures still suffer from inaccuracy and inefficiency, in addition to failing to provide a principled and interpretable system amenable to high-level vision tasks. We address these issues with the current research.   Our method encompasses an active search procedure that uses contextual data to generate initial bounding-box proposals for a target object. We train a convolutional neural network to approximate an offset distance from the target object. Next, we use a Gaussian Process to model this offset response signal over the search space of the target. We then employ a Bayesian active search for accurate localization of the target.   In experiments, we compare our approach to a state-of-theart bounding-box regression method for a challenging pedestrian localization task. Our method exhibits a substantial improvement over this baseline regression method.



### Improving the Accuracy of the CogniLearn System for Cognitive Behavior Assessment
- **Arxiv ID**: http://arxiv.org/abs/1703.08697v1
- **DOI**: 10.1145/3056540.3064942
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.08697v1)
- **Published**: 2017-03-25 14:36:12+00:00
- **Updated**: 2017-03-25 14:36:12+00:00
- **Authors**: Amir Ghaderi, Srujana Gattupalli, Dylan Ebert, Ali Sharifara, Vassilis Athitsos, Fillia Makedon
- **Comment**: None
- **Journal**: None
- **Summary**: HTKS is a game-like cognitive assessment method, designed for children between four and eight years of age. During the HTKS assessment, a child responds to a sequence of requests, such as "touch your head" or "touch your toes". The cognitive challenge stems from the fact that the children are instructed to interpret these requests not literally, but by touching a different body part than the one stated. In prior work, we have developed the CogniLearn system, that captures data from subjects performing the HTKS game, and analyzes the motion of the subjects. In this paper we propose some specific improvements that make the motion analysis module more accurate. As a result of these improvements, the accuracy in recognizing cases where subjects touch their toes has gone from 76.46% in our previous work to 97.19% in this paper.



### Count-ception: Counting by Fully Convolutional Redundant Counting
- **Arxiv ID**: http://arxiv.org/abs/1703.08710v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1703.08710v2)
- **Published**: 2017-03-25 16:49:03+00:00
- **Updated**: 2017-07-23 17:36:30+00:00
- **Authors**: Joseph Paul Cohen, Genevieve Boucher, Craig A. Glastonbury, Henry Z. Lo, Yoshua Bengio
- **Comment**: Under Review
- **Journal**: None
- **Summary**: Counting objects in digital images is a process that should be replaced by machines. This tedious task is time consuming and prone to errors due to fatigue of human annotators. The goal is to have a system that takes as input an image and returns a count of the objects inside and justification for the prediction in the form of object localization. We repose a problem, originally posed by Lempitsky and Zisserman, to instead predict a count map which contains redundant counts based on the receptive field of a smaller regression network. The regression network predicts a count of the objects that exist inside this frame. By processing the image in a fully convolutional way each pixel is going to be accounted for some number of times, the number of windows which include it, which is the size of each window, (i.e., 32x32 = 1024). To recover the true count we take the average over the redundant predictions. Our contribution is redundant counting instead of predicting a density map in order to average over errors. We also propose a novel deep neural network architecture adapted from the Inception family of networks called the Count-ception network. Together our approach results in a 20% relative improvement (2.9 to 2.3 MAE) over the state of the art method by Xie, Noble, and Zisserman in 2016.



### Cartoonish sketch-based face editing in videos using identity deformation transfer
- **Arxiv ID**: http://arxiv.org/abs/1703.08738v3
- **DOI**: 10.1016/j.cag.2019.01.004
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1703.08738v3)
- **Published**: 2017-03-25 20:33:45+00:00
- **Updated**: 2019-01-26 04:05:45+00:00
- **Authors**: Long Zhao, Fangda Han, Xi Peng, Xun Zhang, Mubbasir Kapadia, Vladimir Pavlovic, Dimitris N. Metaxas
- **Comment**: In Computers & Graphics, 2019. (12 pages, 10 figures)
- **Journal**: None
- **Summary**: We address the problem of using hand-drawn sketches to create exaggerated deformations to faces in videos, such as enlarging the shape or modifying the position of eyes or mouth. This task is formulated as a 3D face model reconstruction and deformation problem. We first recover the facial identity and expressions from the video by fitting a face morphable model for each frame. At the same time, user's editing intention is recognized from input sketches as a set of facial modifications. Then a novel identity deformation algorithm is proposed to transfer these facial deformations from 2D space to the 3D facial identity directly while preserving the facial expressions. After an optional stage for further refining the 3D face model, these changes are propagated to the whole video with the modified identity. Both the user study and experimental results demonstrate that our sketching framework can help users effectively edit facial identities in videos, while high consistency and fidelity are ensured at the same time.



