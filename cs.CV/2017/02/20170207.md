# Arxiv Papers in cs.CV on 2017-02-07
### Development of JavaScript-based deep learning platform and application to distributed training
- **Arxiv ID**: http://arxiv.org/abs/1702.01846v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/1702.01846v3)
- **Published**: 2017-02-07 02:02:08+00:00
- **Updated**: 2017-03-27 09:28:06+00:00
- **Authors**: Masatoshi Hidaka, Ken Miura, Tatsuya Harada
- **Comment**: Workshop paper for ICLR2017
- **Journal**: None
- **Summary**: Deep learning is increasingly attracting attention for processing big data. Existing frameworks for deep learning must be set up to specialized computer systems. Gaining sufficient computing resources therefore entails high costs of deployment and maintenance. In this work, we implement a matrix library and deep learning framework that uses JavaScript. It can run on web browsers operating on ordinary personal computers and smartphones. Using JavaScript, deep learning can be accomplished in widely diverse environments without the necessity for software installation. Using GPGPU from WebCL framework, our framework can train large scale convolutional neural networks such as VGGNet and ResNet. In the experiments, we demonstrate their practicality by training VGGNet in a distributed manner using web browsers as the client.



### Low Rank Matrix Recovery with Simultaneous Presence of Outliers and Sparse Corruption
- **Arxiv ID**: http://arxiv.org/abs/1702.01847v1
- **DOI**: 10.1109/JSTSP.2018.2876604
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1702.01847v1)
- **Published**: 2017-02-07 02:08:51+00:00
- **Updated**: 2017-02-07 02:08:51+00:00
- **Authors**: Mostafa Rahmani, George Atia
- **Comment**: None
- **Journal**: None
- **Summary**: We study a data model in which the data matrix D can be expressed as D = L + S + C, where L is a low rank matrix, S an element-wise sparse matrix and C a matrix whose non-zero columns are outlying data points. To date, robust PCA algorithms have solely considered models with either S or C, but not both. As such, existing algorithms cannot account for simultaneous element-wise and column-wise corruptions. In this paper, a new robust PCA algorithm that is robust to simultaneous types of corruption is proposed. Our approach hinges on the sparse approximation of a sparsely corrupted column so that the sparse expansion of a column with respect to the other data points is used to distinguish a sparsely corrupted inlier column from an outlying data point. We also develop a randomized design which provides a scalable implementation of the proposed approach. The core idea of sparse approximation is analyzed analytically where we show that the underlying ell_1-norm minimization can obtain the representation of an inlier in presence of sparse corruptions.



### A New Point-set Registration Algorithm for Fingerprint Matching
- **Arxiv ID**: http://arxiv.org/abs/1702.01870v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01870v1)
- **Published**: 2017-02-07 03:43:31+00:00
- **Updated**: 2017-02-07 03:43:31+00:00
- **Authors**: A. Pasha Hosseinbor, Renat Zhdanov, Alexander Ushveridze
- **Comment**: Point pattern matching, point-set registration, fingerprint, minutia
  matching, alignment
- **Journal**: None
- **Summary**: A novel minutia-based fingerprint matching algorithm is proposed that employs iterative global alignment on two minutia sets. The matcher considers all possible minutia pairings and iteratively aligns the two sets until the number of minutia pairs does not exceed the maximum number of allowable one-to-one pairings. The optimal alignment parameters are derived analytically via linear least squares. The first alignment establishes a region of overlap between the two minutia sets, which is then (iteratively) refined by each successive alignment. After each alignment, minutia pairs that exhibit weak correspondence are discarded. The process is repeated until the number of remaining pairs no longer exceeds the maximum number of allowable one-to-one pairings. The proposed algorithm is tested on both the FVC2000 and FVC2002 databases, and the results indicate that the proposed matcher is both effective and efficient for fingerprint authentication; it is fast and does not utilize any computationally expensive mathematical functions (e.g. trigonometric, exponential). In addition to the proposed matcher, another contribution of the paper is the analytical derivation of the least squares solution for the optimal alignment parameters for two point-sets lacking exact correspondence.



### Hashing in the Zero Shot Framework with Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1702.01933v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01933v2)
- **Published**: 2017-02-07 09:22:11+00:00
- **Updated**: 2017-02-28 19:43:41+00:00
- **Authors**: Shubham Pachori, Ameya Deshpande, Shanmuganathan Raman
- **Comment**: None
- **Journal**: None
- **Summary**: Techniques to learn hash codes which can store and retrieve large dimensional multimedia data efficiently have attracted broad research interests in the recent years. With rapid explosion of newly emerged concepts and online data, existing supervised hashing algorithms suffer from the problem of scarcity of ground truth annotations due to the high cost of obtaining manual annotations. Therefore, we propose an algorithm to learn a hash function from training images belonging to `seen' classes which can efficiently encode images of `unseen' classes to binary codes. Specifically, we project the image features from visual space and semantic features from semantic space into a common Hamming subspace. Earlier works to generate hash codes have tried to relax the discrete constraints on hash codes and solve the continuous optimization problem. However, it often leads to quantization errors. In this work, we use the max-margin classifier to learn an efficient hash function. To address the concern of domain-shift which may arise due to the introduction of new classes, we also introduce an unsupervised domain adaptation model in the proposed hashing framework. Results on the three datasets show the advantage of using domain adaptation in learning a high-quality hash function and superiority of our method for the task of image retrieval performance as compared to several state-of-the-art hashing methods.



### A Region Based Easy Path Wavelet Transform For Sparse Image Representation
- **Arxiv ID**: http://arxiv.org/abs/1702.01961v2
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, cs.GR, math.IT, 65T60, 68U10, 94A08, 42C40
- **Links**: [PDF](http://arxiv.org/pdf/1702.01961v2)
- **Published**: 2017-02-07 11:13:08+00:00
- **Updated**: 2017-02-15 10:41:38+00:00
- **Authors**: Renato Budinich
- **Comment**: Fixed use of HaarPSI - see Figure 9
- **Journal**: None
- **Summary**: The Easy Path Wavelet Transform is an adaptive transform for bivariate functions (in particular natural images) which has been proposed in [1]. It provides a sparse representation by finding a path in the domain of the function leveraging the local correlations of the function values. It then applies a one dimensional wavelet transform to the obtained vector, decimates the points and iterates the procedure. The main drawback of such method is the need to store, for each level of the transform, the path which vectorizes the two dimensional data. Here we propose a variation on the method which consists of firstly applying a segmentation procedure to the function domain, partitioning it into regions where the variation in the function values is low; in a second step, inside each such region, a path is found in some deterministic way, i.e. not data-dependent. This circumvents the need to store the paths at each level, while still obtaining good quality lossy compression. This method is particularly well suited to encode a Region of Interest in the image with different quality than the rest of the image.   [1] Gerlind Plonka. The easy path wavelet transform: A new adaptive wavelet transform for sparse representation of two-dimensional data. Multiscale Modeling & Simulation, 7(3):1474$-$1496, 2008.



### Image Reconstruction using Matched Wavelet Estimated from Data Sensed Compressively using Partial Canonical Identity Matrix
- **Arxiv ID**: http://arxiv.org/abs/1702.01970v1
- **DOI**: 10.1109/TIP.2017.2700719
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01970v1)
- **Published**: 2017-02-07 11:46:49+00:00
- **Updated**: 2017-02-07 11:46:49+00:00
- **Authors**: Naushad Ansari, Anubha Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a joint framework wherein lifting-based, separable, image-matched wavelets are estimated from compressively sensed (CS) images and used for the reconstruction of the same. Matched wavelet can be easily designed if full image is available. Also matched wavelet may provide better reconstruction results in CS application compared to standard wavelet sparsifying basis. Since in CS application, we have compressively sensed image instead of full image, existing methods of designing matched wavelet cannot be used. Thus, we propose a joint framework that estimates matched wavelet from the compressively sensed images and also reconstructs full images. This paper has three significant contributions. First, lifting-based, image-matched separable wavelet is designed from compressively sensed images and is also used to reconstruct the same. Second, a simple sensing matrix is employed to sample data at sub-Nyquist rate such that sensing and reconstruction time is reduced considerably without any noticeable degradation in the reconstruction performance. Third, a new multi-level L-Pyramid wavelet decomposition strategy is provided for separable wavelet implementation on images that leads to improved reconstruction performance. Compared to CS-based reconstruction using standard wavelets with Gaussian sensing matrix and with existing wavelet decomposition strategy, the proposed methodology provides faster and better image reconstruction in compressive sensing application.



### Face Aging With Conditional Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1702.01983v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01983v2)
- **Published**: 2017-02-07 12:40:35+00:00
- **Updated**: 2017-05-30 14:02:03+00:00
- **Authors**: Grigory Antipov, Moez Baccouche, Jean-Luc Dugelay
- **Comment**: 5 pages, 3 figures, accepted at ICIP 2017. With respect to v1: (1)
  changed the abbreviation of the main model from "acGAN" to "Age-cGAN" in
  order to avoid confusion with "Auxiliary Classifier Generative Adversarial
  Networks" introduced by Odena et al.; (2) corrected a typo in Formula 1
- **Journal**: None
- **Summary**: It has been recently shown that Generative Adversarial Networks (GANs) can produce synthetic images of exceptional visual fidelity. In this work, we propose the GAN-based method for automatic face aging. Contrary to previous works employing GANs for altering of facial attributes, we make a particular emphasize on preserving the original person's identity in the aged version of his/her face. To this end, we introduce a novel approach for "Identity-Preserving" optimization of GAN's latent vectors. The objective evaluation of the resulting aged and rejuvenated face images by the state-of-the-art face recognition and age estimation solutions demonstrate the high potential of the proposed method.



### Tracking using Numerous Anchor points
- **Arxiv ID**: http://arxiv.org/abs/1702.02012v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.02012v2)
- **Published**: 2017-02-07 13:51:06+00:00
- **Updated**: 2017-12-10 21:31:28+00:00
- **Authors**: Tanushri Chakravorty, Guillaume-Alexandre Bilodeau, Eric Granger
- **Comment**: Revised text version. Accepted for publication in Journal of Machine
  Vision and Applications, December, 2017
- **Journal**: None
- **Summary**: In this paper, an online adaptive model-free tracker is proposed to track single objects in video sequences to deal with real-world tracking challenges like low-resolution, object deformation, occlusion and motion blur. The novelty lies in the construction of a strong appearance model that captures features from the initialized bounding box and then are assembled into anchor-point features. These features memorize the global pattern of the object and have an internal star graph-like structure. These features are unique and flexible and helps tracking generic and deformable objects with no limitation on specific objects. In addition, the relevance of each feature is evaluated online using short-term consistency and long-term consistency. These parameters are adapted to retain consistent features that vote for the object location and that deal with outliers for long-term tracking scenarios. Additionally, voting in a Gaussian manner helps in tackling inherent noise of the tracking system and in accurate object localization. Furthermore, the proposed tracker uses pairwise distance measure to cope with scale variations and combines pixel-level binary features and global weighted color features for model update. Finally, experimental results on a visual tracking benchmark dataset are presented to demonstrate the effectiveness and competitiveness of the proposed tracker.



### An Implementation of Faster RCNN with Study for Region Sampling
- **Arxiv ID**: http://arxiv.org/abs/1702.02138v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.02138v2)
- **Published**: 2017-02-07 18:54:34+00:00
- **Updated**: 2017-02-08 07:02:25+00:00
- **Authors**: Xinlei Chen, Abhinav Gupta
- **Comment**: Technical Report, 3 pages
- **Journal**: None
- **Summary**: We adapted the join-training scheme of Faster RCNN framework from Caffe to TensorFlow as a baseline implementation for object detection. Our code is made publicly available. This report documents the simplifications made to the original pipeline, with justifications from ablation analysis on both PASCAL VOC 2007 and COCO 2014. We further investigated the role of non-maximal suppression (NMS) in selecting regions-of-interest (RoIs) for region classification, and found that a biased sampling toward small regions helps performance and can achieve on-par mAP to NMS-based sampling when converged sufficiently.



### Keyframe-Based Visual-Inertial Online SLAM with Relocalization
- **Arxiv ID**: http://arxiv.org/abs/1702.02175v2
- **DOI**: 10.1109/IROS.2017.8206581
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.02175v2)
- **Published**: 2017-02-07 19:32:50+00:00
- **Updated**: 2017-03-02 15:18:57+00:00
- **Authors**: Anton Kasyanov, Francis Engelmann, Jörg Stückler, Bastian Leibe
- **Comment**: None
- **Journal**: None
- **Summary**: Complementing images with inertial measurements has become one of the most popular approaches to achieve highly accurate and robust real-time camera pose tracking. In this paper, we present a keyframe-based approach to visual-inertial simultaneous localization and mapping (SLAM) for monocular and stereo cameras. Our visual-inertial SLAM system is based on a real-time capable visual-inertial odometry method that provides locally consistent trajectory and map estimates. We achieve global consistency in the estimate through online loop-closing and non-linear optimization. Furthermore, our system supports relocalization in a map that has been previously obtained and allows for continued SLAM operation. We evaluate our approach in terms of accuracy, relocalization capability and run-time efficiency on public indoor benchmark datasets and on newly recorded outdoor sequences. We demonstrate state-of-the-art performance of our system compared to a visual-inertial odometry method and baseline visual SLAM approaches in recovering the trajectory of the camera.



### Comparison of machine learning methods for classifying mediastinal lymph node metastasis of non-small cell lung cancer from 18F-FDG PET/CT images
- **Arxiv ID**: http://arxiv.org/abs/1702.02223v1
- **DOI**: 10.1186/s13550-017-0260-9
- **Categories**: **cs.CV**, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1702.02223v1)
- **Published**: 2017-02-07 23:12:45+00:00
- **Updated**: 2017-02-07 23:12:45+00:00
- **Authors**: Hongkai Wang, Zongwei Zhou, Yingci Li, Zhonghua Chen, Peiou Lu, Wenzhi Wang, Wanyu Liu, Lijuan Yu
- **Comment**: None
- **Journal**: None
- **Summary**: The present study shows that the performance of CNN is not significantly different from the best classical methods and human doctors for classifying mediastinal lymph node metastasis of NSCLC from PET/CT images. Because CNN does not need tumor segmentation or feature calculation, it is more convenient and more objective than the classical methods. However, CNN does not make use of the import diagnostic features, which have been proved more discriminative than the texture features for classifying small-sized lymph nodes. Therefore, incorporating the diagnostic features into CNN is a promising direction for future research.



