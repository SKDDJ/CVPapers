# Arxiv Papers in cs.CV on 2017-02-05
### Relative Camera Pose Estimation Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1702.01381v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01381v3)
- **Published**: 2017-02-05 08:53:24+00:00
- **Updated**: 2017-07-28 07:34:50+00:00
- **Authors**: Iaroslav Melekhov, Juha Ylioinas, Juho Kannala, Esa Rahtu
- **Comment**: To be published in proceedings of Advanced Concepts for Intelligent
  Vision Systems (ACIVS) 2017
- **Journal**: None
- **Summary**: This paper presents a convolutional neural network based approach for estimating the relative pose between two cameras. The proposed network takes RGB images from both cameras as input and directly produces the relative rotation and translation as output. The system is trained in an end-to-end manner utilising transfer learning from a large scale classification dataset. The introduced approach is compared with widely used local feature based methods (SURF, ORB) and the results indicate a clear improvement over the baseline. In addition, a variant of the proposed architecture containing a spatial pyramid pooling (SPP) layer is evaluated and shown to further improve the performance.



### Robust features for facial action recognition
- **Arxiv ID**: http://arxiv.org/abs/1702.01426v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01426v2)
- **Published**: 2017-02-05 16:28:26+00:00
- **Updated**: 2017-06-11 17:08:43+00:00
- **Authors**: Nadav Israel, Lior Wolf, Ran Barzilay, Gal Shoval
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic recognition of facial gestures is becoming increasingly important as real world AI agents become a reality. In this paper, we present an automated system that recognizes facial gestures by capturing local changes and encoding the motion into a histogram of frequencies. We evaluate the proposed method by demonstrating its effectiveness on spontaneous face action benchmarks: the FEEDTUM dataset, the Pain dataset and the HMDB51 dataset. The results show that, compared to known methods, the new encoding methods significantly improve the recognition accuracy and the robustness of analysis for a variety of applications.



### Printed Arabic Text Recognition using Linear and Nonlinear Regression
- **Arxiv ID**: http://arxiv.org/abs/1702.01444v1
- **DOI**: 10.14569/IJACSA.2017.080129
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.01444v1)
- **Published**: 2017-02-05 19:23:59+00:00
- **Updated**: 2017-02-05 19:23:59+00:00
- **Authors**: Ashraf A. Shahin
- **Comment**: http://thesai.org/Downloads/Volume8No1/Paper_29-Printed_Arabic_Text_Recognition_using_Linear.pdf
- **Journal**: International Journal of Advanced Computer Science and
  Applications(IJACSA), 8(1), 2017
- **Summary**: Arabic language is one of the most popular languages in the world. Hundreds of millions of people in many countries around the world speak Arabic as their native speaking. However, due to complexity of Arabic language, recognition of printed and handwritten Arabic text remained untouched for a very long time compared with English and Chinese. Although, in the last few years, significant number of researches has been done in recognizing printed and handwritten Arabic text, it stills an open research field due to cursive nature of Arabic script. This paper proposes automatic printed Arabic text recognition technique based on linear and ellipse regression techniques. After collecting all possible forms of each character, unique code is generated to represent each character form. Each code contains a sequence of lines and ellipses. To recognize fonts, a unique list of codes is identified to be used as a fingerprint of font. The proposed technique has been evaluated using over 14000 different Arabic words with different fonts and experimental results show that average recognition rate of the proposed technique is 86%.



