# Arxiv Papers in cs.CV on 2017-02-17
### Be Precise or Fuzzy: Learning the Meaning of Cardinals and Quantifiers from Vision
- **Arxiv ID**: http://arxiv.org/abs/1702.05270v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1702.05270v1)
- **Published**: 2017-02-17 09:26:10+00:00
- **Updated**: 2017-02-17 09:26:10+00:00
- **Authors**: Sandro Pezzelle, Marco Marelli, Raffaella Bernardi
- **Comment**: Accepted at EACL2017. 7 pages
- **Journal**: None
- **Summary**: People can refer to quantities in a visual scene by using either exact cardinals (e.g. one, two, three) or natural language quantifiers (e.g. few, most, all). In humans, these two processes underlie fairly different cognitive and neural mechanisms. Inspired by this evidence, the present study proposes two models for learning the objective meaning of cardinals and quantifiers from visual scenes containing multiple objects. We show that a model capitalizing on a 'fuzzy' measure of similarity is effective for learning quantifiers, whereas the learning of exact cardinals is better accomplished when information about number is provided.



### EMNIST: an extension of MNIST to handwritten letters
- **Arxiv ID**: http://arxiv.org/abs/1702.05373v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.05373v2)
- **Published**: 2017-02-17 15:06:14+00:00
- **Updated**: 2017-03-01 08:55:36+00:00
- **Authors**: Gregory Cohen, Saeed Afshar, Jonathan Tapson, Andr√© van Schaik
- **Comment**: The dataset is now available for download from
  https://www.westernsydney.edu.au/bens/home/reproducible_research/emnist. This
  link is also included in the revised article
- **Journal**: None
- **Summary**: The MNIST dataset has become a standard benchmark for learning, classification and computer vision systems. Contributing to its widespread adoption are the understandable and intuitive nature of the task, its relatively small size and storage requirements and the accessibility and ease-of-use of the database itself. The MNIST database was derived from a larger dataset known as the NIST Special Database 19 which contains digits, uppercase and lowercase handwritten letters. This paper introduces a variant of the full NIST dataset, which we have called Extended MNIST (EMNIST), which follows the same conversion paradigm used to create the MNIST dataset. The result is a set of datasets that constitute a more challenging classification tasks involving letters and digits, and that shares the same image structure and parameters as the original MNIST task, allowing for direct compatibility with all existing classifiers and systems. Benchmark results are presented along with a validation of the conversion process through the comparison of the classification results on converted NIST digits and the MNIST digits.



### Domain Adaptation for Visual Applications: A Comprehensive Survey
- **Arxiv ID**: http://arxiv.org/abs/1702.05374v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.05374v2)
- **Published**: 2017-02-17 15:07:40+00:00
- **Updated**: 2017-03-30 15:42:12+00:00
- **Authors**: Gabriela Csurka
- **Comment**: Book chapter to appear in "Domain Adaptation in Computer Vision
  Applications", Springer Series: Advances in Computer Vision and Pattern
  Recognition, Edited by Gabriela Csurka
- **Journal**: None
- **Summary**: The aim of this paper is to give an overview of domain adaptation and transfer learning with a specific view on visual applications. After a general motivation, we first position domain adaptation in the larger transfer learning problem. Second, we try to address and analyze briefly the state-of-the-art methods for different types of scenarios, first describing the historical shallow methods, addressing both the homogeneous and the heterogeneous domain adaptation methods. Third, we discuss the effect of the success of deep convolutional architectures which led to new type of domain adaptation methods that integrate the adaptation within the deep architecture. Fourth, we overview the methods that go beyond image categorization, such as object detection or image segmentation, video analyses or learning visual attributes. Finally, we conclude the paper with a section where we relate domain adaptation to other machine learning solutions.



### Vehicle Speed Detecting App
- **Arxiv ID**: http://arxiv.org/abs/1702.05388v2
- **DOI**: None
- **Categories**: **cs.CV**, I.5.4; D.2.9
- **Links**: [PDF](http://arxiv.org/pdf/1702.05388v2)
- **Published**: 2017-02-17 15:34:02+00:00
- **Updated**: 2017-03-24 16:01:05+00:00
- **Authors**: Itoro Ikon
- **Comment**: Revised
- **Journal**: None
- **Summary**: The report presents the measurement of vehicular speed using a smartphone camera. The speed measurement is accomplished by detecting the position of the vehicle on a camera frame using the LBP cascade classifier of OpenCV API, the displacement of the detected vehicle with time is used to compute the speed. Conversion coefficient is determined to map the pixel displacement to actual vehicle distance. The speeds measured are proportional to the ground truth speeds.



### 3D Cell Nuclei Segmentation with Balanced Graph Partitioning
- **Arxiv ID**: http://arxiv.org/abs/1702.05413v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DS
- **Links**: [PDF](http://arxiv.org/pdf/1702.05413v1)
- **Published**: 2017-02-17 16:01:50+00:00
- **Updated**: 2017-02-17 16:01:50+00:00
- **Authors**: Julian Arz, Peter Sanders, Johannes Stegmaier, Ralf Mikut
- **Comment**: None
- **Journal**: None
- **Summary**: Cell nuclei segmentation is one of the most important tasks in the analysis of biomedical images. With ever-growing sizes and amounts of three-dimensional images to be processed, there is a need for better and faster segmentation methods. Graph-based image segmentation has seen a rise in popularity in recent years, but is seen as very costly with regard to computational demand. We propose a new segmentation algorithm which overcomes these limitations. Our method uses recursive balanced graph partitioning to segment foreground components of a fast and efficient binarization. We construct a model for the cell nuclei to guide the partitioning process. Our algorithm is compared to other state-of-the-art segmentation algorithms in an experimental evaluation on two sets of realistically simulated inputs. Our method is faster, has similar or better quality and an acceptable memory overhead.



### Forest understory trees can be segmented accurately within sufficiently dense airborne laser scanning point clouds
- **Arxiv ID**: http://arxiv.org/abs/1702.06188v2
- **DOI**: 10.1038/s41598-017-07200-0
- **Categories**: **cs.CV**, cs.CG
- **Links**: [PDF](http://arxiv.org/pdf/1702.06188v2)
- **Published**: 2017-02-17 16:07:53+00:00
- **Updated**: 2017-08-03 01:32:01+00:00
- **Authors**: Hamid Hamraz, Marco A. Contreras, Jun Zhang
- **Comment**: arXiv admin note: text overlap with arXiv:1701.00169
- **Journal**: Scientific Reports, 7(1), 6770 (2017)
- **Summary**: Airborne laser scanning (LiDAR) point clouds over large forested areas can be processed to segment individual trees and subsequently extract tree-level information. Existing segmentation procedures typically detect more than 90% of overstory trees, yet they barely detect 60% of understory trees because of the occlusion effect of higher canopy layers. Although understory trees provide limited financial value, they are an essential component of ecosystem functioning by offering habitat for numerous wildlife species and influencing stand development. Here we model the occlusion effect in terms of point density. We estimate the fractions of points representing different canopy layers (one overstory and multiple understory) and also pinpoint the required density for reasonable tree segmentation (where accuracy plateaus). We show that at a density of ~170 pt/m-sqr understory trees can likely be segmented as accurately as overstory trees. Given the advancements of LiDAR sensor technology, point clouds will affordably reach this required density. Using modern computational approaches for big data, the denser point clouds can efficiently be processed to ultimately allow accurate remote quantification of forest resources. The methodology can also be adopted for other similar remote sensing or advanced imaging applications such as geological subsurface modelling or biomedical tissue analysis.



### Learning to Detect Human-Object Interactions
- **Arxiv ID**: http://arxiv.org/abs/1702.05448v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.05448v2)
- **Published**: 2017-02-17 17:21:30+00:00
- **Updated**: 2018-03-01 00:23:31+00:00
- **Authors**: Yu-Wei Chao, Yunfan Liu, Xieyang Liu, Huayi Zeng, Jia Deng
- **Comment**: Accepted in WACV 2018
- **Journal**: None
- **Summary**: We study the problem of detecting human-object interactions (HOI) in static images, defined as predicting a human and an object bounding box with an interaction class label that connects them. HOI detection is a fundamental problem in computer vision as it provides semantic information about the interactions among the detected objects. We introduce HICO-DET, a new large benchmark for HOI detection, by augmenting the current HICO classification benchmark with instance annotations. To solve the task, we propose Human-Object Region-based Convolutional Neural Networks (HO-RCNN). At the core of our HO-RCNN is the Interaction Pattern, a novel DNN input that characterizes the spatial relations between two bounding boxes. Experiments on HICO-DET demonstrate that our HO-RCNN, by exploiting human-object spatial relations through Interaction Patterns, significantly improves the performance of HOI detection over baseline approaches.



### Adversarial Discriminative Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1702.05464v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.05464v1)
- **Published**: 2017-02-17 18:10:53+00:00
- **Updated**: 2017-02-17 18:10:53+00:00
- **Authors**: Eric Tzeng, Judy Hoffman, Kate Saenko, Trevor Darrell
- **Comment**: None
- **Journal**: None
- **Summary**: Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They also can improve recognition despite the presence of domain shift or dataset bias: several adversarial approaches to unsupervised domain adaptation have recently been introduced, which reduce the difference between the training and test domain distributions and thus improve generalization performance. Prior generative approaches show compelling visualizations, but are not optimal on discriminative tasks and can be limited to smaller shifts. Prior discriminative approaches could handle larger domain shifts, but imposed tied weights on the model and did not exploit a GAN-based loss. We first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and we use this generalized view to better relate the prior approaches. We propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard cross-domain digit classification tasks and a new more difficult cross-modality object classification task.



### An Unsupervised Approach for Overlapping Cervical Cell Cytoplasm Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1702.05506v1
- **DOI**: 10.1109/IECBES.2016.7843424
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1702.05506v1)
- **Published**: 2017-02-17 19:29:57+00:00
- **Updated**: 2017-02-17 19:29:57+00:00
- **Authors**: Pranav Kumar, S L Happy, Swarnadip Chatterjee, Debdoot Sheet, Aurobinda Routray
- **Comment**: 4 pages, 4 figures, Biomedical Engineering and Sciences (IECBES),
  2016 IEEE EMBS Conference on. IEEE, 2016
- **Journal**: IEEE EMBS Conference on Biomedical Engineering and Sciences
  (IECBES), 2016
- **Summary**: The poor contrast and the overlapping of cervical cell cytoplasm are the major issues in the accurate segmentation of cervical cell cytoplasm. This paper presents an automated unsupervised cytoplasm segmentation approach which can effectively find the cytoplasm boundaries in overlapping cells. The proposed approach first segments the cell clumps from the cervical smear image and detects the nuclei in each cell clump. A modified Otsu method with prior class probability is proposed for accurate segmentation of nuclei from the cell clumps. Using distance regularized level set evolution, the contour around each nucleus is evolved until it reaches the cytoplasm boundaries. Promising results were obtained by experimenting on ISBI 2015 challenge dataset.



