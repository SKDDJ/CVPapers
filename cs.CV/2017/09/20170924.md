# Arxiv Papers in cs.CV on 2017-09-24
### Domain Adaptation from Synthesis to Reality in Single-model Detector for Video Smoke Detection
- **Arxiv ID**: http://arxiv.org/abs/1709.08142v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08142v3)
- **Published**: 2017-09-24 03:33:41+00:00
- **Updated**: 2018-11-21 01:12:34+00:00
- **Authors**: Gao Xu, Yongming Zhang, Qixing Zhang, Gaohua Lin, Jinjun Wang
- **Comment**: The manuscript approved by all authors is our original work, and has
  submitted to Pattern Recognition for peer review previously. There are 4532
  words, 6 figures and 1 table in this manuscript
- **Journal**: None
- **Summary**: This paper proposes a method for video smoke detection using synthetic smoke samples. The virtual data can automatically offer precise and rich annotated samples. However, the learning of smoke representations will be hurt by the appearance gap between real and synthetic smoke samples. The existed researches mainly work on the adaptation to samples extracted from original annotated samples. These methods take the object detection and domain adaptation as two independent parts. To train a strong detector with rich synthetic samples, we construct the adaptation to the detection layer of state-of-the-art single-model detectors (SSD and MS-CNN). The training procedure is an end-to-end stage. The classification, location and adaptation are combined in the learning. The performance of the proposed model surpasses the original baseline in our experiments. Meanwhile, our results show that the detectors based on the adversarial adaptation are superior to the detectors based on the discrepancy adaptation. Code will be made publicly available on http://smoke.ustc.edu.cn. Moreover, the domain adaptation for two-stage detector is described in Appendix A.



### Comparison of Batch Normalization and Weight Normalization Algorithms for the Large-scale Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1709.08145v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08145v2)
- **Published**: 2017-09-24 04:33:53+00:00
- **Updated**: 2017-10-07 23:28:57+00:00
- **Authors**: Igor Gitman, Boris Ginsburg
- **Comment**: None
- **Journal**: None
- **Summary**: Batch normalization (BN) has become a de facto standard for training deep convolutional networks. However, BN accounts for a significant fraction of training run-time and is difficult to accelerate, since it is a memory-bandwidth bounded operation. Such a drawback of BN motivates us to explore recently proposed weight normalization algorithms (WN algorithms), i.e. weight normalization, normalization propagation and weight normalization with translated ReLU. These algorithms don't slow-down training iterations and were experimentally shown to outperform BN on relatively small networks and datasets. However, it is not clear if these algorithms could replace BN in practical, large-scale applications. We answer this question by providing a detailed comparison of BN and WN algorithms using ResNet-50 network trained on ImageNet. We found that although WN achieves better training accuracy, the final test accuracy is significantly lower ($\approx 6\%$) than that of BN. This result demonstrates the surprising strength of the BN regularization effect which we were unable to compensate for using standard regularization techniques like dropout and weight decay. We also found that training of deep networks with WN algorithms is significantly less stable compared to BN, limiting their practical applications.



### Rapid and Robust Automated Macroscopic Wood Identification System using Smartphone with Macro-lens
- **Arxiv ID**: http://arxiv.org/abs/1709.08154v1
- **DOI**: None
- **Categories**: **cs.CY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.08154v1)
- **Published**: 2017-09-24 06:10:52+00:00
- **Updated**: 2017-09-24 06:10:52+00:00
- **Authors**: Xin Jie Tang, Yong Haur Tay, Nordahlia Abdullah Siam, Seng Choon Lim
- **Comment**: Accepted by PRWAC 2017
- **Journal**: None
- **Summary**: Wood Identification has never been more important to serve the purpose of global forest species protection and timber regulation. Macroscopic level wood identification practiced by wood anatomists can identify wood up to genus level. This is sufficient to serve as a frontline identification to fight against illegal wood logging and timber trade for law enforcement authority. However, frontline enforcement official may lack of the accuracy and confidence of a well trained wood anatomist. Hence, computer assisted method such as machine vision methods are developed to do rapid field identification for law enforcement official. In this paper, we proposed a rapid and robust macroscopic wood identification system using machine vision method with off-the-shelf smartphone and retrofitted macro-lens. Our system is cost effective, easily accessible, fast and scalable at the same time provides human-level accuracy on identification. Camera-enabled smartphone with Internet connectivity coupled with a macro-lens provides a simple and effective digital acquisition of macroscopic wood images which are essential for macroscopic wood identification. The images are immediately streamed to a cloud server via Internet connection for identification which are done within seconds.



### Tensor-Based Classifiers for Hyperspectral Data Analysis
- **Arxiv ID**: http://arxiv.org/abs/1709.08164v2
- **DOI**: 10.1109/TGRS.2018.2845450
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08164v2)
- **Published**: 2017-09-24 09:05:36+00:00
- **Updated**: 2018-07-03 13:25:08+00:00
- **Authors**: Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis, Antonis Nikitakis
- **Comment**: To appear in IEEE Transactions on Geoscience and Remote Sensing
- **Journal**: None
- **Summary**: In this work, we present tensor-based linear and nonlinear models for hyperspectral data classification and analysis. By exploiting principles of tensor algebra, we introduce new classification architectures, the weight parameters of which satisfies the {\it rank}-1 canonical decomposition property. Then, we introduce learning algorithms to train both the linear and the non-linear classifier in a way to i) to minimize the error over the training samples and ii) the weight coefficients satisfies the {\it rank}-1 canonical decomposition property. The advantages of the proposed classification model is that i) it reduces the number of parameters required and thus reduces the respective number of training samples required to properly train the model, ii) it provides a physical interpretation regarding the model coefficients on the classification output and iii) it retains the spatial and spectral coherency of the input samples. To address issues related with linear classification, characterizing by low capacity, since it can produce rules that are linear in the input space, we introduce non-linear classification models based on a modification of a feedforward neural network. We call the proposed architecture {\it rank}-1 Feedfoward Neural Network (FNN), since their weights satisfy the {\it rank}-1 caconical decomposition property. Appropriate learning algorithms are also proposed to train the network. Experimental results and comparisons with state of the art classification methods, either linear (e.g., SVM) and non-linear (e.g., deep learning) indicates the outperformance of the proposed scheme, especially in cases where a small number of training samples are available. Furthermore, the proposed tensor-based classfiers are evaluated against their capabilities in dimensionality reduction.



### Can Image Retrieval help Visual Saliency Detection?
- **Arxiv ID**: http://arxiv.org/abs/1709.08172v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08172v1)
- **Published**: 2017-09-24 09:50:48+00:00
- **Updated**: 2017-09-24 09:50:48+00:00
- **Authors**: Shuang Li, Peter Mathews
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel image retrieval framework for visual saliency detection using information about salient objects contained within bounding box annotations for similar images. For each test image, we train a customized SVM from similar example images to predict the saliency values of its object proposals and generate an external saliency map (ES) by aggregating the regional scores. To overcome limitations caused by the size of the training dataset, we also propose an internal optimization module which computes an internal saliency map (IS) by measuring the low-level contrast information of the test image. The two maps, ES and IS, have complementary properties so we take a weighted combination to further improve the detection performance. Experimental results on several challenging datasets demonstrate that the proposed algorithm performs favorably against the state-of-the-art methods.



### Performance Characterization of Image Feature Detectors in Relation to the Scene Content Utilizing a Large Image Database
- **Arxiv ID**: http://arxiv.org/abs/1709.08202v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08202v2)
- **Published**: 2017-09-24 14:22:52+00:00
- **Updated**: 2017-10-13 15:42:32+00:00
- **Authors**: Bruno Ferrarini, Shoaib Ehsan, Ales Leonardis, Naveed Ur Rehman, Klaus D. McDonald-Maier
- **Comment**: Extended version of the conference paper available at
  http://ieeexplore.ieee.org/abstract/document/7314191/?reload=true
- **Journal**: None
- **Summary**: Selecting the most suitable local invariant feature detector for a particular application has rendered the task of evaluating feature detectors a critical issue in vision research. Although the literature offers a variety of comparison works focusing on performance evaluation of image feature detectors under several types of image transformations, the influence of the scene content on the performance of local feature detectors has received little attention so far. This paper aims to bridge this gap with a new framework for determining the type of scenes which maximize and minimize the performance of detectors in terms of repeatability rate. The results are presented for several state-of-the-art feature detectors that have been obtained using a large image database of 20482 images under JPEG compression, uniform light and blur changes with 539 different scenes captured from real-world scenarios. These results provide new insights into the behavior of feature detectors.



### Survey of Recent Advances in Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1709.08203v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08203v1)
- **Published**: 2017-09-24 14:42:17+00:00
- **Updated**: 2017-09-24 14:42:17+00:00
- **Authors**: Supriya Pandhre, Shagun Sodhani
- **Comment**: 7 pages, 2 tables
- **Journal**: None
- **Summary**: Visual Question Answering (VQA) presents a unique challenge as it requires the ability to understand and encode the multi-modal inputs - in terms of image processing and natural language processing. The algorithm further needs to learn how to perform reasoning over this multi-modal representation so it can answer the questions correctly. This paper presents a survey of different approaches proposed to solve the problem of Visual Question Answering. We also describe the current state of the art model in later part of paper. In particular, the paper describes the approaches taken by various algorithms to extract image features, text features and the way these are employed to predict answers. We also briefly discuss the experiments performed to evaluate the VQA models and report their performances on diverse datasets including newly released VQA2.0[8].



### Discovery Radiomics via Deep Multi-Column Radiomic Sequencers for Skin Cancer Detection
- **Arxiv ID**: http://arxiv.org/abs/1709.08248v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1709.08248v1)
- **Published**: 2017-09-24 19:53:20+00:00
- **Updated**: 2017-09-24 19:53:20+00:00
- **Authors**: Mohammad Javad Shafiee, Alexander Wong
- **Comment**: None
- **Journal**: None
- **Summary**: While skin cancer is the most diagnosed form of cancer in men and women, with more cases diagnosed each year than all other cancers combined, sufficiently early diagnosis results in very good prognosis and as such makes early detection crucial. While radiomics have shown considerable promise as a powerful diagnostic tool for significantly improving oncological diagnostic accuracy and efficiency, current radiomics-driven methods have largely rely on pre-defined, hand-crafted quantitative features, which can greatly limit the ability to fully characterize unique cancer phenotype that distinguish it from healthy tissue. Recently, the notion of discovery radiomics was introduced, where a large amount of custom, quantitative radiomic features are directly discovered from the wealth of readily available medical imaging data. In this study, we present a novel discovery radiomics framework for skin cancer detection, where we leverage novel deep multi-column radiomic sequencers for high-throughput discovery and extraction of a large amount of custom radiomic features tailored for characterizing unique skin cancer tissue phenotype. The discovered radiomic sequencer was tested against 9,152 biopsy-proven clinical images comprising of different skin cancers such as melanoma and basal cell carcinoma, and demonstrated sensitivity and specificity of 91% and 75%, respectively, thus achieving dermatologist-level performance and \break hence can be a powerful tool for assisting general practitioners and dermatologists alike in improving the efficiency, consistency, and accuracy of skin cancer diagnosis.



### Calligraphic Stylisation Learning with a Physiologically Plausible Model of Movement and Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.01214v1
- **DOI**: 10.1145/3077981.3078049
- **Categories**: **cs.CV**, I.2.6; I.6.8; D.2.2
- **Links**: [PDF](http://arxiv.org/pdf/1710.01214v1)
- **Published**: 2017-09-24 19:53:40+00:00
- **Updated**: 2017-09-24 19:53:40+00:00
- **Authors**: Daniel Berio, Memo Akten, Frederic Fol Leymarie, Mick Grierson, Réjean Plamondon
- **Comment**: 8 Pages, Accepted for publication at MOCO '17, 4th International
  Conference on Movement Computing 28-30 June 2017, London, United Kingdom
- **Journal**: None
- **Summary**: We propose a computational framework to learn stylisation patterns from example drawings or writings, and then generate new trajectories that possess similar stylistic qualities. We particularly focus on the generation and stylisation of trajectories that are similar to the ones that can be seen in calligraphy and graffiti art. Our system is able to extract and learn dynamic and visual qualities from a small number of user defined examples which can be recorded with a digitiser device, such as a tablet, mouse or motion capture sensors. Our system is then able to transform new user drawn traces to be kinematically and stylistically similar to the training examples. We implement the system using a Recurrent Mixture Density Network (RMDN) combined with a representation given by the parameters of the Sigma Lognormal model, a physiologically plausible model of movement that has been shown to closely reproduce the velocity and trace of human handwriting gestures.



### HDLTex: Hierarchical Deep Learning for Text Classification
- **Arxiv ID**: http://arxiv.org/abs/1709.08267v2
- **DOI**: 10.1109/ICMLA.2017.0-134
- **Categories**: **cs.LG**, cs.AI, cs.CL, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1709.08267v2)
- **Published**: 2017-09-24 21:58:12+00:00
- **Updated**: 2017-10-06 18:16:31+00:00
- **Authors**: Kamran Kowsari, Donald E. Brown, Mojtaba Heidarysafa, Kiana Jafari Meimandi, Matthew S. Gerber, Laura E. Barnes
- **Comment**: ICMLA 2017
- **Journal**: None
- **Summary**: The continually increasing number of documents produced each year necessitates ever improving information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of these traditional classifiers has degraded as the number of documents has increased. This is because along with this growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document hierarchy.



### 3D Camouflaging Object using RGB-D Sensors
- **Arxiv ID**: http://arxiv.org/abs/1709.08271v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08271v1)
- **Published**: 2017-09-24 22:19:24+00:00
- **Updated**: 2017-09-24 22:19:24+00:00
- **Authors**: Ahmed M. Siddek, Mohsen A. Rashwan, Islam A. Eshrah
- **Comment**: 6 pages, 12 figures, 2017 IEEE International Conference on SMC
- **Journal**: None
- **Summary**: This paper proposes a new optical camouflage system that uses RGB-D cameras, for acquiring point cloud of background scene, and tracking observers eyes. This system enables a user to conceal an object located behind a display that surrounded by 3D objects. If we considered here the tracked point of observer s eyes is a light source, the system will work on estimating shadow shape of the display device that falls on the objects in background. The system uses the 3d observer s eyes and the locations of display corners to predict their shadow points which have nearest neighbors in the constructed point cloud of background scene.



