# Arxiv Papers in cs.CV on 2017-09-23
### Visual Reference Resolution using Attention Memory for Visual Dialog
- **Arxiv ID**: http://arxiv.org/abs/1709.07992v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.07992v3)
- **Published**: 2017-09-23 02:53:48+00:00
- **Updated**: 2018-08-06 21:03:18+00:00
- **Authors**: Paul Hongsuck Seo, Andreas Lehrmann, Bohyung Han, Leonid Sigal
- **Comment**: None
- **Journal**: None
- **Summary**: Visual dialog is a task of answering a series of inter-dependent questions given an input image, and often requires to resolve visual references among the questions. This problem is different from visual question answering (VQA), which relies on spatial attention (a.k.a. visual grounding) estimated from an image and question pair. We propose a novel attention mechanism that exploits visual attentions in the past to resolve the current reference in the visual dialog scenario. The proposed model is equipped with an associative attention memory storing a sequence of previous (attention, key) pairs. From this memory, the model retrieves the previous attention, taking into account recency, which is most relevant for the current question, in order to resolve potentially ambiguous references. The model then merges the retrieved attention with a tentative one to obtain the final attention for the current question; specifically, we use dynamic parameter prediction to combine the two attentions conditioned on the question. Through extensive experiments on a new synthetic visual dialog dataset, we show that our model significantly outperforms the state-of-the-art (by ~16 % points) in situations, where visual reference resolution plays an important role. Moreover, the proposed model achieves superior performance (~ 2 % points improvement) in the Visual Dialog dataset, despite having significantly fewer parameters than the baselines.



### A semi-automated segmentation method for detection of pulmonary embolism in True-FISP MRI sequences
- **Arxiv ID**: http://arxiv.org/abs/1709.07993v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.07993v1)
- **Published**: 2017-09-23 03:02:35+00:00
- **Updated**: 2017-09-23 03:02:35+00:00
- **Authors**: Luis R Soenksen, Luis Jim√©nez-Angeles, Gabriela Melendez, Aloha Meave
- **Comment**: 8 pages, 5 figures
- **Journal**: None
- **Summary**: Pulmonary embolism (PE) is a highly mortal disease, currently assessed by pulmonary CT angiography. True-FISP MRI has emerged as an innocuous alternative that does not hold many of the limitations of x-ray imaging. However, True-FISP MRI is very sensitive to turbulent blood flow, generating artifacts that may resemble fake clots in the pulmonary vasculature. These misinterpretations reduce its overall diagnostic accuracy to 94%, limiting a wider use in clinical environments. A new segmentation algorithm is proposed to confirm the presence of real pulmonary clots in True-FISP MR images by quantitative means, measuring the shape, intensity, and solidity of the formation. The algorithm was evaluated in 37 patients. The developed method increased the diagnostic accuracy of expert observers assessing Pulmonary True-FISP MRI sequences by 6% without the use of ionizing radiation, achieving a diagnostic accuracy comparable to standard CT angiography.



### Semi-Supervised Hierarchical Semantic Object Parsing
- **Arxiv ID**: http://arxiv.org/abs/1709.08019v3
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.08019v3)
- **Published**: 2017-09-23 08:01:44+00:00
- **Updated**: 2017-10-29 16:24:53+00:00
- **Authors**: Jalal Mirakhorli, Hamidreza Amindavar
- **Comment**: None
- **Journal**: None
- **Summary**: Models based on Convolutional Neural Networks (CNNs) have been proven very successful for semantic segmentation and object parsing that yield hierarchies of features. Our key insight is to build convolutional networks that take input of arbitrary size and produce object parsing output with efficient inference and learning. In this work, we focus on the task of instance segmentation and parsing which recognizes and localizes objects down to a pixel level base on deep CNN. Therefore, unlike some related work, a pixel cannot belong to multiple instances and parsing. Our model is based on a deep neural network trained for object masking that supervised with input image and follow incorporates a Conditional Random Field (CRF) with end-to-end trainable piecewise order potentials based on object parsing outputs. In each CRF unit we designed terms to capture the short range and long range dependencies from various neighbors. The accurate instance-level segmentation that our network produce is reflected by the considerable improvements obtained over previous work at high APr thresholds. We demonstrate the effectiveness of our model with extensive experiments on challenging dataset subset of PASCAL VOC2012.



### Adaptive Measurement Network for CS Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1710.01244v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.01244v1)
- **Published**: 2017-09-23 15:11:19+00:00
- **Updated**: 2017-09-23 15:11:19+00:00
- **Authors**: Xuemei Xie, Yuxiang Wang, Guangming Shi, Chenye Wang, Jiang Du, Zhifu Zhao
- **Comment**: 11pages,8figures
- **Journal**: None
- **Summary**: Conventional compressive sensing (CS) reconstruction is very slow for its characteristic of solving an optimization problem. Convolu- tional neural network can realize fast processing while achieving compa- rable results. While CS image recovery with high quality not only de- pends on good reconstruction algorithms, but also good measurements. In this paper, we propose an adaptive measurement network in which measurement is obtained by learning. The new network consists of a fully-connected layer and ReconNet. The fully-connected layer which has low-dimension output acts as measurement. We train the fully-connected layer and ReconNet simultaneously and obtain adaptive measurement. Because the adaptive measurement fits dataset better, in contrast with random Gaussian measurement matrix, under the same measuremen- t rate, it can extract the information of scene more efficiently and get better reconstruction results. Experiments show that the new network outperforms the original one.



### A Generic Regression Framework for Pose Recognition on Color and Depth Images
- **Arxiv ID**: http://arxiv.org/abs/1709.08068v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08068v1)
- **Published**: 2017-09-23 15:56:58+00:00
- **Updated**: 2017-09-23 15:56:58+00:00
- **Authors**: Wenye He
- **Comment**: None
- **Journal**: None
- **Summary**: Cascaded regression method is a fast and accurate method on finding 2D pose of objects in RGB images. It is able to find the accurate pose of objects in an image by a great number of corrections on the good initial guess of the pose of objects. This paper explains the algorithm and shows the result of two experiments carried by the researchers. The presented new method to quickly and accurately predict 3D positions of body joints from a single depth image, using no temporal information. We take an object recognition approach, designing an intermediate body parts representation that maps the difficult pose estimation problem into a simpler per-pixel classification problem. Our large and highly varied training dataset allows the classifier to estimate body parts invariant to pose, body shape, clothing. Finally, we generate confidence-scored 3D proposals of several body parts by re-projecting the classification result and finding local modes.



### Compact Environment-Invariant Codes for Robust Visual Place Recognition
- **Arxiv ID**: http://arxiv.org/abs/1709.08103v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08103v1)
- **Published**: 2017-09-23 19:08:47+00:00
- **Updated**: 2017-09-23 19:08:47+00:00
- **Authors**: Unnat Jain, Vinay P. Namboodiri, Gaurav Pandey
- **Comment**: Conference on Computer and Robot Vision (CRV) 2017
- **Journal**: None
- **Summary**: Robust visual place recognition (VPR) requires scene representations that are invariant to various environmental challenges such as seasonal changes and variations due to ambient lighting conditions during day and night. Moreover, a practical VPR system necessitates compact representations of environmental features. To satisfy these requirements, in this paper we suggest a modification to the existing pipeline of VPR systems to incorporate supervised hashing. The modified system learns (in a supervised setting) compact binary codes from image feature descriptors. These binary codes imbibe robustness to the visual variations exposed to it during the training phase, thereby, making the system adaptive to severe environmental changes. Also, incorporating supervised hashing makes VPR computationally more efficient and easy to implement on simple hardware. This is because binary embeddings can be learned over simple-to-compute features and the distance computation is also in the low-dimensional hamming space of binary codes. We have performed experiments on several challenging data sets covering seasonal, illumination and viewpoint variations. We also compare two widely used supervised hashing methods of CCAITQ and MLH and show that this new pipeline out-performs or closely matches the state-of-the-art deep learning VPR methods that are based on high-dimensional features extracted from pre-trained deep convolutional neural networks.



### Robust Facial Landmark Detection under Significant Head Poses and Occlusion
- **Arxiv ID**: http://arxiv.org/abs/1709.08127v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08127v1)
- **Published**: 2017-09-23 23:34:53+00:00
- **Updated**: 2017-09-23 23:34:53+00:00
- **Authors**: Yue Wu, Qiang Ji
- **Comment**: International Conference on Computer Vision, 2015
- **Journal**: None
- **Summary**: There have been tremendous improvements for facial landmark detection on general "in-the-wild" images. However, it is still challenging to detect the facial landmarks on images with severe occlusion and images with large head poses (e.g. profile face). In fact, the existing algorithms usually can only handle one of them. In this work, we propose a unified robust cascade regression framework that can handle both images with severe occlusion and images with large head poses. Specifically, the method iteratively predicts the landmark occlusions and the landmark locations. For occlusion estimation, instead of directly predicting the binary occlusion vectors, we introduce a supervised regression method that gradually updates the landmark visibility probabilities in each iteration to achieve robustness. In addition, we explicitly add occlusion pattern as a constraint to improve the performance of occlusion prediction. For landmark detection, we combine the landmark visibility probabilities, the local appearances, and the local shapes to iteratively update their positions. The experimental results show that the proposed method is significantly better than state-of-the-art works on images with severe occlusion and images with large head poses. It is also comparable to other methods on general "in-the-wild" images.



### Constrained Deep Transfer Feature Learning and its Applications
- **Arxiv ID**: http://arxiv.org/abs/1709.08128v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08128v1)
- **Published**: 2017-09-23 23:44:00+00:00
- **Updated**: 2017-09-23 23:44:00+00:00
- **Authors**: Yue Wu, Qiang Ji
- **Comment**: International Conference on Computer Vision and Pattern Recognition,
  2016
- **Journal**: None
- **Summary**: Feature learning with deep models has achieved impressive results for both data representation and classification for various vision tasks. Deep feature learning, however, typically requires a large amount of training data, which may not be feasible for some application domains. Transfer learning can be one of the approaches to alleviate this problem by transferring data from data-rich source domain to data-scarce target domain. Existing transfer learning methods typically perform one-shot transfer learning and often ignore the specific properties that the transferred data must satisfy. To address these issues, we introduce a constrained deep transfer feature learning method to perform simultaneous transfer learning and feature learning by performing transfer learning in a progressively improving feature space iteratively in order to better narrow the gap between the target domain and the source domain for effective transfer of the data from the source domain to target domain. Furthermore, we propose to exploit the target domain knowledge and incorporate such prior knowledge as a constraint during transfer learning to ensure that the transferred data satisfies certain properties of the target domain. To demonstrate the effectiveness of the proposed constrained deep transfer feature learning method, we apply it to thermal feature learning for eye detection by transferring from the visible domain. We also applied the proposed method for cross-view facial expression recognition as a second application. The experimental results demonstrate the effectiveness of the proposed method for both applications.



### Constrained Joint Cascade Regression Framework for Simultaneous Facial Action Unit Recognition and Facial Landmark Detection
- **Arxiv ID**: http://arxiv.org/abs/1709.08129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08129v1)
- **Published**: 2017-09-23 23:46:02+00:00
- **Updated**: 2017-09-23 23:46:02+00:00
- **Authors**: Yue Wu, Qiang Ji
- **Comment**: International Conference on Computer Vision and Pattern Recognition,
  2016
- **Journal**: None
- **Summary**: Cascade regression framework has been shown to be effective for facial landmark detection. It starts from an initial face shape and gradually predicts the face shape update from the local appearance features to generate the facial landmark locations in the next iteration until convergence. In this paper, we improve upon the cascade regression framework and propose the Constrained Joint Cascade Regression Framework (CJCRF) for simultaneous facial action unit recognition and facial landmark detection, which are two related face analysis tasks, but are seldomly exploited together. In particular, we first learn the relationships among facial action units and face shapes as a constraint. Then, in the proposed constrained joint cascade regression framework, with the help from the constraint, we iteratively update the facial landmark locations and the action unit activation probabilities until convergence. Experimental results demonstrate that the intertwined relationships of facial action units and face shapes boost the performances of both facial action unit recognition and facial landmark detection. The experimental results also demonstrate the effectiveness of the proposed method comparing to the state-of-the-art works.



### Simultaneous Facial Landmark Detection, Pose and Deformation Estimation under Facial Occlusion
- **Arxiv ID**: http://arxiv.org/abs/1709.08130v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.08130v1)
- **Published**: 2017-09-23 23:53:44+00:00
- **Updated**: 2017-09-23 23:53:44+00:00
- **Authors**: Yue Wu, Chao Gou, Qiang Ji
- **Comment**: International Conference on Computer Vision and Pattern Recognition,
  2017
- **Journal**: None
- **Summary**: Facial landmark detection, head pose estimation, and facial deformation analysis are typical facial behavior analysis tasks in computer vision. The existing methods usually perform each task independently and sequentially, ignoring their interactions. To tackle this problem, we propose a unified framework for simultaneous facial landmark detection, head pose estimation, and facial deformation analysis, and the proposed model is robust to facial occlusion. Following a cascade procedure augmented with model-based head pose estimation, we iteratively update the facial landmark locations, facial occlusion, head pose and facial de- formation until convergence. The experimental results on benchmark databases demonstrate the effectiveness of the proposed method for simultaneous facial landmark detection, head pose and facial deformation estimation, even if the images are under facial occlusion.



