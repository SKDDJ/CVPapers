# Arxiv Papers in cs.CV on 2017-09-09
### Simultaneously Learning Neighborship and Projection Matrix for Supervised Dimensionality Reduction
- **Arxiv ID**: http://arxiv.org/abs/1709.02896v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1709.02896v1)
- **Published**: 2017-09-09 02:44:18+00:00
- **Updated**: 2017-09-09 02:44:18+00:00
- **Authors**: Yanwei Pang, Bo Zhou, Feiping Nie
- **Comment**: None
- **Journal**: None
- **Summary**: Explicitly or implicitly, most of dimensionality reduction methods need to determine which samples are neighbors and the similarity between the neighbors in the original highdimensional space. The projection matrix is then learned on the assumption that the neighborhood information (e.g., the similarity) is known and fixed prior to learning. However, it is difficult to precisely measure the intrinsic similarity of samples in high-dimensional space because of the curse of dimensionality. Consequently, the neighbors selected according to such similarity might and the projection matrix obtained according to such similarity and neighbors are not optimal in the sense of classification and generalization. To overcome the drawbacks, in this paper we propose to let the similarity and neighbors be variables and model them in low-dimensional space. Both the optimal similarity and projection matrix are obtained by minimizing a unified objective function. Nonnegative and sum-to-one constraints on the similarity are adopted. Instead of empirically setting the regularization parameter, we treat it as a variable to be optimized. It is interesting that the optimal regularization parameter is adaptive to the neighbors in low-dimensional space and has intuitive meaning. Experimental results on the YALE B, COIL-100, and MNIST datasets demonstrate the effectiveness of the proposed method.



### Learning a Dilated Residual Network for SAR Image Despeckling
- **Arxiv ID**: http://arxiv.org/abs/1709.02898v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02898v3)
- **Published**: 2017-09-09 03:22:26+00:00
- **Updated**: 2018-01-24 03:06:32+00:00
- **Authors**: Qiang Zhang, Qiangqiang Yuan, Jie Li, Zhen Yang, Xiaoshuang Ma
- **Comment**: 18 pages, 13 figures, 7 tables
- **Journal**: None
- **Summary**: In this paper, to break the limit of the traditional linear models for synthetic aperture radar (SAR) image despeckling, we propose a novel deep learning approach by learning a non-linear end-to-end mapping between the noisy and clean SAR images with a dilated residual network (SAR-DRN). SAR-DRN is based on dilated convolutions, which can both enlarge the receptive field and maintain the filter size and layer depth with a lightweight structure. In addition, skip connections and residual learning strategy are added to the despeckling model to maintain the image details and reduce the vanishing gradient problem. Compared with the traditional despeckling methods, the proposed method shows superior performance over the state-of-the-art methods on both quantitative and visual assessments, especially for strong speckle noise.



### Image Processing Operations Identification via Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1709.02908v1
- **DOI**: 10.1007/s11432-018-9492-6
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.02908v1)
- **Published**: 2017-09-09 04:34:48+00:00
- **Updated**: 2017-09-09 04:34:48+00:00
- **Authors**: Bolin Chen, Haodong Li, Weiqi Luo
- **Comment**: None
- **Journal**: Sci. China Inf. Sci. 63, 139109 (2020)
- **Summary**: In recent years, image forensics has attracted more and more attention, and many forensic methods have been proposed for identifying image processing operations. Up to now, most existing methods are based on hand crafted features, and just one specific operation is considered in their methods. In many forensic scenarios, however, multiple classification for various image processing operations is more practical. Besides, it is difficult to obtain effective features by hand for some image processing operations. In this paper, therefore, we propose a new convolutional neural network (CNN) based method to adaptively learn discriminative features for identifying typical image processing operations. We carefully design the high pass filter bank to get the image residuals of the input image, the channel expansion layer to mix up the resulting residuals, the pooling layers, and the activation functions employed in our method. The extensive results show that the proposed method can outperform the currently best method based on hand crafted features and three related methods based on CNN for image steganalysis and/or forensics, achieving the state-of-the-art results. Furthermore, we provide more supplementary results to show the rationality and robustness of the proposed model.



### Graph Scaling Cut with L1-Norm for Classification of Hyperspectral Images
- **Arxiv ID**: http://arxiv.org/abs/1709.02920v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02920v1)
- **Published**: 2017-09-09 06:51:23+00:00
- **Updated**: 2017-09-09 06:51:23+00:00
- **Authors**: Ramanarayan Mohanty, S L Happy, Aurobinda Routray
- **Comment**: European Signal Processing Conference 2017
- **Journal**: None
- **Summary**: In this paper, we propose an L1 normalized graph based dimensionality reduction method for Hyperspectral images, called as L1-Scaling Cut (L1-SC). The underlying idea of this method is to generate the optimal projection matrix by retaining the original distribution of the data. Though L2-norm is generally preferred for computation, it is sensitive to noise and outliers. However, L1-norm is robust to them. Therefore, we obtain the optimal projection matrix by maximizing the ratio of between-class dispersion to within-class dispersion using L1-norm. Furthermore, an iterative algorithm is described to solve the optimization problem. The experimental results of the HSI classification confirm the effectiveness of the proposed L1-SC method on both noisy and noiseless data.



### Joint Calibration of Panoramic Camera and Lidar Based on Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1709.02926v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02926v2)
- **Published**: 2017-09-09 08:08:36+00:00
- **Updated**: 2017-09-13 08:19:47+00:00
- **Authors**: Mingwei Cao, Ming Yang, Chunxiang Wang, Yeqiang Qian, Bing Wang
- **Comment**: in Chinese
- **Journal**: None
- **Summary**: In view of contemporary panoramic camera-laser scanner system, the traditional calibration method is not suitable for panoramic cameras whose imaging model is extremely nonlinear. The method based on statistical optimization has the disadvantage that the requirement of the number of laser scanner's channels is relatively high. Calibration equipments with extreme accuracy for panoramic camera-laser scanner system are costly. Facing all these in the calibration of panoramic camera-laser scanner system, a method based on supervised learning is proposed. Firstly, corresponding feature points of panoramic images and point clouds are gained to generate the training dataset by designing a round calibration object. Furthermore, the traditional calibration problem is transformed into a multiple nonlinear regression optimization problem by designing a supervised learning network with preprocessing of the panoramic imaging model. Back propagation algorithm is utilized to regress the rotation and translation matrix with high accuracy. Experimental results show that this method can quickly regress the calibration parameters and the accuracy is better than the traditional calibration method and the method based on statistical optimization. The calibration accuracy of this method is really high, and it is more highly-automated.



### Model Distillation with Knowledge Transfer from Face Classification to Alignment and Verification
- **Arxiv ID**: http://arxiv.org/abs/1709.02929v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02929v2)
- **Published**: 2017-09-09 08:30:18+00:00
- **Updated**: 2017-10-23 07:51:29+00:00
- **Authors**: Chong Wang, Xipeng Lan, Yangang Zhang
- **Comment**: 10 pages, 1 figures
- **Journal**: None
- **Summary**: Knowledge distillation is a potential solution for model compression. The idea is to make a small student network imitate the target of a large teacher network, then the student network can be competitive to the teacher one. Most previous studies focus on model distillation in the classification task, where they propose different architects and initializations for the student network. However, only the classification task is not enough, and other related tasks such as regression and retrieval are barely considered. To solve the problem, in this paper, we take face recognition as a breaking point and propose model distillation with knowledge transfer from face classification to alignment and verification. By selecting appropriate initializations and targets in the knowledge transfer, the distillation can be easier in non-classification tasks. Experiments on the CelebA and CASIA-WebFace datasets demonstrate that the student network can be competitive to the teacher one in alignment and verification, and even surpasses the teacher network under specific compression rates. In addition, to achieve stronger knowledge transfer, we also use a common initialization trick to improve the distillation performance of classification. Evaluations on the CASIA-Webface and large-scale MS-Celeb-1M datasets show the effectiveness of this simple trick.



### Urban morphology meets deep learning: Exploring urban forms in one million cities, town and villages across the planet
- **Arxiv ID**: http://arxiv.org/abs/1709.02939v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1709.02939v2)
- **Published**: 2017-09-09 10:06:48+00:00
- **Updated**: 2017-09-12 10:30:20+00:00
- **Authors**: Vahid Moosavi
- **Comment**: 10 pages, 10 figures
- **Journal**: None
- **Summary**: Study of urban form is an important area of research in urban planning/design that contributes to our understanding of how cities function and evolve. However, classical approaches are based on very limited observations and inconsistent methods. As an alternative, availability of massive urban data collections such as Open Street Map from the one hand and the recent advancements in machine learning methods such as deep learning techniques on the other have opened up new possibilities to automatically investigate urban forms at the global scale. In this work for the first time, by collecting a large data set of street networks in more than one million cities, towns and villages all over the world, we trained a deep convolutional auto-encoder, that automatically learns the hierarchical structures of urban forms and represents them via dense and comparable vectors. We showed how the learned urban vectors could be used for different investigations. Using the learned urban vectors, one is able to easily find and compare similar urban forms all over the world, considering their overall spatial structure and other factors such as orientation, graphical structure, and density and partial deformations. Further cluster analysis reveals the distribution of the main patterns of urban forms all over the planet.



### How to Train Triplet Networks with 100K Identities?
- **Arxiv ID**: http://arxiv.org/abs/1709.02940v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02940v1)
- **Published**: 2017-09-09 10:18:41+00:00
- **Updated**: 2017-09-09 10:18:41+00:00
- **Authors**: Chong Wang, Xue Zhang, Xipeng Lan
- **Comment**: 9 pages, 9 figures
- **Journal**: None
- **Summary**: Training triplet networks with large-scale data is challenging in face recognition. Due to the number of possible triplets explodes with the number of samples, previous studies adopt the online hard negative mining(OHNM) to handle it. However, as the number of identities becomes extremely large, the training will suffer from bad local minima because effective hard triplets are difficult to be found. To solve the problem, in this paper, we propose training triplet networks with subspace learning, which splits the space of all identities into subspaces consisting of only similar identities. Combined with the batch OHNM, hard triplets can be found much easier. Experiments on the large-scale MS-Celeb-1M challenge with 100K identities demonstrate that the proposed method can largely improve the performance. In addition, to deal with heavy noise and large-scale retrieval, we also make some efforts on robust noise removing and efficient image retrieval, which are used jointly with the subspace learning to obtain the state-of-the-art performance on the MS-Celeb-1M competition (without external data in Challenge1).



### Improving precision and recall of face recognition in SIPP with combination of modified mean search and LSH
- **Arxiv ID**: http://arxiv.org/abs/1709.03872v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.03872v2)
- **Published**: 2017-09-09 11:42:28+00:00
- **Updated**: 2018-02-27 16:33:02+00:00
- **Authors**: Xihua Li
- **Comment**: None
- **Journal**: None
- **Summary**: Although face recognition has been improved much as the development of Deep Neural Networks, SIPP(Single Image Per Person) problem in face recognition has not been better solved, especially in practical applications where searching over complicated database. In this paper, a combination of modified mean search and LSH method would be introduced orderly to improve the precision and recall of SIPP face recognition without retrain of the DNN model. First, a modified SVD based augmentation method would be introduced to get more intra-class variations even for person with only one image. Second, an unique rule based combination of modified mean search and LSH method was proposed the first time to help get the most similar personID in a complicated dataset, and some theoretical explaining followed. Third, we would like to emphasize, no need to retrain of the DNN model and would easy to be extended without much efforts. We do some practical testing in competition of Msceleb challenge-2 2017 which was hold by Microsoft Research, great improvement of coverage from 13.39% to 19.25%, 29.94%, 42.11%, 47.52% at precision 99%(P99) would be shown latter, coverage reach 94.2% and 100% at precision 97%(P97) and 95%(P95) respectively. As far as we known, this is the only paper who do not fine-tuning on competition dataset and ranked top-10. A similar test on CASIA WebFace dataset also demonstrated the same improvements on both precision and recall.



### Sequential 3D U-Nets for Biologically-Informed Brain Tumor Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1709.02967v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02967v1)
- **Published**: 2017-09-09 15:57:51+00:00
- **Updated**: 2017-09-09 15:57:51+00:00
- **Authors**: Andrew Beers, Ken Chang, James Brown, Emmett Sartor, CP Mammen, Elizabeth Gerstner, Bruce Rosen, Jayashree Kalpathy-Cramer
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning has quickly become the weapon of choice for brain lesion segmentation. However, few existing algorithms pre-configure any biological context of their chosen segmentation tissues, and instead rely on the neural network's optimizer to develop such associations de novo. We present a novel method for applying deep neural networks to the problem of glioma tissue segmentation that takes into account the structured nature of gliomas - edematous tissue surrounding mutually-exclusive regions of enhancing and non-enhancing tumor. We trained multiple deep neural networks with a 3D U-Net architecture in a tree structure to create segmentations for edema, non-enhancing tumor, and enhancing tumor regions. Specifically, training was configured such that the whole tumor region including edema was predicted first, and its output segmentation was fed as input into separate models to predict enhancing and non-enhancing tumor. Our method was trained and evaluated on the publicly available BraTS dataset, achieving Dice scores of 0.882, 0.732, and 0.730 for whole tumor, enhancing tumor and tumor core respectively.



### Large Scale Image Segmentation with Structured Loss based Deep Learning for Connectome Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1709.02974v4
- **DOI**: 10.1109/TPAMI.2018.2835450
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02974v4)
- **Published**: 2017-09-09 16:25:52+00:00
- **Updated**: 2020-07-28 09:21:55+00:00
- **Authors**: Jan Funke, Fabian David Tschopp, William Grisaitis, Arlo Sheridan, Chandan Singh, Stephan Saalfeld, Srinivas C. Turaga
- **Comment**: None
- **Journal**: None
- **Summary**: We present a method combining affinity prediction with region agglomeration, which improves significantly upon the state of the art of neuron segmentation from electron microscopy (EM) in accuracy and scalability. Our method consists of a 3D U-NET, trained to predict affinities between voxels, followed by iterative region agglomeration. We train using a structured loss based on MALIS, encouraging topologically correct segmentations obtained from affinity thresholding. Our extension consists of two parts: First, we present a quasi-linear method to compute the loss gradient, improving over the original quadratic algorithm. Second, we compute the gradient in two separate passes to avoid spurious gradient contributions in early training stages. Our predictions are accurate enough that simple learning-free percentile-based agglomeration outperforms more involved methods used earlier on inferior predictions. We present results on three diverse EM datasets, achieving relative improvements over previous results of 27%, 15%, and 250%. Our findings suggest that a single method can be applied to both nearly isotropic block-face EM data and anisotropic serial sectioned EM data. The runtime of our method scales linearly with the size of the volume and achieves a throughput of about 2.6 seconds per megavoxel, qualifying our method for the processing of very large datasets.



### Can you tell a face from a HEVC bitstream?
- **Arxiv ID**: http://arxiv.org/abs/1709.02993v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02993v1)
- **Published**: 2017-09-09 18:43:52+00:00
- **Updated**: 2017-09-09 18:43:52+00:00
- **Authors**: Saeed Ranjbar Alvar, Hyomin Choi, Ivan V. Bajic
- **Comment**: None
- **Journal**: None
- **Summary**: Image and video analytics are being increasingly used on a massive scale. Not only is the amount of data growing, but the complexity of the data processing pipelines is also increasing, thereby exacerbating the problem. It is becoming increasingly important to save computational resources wherever possible. We focus on one of the poster problems of visual analytics -- face detection -- and approach the issue of reducing the computation by asking: Is it possible to detect a face without full image reconstruction from the High Efficiency Video Coding (HEVC) bitstream? We demonstrate that this is indeed possible, with accuracy comparable to conventional face detection, by training a Convolutional Neural Network on the output of the HEVC entropy decoder.



### Optimal Transport for Deep Joint Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/1709.02995v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02995v1)
- **Published**: 2017-09-09 18:56:05+00:00
- **Updated**: 2017-09-09 18:56:05+00:00
- **Authors**: Ying Lu, Liming Chen, Alexandre Saidi
- **Comment**: None
- **Journal**: None
- **Summary**: Training a Deep Neural Network (DNN) from scratch requires a large amount of labeled data. For a classification task where only small amount of training data is available, a common solution is to perform fine-tuning on a DNN which is pre-trained with related source data. This consecutive training process is time consuming and does not consider explicitly the relatedness between different source and target tasks.   In this paper, we propose a novel method to jointly fine-tune a Deep Neural Network with source data and target data. By adding an Optimal Transport loss (OT loss) between source and target classifier predictions as a constraint on the source classifier, the proposed Joint Transfer Learning Network (JTLN) can effectively learn useful knowledge for target classification from source data. Furthermore, by using different kind of metric as cost matrix for the OT loss, JTLN can incorporate different prior knowledge about the relatedness between target categories and source categories.   We carried out experiments with JTLN based on Alexnet on image classification datasets and the results verify the effectiveness of the proposed JTLN in comparison with standard consecutive fine-tuning. This Joint Transfer Learning with OT loss is general and can also be applied to other kind of Neural Networks.



### How to Train a CAT: Learning Canonical Appearance Transformations for Direct Visual Localization Under Illumination Change
- **Arxiv ID**: http://arxiv.org/abs/1709.03009v6
- **DOI**: 10.1109/LRA.2018.2799741
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.03009v6)
- **Published**: 2017-09-09 21:58:12+00:00
- **Updated**: 2022-07-04 03:22:46+00:00
- **Authors**: Lee Clement, Jonathan Kelly
- **Comment**: In IEEE Robotics and Automation Letters (RA-L) and presented at the
  IEEE International Conference on Robotics and Automation (ICRA'18), Brisbane,
  Australia, May 21-25, 2018
- **Journal**: IEEE Robotics and Automation Letters (RA-L), Vol. 3, No. 3, pp.
  2447-2454, Jul. 2018
- **Summary**: Direct visual localization has recently enjoyed a resurgence in popularity with the increasing availability of cheap mobile computing power. The competitive accuracy and robustness of these algorithms compared to state-of-the-art feature-based methods, as well as their natural ability to yield dense maps, makes them an appealing choice for a variety of mobile robotics applications. However, direct methods remain brittle in the face of appearance change due to their underlying assumption of photometric consistency, which is commonly violated in practice. In this paper, we propose to mitigate this problem by training deep convolutional encoder-decoder models to transform images of a scene such that they correspond to a previously-seen canonical appearance. We validate our method in multiple environments and illumination conditions using high-fidelity synthetic RGB-D datasets, and integrate the trained models into a direct visual localization pipeline, yielding improvements in visual odometry (VO) accuracy through time-varying illumination conditions, as well as improved metric relocalization performance under illumination change, where conventional methods normally fail. We further provide a preliminary investigation of transfer learning from synthetic to real environments in a localization context. An open-source implementation of our method using PyTorch is available at https://github.com/utiasSTARS/cat-net.



