# Arxiv Papers in cs.CV on 2017-09-08
### DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets
- **Arxiv ID**: http://arxiv.org/abs/1709.02495v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02495v1)
- **Published**: 2017-09-08 01:15:16+00:00
- **Updated**: 2017-09-08 01:15:16+00:00
- **Authors**: Ali Mahdi, Jun Qin
- **Comment**: 9 pages, 7 figures, submitted to IEEE transactions on cognitive
  developmental systems
- **Journal**: None
- **Summary**: A deep feature based saliency model (DeepFeat) is developed to leverage the understanding of the prediction of human fixations. Traditional saliency models often predict the human visual attention relying on few level image cues. Although such models predict fixations on a variety of image complexities, their approaches are limited to the incorporated features. In this study, we aim to provide an intuitive interpretation of convolu- tional neural network deep features by combining low and high level visual factors. We exploit four evaluation metrics to evaluate the correspondence between the proposed framework and the ground-truth fixations. The key findings of the results demon- strate that the DeepFeat algorithm, incorporation of bottom up and top down saliency maps, outperforms the individual bottom up and top down approach. Moreover, in comparison to nine 9 state-of-the-art saliency models, our proposed DeepFeat model achieves satisfactory performance based on all four evaluation metrics.



### Deep Subspace Clustering Networks
- **Arxiv ID**: http://arxiv.org/abs/1709.02508v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02508v1)
- **Published**: 2017-09-08 02:22:22+00:00
- **Updated**: 2017-09-08 02:22:22+00:00
- **Authors**: Pan Ji, Tong Zhang, Hongdong Li, Mathieu Salzmann, Ian Reid
- **Comment**: Accepted to NIPS'17
- **Journal**: None
- **Summary**: We present a novel deep neural network architecture for unsupervised subspace clustering. This architecture is built upon deep auto-encoders, which non-linearly map the input data into a latent space. Our key idea is to introduce a novel self-expressive layer between the encoder and the decoder to mimic the "self-expressiveness" property that has proven effective in traditional subspace clustering. Being differentiable, our new self-expressive layer provides a simple but effective way to learn pairwise affinities between all data points through a standard back-propagation procedure. Being nonlinear, our neural-network based method is able to cluster data points having complex (often nonlinear) structures. We further propose pre-training and fine-tuning strategies that let us effectively learn the parameters of our subspace clustering networks. Our experiments show that the proposed method significantly outperforms the state-of-the-art unsupervised subspace clustering methods.



### Extreme Sparse Multinomial Logistic Regression: A Fast and Robust Framework for Hyperspectral Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1709.02517v2
- **DOI**: 10.3390/rs9121255
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02517v2)
- **Published**: 2017-09-08 03:16:52+00:00
- **Updated**: 2017-09-27 07:32:27+00:00
- **Authors**: Faxian Cao, Zhijing Yang, Jinchang Ren, Wing-Kuen Ling
- **Comment**: 14 pages,7 figures,4 tables
- **Journal**: Remote sensing,9,2017,1255
- **Summary**: Although the sparse multinomial logistic regression (SMLR) has provided a useful tool for sparse classification, it suffers from inefficacy in dealing with high dimensional features and manually set initial regressor values. This has significantly constrained its applications for hyperspectral image (HSI) classification. In order to tackle these two drawbacks, an extreme sparse multinomial logistic regression (ESMLR) is proposed for effective classification of HSI. First, the HSI dataset is projected to a new feature space with randomly generated weight and bias. Second, an optimization model is established by the Lagrange multiplier method and the dual principle to automatically determine a good initial regressor for SMLR via minimizing the training error and the regressor value. Furthermore, the extended multi-attribute profiles (EMAPs) are utilized for extracting both the spectral and spatial features. A combinational linear multiple features learning (MFL) method is proposed to further enhance the features extracted by ESMLR and EMAPs. Finally, the logistic regression via the variable splitting and the augmented Lagrangian (LORSAL) is adopted in the proposed framework for reducing the computational time. Experiments are conducted on two well-known HSI datasets, namely the Indian Pines dataset and the Pavia University dataset, which have shown the fast and robust performance of the proposed ESMLR framework.



### A Novel Low-Complexity Framework in Ultra-Wideband Imaging for Breast Cancer Detection
- **Arxiv ID**: http://arxiv.org/abs/1709.02549v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02549v1)
- **Published**: 2017-09-08 05:45:15+00:00
- **Updated**: 2017-09-08 05:45:15+00:00
- **Authors**: Yasaman Ettefagh, Mohammad Hossein Moghaddam, Saeed Vahidian
- **Comment**: None
- **Journal**: None
- **Summary**: In this research work, a novel framework is pro- posed as an efficient successor to traditional imaging methods for breast cancer detection in order to decrease the computational complexity. In this framework, the breast is devided into seg- ments in an iterative process and in each iteration, the one having the most probability of containing tumor with lowest possible resolution is selected by using suitable decision metrics. After finding the smallest tumor-containing segment, the resolution is increased in the detected tumor-containing segment, leaving the other parts of the breast image with low resolution. Our framework is applied on the most common used beamforming techniques, such as delay and sum (DAS) and delay multiply and sum (DMAS) and according to simulation results, our framework can decrease the computational complexity significantly for both DAS and DMAS without imposing any degradation on accuracy of basic algorithms. The amount of complexity reduction can be determined manually or automatically based on two proposed methods that are described in this framework.



### Learning to Segment Breast Biopsy Whole Slide Images
- **Arxiv ID**: http://arxiv.org/abs/1709.02554v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02554v2)
- **Published**: 2017-09-08 06:20:23+00:00
- **Updated**: 2017-10-10 22:22:06+00:00
- **Authors**: Sachin Mehta, Ezgi Mercan, Jamen Bartlett, Donald Weaver, Joann Elmore, Linda Shapiro
- **Comment**: Added more WSI images in appendix
- **Journal**: None
- **Summary**: We trained and applied an encoder-decoder model to semantically segment breast biopsy images into biologically meaningful tissue labels. Since conventional encoder-decoder networks cannot be applied directly on large biopsy images and the different sized structures in biopsies present novel challenges, we propose four modifications: (1) an input-aware encoding block to compensate for information loss, (2) a new dense connection pattern between encoder and decoder, (3) dense and sparse decoders to combine multi-level features, (4) a multi-resolution network that fuses the results of encoder-decoders run on different resolutions. Our model outperforms a feature-based approach and conventional encoder-decoders from the literature. We use semantic segmentations produced with our model in an automated diagnosis task and obtain higher accuracies than a baseline approach that employs an SVM for feature-based segmentation, both using the same segmentation-based diagnostic features.



### Low-memory GEMM-based convolution algorithms for deep neural networks
- **Arxiv ID**: http://arxiv.org/abs/1709.03395v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.03395v1)
- **Published**: 2017-09-08 06:32:33+00:00
- **Updated**: 2017-09-08 06:32:33+00:00
- **Authors**: Andrew Anderson, Aravind Vasudevan, Cormac Keane, David Gregg
- **Comment**: 13 pages, 16 figures and 3 tables. arXiv admin note: text overlap
  with arXiv:1704.04428
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) require very large amounts of computation both for training and for inference when deployed in the field. A common approach to implementing DNNs is to recast the most computationally expensive operations as general matrix multiplication (GEMM). However, as we demonstrate in this paper, there are a great many different ways to express DNN convolution operations using GEMM. Although different approaches all perform the same number of operations, the size of temporary data structures differs significantly. Convolution of an input matrix with dimensions $C \times H \times W$, requires $O(K^2CHW)$ additional space using the classical im2col approach. More recently memory-efficient approaches requiring just $O(KCHW)$ auxiliary space have been proposed.   We present two novel GEMM-based algorithms that require just $O(MHW)$ and $O(KW)$ additional space respectively, where $M$ is the number of channels in the result of the convolution. These algorithms dramatically reduce the space overhead of DNN convolution, making it much more suitable for memory-limited embedded systems. Experimental evaluation shows that our low-memory algorithms are just as fast as the best patch-building approaches despite requiring just a fraction of the amount of additional memory. Our low-memory algorithms have excellent data locality which gives them a further edge over patch-building algorithms when multiple cores are used. As a result, our low memory algorithms often outperform the best patch-building algorithms using multiple threads.



### Segmentation and Classification of Cine-MR Images Using Fully Convolutional Networks and Handcrafted Features
- **Arxiv ID**: http://arxiv.org/abs/1709.02565v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02565v2)
- **Published**: 2017-09-08 06:56:01+00:00
- **Updated**: 2017-09-11 07:54:23+00:00
- **Authors**: M. Hossein Eybposh, Mohammad Haghir Ebrahim-Abadi, Mohammad Jalilpour-Monesi, Seyed Saman Saboksayr
- **Comment**: 9 pages, 3 figures, 2 tables. Was accepted to the ACDC challenge,
  MICCAI 2017 (not attended)
- **Journal**: None
- **Summary**: Three-dimensional cine-MRI is of crucial importance for assessing the cardiac function. Features that describe the anatomy and function of cardiac structures (e.g. Left Ventricle (LV), Right Ventricle (RV), and Myocardium(MC)) are known to have significant diagnostic value and can be computed from 3D cine-MR images. However, these features require precise segmentation of cardiac structures. Among the fully automated segmentation methods, Fully Convolutional Networks (FCN) with Skip Connections have shown robustness in medical segmentation problems. In this study, we develop a complete pipeline for classification of subjects with cardiac conditions based on 3D cine-MRI. For the segmentation task, we develop a 2D FCN and introduce Parallel Paths (PP) as a way to exploit the 3D information of the cine-MR image. For the classification task, 125 features were extracted from the segmented structures, describing their anatomy and function. Next, a two-stage pipeline for feature selection using the LASSO method is developed. A subset of 20 features is selected for classification. Each subject is classified using an ensemble of Logistic Regression, Multi-Layer Perceptron, and Support Vector Machine classifiers through majority voting. The Dice Coefficient for segmentation was 0.95+-0.03, 0.89+-0.13, and 0.90+-0.03 for LV, RV, and MC respectively. The 8-fold cross validation accuracy for the classification task was 95.05% and 92.77% based on ground truth and the proposed methods segmentations respectively. The results show that the PPs increase the segmentation accuracy, by exploiting the spatial relations. Moreover, the classification algorithm and the features showed discriminability while keeping the sensitivity to segmentation error as low as possible.



### Objectness Scoring and Detection Proposals in Forward-Looking Sonar Images with Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1709.02600v1
- **DOI**: 10.1007/978-3-319-46182-3_18
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1709.02600v1)
- **Published**: 2017-09-08 09:11:32+00:00
- **Updated**: 2017-09-08 09:11:32+00:00
- **Authors**: Matias Valdenegro-Toro
- **Comment**: Author version
- **Journal**: Proceedings of ANNPR 2016
- **Summary**: Forward-looking sonar can capture high resolution images of underwater scenes, but their interpretation is complex. Generic object detection in such images has not been solved, specially in cases of small and unknown objects. In comparison, detection proposal algorithms have produced top performing object detectors in real-world color images. In this work we develop a Convolutional Neural Network that can reliably score objectness of image windows in forward-looking sonar images and by thresholding objectness, we generate detection proposals. In our dataset of marine garbage objects, we obtain 94% recall, generating around 60 proposals per image. The biggest strength of our method is that it can generalize to previously unseen objects. We show this by detecting chain links, walls and a wrench without previous training in such objects. We strongly believe our method can be used for class-independent object detection, with many real-world applications such as chain following and mine detection.



### Best Practices in Convolutional Networks for Forward-Looking Sonar Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1709.02601v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02601v1)
- **Published**: 2017-09-08 09:14:25+00:00
- **Updated**: 2017-09-08 09:14:25+00:00
- **Authors**: Matias Valdenegro-Toro
- **Comment**: Author version; IEEE/MTS Oceans 2017 Aberdeen
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNN) have revolutionized perception for color images, and their application to sonar images has also obtained good results. But in general CNNs are difficult to train without a large dataset, need manual tuning of a considerable number of hyperparameters, and require many careful decisions by a designer. In this work, we evaluate three common decisions that need to be made by a CNN designer, namely the performance of transfer learning, the effect of object/image size and the relation between training set size. We evaluate three CNN models, namely one based on LeNet, and two based on the Fire module from SqueezeNet. Our findings are: Transfer learning with an SVM works very well, even when the train and transfer sets have no classes in common, and high classification performance can be obtained even when the target dataset is small. The ADAM optimizer combined with Batch Normalization can make a high accuracy CNN classifier, even with small image sizes (16 pixels). At least 50 samples per class are required to obtain $90\%$ test accuracy, and using Dropout with a small dataset helps improve performance, but Batch Normalization is better when a large dataset is available.



### Calibration of depth cameras using denoised depth images
- **Arxiv ID**: http://arxiv.org/abs/1709.02635v1
- **DOI**: 10.1109/ICIP.2014.7025702
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02635v1)
- **Published**: 2017-09-08 10:34:11+00:00
- **Updated**: 2017-09-08 10:34:11+00:00
- **Authors**: Ramanpreet Singh Pahwa, Minh N. Do, Tian Tsong Ng, Binh-Son Hua
- **Comment**: 5 pages, 3 figures, conference
- **Journal**: 2014 IEEE International Conference on Image Processing (ICIP),
  Paris, 2014, pp. 3459-3463
- **Summary**: Depth sensing devices have created various new applications in scientific and commercial research with the advent of Microsoft Kinect and PMD (Photon Mixing Device) cameras. Most of these applications require the depth cameras to be pre-calibrated. However, traditional calibration methods using a checkerboard do not work very well for depth cameras due to the low image resolution. In this paper, we propose a depth calibration scheme which excels in estimating camera calibration parameters when only a handful of corners and calibration images are available. We exploit the noise properties of PMD devices to denoise depth measurements and perform camera calibration using the denoised depth as an additional set of measurements. Our synthetic and real experiments show that our depth denoising and depth based calibration scheme provides significantly better results than traditional calibration methods.



### Completion of High Order Tensor Data with Missing Entries via Tensor-train Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1709.02641v2
- **DOI**: None
- **Categories**: **cs.NA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.02641v2)
- **Published**: 2017-09-08 10:48:56+00:00
- **Updated**: 2017-09-14 12:36:41+00:00
- **Authors**: Longhao Yuan, Qibin Zhao, Jianting Cao
- **Comment**: 8 pages, ICONIP 2017
- **Journal**: None
- **Summary**: In this paper, we aim at the completion problem of high order tensor data with missing entries. The existing tensor factorization and completion methods suffer from the curse of dimensionality when the order of tensor N>>3. To overcome this problem, we propose an efficient algorithm called TT-WOPT (Tensor-train Weighted OPTimization) to find the latent core tensors of tensor data and recover the missing entries. Tensor-train decomposition, which has the powerful representation ability with linear scalability to tensor order, is employed in our algorithm. The experimental results on synthetic data and natural image completion demonstrate that our method significantly outperforms the other related methods. Especially when the missing rate of data is very high, e.g., 85% to 99%, our algorithm can achieve much better performance than other state-of-the-art algorithms.



### Locating 3D Object Proposals: A Depth-Based Online Approach
- **Arxiv ID**: http://arxiv.org/abs/1709.02653v1
- **DOI**: 10.1109/TCSVT.2016.2616143
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02653v1)
- **Published**: 2017-09-08 11:24:32+00:00
- **Updated**: 2017-09-08 11:24:32+00:00
- **Authors**: Ramanpreet Singh Pahwa, Jiangbo Lu, Nianjuan Jiang, Tian Tsong Ng, Minh N. Do
- **Comment**: 14 pages, 12 figures, journal
- **Journal**: IEEE Transactions on Circuits and Systems for Video Technology,
  2016
- **Summary**: 2D object proposals, quickly detected regions in an image that likely contain an object of interest, are an effective approach for improving the computational efficiency and accuracy of object detection in color images. In this work, we propose a novel online method that generates 3D object proposals in a RGB-D video sequence. Our main observation is that depth images provide important information about the geometry of the scene. Diverging from the traditional goal of 2D object proposals to provide a high recall (lots of 2D bounding boxes near potential objects), we aim for precise 3D proposals. We leverage on depth information per frame and multi-view scene information to obtain accurate 3D object proposals. Using efficient but robust registration enables us to combine multiple frames of a scene in near real time and generate 3D bounding boxes for potential 3D regions of interest. Using standard metrics, such as Precision-Recall curves and F-measure, we show that the proposed approach is significantly more accurate than the current state-of-the-art techniques. Our online approach can be integrated into SLAM based video processing for quick 3D object localization. Our method takes less than a second in MATLAB on the UW-RGBD scene dataset on a single thread CPU and thus, has potential to be used in low-power chips in Unmanned Aerial Vehicles (UAVs), quadcopters, and drones.



### Method to Detect Eye Position Noise from Video-Oculography when Detection of Pupil or Corneal Reflection Position Fails
- **Arxiv ID**: http://arxiv.org/abs/1709.02700v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02700v1)
- **Published**: 2017-09-08 13:39:14+00:00
- **Updated**: 2017-09-08 13:39:14+00:00
- **Authors**: Evgeny Abdulin, Lee Friedman, Oleg V. Komogortsev
- **Comment**: 9 figures, 20 pages, pseudocode and Matlab code
- **Journal**: None
- **Summary**: We present software to detect noise in eye position signals from video-based eye-tracking systems that depend on accurate pupil and corneal reflection position estimation. When such systems transiently fail to properly detect the pupil or the corneal reflection due to occlusion from eyelids, eye lashes or various shadows, the estimated gaze position is false. This produces an artifactual signal in the position trace that is rapidly, irregularly oscillating between true and false gaze positions. We refer to this noise as RIONEPS (Rapid Irregularly Oscillating Noise of the Eye Position Signal). Our method for detecting these periods automatically is based on an estimate of the relative inefficiency of the eye position signal. We look for RIONEPS in the horizontal and vertical traces separately, and although we typically use it offline, it is suitable to adaptation for real time use. This method requires a threshold to be set, and although we provide some guidance, thresholds will have to be estimated empirically.



### Vessel Segmentation and Catheter Detection in X-Ray Angiograms Using Superpixels
- **Arxiv ID**: http://arxiv.org/abs/1709.02741v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02741v1)
- **Published**: 2017-09-08 15:22:36+00:00
- **Updated**: 2017-09-08 15:22:36+00:00
- **Authors**: Hamid R. Fazlali, Nader Karimi, S. M. Reza Soroushmehr, Shahram Shirani, Brahmajee. K. Nallamothu, Kevin R. Ward, Shadrokh Samavi, Kayvan Najarian
- **Comment**: 14 Pages, 19 figures, 2 tables
- **Journal**: None
- **Summary**: Coronary artery disease (CAD) is the leading causes of death around the world. One of the most common imaging methods for diagnosing this disease is X-ray angiography. Diagnosing using these images is usually challenging due to non-uniform illumination, low contrast, presence of other body tissues, presence of catheter etc. These challenges make the diagnoses task of cardiologists tougher and more prone to misdiagnosis. In this paper we propose a new automated framework for coronary arteries segmentation, catheter detection and center-line extraction in x-ray angiography images. Our proposed segmentation method is based on superpixels. In this method at first three different superpixel scales are exploited and a measure for vesselness probability of each superpixel is determined. A majority voting is used for obtaining an initial segmentation map from these three superpixel scales. This initial segmentation is refined by finding the orthogonal line on each ridge pixel of vessel region. In this framework we use our catheter detection and tracking method which detects the catheter by finding its ridge in the first frame and traces in other frames by fitting a second order polynomial on it. Also we use the image ridges for extracting the coronary arteries centerlines. We evaluated our method qualitatively and quantitatively on two different challenging datasets and compared it with one of the previous well-known coronary arteries segmentation methods. Our method could detect the catheter and reduced the false positive rate in addition to achieving better segmentation results. The evaluation results prove that our method performs better in a much shorter time.



### An Adaptive Sampling Scheme to Efficiently Train Fully Convolutional Networks for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1709.02764v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02764v4)
- **Published**: 2017-09-08 16:17:55+00:00
- **Updated**: 2017-12-22 14:16:07+00:00
- **Authors**: Lorenz Berger, Eoin Hyde, M. Jorge Cardoso, Sebastien Ourselin
- **Comment**: None
- **Journal**: None
- **Summary**: Deep convolutional neural networks (CNNs) have shown excellent performance in object recognition tasks and dense classification problems such as semantic segmentation. However, training deep neural networks on large and sparse datasets is still challenging and can require large amounts of computation and memory. In this work, we address the task of performing semantic segmentation on large data sets, such as three-dimensional medical images. We propose an adaptive sampling scheme that uses a-posterior error maps, generated throughout training, to focus sampling on difficult regions, resulting in improved learning. Our contribution is threefold: 1) We give a detailed description of the proposed sampling algorithm to speed up and improve learning performance on large images. We propose a deep dual path CNN that captures information at fine and coarse scales, resulting in a network with a large field of view and high resolution outputs. We show that our method is able to attain new state-of-the-art results on the VISCERAL Anatomy benchmark.



### Machine learning \& artificial intelligence in the quantum domain
- **Arxiv ID**: http://arxiv.org/abs/1709.02779v1
- **DOI**: None
- **Categories**: **quant-ph**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1709.02779v1)
- **Published**: 2017-09-08 16:53:24+00:00
- **Updated**: 2017-09-08 16:53:24+00:00
- **Authors**: Vedran Dunjko, Hans J. Briegel
- **Comment**: Review paper. 106 pages. 16 figures
- **Journal**: None
- **Summary**: Quantum information technologies, and intelligent learning systems, are both emergent technologies that will likely have a transforming impact on our society. The respective underlying fields of research -- quantum information (QI) versus machine learning (ML) and artificial intelligence (AI) -- have their own specific challenges, which have hitherto been investigated largely independently. However, in a growing body of recent work, researchers have been probing the question to what extent these fields can learn and benefit from each other. QML explores the interaction between quantum computing and ML, investigating how results and techniques from one field can be used to solve the problems of the other. Recently, we have witnessed breakthroughs in both directions of influence. For instance, quantum computing is finding a vital application in providing speed-ups in ML, critical in our "big data" world. Conversely, ML already permeates cutting-edge technologies, and may become instrumental in advanced quantum technologies. Aside from quantum speed-up in data analysis, or classical ML optimization used in quantum experiments, quantum enhancements have also been demonstrated for interactive learning, highlighting the potential of quantum-enhanced learning agents. Finally, works exploring the use of AI for the very design of quantum experiments, and for performing parts of genuine research autonomously, have reported their first successes. Beyond the topics of mutual enhancement, researchers have also broached the fundamental issue of quantum generalizations of ML/AI concepts. This deals with questions of the very meaning of learning and intelligence in a world that is described by quantum mechanics. In this review, we describe the main ideas, recent developments, and progress in a broad spectrum of research investigating machine learning and artificial intelligence in the quantum domain.



### Detecting Hands in Egocentric Videos: Towards Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1709.02780v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02780v1)
- **Published**: 2017-09-08 17:08:15+00:00
- **Updated**: 2017-09-08 17:08:15+00:00
- **Authors**: Alejandro Cartas, Mariella Dimiccoli, Petia Radeva
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, there has been a growing interest in analyzing human daily activities from data collected by wearable cameras. Since the hands are involved in a vast set of daily tasks, detecting hands in egocentric images is an important step towards the recognition of a variety of egocentric actions. However, besides extreme illumination changes in egocentric images, hand detection is not a trivial task because of the intrinsic large variability of hand appearance. We propose a hand detector that exploits skin modeling for fast hand proposal generation and Convolutional Neural Networks for hand recognition. We tested our method on UNIGE-HANDS dataset and we showed that the proposed approach achieves competitive hand detection results.



### Improving Heterogeneous Face Recognition with Conditional Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1709.02848v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.02848v2)
- **Published**: 2017-09-08 20:09:50+00:00
- **Updated**: 2017-09-13 18:01:12+00:00
- **Authors**: Wuming Zhang, Zhixin Shu, Dimitris Samaras, Liming Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Heterogeneous face recognition between color image and depth image is a much desired capacity for real world applications where shape information is looked upon as merely involved in gallery. In this paper, we propose a cross-modal deep learning method as an effective and efficient workaround for this challenge. Specifically, we begin with learning two convolutional neural networks (CNNs) to extract 2D and 2.5D face features individually. Once trained, they can serve as pre-trained models for another two-way CNN which explores the correlated part between color and depth for heterogeneous matching. Compared with most conventional cross-modal approaches, our method additionally conducts accurate depth image reconstruction from single color image with Conditional Generative Adversarial Nets (cGAN), and further enhances the recognition performance by fusing multi-modal matching results. Through both qualitative and quantitative experiments on benchmark FRGC 2D/3D face database, we demonstrate that the proposed pipeline outperforms state-of-the-art performance on heterogeneous face recognition and ensures a drastically efficient on-line stage.



### Benchmarking Super-Resolution Algorithms on Real Data
- **Arxiv ID**: http://arxiv.org/abs/1709.04881v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1709.04881v1)
- **Published**: 2017-09-08 21:44:29+00:00
- **Updated**: 2017-09-08 21:44:29+00:00
- **Authors**: Thomas Köhler, Michel Bätz, Farzad Naderi, André Kaup, Andreas K. Maier, Christian Riess
- **Comment**: None
- **Journal**: None
- **Summary**: Over the past decades, various super-resolution (SR) techniques have been developed to enhance the spatial resolution of digital images. Despite the great number of methodical contributions, there is still a lack of comparative validations of SR under practical conditions, as capturing real ground truth data is a challenging task. Therefore, current studies are either evaluated 1) on simulated data or 2) on real data without a pixel-wise ground truth.   To facilitate comprehensive studies, this paper introduces the publicly available Super-Resolution Erlangen (SupER) database that includes real low-resolution images along with high-resolution ground truth data. Our database comprises image sequences with more than 20k images captured from 14 scenes under various types of motions and photometric conditions. The datasets cover four spatial resolution levels using camera hardware binning. With this database, we benchmark 15 single-image and multi-frame SR algorithms. Our experiments quantitatively analyze SR accuracy and robustness under realistic conditions including independent object and camera motion or photometric variations.



