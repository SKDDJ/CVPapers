# Arxiv Papers in cs.CV on 2017-06-06
### Global-Local Airborne Mapping (GLAM): Reconstructing a City from Aerial Videos
- **Arxiv ID**: http://arxiv.org/abs/1706.01580v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01580v2)
- **Published**: 2017-06-06 01:54:27+00:00
- **Updated**: 2018-06-07 05:39:15+00:00
- **Authors**: Hasnain Vohra, Maxim Bazik, Matthew Antone, Joseph Mundy, William Stephenson
- **Comment**: None
- **Journal**: None
- **Summary**: Monocular visual SLAM has become an attractive practical approach for robot localization and 3D environment mapping, since cameras are small, lightweight, inexpensive, and produce high-rate, high-resolution data streams. Although numerous robust tools have been developed, most existing systems are designed to operate in terrestrial environments and at relatively small scale (a few thousand frames) due to constraints on computation and storage.   In this paper, we present a feature-based visual SLAM system for aerial video whose simple design permits near real-time operation, and whose scalability permits large-area mapping using tens of thousands of frames, all on a single conventional computer. Our approach consists of two parallel threads: the first incrementally creates small locally consistent submaps and estimates camera poses at video rate; the second aligns these submaps with one another to produce a single globally consistent map via factor graph optimization over both poses and landmarks. Scale drift is minimized through the use of 7-degree-of-freedom similarity transformations during submap alignment.   We quantify our system's performance on both simulated and real data sets, and demonstrate city-scale map reconstruction accurate to within 2 meters using nearly 90,000 aerial video frames - to our knowledge, the largest and fastest such reconstruction to date.



### Incorporating Network Built-in Priors in Weakly-supervised Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1706.02189v1
- **DOI**: 10.1109/TPAMI.2017.2713785
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.02189v1)
- **Published**: 2017-06-06 03:23:17+00:00
- **Updated**: 2017-06-06 03:23:17+00:00
- **Authors**: Fatemeh Sadat Saleh, Mohammad Sadegh Aliakbarian, Mathieu Salzmann, Lars Petersson, Jose M. Alvarez, Stephen Gould
- **Comment**: 14 pages, 11 figures, 8 tables, Accepted in IEEE Transaction on
  Pattern Analysis and Machine Intelligence (IEEE TPAMI)
- **Journal**: None
- **Summary**: Pixel-level annotations are expensive and time consuming to obtain. Hence, weak supervision using only image tags could have a significant impact in semantic segmentation. Recently, CNN-based methods have proposed to fine-tune pre-trained networks using image tags. Without additional information, this leads to poor localization accuracy. This problem, however, was alleviated by making use of objectness priors to generate foreground/background masks. Unfortunately these priors either require pixel-level annotations/bounding boxes, or still yield inaccurate object boundaries. Here, we propose a novel method to extract accurate masks from networks pre-trained for the task of object recognition, thus forgoing external objectness modules. We first show how foreground/background masks can be obtained from the activations of higher-level convolutional layers of a network. We then show how to obtain multi-class masks by the fusion of foreground/background ones with information extracted from a weakly-supervised localization network. Our experiments evidence that exploiting these masks in conjunction with a weakly-supervised training loss yields state-of-the-art tag-based weakly-supervised semantic segmentation results.



### Hyperplane Clustering Via Dual Principal Component Pursuit
- **Arxiv ID**: http://arxiv.org/abs/1706.01604v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1706.01604v2)
- **Published**: 2017-06-06 04:27:24+00:00
- **Updated**: 2017-06-19 19:20:23+00:00
- **Authors**: Manolis C. Tsakiris, Rene Vidal
- **Comment**: None
- **Journal**: Proceedings of the 34th International Conference on Machine
  Learning, PMLR 70:3472-3481, 2017
- **Summary**: We extend the theoretical analysis of a recently proposed single subspace learning algorithm, called Dual Principal Component Pursuit (DPCP), to the case where the data are drawn from of a union of hyperplanes. To gain insight into the properties of the $\ell_1$ non-convex problem associated with DPCP, we develop a geometric analysis of a closely related continuous optimization problem. Then transferring this analysis to the discrete problem, our results state that as long as the hyperplanes are sufficiently separated, the dominant hyperplane is sufficiently dominant and the points are uniformly distributed inside the associated hyperplanes, then the non-convex DPCP problem has a unique global solution, equal to the normal vector of the dominant hyperplane. This suggests the correctness of a sequential hyperplane learning algorithm based on DPCP. A thorough experimental evaluation reveals that hyperplane learning schemes based on DPCP dramatically improve over the state-of-the-art methods for the case of synthetic data, while are competitive to the state-of-the-art in the case of 3D plane clustering for Kinect data.



### Volume Calculation of CT lung Lesions based on Halton Low-discrepancy Sequences
- **Arxiv ID**: http://arxiv.org/abs/1706.01644v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01644v1)
- **Published**: 2017-06-06 07:52:04+00:00
- **Updated**: 2017-06-06 07:52:04+00:00
- **Authors**: Liansheng Wang, Shusheng Li, Shuo Li
- **Comment**: None
- **Journal**: None
- **Summary**: Volume calculation from the Computed Tomography (CT) lung lesions data is a significant parameter for clinical diagnosis. The volume is widely used to assess the severity of the lung nodules and track its progression, however, the accuracy and efficiency of previous studies are not well achieved for clinical uses. It remains to be a challenging task due to its tight attachment to the lung wall, inhomogeneous background noises and large variations in sizes and shape. In this paper, we employ Halton low-discrepancy sequences to calculate the volume of the lung lesions. The proposed method directly compute the volume without the procedure of three-dimension (3D) model reconstruction and surface triangulation, which significantly improves the efficiency and reduces the complexity. The main steps of the proposed method are: (1) generate a certain number of random points in each slice using Halton low-discrepancy sequences and calculate the lesion area of each slice through the proportion; (2) obtain the volume by integrating the areas in the sagittal direction. In order to evaluate our proposed method, the experiments were conducted on the sufficient data sets with different size of lung lesions. With the uniform distribution of random points, our proposed method achieves more accurate results compared with other methods, which demonstrates the robustness and accuracy for the volume calculation of CT lung lesions. In addition, our proposed method is easy to follow and can be extensively applied to other applications, e.g., volume calculation of liver tumor, atrial wall aneurysm, etc.



### A Minimal Solution for Two-view Focal-length Estimation using Two Affine Correspondences
- **Arxiv ID**: http://arxiv.org/abs/1706.01649v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01649v1)
- **Published**: 2017-06-06 08:19:18+00:00
- **Updated**: 2017-06-06 08:19:18+00:00
- **Authors**: Daniel Barath, Tekla Toth, Levente Hajder
- **Comment**: None
- **Journal**: None
- **Summary**: A minimal solution using two affine correspondences is presented to estimate the common focal length and the fundamental matrix between two semi-calibrated cameras - known intrinsic parameters except a common focal length. To the best of our knowledge, this problem is unsolved. The proposed approach extends point correspondence-based techniques with linear constraints derived from local affine transformations. The obtained multivariate polynomial system is efficiently solved by the hidden-variable technique. Observing the geometry of local affinities, we introduce novel conditions eliminating invalid roots. To select the best one out of the remaining candidates, a root selection technique is proposed outperforming the recent ones especially in case of high-level noise. The proposed 2-point algorithm is validated on both synthetic data and 104 publicly available real image pairs. A Matlab implementation of the proposed solution is included in the paper.



### Compression Fractures Detection on CT
- **Arxiv ID**: http://arxiv.org/abs/1706.01671v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01671v1)
- **Published**: 2017-06-06 09:29:10+00:00
- **Updated**: 2017-06-06 09:29:10+00:00
- **Authors**: Amir Bar, Lior Wolf, Orna Bergman Amitai, Eyal Toledano, Eldad Elnekave
- **Comment**: None
- **Journal**: Proc. SPIE 10134, Medical Imaging 2017: Computer-Aided Diagnosis,
  1013440 (March 3, 2017)
- **Summary**: The presence of a vertebral compression fracture is highly indicative of osteoporosis and represents the single most robust predictor for development of a second osteoporotic fracture in the spine or elsewhere. Less than one third of vertebral compression fractures are diagnosed clinically. We present an automated method for detecting spine compression fractures in Computed Tomography (CT) scans. The algorithm is composed of three processes. First, the spinal column is segmented and sagittal patches are extracted. The patches are then binary classified using a Convolutional Neural Network (CNN). Finally a Recurrent Neural Network (RNN) is utilized to predict whether a vertebral fracture is present in the series of patches.



### Deep Alignment Network: A convolutional neural network for robust face alignment
- **Arxiv ID**: http://arxiv.org/abs/1706.01789v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01789v2)
- **Published**: 2017-06-06 14:36:52+00:00
- **Updated**: 2017-08-10 06:27:00+00:00
- **Authors**: Marek Kowalski, Jacek Naruniec, Tomasz Trzcinski
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition Workshop
  (CVPRW) 2017
- **Journal**: None
- **Summary**: In this paper, we propose Deep Alignment Network (DAN), a robust face alignment method based on a deep neural network architecture. DAN consists of multiple stages, where each stage improves the locations of the facial landmarks estimated by the previous stage. Our method uses entire face images at all stages, contrary to the recently proposed face alignment methods that rely on local patches. This is possible thanks to the use of landmark heatmaps which provide visual information about landmark locations estimated at the previous stages of the algorithm. The use of entire face images rather than patches allows DAN to handle face images with large variation in head pose and difficult initializations. An extensive evaluation on two publicly available datasets shows that DAN reduces the state-of-the-art failure rate by up to 70%. Our method has also been submitted for evaluation as part of the Menpo challenge.



### Understanding Kernel Size in Blind Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/1706.01797v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01797v5)
- **Published**: 2017-06-06 14:46:45+00:00
- **Updated**: 2019-02-22 11:02:51+00:00
- **Authors**: Li Si-Yao, Dongwei Ren, Qian Yin
- **Comment**: Accepted by WACV 2019
- **Journal**: None
- **Summary**: Most blind deconvolution methods usually pre-define a large kernel size to guarantee the support domain. Blur kernel estimation error is likely to be introduced, yielding severe artifacts in deblurring results. In this paper, we first theoretically and experimentally analyze the mechanism to estimation error in oversized kernel, and show that it holds even on blurry images without noises. Then to suppress this adverse effect, we propose a low rank-based regularization on blur kernel to exploit the structural information in degraded kernels, by which larger-kernel effect can be effectively suppressed. And we propose an efficient optimization algorithm to solve it. Experimental results on benchmark datasets show that the proposed method is comparable with the state-of-the-arts by accordingly setting proper kernel size, and performs much better in handling larger-size kernels quantitatively and qualitatively. The deblurring results on real-world blurry images further validate the effectiveness of the proposed method.



### SegAN: Adversarial Network with Multi-scale $L_1$ Loss for Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1706.01805v2
- **DOI**: 10.1007/s12021-018-9377-x
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01805v2)
- **Published**: 2017-06-06 15:01:57+00:00
- **Updated**: 2017-07-16 01:41:03+00:00
- **Authors**: Yuan Xue, Tao Xu, Han Zhang, Rodney Long, Xiaolei Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Inspired by classic generative adversarial networks (GAN), we propose a novel end-to-end adversarial neural network, called SegAN, for the task of medical image segmentation. Since image segmentation requires dense, pixel-level labeling, the single scalar real/fake output of a classic GAN's discriminator may be ineffective in producing stable and sufficient gradient feedback to the networks. Instead, we use a fully convolutional neural network as the segmentor to generate segmentation label maps, and propose a novel adversarial critic network with a multi-scale $L_1$ loss function to force the critic and segmentor to learn both global and local features that capture long- and short-range spatial relationships between pixels. In our SegAN framework, the segmentor and critic networks are trained in an alternating fashion in a min-max game: The critic takes as input a pair of images, (original_image $*$ predicted_label_map, original_image $*$ ground_truth_label_map), and then is trained by maximizing a multi-scale loss function; The segmentor is trained with only gradients passed along by the critic, with the aim to minimize the multi-scale loss function. We show that such a SegAN framework is more effective and stable for the segmentation task, and it leads to better performance than the state-of-the-art U-net segmentation method. We tested our SegAN method using datasets from the MICCAI BRATS brain tumor segmentation challenge. Extensive experimental results demonstrate the effectiveness of the proposed SegAN with multi-scale loss: on BRATS 2013 SegAN gives performance comparable to the state-of-the-art for whole tumor and tumor core segmentation while achieves better precision and sensitivity for Gd-enhance tumor core segmentation; on BRATS 2015 SegAN achieves better performance than the state-of-the-art in both dice score and precision.



### Face Alignment Using K-Cluster Regression Forests With Weighted Splitting
- **Arxiv ID**: http://arxiv.org/abs/1706.01820v1
- **DOI**: 10.1109/LSP.2016.2608139
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01820v1)
- **Published**: 2017-06-06 15:42:12+00:00
- **Updated**: 2017-06-06 15:42:12+00:00
- **Authors**: Marek Kowalski, Jacek Naruniec
- **Comment**: Postprint of an article published in IEEE Signal Processing Letters
  in 2016. A video explaining the method:
  https://www.youtube.com/watch?v=F4tgihZLrYw
- **Journal**: IEEE Signal Processing Letters, vol. 23, no. 11, pp. 1567-1571
  (Nov. 2016)
- **Summary**: In this work we present a face alignment pipeline based on two novel methods: weighted splitting for K-cluster Regression Forests and 3D Affine Pose Regression for face shape initialization. Our face alignment method is based on the Local Binary Feature framework, where instead of standard regression forests and pixel difference features used in the original method, we use our K-cluster Regression Forests with Weighted Splitting (KRFWS) and Pyramid HOG features. We also use KRFWS to perform Affine Pose Regression (APR) and 3D-Affine Pose Regression (3D-APR), which intend to improve the face shape initialization. APR applies a rigid 2D transform to the initial face shape that compensates for inaccuracy in the initial face location, size and in-plane rotation. 3D-APR estimates the parameters of a 3D transform that additionally compensates for out-of-plane rotation. The resulting pipeline, consisting of APR and 3D-APR followed by face alignment, shows an improvement of 20% over standard LBF on the challenging IBUG dataset, and state-of-theart accuracy on the entire 300-W dataset.



### Learning to Represent Mechanics via Long-term Extrapolation and Interpolation
- **Arxiv ID**: http://arxiv.org/abs/1706.02179v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1706.02179v2)
- **Published**: 2017-06-06 15:45:48+00:00
- **Updated**: 2017-06-08 09:31:22+00:00
- **Authors**: Sébastien Ehrhardt, Aron Monszpart, Andrea Vedaldi, Niloy Mitra
- **Comment**: arXiv admin note: text overlap with arXiv:1703.00247
- **Journal**: None
- **Summary**: While the basic laws of Newtonian mechanics are well understood, explaining a physical scenario still requires manually modeling the problem with suitable equations and associated parameters. In order to adopt such models for artificial intelligence, researchers have handcrafted the relevant states, and then used neural networks to learn the state transitions using simulation runs as training data. Unfortunately, such approaches can be unsuitable for modeling complex real-world scenarios, where manually authoring relevant state spaces tend to be challenging. In this work, we investigate if neural networks can implicitly learn physical states of real-world mechanical processes only based on visual data, and thus enable long-term physical extrapolation. We develop a recurrent neural network architecture for this task and also characterize resultant uncertainties in the form of evolving variance estimates. We evaluate our setup to extrapolate motion of a rolling ball on bowl of varying shape and orientation using only images as input, and report competitive results with approaches that assume access to internal physics models and parameters.



### Added value of morphological features to breast lesion diagnosis in ultrasound
- **Arxiv ID**: http://arxiv.org/abs/1706.01855v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01855v1)
- **Published**: 2017-06-06 17:08:50+00:00
- **Updated**: 2017-06-06 17:08:50+00:00
- **Authors**: Michał Byra, Katarzyna Dobruch-Sobczak, Hanna Piotrzkowska-Wróblewska, Andrzej Nowicki
- **Comment**: 7 pages, 3 figures
- **Journal**: None
- **Summary**: Ultrasound imaging plays an important role in breast lesion differentiation. However, diagnostic accuracy depends on ultrasonographer experience. Various computer aided diagnosis systems has been developed to improve breast cancer detection and reduce the number of unnecessary biopsies. In this study, our aim was to improve breast lesion classification based on the BI-RADS (Breast Imaging - Reporting and Data System). This was accomplished by combining the BI-RADS with morphological features which assess lesion boundary. A dataset of 214 lesion images was used for analysis. 30 morphological features were extracted and feature selection scheme was applied to find features which improve the BI-RADS classification performance. Additionally, the best performing morphological feature subset was indicated. We obtained a better classification by combining the BI-RADS with six morphological features. These features were the extent, overlap ratio, NRL entropy, circularity, elliptic-normalized circumference and the normalized residual value. The area under the receiver operating curve calculated with the use of the combined classifier was 0.986. The best performing morphological feature subset contained six features: the DWR, NRL entropy, normalized residual value, overlap ratio, extent and the morphological closing ratio. For this set, the area under the curve was 0.901. The combination of the radiologist's experience related to the BI-RADS and the morphological features leads to a more effective breast lesion classification.



### Director Field Analysis (DFA): Exploring Local White Matter Geometric Structure in diffusion MRI
- **Arxiv ID**: http://arxiv.org/abs/1706.01862v2
- **DOI**: 10.1016/j.media.2017.10.003
- **Categories**: **cs.CV**, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1706.01862v2)
- **Published**: 2017-06-06 17:23:22+00:00
- **Updated**: 2017-10-14 13:49:56+00:00
- **Authors**: Jian Cheng, Peter J. Basser
- **Comment**: Accepted by Medical Image Analysis
- **Journal**: None
- **Summary**: In Diffusion Tensor Imaging (DTI) or High Angular Resolution Diffusion Imaging (HARDI), a tensor field or a spherical function field (e.g., an orientation distribution function field), can be estimated from measured diffusion weighted images. In this paper, inspired by the microscopic theoretical treatment of phases in liquid crystals, we introduce a novel mathematical framework, called Director Field Analysis (DFA), to study local geometric structural information of white matter based on the reconstructed tensor field or spherical function field: 1) We propose a set of mathematical tools to process general director data, which consists of dyadic tensors that have orientations but no direction. 2) We propose Orientational Order (OO) and Orientational Dispersion (OD) indices to describe the degree of alignment and dispersion of a spherical function in a single voxel or in a region, respectively; 3) We also show how to construct a local orthogonal coordinate frame in each voxel exhibiting anisotropic diffusion; 4) Finally, we define three indices to describe three types of orientational distortion (splay, bend, and twist) in a local spatial neighborhood, and a total distortion index to describe distortions of all three types. To our knowledge, this is the first work to quantitatively describe orientational distortion (splay, bend, and twist) in general spherical function fields from DTI or HARDI data. The proposed DFA and its related mathematical tools can be used to process not only diffusion MRI data but also general director field data, and the proposed scalar indices are useful for detecting local geometric changes of white matter for voxel-based or tract-based analysis in both DTI and HARDI acquisitions. The related codes and a tutorial for DFA will be released in DMRITool.



### StreetStyle: Exploring world-wide clothing styles from millions of photos
- **Arxiv ID**: http://arxiv.org/abs/1706.01869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01869v1)
- **Published**: 2017-06-06 17:44:43+00:00
- **Updated**: 2017-06-06 17:44:43+00:00
- **Authors**: Kevin Matzen, Kavita Bala, Noah Snavely
- **Comment**: None
- **Journal**: None
- **Summary**: Each day billions of photographs are uploaded to photo-sharing services and social media platforms. These images are packed with information about how people live around the world. In this paper we exploit this rich trove of data to understand fashion and style trends worldwide. We present a framework for visual discovery at scale, analyzing clothing and fashion across millions of images of people around the world and spanning several years. We introduce a large-scale dataset of photos of people annotated with clothing attributes, and use this dataset to train attribute classifiers via deep learning. We also present a method for discovering visually consistent style clusters that capture useful visual correlations in this massive dataset. Using these tools, we analyze millions of photos to derive visual insight, producing a first-of-its-kind analysis of global and per-city fashion choices and spatio-temporal trends.



### Full Quantification of Left Ventricle via Deep Multitask Learning Network Respecting Intra- and Inter-Task Relatedness
- **Arxiv ID**: http://arxiv.org/abs/1706.01912v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.01912v2)
- **Published**: 2017-06-06 18:22:44+00:00
- **Updated**: 2017-06-14 16:12:49+00:00
- **Authors**: Wufeng Xue, Andrea Lum, Ashley Mercado, Mark Landis, James Warringto, Shuo Li
- **Comment**: Accepted at MICCAI 2017
- **Journal**: None
- **Summary**: Cardiac left ventricle (LV) quantification is among the most clinically important tasks for identification and diagnosis of cardiac diseases, yet still a challenge due to the high variability of cardiac structure and the complexity of temporal dynamics. Full quantification, i.e., to simultaneously quantify all LV indices including two areas (cavity and myocardium), six regional wall thicknesses (RWT), three LV dimensions, and one cardiac phase, is even more challenging since the uncertain relatedness intra and inter each type of indices may hinder the learning procedure from better convergence and generalization. In this paper, we propose a newly-designed multitask learning network (FullLVNet), which is constituted by a deep convolution neural network (CNN) for expressive feature embedding of cardiac structure; two followed parallel recurrent neural network (RNN) modules for temporal dynamic modeling; and four linear models for the final estimation. During the final estimation, both intra- and inter-task relatedness are modeled to enforce improvement of generalization: 1) respecting intra-task relatedness, group lasso is applied to each of the regression tasks for sparse and common feature selection and consistent prediction; 2) respecting inter-task relatedness, three phase-guided constraints are proposed to penalize violation of the temporal behavior of the obtained LV indices. Experiments on MR sequences of 145 subjects show that FullLVNet achieves high accurate prediction with our intra- and inter-task relatedness, leading to MAE of 190mm$^2$, 1.41mm, 2.68mm for average areas, RWT, dimensions and error rate of 10.4\% for the phase classification. This endows our method a great potential in comprehensive clinical assessment of global, regional and dynamic cardiac function.



### Deep Convolutional Decision Jungle for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1706.02003v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.02003v2)
- **Published**: 2017-06-06 23:03:44+00:00
- **Updated**: 2018-05-18 12:53:33+00:00
- **Authors**: Seungryul Baek, Kwang In Kim, Tae-Kyun Kim
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel method called deep convolutional decision jungle (CDJ) and its learning algorithm for image classification. The CDJ maintains the structure of standard convolutional neural networks (CNNs), i.e. multiple layers of multiple response maps fully connected. Each response map-or node-in both the convolutional and fully-connected layers selectively respond to class labels s.t. each data sample travels via a specific soft route of those activated nodes. The proposed method CDJ automatically learns features, whereas decision forests and jungles require pre-defined feature sets. Compared to CNNs, the method embeds the benefits of using data-dependent discriminative functions, which better handles multi-modal/heterogeneous data; further,the method offers more diverse sparse network responses, which in turn can be used for cost-effective learning/classification. The network is learnt by combining conventional softmax and proposed entropy losses in each layer. The entropy loss,as used in decision tree growing, measures the purity of data activation according to the class label distribution. The back-propagation rule for the proposed loss function is derived from stochastic gradient descent (SGD) optimization of CNNs. We show that our proposed method outperforms state-of-the-art methods on three public image classification benchmarks and one face verification dataset. We also demonstrate the use of auxiliary data labels, when available, which helps our method to learn more discriminative routing and representations and leads to improved classification.



