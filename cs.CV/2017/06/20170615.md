# Arxiv Papers in cs.CV on 2017-06-15
### Recent Progress of Face Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1706.04717v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04717v1)
- **Published**: 2017-06-15 01:55:17+00:00
- **Updated**: 2017-06-15 01:55:17+00:00
- **Authors**: Zhihe Lu, Zhihang Li, Jie Cao, Ran He, Zhenan Sun
- **Comment**: 17 pages, 10 figures
- **Journal**: None
- **Summary**: Face synthesis has been a fascinating yet challenging problem in computer vision and machine learning. Its main research effort is to design algorithms to generate photo-realistic face images via given semantic domain. It has been a crucial prepossessing step of main-stream face recognition approaches and an excellent test of AI ability to use complicated probability distributions. In this paper, we provide a comprehensive review of typical face synthesis works that involve traditional methods as well as advanced deep learning approaches. Particularly, Generative Adversarial Net (GAN) is highlighted to generate photo-realistic and identity preserving results. Furthermore, the public available databases and evaluation metrics are introduced in details. We end the review with discussing unsolved difficulties and promising directions for future research.



### Effective Sequential Classifier Training for SVM-based Multitemporal Remote Sensing Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1706.04719v2
- **DOI**: 10.1109/TIP.2018.2808767
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1706.04719v2)
- **Published**: 2017-06-15 02:01:44+00:00
- **Updated**: 2018-01-17 02:24:47+00:00
- **Authors**: Yiqing Guo, Xiuping Jia, David Paull
- **Comment**: None
- **Journal**: None
- **Summary**: The explosive availability of remote sensing images has challenged supervised classification algorithms such as Support Vector Machines (SVM), as training samples tend to be highly limited due to the expensive and laborious task of ground truthing. The temporal correlation and spectral similarity between multitemporal images have opened up an opportunity to alleviate this problem. In this study, a SVM-based Sequential Classifier Training (SCT-SVM) approach is proposed for multitemporal remote sensing image classification. The approach leverages the classifiers of previous images to reduce the required number of training samples for the classifier training of an incoming image. For each incoming image, a rough classifier is firstly predicted based on the temporal trend of a set of previous classifiers. The predicted classifier is then fine-tuned into a more accurate position with current training samples. This approach can be applied progressively to sequential image data, with only a small number of training samples being required from each image. Experiments were conducted with Sentinel-2A multitemporal data over an agricultural area in Australia. Results showed that the proposed SCT-SVM achieved better classification accuracies compared with two state-of-the-art model transfer algorithms. When training data are insufficient, the overall classification accuracy of the incoming image was improved from 76.18% to 94.02% with the proposed SCT-SVM, compared with those obtained without the assistance from previous images. These results demonstrate that the leverage of a priori information from previous images can provide advantageous assistance for later images in multitemporal image classification.



### The Compressed Model of Residual CNDS
- **Arxiv ID**: http://arxiv.org/abs/1706.06419v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.06419v1)
- **Published**: 2017-06-15 02:17:53+00:00
- **Updated**: 2017-06-15 02:17:53+00:00
- **Authors**: Hussam Qassim, David Feinzimer, Abhishek Verma
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks have achieved a great success in the recent years. Although, the way to maximize the performance of the convolutional neural networks still in the beginning. Furthermore, the optimization of the size and the time that need to train the convolutional neural networks is very far away from reaching the researcher's ambition. In this paper, we proposed a new convolutional neural network that combined several techniques to boost the optimization of the convolutional neural network in the aspects of speed and size. As we used our previous model Residual-CNDS (ResCNDS), which solved the problems of slower convergence, overfitting, and degradation, and compressed it. The outcome model called Residual-Squeeze-CNDS (ResSquCNDS), which we demonstrated on our sold technique to add residual learning and our model of compressing the convolutional neural networks. Our model of compressing adapted from the SQUEEZENET model, but our model is more generalizable, which can be applied almost to any neural network model, and fully integrated into the residual learning, which addresses the problem of the degradation very successfully. Our proposed model trained on very large-scale MIT Places365-Standard scene datasets, which backing our hypothesis that the new compressed model inherited the best of the previous ResCNDS8 model, and almost get the same accuracy in the validation Top-1 and Top-5 with 87.64% smaller in size and 13.33% faster in the training time.



### Suggestive Annotation: A Deep Active Learning Framework for Biomedical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1706.04737v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04737v1)
- **Published**: 2017-06-15 05:01:53+00:00
- **Updated**: 2017-06-15 05:01:53+00:00
- **Authors**: Lin Yang, Yizhe Zhang, Jianxu Chen, Siyuan Zhang, Danny Z. Chen
- **Comment**: Accepted at MICCAI 2017
- **Journal**: None
- **Summary**: Image segmentation is a fundamental problem in biomedical image analysis. Recent advances in deep learning have achieved promising results on many biomedical image segmentation benchmarks. However, due to large variations in biomedical images (different modalities, image settings, objects, noise, etc), to utilize deep learning on a new application, it usually needs a new set of training data. This can incur a great deal of annotation effort and cost, because only biomedical experts can annotate effectively, and often there are too many instances in images (e.g., cells) to annotate. In this paper, we aim to address the following question: With limited effort (e.g., time) for annotation, what instances should be annotated in order to attain the best performance? We present a deep active learning framework that combines fully convolutional network (FCN) and active learning to significantly reduce annotation effort by making judicious suggestions on the most effective annotation areas. We utilize uncertainty and similarity information provided by FCN and formulate a generalized version of the maximum set cover problem to determine the most representative and uncertain areas for annotation. Extensive experiments using the 2015 MICCAI Gland Challenge dataset and a lymph node ultrasound image segmentation dataset show that, using annotation suggestions by our method, state-of-the-art segmentation performance can be achieved by using only 50% of training data.



### Holistic Planimetric prediction to Local Volumetric prediction for 3D Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1706.04758v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04758v2)
- **Published**: 2017-06-15 07:25:34+00:00
- **Updated**: 2017-07-08 17:10:18+00:00
- **Authors**: Gyeongsik Moon, Ju Yong Chang, Yumin Suh, Kyoung Mu Lee
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel approach to 3D human pose estimation from a single depth map. Recently, convolutional neural network (CNN) has become a powerful paradigm in computer vision. Many of computer vision tasks have benefited from CNNs, however, the conventional approach to directly regress 3D body joint locations from an image does not yield a noticeably improved performance. In contrast, we formulate the problem as estimating per-voxel likelihood of key body joints from a 3D occupancy grid. We argue that learning a mapping from volumetric input to volumetric output with 3D convolution consistently improves the accuracy when compared to learning a regression from depth map to 3D joint coordinates. We propose a two-stage approach to reduce the computational overhead caused by volumetric representation and 3D convolution: Holistic 2D prediction and Local 3D prediction. In the first stage, Planimetric Network (P-Net) estimates per-pixel likelihood for each body joint in the holistic 2D space. In the second stage, Volumetric Network (V-Net) estimates the per-voxel likelihood of each body joints in the local 3D space around the 2D estimations of the first stage, effectively reducing the computational cost. Our model outperforms existing methods by a large margin in publicly available datasets.



### Arabian Horse Identification Benchmark Dataset
- **Arxiv ID**: http://arxiv.org/abs/1706.04870v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04870v1)
- **Published**: 2017-06-15 13:58:02+00:00
- **Updated**: 2017-06-15 13:58:02+00:00
- **Authors**: Ayat Taha, Ashraf Darwish, Aboul Ella Hassanien
- **Comment**: None
- **Journal**: None
- **Summary**: The lack of a standard muzzle print database is a challenge for conducting researches in Arabian horse identification systems. Therefore, collecting a muzzle print images database is a crucial decision. The dataset presented in this paper is an option for the studies that need a dataset for testing and comparing the algorithms under development for Arabian horse identification. Our collected dataset consists of 300 color images that were collected from 50 Arabian horse muzzle species. This dataset has been collected from 50 Arabian horses with 6 muzzle print images each. A special care has been given to the quality of the collected images. The collected images cover different quality levels and degradation factors such as image rotation and image partiality for simulating real time identification operations. This dataset can be used to test the identification of Arabian horse system including the extracted features and the selected classifier.



### DOTE: Dual cOnvolutional filTer lEarning for Super-Resolution and Cross-Modality Synthesis in MRI
- **Arxiv ID**: http://arxiv.org/abs/1706.04954v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04954v1)
- **Published**: 2017-06-15 16:27:23+00:00
- **Updated**: 2017-06-15 16:27:23+00:00
- **Authors**: Yawen Huang, Ling Shao, Alejandro F. Frangi
- **Comment**: 8 pages, 5 figures To appear in MICCAI 2017
- **Journal**: None
- **Summary**: Cross-modal image synthesis is a topical problem in medical image computing. Existing methods for image synthesis are either tailored to a specific application, require large scale training sets, or are based on partitioning images into overlapping patches. In this paper, we propose a novel Dual cOnvolutional filTer lEarning (DOTE) approach to overcome the drawbacks of these approaches. We construct a closed loop joint filter learning strategy that generates informative feedback for model self-optimization. Our method can leverage data more efficiently thus reducing the size of the required training set. We extensively evaluate DOTE in two challenging tasks: image super-resolution and cross-modality synthesis. The experimental results demonstrate superior performance of our method over other state-of-the-art methods.



### Stochastic Primal-Dual Hybrid Gradient Algorithm with Arbitrary Sampling and Imaging Applications
- **Arxiv ID**: http://arxiv.org/abs/1706.04957v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.NA, math.NA, 65D18, 65K10, 74S60, 90C25, 90C15, 92C55, 94A08
- **Links**: [PDF](http://arxiv.org/pdf/1706.04957v2)
- **Published**: 2017-06-15 16:43:16+00:00
- **Updated**: 2018-04-10 12:16:17+00:00
- **Authors**: Antonin Chambolle, Matthias J. Ehrhardt, Peter Richtárik, Carola-Bibiane Schönlieb
- **Comment**: 25 pages, 8 figures, submitted
- **Journal**: None
- **Summary**: We propose a stochastic extension of the primal-dual hybrid gradient algorithm studied by Chambolle and Pock in 2011 to solve saddle point problems that are separable in the dual variable. The analysis is carried out for general convex-concave saddle point problems and problems that are either partially smooth / strongly convex or fully smooth / strongly convex. We perform the analysis for arbitrary samplings of dual variables, and obtain known deterministic results as a special case. Several variants of our stochastic method significantly outperform the deterministic variant on a variety of imaging tasks.



### A convolutional autoencoder approach for mining features in cellular electron cryo-tomograms and weakly supervised coarse segmentation
- **Arxiv ID**: http://arxiv.org/abs/1706.04970v2
- **DOI**: 10.1016/j.jsb.2017.12.015
- **Categories**: **q-bio.QM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1706.04970v2)
- **Published**: 2017-06-15 17:13:37+00:00
- **Updated**: 2017-12-28 18:32:31+00:00
- **Authors**: Xiangrui Zeng, Miguel Ricardo Leung, Tzviya Zeev-Ben-Mordehai, Min Xu
- **Comment**: Accepted by Journal of Structural Biology
- **Journal**: None
- **Summary**: Cellular electron cryo-tomography enables the 3D visualization of cellular organization in the near-native state and at submolecular resolution. However, the contents of cellular tomograms are often complex, making it difficult to automatically isolate different in situ cellular components. In this paper, we propose a convolutional autoencoder-based unsupervised approach to provide a coarse grouping of 3D small subvolumes extracted from tomograms. We demonstrate that the autoencoder can be used for efficient and coarse characterization of features of macromolecular complexes and surfaces, such as membranes. In addition, the autoencoder can be used to detect non-cellular features related to sample preparation and data collection, such as carbon edges from the grid and tomogram boundaries. The autoencoder is also able to detect patterns that may indicate spatial interactions between cellular components. Furthermore, we demonstrate that our autoencoder can be used for weakly supervised semantic segmentation of cellular components, requiring a very small amount of manual annotation.



### Hierarchical Label Inference for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1706.05028v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.05028v2)
- **Published**: 2017-06-15 18:25:24+00:00
- **Updated**: 2018-01-21 23:53:47+00:00
- **Authors**: Nelson Nauata, Jonathan Smith, Greg Mori
- **Comment**: None
- **Journal**: None
- **Summary**: Videos are a rich source of high-dimensional structured data, with a wide range of interacting components at varying levels of granularity. In order to improve understanding of unconstrained internet videos, it is important to consider the role of labels at separate levels of abstraction. In this paper, we consider the use of the Bidirectional Inference Neural Network (BINN) for performing graph-based inference in label space for the task of video classification. We take advantage of the inherent hierarchy between labels at increasing granularity. The BINN is evaluated on the first and second release of the YouTube-8M large scale multilabel video dataset. Our results demonstrate the effectiveness of BINN, achieving significant improvements against baseline models.



### Distance weighted discrimination of face images for gender classification
- **Arxiv ID**: http://arxiv.org/abs/1706.05029v2
- **DOI**: 10.1002/sta4.151
- **Categories**: **stat.AP**, cs.CV, stat.ME, 62H30, 62H35
- **Links**: [PDF](http://arxiv.org/pdf/1706.05029v2)
- **Published**: 2017-06-15 18:25:50+00:00
- **Updated**: 2020-09-21 10:14:26+00:00
- **Authors**: Mónica Benito, Eduardo García-Portugués, J. S. Marron, Daniel Peña
- **Comment**: 9 pages, 4 figures, 1 table
- **Journal**: Stat, 6:231-240, 2017
- **Summary**: We illustrate the advantages of distance weighted discrimination for classification and feature extraction in a High Dimension Low Sample Size (HDLSS) situation. The HDLSS context is a gender classification problem of face images in which the dimension of the data is several orders of magnitude larger than the sample size. We compare distance weighted discrimination with Fisher's linear discriminant, support vector machines, and principal component analysis by exploring their classification interpretation through insightful visuanimations and by examining the classifiers' discriminant errors. This analysis enables us to make new contributions to the understanding of the drivers of human discrimination between males and females.



### Human-like Clustering with Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1706.05048v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1706.05048v2)
- **Published**: 2017-06-15 19:10:50+00:00
- **Updated**: 2017-12-11 23:45:26+00:00
- **Authors**: Ali Borji, Aysegul Dundar
- **Comment**: None
- **Journal**: None
- **Summary**: Classification and clustering have been studied separately in machine learning and computer vision. Inspired by the recent success of deep learning models in solving various vision problems (e.g., object recognition, semantic segmentation) and the fact that humans serve as the gold standard in assessing clustering algorithms, here, we advocate for a unified treatment of the two problems and suggest that hierarchical frameworks that progressively build complex patterns on top of the simpler ones (e.g., convolutional neural networks) offer a promising solution. We do not dwell much on the learning mechanisms in these frameworks as they are still a matter of debate, with respect to biological constraints. Instead, we emphasize on the compositionality of the real world structures and objects. In particular, we show that CNNs, trained end to end using back propagation with noisy labels, are able to cluster data points belonging to several overlapping shapes, and do so much better than the state of the art algorithms. The main takeaway lesson from our study is that mechanisms of human vision, particularly the hierarchal organization of the visual ventral stream should be taken into account in clustering algorithms (e.g., for learning representations in an unsupervised manner or with minimum supervision) to reach human level clustering performance. This, by no means, suggests that other methods do not hold merits. For example, methods relying on pairwise affinities (e.g., spectral clustering) have been very successful in many scenarios but still fail in some cases (e.g., overlapping clusters).



### Face Clustering: Representation and Pairwise Constraints
- **Arxiv ID**: http://arxiv.org/abs/1706.05067v2
- **DOI**: 10.1109/TIFS.2018.2796999
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.05067v2)
- **Published**: 2017-06-15 20:17:33+00:00
- **Updated**: 2018-07-27 01:13:07+00:00
- **Authors**: Yichun Shi, Charles Otto, Anil K. Jain
- **Comment**: This second version is the same as TIFS version. Some experiment
  results are different from v1 because we correct the protocols
- **Journal**: IEEE Transactions on Information Forensics and Security ( Volume:
  13, Issue: 7, July 2018 )
- **Summary**: Clustering face images according to their identity has two important applications: (i) grouping a collection of face images when no external labels are associated with images, and (ii) indexing for efficient large scale face retrieval. The clustering problem is composed of two key parts: face representation and choice of similarity for grouping faces. We first propose a representation based on ResNet, which has been shown to perform very well in image classification problems. Given this representation, we design a clustering algorithm, Conditional Pairwise Clustering (ConPaC), which directly estimates the adjacency matrix only based on the similarity between face images. This allows a dynamic selection of number of clusters and retains pairwise similarity between faces. ConPaC formulates the clustering problem as a Conditional Random Field (CRF) model and uses Loopy Belief Propagation to find an approximate solution for maximizing the posterior probability of the adjacency matrix. Experimental results on two benchmark face datasets (LFW and IJB-B) show that ConPaC outperforms well known clustering algorithms such as k-means, spectral clustering and approximate rank-order. Additionally, our algorithm can naturally incorporate pairwise constraints to obtain a semi-supervised version that leads to improved clustering performance. We also propose an k-NN variant of ConPaC, which has a linear time complexity given a k-NN graph, suitable for large datasets.



### Symplectomorphic registration with phase space regularization by entropy spectrum pathways
- **Arxiv ID**: http://arxiv.org/abs/1706.05105v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.05105v1)
- **Published**: 2017-06-15 21:46:44+00:00
- **Updated**: 2017-06-15 21:46:44+00:00
- **Authors**: Vitaly L. Galinsky, Lawrence R. Frank
- **Comment**: 26 pages, 7 figures
- **Journal**: None
- **Summary**: The ability to register image data to a common coordinate system is a critical feature of virtually all imaging studies that require multiple subject analysis, combining single subject data from multiple modalities, or both. However, in spite of the abundance of literature on the subject and the existence of several variants of registration algorithms, their practical utility remains problematic, as commonly acknowledged even by developers of these methods because the complexity of the problem has resisted a general, flexible, and robust theoretical and computational framework.   To address this issue, we present a new registration method that is similar in spirit to the current state-of-the-art technique of diffeomorphic mapping, but is more general and flexible. The method utilizes a Hamiltonian formalism and constructs registration as a sequence of symplectomorphic maps in conjunction with a novel phase space regularization based on the powerful entropy spectrum pathways (ESP) framework.   The method is demonstrated on the three different magnetic resonance imaging (MRI) modalities routinely used for human neuroimaging applications by mapping between high resolution anatomical (HRA) volumes, medium resolution diffusion weighted MRI (DW-MRI) and HRA volumes, and low resolution functional MRI (fMRI) and HRA volumes. The typical processing time for high quality mapping ranges from less than a minute to several minutes on a modern multi core CPU for typical high resolution anatomical (~256x256x256 voxels) MRI volumes.



