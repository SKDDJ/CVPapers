# Arxiv Papers in cs.CV on 2017-06-24
### Fundamental Matrix Estimation: A Study of Error Criteria
- **Arxiv ID**: http://arxiv.org/abs/1706.07886v1
- **DOI**: 10.1016/j.patrec.2010.09.019
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.07886v1)
- **Published**: 2017-06-24 00:13:29+00:00
- **Updated**: 2017-06-24 00:13:29+00:00
- **Authors**: Mohammed E. Fathy, Ashraf S. Hussein, Mohammed F. Tolba
- **Comment**: 15 pages, 7 figures, Pattern Recognition Letters, 2011
- **Journal**: None
- **Summary**: The fundamental matrix (FM) describes the geometric relations that exist between two images of the same scene. Different error criteria are used for estimating FMs from an input set of correspondences. In this paper, the accuracy and efficiency aspects of the different error criteria were studied. We mathematically and experimentally proved that the most popular error criterion, the symmetric epipolar distance, is biased. It was also shown that despite the similarity between the algebraic expressions of the symmetric epipolar distance and Sampson distance, they have different accuracy properties. In addition, a new error criterion, Kanatani distance, was proposed and was proved to be the most effective for use during the outlier removal phase from accuracy and efficiency perspectives. To thoroughly test the accuracy of the different error criteria, we proposed a randomized algorithm for Reprojection Error-based Correspondence Generation (RE-CG). As input, RE-CG takes an FM and a desired reprojection error value $d$. As output, RE-CG generates a random correspondence having that error value. Mathematical analysis of this algorithm revealed that the success probability for any given trial is 1 - (2/3)^2 at best and is 1 - (6/7)^2 at worst while experiments demonstrated that the algorithm often succeeds after only one trial.



### Evolving Spatially Aggregated Features from Satellite Imagery for Regional Modeling
- **Arxiv ID**: http://arxiv.org/abs/1706.07888v2
- **DOI**: 10.1007/978-3-319-45823-6_66
- **Categories**: **stat.ML**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1706.07888v2)
- **Published**: 2017-06-24 01:25:12+00:00
- **Updated**: 2017-12-14 17:42:18+00:00
- **Authors**: Sam Kriegman, Marcin Szubert, Josh C. Bongard, Christian Skalka
- **Comment**: None
- **Journal**: Parallel Problem Solving from Nature - PPSN XIV. PPSN 2016.
  Lecture Notes in Computer Science, vol 9921. Springer, Cham
- **Summary**: Satellite imagery and remote sensing provide explanatory variables at relatively high resolutions for modeling geospatial phenomena, yet regional summaries are often desirable for analysis and actionable insight. In this paper, we propose a novel method of inducing spatial aggregations as a component of the machine learning process, yielding regional model features whose construction is driven by model prediction performance rather than prior assumptions. Our results demonstrate that Genetic Programming is particularly well suited to this type of feature construction because it can automatically synthesize appropriate aggregations, as well as better incorporate them into predictive models compared to other regression methods we tested. In our experiments we consider a specific problem instance and real-world dataset relevant to predicting snow properties in high-mountain Asia.



### Deep Mixture of Diverse Experts for Large-Scale Visual Recognition
- **Arxiv ID**: http://arxiv.org/abs/1706.07901v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.07901v1)
- **Published**: 2017-06-24 03:41:37+00:00
- **Updated**: 2017-06-24 03:41:37+00:00
- **Authors**: Tianyi Zhao, Jun Yu, Zhenzhong Kuang, Wei Zhang, Jianping Fan
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, a deep mixture of diverse experts algorithm is developed for seamlessly combining a set of base deep CNNs (convolutional neural networks) with diverse outputs (task spaces), e.g., such base deep CNNs are trained to recognize different subsets of tens of thousands of atomic object classes. First, a two-layer (category layer and object class layer) ontology is constructed to achieve more effective solution for task group generation, e.g., assigning the semantically-related atomic object classes at the sibling leaf nodes into the same task group because they may share similar learning complexities. Second, one particular base deep CNNs with $M+1$ ($M \leq 1,000$) outputs is learned for each task group to recognize its $M$ atomic object classes effectively and identify one special class of "not-in-group" automatically, and the network structure (numbers of layers and units in each layer) of the well-designed AlexNet is directly used to configure such base deep CNNs. A deep multi-task learning algorithm is developed to leverage the inter-class visual similarities to learn more discriminative base deep CNNs and multi-task softmax for enhancing the separability of the atomic object classes in the same task group. Finally, all these base deep CNNs with diverse outputs (task spaces) are seamlessly combined to form a deep mixture of diverse experts for recognizing tens of thousands of atomic object classes. Our experimental results have demonstrated that our deep mixture of diverse experts algorithm can achieve very competitive results on large-scale visual recognition.



### Large-Scale Mapping of Human Activity using Geo-Tagged Videos
- **Arxiv ID**: http://arxiv.org/abs/1706.07911v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY, cs.MM, cs.SI
- **Links**: [PDF](http://arxiv.org/pdf/1706.07911v3)
- **Published**: 2017-06-24 05:59:37+00:00
- **Updated**: 2017-11-28 19:05:37+00:00
- **Authors**: Yi Zhu, Sen Liu, Shawn Newsam
- **Comment**: Accepted at ACM SIGSPATIAL 2017
- **Journal**: None
- **Summary**: This paper is the first work to perform spatio-temporal mapping of human activity using the visual content of geo-tagged videos. We utilize a recent deep-learning based video analysis framework, termed hidden two-stream networks, to recognize a range of activities in YouTube videos. This framework is efficient and can run in real time or faster which is important for recognizing events as they occur in streaming video or for reducing latency in analyzing already captured video. This is, in turn, important for using video in smart-city applications. We perform a series of experiments to show our approach is able to accurately map activities both spatially and temporally. We also demonstrate the advantages of using the visual content over the tags/titles.



### ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing
- **Arxiv ID**: http://arxiv.org/abs/1706.07929v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1706.07929v2)
- **Published**: 2017-06-24 09:02:21+00:00
- **Updated**: 2018-06-18 09:24:34+00:00
- **Authors**: Jian Zhang, Bernard Ghanem
- **Comment**: 10 pages, 6 figures, 4 Tables. To appear in CVPR 2018
- **Journal**: None
- **Summary**: With the aim of developing a fast yet accurate algorithm for compressive sensing (CS) reconstruction of natural images, we combine in this paper the merits of two existing categories of CS methods: the structure insights of traditional optimization-based methods and the speed of recent network-based ones. Specifically, we propose a novel structured deep network, dubbed ISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm (ISTA) for optimizing a general $\ell_1$ norm CS reconstruction model. To cast ISTA into deep network form, we develop an effective strategy to solve the proximal mapping associated with the sparsity-inducing regularizer using nonlinear transforms. All the parameters in ISTA-Net (\eg nonlinear transforms, shrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than being hand-crafted. Moreover, considering that the residuals of natural images are more compressible, an enhanced version of ISTA-Net in the residual domain, dubbed {ISTA-Net}$^+$, is derived to further improve CS reconstruction. Extensive CS experiments demonstrate that the proposed ISTA-Nets outperform existing state-of-the-art optimization-based and network-based CS methods by large margins, while maintaining fast computational speed. Our source codes are available: \textsl{http://jianzhang.tech/projects/ISTA-Net}.



### Encoding Video and Label Priors for Multi-label Video Classification on YouTube-8M dataset
- **Arxiv ID**: http://arxiv.org/abs/1706.07960v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.07960v2)
- **Published**: 2017-06-24 13:50:41+00:00
- **Updated**: 2017-07-12 05:33:50+00:00
- **Authors**: Seil Na, Youngjae Yu, Sangho Lee, Jisung Kim, Gunhee Kim
- **Comment**: accepted at Youtube-8M CVPR'17 Workshop as Oral Presentation. Kaggle
  8th model
- **Journal**: None
- **Summary**: YouTube-8M is the largest video dataset for multi-label video classification. In order to tackle the multi-label classification on this challenging dataset, it is necessary to solve several issues such as temporal modeling of videos, label imbalances, and correlations between labels. We develop a deep neural network model, which consists of four components: the frame encoder, the classification layer, the label processing layer, and the loss function. We introduce our newly proposed methods and discusses how existing models operate in the YouTube-8M Classification Task, what insights they have, and why they succeed (or fail) to achieve good performance. Most of the models we proposed are very high compared to the baseline models, and the ensemble of the models we used is 8th in the Kaggle Competition.



### Irregular Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1706.07966v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.07966v1)
- **Published**: 2017-06-24 14:19:41+00:00
- **Updated**: 2017-06-24 14:19:41+00:00
- **Authors**: Jiabin Ma, Wei Wang, Liang Wang
- **Comment**: 7 pages, 5 figures, 3 tables
- **Journal**: None
- **Summary**: Convolutional kernels are basic and vital components of deep Convolutional Neural Networks (CNN). In this paper, we equip convolutional kernels with shape attributes to generate the deep Irregular Convolutional Neural Networks (ICNN). Compared to traditional CNN applying regular convolutional kernels like ${3\times3}$, our approach trains irregular kernel shapes to better fit the geometric variations of input features. In other words, shapes are learnable parameters in addition to weights. The kernel shapes and weights are learned simultaneously during end-to-end training with the standard back-propagation algorithm. Experiments for semantic segmentation are implemented to validate the effectiveness of our proposed ICNN.



