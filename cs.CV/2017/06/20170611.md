# Arxiv Papers in cs.CV on 2017-06-11
### Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters
- **Arxiv ID**: http://arxiv.org/abs/1706.03292v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.DC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1706.03292v1)
- **Published**: 2017-06-11 01:11:06+00:00
- **Updated**: 2017-06-11 01:11:06+00:00
- **Authors**: Hao Zhang, Zeyu Zheng, Shizhen Xu, Wei Dai, Qirong Ho, Xiaodan Liang, Zhiting Hu, Jinliang Wei, Pengtao Xie, Eric P. Xing
- **Comment**: To appear in 2017 USENIX Annual Technical Conference
- **Journal**: None
- **Summary**: Deep learning models can take weeks to train on a single GPU-equipped machine, necessitating scaling out DL training to a GPU-cluster. However, current distributed DL implementations can scale poorly due to substantial parameter synchronization over the network, because the high throughput of GPUs allows more data batches to be processed per unit time than CPUs, leading to more frequent network synchronization. We present Poseidon, an efficient communication architecture for distributed DL on GPUs. Poseidon exploits the layered model structures in DL programs to overlap communication and computation, reducing bursty network communication. Moreover, Poseidon uses a hybrid communication scheme that optimizes the number of bytes required to synchronize each layer, according to layer properties and the number of machines. We show that Poseidon is applicable to different DL frameworks by plugging Poseidon into Caffe and TensorFlow. We show that Poseidon enables Caffe and TensorFlow to achieve 15.5x speed-up on 16 single-GPU machines, even with limited bandwidth (10GbE) and the challenging VGG19-22K network for image classification. Moreover, Poseidon-enabled TensorFlow achieves 31.5x speed-up with 32 single-GPU machines on Inception-V3, a 50% improvement over the open-source TensorFlow (20x speed-up).



### Bicycle Detection Based On Multi-feature and Multi-frame Fusion in low-resolution traffic videos
- **Arxiv ID**: http://arxiv.org/abs/1706.03309v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.03309v1)
- **Published**: 2017-06-11 04:51:15+00:00
- **Updated**: 2017-06-11 04:51:15+00:00
- **Authors**: Yicheng Zhang, Qiang Ling
- **Comment**: None
- **Journal**: None
- **Summary**: As a major type of transportation equipments, bicycles, including electrical bicycles, are distributed almost everywhere in China. The accidents caused by bicycles have become a serious threat to the public safety. So bicycle detection is one major task of traffic video surveillance systems in China. In this paper, a method based on multi-feature and multi-frame fusion is presented for bicycle detection in low-resolution traffic videos. It first extracts some geometric features of objects from each frame image, then concatenate multiple features into a feature vector and use linear support vector machine (SVM) to learn a classifier, or put these features into a cascade classifier, to yield a preliminary detection result regarding whether an object is a bicycle. It further fuses these preliminary detection results from multiple frames to provide a more reliable detection decision, together with a confidence level of that decision. Experimental results show that this method based on multi-feature and multi-frame fusion can identify bicycles with high accuracy and low computational complexity. It is, therefore, applicable for real-time traffic video surveillance systems.



### Style Transfer for Anime Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN
- **Arxiv ID**: http://arxiv.org/abs/1706.03319v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.03319v2)
- **Published**: 2017-06-11 07:56:32+00:00
- **Updated**: 2017-06-13 02:32:19+00:00
- **Authors**: Lvmin Zhang, Yi Ji, Xin Lin
- **Comment**: Submitted to ACPR 2017
- **Journal**: None
- **Summary**: Recently, with the revolutionary neural style transferring methods, creditable paintings can be synthesized automatically from content images and style images. However, when it comes to the task of applying a painting's style to an anime sketch, these methods will just randomly colorize sketch lines as outputs and fail in the main task: specific style tranfer. In this paper, we integrated residual U-net to apply the style to the gray-scale sketch with auxiliary classifier generative adversarial network (AC-GAN). The whole process is automatic and fast, and the results are creditable in the quality of art style as well as colorization.



### A dynamic graph-cuts method with integrated multiple feature maps for segmenting kidneys in ultrasound images
- **Arxiv ID**: http://arxiv.org/abs/1706.03372v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.03372v1)
- **Published**: 2017-06-11 16:17:51+00:00
- **Updated**: 2017-06-11 16:17:51+00:00
- **Authors**: Qiang Zheng, Steven Warner, Gregory Tasian, Yong Fan
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose: To improve kidney segmentation in clinical ultrasound (US) images, we develop a new graph cuts based method to segment kidney US images by integrating original image intensity information and texture feature maps extracted using Gabor filters. Methods: To handle large appearance variation within kidney images and improve computational efficiency, we build a graph of image pixels close to kidney boundary instead of building a graph of the whole image. To make the kidney segmentation robust to weak boundaries, we adopt localized regional information to measure similarity between image pixels for computing edge weights to build the graph of image pixels. The localized graph is dynamically updated and the GC based segmentation iteratively progresses until convergence. The proposed method has been evaluated and compared with state of the art image segmentation methods based on clinical kidney US images of 85 subjects. We randomly selected US images of 20 subjects as training data for tuning the parameters, and validated the methods based on US images of the remaining 65 subjects. The segmentation results have been quantitatively analyzed using 3 metrics, including Dice Index, Jaccard Index, and Mean Distance. Results: Experiment results demonstrated that the proposed method obtained segmentation results for bilateral kidneys of 65 subjects with average Dice index of 0.9581, Jaccard index of 0.9204, and Mean Distance of 1.7166, better than other methods under comparison (p<10-19, paired Wilcoxon rank sum tests). Conclusions: The proposed method achieved promising performance for segmenting kidneys in US images, better than segmentation methods that built on any single channel of image information. This method will facilitate extraction of kidney characteristics that may predict important clinical outcomes such progression chronic kidney disease.



### Text Extraction From Texture Images Using Masked Signal Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1706.04041v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.04041v3)
- **Published**: 2017-06-11 20:52:00+00:00
- **Updated**: 2017-07-11 02:07:35+00:00
- **Authors**: Shervin Minaee, Yao Wang
- **Comment**: arXiv admin note: text overlap with arXiv:1704.07711
- **Journal**: None
- **Summary**: Text extraction is an important problem in image processing with applications from optical character recognition to autonomous driving. Most of the traditional text segmentation algorithms consider separating text from a simple background (which usually has a different color from texts). In this work we consider separating texts from a textured background, that has similar color to texts. We look at this problem from a signal decomposition perspective, and consider a more realistic scenario where signal components are overlaid on top of each other (instead of adding together). When the signals are overlaid, to separate signal components, we need to find a binary mask which shows the support of each component. Because directly solving the binary mask is intractable, we relax this problem to the approximated continuous problem, and solve it by alternating optimization method. We show that the proposed algorithm achieves significantly better results than other recent works on several challenging images.



### PatternNet: A Benchmark Dataset for Performance Evaluation of Remote Sensing Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1706.03424v2
- **DOI**: 10.1016/j.isprsjprs.2018.01.004
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1706.03424v2)
- **Published**: 2017-06-11 23:45:07+00:00
- **Updated**: 2017-07-10 04:37:30+00:00
- **Authors**: Weixun Zhou, Shawn Newsam, Congmin Li, Zhenfeng Shao
- **Comment**: 49 pages
- **Journal**: None
- **Summary**: Remote sensing image retrieval(RSIR), which aims to efficiently retrieve data of interest from large collections of remote sensing data, is a fundamental task in remote sensing. Over the past several decades, there has been significant effort to extract powerful feature representations for this task since the retrieval performance depends on the representative strength of the features. Benchmark datasets are also critical for developing, evaluating, and comparing RSIR approaches. Current benchmark datasets are deficient in that 1) they were originally collected for land use/land cover classification and not image retrieval, 2) they are relatively small in terms of the number of classes as well the number of sample images per class, and 3) the retrieval performance has saturated. These limitations have severely restricted the development of novel feature representations for RSIR, particularly the recent deep-learning based features which require large amounts of training data. We therefore present in this paper, a new large-scale remote sensing dataset termed "PatternNet" that was collected specifically for RSIR. PatternNet was collected from high-resolution imagery and contains 38 classes with 800 images per class. We also provide a thorough review of RSIR approaches ranging from traditional handcrafted feature based methods to recent deep learning based ones. We evaluate over 35 methods to establish extensive baseline results for future RSIR research using the PatternNet benchmark.



