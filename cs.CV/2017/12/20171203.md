# Arxiv Papers in cs.CV on 2017-12-03
### GAGAN: Geometry-Aware Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1712.00684v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00684v3)
- **Published**: 2017-12-03 00:12:41+00:00
- **Updated**: 2018-03-27 22:11:56+00:00
- **Authors**: Jean Kossaifi, Linh Tran, Yannis Panagakis, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: Deep generative models learned through adversarial training have become increasingly popular for their ability to generate naturalistic image textures. However, aside from their texture, the visual appearance of objects is significantly influenced by their shape geometry; information which is not taken into account by existing generative models. This paper introduces the Geometry-Aware Generative Adversarial Networks (GAGAN) for incorporating geometric information into the image generation process. Specifically, in GAGAN the generator samples latent variables from the probability space of a statistical shape model. By mapping the output of the generator to a canonical coordinate frame through a differentiable geometric transformation, we enforce the geometry of the objects and add an implicit connection from the prior to the generated object. Experimental results on face generation indicate that the GAGAN can generate realistic images of faces with arbitrary facial attributes such as facial expression, pose, and morphology, that are of better quality than current GAN-based methods. Our method can be used to augment any existing GAN architecture and improve the quality of the images generated.



### Low-Rank Tensor Completion by Truncated Nuclear Norm Regularization
- **Arxiv ID**: http://arxiv.org/abs/1712.00704v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00704v5)
- **Published**: 2017-12-03 03:40:08+00:00
- **Updated**: 2018-05-28 03:03:14+00:00
- **Authors**: Shengke Xue, Wenyuan Qiu, Fan Liu, Xinyu Jin
- **Comment**: Accepted as a poster presentation at the 24th International
  Conference on Pattern Recognition in 20-24 August 2018, Beijing, China
- **Journal**: None
- **Summary**: Currently, low-rank tensor completion has gained cumulative attention in recovering incomplete visual data whose partial elements are missing. By taking a color image or video as a three-dimensional (3D) tensor, previous studies have suggested several definitions of tensor nuclear norm. However, they have limitations and may not properly approximate the real rank of a tensor. Besides, they do not explicitly use the low-rank property in optimization. It is proved that the recently proposed truncated nuclear norm (TNN) can replace the traditional nuclear norm, as a better estimation to the rank of a matrix. Thus, this paper presents a new method called the tensor truncated nuclear norm (T-TNN), which proposes a new definition of tensor nuclear norm and extends the truncated nuclear norm from the matrix case to the tensor case. Beneficial from the low rankness of TNN, our approach improves the efficacy of tensor completion. We exploit the previously proposed tensor singular value decomposition and the alternating direction method of multipliers in optimization. Extensive experiments on real-world videos and images demonstrate that the performance of our approach is superior to those of existing methods.



### Evaluation of Alzheimer's Disease by Analysis of MR Images using Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the ADC Maps
- **Arxiv ID**: http://arxiv.org/abs/1712.00712v1
- **DOI**: 10.1109/IEMBS.2007.4352740
- **Categories**: **eess.IV**, cs.AI, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1712.00712v1)
- **Published**: 2017-12-03 05:54:40+00:00
- **Updated**: 2017-12-03 05:54:40+00:00
- **Authors**: Wellington Pinheiro dos Santos, Ricardo Emmanuel de Souza, Pl√≠nio B. dos Santos Filho
- **Comment**: 29th Annual Conference of the IEEE Engineering in Medicine and
  Biology Society - EMBC 2007
- **Journal**: None
- **Summary**: Alzheimer's disease is the most common cause of dementia, yet hard to diagnose precisely without invasive techniques, particularly at the onset of the disease. This work approaches image analysis and classification of synthetic multispectral images composed by diffusion-weighted magnetic resonance (MR) cerebral images for the evaluation of cerebrospinal fluid area and measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging system was used to acquire all images presented. The classification methods are based on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We assume the classes of interest can be separated by hyperquadrics. Therefore, a 2-degree polynomial network is used to classify the original image, generating the ground truth image. The classification results are used to improve the usual analysis of the apparent diffusion coefficient map.



### Spatial PixelCNN: Generating Images from Patches
- **Arxiv ID**: http://arxiv.org/abs/1712.00714v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1712.00714v1)
- **Published**: 2017-12-03 06:02:23+00:00
- **Updated**: 2017-12-03 06:02:23+00:00
- **Authors**: Nader Akoury, Anh Nguyen
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we propose Spatial PixelCNN, a conditional autoregressive model that generates images from small patches. By conditioning on a grid of pixel coordinates and global features extracted from a Variational Autoencoder (VAE), we are able to train on patches of images, and reproduce the full-sized image. We show that it not only allows for generating high quality samples at the same resolution as the underlying dataset, but is also capable of upscaling images to arbitrary resolutions (tested at resolutions up to $50\times$) on the MNIST dataset. Compared to a PixelCNN++ baseline, Spatial PixelCNN quantitatively and qualitatively achieves similar performance on the MNIST dataset.



### Automatic Recognition of Coal and Gangue based on Convolution Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1712.00720v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00720v1)
- **Published**: 2017-12-03 06:37:15+00:00
- **Updated**: 2017-12-03 06:37:15+00:00
- **Authors**: Huichao Hong, Lixin Zheng, Jianqing Zhu, Shuwan Pan, Kaiting Zhou
- **Comment**: None
- **Journal**: None
- **Summary**: We designed a gangue sorting system,and built a convolutional neural network model based on AlexNet. Data enhancement and transfer learning are used to solve the problem which the convolution neural network has insufficient training data in the training stage. An object detection and region clipping algorithm is proposed to adjust the training image data to the optimum size. Compared with traditional neural network and SVM algorithm, this algorithm has higher recognition rate for coal and coal gangue, and provides important reference for identification and separation of coal and gangue.



### Feature Agglomeration Networks for Single Stage Face Detection
- **Arxiv ID**: http://arxiv.org/abs/1712.00721v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00721v2)
- **Published**: 2017-12-03 06:38:09+00:00
- **Updated**: 2018-09-10 05:42:16+00:00
- **Authors**: Jialiang Zhang, Xiongwei Wu, Jianke Zhu, Steven C. H. Hoi
- **Comment**: None
- **Journal**: None
- **Summary**: Recent years have witnessed promising results of face detection using deep learning. Despite making remarkable progresses, face detection in the wild remains an open research challenge especially when detecting faces at vastly different scales and characteristics. In this paper, we propose a novel simple yet effective framework of "Feature Agglomeration Networks" (FANet) to build a new single stage face detector, which not only achieves state-of-the-art performance but also runs efficiently. As inspired by Feature Pyramid Networks (FPN), the key idea of our framework is to exploit inherent multi-scale features of a single convolutional neural network by aggregating higher-level semantic feature maps of different scales as contextual cues to augment lower-level feature maps via a hierarchical agglomeration manner at marginal extra computation cost. We further propose a Hierarchical Loss to effectively train the FANet model. We evaluate the proposed FANet detector on several public face detection benchmarks, including PASCAL face, FDDB and WIDER FACE datasets and achieved state-of-the-art results. Our detector can run in real time for VGA-resolution images on GPU.



### Sentiment Classification using Images and Label Embeddings
- **Arxiv ID**: http://arxiv.org/abs/1712.00725v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1712.00725v1)
- **Published**: 2017-12-03 07:20:15+00:00
- **Updated**: 2017-12-03 07:20:15+00:00
- **Authors**: Laura Graesser, Abhinav Gupta, Lakshay Sharma, Evelina Bakhturina
- **Comment**: 13 pages, 3 figures, 9 tables. Technical report for Statistical
  Natural Language Processing Project (NYU CS - Fall 2016)
- **Journal**: None
- **Summary**: In this project we analysed how much semantic information images carry, and how much value image data can add to sentiment analysis of the text associated with the images. To better understand the contribution from images, we compared models which only made use of image data, models which only made use of text data, and models which combined both data types. We also analysed if this approach could help sentiment classifiers generalize to unknown sentiments.



### Cascade R-CNN: Delving into High Quality Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1712.00726v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00726v1)
- **Published**: 2017-12-03 07:24:45+00:00
- **Updated**: 2017-12-03 07:24:45+00:00
- **Authors**: Zhaowei Cai, Nuno Vasconcelos
- **Comment**: None
- **Journal**: None
- **Summary**: In object detection, an intersection over union (IoU) threshold is required to define positives and negatives. An object detector, trained with low IoU threshold, e.g. 0.5, usually produces noisy detections. However, detection performance tends to degrade with increasing the IoU thresholds. Two main factors are responsible for this: 1) overfitting during training, due to exponentially vanishing positive samples, and 2) inference-time mismatch between the IoUs for which the detector is optimal and those of the input hypotheses. A multi-stage object detection architecture, the Cascade R-CNN, is proposed to address these problems. It consists of a sequence of detectors trained with increasing IoU thresholds, to be sequentially more selective against close false positives. The detectors are trained stage by stage, leveraging the observation that the output of a detector is a good distribution for training the next higher quality detector. The resampling of progressively improved hypotheses guarantees that all detectors have a positive set of examples of equivalent size, reducing the overfitting problem. The same cascade procedure is applied at inference, enabling a closer match between the hypotheses and the detector quality of each stage. A simple implementation of the Cascade R-CNN is shown to surpass all single-model object detectors on the challenging COCO dataset. Experiments also show that the Cascade R-CNN is widely applicable across detector architectures, achieving consistent gains independently of the baseline detector strength. The code will be made available at https://github.com/zhaoweicai/cascade-rcnn.



### Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks
- **Arxiv ID**: http://arxiv.org/abs/1712.00733v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1712.00733v1)
- **Published**: 2017-12-03 08:41:35+00:00
- **Updated**: 2017-12-03 08:41:35+00:00
- **Authors**: Guohao Li, Hang Su, Wenwu Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Visual Question Answering (VQA) has attracted much attention since it offers insight into the relationships between the multi-modal analysis of images and natural language. Most of the current algorithms are incapable of answering open-domain questions that require to perform reasoning beyond the image contents. To address this issue, we propose a novel framework which endows the model capabilities in answering more complex questions by leveraging massive external knowledge with dynamic memory networks. Specifically, the questions along with the corresponding images trigger a process to retrieve the relevant information in external knowledge bases, which are embedded into a continuous vector space by preserving the entity-relation structures. Afterwards, we employ dynamic memory networks to attend to the large body of facts in the knowledge graph and images, and then perform reasoning over these facts to generate corresponding answers. Extensive experiments demonstrate that our model not only achieves the state-of-the-art performance in the visual question answering task, but can also answer open-domain questions effectively by leveraging the external knowledge.



### Towards Real-Time Advancement of Underwater Visual Quality with GAN
- **Arxiv ID**: http://arxiv.org/abs/1712.00736v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1712.00736v4)
- **Published**: 2017-12-03 09:39:29+00:00
- **Updated**: 2020-03-25 05:32:04+00:00
- **Authors**: Xingyu Chen, Junzhi Yu, Shihan Kong, Zhengxing Wu, Xi Fang, Li Wen
- **Comment**: None
- **Journal**: None
- **Summary**: Low visual quality has prevented underwater robotic vision from a wide range of applications. Although several algorithms have been developed, real-time and adaptive methods are deficient for real-world tasks. In this paper, we address this difficulty based on generative adversarial networks (GAN), and propose a GAN-based restoration scheme (GAN-RS). In particular, we develop a multi-branch discriminator including an adversarial branch and a critic branch for the purpose of simultaneously preserving image content and removing underwater noise. In addition to adversarial learning, a novel dark channel prior loss also promotes the generator to produce realistic vision. More specifically, an underwater index is investigated to describe underwater properties, and a loss function based on the underwater index is designed to train the critic branch for underwater noise suppression. Through extensive comparisons on visual quality and feature restoration, we confirm the superiority of the proposed approach. Consequently, the GAN-RS can adaptively improve underwater visual quality in real time and induce an overall superior restoration performance. Finally, a real-world experiment is conducted on the seabed for grasping marine products, and the results are quite promising. The source code is publicly available at https://github.com/SeanChenxy/GAN_RS.



### Gradient Descent Learns One-hidden-layer CNN: Don't be Afraid of Spurious Local Minima
- **Arxiv ID**: http://arxiv.org/abs/1712.00779v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1712.00779v2)
- **Published**: 2017-12-03 15:00:35+00:00
- **Updated**: 2018-06-15 00:41:03+00:00
- **Authors**: Simon S. Du, Jason D. Lee, Yuandong Tian, Barnabas Poczos, Aarti Singh
- **Comment**: Accepted by ICML 2018
- **Journal**: None
- **Summary**: We consider the problem of learning a one-hidden-layer neural network with non-overlapping convolutional layer and ReLU activation, i.e., $f(\mathbf{Z}, \mathbf{w}, \mathbf{a}) = \sum_j a_j\sigma(\mathbf{w}^T\mathbf{Z}_j)$, in which both the convolutional weights $\mathbf{w}$ and the output weights $\mathbf{a}$ are parameters to be learned. When the labels are the outputs from a teacher network of the same architecture with fixed weights $(\mathbf{w}^*, \mathbf{a}^*)$, we prove that with Gaussian input $\mathbf{Z}$, there is a spurious local minimizer. Surprisingly, in the presence of the spurious local minimizer, gradient descent with weight normalization from randomly initialized weights can still be proven to recover the true parameters with constant probability, which can be boosted to probability $1$ with multiple restarts. We also show that with constant probability, the same procedure could also converge to the spurious local minimum, showing that the local minimum plays a non-trivial role in the dynamics of gradient descent. Furthermore, a quantitative analysis shows that the gradient descent dynamics has two phases: it starts off slow, but converges much faster after several iterations.



### Multimodal Visual Concept Learning with Weakly Supervised Techniques
- **Arxiv ID**: http://arxiv.org/abs/1712.00796v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.00796v3)
- **Published**: 2017-12-03 16:51:56+00:00
- **Updated**: 2018-04-04 18:29:11+00:00
- **Authors**: Giorgos Bouritsas, Petros Koutras, Athanasia Zlatintsi, Petros Maragos
- **Comment**: CVPR 2018
- **Journal**: None
- **Summary**: Despite the availability of a huge amount of video data accompanied by descriptive texts, it is not always easy to exploit the information contained in natural language in order to automatically recognize video concepts. Towards this goal, in this paper we use textual cues as means of supervision, introducing two weakly supervised techniques that extend the Multiple Instance Learning (MIL) framework: the Fuzzy Sets Multiple Instance Learning (FSMIL) and the Probabilistic Labels Multiple Instance Learning (PLMIL). The former encodes the spatio-temporal imprecision of the linguistic descriptions with Fuzzy Sets, while the latter models different interpretations of each description's semantics with Probabilistic Labels, both formulated through a convex optimization algorithm. In addition, we provide a novel technique to extract weak labels in the presence of complex semantics, that consists of semantic similarity computations. We evaluate our methods on two distinct problems, namely face and action recognition, in the challenging and realistic setting of movies accompanied by their screenplays, contained in the COGNIMUSE database. We show that, on both tasks, our method considerably outperforms a state-of-the-art weakly supervised approach, as well as other baselines.



### A semi-supervised fuzzy GrowCut algorithm to segment and classify regions of interest of mammographic images
- **Arxiv ID**: http://arxiv.org/abs/1801.01443v1
- **DOI**: 10.1016/j.eswa.2016.08.016
- **Categories**: **cs.CV**, cs.AI, cs.IR, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1801.01443v1)
- **Published**: 2017-12-03 17:31:01+00:00
- **Updated**: 2017-12-03 17:31:01+00:00
- **Authors**: Filipe Rolim Cordeiro, Wellington Pinheiro dos Santos, Abel Guilhermino da Silva Filho
- **Comment**: None
- **Journal**: Expert Systems With Applications, 65 (2016), 116-126
- **Summary**: According to the World Health Organization, breast cancer is the most common form of cancer in women. It is the second leading cause of death among women round the world, becoming the most fatal form of cancer. Mammographic image segmentation is a fundamental task to support image analysis and diagnosis, taking into account shape analysis of mammary lesions and their borders. However, mammogram segmentation is a very hard process, once it is highly dependent on the types of mammary tissues. In this work we present a new semi-supervised segmentation algorithm based on the modification of the GrowCut algorithm to perform automatic mammographic image segmentation once a region of interest is selected by a specialist. In our proposal, we used fuzzy Gaussian membership functions to modify the evolution rule of the original GrowCut algorithm, in order to estimate the uncertainty of a pixel being object or background. The main impact of the proposed method is the significant reduction of expert effort in the initialization of seed points of GrowCut to perform accurate segmentation, once it removes the need of selection of background seeds. We also constructed an automatic point selection process based on the simulated annealing optimization method, avoiding the need of human intervention. The proposed approach was qualitatively compared with other state-of-the-art segmentation techniques, considering the shape of segmented regions. In order to validate our proposal, we built an image classifier using a classical multilayer perceptron. We used Zernike moments to extract segmented image features. This analysis employed 685 mammograms from IRMA breast cancer database, using fat and fibroid tissues. Results show that the proposed technique could achieve a classification rate of 91.28\% for fat tissues, evidencing the feasibility of our approach.



### Fuzzy-Based Dialectical Non-Supervised Image Classification and Clustering
- **Arxiv ID**: http://arxiv.org/abs/1712.01694v1
- **DOI**: 10.3233/HIS-2010-0108
- **Categories**: **cs.CV**, cs.AI, cs.GR, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.01694v1)
- **Published**: 2017-12-03 17:56:15+00:00
- **Updated**: 2017-12-03 17:56:15+00:00
- **Authors**: Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo Emmanuel de Souza, Priscilla B. Mendes, Henrique S. S. Monteiro, Havana Diogo Alves
- **Comment**: None
- **Journal**: International Journal of Hybrid Intelligent Systems, v. 7, p.
  115-124, 2010
- **Summary**: The materialist dialectical method is a philosophical investigative method to analyze aspects of reality. These aspects are viewed as complex processes composed by basic units named poles, which interact with each other. Dialectics has experienced considerable progress in the 19th century, with Hegel's dialectics and, in the 20th century, with the works of Marx, Engels, and Gramsci, in Philosophy and Economics. The movement of poles through their contradictions is viewed as a dynamic process with intertwined phases of evolution and revolutionary crisis. In order to build a computational process based on dialectics, the interaction between poles can be modeled using fuzzy membership functions. Based on this assumption, we introduce the Objective Dialectical Classifier (ODC), a non-supervised map for classification based on materialist dialectics and designed as an extension of fuzzy c-means classifier. As a case study, we used ODC to classify 181 magnetic resonance synthetic multispectral images composed by proton density, $T_1$- and $T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means, and Kohonen's self-organized maps, concerning with image fidelity indexes as estimatives of quantization distortion, we proved that ODC can reach almost the same quantization performance as optimal non-supervised classifiers like Kohonen's self-organized maps.



### Triagem virtual de imagens de imuno-histoqu√≠mica usando redes neurais artificiais e espectro de padr√µes
- **Arxiv ID**: http://arxiv.org/abs/1712.01695v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.01695v1)
- **Published**: 2017-12-03 18:06:22+00:00
- **Updated**: 2017-12-03 18:06:22+00:00
- **Authors**: Higor Neto Lima, Wellington Pinheiro dos Santos, M√™user Jorge Silva Valen√ßa
- **Comment**: in Portuguese
- **Journal**: Learning and Nonlinear Models, v. 8, p. 202-215, 2010
- **Summary**: The importance of organizing medical images according to their nature, application and relevance is increasing. Furhermore, a previous selection of medical images can be useful to accelerate the task of analysis by pathologists. Herein this work we propose an image classifier to integrate a CBIR (Content-Based Image Retrieval) selection system. This classifier is based on pattern spectra and neural networks. Feature selection is performed using pattern spectra and principal component analysis, whilst image classification is based on multilayer perceptrons and a composition of self-organizing maps and learning vector quantization. These methods were applied for content selection of immunohistochemical images of placenta and newdeads lungs. Results demonstrated that this approach can reach reasonable classification performance.



### Avalia√ß√£o do m√©todo dial√©tico na quantiza√ß√£o de imagens multiespectrais
- **Arxiv ID**: http://arxiv.org/abs/1712.01696v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.01696v1)
- **Published**: 2017-12-03 18:13:27+00:00
- **Updated**: 2017-12-03 18:13:27+00:00
- **Authors**: Wellington Pinheiro dos Santos, Francisco Marcos de Assis
- **Comment**: in Portuguese
- **Journal**: Learning and Nonlinear Models, v. 8, p. 174-201, 2010
- **Summary**: The unsupervised classification has a very important role in the analysis of multispectral images, given its ability to assist the extraction of a priori knowledge of images. Algorithms like k-means and fuzzy c-means has long been used in this task. Computational Intelligence has proven to be an important field to assist in building classifiers optimized according to the quality of the grouping of classes and the evaluation of the quality of vector quantization. Several studies have shown that Philosophy, especially the Dialectical Method, has served as an important inspiration for the construction of new computational methods. This paper presents an evaluation of four methods based on the Dialectics: the Objective Dialectical Classifier and the Dialectical Optimization Method adapted to build a version of k-means with optimal quality indices; each of them is presented in two versions: a canonical version and another version obtained by applying the Principle of Maximum Entropy. These methods were compared to k-means, fuzzy c-means and Kohonen's self-organizing maps. The results showed that the methods based on Dialectics are robust to noise, and quantization can achieve results as good as those obtained with the Kohonen map, considered an optimal quantizer.



### Dialectical Multispectral Classification of Diffusion-Weighted Magnetic Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to Perform Anatomical Analysis
- **Arxiv ID**: http://arxiv.org/abs/1712.01697v1
- **DOI**: 10.1016/j.compmedimag.2009.04.004
- **Categories**: **cs.CV**, cs.GR, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.01697v1)
- **Published**: 2017-12-03 18:23:33+00:00
- **Updated**: 2017-12-03 18:23:33+00:00
- **Authors**: Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo Emmanuel de Souza, Pl√≠nio Batista dos Santos Filho, Fernando Buarque de Lima Neto
- **Comment**: None
- **Journal**: Computerized Medical Imaging and Graphics, v. 33, p. 442-460, 2009
- **Summary**: Multispectral image analysis is a relatively promising field of research with applications in several areas, such as medical imaging and satellite monitoring. A considerable number of current methods of analysis are based on parametric statistics. Alternatively, some methods in Computational Intelligence are inspired by biology and other sciences. Here we claim that Philosophy can be also considered as a source of inspiration. This work proposes the Objective Dialectical Method (ODM): a method for classification based on the Philosophy of Praxis. ODM is instrumental in assembling evolvable mathematical tools to analyze multispectral images. In the case study described in this paper, multispectral images are composed of diffusion-weighted (DW) magnetic resonance (MR) images. The results are compared to ground-truth images produced by polynomial networks using a morphological similarity index. The classification results are used to improve the usual analysis of the apparent diffusion coefficient map. Such results proved that gray and white matter can be distinguished in DW-MR multispectral analysis and, consequently, DW-MR images can also be used to furnish anatomical information.



### Semi-Global Stereo Matching with Surface Orientation Priors
- **Arxiv ID**: http://arxiv.org/abs/1712.00818v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1712.00818v1)
- **Published**: 2017-12-03 18:59:48+00:00
- **Updated**: 2017-12-03 18:59:48+00:00
- **Authors**: Daniel Scharstein, Tatsunori Taniai, Sudipta N. Sinha
- **Comment**: extended draft of 3DV 2017 (spotlight) paper
- **Journal**: None
- **Summary**: Semi-Global Matching (SGM) is a widely-used efficient stereo matching technique. It works well for textured scenes, but fails on untextured slanted surfaces due to its fronto-parallel smoothness assumption. To remedy this problem, we propose a simple extension, termed SGM-P, to utilize precomputed surface orientation priors. Such priors favor different surface slants in different 2D image regions or 3D scene regions and can be derived in various ways. In this paper we evaluate plane orientation priors derived from stereo matching at a coarser resolution and show that such priors can yield significant performance gains for difficult weakly-textured scenes. We also explore surface normal priors derived from Manhattan-world assumptions, and we analyze the potential performance gains using oracle priors derived from ground-truth data. SGM-P only adds a minor computational overhead to SGM and is an attractive alternative to more complex methods employing higher-order smoothness terms.



### Avalia√ß√£o da doen√ßa de Alzheimer pela an√°lise multiespectral de imagens DW-MR por redes RBF como alternativa aos mapas ADC
- **Arxiv ID**: http://arxiv.org/abs/1712.01700v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.01700v1)
- **Published**: 2017-12-03 19:02:00+00:00
- **Updated**: 2017-12-03 19:02:00+00:00
- **Authors**: Wellington Pinheiro dos Santos, Ricardo Emmanuel de Souza, Ascendino Fl√°vio Dias e Silva, Pl√≠nio Batista dos Santos Filho
- **Comment**: in Portuguese
- **Journal**: Learning and Nonlinear Models, v. 4, p. 43-53, 2008
- **Summary**: Alzheimer's disease is the most common cause of dementia, yet difficult to accurately diagnose without the use of invasive techniques, particularly at the beginning of the disease. This work addresses the classification and analysis of multispectral synthetic images composed by diffusion-weighted magnetic resonance brain volumes for evaluation of the area of cerebrospinal fluid and its correlation with the progression of Alzheimer's disease. A 1.5 T MR imaging system was used to acquire all the images presented. The classification methods are based on multilayer perceptrons and classifiers of radial basis function networks. It is assumed that the classes of interest can be separated by hyperquadrics. A polynomial network of degree 2 is used to classify the original volumes, generating a ground-truth volume. The classification results are used to improve the usual analysis by the map of apparent diffusion coefficients.



### Visual Explanation by High-Level Abduction: On Answer-Set Programming Driven Reasoning about Moving Objects
- **Arxiv ID**: http://arxiv.org/abs/1712.00840v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LO, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1712.00840v1)
- **Published**: 2017-12-03 21:17:07+00:00
- **Updated**: 2017-12-03 21:17:07+00:00
- **Authors**: Jakob Suchan, Mehul Bhatt, Przemys≈Çaw Wa≈Çƒôga, Carl Schultz
- **Comment**: Preprint of final publication published as part of AAAI 2018: J.
  Suchan., M. Bhatt, Wa{\l}\k{e}ga, P., Schultz, C. (2018). Visual Explanation
  by High-Level Abduction: On Answer-Set Programming Driven Reasoning about
  Moving Objects. In AAAI 2018: Proceedings of the Thirty-Second AAAI
  Conference on Artificial Intelligence, February 2-7, 2018, New Orleans, USA
- **Journal**: None
- **Summary**: We propose a hybrid architecture for systematically computing robust visual explanation(s) encompassing hypothesis formation, belief revision, and default reasoning with video data. The architecture consists of two tightly integrated synergistic components: (1) (functional) answer set programming based abductive reasoning with space-time tracklets as native entities; and (2) a visual processing pipeline for detection based object tracking and motion analysis.   We present the formal framework, its general implementation as a (declarative) method in answer set programming, and an example application and evaluation based on two diverse video datasets: the MOTChallenge benchmark developed by the vision community, and a recently developed Movie Dataset.



