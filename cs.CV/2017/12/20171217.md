# Arxiv Papers in cs.CV on 2017-12-17
### Nearly Optimal Robust Subspace Tracking
- **Arxiv ID**: http://arxiv.org/abs/1712.06061v4
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1712.06061v4)
- **Published**: 2017-12-17 06:14:58+00:00
- **Updated**: 2018-07-06 17:41:33+00:00
- **Authors**: Praneeth Narayanamurthy, Namrata Vaswani
- **Comment**: A [short
  version](http://proceedings.mlr.press/v80/narayanamurthy18a.html) will be
  presented at ICML 2018 (Long Talk). arXiv admin note: text overlap with
  arXiv:1803.00651
- **Journal**: None
- **Summary**: In this work, we study the robust subspace tracking (RST) problem and obtain one of the first two provable guarantees for it. The goal of RST is to track sequentially arriving data vectors that lie in a slowly changing low-dimensional subspace, while being robust to corruption by additive sparse outliers. It can also be interpreted as a dynamic (time-varying) extension of robust PCA (RPCA), with the minor difference that RST also requires a short tracking delay. We develop a recursive projected compressive sensing algorithm that we call Nearly Optimal RST via ReProCS (ReProCS-NORST) because its tracking delay is nearly optimal. We prove that NORST solves both the RST and the dynamic RPCA problems under weakened standard RPCA assumptions, two simple extra assumptions (slow subspace change and most outlier magnitudes lower bounded), and a few minor assumptions.   Our guarantee shows that NORST enjoys a near optimal tracking delay of $O(r \log n \log(1/\epsilon))$. Its required delay between subspace change times is the same, and its memory complexity is $n$ times this value. Thus both these are also nearly optimal. Here $n$ is the ambient space dimension, $r$ is the subspaces' dimension, and $\epsilon$ is the tracking accuracy. NORST also has the best outlier tolerance compared with all previous RPCA or RST methods, both theoretically and empirically (including for real videos), without requiring any model on how the outlier support is generated. This is possible because of the extra assumptions it uses.



### Spatial As Deep: Spatial CNN for Traffic Scene Understanding
- **Arxiv ID**: http://arxiv.org/abs/1712.06080v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.06080v1)
- **Published**: 2017-12-17 09:37:52+00:00
- **Updated**: 2017-12-17 09:37:52+00:00
- **Authors**: Xingang Pan, Jianping Shi, Ping Luo, Xiaogang Wang, Xiaoou Tang
- **Comment**: To appear in AAAI 2018
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) are usually built by stacking convolutional operations layer-by-layer. Although CNN has shown strong capability to extract semantics from raw pixels, its capacity to capture spatial relationships of pixels across rows and columns of an image is not fully explored. These relationships are important to learn semantic objects with strong shape priors but weak appearance coherences, such as traffic lanes, which are often occluded or not even painted on the road surface as shown in Fig. 1 (a). In this paper, we propose Spatial CNN (SCNN), which generalizes traditional deep layer-by-layer convolutions to slice-byslice convolutions within feature maps, thus enabling message passings between pixels across rows and columns in a layer. Such SCNN is particular suitable for long continuous shape structure or large objects, with strong spatial relationship but less appearance clues, such as traffic lanes, poles, and wall. We apply SCNN on a newly released very challenging traffic lane detection dataset and Cityscapse dataset. The results show that SCNN could learn the spatial relationship for structure output and significantly improves the performance. We show that SCNN outperforms the recurrent neural network (RNN) based ReNet and MRF+CNN (MRFNet) in the lane detection dataset by 8.7% and 4.6% respectively. Moreover, our SCNN won the 1st place on the TuSimple Benchmark Lane Detection Challenge, with an accuracy of 96.53%.



### "Zero-Shot" Super-Resolution using Deep Internal Learning
- **Arxiv ID**: http://arxiv.org/abs/1712.06087v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1712.06087v1)
- **Published**: 2017-12-17 11:00:30+00:00
- **Updated**: 2017-12-17 11:00:30+00:00
- **Authors**: Assaf Shocher, Nadav Cohen, Michal Irani
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Learning has led to a dramatic leap in Super-Resolution (SR) performance in the past few years. However, being supervised, these SR methods are restricted to specific training data, where the acquisition of the low-resolution (LR) images from their high-resolution (HR) counterparts is predetermined (e.g., bicubic downscaling), without any distracting artifacts (e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images, however, rarely obey these restrictions, resulting in poor SR results by SotA (State of the Art) methods. In this paper we introduce "Zero-Shot" SR, which exploits the power of Deep Learning, but does not rely on prior training. We exploit the internal recurrence of information inside a single image, and train a small image-specific CNN at test time, on examples extracted solely from the input image itself. As such, it can adapt itself to different settings per image. This allows to perform SR of real old photos, noisy images, biological data, and other images where the acquisition process is unknown or non-ideal. On such images, our method outperforms SotA CNN-based SR methods, as well as previous unsupervised SR methods. To the best of our knowledge, this is the first unsupervised CNN-based SR method.



### Efficient B-mode Ultrasound Image Reconstruction from Sub-sampled RF Data using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1712.06096v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1712.06096v3)
- **Published**: 2017-12-17 12:15:08+00:00
- **Updated**: 2018-08-07 09:19:13+00:00
- **Authors**: Yeo Hun Yoon, Shujaat Khan, Jaeyoung Huh, Jong Chul Ye
- **Comment**: The title has been changed. This version will appear in IEEE Trans.
  on Medical Imaging
- **Journal**: None
- **Summary**: In portable, three dimensional, and ultra-fast ultrasound imaging systems, there is an increasing demand for the reconstruction of high quality images from a limited number of radio-frequency (RF) measurements due to receiver (Rx) or transmit (Xmit) event sub-sampling. However, due to the presence of side lobe artifacts from RF sub-sampling, the standard beamformer often produces blurry images with less contrast, which are unsuitable for diagnostic purposes. Existing compressed sensing approaches often require either hardware changes or computationally expensive algorithms, but their quality improvements are limited. To address this problem, here we propose a novel deep learning approach that directly interpolates the missing RF data by utilizing redundancy in the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF data from a multi-line acquisition B-mode system confirm that the proposed method can effectively reduce the data rate without sacrificing image quality.



### Railway Track Specific Traffic Signal Selection Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1712.06107v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.06107v1)
- **Published**: 2017-12-17 13:00:25+00:00
- **Updated**: 2017-12-17 13:00:25+00:00
- **Authors**: S Ritika, Shruti Mittal, Dattaraj Rao
- **Comment**: None
- **Journal**: None
- **Summary**: With the railway transportation Industry moving actively towards automation, accurate location and inventory of wayside track assets like traffic signals, crossings, switches, mileposts, etc. is of extreme importance. With the new Positive Train Control (PTC) regulation coming into effect, many railway safety rules will be tied directly to location of assets like mileposts and signals. Newer speed regulations will be enforced based on location of the Train with respect to a wayside asset. Hence it is essential for the railroads to have an accurate database of the types and locations of these assets. This paper talks about a real-world use-case of detecting railway signals from a camera mounted on a moving locomotive and tracking their locations. The camera is engineered to withstand the environment factors on a moving train and provide a consistent steady image at around 30 frames per second. Using advanced image analysis and deep learning techniques, signals are detected in these camera images and a database of their locations is created. Railway signals differ a lot from road signals in terms of shapes and rules for placement with respect to track. Due to space constraint and traffic densities in urban areas signals are not placed on the same side of the track and multiple lines can run in parallel. Hence there is need to associate signal detected with the track on which the train runs. We present a method to associate the signals to the specific track they belong to using a video feed from the front facing camera mounted on the lead locomotive. A pipeline of track detection, region of interest selection, signal detection has been implemented which gives an overall accuracy of 94.7% on a route covering 150km with 247 signals.



### Learning a Single Convolutional Super-Resolution Network for Multiple Degradations
- **Arxiv ID**: http://arxiv.org/abs/1712.06116v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.06116v2)
- **Published**: 2017-12-17 14:04:47+00:00
- **Updated**: 2018-05-24 13:41:28+00:00
- **Authors**: Kai Zhang, Wangmeng Zuo, Lei Zhang
- **Comment**: CVPR 2018, code: https://github.com/cszn/SRMD
- **Journal**: None
- **Summary**: Recent years have witnessed the unprecedented success of deep convolutional neural networks (CNNs) in single image super-resolution (SISR). However, existing CNN-based SISR methods mostly assume that a low-resolution (LR) image is bicubicly downsampled from a high-resolution (HR) image, thus inevitably giving rise to poor performance when the true degradation does not follow this assumption. Moreover, they lack scalability in learning a single model to non-blindly deal with multiple degradations. To address these issues, we propose a general framework with dimensionality stretching strategy that enables a single convolutional super-resolution network to take two key factors of the SISR degradation process, i.e., blur kernel and noise level, as input. Consequently, the super-resolver can handle multiple and even spatially variant degradations, which significantly improves the practicability. Extensive experimental results on synthetic and real LR images show that the proposed convolutional super-resolution network not only can produce favorable results on multiple degradations but also is computationally efficient, providing a highly effective and scalable solution to practical SISR applications.



### Super-sparse Learning in Similarity Spaces
- **Arxiv ID**: http://arxiv.org/abs/1712.06131v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.2.6; I.4; I.5
- **Links**: [PDF](http://arxiv.org/pdf/1712.06131v1)
- **Published**: 2017-12-17 15:59:38+00:00
- **Updated**: 2017-12-17 15:59:38+00:00
- **Authors**: Ambra Demontis, Marco Melis, Battista Biggio, Giorgio Fumera, Fabio Roli
- **Comment**: None
- **Journal**: IEEE Computational Intell. Mag., 11(4):36-45, Nov 2016
- **Summary**: In several applications, input samples are more naturally represented in terms of similarities between each other, rather than in terms of feature vectors. In these settings, machine-learning algorithms can become very computationally demanding, as they may require matching the test samples against a very large set of reference prototypes. To mitigate this issue, different approaches have been developed to reduce the number of required reference prototypes. Current reduction approaches select a small subset of representative prototypes in the space induced by the similarity measure, and then separately train the classification function on the reduced subset. However, decoupling these two steps may not allow reducing the number of prototypes effectively without compromising accuracy. We overcome this limitation by jointly learning the classification function along with an optimal set of virtual prototypes, whose number can be either fixed a priori or optimized according to application-specific criteria. Creating a super-sparse set of virtual prototypes provides much sparser solutions, drastically reducing complexity at test time, at the expense of a slightly increased complexity during training. A much smaller set of prototypes also results in easier-to-interpret decisions. We empirically show that our approach can reduce up to ten times the complexity of Support Vector Machines, LASSO and ridge regression at test time, without almost affecting their classification accuracy.



### clcNet: Improving the Efficiency of Convolutional Neural Network using Channel Local Convolutions
- **Arxiv ID**: http://arxiv.org/abs/1712.06145v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.06145v3)
- **Published**: 2017-12-17 17:07:54+00:00
- **Updated**: 2018-03-25 09:33:03+00:00
- **Authors**: Dong-Qing Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Depthwise convolution and grouped convolution has been successfully applied to improve the efficiency of convolutional neural network (CNN). We suggest that these models can be considered as special cases of a generalized convolution operation, named channel local convolution(CLC), where an output channel is computed using a subset of the input channels. This definition entails computation dependency relations between input and output channels, which can be represented by a channel dependency graph(CDG). By modifying the CDG of grouped convolution, a new CLC kernel named interlaced grouped convolution (IGC) is created. Stacking IGC and GC kernels results in a convolution block (named CLC Block) for approximating regular convolution. By resorting to the CDG as an analysis tool, we derive the rule for setting the meta-parameters of IGC and GC and the framework for minimizing the computational cost. A new CNN model named clcNet is then constructed using CLC blocks, which shows significantly higher computational efficiency and fewer parameters compared to state-of-the-art networks, when being tested using the ImageNet-1K dataset. Source code is available at https://github.com/dqzhang17/clcnet.torch .



### Attenuation correction for brain PET imaging using deep neural network based on dixon and ZTE MR images
- **Arxiv ID**: http://arxiv.org/abs/1712.06203v2
- **DOI**: 10.1088/1361-6560/aac763
- **Categories**: **physics.med-ph**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1712.06203v2)
- **Published**: 2017-12-17 23:07:35+00:00
- **Updated**: 2018-05-24 20:19:24+00:00
- **Authors**: Kuang Gong, Jaewon Yang, Kyungsang Kim, Georges El Fakhri, Youngho Seo, Quanzheng Li
- **Comment**: 15 pages, 12 figures
- **Journal**: None
- **Summary**: Positron Emission Tomography (PET) is a functional imaging modality widely used in neuroscience studies. To obtain meaningful quantitative results from PET images, attenuation correction is necessary during image reconstruction. For PET/MR hybrid systems, PET attenuation is challenging as Magnetic Resonance (MR) images do not reflect attenuation coefficients directly. To address this issue, we present deep neural network methods to derive the continuous attenuation coefficients for brain PET imaging from MR images. With only Dixon MR images as the network input, the existing U-net structure was adopted and analysis using forty patient data sets shows it is superior than other Dixon based methods. When both Dixon and zero echo time (ZTE) images are available, we have proposed a modified U-net structure, named GroupU-net, to efficiently make use of both Dixon and ZTE information through group convolution modules when the network goes deeper. Quantitative analysis based on fourteen real patient data sets demonstrates that both network approaches can perform better than the standard methods, and the proposed network structure can further reduce the PET quantification error compared to the U-net structure.



