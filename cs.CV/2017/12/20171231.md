# Arxiv Papers in cs.CV on 2017-12-31
### Integrating semi-supervised label propagation and random forests for multi-atlas based hippocampus segmentation
- **Arxiv ID**: http://arxiv.org/abs/1801.00223v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00223v1)
- **Published**: 2017-12-31 01:52:23+00:00
- **Updated**: 2017-12-31 01:52:23+00:00
- **Authors**: Qiang Zheng, Yong Fan
- **Comment**: Accepted paper in IEEE International Symposium on Biomedical Imaging
  (ISBI), 2018
- **Journal**: None
- **Summary**: A novel multi-atlas based image segmentation method is proposed by integrating a semi-supervised label propagation method and a supervised random forests method in a pattern recognition based label fusion framework. The semi-supervised label propagation method takes into consideration local and global image appearance of images to be segmented and segments the images by propagating reliable segmentation results obtained by the supervised random forests method. Particularly, the random forests method is used to train a regression model based on image patches of atlas images for each voxel of the images to be segmented. The regression model is used to obtain reliable segmentation results to guide the label propagation for the segmentation. The proposed method has been compared with state-of-the-art multi-atlas based image segmentation methods for segmenting the hippocampus in MR images. The experiment results have demonstrated that our method obtained superior segmentation performance.



### Transfer learning for diagnosis of congenital abnormalities of the kidney and urinary tract in children based on Ultrasound imaging data
- **Arxiv ID**: http://arxiv.org/abs/1801.00224v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00224v1)
- **Published**: 2017-12-31 01:55:40+00:00
- **Updated**: 2017-12-31 01:55:40+00:00
- **Authors**: Qiang Zheng, Gregory Tasian, Yong Fan
- **Comment**: Accepted paper in IEEE International Symposium on Biomedical Imaging
  (ISBI), 2018
- **Journal**: None
- **Summary**: Classification of ultrasound (US) kidney images for diagnosis of congenital abnormalities of the kidney and urinary tract (CAKUT) in children is a challenging task. It is desirable to improve existing pattern classification models that are built upon conventional image features. In this study, we propose a transfer learning-based method to extract imaging features from US kidney images in order to improve the CAKUT diagnosis in children. Particularly, a pre-trained deep learning model (imagenet-caffe-alex) is adopted for transfer learning-based feature extraction from 3-channel feature maps computed from US images, including original images, gradient features, and distanced transform features. Support vector machine classifiers are then built upon different sets of features, including the transfer learning features, conventional imaging features, and their combination. Experimental results have demonstrated that the combination of transfer learning features and conventional imaging features yielded the best classification performance for distinguishing CAKUT patients from normal controls based on their US kidney images.



### Context aware saliency map generation using semantic segmentation
- **Arxiv ID**: http://arxiv.org/abs/1801.00256v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00256v2)
- **Published**: 2017-12-31 08:55:17+00:00
- **Updated**: 2018-01-03 08:11:57+00:00
- **Authors**: Mahdi Ahmadi, Mohsen Hajabdollahi, Nader Karimi, Shadrokh Samavi
- **Comment**: 5 pages, 7 figures, 2 tables
- **Journal**: None
- **Summary**: Saliency map detection, as a method for detecting important regions of an image, is used in many applications such as image classification and recognition. We propose that context detection could have an essential role in image saliency detection. This requires extraction of high level features. In this paper a saliency map is proposed, based on image context detection using semantic segmentation as a high level feature. Saliency map from semantic information is fused with color and contrast based saliency maps. The final saliency map is then generated. Simulation results for Pascal-voc11 image dataset show 99% accuracy in context detection. Also final saliency map produced by our proposed method shows acceptable results in detecting salient points.



### Interactive Video Object Segmentation in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1801.00269v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00269v1)
- **Published**: 2017-12-31 11:46:54+00:00
- **Updated**: 2017-12-31 11:46:54+00:00
- **Authors**: Arnaud Benard, Michael Gygli
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present our system for human-in-the-loop video object segmentation. The backbone of our system is a method for one-shot video object segmentation. While fast, this method requires an accurate pixel-level segmentation of one (or several) frames as input. As manually annotating such a segmentation is impractical, we propose a deep interactive image segmentation method, that can accurately segment objects with only a handful of clicks. On the GrabCut dataset, our method obtains 90% IOU with just 3.8 clicks on average, setting the new state of the art. Furthermore, as our method iteratively refines an initial segmentation, it can effectively correct frames where the video object segmentation fails, thus allowing users to quickly obtain high quality results even on challenging sequences. Finally, we investigate usage patterns and give insights in how many steps users take to annotate frames, what kind of corrections they provide, etc., thus giving important insights for further improving interactive video segmentation.



### Deep Stacked Networks with Residual Polishing for Image Inpainting
- **Arxiv ID**: http://arxiv.org/abs/1801.00289v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1801.00289v1)
- **Published**: 2017-12-31 14:32:27+00:00
- **Updated**: 2017-12-31 14:32:27+00:00
- **Authors**: Ugur Demir, Gozde Unal
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have shown promising results in image inpainting even if the missing area is relatively large. However, most of the existing inpainting networks introduce undesired artifacts and noise to the repaired regions. To solve this problem, we present a novel framework which consists of two stacked convolutional neural networks that inpaint the image and remove the artifacts, respectively. The first network considers the global structure of the damaged image and coarsely fills the blank area. Then the second network modifies the repaired image to cancel the noise introduced by the first network. The proposed framework splits the problem into two distinct partitions that can be optimized separately, therefore it can be applied to any inpainting algorithm by changing the first network. Second stage in our framework which aims at polishing the inpainted images can be treated as a denoising problem where a wide range of algorithms can be employed. Our results demonstrate that the proposed framework achieves significant improvement on both visual and quantitative evaluations.



### Towards Building an Intelligent Anti-Malware System: A Deep Learning Approach using Support Vector Machine (SVM) for Malware Classification
- **Arxiv ID**: http://arxiv.org/abs/1801.00318v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.CR, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1801.00318v2)
- **Published**: 2017-12-31 17:13:55+00:00
- **Updated**: 2019-02-07 06:19:41+00:00
- **Authors**: Abien Fred Agarap
- **Comment**: 5 pages, 5 figures, 3 tables
- **Journal**: None
- **Summary**: Effective and efficient mitigation of malware is a long-time endeavor in the information security community. The development of an anti-malware system that can counteract an unknown malware is a prolific activity that may benefit several sectors. We envision an intelligent anti-malware system that utilizes the power of deep learning (DL) models. Using such models would enable the detection of newly-released malware through mathematical generalization. That is, finding the relationship between a given malware $x$ and its corresponding malware family $y$, $f: x \mapsto y$. To accomplish this feat, we used the Malimg dataset (Nataraj et al., 2011) which consists of malware images that were processed from malware binaries, and then we trained the following DL models 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM (Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM stands out among the DL models with a predictive accuracy of ~84.92%. This stands to reason for the mentioned model had the relatively most sophisticated architecture design among the presented models. The exploration of an even more optimal DL-SVM model is the next stage towards the engineering of an intelligent anti-malware system.



### A General Framework for Adversarial Examples with Objectives
- **Arxiv ID**: http://arxiv.org/abs/1801.00349v2
- **DOI**: 10.1145/3317611
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1801.00349v2)
- **Published**: 2017-12-31 20:17:45+00:00
- **Updated**: 2019-04-04 01:14:44+00:00
- **Authors**: Mahmood Sharif, Sruti Bhagavatula, Lujo Bauer, Michael K. Reiter
- **Comment**: Accepted for publication at ACM TOPS
- **Journal**: None
- **Summary**: Images perturbed subtly to be misclassified by neural networks, called adversarial examples, have emerged as a technically deep challenge and an important concern for several application domains. Most research on adversarial examples takes as its only constraint that the perturbed images are similar to the originals. However, real-world application of these ideas often requires the examples to satisfy additional objectives, which are typically enforced through custom modifications of the perturbation process. In this paper, we propose adversarial generative nets (AGNs), a general methodology to train a generator neural network to emit adversarial examples satisfying desired objectives. We demonstrate the ability of AGNs to accommodate a wide range of objectives, including imprecise ones difficult to model, in two application domains. In particular, we demonstrate physical adversarial examples---eyeglass frames designed to fool face recognition---with better robustness, inconspicuousness, and scalability than previous approaches, as well as a new attack to fool a handwritten-digit classifier.



