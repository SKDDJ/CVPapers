# Arxiv Papers in cs.CV on 2017-12-16
### Impression Network for Video Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1712.05896v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.05896v1)
- **Published**: 2017-12-16 02:53:30+00:00
- **Updated**: 2017-12-16 02:53:30+00:00
- **Authors**: Congrui Hetang, Hongwei Qin, Shaohui Liu, Junjie Yan
- **Comment**: Tech Report
- **Journal**: None
- **Summary**: Video object detection is more challenging compared to image object detection. Previous works proved that applying object detector frame by frame is not only slow but also inaccurate. Visual clues get weakened by defocus and motion blur, causing failure on corresponding frames. Multi-frame feature fusion methods proved effective in improving the accuracy, but they dramatically sacrifice the speed. Feature propagation based methods proved effective in improving the speed, but they sacrifice the accuracy. So is it possible to improve speed and performance simultaneously?   Inspired by how human utilize impression to recognize objects from blurry frames, we propose Impression Network that embodies a natural and efficient feature aggregation mechanism. In our framework, an impression feature is established by iteratively absorbing sparsely extracted frame features. The impression feature is propagated all the way down the video, helping enhance features of low-quality frames. This impression mechanism makes it possible to perform long-range multi-frame feature fusion among sparse keyframes with minimal overhead. It significantly improves per-frame detection baseline on ImageNet VID while being 3 times faster (20 fps). We hope Impression Network can provide a new perspective on video feature enhancement. Code will be made available.



### SRPGAN: Perceptual Generative Adversarial Network for Single Image Super Resolution
- **Arxiv ID**: http://arxiv.org/abs/1712.05927v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.05927v2)
- **Published**: 2017-12-16 09:52:43+00:00
- **Updated**: 2017-12-20 17:46:16+00:00
- **Authors**: Bingzhe Wu, Haodong Duan, Zhichao Liu, Guangyu Sun
- **Comment**: None
- **Journal**: None
- **Summary**: Single image super resolution (SISR) is to reconstruct a high resolution image from a single low resolution image. The SISR task has been a very attractive research topic over the last two decades. In recent years, convolutional neural network (CNN) based models have achieved great performance on SISR task. Despite the breakthroughs achieved by using CNN models, there are still some problems remaining unsolved, such as how to recover high frequency details of high resolution images. Previous CNN based models always use a pixel wise loss, such as l2 loss. Although the high resolution images constructed by these models have high peak signal-to-noise ratio (PSNR), they often tend to be blurry and lack high-frequency details, especially at a large scaling factor. In this paper, we build a super resolution perceptual generative adversarial network (SRPGAN) framework for SISR tasks. In the framework, we propose a robust perceptual loss based on the discriminator of the built SRPGAN model. We use the Charbonnier loss function to build the content loss and combine it with the proposed perceptual loss and the adversarial loss. Compared with other state-of-the-art methods, our method has demonstrated great ability to construct images with sharp edges and rich details. We also evaluate our method on different benchmarks and compare it with previous CNN based methods. The results show that our method can achieve much higher structural similarity index (SSIM) scores on most of the benchmarks than the previous state-of-art methods.



### An Artificial Neural Network Architecture Based on Context Transformations in Cortical Minicolumns
- **Arxiv ID**: http://arxiv.org/abs/1712.05954v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1712.05954v1)
- **Published**: 2017-12-16 13:14:03+00:00
- **Updated**: 2017-12-16 13:14:03+00:00
- **Authors**: Vasily Morzhakov, Alexey Redozubov
- **Comment**: 9 pages, 8 figures
- **Journal**: None
- **Summary**: Cortical minicolumns are considered a model of cortical organization. Their function is still a source of research and not reflected properly in modern architecture of nets in algorithms of Artificial Intelligence. We assume its function and describe it in this article. Furthermore, we show how this proposal allows to construct a new architecture, that is not based on convolutional neural networks, test it on MNIST data and receive close to Convolutional Neural Network accuracy. We also show that the proposed architecture possesses an ability to train on a small quantity of samples. To achieve these results, we enable the minicolumns to remember context transformations.



### Learning a Virtual Codec Based on Deep Convolutional Neural Network to Compress Image
- **Arxiv ID**: http://arxiv.org/abs/1712.05969v7
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.05969v7)
- **Published**: 2017-12-16 14:55:13+00:00
- **Updated**: 2018-01-16 10:02:55+00:00
- **Authors**: Lijun Zhao, Huihui Bai, Anhong Wang, Yao Zhao
- **Comment**: 11 pages, 7 figures
- **Journal**: None
- **Summary**: Although deep convolutional neural network has been proved to efficiently eliminate coding artifacts caused by the coarse quantization of traditional codec, it's difficult to train any neural network in front of the encoder for gradient's back-propagation. In this paper, we propose an end-to-end image compression framework based on convolutional neural network to resolve the problem of non-differentiability of the quantization function in the standard codec. First, the feature description neural network is used to get a valid description in the low-dimension space with respect to the ground-truth image so that the amount of image data is greatly reduced for storage or transmission. After image's valid description, standard image codec such as JPEG is leveraged to further compress image, which leads to image's great distortion and compression artifacts, especially blocking artifacts, detail missing, blurring, and ringing artifacts. Then, we use a post-processing neural network to remove these artifacts. Due to the challenge of directly learning a non-linear function for a standard codec based on convolutional neural network, we propose to learn a virtual codec neural network to approximate the projection from the valid description image to the post-processed compressed image, so that the gradient could be efficiently back-propagated from the post-processing neural network to the feature description neural network during training. Meanwhile, an advanced learning algorithm is proposed to train our deep neural networks for compression. Obviously, the priority of the proposed method is compatible with standard existing codecs and our learning strategy can be easily extended into these codecs based on convolutional neural network. Experimental results have demonstrated the advances of the proposed method as compared to several state-of-the-art approaches, especially at very low bit-rate.



### An ILP Solver for Multi-label MRFs with Connectivity Constraints
- **Arxiv ID**: http://arxiv.org/abs/1712.06020v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.06020v2)
- **Published**: 2017-12-16 21:19:44+00:00
- **Updated**: 2018-03-20 09:43:47+00:00
- **Authors**: Ruobing Shen, Eric Kendinibilir, Ismail Ben Ayed, Andrea Lodi, Andrea Tramontani, Gerhard Reinelt
- **Comment**: 19 pages
- **Journal**: None
- **Summary**: Integer Linear Programming (ILP) formulations of Markov random fields (MRFs) models with global connectivity priors were investigated previously in computer vision, e.g., \cite{globalinter,globalconn}. In these works, only Linear Programing (LP) relaxations \cite{globalinter,globalconn} or simplified versions \cite{graphcutbase} of the problem were solved. This paper investigates the ILP of multi-label MRF with exact connectivity priors via a branch-and-cut method, which provably finds globally optimal solutions. The method enforces connectivity priors iteratively by a cutting plane method, and provides feasible solutions with a guarantee on sub-optimality even if we terminate it earlier. The proposed ILP can be applied as a post-processing method on top of any existing multi-label segmentation approach. As it provides globally optimal solution, it can be used off-line to generate ground-truth labeling, which serves as quality check for any fast on-line algorithm. Furthermore, it can be used to generate ground-truth proposals for weakly supervised segmentation. We demonstrate the power and usefulness of our model by several experiments on the BSDS500 and PASCAL image dataset, as well as on medical images with trained probability maps.



