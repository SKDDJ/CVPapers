# Arxiv Papers in cs.CV on 2017-12-24
### Use of Generative Adversarial Network for Cross-Domain Change Detection
- **Arxiv ID**: http://arxiv.org/abs/1712.08868v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.08868v1)
- **Published**: 2017-12-24 02:23:57+00:00
- **Updated**: 2017-12-24 02:23:57+00:00
- **Authors**: Yamaguchi Kousuke, Tanaka Kanji, Sugimoto Takuma
- **Comment**: 5 pages, 4 figures, technical report
- **Journal**: None
- **Summary**: This paper addresses the problem of cross-domain change detection from a novel perspective of image-to-image translation. In general, change detection aims to identify interesting changes between a given query image and a reference image of the same scene taken at a different time. This problem becomes a challenging one when query and reference images involve different domains (e.g., time of the day, weather, and season) due to variations in object appearance and a limited amount of training examples. In this study, we address the above issue by leveraging a generative adversarial network (GAN). Our key concept is to use a limited amount of training data to train a GAN-based image translator that maps a reference image to a virtual image that cannot be discriminated from query domain images. This enables us to treat the cross-domain change detection task as an in-domain image comparison. This allows us to leverage the large body of literature on in-domain generic change detectors. In addition, we also consider the use of visual place recognition as a method for mining more appropriate reference images over the space of virtual images. Experiments validate efficacy of the proposed approach.



### Blind Image Deblurring via Reweighted Graph Total Variation
- **Arxiv ID**: http://arxiv.org/abs/1712.08877v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.08877v1)
- **Published**: 2017-12-24 05:01:47+00:00
- **Updated**: 2017-12-24 05:01:47+00:00
- **Authors**: Yuanchao Bai, Gene Cheung, Xianming Liu, Wen Gao
- **Comment**: 5 pages, submitted to IEEE International Conference on Acoustics,
  Speech and Signal Processing, Calgary, Alberta, Canada, April, 2018
- **Journal**: None
- **Summary**: Blind image deblurring, i.e., deblurring without knowledge of the blur kernel, is a highly ill-posed problem. The problem can be solved in two parts: i) estimate a blur kernel from the blurry image, and ii) given estimated blur kernel, de-convolve blurry input to restore the target image. In this paper, by interpreting an image patch as a signal on a weighted graph, we first argue that a skeleton image---a proxy that retains the strong gradients of the target but smooths out the details---can be used to accurately estimate the blur kernel and has a unique bi-modal edge weight distribution. We then design a reweighted graph total variation (RGTV) prior that can efficiently promote bi-modal edge weight distribution given a blurry patch. However, minimizing a blind image deblurring objective with RGTV results in a non-convex non-differentiable optimization problem. We propose a fast algorithm that solves for the skeleton image and the blur kernel alternately. Finally with the computed blur kernel, recent non-blind image deblurring algorithms can be applied to restore the target image. Experimental results show that our algorithm can robustly estimate the blur kernel with large kernel size, and the reconstructed sharp image is competitive against the state-of-the-art methods.



### PuRe: Robust pupil detection for real-time pervasive eye tracking
- **Arxiv ID**: http://arxiv.org/abs/1712.08900v1
- **DOI**: 10.1016/j.cviu.2018.02.002
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1712.08900v1)
- **Published**: 2017-12-24 10:09:10+00:00
- **Updated**: 2017-12-24 10:09:10+00:00
- **Authors**: Thiago Santini, Wolfgang Fuhl, Enkelejda Kasneci
- **Comment**: None
- **Journal**: None
- **Summary**: Real-time, accurate, and robust pupil detection is an essential prerequisite to enable pervasive eye-tracking and its applications -- e.g., gaze-based human computer interaction, health monitoring, foveated rendering, and advanced driver assistance. However, automated pupil detection has proved to be an intricate task in real-world scenarios due to a large mixture of challenges such as quickly changing illumination and occlusions. In this paper, we introduce the Pupil Reconstructor PuRe, a method for pupil detection in pervasive scenarios based on a novel edge segment selection and conditional segment combination schemes; the method also includes a confidence measure for the detected pupil. The proposed method was evaluated on over 316,000 images acquired with four distinct head-mounted eye tracking devices. Results show a pupil detection rate improvement of over 10 percentage points w.r.t. state-of-the-art algorithms in the two most challenging data sets (6.46 for all data sets), further pushing the envelope for pupil detection. Moreover, we advance the evaluation protocol of pupil detection algorithms by also considering eye images in which pupils are not present. In this aspect, PuRe improved precision and specificity w.r.t. state-of-the-art algorithms by 25.05 and 10.94 percentage points, respectively, demonstrating the meaningfulness of PuRe's confidence measure. PuRe operates in real-time for modern eye trackers (at 120 fps).



