# Arxiv Papers in cs.CV on 2017-11-03
### AxonDeepSeg: automatic axon and myelin segmentation from microscopy data using convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1711.01004v2
- **DOI**: 10.1038/s41598-018-22181-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01004v2)
- **Published**: 2017-11-03 03:04:23+00:00
- **Updated**: 2017-11-17 16:10:04+00:00
- **Authors**: Aldo Zaimi, Maxime Wabartha, Victor Herman, Pierre-Louis Antonsanti, Christian Samuel Perone, Julien Cohen-Adad
- **Comment**: 14 pages, 7 figures
- **Journal**: None
- **Summary**: Segmentation of axon and myelin from microscopy images of the nervous system provides useful quantitative information about the tissue microstructure, such as axon density and myelin thickness. This could be used for instance to document cell morphometry across species, or to validate novel non-invasive quantitative magnetic resonance imaging techniques. Most currently-available segmentation algorithms are based on standard image processing and usually require multiple processing steps and/or parameter tuning by the user to adapt to different modalities. Moreover, only few methods are publicly available. We introduce AxonDeepSeg, an open-source software that performs axon and myelin segmentation of microscopic images using deep learning. AxonDeepSeg features: (i) a convolutional neural network architecture; (ii) an easy training procedure to generate new models based on manually-labelled data and (iii) two ready-to-use models trained from scanning electron microscopy (SEM) and transmission electron microscopy (TEM). Results show high pixel-wise accuracy across various species: 85% on rat SEM, 81% on human SEM, 95% on mice TEM and 84% on macaque TEM. Segmentation of a full rat spinal cord slice is computed and morphological metrics are extracted and compared against the literature. AxonDeepSeg is freely available at https://github.com/neuropoly/axondeepseg



### In-Bed Pose Estimation: Deep Learning with Shallow Dataset
- **Arxiv ID**: http://arxiv.org/abs/1711.01005v3
- **DOI**: 10.1109/JTEHM.2019.2892970
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01005v3)
- **Published**: 2017-11-03 03:05:05+00:00
- **Updated**: 2018-07-07 20:37:06+00:00
- **Authors**: Shuangjun Liu, Yu Yin, Sarah Ostadabbas
- **Comment**: None
- **Journal**: IEEE Journal of Translational Engineering in Health and Medicine
  2019
- **Summary**: Although human pose estimation for various computer vision (CV) applications has been studied extensively in the last few decades, yet in-bed pose estimation using camera-based vision methods has been ignored by the CV community because it is assumed to be identical to the general purpose pose estimation methods. However, in-bed pose estimation has its own specialized aspects and comes with specific challenges including the notable differences in lighting conditions throughout a day and also having different pose distribution from the common human surveillance viewpoint. In this paper, we demonstrate that these challenges significantly lessen the effectiveness of existing general purpose pose estimation models. In order to address the lighting variation challenge, infrared selective (IRS) image acquisition technique is proposed to provide uniform quality data under various lighting conditions. In addition, to deal with unconventional pose perspective, a 2-end histogram of oriented gradient (HOG) rectification method is presented. In this work, we explored the idea of employing a pre-trained convolutional neural network (CNN) model trained on large public datasets of general human poses and fine-tuning the model using our own shallow in-bed IRS dataset. We developed an IRS imaging system and collected IRS image data from several realistic life-size mannequins in a simulated hospital room environment. A pre-trained CNN called convolutional pose machine (CPM) was repurposed for in-bed pose estimation by fine-tuning its specific intermediate layers. Using the HOG rectification method, the pose estimation performance of CPM significantly improved by 26.4% in PCK0.1 criteria compared to the model without such rectification.



### A Taught-Obesrve-Ask (TOA) Method for Object Detection with Critical Supervision
- **Arxiv ID**: http://arxiv.org/abs/1711.01043v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01043v1)
- **Published**: 2017-11-03 07:19:59+00:00
- **Updated**: 2017-11-03 07:19:59+00:00
- **Authors**: Chi-Hao Wu, Qin Huang, Siyang Li, C. -C. Jay Kuo
- **Comment**: None
- **Journal**: None
- **Summary**: Being inspired by child's learning experience - taught first and followed by observation and questioning, we investigate a critically supervised learning methodology for object detection in this work. Specifically, we propose a taught-observe-ask (TOA) method that consists of several novel components such as negative object proposal, critical example mining, and machine-guided question-answer (QA) labeling. To consider labeling time and performance jointly, new evaluation methods are developed to compare the performance of the TOA method, with the fully and weakly supervised learning methods. Extensive experiments are conducted on the PASCAL VOC and the Caltech benchmark datasets. The TOA method provides significantly improved performance of weakly supervision yet demands only about 3-6% of labeling time of full supervision. The effectiveness of each novel component is also analyzed.



### Multi-Glimpse LSTM with Color-Depth Feature Fusion for Human Detection
- **Arxiv ID**: http://arxiv.org/abs/1711.01062v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01062v1)
- **Published**: 2017-11-03 08:52:42+00:00
- **Updated**: 2017-11-03 08:52:42+00:00
- **Authors**: Hengduo Li, Jun Liu, Guyue Zhang, Yuan Gao, Yirui Wu
- **Comment**: ICIP 2017 Oral
- **Journal**: None
- **Summary**: With the development of depth cameras such as Kinect and Intel Realsense, RGB-D based human detection receives continuous research attention due to its usage in a variety of applications. In this paper, we propose a new Multi-Glimpse LSTM (MG-LSTM) network, in which multi-scale contextual information is sequentially integrated to promote the human detection performance. Furthermore, we propose a feature fusion strategy based on our MG-LSTM network to better incorporate the RGB and depth information. To the best of our knowledge, this is the first attempt to utilize LSTM structure for RGB-D based human detection. Our method achieves superior performance on two publicly available datasets.



### Î©-Net (Omega-Net): Fully Automatic, Multi-View Cardiac MR Detection, Orientation, and Segmentation with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.01094v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01094v3)
- **Published**: 2017-11-03 10:31:27+00:00
- **Updated**: 2018-03-20 10:32:33+00:00
- **Authors**: Davis M. Vigneault, Weidi Xie, Carolyn Y. Ho, David A. Bluemke, J. Alison Noble
- **Comment**: First two authors contributed equally to this work, result for MICCAI
  Automated Cardiac Diagnosis Challenge (ACDC) dataset is added
- **Journal**: None
- **Summary**: Pixelwise segmentation of the left ventricular (LV) myocardium and the four cardiac chambers in 2-D steady state free precession (SSFP) cine sequences is an essential preprocessing step for a wide range of analyses. Variability in contrast, appearance, orientation, and placement of the heart between patients, clinical views, scanners, and protocols makes fully automatic semantic segmentation a notoriously difficult problem. Here, we present ${\Omega}$-Net (Omega-Net): a novel convolutional neural network (CNN) architecture for simultaneous localization, transformation into a canonical orientation, and semantic segmentation. First, an initial segmentation is performed on the input image, second, the features learned during this initial segmentation are used to predict the parameters needed to transform the input image into a canonical orientation, and third, a final segmentation is performed on the transformed image. In this work, ${\Omega}$-Nets of varying depths were trained to detect five foreground classes in any of three clinical views (short axis, SA, four-chamber, 4C, two-chamber, 2C), without prior knowledge of the view being segmented. The architecture was trained on a cohort of patients with hypertrophic cardiomyopathy and healthy control subjects. Network performance as measured by weighted foreground intersection-over-union (IoU) was substantially improved in the best-performing ${\Omega}$- Net compared with U-Net segmentation without localization or orientation. In addition, {\Omega}-Net was retrained from scratch on the 2017 MICCAI ACDC dataset, and achieves state-of-the-art results on the LV and RV bloodpools, and performed slightly worse in segmentation of the LV myocardium. We conclude this architecture represents a substantive advancement over prior approaches, with implications for biomedical image segmentation more generally.



### Motion Artifact Detection in Confocal Laser Endomicroscopy Images
- **Arxiv ID**: http://arxiv.org/abs/1711.01117v2
- **DOI**: 10.1007/978-3-662-56537-7_85
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01117v2)
- **Published**: 2017-11-03 12:02:46+00:00
- **Updated**: 2018-05-04 12:47:13+00:00
- **Authors**: Maike P. Stoeve, Marc Aubreville, Nicolai Oetter, Christian Knipfer, Helmut Neumann, Florian Stelzle, Andreas Maier
- **Comment**: None
- **Journal**: Bildverarbeitung f\"ur die Medizin 2018 (2018) 328-333
- **Summary**: Confocal Laser Endomicroscopy (CLE), an optical imaging technique allowing non-invasive examination of the mucosa on a (sub)cellular level, has proven to be a valuable diagnostic tool in gastroenterology and shows promising results in various anatomical regions including the oral cavity. Recently, the feasibility of automatic carcinoma detection for CLE images of sufficient quality was shown. However, in real world data sets a high amount of CLE images is corrupted by artifacts. Amongst the most prevalent artifact types are motion-induced image deteriorations. In the scope of this work, algorithmic approaches for the automatic detection of motion artifact-tainted image regions were developed. Hence, this work provides an important step towards clinical applicability of automatic carcinoma detection. Both, conventional machine learning and novel, deep learning-based approaches were assessed. The deep learning-based approach outperforms the conventional approaches, attaining an AUC of 0.90.



### End-to-end Flow Correlation Tracking with Spatial-temporal Attention
- **Arxiv ID**: http://arxiv.org/abs/1711.01124v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01124v4)
- **Published**: 2017-11-03 12:20:50+00:00
- **Updated**: 2018-02-27 12:08:55+00:00
- **Authors**: Zheng Zhu, Wei Wu, Wei Zou, Junjie Yan
- **Comment**: Accepted in CVPR 2018
- **Journal**: None
- **Summary**: Discriminative correlation filters (DCF) with deep convolutional features have achieved favorable performance in recent tracking benchmarks. However, most of existing DCF trackers only consider appearance features of current frame, and hardly benefit from motion and inter-frame information. The lack of temporal information degrades the tracking performance during challenges such as partial occlusion and deformation. In this work, we focus on making use of the rich flow information in consecutive frames to improve the feature representation and the tracking accuracy. Firstly, individual components, including optical flow estimation, feature extraction, aggregation and correlation filter tracking are formulated as special layers in network. To the best of our knowledge, this is the first work to jointly train flow and tracking task in a deep learning framework. Then the historical feature maps at predefined intervals are warped and aggregated with current ones by the guiding of flow. For adaptive aggregation, we propose a novel spatial-temporal attention mechanism. Extensive experiments are performed on four challenging tracking datasets: OTB2013, OTB2015, VOT2015 and VOT2016, and the proposed method achieves superior results on these benchmarks.



### Radical analysis network for zero-shot learning in printed Chinese character recognition
- **Arxiv ID**: http://arxiv.org/abs/1711.01889v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1711.01889v2)
- **Published**: 2017-11-03 14:40:28+00:00
- **Updated**: 2018-03-29 05:25:29+00:00
- **Authors**: Jianshu Zhang, Yixing Zhu, Jun Du, Lirong Dai
- **Comment**: Accepted by ICME2018
- **Journal**: None
- **Summary**: Chinese characters have a huge set of character categories, more than 20,000 and the number is still increasing as more and more novel characters continue being created. However, the enormous characters can be decomposed into a compact set of about 500 fundamental and structural radicals. This paper introduces a novel radical analysis network (RAN) to recognize printed Chinese characters by identifying radicals and analyzing two-dimensional spatial structures among them. The proposed RAN first extracts visual features from input by employing convolutional neural networks as an encoder. Then a decoder based on recurrent neural networks is employed, aiming at generating captions of Chinese characters by detecting radicals and two-dimensional structures through a spatial attention mechanism. The manner of treating a Chinese character as a composition of radicals rather than a single character class largely reduces the size of vocabulary and enables RAN to possess the ability of recognizing unseen Chinese character classes, namely zero-shot learning.



### Convolutional Drift Networks for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1711.01201v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1711.01201v1)
- **Published**: 2017-11-03 15:07:24+00:00
- **Updated**: 2017-11-03 15:07:24+00:00
- **Authors**: Dillon Graham, Seyed Hamed Fatemi Langroudi, Christopher Kanan, Dhireesha Kudithipudi
- **Comment**: Published in IEEE Rebooting Computing
- **Journal**: None
- **Summary**: Analyzing spatio-temporal data like video is a challenging task that requires processing visual and temporal information effectively. Convolutional Neural Networks have shown promise as baseline fixed feature extractors through transfer learning, a technique that helps minimize the training cost on visual information. Temporal information is often handled using hand-crafted features or Recurrent Neural Networks, but this can be overly specific or prohibitively complex. Building a fully trainable system that can efficiently analyze spatio-temporal data without hand-crafted features or complex training is an open challenge. We present a new neural network architecture to address this challenge, the Convolutional Drift Network (CDN). Our CDN architecture combines the visual feature extraction power of deep Convolutional Neural Networks with the intrinsically efficient temporal processing provided by Reservoir Computing. In this introductory paper on the CDN, we provide a very simple baseline implementation tested on two egocentric (first-person) video activity datasets.We achieve video-level activity classification results on-par with state-of-the art methods. Notably, performance on this complex spatio-temporal task was produced by only training a single feed-forward layer in the CDN.



### Background Subtraction via Fast Robust Matrix Completion
- **Arxiv ID**: http://arxiv.org/abs/1711.01218v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1711.01218v1)
- **Published**: 2017-11-03 15:55:49+00:00
- **Updated**: 2017-11-03 15:55:49+00:00
- **Authors**: Behnaz Rezaei, Sarah Ostadabbas
- **Comment**: None
- **Journal**: None
- **Summary**: Background subtraction is the primary task of the majority of video inspection systems. The most important part of the background subtraction which is common among different algorithms is background modeling. In this regard, our paper addresses the problem of background modeling in a computationally efficient way, which is important for current eruption of "big data" processing coming from high resolution multi-channel videos. Our model is based on the assumption that background in natural images lies on a low-dimensional subspace. We formulated and solved this problem in a low-rank matrix completion framework. In modeling the background, we benefited from the in-face extended Frank-Wolfe algorithm for solving a defined convex optimization problem. We evaluated our fast robust matrix completion (fRMC) method on both background models challenge (BMC) and Stuttgart artificial background subtraction (SABS) datasets. The results were compared with the robust principle component analysis (RPCA) and low-rank robust matrix completion (RMC) methods, both solved by inexact augmented Lagrangian multiplier (IALM). The results showed faster computation, at least twice as when IALM solver is used, while having a comparable accuracy even better in some challenges, in subtracting the backgrounds in order to detect moving objects in the scene.



### Real-Time Document Image Classification using Deep CNN and Extreme Learning Machines
- **Arxiv ID**: http://arxiv.org/abs/1711.05862v1
- **DOI**: 10.1109/ICDAR.2017.217
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05862v1)
- **Published**: 2017-11-03 17:02:57+00:00
- **Updated**: 2017-11-03 17:02:57+00:00
- **Authors**: Andreas KÃ¶lsch, Muhammad Zeshan Afzal, Markus Ebbecke, Marcus Liwicki
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents an approach for real-time training and testing for document image classification. In production environments, it is crucial to perform accurate and (time-)efficient training. Existing deep learning approaches for classifying documents do not meet these requirements, as they require much time for training and fine-tuning the deep architectures. Motivated from Computer Vision, we propose a two-stage approach. The first stage trains a deep network that works as feature extractor and in the second stage, Extreme Learning Machines (ELMs) are used for classification. The proposed approach outperforms all previously reported structural and deep learning based methods with a final accuracy of 83.24% on Tobacco-3482 dataset, leading to a relative error reduction of 25% when compared to a previous Convolutional Neural Network (CNN) based approach (DeepDocClassifier). More importantly, the training time of the ELM is only 1.176 seconds and the overall prediction time for 2,482 images is 3.066 seconds. As such, this novel approach makes deep learning-based document classification suitable for large-scale real-time applications.



### Routing Networks: Adaptive Selection of Non-linear Functions for Multi-Task Learning
- **Arxiv ID**: http://arxiv.org/abs/1711.01239v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1711.01239v2)
- **Published**: 2017-11-03 17:07:51+00:00
- **Updated**: 2017-12-31 14:53:00+00:00
- **Authors**: Clemens Rosenbaum, Tim Klinger, Matthew Riemer
- **Comment**: Under Review at ICLR 2018
- **Journal**: None
- **Summary**: Multi-task learning (MTL) with neural networks leverages commonalities in tasks to improve performance, but often suffers from task interference which reduces the benefits of transfer. To address this issue we introduce the routing network paradigm, a novel neural network and training algorithm. A routing network is a kind of self-organizing neural network consisting of two components: a router and a set of one or more function blocks. A function block may be any neural network - for example a fully-connected or a convolutional layer. Given an input the router makes a routing decision, choosing a function block to apply and passing the output back to the router recursively, terminating when a fixed recursion depth is reached. In this way the routing network dynamically composes different function blocks for each input. We employ a collaborative multi-agent reinforcement learning (MARL) approach to jointly train the router and function blocks. We evaluate our model against cross-stitch networks and shared-layer baselines on multi-task settings of the MNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a significant improvement in accuracy, with sharper convergence. In addition, routing networks have nearly constant per-task training cost while cross-stitch networks scale linearly with the number of tasks. On CIFAR-100 (20 tasks) we obtain cross-stitch performance levels with an 85% reduction in training time.



### ReBNet: Residual Binarized Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1711.01243v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1711.01243v3)
- **Published**: 2017-11-03 17:12:15+00:00
- **Updated**: 2018-03-27 20:58:01+00:00
- **Authors**: Mohammad Ghasemzadeh, Mohammad Samragh, Farinaz Koushanfar
- **Comment**: To Appear In The 26th IEEE International Symposium on
  Field-Programmable Custom Computing Machines
- **Journal**: None
- **Summary**: This paper proposes ReBNet, an end-to-end framework for training reconfigurable binary neural networks on software and developing efficient accelerators for execution on FPGA. Binary neural networks offer an intriguing opportunity for deploying large-scale deep learning models on resource-constrained devices. Binarization reduces the memory footprint and replaces the power-hungry matrix-multiplication with light-weight XnorPopcount operations. However, binary networks suffer from a degraded accuracy compared to their fixed-point counterparts. We show that the state-of-the-art methods for optimizing binary networks accuracy, significantly increase the implementation cost and complexity. To compensate for the degraded accuracy while adhering to the simplicity of binary networks, we devise the first reconfigurable scheme that can adjust the classification accuracy based on the application. Our proposition improves the classification accuracy by representing features with multiple levels of residual binarization. Unlike previous methods, our approach does not exacerbate the area cost of the hardware accelerator. Instead, it provides a tradeoff between throughput and accuracy while the area overhead of multi-level binarization is negligible.



### Distributed Unmixing of Hyperspectral Data With Sparsity Constraint
- **Arxiv ID**: http://arxiv.org/abs/1711.01249v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01249v1)
- **Published**: 2017-11-03 17:23:49+00:00
- **Updated**: 2017-11-03 17:23:49+00:00
- **Authors**: Sara Khoshsokhan, Roozbeh Rajabi, Hadi Zayyani
- **Comment**: 6 pages, conference paper
- **Journal**: None
- **Summary**: Spectral unmixing (SU) is a data processing problem in hyperspectral remote sensing. The significant challenge in the SU problem is how to identify endmembers and their weights, accurately. For estimation of signature and fractional abundance matrices in a blind problem, nonnegative matrix factorization (NMF) and its developments are used widely in the SU problem. One of the constraints which was added to NMF is sparsity constraint that was regularized by L 1/2 norm. In this paper, a new algorithm based on distributed optimization has been used for spectral unmixing. In the proposed algorithm, a network including single-node clusters has been employed. Each pixel in hyperspectral images considered as a node in this network. The distributed unmixing with sparsity constraint has been optimized with diffusion LMS strategy, and then the update equations for fractional abundance and signature matrices are obtained. Simulation results based on defined performance metrics, illustrate advantage of the proposed algorithm in spectral unmixing of hyperspectral data compared with other methods. The results show that the AAD and SAD of the proposed approach are improved respectively about 6 and 27 percent toward distributed unmixing in SNR=25dB.



### Fine-tuning CNN Image Retrieval with No Human Annotation
- **Arxiv ID**: http://arxiv.org/abs/1711.02512v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02512v2)
- **Published**: 2017-11-03 21:29:55+00:00
- **Updated**: 2018-07-10 05:25:34+00:00
- **Authors**: Filip RadenoviÄ, Giorgos Tolias, OndÅej Chum
- **Comment**: TPAMI 2018. arXiv admin note: substantial text overlap with
  arXiv:1604.02426
- **Journal**: None
- **Summary**: Image descriptors based on activations of Convolutional Neural Networks (CNNs) have become dominant in image retrieval due to their discriminative power, compactness of representation, and search efficiency. Training of CNNs, either from scratch or fine-tuning, requires a large amount of annotated data, where a high quality of annotation is often crucial. In this work, we propose to fine-tune CNNs for image retrieval on a large collection of unordered images in a fully automated manner. Reconstructed 3D models obtained by the state-of-the-art retrieval and structure-from-motion methods guide the selection of the training data. We show that both hard-positive and hard-negative examples, selected by exploiting the geometry and the camera positions available from the 3D models, enhance the performance of particular-object retrieval. CNN descriptor whitening discriminatively learned from the same training data outperforms commonly used PCA whitening. We propose a novel trainable Generalized-Mean (GeM) pooling layer that generalizes max and average pooling and show that it boosts retrieval performance. Applying the proposed method to the VGG network achieves state-of-the-art performance on the standard benchmarks: Oxford Buildings, Paris, and Holidays datasets.



### Computationally efficient cardiac views projection using 3D Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.01345v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.01345v1)
- **Published**: 2017-11-03 21:47:05+00:00
- **Updated**: 2017-11-03 21:47:05+00:00
- **Authors**: Matthieu Le, Jesse Lieman-Sifry, Felix Lau, Sean Sall, Albert Hsiao, Daniel Golden
- **Comment**: None
- **Journal**: None
- **Summary**: 4D Flow is an MRI sequence which allows acquisition of 3D images of the heart. The data is typically acquired volumetrically, so it must be reformatted to generate cardiac long axis and short axis views for diagnostic interpretation. These views may be generated by placing 6 landmarks: the left and right ventricle apex, and the aortic, mitral, pulmonary, and tricuspid valves. In this paper, we propose an automatic method to localize landmarks in order to compute the cardiac views. Our approach consists of first calculating a bounding box that tightly crops the heart, followed by a landmark localization step within this bounded region. Both steps are based on a 3D extension of the recently introduced ENet. We demonstrate that the long and short axis projections computed with our automated method are of equivalent quality to projections created with landmarks placed by an experienced cardiac radiologist, based on a blinded test administered to a different cardiac radiologist.



### Reconstructing Video from Interferometric Measurements of Time-Varying Sources
- **Arxiv ID**: http://arxiv.org/abs/1711.01357v2
- **DOI**: None
- **Categories**: **astro-ph.IM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1711.01357v2)
- **Published**: 2017-11-03 23:09:17+00:00
- **Updated**: 2018-02-01 23:37:42+00:00
- **Authors**: Katherine L. Bouman, Michael D. Johnson, Adrian V. Dalca, Andrew A. Chael, Freek Roelofs, Sheperd S. Doeleman, William T. Freeman
- **Comment**: Submitted to Transactions on Computational Imaging
- **Journal**: None
- **Summary**: Very long baseline interferometry (VLBI) makes it possible to recover images of astronomical sources with extremely high angular resolution. Most recently, the Event Horizon Telescope (EHT) has extended VLBI to short millimeter wavelengths with a goal of achieving angular resolution sufficient for imaging the event horizons of nearby supermassive black holes. VLBI provides measurements related to the underlying source image through a sparse set spatial frequencies. An image can then be recovered from these measurements by making assumptions about the underlying image. One of the most important assumptions made by conventional imaging methods is that over the course of a night's observation the image is static. However, for quickly evolving sources, such as the galactic center's supermassive black hole (Sgr A*) targeted by the EHT, this assumption is violated and these conventional imaging approaches fail. In this work we propose a new way to model VLBI measurements that allows us to recover both the appearance and dynamics of an evolving source by reconstructing a video rather than a static image. By modeling VLBI measurements using a Gaussian Markov Model, we are able to propagate information across observations in time to reconstruct a video, while simultaneously learning about the dynamics of the source's emission region. We demonstrate our proposed Expectation-Maximization (EM) algorithm, StarWarps, on realistic synthetic observations of black holes, and show how it substantially improves results compared to conventional imaging algorithms. Additionally, we demonstrate StarWarps on real VLBI data of the M87 Jet from the VLBA.



