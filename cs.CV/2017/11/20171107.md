# Arxiv Papers in cs.CV on 2017-11-07
### Visually-Aware Fashion Recommendation and Design with Generative Image Models
- **Arxiv ID**: http://arxiv.org/abs/1711.02231v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.HC, cs.IR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1711.02231v1)
- **Published**: 2017-11-07 00:17:51+00:00
- **Updated**: 2017-11-07 00:17:51+00:00
- **Authors**: Wang-Cheng Kang, Chen Fang, Zhaowen Wang, Julian McAuley
- **Comment**: 10 pages, 6 figures. Accepted by ICDM'17 as a long paper
- **Journal**: None
- **Summary**: Building effective recommender systems for domains like fashion is challenging due to the high level of subjectivity and the semantic complexity of the features involved (i.e., fashion styles). Recent work has shown that approaches to `visual' recommendation (e.g.~clothing, art, etc.) can be made more accurate by incorporating visual signals directly into the recommendation objective, using `off-the-shelf' feature representations derived from deep networks. Here, we seek to extend this contribution by showing that recommendation performance can be significantly improved by learning `fashion aware' image representations directly, i.e., by training the image representation (from the pixel level) and the recommender system jointly; this contribution is related to recent work using Siamese CNNs, though we are able to show improvements over state-of-the-art recommendation techniques such as BPR and variants that make use of pre-trained visual features. Furthermore, we show that our model can be used \emph{generatively}, i.e., given a user and a product category, we can generate new images (i.e., clothing items) that are most consistent with their personal taste. This represents a first step towards building systems that go beyond recommending existing items from a product corpus, but which can be used to suggest styles and aid the design of new products.



### Challenges in Disentangling Independent Factors of Variation
- **Arxiv ID**: http://arxiv.org/abs/1711.02245v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02245v1)
- **Published**: 2017-11-07 01:13:04+00:00
- **Updated**: 2017-11-07 01:13:04+00:00
- **Authors**: Attila Szab√≥, Qiyang Hu, Tiziano Portenier, Matthias Zwicker, Paolo Favaro
- **Comment**: Submitted to ICLR 2018
- **Journal**: None
- **Summary**: We study the problem of building models that disentangle independent factors of variation. Such models could be used to encode features that can efficiently be used for classification and to transfer attributes between different images in image synthesis. As data we use a weakly labeled training set. Our weak labels indicate what single factor has changed between two data samples, although the relative value of the change is unknown. This labeling is of particular interest as it may be readily available without annotation costs. To make use of weak labels we introduce an autoencoder model and train it through constraints on image pairs and triplets. We formally prove that without additional knowledge there is no guarantee that two images with the same factor of variation will be mapped to the same feature. We call this issue the reference ambiguity. Moreover, we show the role of the feature dimensionality and adversarial training. We demonstrate experimentally that the proposed model can successfully transfer attributes on several datasets, but show also cases when the reference ambiguity occurs.



### SparCE: Sparsity aware General Purpose Core Extensions to Accelerate Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.06315v2
- **DOI**: None
- **Categories**: **cs.DC**, cs.AR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1711.06315v2)
- **Published**: 2017-11-07 01:20:19+00:00
- **Updated**: 2017-11-29 16:42:03+00:00
- **Authors**: Sanchari Sen, Shubham Jain, Swagath Venkataramani, Anand Raghunathan
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Neural Networks (DNNs) have emerged as the method of choice for solving a wide range of machine learning tasks. The enormous computational demands posed by DNNs have most commonly been addressed through the design of custom accelerators. However, these accelerators are prohibitive in many design scenarios (e.g., wearable devices and IoT sensors), due to stringent area/cost constraints. Accelerating DNNs on these low-power systems, comprising of mainly the general-purpose processor (GPP) cores, requires new approaches. We improve the performance of DNNs on GPPs by exploiting a key attribute of DNNs, i.e., sparsity. We propose Sparsity aware Core Extensions (SparCE)- a set of micro-architectural and ISA extensions that leverage sparsity and are minimally intrusive and low-overhead. We dynamically detect zero operands and skip a set of future instructions that use it. Our design ensures that the instructions to be skipped are prevented from even being fetched, as squashing instructions comes with a penalty. SparCE consists of 2 key micro-architectural enhancements- a Sparsity Register File (SpRF) that tracks zero registers and a Sparsity aware Skip Address (SASA) table that indicates instructions to be skipped. When an instruction is fetched, SparCE dynamically pre-identifies whether the following instruction(s) can be skipped and appropriately modifies the program counter, thereby skipping the redundant instructions and improving performance. We model SparCE using the gem5 architectural simulator, and evaluate our approach on 6 image-recognition DNNs in the context of both training and inference using the Caffe framework. On a scalar microprocessor, SparCE achieves 19%-31% reduction in application-level. We also evaluate SparCE on a 4-way SIMD ARMv8 processor using the OpenBLAS library, and demonstrate that SparCE achieves 8%-15% reduction in the application-level execution time.



### Doppler-Radar Based Hand Gesture Recognition System Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.02254v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02254v3)
- **Published**: 2017-11-07 01:58:11+00:00
- **Updated**: 2017-11-22 11:53:47+00:00
- **Authors**: Jiajun Zhang, Jinkun Tao, Jiangtao Huangfu, Zhiguo Shi
- **Comment**: Best Paper Award of International Conference on Communications,
  Signal Processing, and Systems 2017
- **Journal**: None
- **Summary**: Hand gesture recognition has long been a hot topic in human computer interaction. Traditional camera-based hand gesture recognition systems cannot work properly under dark circumstances. In this paper, a Doppler Radar based hand gesture recognition system using convolutional neural networks is proposed. A cost-effective Doppler radar sensor with dual receiving channels at 5.8GHz is used to acquire a big database of four standard gestures. The received hand gesture signals are then processed with time-frequency analysis. Convolutional neural networks are used to classify different gestures. Experimental results verify the effectiveness of the system with an accuracy of 98%. Besides, related factors such as recognition distance and gesture scale are investigated.



### GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.02257v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02257v4)
- **Published**: 2017-11-07 02:08:12+00:00
- **Updated**: 2018-06-12 06:45:49+00:00
- **Authors**: Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, Andrew Rabinovich
- **Comment**: ICML 2018
- **Journal**: Proceedings of the 35th International Conference on Machine
  Learning (2018), 793-802
- **Summary**: Deep multitask networks, in which one neural network produces multiple predictive outputs, can offer better speed and performance than their single-task counterparts but are challenging to train properly. We present a gradient normalization (GradNorm) algorithm that automatically balances training in deep multitask models by dynamically tuning gradient magnitudes. We show that for various network architectures, for both regression and classification tasks, and on both synthetic and real datasets, GradNorm improves accuracy and reduces overfitting across multiple tasks when compared to single-task networks, static baselines, and other adaptive multitask loss balancing techniques. GradNorm also matches or surpasses the performance of exhaustive grid search methods, despite only involving a single asymmetry hyperparameter $\alpha$. Thus, what was once a tedious search process that incurred exponentially more compute for each task added can now be accomplished within a few training runs, irrespective of the number of tasks. Ultimately, we will demonstrate that gradient manipulation affords us great control over the training dynamics of multitask networks and may be one of the keys to unlocking the potential of multitask learning.



### Single Image Super-Resolution Using Lightweight CNN with Maxout Units
- **Arxiv ID**: http://arxiv.org/abs/1711.02321v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02321v2)
- **Published**: 2017-11-07 07:37:06+00:00
- **Updated**: 2018-12-13 02:30:29+00:00
- **Authors**: Jae-Seok Choi, Munchurl Kim
- **Comment**: ACCV2018
- **Journal**: None
- **Summary**: Rectified linear units (ReLU) are well-known to be helpful in obtaining faster convergence and thus higher performance for many deep-learning-based applications. However, networks with ReLU tend to perform poorly when the number of filter parameters is constrained to a small number. To overcome it, in this paper, we propose a novel network utilizing maxout units (MU), and show its effectiveness on super-resolution (SR) applications. In general, the MU has been known to make the filter sizes doubled in generating the feature maps of the same sizes in classification problems. In this paper, we first reveal that the MU can even make the filter sizes halved in restoration problems thus leading to compaction of the network sizes. To show this, our SR network is designed without increasing the filter sizes with MU, which outperforms the state of the art SR methods with a smaller number of filter parameters. To the best of our knowledge, we are the first to incorporate MU into SR applications and show promising performance results. In MU, feature maps from a previous convolutional layer are divided into two parts along channels, which are then compared element-wise and only their max values are passed to a next layer. Along with some interesting properties of MU to be analyzed, we further investigate other variants of MU and their effects. In addition, while ReLU have a trouble for learning in networks with a very small number of convolutional filter parameters, MU do not. For SR applications, our MU-based network reconstructs high-resolution images with comparable quality compared to previous deep-learning-based SR methods, with lower filter parameters.



### Interpreting Convolutional Neural Networks Through Compression
- **Arxiv ID**: http://arxiv.org/abs/1711.02329v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.02329v1)
- **Published**: 2017-11-07 08:10:52+00:00
- **Updated**: 2017-11-07 08:10:52+00:00
- **Authors**: Reza Abbasi-Asl, Bin Yu
- **Comment**: Presented at NIPS 2017 Symposium on Interpretable Machine Learning
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) achieve state-of-the-art performance in a wide variety of tasks in computer vision. However, interpreting CNNs still remains a challenge. This is mainly due to the large number of parameters in these networks. Here, we investigate the role of compression and particularly pruning filters in the interpretation of CNNs. We exploit our recently-proposed greedy structural compression scheme that prunes filters in a trained CNN. In our compression, the filter importance index is defined as the classification accuracy reduction (CAR) of the network after pruning that filter. The filters are then iteratively pruned based on the CAR index. We demonstrate the interpretability of CAR-compressed CNNs by showing that our algorithm prunes filters with visually redundant pattern selectivity. Specifically, we show the importance of shape-selective filters for object recognition, as opposed to color-selective filters. Out of top 20 CAR-pruned filters in AlexNet, 17 of them in the first layer and 14 of them in the second layer are color-selective filters. Finally, we introduce a variant of our CAR importance index that quantifies the importance of each image class to each CNN filter. We show that the most and the least important class labels present a meaningful interpretation of each filter that is consistent with the visualized pattern selectivity of that filter.



### An EEG-based Image Annotation System
- **Arxiv ID**: http://arxiv.org/abs/1711.02383v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02383v1)
- **Published**: 2017-11-07 10:38:21+00:00
- **Updated**: 2017-11-07 10:38:21+00:00
- **Authors**: Viral Parekh, Ramanathan Subramanian, Dipanjan Roy, C. V. Jawahar
- **Comment**: None
- **Journal**: None
- **Summary**: The success of deep learning in computer vision has greatly increased the need for annotated image datasets. We propose an EEG (Electroencephalogram)-based image annotation system. While humans can recognize objects in 20-200 milliseconds, the need to manually label images results in a low annotation throughput. Our system employs brain signals captured via a consumer EEG device to achieve an annotation rate of up to 10 images per second. We exploit the P300 event-related potential (ERP) signature to identify target images during a rapid serial visual presentation (RSVP) task. We further perform unsupervised outlier removal to achieve an F1-score of 0.88 on the test set. The proposed system does not depend on category-specific EEG signatures enabling the annotation of any new image category without any model pre-training.



### Unconstrained Scene Text and Video Text Recognition for Arabic Script
- **Arxiv ID**: http://arxiv.org/abs/1711.02396v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02396v1)
- **Published**: 2017-11-07 11:07:48+00:00
- **Updated**: 2017-11-07 11:07:48+00:00
- **Authors**: Mohit Jain, Minesh Mathew, C. V. Jawahar
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Building robust recognizers for Arabic has always been challenging. We demonstrate the effectiveness of an end-to-end trainable CNN-RNN hybrid architecture in recognizing Arabic text in videos and natural scenes. We outperform previous state-of-the-art on two publicly available video text datasets - ALIF and ACTIV. For the scene text recognition task, we introduce a new Arabic scene text dataset and establish baseline results. For scripts like Arabic, a major challenge in developing robust recognizers is the lack of large quantity of annotated data. We overcome this by synthesising millions of Arabic text images from a large vocabulary of Arabic words and phrases. Our implementation is built on top of the model introduced here [37] which is proven quite effective for English scene text recognition. The model follows a segmentation-free, sequence to sequence transcription approach. The network transcribes a sequence of convolutional features from the input image to a sequence of target labels. This does away with the need for segmenting input image into constituent characters/glyphs, which is often difficult for Arabic script. Further, the ability of RNNs to model contextual dependencies yields superior recognition results.



### A Survey on Hardware Implementations of Visual Object Trackers
- **Arxiv ID**: http://arxiv.org/abs/1711.02441v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1711.02441v1)
- **Published**: 2017-11-07 12:45:12+00:00
- **Updated**: 2017-11-07 12:45:12+00:00
- **Authors**: Al-Hussein A. El-Shafie, S. E. D. Habib
- **Comment**: 17 pages, 14 Figures, 6 tables, 84 references
- **Journal**: None
- **Summary**: Visual object tracking is an active topic in the computer vision domain with applications extending over numerous fields. The main sub-tasks required to build an object tracker (e.g. object detection, feature extraction and object tracking) are computation-intensive. In addition, real-time operation of the tracker is indispensable for almost all of its applications. Therefore, complete hardware or hardware/software co-design approaches are pursued for better tracker implementations. This paper presents a literature survey of the hardware implementations of object trackers over the last two decades. Although several tracking surveys exist in literature, a survey addressing the hardware implementations of the different trackers is missing. We believe this survey would fill the gap and complete the picture with the existing surveys of how to design an efficient tracker and point out the future directions researchers can follow in this field. We highlight the lack of hardware implementations for state-of-the-art tracking algorithms as well as for enhanced classical algorithms. We also stress the need for measuring the tracking performance of the hardware-based trackers. Additionally, enough details of the hardware-based trackers need to be provided to allow reasonable comparison between the different implementations.



### MSR-net:Low-light Image Enhancement Using Deep Convolutional Network
- **Arxiv ID**: http://arxiv.org/abs/1711.02488v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02488v1)
- **Published**: 2017-11-07 14:32:25+00:00
- **Updated**: 2017-11-07 14:32:25+00:00
- **Authors**: Liang Shen, Zihan Yue, Fan Feng, Quan Chen, Shihao Liu, Jie Ma
- **Comment**: 9pages
- **Journal**: None
- **Summary**: Images captured in low-light conditions usually suffer from very low contrast, which increases the difficulty of subsequent computer vision tasks in a great extent. In this paper, a low-light image enhancement model based on convolutional neural network and Retinex theory is proposed. Firstly, we show that multi-scale Retinex is equivalent to a feedforward convolutional neural network with different Gaussian convolution kernels. Motivated by this fact, we consider a Convolutional Neural Network(MSR-net) that directly learns an end-to-end mapping between dark and bright images. Different fundamentally from existing approaches, low-light image enhancement in this paper is regarded as a machine learning problem. In this model, most of the parameters are optimized by back-propagation, while the parameters of traditional models depend on the artificial setting. Experiments on a number of challenging images reveal the advantages of our method in comparison with other state-of-the-art methods from the qualitative and quantitative perspective.



### Remote Sensing Image Fusion Based on Two-stream Fusion Network
- **Arxiv ID**: http://arxiv.org/abs/1711.02549v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02549v3)
- **Published**: 2017-11-07 15:33:29+00:00
- **Updated**: 2018-01-26 09:44:19+00:00
- **Authors**: Xiangyu Liu, Qingjie Liu, Yunhong Wang
- **Comment**: An extension of MMM 2018
- **Journal**: None
- **Summary**: Remote sensing image fusion (also known as pan-sharpening) aims at generating high resolution multi-spectral (MS) image from inputs of a high spatial resolution single band panchromatic (PAN) image and a low spatial resolution multi-spectral image. Inspired by the astounding achievements of convolutional neural networks (CNNs) in a variety of computer vision tasks, in this paper, we propose a two-stream fusion network (TFNet) to address the problem of pan-sharpening. Unlike previous CNN based methods that consider pan-sharpening as a super resolution problem and perform pan-sharpening in pixel level, the proposed TFNet aims to fuse PAN and MS images in feature level and reconstruct the pan-sharpened image from the fused features. The TFNet mainly consists of three parts. The first part is comprised of two networks extracting features from PAN and MS images, respectively. The subsequent network fuses them together to form compact features that represent both spatial and spectral information of PAN and MS images, simultaneously. Finally, the desired high spatial resolution MS image is recovered from the fused features through an image reconstruction network. Experiments on Quickbird and \mbox{GaoFen-1} satellite images demonstrate that the proposed TFNet can fuse PAN and MS images, effectively, and produce pan-sharpened images competitive with even superior to state of the arts.



### Image Captioning and Classification of Dangerous Situations
- **Arxiv ID**: http://arxiv.org/abs/1711.02578v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02578v1)
- **Published**: 2017-11-07 16:02:09+00:00
- **Updated**: 2017-11-07 16:02:09+00:00
- **Authors**: Octavio Arriaga, Paul Pl√∂ger, Matias Valdenegro-Toro
- **Comment**: None
- **Journal**: None
- **Summary**: Current robot platforms are being employed to collaborate with humans in a wide range of domestic and industrial tasks. These environments require autonomous systems that are able to classify and communicate anomalous situations such as fires, injured persons, car accidents; or generally, any potentially dangerous situation for humans. In this paper we introduce an anomaly detection dataset for the purpose of robot applications as well as the design and implementation of a deep learning architecture that classifies and describes dangerous situations using only a single image as input. We report a classification accuracy of 97 % and METEOR score of 16.2. We will make the dataset publicly available after this paper is accepted.



### Moonshine: Distilling with Cheap Convolutions
- **Arxiv ID**: http://arxiv.org/abs/1711.02613v4
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.02613v4)
- **Published**: 2017-11-07 17:21:06+00:00
- **Updated**: 2019-01-17 12:26:19+00:00
- **Authors**: Elliot J. Crowley, Gavin Gray, Amos Storkey
- **Comment**: 32nd Conference on Neural Information Processing Systems (NeurIPS
  2018)
- **Journal**: None
- **Summary**: Many engineers wish to deploy modern neural networks in memory-limited settings; but the development of flexible methods for reducing memory use is in its infancy, and there is little knowledge of the resulting cost-benefit. We propose structural model distillation for memory reduction using a strategy that produces a student architecture that is a simple transformation of the teacher architecture: no redesign is needed, and the same hyperparameters can be used. Using attention transfer, we provide Pareto curves/tables for distillation of residual networks with four benchmark datasets, indicating the memory versus accuracy payoff. We show that substantial memory savings are possible with very little loss of accuracy, and confirm that distillation provides student network performance that is better than training that student architecture directly on data.



### Compression-aware Training of Deep Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.02638v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02638v2)
- **Published**: 2017-11-07 17:58:34+00:00
- **Updated**: 2017-11-13 18:10:42+00:00
- **Authors**: Jose M. Alvarez, Mathieu Salzmann
- **Comment**: Accepted at NIPS 2017
- **Journal**: None
- **Summary**: In recent years, great progress has been made in a variety of application domains thanks to the development of increasingly deeper neural networks. Unfortunately, the huge number of units of these networks makes them expensive both computationally and memory-wise. To overcome this, exploiting the fact that deep networks are over-parametrized, several compression strategies have been proposed. These methods, however, typically start from a network that has been trained in a standard manner, without considering such a future compression. In this paper, we propose to explicitly account for compression in the training process. To this end, we introduce a regularizer that encourages the parameter matrix of each layer to have low rank during training. We show that accounting for compression during training allows us to learn much more compact, yet at least as effective, models than state-of-the-art compression techniques.



### Latent hypernet: Exploring all Layers from Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.02652v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02652v2)
- **Published**: 2017-11-07 18:32:40+00:00
- **Updated**: 2018-11-16 14:57:28+00:00
- **Authors**: Artur Jordao, Ricardo Kloss, William Robson Schwartz
- **Comment**: None
- **Journal**: None
- **Summary**: Since Convolutional Neural Networks (ConvNets) are able to simultaneously learn features and classifiers to discriminate different categories of activities, recent works have employed ConvNets approaches to perform human activity recognition (HAR) based on wearable sensors, allowing the removal of expensive human work and expert knowledge. However, these approaches have their power of discrimination limited mainly by the large number of parameters that compose the network and the reduced number of samples available for training. Inspired by this, we propose an accurate and robust approach, referred to as Latent HyperNet (LHN). The LHN uses feature maps from early layers (hyper) and projects them, individually, onto a low dimensionality space (latent). Then, these latent features are concatenated and presented to a classifier. To demonstrate the robustness and accuracy of the LHN, we evaluate it using four different networks architectures in five publicly available HAR datasets based on wearable sensors, which vary in the sampling rate and number of activities. Our experiments demonstrate that the proposed LHN is able to produce rich information, improving the results regarding the original ConvNets. Furthermore, the method outperforms existing state-of-the-art methods.



### Curve-Structure Segmentation from Depth Maps: A CNN-based Approach and Its Application to Exploring Cultural Heritage Objects
- **Arxiv ID**: http://arxiv.org/abs/1711.02718v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.02718v2)
- **Published**: 2017-11-07 20:45:07+00:00
- **Updated**: 2017-11-22 05:51:14+00:00
- **Authors**: Yuhang Lu, Jun Zhou, Jing Wang, Jun Chen, Karen Smith, Colin Wilder, Song Wang
- **Comment**: Accepted by AAAI2018
- **Journal**: None
- **Summary**: Motivated by the important archaeological application of exploring cultural heritage objects, in this paper we study the challenging problem of automatically segmenting curve structures that are very weakly stamped or carved on an object surface in the form of a highly noisy depth map. Different from most classical low-level image segmentation methods that are known to be very sensitive to the noise and occlusions, we propose a new supervised learning algorithm based on Convolutional Neural Network (CNN) to implicitly learn and utilize more curve geometry and pattern information for addressing this challenging problem. More specifically, we first propose a Fully Convolutional Network (FCN) to estimate the skeleton of curve structures and at each skeleton pixel, a scale value is estimated to reflect the local curve width. Then we propose a dense prediction network to refine the estimated curve skeletons. Based on the estimated scale values, we finally develop an adaptive thresholding algorithm to achieve the final segmentation of curve structures. In the experiment, we validate the performance of the proposed method on a dataset of depth images scanned from unearthed pottery sherds dating to the Woodland period of Southeastern North America.



### Recurrent Autoregressive Networks for Online Multi-Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1711.02741v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.02741v2)
- **Published**: 2017-11-07 21:51:22+00:00
- **Updated**: 2018-03-04 04:21:03+00:00
- **Authors**: Kuan Fang, Yu Xiang, Xiaocheng Li, Silvio Savarese
- **Comment**: 10 pages, 3 figures, 6 tables
- **Journal**: None
- **Summary**: The main challenge of online multi-object tracking is to reliably associate object trajectories with detections in each video frame based on their tracking history. In this work, we propose the Recurrent Autoregressive Network (RAN), a temporal generative modeling framework to characterize the appearance and motion dynamics of multiple objects over time. The RAN couples an external memory and an internal memory. The external memory explicitly stores previous inputs of each trajectory in a time window, while the internal memory learns to summarize long-term tracking history and associate detections by processing the external memory. We conduct experiments on the MOT 2015 and 2016 datasets to demonstrate the robustness of our tracking method in highly crowded and occluded scenes. Our method achieves top-ranked results on the two benchmarks.



### Hidden Markov Random Field Iterative Closest Point
- **Arxiv ID**: http://arxiv.org/abs/1711.05864v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1711.05864v1)
- **Published**: 2017-11-07 23:12:26+00:00
- **Updated**: 2017-11-07 23:12:26+00:00
- **Authors**: John Stechschulte, Christoffer Heckman
- **Comment**: None
- **Journal**: None
- **Summary**: When registering point clouds resolved from an underlying 2-D pixel structure, such as those resulting from structured light and flash LiDAR sensors, or stereo reconstruction, it is expected that some points in one cloud do not have corresponding points in the other cloud, and that these would occur together, such as along an edge of the depth map. In this work, a hidden Markov random field model is used to capture this prior within the framework of the iterative closest point algorithm. The EM algorithm is used to estimate the distribution parameters and the hidden component memberships. Experiments are presented demonstrating that this method outperforms several other outlier rejection methods when the point clouds have low or moderate overlap.



