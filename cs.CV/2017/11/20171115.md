# Arxiv Papers in cs.CV on 2017-11-15
### Can CNN Construct Highly Accurate Models Efficiently for High-Dimensional Problems in Complex Product Designs?
- **Arxiv ID**: http://arxiv.org/abs/1712.01639v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1712.01639v3)
- **Published**: 2017-11-15 00:06:54+00:00
- **Updated**: 2019-02-21 01:04:46+00:00
- **Authors**: Yu Li, Hu Wang, Juanjuan Liu
- **Comment**: None
- **Journal**: None
- **Summary**: With the increase of the nonlinearity and dimension, it is difficult for the present popular metamodeling techniques to construct reliable metamodels. To address this problem, Convolutional Neural Network (CNN) is introduced to construct a highly accurate metamodel efficiently. Considering the inherent characteristics of the CNN, it is a potential modeling tool to handle highly nonlinear and dimensional problems (hundreds-dimensional problems) with the limited training samples. In order to evaluate the proposed CNN metamodel for hundreds-dimensional and strong nonlinear problems, CNN is compared with other metamodeling techniques. Furthermore, several high-dimensional analytical functions are also employed to test the CNN metamodel. Testing and comparisons confirm the efficiency and capability of the CNN metamodel for hundreds-dimensional and strong nonlinear problems. Moreover, the proposed CNN metamodel is also applied to IsoGeometric Analysis (IGA)-based optimization successfully.



### Velocity variations at Columbia Glacier captured by particle filtering of oblique time-lapse images
- **Arxiv ID**: http://arxiv.org/abs/1711.05366v1
- **DOI**: None
- **Categories**: **cs.CV**, physics.data-an, physics.flu-dyn
- **Links**: [PDF](http://arxiv.org/pdf/1711.05366v1)
- **Published**: 2017-11-15 00:45:59+00:00
- **Updated**: 2017-11-15 00:45:59+00:00
- **Authors**: Douglas Brinkerhoff, Shad O'Neel
- **Comment**: 24 pages, 8 figures
- **Journal**: None
- **Summary**: We develop a probabilistic method for tracking glacier surface motion based on time-lapse imagery, which works by sequentially resampling a stochastic state-space model according to a likelihood determined through correlation between reference and test images. The method is robust due to its natural handling of periodic occlusion and its capacity to follow multiple hypothesis displacements between images, and can improve estimates of velocity magnitude and direction through the inclusion of observations from an arbitrary number of cameras. We apply the method to an annual record of images from two cameras near the terminus of Columbia Glacier. While the method produces velocities at daily resolution, we verify our results by comparing eleven-day means to TerraSar-X. We find that Columbia Glacier transitions between a winter state characterized by moderate velocities and little temporal variability, to an early summer speed-up in which velocities are sensitive to increases in melt- and rainwater, to a fall slowdown, where velocities drop to below their winter mean and become insensitive to external forcing, a pattern consistent with the development and collapse of efficient and inefficient subglacial hydrologic networks throughout the year.



### A Novel SDASS Descriptor for Fully Encoding the Information of 3D Local Surface
- **Arxiv ID**: http://arxiv.org/abs/1711.05368v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05368v3)
- **Published**: 2017-11-15 00:50:16+00:00
- **Updated**: 2018-06-26 13:06:34+00:00
- **Authors**: Bao Zhao, Xinyi Le, Juntong Xi
- **Comment**: 21 pages, 15 figures
- **Journal**: None
- **Summary**: Local feature description is a fundamental yet challenging task in 3D computer vision. This paper proposes a novel descriptor, named Statistic of Deviation Angles on Subdivided Space (SDASS), of encoding geometrical and spatial information of local surface on Local Reference Axis (LRA). In terms of encoding geometrical information, considering that surface normals, which are usually used for encoding geometrical information of local surface, are vulnerable to various nuisances (e.g., noise, varying mesh resolutions etc.), we propose a robust geometrical attribute, called Local Minimum Axis (LMA), to replace the normals for generating the geometrical feature in our SDASS descriptor. For encoding spatial information, we use two spatial features for fully encoding the spatial information of a local surface based on LRA which usually presents high overall repeatability than Local Reference Axis (LRF). Besides, an improved LRA is proposed for increasing the robustness of our SDASS to noise and varying mesh resolutions. The performance of the SDASS descriptor is rigorously tested on four popular datasets. The results show that our descriptor has a high descriptiveness and strong robustness, and its performance outperform existing algorithms by a large margin. Finally, the proposed descriptor is applied to 3D registration. The accurate result further confirms the effectiveness of our SDASS method.



### Sliced Wasserstein Distance for Learning Gaussian Mixture Models
- **Arxiv ID**: http://arxiv.org/abs/1711.05376v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1711.05376v2)
- **Published**: 2017-11-15 01:33:01+00:00
- **Updated**: 2017-11-16 02:05:11+00:00
- **Authors**: Soheil Kolouri, Gustavo K. Rohde, Heiko Hoffmann
- **Comment**: None
- **Journal**: None
- **Summary**: Gaussian mixture models (GMM) are powerful parametric tools with many applications in machine learning and computer vision. Expectation maximization (EM) is the most popular algorithm for estimating the GMM parameters. However, EM guarantees only convergence to a stationary point of the log-likelihood function, which could be arbitrarily worse than the optimal solution. Inspired by the relationship between the negative log-likelihood function and the Kullback-Leibler (KL) divergence, we propose an alternative formulation for estimating the GMM parameters using the sliced Wasserstein distance, which gives rise to a new algorithm. Specifically, we propose minimizing the sliced-Wasserstein distance between the mixture model and the data distribution with respect to the GMM parameters. In contrast to the KL-divergence, the energy landscape for the sliced-Wasserstein distance is more well-behaved and therefore more suitable for a stochastic gradient descent scheme to obtain the optimal GMM parameters. We show that our formulation results in parameter estimates that are more robust to random initializations and demonstrate that it can estimate high-dimensional data distributions more faithfully than the EM algorithm.



### Deep Epitome for Unravelling Generalized Hamming Network: A Fuzzy Logic Interpretation of Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1711.05397v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05397v1)
- **Published**: 2017-11-15 03:36:06+00:00
- **Updated**: 2017-11-15 03:36:06+00:00
- **Authors**: Lixin Fan
- **Comment**: 25 pages, 14 figures
- **Journal**: None
- **Summary**: This paper gives a rigorous analysis of trained Generalized Hamming Networks(GHN) proposed by Fan (2017) and discloses an interesting finding about GHNs, i.e., stacked convolution layers in a GHN is equivalent to a single yet wide convolution layer. The revealed equivalence, on the theoretical side, can be regarded as a constructive manifestation of the universal approximation theorem Cybenko(1989); Hornik (1991). In practice, it has profound and multi-fold implications. For network visualization, the constructed deep epitomes at each layer provide a visualization of network internal representation that does not rely on the input data. Moreover, deep epitomes allows the direct extraction of features in just one step, without resorting to regularized optimizations used in existing visualization tools.



### MARGIN: Uncovering Deep Neural Networks using Graph Signal Analysis
- **Arxiv ID**: http://arxiv.org/abs/1711.05407v4
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.05407v4)
- **Published**: 2017-11-15 04:52:38+00:00
- **Updated**: 2021-01-15 20:40:23+00:00
- **Authors**: Rushil Anirudh, Jayaraman J. Thiagarajan, Rahul Sridhar, Peer-Timo Bremer
- **Comment**: Technical Report
- **Journal**: None
- **Summary**: Interpretability has emerged as a crucial aspect of building trust in machine learning systems, aimed at providing insights into the working of complex neural networks that are otherwise opaque to a user. There are a plethora of existing solutions addressing various aspects of interpretability ranging from identifying prototypical samples in a dataset to explaining image predictions or explaining mis-classifications. While all of these diverse techniques address seemingly different aspects of interpretability, we hypothesize that a large family of interepretability tasks are variants of the same central problem which is identifying \emph{relative} change in a model's prediction. This paper introduces MARGIN, a simple yet general approach to address a large set of interpretability tasks MARGIN exploits ideas rooted in graph signal analysis to determine influential nodes in a graph, which are defined as those nodes that maximally describe a function defined on the graph. By carefully defining task-specific graphs and functions, we demonstrate that MARGIN outperforms existing approaches in a number of disparate interpretability challenges.



### DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images
- **Arxiv ID**: http://arxiv.org/abs/1711.05415v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05415v2)
- **Published**: 2017-11-15 05:49:39+00:00
- **Updated**: 2018-03-28 02:42:06+00:00
- **Authors**: Taihong Xiao, Jiapeng Hong, Jinwen Ma
- **Comment**: ICLR 2018 workshop, github: https://github.com/Prinsphield/DNA-GAN
- **Journal**: None
- **Summary**: Disentangling factors of variation has become a very challenging problem on representation learning. Existing algorithms suffer from many limitations, such as unpredictable disentangling factors, poor quality of generated images from encodings, lack of identity information, etc. In this paper, we propose a supervised learning model called DNA-GAN which tries to disentangle different factors or attributes of images. The latent representations of images are DNA-like, in which each individual piece (of the encoding) represents an independent factor of the variation. By annihilating the recessive piece and swapping a certain piece of one latent representation with that of the other one, we obtain two different representations which could be decoded into two kinds of images with the existence of the corresponding attribute being changed. In order to obtain realistic images and also disentangled representations, we further introduce the discriminator for adversarial training. Experiments on Multi-PIE and CelebA datasets finally demonstrate that our proposed method is effective for factors disentangling and even overcome certain limitations of the existing methods.



### Deep Inception-Residual Laplacian Pyramid Networks for Accurate Single Image Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1711.05431v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05431v1)
- **Published**: 2017-11-15 07:04:30+00:00
- **Updated**: 2017-11-15 07:04:30+00:00
- **Authors**: Yongliang Tang, Weiguo Gong, Xi Chen, Weihong Li
- **Comment**: None
- **Journal**: None
- **Summary**: With exploiting contextual information over large image regions in an efficient way, the deep convolutional neural network has shown an impressive performance for single image super-resolution (SR). In this paper, we propose a deep convolutional network by cascading the well-designed inception-residual blocks within the deep Laplacian pyramid framework to progressively restore the missing high-frequency details of high-resolution (HR) images. By optimizing our network structure, the trainable depth of the proposed network gains a significant improvement, which in turn improves super-resolving accuracy. With our network depth increasing, however, the saturation and degradation of training accuracy continues to be a critical problem. As regard to this, we propose an effective two-stage training strategy, in which we firstly use images downsampled from the ground-truth HR images as the optimal objective to train the inception-residual blocks in each pyramid level with an extremely high learning rate enabled by gradient clipping, and then the ground-truth HR images are used to fine-tune all the pre-trained inception-residual blocks for obtaining the final SR model. Furthermore, we present a new loss function operating in both image space and local rank space to optimize our network for exploiting the contextual information among different output components. Extensive experiments on benchmark datasets validate that the proposed method outperforms existing state-of-the-art SR methods in terms of the objective evaluation as well as the visual quality.



### Robust Real-Time Multi-View Eye Tracking
- **Arxiv ID**: http://arxiv.org/abs/1711.05444v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1711.05444v2)
- **Published**: 2017-11-15 08:23:06+00:00
- **Updated**: 2018-01-03 16:10:53+00:00
- **Authors**: Nuri Murat Arar, Jean-Philippe Thiran
- **Comment**: Organisational changes in the main msp and supplementary info.
  Results unchanged. Main msp: 14 pages, 15 figures. Supplementary: 2 tables, 1
  figure. Under review for an IEEE transactions publication
- **Journal**: None
- **Summary**: Despite significant advances in improving the gaze tracking accuracy under controlled conditions, the tracking robustness under real-world conditions, such as large head pose and movements, use of eyeglasses, illumination and eye type variations, remains a major challenge in eye tracking. In this paper, we revisit this challenge and introduce a real-time multi-camera eye tracking framework to improve the tracking robustness. First, differently from previous work, we design a multi-view tracking setup that allows for acquiring multiple eye appearances simultaneously. Leveraging multi-view appearances enables to more reliably detect gaze features under challenging conditions, particularly when they are obstructed in conventional single-view appearance due to large head movements or eyewear effects. The features extracted on various appearances are then used for estimating multiple gaze outputs. Second, we propose to combine estimated gaze outputs through an adaptive fusion mechanism to compute user's overall point of regard. The proposed mechanism firstly determines the estimation reliability of each gaze output according to user's momentary head pose and predicted gazing behavior, and then performs a reliability-based weighted fusion. We demonstrate the efficacy of our framework with extensive simulations and user experiments on a collected dataset featuring 20 subjects. Our results show that in comparison with state-of-the-art eye trackers, the proposed framework provides not only a significant enhancement in accuracy but also a notable robustness. Our prototype system runs at 30 frames-per-second (fps) and achieves 1 degree accuracy under challenging experimental scenarios, which makes it suitable for applications demanding high accuracy and robustness.



### A Public Image Database for Benchmark of Plant Seedling Classification Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1711.05458v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05458v1)
- **Published**: 2017-11-15 08:56:25+00:00
- **Updated**: 2017-11-15 08:56:25+00:00
- **Authors**: Thomas Mosgaard Giselsson, Rasmus Nyholm Jørgensen, Peter Kryger Jensen, Mads Dyrmann, Henrik Skov Midtiby
- **Comment**: None
- **Journal**: None
- **Summary**: A database of images of approximately 960 unique plants belonging to 12 species at several growth stages is made publicly available. It comprises annotated RGB images with a physical resolution of roughly 10 pixels per mm. To standardise the evaluation of classification results obtained with the database, a benchmark based on $f_{1}$ scores is proposed. The dataset is available at https://vision.eng.au.dk/plant-seedlings-dataset



### Exploring the Bounds of the Utility of Context for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1711.05471v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05471v4)
- **Published**: 2017-11-15 09:25:49+00:00
- **Updated**: 2019-04-04 14:53:28+00:00
- **Authors**: Ehud Barnea, Ohad Ben-Shahar
- **Comment**: None
- **Journal**: None
- **Summary**: The recurring context in which objects appear holds valuable information that can be employed to predict their existence. This intuitive observation indeed led many researchers to endow appearance-based detectors with explicit reasoning about context. The underlying thesis suggests that stronger contextual relations would facilitate greater improvements in detection capacity. In practice, however, the observed improvement in many cases is modest at best, and often only marginal. In this work we seek to improve our understanding of this phenomenon, in part by pursuing an opposite approach. Instead of attempting to improve detection scores by employing context, we treat the utility of context as an optimization problem: to what extent can detection scores be improved by considering context or any other kind of additional information? With this approach we explore the bounds on improvement by using contextual relations between objects and provide a tool for identifying the most helpful ones. We show that simple co-occurrence relations can often provide large gains, while in other cases a significant improvement is simply impossible or impractical with either co-occurrence or more precise spatial relations. To better understand these results we then analyze the ability of context to handle different types of false detections, revealing that tested contextual information cannot ameliorate localization errors, severely limiting its gains. These and additional insights further our understanding on where and why utilization of context for object detection succeeds and fails.



### No Reference Stereoscopic Video Quality Assessment Using Joint Motion and Depth Statistics
- **Arxiv ID**: http://arxiv.org/abs/1711.05480v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1711.05480v1)
- **Published**: 2017-11-15 09:52:23+00:00
- **Updated**: 2017-11-15 09:52:23+00:00
- **Authors**: Appina Balasubramanyam, Jalli Akshith, Battula Shanmukh Srinivas, Channappayya S Sumohana
- **Comment**: 13 PAGES, 7 FIGURES, 7 TABLES
- **Journal**: None
- **Summary**: We present a no reference (NR) quality assessment algorithm for assessing the perceptual quality of natural stereoscopic 3D (S3D) videos. This work is inspired by our finding that the joint statistics of the subband coefficients of motion (optical flow or motion vector magnitude) and depth (disparity map) of natural S3D videos possess a unique signature. Specifically, we empirically show that the joint statistics of the motion and depth subband coefficients of S3D video frames can be modeled accurately using a Bivariate Generalized Gaussian Distribution (BGGD). We then demonstrate that the parameters of the BGGD model possess the ability to discern quality variations in S3D videos. Therefore, the BGGD model parameters are employed as motion and depth quality features. In addition to these features, we rely on a frame level spatial quality feature that is computed using a robust off the shelf NR image quality assessment (IQA) algorithm. These frame level motion, depth and spatial features are consolidated and used with the corresponding S3D video's difference mean opinion score (DMOS) labels for supervised learning using support vector regression (SVR). The overall quality of an S3D video is computed by averaging the frame level quality predictions of the constituent video frames. The proposed algorithm, dubbed Video QUality Evaluation using MOtion and DEpth Statistics (VQUEMODES) is shown to outperform the state of the art methods when evaluated over the IRCCYN and LFOVIA S3D subjective quality assessment databases.



### Squeeze-SegNet: A new fast Deep Convolutional Neural Network for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1711.05491v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05491v1)
- **Published**: 2017-11-15 10:41:52+00:00
- **Updated**: 2017-11-15 10:41:52+00:00
- **Authors**: Geraldin Nanfack, Azeddine Elhassouny, Rachid Oulad Haj Thami
- **Comment**: The 10th International Conference on Machine Vision (ICMV 2017).
  arXiv admin note: text overlap with arXiv:1704.06857 by other authors
- **Journal**: None
- **Summary**: The recent researches in Deep Convolutional Neural Network have focused their attention on improving accuracy that provide significant advances. However, if they were limited to classification tasks, nowadays with contributions from Scientific Communities who are embarking in this field, they have become very useful in higher level tasks such as object detection and pixel-wise semantic segmentation. Thus, brilliant ideas in the field of semantic segmentation with deep learning have completed the state of the art of accuracy, however this architectures become very difficult to apply in embedded systems as is the case for autonomous driving. We present a new Deep fully Convolutional Neural Network for pixel-wise semantic segmentation which we call Squeeze-SegNet. The architecture is based on Encoder-Decoder style. We use a SqueezeNet-like encoder and a decoder formed by our proposed squeeze-decoder module and upsample layer using downsample indices like in SegNet and we add a deconvolution layer to provide final multi-channel feature map. On datasets like Camvid or City-states, our net gets SegNet-level accuracy with less than 10 times fewer parameters than SegNet.



### Spectral-spatial classification of hyperspectral images: three tricks and a new supervised learning setting
- **Arxiv ID**: http://arxiv.org/abs/1711.05512v4
- **DOI**: 10.3390/rs10071156
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05512v4)
- **Published**: 2017-11-15 12:02:57+00:00
- **Updated**: 2018-07-23 16:24:52+00:00
- **Authors**: Jacopo Acquarelli, Elena Marchiori, Lutgarde M. C. Buydens, Thanh Tran, Twan van Laarhoven
- **Comment**: Remote Sensing 2018
- **Journal**: None
- **Summary**: Spectral-spatial classification of hyperspectral images has been the subject of many studies in recent years. In the presence of only very few labeled pixels, this task becomes challenging. In this paper we address the following two research questions: 1) Can a simple neural network with just a single hidden layer achieve state of the art performance in the presence of few labeled pixels? 2) How is the performance of hyperspectral image classification methods affected when using disjoint train and test sets? We give a positive answer to the first question by using three tricks within a very basic shallow Convolutional Neural Network (CNN) architecture: a tailored loss function, and smooth- and label-based data augmentation. The tailored loss function enforces that neighborhood wavelengths have similar contributions to the features generated during training. A new label-based technique here proposed favors selection of pixels in smaller classes, which is beneficial in the presence of very few labeled pixels and skewed class distributions. To address the second question, we introduce a new sampling procedure to generate disjoint train and test set. Then the train set is used to obtain the CNN model, which is then applied to pixels in the test set to estimate their labels. We assess the efficacy of the simple neural network method on five publicly available hyperspectral images. On these images our method significantly outperforms considered baselines. Notably, with just 1% of labeled pixels per class, on these datasets our method achieves an accuracy that goes from 86.42% (challenging dataset) to 99.52% (easy dataset). Furthermore we show that the simple neural network method improves over other baselines in the new challenging supervised setting. Our analysis substantiates the highly beneficial effect of using the entire image (so train and test data) for constructing a model.



### A Correlation Based Feature Representation for First-Person Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/1711.05523v2
- **DOI**: 10.1007/s11042-019-7429-3
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05523v2)
- **Published**: 2017-11-15 12:26:42+00:00
- **Updated**: 2018-02-09 13:30:55+00:00
- **Authors**: Reza Kahani, Alireza Talebpour, Ahmad Mahmoudi-Aznaveh
- **Comment**: 15 pages, 6 figures, 5 tables
- **Journal**: Multimedia Tools and Applications, March 30 2019
- **Summary**: In this paper, a simple yet efficient activity recognition method for first-person video is introduced. The proposed method is appropriate for representation of high-dimensional features such as those extracted from convolutional neural networks (CNNs). The per-frame (per-segment) extracted features are considered as a set of time series, and inter and intra-time series relations are employed to represent the video descriptors. To find the inter-time relations, the series are grouped and the linear correlation between each pair of groups is calculated. The relations between them can represent the scene dynamics and local motions. The introduced grouping strategy helps to considerably reduce the computational cost. Furthermore, we split the series in temporal direction in order to preserve long term motions and better focus on each local time window. In order to extract the cyclic motion patterns, which can be considered as primary components of various activities, intra-time series correlations are exploited. The representation method results in highly discriminative features which can be linearly classified. The experiments confirm that our method outperforms the state-of-the-art methods on recognizing first-person activities on the two challenging first-person datasets.



### Dual-Path Convolutional Image-Text Embeddings with Instance Loss
- **Arxiv ID**: http://arxiv.org/abs/1711.05535v4
- **DOI**: 10.1145/3383184
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1711.05535v4)
- **Published**: 2017-11-15 12:40:11+00:00
- **Updated**: 2021-07-27 07:45:26+00:00
- **Authors**: Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, Yi-Dong Shen
- **Comment**: 15pages, 15 figures, 8 tables
- **Journal**: None
- **Summary**: Matching images and sentences demands a fine understanding of both modalities. In this paper, we propose a new system to discriminatively embed the image and text to a shared visual-textual space. In this field, most existing works apply the ranking loss to pull the positive image / text pairs close and push the negative pairs apart from each other. However, directly deploying the ranking loss is hard for network learning, since it starts from the two heterogeneous features to build inter-modal relationship. To address this problem, we propose the instance loss which explicitly considers the intra-modal data distribution. It is based on an unsupervised assumption that each image / text group can be viewed as a class. So the network can learn the fine granularity from every image/text group. The experiment shows that the instance loss offers better weight initialization for the ranking loss, so that more discriminative embeddings can be learned. Besides, existing works usually apply the off-the-shelf features, i.e., word2vec and fixed visual feature. So in a minor contribution, this paper constructs an end-to-end dual-path convolutional network to learn the image and text representations. End-to-end learning allows the system to directly learn from the data and fully utilize the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO), experiments demonstrate that our method yields competitive accuracy compared to state-of-the-art methods. Moreover, in language based person retrieval, we improve the state of the art by a large margin. The code has been made publicly available.



### People, Penguins and Petri Dishes: Adapting Object Counting Models To New Visual Domains And Object Types Without Forgetting
- **Arxiv ID**: http://arxiv.org/abs/1711.05586v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05586v1)
- **Published**: 2017-11-15 14:25:20+00:00
- **Updated**: 2017-11-15 14:25:20+00:00
- **Authors**: Mark Marsden, Kevin McGuinness, Suzanne Little, Ciara E. Keogh, Noel E. O'Connor
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: In this paper we propose a technique to adapt a convolutional neural network (CNN) based object counter to additional visual domains and object types while still preserving the original counting function. Domain-specific normalisation and scaling operators are trained to allow the model to adjust to the statistical distributions of the various visual domains. The developed adaptation technique is used to produce a singular patch-based counting regressor capable of counting various object types including people, vehicles, cell nuclei and wildlife. As part of this study a challenging new cell counting dataset in the context of tissue culture and patient diagnosis is constructed. This new collection, referred to as the Dublin Cell Counting (DCC) dataset, is the first of its kind to be made available to the wider computer vision community. State-of-the-art object counting performance is achieved in both the Shanghaitech (parts A and B) and Penguins datasets while competitive performance is observed on the TRANCOS and Modified Bone Marrow (MBM) datasets, all using a shared counting model.



### Interpreting Deep Visual Representations via Network Dissection
- **Arxiv ID**: http://arxiv.org/abs/1711.05611v2
- **DOI**: None
- **Categories**: **cs.CV**, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1711.05611v2)
- **Published**: 2017-11-15 15:05:25+00:00
- **Updated**: 2018-06-26 15:38:31+00:00
- **Authors**: Bolei Zhou, David Bau, Aude Oliva, Antonio Torralba
- **Comment**: *B. Zhou and D. Bau contributed equally to this work. 15 pages, 27
  figures
- **Journal**: None
- **Summary**: The success of recent deep convolutional neural networks (CNNs) depends on learning hidden representations that can summarize the important factors of variation behind the data. However, CNNs often criticized as being black boxes that lack interpretability, since they have millions of unexplained model parameters. In this work, we describe Network Dissection, a method that interprets networks by providing labels for the units of their deep visual representations. The proposed method quantifies the interpretability of CNN representations by evaluating the alignment between individual hidden units and a set of visual semantic concepts. By identifying the best alignments, units are given human interpretable labels across a range of objects, parts, scenes, textures, materials, and colors. The method reveals that deep representations are more transparent and interpretable than expected: we find that representations are significantly more interpretable than they would be under a random equivalently powerful basis. We apply the method to interpret and compare the latent representations of various network architectures trained to solve different supervised and self-supervised training tasks. We then examine factors affecting the network interpretability such as the number of the training iterations, regularizations, different initializations, and the network depth and width. Finally we show that the interpreted units can be used to provide explicit explanations of a prediction given by a CNN for an image. Our results highlight that interpretability is an important property of deep neural networks that provides new insights into their hierarchical structure.



### Brain Extraction from Normal and Pathological Images: A Joint PCA/Image-Reconstruction Approach
- **Arxiv ID**: http://arxiv.org/abs/1711.05702v2
- **DOI**: 10.1016/j.neuroimage.2018.04.073
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05702v2)
- **Published**: 2017-11-15 17:57:52+00:00
- **Updated**: 2018-04-30 19:53:45+00:00
- **Authors**: Xu Han, Roland Kwitt, Stephen Aylward, Spyridon Bakas, Bjoern Menze, Alexander Asturias, Paul Vespa, John Van Horn, Marc Niethammer
- **Comment**: None
- **Journal**: None
- **Summary**: Brain extraction from images is a common pre-processing step. Many approaches exist, but they are frequently only designed to perform brain extraction from images without strong pathologies. Extracting the brain from images with strong pathologies, for example, the presence of a tumor or of a traumatic brain injury, is challenging. In such cases, tissue appearance may deviate from normal tissue and violates algorithmic assumptions for these approaches; hence, the brain may not be correctly extracted. This paper proposes a brain extraction approach which can explicitly account for pathologies by jointly modeling normal tissue and pathologies. Specifically, our model uses a three-part image decomposition: (1) normal tissue appearance is captured by principal component analysis, (2) pathologies are captured via a total variation term, and (3) non-brain tissue is captured by a sparse term. Decomposition and image registration steps are alternated to allow statistical modeling in a fixed atlas space. As a beneficial side effect, the model allows for the identification of potential pathologies and the reconstruction of a quasi-normal image in atlas space. We demonstrate the effectiveness of our method on four datasets: the IBSR and LPBA40 datasets which show normal images, the BRATS dataset containing images with brain tumors and a dataset containing clinical TBI images. We compare the performance with other popular models: ROBEX, BEaST, MASS, BET, BSE and a recently proposed deep learning approach. Our model performs better than these competing methods on all four datasets. Specifically, our model achieves the best median (97.11) and mean (96.88) Dice scores over all datasets. The two best performing competitors, ROBEX and MASS, achieve scores of 96.23/95.62 and 96.67/94.25 respectively. Hence, our approach is an effective method for high quality brain extraction on a wide variety of images.



### Contextual Object Detection with a Few Relevant Neighbors
- **Arxiv ID**: http://arxiv.org/abs/1711.05705v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05705v3)
- **Published**: 2017-11-15 17:59:42+00:00
- **Updated**: 2018-10-17 21:51:54+00:00
- **Authors**: Ehud Barnea, Ohad Ben-Shahar
- **Comment**: None
- **Journal**: None
- **Summary**: A natural way to improve the detection of objects is to consider the contextual constraints imposed by the detection of additional objects in a given scene. In this work, we exploit the spatial relations between objects in order to improve detection capacity, as well as analyze various properties of the contextual object detection problem. To precisely calculate context-based probabilities of objects, we developed a model that examines the interactions between objects in an exact probabilistic setting, in contrast to previous methods that typically utilize approximations based on pairwise interactions. Such a scheme is facilitated by the realistic assumption that the existence of an object in any given location is influenced by only few informative locations in space. Based on this assumption, we suggest a method for identifying these relevant locations and integrating them into a mostly exact calculation of probability based on their raw detector responses. This scheme is shown to improve detection results and provides unique insights about the process of contextual inference for object detection. We show that it is generally difficult to learn that a particular object reduces the probability of another, and that in cases when the context and detector strongly disagree this learning becomes virtually impossible for the purposes of improving the results of an object detector. Finally, we demonstrate improved detection results through use of our approach as applied to the PASCAL VOC and COCO datasets.



### Fast Predictive Simple Geodesic Regression
- **Arxiv ID**: http://arxiv.org/abs/1711.05766v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1711.05766v1)
- **Published**: 2017-11-15 19:30:20+00:00
- **Updated**: 2017-11-15 19:30:20+00:00
- **Authors**: Zhipeng Ding, Greg Fleishman, Xiao Yang, Paul Thompson, Roland Kwitt, Marc Niethammer
- **Comment**: 19 pages, 10 figures, 13 tables
- **Journal**: None
- **Summary**: Deformable image registration and regression are important tasks in medical image analysis. However, they are computationally expensive, especially when analyzing large-scale datasets that contain thousands of images. Hence, cluster computing is typically used, making the approaches dependent on such computational infrastructure. Even larger computational resources are required as study sizes increase. This limits the use of deformable image registration and regression for clinical applications and as component algorithms for other image analysis approaches. We therefore propose using a fast predictive approach to perform image registrations. In particular, we employ these fast registration predictions to approximate a simplified geodesic regression model to capture longitudinal brain changes. The resulting method is orders of magnitude faster than the standard optimization-based regression model and hence facilitates large-scale analysis on a single graphics processing unit (GPU). We evaluate our results on 3D brain magnetic resonance images (MRI) from the ADNI datasets.



### PackNet: Adding Multiple Tasks to a Single Network by Iterative Pruning
- **Arxiv ID**: http://arxiv.org/abs/1711.05769v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05769v2)
- **Published**: 2017-11-15 19:36:51+00:00
- **Updated**: 2018-05-13 16:48:51+00:00
- **Authors**: Arun Mallya, Svetlana Lazebnik
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a method for adding multiple tasks to a single deep neural network while avoiding catastrophic forgetting. Inspired by network pruning techniques, we exploit redundancies in large deep networks to free up parameters that can then be employed to learn new tasks. By performing iterative pruning and network re-training, we are able to sequentially "pack" multiple tasks into a single network while ensuring minimal drop in performance and minimal storage overhead. Unlike prior work that uses proxy losses to maintain accuracy on older tasks, we always optimize for the task at hand. We perform extensive experiments on a variety of network architectures and large-scale datasets, and observe much better robustness against catastrophic forgetting than prior work. In particular, we are able to add three fine-grained classification tasks to a single ImageNet-trained VGG-16 network and achieve accuracies close to those of separately trained networks for each task. Code available at https://github.com/arunmallya/packnet



### End-to-end Training for Whole Image Breast Cancer Diagnosis using An All Convolutional Design
- **Arxiv ID**: http://arxiv.org/abs/1711.05775v1
- **DOI**: 10.1038/s41598-019-48995-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05775v1)
- **Published**: 2017-11-15 19:52:27+00:00
- **Updated**: 2017-11-15 19:52:27+00:00
- **Authors**: Li Shen
- **Comment**: Accepted poster at NIPS 2017 Workshop on Machine Learning for Health
  (https://ml4health.github.io/2017/)
- **Journal**: Scientific Reports, volume 9, Article number: 12495 (2019)
- **Summary**: We develop an end-to-end training algorithm for whole-image breast cancer diagnosis based on mammograms. It requires lesion annotations only at the first stage of training. After that, a whole image classifier can be trained using only image level labels. This greatly reduced the reliance on lesion annotations. Our approach is implemented using an all convolutional design that is simple yet provides superior performance in comparison with the previous methods. On DDSM, our best single-model achieves a per-image AUC score of 0.88 and three-model averaging increases the score to 0.91. On INbreast, our best single-model achieves a per-image AUC score of 0.96. Using DDSM as benchmark, our models compare favorably with the current state-of-the-art. We also demonstrate that a whole image model trained on DDSM can be easily transferred to INbreast without using its lesion annotations and using only a small amount of training data. Code availability: https://github.com/lishen/end2end-all-conv



### Robust and Precise Vehicle Localization based on Multi-sensor Fusion in Diverse City Scenes
- **Arxiv ID**: http://arxiv.org/abs/1711.05805v2
- **DOI**: 10.1109/ICRA.2018.8461224
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1711.05805v2)
- **Published**: 2017-11-15 21:05:13+00:00
- **Updated**: 2020-03-06 04:18:16+00:00
- **Authors**: Guowei Wan, Xiaolong Yang, Renlan Cai, Hao Li, Hao Wang, Shiyu Song
- **Comment**: 8 pages, 6 figures, 2 tables, Accepted by ICRA 2018
- **Journal**: IEEE International Conference on Robotics and Automation (ICRA),
  2018, pp. 4670-4677
- **Summary**: We present a robust and precise localization system that achieves centimeter-level localization accuracy in disparate city scenes. Our system adaptively uses information from complementary sensors such as GNSS, LiDAR, and IMU to achieve high localization accuracy and resilience in challenging scenes, such as urban downtown, highways, and tunnels. Rather than relying only on LiDAR intensity or 3D geometry, we make innovative use of LiDAR intensity and altitude cues to significantly improve localization system accuracy and robustness. Our GNSS RTK module utilizes the help of the multi-sensor fusion framework and achieves a better ambiguity resolution success rate. An error-state Kalman filter is applied to fuse the localization measurements from different sources with novel uncertainty estimation. We validate, in detail, the effectiveness of our approaches, achieving 5-10cm RMS accuracy and outperforming previous state-of-the-art systems. Importantly, our system, while deployed in a large autonomous driving fleet, made our vehicles fully autonomous in crowded city streets despite road construction that occurred from time to time. A dataset including more than 60 km real traffic driving in various urban roads is used to comprehensively test our system.



### Zero-Shot Learning via Class-Conditioned Deep Generative Models
- **Arxiv ID**: http://arxiv.org/abs/1711.05820v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1711.05820v2)
- **Published**: 2017-11-15 21:53:11+00:00
- **Updated**: 2017-11-19 23:32:05+00:00
- **Authors**: Wenlin Wang, Yunchen Pu, Vinay Kumar Verma, Kai Fan, Yizhe Zhang, Changyou Chen, Piyush Rai, Lawrence Carin
- **Comment**: To appear in AAAI 2018
- **Journal**: None
- **Summary**: We present a deep generative model for learning to predict classes not seen at training time. Unlike most existing methods for this problem, that represent each class as a point (via a semantic embedding), we represent each seen/unseen class using a class-specific latent-space distribution, conditioned on class attributes. We use these latent-space distributions as a prior for a supervised variational autoencoder (VAE), which also facilitates learning highly discriminative feature representations for the inputs. The entire framework is learned end-to-end using only the seen-class training data. The model infers corresponding attributes of a test image by maximizing the VAE lower bound; the inferred attributes may be linked to labels not seen when training. We further extend our model to a (1) semi-supervised/transductive setting by leveraging unlabeled unseen-class data via an unsupervised learning module, and (2) few-shot learning where we also have a small number of labeled inputs from the unseen classes. We compare our model with several state-of-the-art methods through a comprehensive set of experiments on a variety of benchmark data sets.



### AOGNets: Compositional Grammatical Architectures for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1711.05847v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.05847v3)
- **Published**: 2017-11-15 23:42:45+00:00
- **Updated**: 2019-04-06 14:04:30+00:00
- **Authors**: Xilai Li, Xi Song, Tianfu Wu
- **Comment**: accepted to CVPR2019
- **Journal**: None
- **Summary**: Neural architectures are the foundation for improving performance of deep neural networks (DNNs). This paper presents deep compositional grammatical architectures which harness the best of two worlds: grammar models and DNNs. The proposed architectures integrate compositionality and reconfigurability of the former and the capability of learning rich features of the latter in a principled way. We utilize AND-OR Grammar (AOG) as network generator in this paper and call the resulting networks AOGNets. An AOGNet consists of a number of stages each of which is composed of a number of AOG building blocks. An AOG building block splits its input feature map into N groups along feature channels and then treat it as a sentence of N words. It then jointly realizes a phrase structure grammar and a dependency grammar in bottom-up parsing the "sentence" for better feature exploration and reuse. It provides a unified framework for the best practices developed in state-of-the-art DNNs. In experiments, AOGNet is tested in the CIFAR-10, CIFAR-100 and ImageNet-1K classification benchmark and the MS-COCO object detection and segmentation benchmark. In CIFAR-10, CIFAR-100 and ImageNet-1K, AOGNet obtains better performance than ResNet and most of its variants, ResNeXt and its attention based variants such as SENet, DenseNet and DualPathNet. AOGNet also obtains the best model interpretability score using network dissection. AOGNet further shows better potential in adversarial defense. In MS-COCO, AOGNet obtains better performance than the ResNet and ResNeXt backbones in Mask R-CNN.



### Apprentice: Using Knowledge Distillation Techniques To Improve Low-Precision Network Accuracy
- **Arxiv ID**: http://arxiv.org/abs/1711.05852v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1711.05852v1)
- **Published**: 2017-11-15 23:45:59+00:00
- **Updated**: 2017-11-15 23:45:59+00:00
- **Authors**: Asit Mishra, Debbie Marr
- **Comment**: None
- **Journal**: None
- **Summary**: Deep learning networks have achieved state-of-the-art accuracies on computer vision workloads like image classification and object detection. The performant systems, however, typically involve big models with numerous parameters. Once trained, a challenging aspect for such top performing models is deployment on resource constrained inference systems - the models (often deep networks or wide networks or both) are compute and memory intensive. Low-precision numerics and model compression using knowledge distillation are popular techniques to lower both the compute requirements and memory footprint of these deployed models. In this paper, we study the combination of these two techniques and show that the performance of low-precision networks can be significantly improved by using knowledge distillation techniques. Our approach, Apprentice, achieves state-of-the-art accuracies using ternary precision and 4-bit precision for variants of ResNet architecture on ImageNet dataset. We present three schemes using which one can apply knowledge distillation techniques to various stages of the train-and-deploy pipeline.



