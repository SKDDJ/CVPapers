# Arxiv Papers in cs.CV on 2017-11-13
### Crowd counting via scale-adaptive convolutional neural network
- **Arxiv ID**: http://arxiv.org/abs/1711.04433v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04433v4)
- **Published**: 2017-11-13 06:25:56+00:00
- **Updated**: 2018-02-06 21:32:53+00:00
- **Authors**: Lu Zhang, Miaojing Shi, Qiaobo Chen
- **Comment**: IEEE Winter Conf. on Applications of Computer Vision (WACV'18)
- **Journal**: None
- **Summary**: The task of crowd counting is to automatically estimate the pedestrian number in crowd images. To cope with the scale and perspective changes that commonly exist in crowd images, state-of-the-art approaches employ multi-column CNN architectures to regress density maps of crowd images. Multiple columns have different receptive fields corresponding to pedestrians (heads) of different scales. We instead propose a scale-adaptive CNN (SaCNN) architecture with a backbone of fixed small receptive fields. We extract feature maps from multiple layers and adapt them to have the same output size; we combine them to produce the final density map. The number of people is computed by integrating the density map. We also introduce a relative count loss along with the density map loss to improve the network generalization on crowd scenes with few pedestrians, where most representative approaches perform poorly on. We conduct extensive experiments on the ShanghaiTech, UCF_CC_50 and WorldExpo datasets as well as a new dataset SmartCity that we collect for crowd scenes with few people. The results demonstrate significant improvements of SaCNN over the state-of-the-art.



### All-Transfer Learning for Deep Neural Networks and its Application to Sepsis Classification
- **Arxiv ID**: http://arxiv.org/abs/1711.04450v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04450v1)
- **Published**: 2017-11-13 07:28:37+00:00
- **Updated**: 2017-11-13 07:28:37+00:00
- **Authors**: Yoshihide Sawada, Yoshikuni Sato, Toru Nakada, Kei Ujimoto, Nobuhiro Hayashi
- **Comment**: Long version of article published at ECAI 2016 (9 pages, 13 figures,
  8 tables)
- **Journal**: None
- **Summary**: In this article, we propose a transfer learning method for deep neural networks (DNNs). Deep learning has been widely used in many applications. However, applying deep learning is problematic when a large amount of training data are not available. One of the conventional methods for solving this problem is transfer learning for DNNs. In the field of image recognition, state-of-the-art transfer learning methods for DNNs re-use parameters trained on source domain data except for the output layer. However, this method may result in poor classification performance when the amount of target domain data is significantly small. To address this problem, we propose a method called All-Transfer Deep Learning, which enables the transfer of all parameters of a DNN. With this method, we can compute the relationship between the source and target labels by the source domain knowledge. We applied our method to actual two-dimensional electrophoresis image~(2-DE image) classification for determining if an individual suffers from sepsis; the first attempt to apply a classification approach to 2-DE images for proteomics, which has attracted considerable attention as an extension beyond genomics. The results suggest that our proposed method outperforms conventional transfer learning methods for DNNs.



### Visual Concepts and Compositional Voting
- **Arxiv ID**: http://arxiv.org/abs/1711.04451v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04451v1)
- **Published**: 2017-11-13 07:29:04+00:00
- **Updated**: 2017-11-13 07:29:04+00:00
- **Authors**: Jianyu Wang, Zhishuai Zhang, Cihang Xie, Yuyin Zhou, Vittal Premachandran, Jun Zhu, Lingxi Xie, Alan Yuille
- **Comment**: It is accepted by Annals of Mathematical Sciences and Applications
- **Journal**: None
- **Summary**: It is very attractive to formulate vision in terms of pattern theory \cite{Mumford2010pattern}, where patterns are defined hierarchically by compositions of elementary building blocks. But applying pattern theory to real world images is currently less successful than discriminative methods such as deep networks. Deep networks, however, are black-boxes which are hard to interpret and can easily be fooled by adding occluding objects. It is natural to wonder whether by better understanding deep networks we can extract building blocks which can be used to develop pattern theoretic models. This motivates us to study the internal representations of a deep network using vehicle images from the PASCAL3D+ dataset. We use clustering algorithms to study the population activities of the features and extract a set of visual concepts which we show are visually tight and correspond to semantic parts of vehicles. To analyze this we annotate these vehicles by their semantic parts to create a new dataset, VehicleSemanticParts, and evaluate visual concepts as unsupervised part detectors. We show that visual concepts perform fairly well but are outperformed by supervised discriminative methods such as Support Vector Machines (SVM). We next give a more detailed analysis of visual concepts and how they relate to semantic parts. Following this, we use the visual concepts as building blocks for a simple pattern theoretical model, which we call compositional voting. In this model several visual concepts combine to detect semantic parts. We show that this approach is significantly better than discriminative methods like SVM and deep networks trained specifically for semantic part detection. Finally, we return to studying occlusion by creating an annotated dataset with occlusion, called VehicleOcclusion, and show that compositional voting outperforms even deep networks when the amount of occlusion becomes large.



### An Automatic Diagnosis Method of Facial Acne Vulgaris Based on Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1711.04481v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04481v1)
- **Published**: 2017-11-13 09:16:09+00:00
- **Updated**: 2017-11-13 09:16:09+00:00
- **Authors**: Xiaolei Shen, Jiachi Zhang, Chenjun Yan, Hong Zhou
- **Comment**: 12 pages, 7 figures, 5 tables
- **Journal**: None
- **Summary**: In this paper, we present a new automatic diagnosis method of facial acne vulgaris based on convolutional neural network. This method is proposed to overcome the shortcoming of classification types in previous methods. The core of our method is to extract features of images based on convolutional neural network and achieve classification by classifier. We design a binary classifier of skin-and-non-skin to detect skin area and a seven-classifier to achieve the classification of facial acne vulgaris and healthy skin. In the experiment, we compared the effectiveness of our convolutional neural network and the pre-trained VGG16 neural network on the ImageNet dataset. And we use the ROC curve and normal confusion matrix to evaluate the performance of the binary classifier and the seven-classifier. The results of our experiment show that the pre-trained VGG16 neural network is more effective in extracting image features. The classifiers based on the pre-trained VGG16 neural network achieve the skin detection and acne classification and have good robustness.



### Conditional Random Field and Deep Feature Learning for Hyperspectral Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1711.04483v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04483v2)
- **Published**: 2017-11-13 09:18:25+00:00
- **Updated**: 2017-12-27 06:26:01+00:00
- **Authors**: Fahim Irfan Alam, Jun Zhou, Alan Wee-Chung Liew, Xiuping Jia, Jocelyn Chanussot, Yongsheng Gao
- **Comment**: Submitted for Journal (Version 2)
- **Journal**: None
- **Summary**: Image segmentation is considered to be one of the critical tasks in hyperspectral remote sensing image processing. Recently, convolutional neural network (CNN) has established itself as a powerful model in segmentation and classification by demonstrating excellent performances. The use of a graphical model such as a conditional random field (CRF) contributes further in capturing contextual information and thus improving the segmentation performance. In this paper, we propose a method to segment hyperspectral images by considering both spectral and spatial information via a combined framework consisting of CNN and CRF. We use multiple spectral cubes to learn deep features using CNN, and then formulate deep CRF with CNN-based unary and pairwise potential functions to effectively extract the semantic correlations between patches consisting of three-dimensional data cubes. Effective piecewise training is applied in order to avoid the computationally expensive iterative CRF inference. Furthermore, we introduce a deep deconvolution network that improves the segmentation masks. We also introduce a new dataset and experimented our proposed method on it along with several widely adopted benchmark datasets to evaluate the effectiveness of our method. By comparing our results with those from several state-of-the-art models, we show the promising potential of our method.



### Vertebral body segmentation with GrowCut: Initial experience, workflow and practical application
- **Arxiv ID**: http://arxiv.org/abs/1711.04592v1
- **DOI**: 10.1177/2050312117740984
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1711.04592v1)
- **Published**: 2017-11-13 14:19:05+00:00
- **Updated**: 2017-11-13 14:19:05+00:00
- **Authors**: Jan Egger, Christopher Nimsky, Xiaojun Chen
- **Comment**: 10 pages
- **Journal**: SAGE Open Medicine, Volume 5, pp. 1-10, Nov. 2017
- **Summary**: In this contribution, we used the GrowCut segmentation algorithm publicly available in three-dimensional Slicer for three-dimensional segmentation of vertebral bodies. To the best of our knowledge, this is the first time that the GrowCut method has been studied for the usage of vertebral body segmentation. In brief, we found that the GrowCut segmentation times were consistently less than the manual segmentation times. Hence, GrowCut provides an alternative to a manual slice-by-slice segmentation process.



### Convolutional neural networks pretrained on large face recognition datasets for emotion classification from video
- **Arxiv ID**: http://arxiv.org/abs/1711.04598v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04598v1)
- **Published**: 2017-11-13 14:38:24+00:00
- **Updated**: 2017-11-13 14:38:24+00:00
- **Authors**: Boris Knyazev, Roman Shvetsov, Natalia Efremova, Artem Kuharenko
- **Comment**: 4 pages
- **Journal**: None
- **Summary**: In this paper we describe a solution to our entry for the emotion recognition challenge EmotiW 2017. We propose an ensemble of several models, which capture spatial and audio features from videos. Spatial features are captured by convolutional neural networks, pretrained on large face recognition datasets. We show that usage of strong industry-level face recognition networks increases the accuracy of emotion recognition. Using our ensemble we improve on the previous best result on the test set by about 1 %, achieving a 60.03 % classification accuracy without any use of visual temporal information.



### Three Factors Influencing Minima in SGD
- **Arxiv ID**: http://arxiv.org/abs/1711.04623v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1711.04623v3)
- **Published**: 2017-11-13 15:11:56+00:00
- **Updated**: 2018-09-13 09:29:55+00:00
- **Authors**: Stanisław Jastrzębski, Zachary Kenton, Devansh Arpit, Nicolas Ballas, Asja Fischer, Yoshua Bengio, Amos Storkey
- **Comment**: First two authors contributed equally. Short version accepted into
  ICLR workshop. Accepted to Artificial Neural Networks and Machine Learning,
  ICANN 2018
- **Journal**: None
- **Summary**: We investigate the dynamical and convergent properties of stochastic gradient descent (SGD) applied to Deep Neural Networks (DNNs). Characterizing the relation between learning rate, batch size and the properties of the final minima, such as width or generalization, remains an open question. In order to tackle this problem we investigate the previously proposed approximation of SGD by a stochastic differential equation (SDE). We theoretically argue that three factors - learning rate, batch size and gradient covariance - influence the minima found by SGD. In particular we find that the ratio of learning rate to batch size is a key determinant of SGD dynamics and of the width of the final minima, and that higher values of the ratio lead to wider minima and often better generalization. We confirm these findings experimentally. Further, we include experiments which show that learning rate schedules can be replaced with batch size schedules and that the ratio of learning rate to batch size is an important factor influencing the memorization process.



### Machine Learning for the Geosciences: Challenges and Opportunities
- **Arxiv ID**: http://arxiv.org/abs/1711.04708v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, physics.geo-ph
- **Links**: [PDF](http://arxiv.org/pdf/1711.04708v1)
- **Published**: 2017-11-13 17:16:38+00:00
- **Updated**: 2017-11-13 17:16:38+00:00
- **Authors**: Anuj Karpatne, Imme Ebert-Uphoff, Sai Ravela, Hassan Ali Babaie, Vipin Kumar
- **Comment**: Under review at IEEE Transactions on Knowledge and Data Engineering
- **Journal**: None
- **Summary**: Geosciences is a field of great societal relevance that requires solutions to several urgent problems facing our humanity and the planet. As geosciences enters the era of big data, machine learning (ML) -- that has been widely successful in commercial domains -- offers immense potential to contribute to problems in geosciences. However, problems in geosciences have several unique challenges that are seldom found in traditional applications, requiring novel problem formulations and methodologies in machine learning. This article introduces researchers in the machine learning (ML) community to these challenges offered by geoscience problems and the opportunities that exist for advancing both machine learning and geosciences. We first highlight typical sources of geoscience data and describe their properties that make it challenging to use traditional machine learning techniques. We then describe some of the common categories of geoscience problems where machine learning can play a role, and discuss some of the existing efforts and promising directions for methodological development in machine learning. We conclude by discussing some of the emerging research themes in machine learning that are applicable across all problems in the geosciences, and the importance of a deep collaboration between machine learning and geosciences for synergistic advancements in both disciplines.



### Spatio-Temporal Data Mining: A Survey of Problems and Methods
- **Arxiv ID**: http://arxiv.org/abs/1711.04710v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.DB
- **Links**: [PDF](http://arxiv.org/pdf/1711.04710v2)
- **Published**: 2017-11-13 17:17:29+00:00
- **Updated**: 2017-11-17 17:31:54+00:00
- **Authors**: Gowtham Atluri, Anuj Karpatne, Vipin Kumar
- **Comment**: Accepted for publication at ACM Computing Surveys
- **Journal**: None
- **Summary**: Large volumes of spatio-temporal data are increasingly collected and studied in diverse domains including, climate science, social sciences, neuroscience, epidemiology, transportation, mobile health, and Earth sciences. Spatio-temporal data differs from relational data for which computational approaches are developed in the data mining community for multiple decades, in that both spatial and temporal attributes are available in addition to the actual measurements/attributes. The presence of these attributes introduces additional challenges that needs to be dealt with. Approaches for mining spatio-temporal data have been studied for over a decade in the data mining community. In this article we present a broad survey of this relatively young field of spatio-temporal data mining. We discuss different types of spatio-temporal data and the relevant data mining questions that arise in the context of analyzing each of these datasets. Based on the nature of the data mining problem studied, we classify literature on spatio-temporal data mining into six major categories: clustering, predictive learning, change detection, frequent pattern mining, anomaly detection, and relationship mining. We discuss the various forms of spatio-temporal data mining problems in each of these categories.



### Learning and Visualizing Localized Geometric Features Using 3D-CNN: An Application to Manufacturability Analysis of Drilled Holes
- **Arxiv ID**: http://arxiv.org/abs/1711.04851v3
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.04851v3)
- **Published**: 2017-11-13 21:05:39+00:00
- **Updated**: 2018-03-28 03:52:41+00:00
- **Authors**: Sambit Ghadai, Aditya Balu, Adarsh Krishnamurthy, Soumik Sarkar
- **Comment**: Presented at NIPS 2017 Symposium on Interpretable Machine Learning
- **Journal**: None
- **Summary**: 3D Convolutional Neural Networks (3D-CNN) have been used for object recognition based on the voxelized shape of an object. However, interpreting the decision making process of these 3D-CNNs is still an infeasible task. In this paper, we present a unique 3D-CNN based Gradient-weighted Class Activation Mapping method (3D-GradCAM) for visual explanations of the distinct local geometric features of interest within an object. To enable efficient learning of 3D geometries, we augment the voxel data with surface normals of the object boundary. We then train a 3D-CNN with this augmented data and identify the local features critical for decision-making using 3D GradCAM. An application of this feature identification framework is to recognize difficult-to-manufacture drilled hole features in a complex CAD geometry. The framework can be extended to identify difficult-to-manufacture features at multiple spatial scales leading to a real-time design for manufacturability decision support system.



### Denoising Imaging Polarimetry by an Adapted BM3D Method
- **Arxiv ID**: http://arxiv.org/abs/1711.04853v2
- **DOI**: 10.1364/JOSAA.35.000690
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04853v2)
- **Published**: 2017-11-13 21:07:40+00:00
- **Updated**: 2017-11-16 10:21:33+00:00
- **Authors**: Alexander B. Tibbs, Ilse M. Daly, Nicholas W. Roberts, David R. Bull
- **Comment**: None
- **Journal**: None
- **Summary**: Imaging polarimetry allows more information to be extracted from a scene than conventional intensity or colour imaging. However, a major challenge of imaging polarimetry is image degradation due to noise. This paper investigates the mitigation of noise through denoising algorithms and compares existing denoising algorithms with a new method, based on BM3D. This algorithm, PBM3D, gives visual quality superior to the state of the art across all images and noise standard deviations tested. We show that denoising polarization images using PBM3D allows the degree of polarization to be more accurately calculated by comparing it to spectroscopy methods.



### Modeling Human Categorization of Natural Images Using Deep Feature Representations
- **Arxiv ID**: http://arxiv.org/abs/1711.04855v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1711.04855v1)
- **Published**: 2017-11-13 21:18:29+00:00
- **Updated**: 2017-11-13 21:18:29+00:00
- **Authors**: Ruairidh M. Battleday, Joshua C. Peterson, Thomas L. Griffiths
- **Comment**: 13 pages, 7 figures, 6 tables. Preliminary work presented at CogSci
  2017
- **Journal**: None
- **Summary**: Over the last few decades, psychologists have developed sophisticated formal models of human categorization using simple artificial stimuli. In this paper, we use modern machine learning methods to extend this work into the realm of naturalistic stimuli, enabling human categorization to be studied over the complex visual domain in which it evolved and developed. We show that representations derived from a convolutional neural network can be used to model behavior over a database of >300,000 human natural image classifications, and find that a group of models based on these representations perform well, near the reliability of human judgments. Interestingly, this group includes both exemplar and prototype models, contrasting with the dominance of exemplar models in previous work. We are able to improve the performance of the remaining models by preprocessing neural network representations to more closely capture human similarity judgments.



### 3D Shape Classification Using Collaborative Representation based Projections
- **Arxiv ID**: http://arxiv.org/abs/1711.04875v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1711.04875v2)
- **Published**: 2017-11-13 22:28:16+00:00
- **Updated**: 2017-11-18 14:17:38+00:00
- **Authors**: F. Fotopoulou, S. Oikonomou, A. Papathanasiou, G. Economou, S. Fotopoulos
- **Comment**: 16 pages, 6 Figures, 3 Tables Statement including that an updated
  version of this manuscript is under condiseration at Pattern Recognition
  Letters, is added
- **Journal**: None
- **Summary**: A novel 3D shape classification scheme, based on collaborative representation learning, is investigated in this work. A data-driven feature-extraction procedure, taking the form of a simple projection operator, is in the core of our methodology. Provided a shape database, a graph encapsulating the structural relationships among all the available shapes, is first constructed and then employed in defining low-dimensional sparse projections. The recently introduced method of CRPs (collaborative representation based projections), which is based on L2-Graph, is the first variant that is included towards this end. A second algorithm, that particularizes the CRPs to shape descriptors that are inherently nonnegative, is also introduced as potential alternative. In both cases, the weights in the graph reflecting the database structure are calculated so as to approximate each shape as a sparse linear combination of the remaining dataset objects. By way of solving a generalized eigenanalysis problem, a linear matrix operator is designed that will act as the feature extractor. Two popular, inherently high dimensional descriptors, namely ShapeDNA and Global Point Signature (GPS), are employed in our experimentations with SHREC10, SHREC11 and SCHREC 15 datasets, where shape recognition is cast as a multi-class classification problem that is tackled by means of an SVM (support vector machine) acting within the reduced dimensional space of the crafted projections. The results are very promising and outperform state of the art methods, providing evidence about the highly discriminative nature of the introduced 3D shape representations.



