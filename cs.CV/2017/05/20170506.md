# Arxiv Papers in cs.CV on 2017-05-06
### Deep Patch Learning for Weakly Supervised Object Classification and Discovery
- **Arxiv ID**: http://arxiv.org/abs/1705.02429v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02429v1)
- **Published**: 2017-05-06 02:05:38+00:00
- **Updated**: 2017-05-06 02:05:38+00:00
- **Authors**: Peng Tang, Xinggang Wang, Zilong Huang, Xiang Bai, Wenyu Liu
- **Comment**: Accepted by Pattern Recognition
- **Journal**: None
- **Summary**: Patch-level image representation is very important for object classification and detection, since it is robust to spatial transformation, scale variation, and cluttered background. Many existing methods usually require fine-grained supervisions (e.g., bounding-box annotations) to learn patch features, which requires a great effort to label images may limit their potential applications. In this paper, we propose to learn patch features via weak supervisions, i.e., only image-level supervisions. To achieve this goal, we treat images as bags and patches as instances to integrate the weakly supervised multiple instance learning constraints into deep neural networks. Also, our method integrates the traditional multiple stages of weakly supervised object classification and discovery into a unified deep convolutional neural network and optimizes the network in an end-to-end way. The network processes the two tasks object classification and discovery jointly, and shares hierarchical deep features. Through this jointly learning strategy, weakly supervised object classification and discovery are beneficial to each other. We test the proposed method on the challenging PASCAL VOC datasets. The results show that our method can obtain state-of-the-art performance on object classification, and very competitive results on object discovery, with faster testing speed than competitors.



### Sparse Representation-based Open Set Recognition
- **Arxiv ID**: http://arxiv.org/abs/1705.02431v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02431v1)
- **Published**: 2017-05-06 02:16:48+00:00
- **Updated**: 2017-05-06 02:16:48+00:00
- **Authors**: He Zhang, Vishal M. Patel
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a generalized Sparse Representation- based Classification (SRC) algorithm for open set recognition where not all classes presented during testing are known during training. The SRC algorithm uses class reconstruction errors for classification. As most of the discriminative information for open set recognition is hidden in the tail part of the matched and sum of non-matched reconstruction error distributions, we model the tail of those two error distributions using the statistical Extreme Value Theory (EVT). Then we simplify the open set recognition problem into a set of hypothesis testing problems. The confidence scores corresponding to the tail distributions of a novel test sample are then fused to determine its identity. The effectiveness of the proposed method is demonstrated using four publicly available image and object classification datasets and it is shown that this method can perform significantly better than many competitive open set recognition algorithms. Code is public available: https://github.com/hezhangsprinter/SROSR



### On human motion prediction using recurrent neural networks
- **Arxiv ID**: http://arxiv.org/abs/1705.02445v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02445v1)
- **Published**: 2017-05-06 05:08:05+00:00
- **Updated**: 2017-05-06 05:08:05+00:00
- **Authors**: Julieta Martinez, Michael J. Black, Javier Romero
- **Comment**: Accepted at CVPR 17
- **Journal**: None
- **Summary**: Human motion modelling is a classical problem at the intersection of graphics and computer vision, with applications spanning human-computer interaction, motion synthesis, and motion prediction for virtual and augmented reality. Following the success of deep learning methods in several computer vision tasks, recent work has focused on using deep recurrent neural networks (RNNs) to model human motion, with the goal of learning time-dependent representations that perform tasks such as short-term motion prediction and long-term human motion synthesis. We examine recent work, with a focus on the evaluation methodologies commonly used in the literature, and show that, surprisingly, state-of-the-art performance can be achieved by a simple baseline that does not attempt to model motion at all. We investigate this result, and analyze recent RNN methods by looking at the architectures, loss functions, and training procedures used in state-of-the-art approaches. We propose three changes to the standard RNN models typically used for human motion, which result in a simple and scalable RNN architecture that obtains state-of-the-art performance on human motion prediction.



### Image Annotation using Multi-Layer Sparse Coding
- **Arxiv ID**: http://arxiv.org/abs/1705.02460v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02460v1)
- **Published**: 2017-05-06 08:15:18+00:00
- **Updated**: 2017-05-06 08:15:18+00:00
- **Authors**: Amara Tariq, Hassan Foroosh
- **Comment**: None
- **Journal**: None
- **Summary**: Automatic annotation of images with descriptive words is a challenging problem with vast applications in the areas of image search and retrieval. This problem can be viewed as a label-assignment problem by a classifier dealing with a very large set of labels, i.e., the vocabulary set. We propose a novel annotation method that employs two layers of sparse coding and performs coarse-to-fine labeling. Themes extracted from the training data are treated as coarse labels. Each theme is a set of training images that share a common subject in their visual and textual contents. Our system extracts coarse labels for training and test images without requiring any prior knowledge. Vocabulary words are the fine labels to be associated with images. Most of the annotation methods achieve low recall due to the large number of available fine labels, i.e., vocabulary words. These systems also tend to achieve high precision for highly frequent words only while relatively rare words are more important for search and retrieval purposes. Our system not only outperforms various previously proposed annotation systems, but also achieves symmetric response in terms of precision and recall. Our system scores and maintains high precision for words with a wide range of frequencies. Such behavior is achieved by intelligently reducing the number of available fine labels or words for each image based on coarse labels assigned to it.



### A Study and Comparison of Human and Deep Learning Recognition Performance Under Visual Distortions
- **Arxiv ID**: http://arxiv.org/abs/1705.02498v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02498v1)
- **Published**: 2017-05-06 16:16:11+00:00
- **Updated**: 2017-05-06 16:16:11+00:00
- **Authors**: Samuel Dodge, Lina Karam
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) achieve excellent performance on standard classification tasks. However, under image quality distortions such as blur and noise, classification accuracy becomes poor. In this work, we compare the performance of DNNs with human subjects on distorted images. We show that, although DNNs perform better than or on par with humans on good quality images, DNN performance is still much lower than human performance on distorted images. We additionally find that there is little correlation in errors between DNNs and human subjects. This could be an indication that the internal representation of images are different between DNNs and the human visual system. These comparisons with human performance could be used to guide future development of more robust DNNs.



### Context-Aware Trajectory Prediction
- **Arxiv ID**: http://arxiv.org/abs/1705.02503v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.02503v1)
- **Published**: 2017-05-06 16:36:32+00:00
- **Updated**: 2017-05-06 16:36:32+00:00
- **Authors**: Federico Bartoli, Giuseppe Lisanti, Lamberto Ballan, Alberto Del Bimbo
- **Comment**: Submitted to BMVC 2017
- **Journal**: None
- **Summary**: Human motion and behaviour in crowded spaces is influenced by several factors, such as the dynamics of other moving agents in the scene, as well as the static elements that might be perceived as points of attraction or obstacles. In this work, we present a new model for human trajectory prediction which is able to take advantage of both human-human and human-space interactions. The future trajectory of humans, are generated by observing their past positions and interactions with the surroundings. To this end, we propose a "context-aware" recurrent neural network LSTM model, which can learn and predict human motion in crowded spaces such as a sidewalk, a museum or a shopping mall. We evaluate our model on a public pedestrian datasets, and we contribute a new challenging dataset that collects videos of humans that navigate in a (real) crowded space such as a big museum. Results show that our approach can predict human trajectories better when compared to previous state-of-the-art forecasting models.



