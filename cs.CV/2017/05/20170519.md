# Arxiv Papers in cs.CV on 2017-05-19
### Deep-LK for Efficient Adaptive Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1705.06839v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06839v2)
- **Published**: 2017-05-19 00:34:50+00:00
- **Updated**: 2017-05-30 02:08:56+00:00
- **Authors**: Chaoyang Wang, Hamed Kiani Galoogahi, Chen-Hsuan Lin, Simon Lucey
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present a new approach for efficient regression based object tracking which we refer to as Deep- LK. Our approach is closely related to the Generic Object Tracking Using Regression Networks (GOTURN) framework of Held et al. We make the following contributions. First, we demonstrate that there is a theoretical relationship between siamese regression networks like GOTURN and the classical Inverse-Compositional Lucas & Kanade (IC-LK) algorithm. Further, we demonstrate that unlike GOTURN IC-LK adapts its regressor to the appearance of the currently tracked frame. We argue that this missing property in GOTURN can be attributed to its poor performance on unseen objects and/or viewpoints. Second, we propose a novel framework for object tracking - which we refer to as Deep-LK - that is inspired by the IC-LK framework. Finally, we show impressive results demonstrating that Deep-LK substantially outperforms GOTURN. Additionally, we demonstrate comparable tracking performance to current state of the art deep-trackers whilst being an order of magnitude (i.e. 100 FPS) computationally efficient.



### A Predictive Account of Cafe Wall Illusions Using a Quantitative Model
- **Arxiv ID**: http://arxiv.org/abs/1705.06846v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06846v4)
- **Published**: 2017-05-19 01:59:04+00:00
- **Updated**: 2018-08-14 09:19:54+00:00
- **Authors**: Nasim Nematzadeh, David M. W. Powers
- **Comment**: Submitted
- **Journal**: None
- **Summary**: This paper explores the tilt illusion effect in the Cafe Wall pattern using a classical Gaussian Receptive Field model. In this illusion, the mortar lines are misperceived as diverging or converging rather than horizontal. We examine the capability of a simple bioplausible filtering model to recognize different degrees of tilt effect in the Cafe Wall illusion based on different characteristics of the pattern. Our study employed a Difference of Gaussians model of retinal to cortical ON center and/or OFF center receptive fields. A wide range of parameters of the stimulus, for example mortar thickness, luminance, tiles contrast, phase of the tile displacement, have been studied. Our model constructs an edge map representation at multiple scales that reveals tilt cues and clues involved in the illusory perception of the Cafe Wall pattern. We present here that our model can not only detect the tilt in this pattern, but also can predict the strength of the illusion and quantify the degree of tilt. For the first time quantitative predictions of a model are reported for this stimulus. The results of our simulations are consistent with previous psychophysical findings across the full range of Cafe Wall variations tested. Our results also suggest that the Difference of Gaussians mechanism is the heart of the effects explained by, and the mechanisms proposed for, the Irradiation, Brightness Induction, and Bandpass Filtering models.



### Online Signature Verification using Recurrent Neural Network and Length-normalized Path Signature
- **Arxiv ID**: http://arxiv.org/abs/1705.06849v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06849v1)
- **Published**: 2017-05-19 02:27:58+00:00
- **Updated**: 2017-05-19 02:27:58+00:00
- **Authors**: Songxuan Lai, Lianwen Jin, Weixin Yang
- **Comment**: 6 pages, 5 figures, 5 tables
- **Journal**: None
- **Summary**: Inspired by the great success of recurrent neural networks (RNNs) in sequential modeling, we introduce a novel RNN system to improve the performance of online signature verification. The training objective is to directly minimize intra-class variations and to push the distances between skilled forgeries and genuine samples above a given threshold. By back-propagating the training signals, our RNN network produced discriminative features with desired metrics. Additionally, we propose a novel descriptor, called the length-normalized path signature (LNPS), and apply it to online signature verification. LNPS has interesting properties, such as scale invariance and rotation invariance after linear combination, and shows promising results in online signature verification. Experiments on the publicly available SVC-2004 dataset yielded state-of-the-art performance of 2.37% equal error rate (EER).



### Prediction of Sea Surface Temperature using Long Short-Term Memory
- **Arxiv ID**: http://arxiv.org/abs/1705.06861v1
- **DOI**: 10.1109/LGRS.2017.2733548
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06861v1)
- **Published**: 2017-05-19 05:14:31+00:00
- **Updated**: 2017-05-19 05:14:31+00:00
- **Authors**: Qin Zhang, Hui Wang, Junyu Dong, Guoqiang Zhong, Xin Sun
- **Comment**: 5 page, 5 figures
- **Journal**: None
- **Summary**: This letter adopts long short-term memory(LSTM) to predict sea surface temperature(SST), which is the first attempt, to our knowledge, to use recurrent neural network to solve the problem of SST prediction, and to make one week and one month daily prediction. We formulate the SST prediction problem as a time series regression problem. LSTM is a special kind of recurrent neural network, which introduces gate mechanism into vanilla RNN to prevent the vanished or exploding gradient problem. It has strong ability to model the temporal relationship of time series data and can handle the long-term dependency problem well. The proposed network architecture is composed of two kinds of layers: LSTM layer and full-connected dense layer. LSTM layer is utilized to model the time series relationship. Full-connected layer is utilized to map the output of LSTM layer to a final prediction. We explore the optimal setting of this architecture by experiments and report the accuracy of coastal seas of China to confirm the effectiveness of the proposed method. In addition, we also show its online updated characteristics.



### ADMM-Net: A Deep Learning Approach for Compressive Sensing MRI
- **Arxiv ID**: http://arxiv.org/abs/1705.06869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06869v1)
- **Published**: 2017-05-19 06:33:18+00:00
- **Updated**: 2017-05-19 06:33:18+00:00
- **Authors**: Yan Yang, Jian Sun, Huibin Li, Zongben Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Compressive sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR images from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and speed, in this paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and generalized versions. ADMM-Nets are defined over data flow graphs, which are derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They take the sampled k-space data as inputs and output reconstructed MR images. Moreover, we extend our network to cope with complex-valued MR images. In the training phase, all parameters of the nets, e.g., transforms, shrinkage functions, etc., are discriminatively trained end-to-end. In the testing phase, they have computational overhead similar to ADMM algorithm but use optimized parameters learned from the data for CS-based reconstruction task. We investigate different configurations in network structures and conduct extensive experiments on MR image reconstruction under different sampling rates. Due to the combination of the advantages in model-based approach and deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction accuracies with fast computational speed.



### Fiber Orientation Estimation Guided by a Deep Network
- **Arxiv ID**: http://arxiv.org/abs/1705.06870v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06870v1)
- **Published**: 2017-05-19 06:37:34+00:00
- **Updated**: 2017-05-19 06:37:34+00:00
- **Authors**: Chuyang Ye, Jerry L. Prince
- **Comment**: A shorter version is accepted by MICCAI 2017
- **Journal**: None
- **Summary**: Diffusion magnetic resonance imaging (dMRI) is currently the only tool for noninvasively imaging the brain's white matter tracts. The fiber orientation (FO) is a key feature computed from dMRI for fiber tract reconstruction. Because the number of FOs in a voxel is usually small, dictionary-based sparse reconstruction has been used to estimate FOs with a relatively small number of diffusion gradients. However, accurate FO estimation in regions with complex FO configurations in the presence of noise can still be challenging. In this work we explore the use of a deep network for FO estimation in a dictionary-based framework and propose an algorithm named Fiber Orientation Reconstruction guided by a Deep Network (FORDN). FORDN consists of two steps. First, we use a smaller dictionary encoding coarse basis FOs to represent the diffusion signals. To estimate the mixture fractions of the dictionary atoms (and thus coarse FOs), a deep network is designed specifically for solving the sparse reconstruction problem. Here, the smaller dictionary is used to reduce the computational cost of training. Second, the coarse FOs inform the final FO estimation, where a larger dictionary encoding dense basis FOs is used and a weighted l1-norm regularized least squares problem is solved to encourage FOs that are consistent with the network output. FORDN was evaluated and compared with state-of-the-art algorithms that estimate FOs using sparse reconstruction on simulated and real dMRI data, and the results demonstrate the benefit of using a deep network for FO estimation.



### Affine-Gradient Based Local Binary Pattern Descriptor for Texture Classiffication
- **Arxiv ID**: http://arxiv.org/abs/1705.06871v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06871v1)
- **Published**: 2017-05-19 06:41:31+00:00
- **Updated**: 2017-05-19 06:41:31+00:00
- **Authors**: You Hao, Shirui Li, Hanlin Mo, Hua Li
- **Comment**: 11 pages,4 pages
- **Journal**: None
- **Summary**: We present a novel Affine-Gradient based Local Binary Pattern (AGLBP) descriptor for texture classification. It is very hard to describe complicated texture using single type information, such as Local Binary Pattern (LBP), which just utilizes the sign information of the difference between the pixel and its local neighbors. Our descriptor has three characteristics: 1) In order to make full use of the information contained in the texture, the Affine-Gradient, which is different from Euclidean-Gradient and invariant to affine transformation is incorporated into AGLBP. 2) An improved method is proposed for rotation invariance, which depends on the reference direction calculating respect to local neighbors. 3) Feature selection method, considering both the statistical frequency and the intraclass variance of the training dataset, is also applied to reduce the dimensionality of descriptors. Experiments on three standard texture datasets, Outex12, Outex10 and KTH-TIPS2, are conducted to evaluate the performance of AGLBP. The results show that our proposed descriptor gets better performance comparing to some state-of-the-art rotation texture descriptors in texture classification.



### Evaluation of Direct Haptic 4D Volume Rendering of Partially Segmented Data for Liver Puncture Simulation
- **Arxiv ID**: http://arxiv.org/abs/1705.07118v1
- **DOI**: 10.1038/s41598-017-00746-z
- **Categories**: **cs.GR**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1705.07118v1)
- **Published**: 2017-05-19 09:13:51+00:00
- **Updated**: 2017-05-19 09:13:51+00:00
- **Authors**: Andre Mastmeyer, Dirk Fortmeier, Heinz Handels
- **Comment**: 15 pages, 16 figures, 1 tables, 11 equations, 39 references
- **Journal**: Nature - Scientific Reports, Nature Publishing Group (NPG),
  7(671), 2017
- **Summary**: This work presents an evaluation study using a force feedback evaluation framework for a novel direct needle force volume rendering concept in the context of liver puncture simulation. PTC/PTCD puncture interventions targeting the bile ducts have been selected to illustrate this concept. The haptic algorithms of the simulator system are based on (1) partially segmented patient image data and (2) a non-linear spring model effective at organ borders. The primary aim is to quantitatively evaluate force errors caused by our patient modeling approach, in comparison to haptic force output obtained from using gold-standard, completely manually-segmented data. The evaluation of the force algorithms compared to a force output from fully manually segmented gold-standard patient models, yields a low mean of 0.12 N root mean squared force error and up to 1.6 N for systematic maximum absolute errors. Force errors were evaluated on 31,222 preplanned test paths from 10 patients. Only twelve percent of the emitted forces along these paths were affected by errors. This is the first study evaluating haptic algorithms with deformable virtual patients in silico. We prove haptic rendering plausibility on a very high number of test paths. Important errors are below just noticeable differences for the hand-arm system.



### Local Shape Spectrum Analysis for 3D Facial Expression Recognition
- **Arxiv ID**: http://arxiv.org/abs/1705.06900v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06900v1)
- **Published**: 2017-05-19 09:24:16+00:00
- **Updated**: 2017-05-19 09:24:16+00:00
- **Authors**: Dmytro Derkach, Federico M. Sukno
- **Comment**: 12th IEEE International Conference on Face and Gesture Recognition,
  Washington, DC, USA, 2017
- **Journal**: None
- **Summary**: We investigate the problem of facial expression recognition using 3D data. Building from one of the most successful frameworks for facial analysis using exclusively 3D geometry, we extend the analysis from a curve-based representation into a spectral representation, which allows a complete description of the underlying surface that can be further tuned to the desired level of detail. Spectral representations are based on the decomposition of the geometry in its spatial frequency components, much like a Fourier transform, which are related to intrinsic characteristics of the surface. In this work, we propose the use of Graph Laplacian Features (GLF), which results from the projection of local surface patches into a common basis obtained from the Graph Laplacian eigenspace. We test the proposed approach in the BU-3DFE database in terms of expressions and Action Units recognition. Our results confirm that the proposed GLF produces consistently higher recognition rates than the curves-based approach, thanks to a more complete description of the surface, while requiring a lower computational complexity. We also show that the GLF outperform the most popular alternative approach for spectral representation, Shape- DNA, which is based on the Laplace Beltrami Operator and cannot provide a stable basis that guarantee that the extracted signatures for the different patches are directly comparable.



### Segmented and Non-Segmented Stacked Denoising Autoencoder for Hyperspectral Band Reduction
- **Arxiv ID**: http://arxiv.org/abs/1705.06920v5
- **DOI**: 10.1016/j.ijleo.2018.10.142
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06920v5)
- **Published**: 2017-05-19 10:33:21+00:00
- **Updated**: 2018-04-22 11:08:12+00:00
- **Authors**: Muhammad Ahmad, Asad Khan, Adil Mehmood Khan, Rasheed Hussain
- **Comment**: 10 pages, 14 figures
- **Journal**: Optik-2019
- **Summary**: Hyperspectral image analysis often requires selecting the most informative bands instead of processing the whole data without losing the key information. Existing band reduction (BR) methods have the capability to reveal the nonlinear properties exhibited in the data but at the expense of loosing its original representation. To cope with the said issue, an unsupervised non-linear segmented and non-segmented stacked denoising autoencoder (UDAE) based BR method is proposed. Our aim is to find an optimal mapping and construct a lower-dimensional space that has a similar structure to the original data with least reconstruction error. The proposed method first confronts the original hyperspectral data into smaller regions in a spatial domain and then each region is processed by UDAE individually. This results in reduced complexity and improved efficiency of BR for both semi-supervised and unsupervised tasks, i.e. classification and clustering. Our experiments on publicly available hyperspectral datasets with various types of classifiers demonstrate the effectiveness of UDAE method which equates favorably with other state-of-the-art dimensionality reduction and BR methods.



### The Kinetics Human Action Video Dataset
- **Arxiv ID**: http://arxiv.org/abs/1705.06950v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.06950v1)
- **Published**: 2017-05-19 12:07:01+00:00
- **Updated**: 2017-05-19 12:07:01+00:00
- **Authors**: Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, Andrew Zisserman
- **Comment**: None
- **Journal**: None
- **Summary**: We describe the DeepMind Kinetics human action video dataset. The dataset contains 400 human action classes, with at least 400 video clips for each action. Each clip lasts around 10s and is taken from a different YouTube video. The actions are human focussed and cover a broad range of classes including human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands. We describe the statistics of the dataset, how it was collected, and give some baseline performance figures for neural network architectures trained and tested for human action classification on this dataset. We also carry out a preliminary analysis of whether imbalance in the dataset leads to bias in the classifiers.



### Improving classification accuracy of feedforward neural networks for spiking neuromorphic chips
- **Arxiv ID**: http://arxiv.org/abs/1705.07755v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1705.07755v1)
- **Published**: 2017-05-19 12:59:14+00:00
- **Updated**: 2017-05-19 12:59:14+00:00
- **Authors**: Antonio Jimeno Yepes, Jianbin Tang, Benjamin Scott Mashford
- **Comment**: IJCAI-2017. arXiv admin note: text overlap with arXiv:1605.07740
- **Journal**: None
- **Summary**: Deep Neural Networks (DNN) achieve human level performance in many image analytics tasks but DNNs are mostly deployed to GPU platforms that consume a considerable amount of power. New hardware platforms using lower precision arithmetic achieve drastic reductions in power consumption. More recently, brain-inspired spiking neuromorphic chips have achieved even lower power consumption, on the order of milliwatts, while still offering real-time processing.   However, for deploying DNNs to energy efficient neuromorphic chips the incompatibility between continuous neurons and synaptic weights of traditional DNNs, discrete spiking neurons and synapses of neuromorphic chips need to be overcome. Previous work has achieved this by training a network to learn continuous probabilities, before it is deployed to a neuromorphic architecture, such as IBM TrueNorth Neurosynaptic System, by random sampling these probabilities.   The main contribution of this paper is a new learning algorithm that learns a TrueNorth configuration ready for deployment. We achieve this by training directly a binary hardware crossbar that accommodates the TrueNorth axon configuration constrains and we propose a different neuron model.   Results of our approach trained on electroencephalogram (EEG) data show a significant improvement with previous work (76% vs 86% accuracy) while maintaining state of the art performance on the MNIST handwritten data set.



### Segmentation of 3D High-frequency Ultrasound Images of Human Lymph Nodes Using Graph Cut with Energy Functional Adapted to Local Intensity Distribution
- **Arxiv ID**: http://arxiv.org/abs/1705.07015v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07015v1)
- **Published**: 2017-05-19 14:25:20+00:00
- **Updated**: 2017-05-19 14:25:20+00:00
- **Authors**: Jen-wei Kuo, Jonathan Mamou, Yao Wang, Emi Saegusa-Beecroft, Junji Machi, Ernest J. Feleppa
- **Comment**: None
- **Journal**: None
- **Summary**: Previous studies by our group have shown that three-dimensional high-frequency quantitative ultrasound methods have the potential to differentiate metastatic lymph nodes from cancer-free lymph nodes dissected from human cancer patients. To successfully perform these methods inside the lymph node parenchyma, an automatic segmentation method is highly desired to exclude the surrounding thin layer of fat from quantitative ultrasound processing and accurately correct for ultrasound attenuation. In high-frequency ultrasound images of lymph nodes, the intensity distribution of lymph node parenchyma and fat varies spatially because of acoustic attenuation and focusing effects. Thus, the intensity contrast between two object regions (e.g., lymph node parenchyma and fat) is also spatially varying. In our previous work, nested graph cut demonstrated its ability to simultaneously segment lymph node parenchyma, fat, and the outer phosphate-buffered saline bath even when some boundaries are lost because of acoustic attenuation and focusing effects. This paper describes a novel approach called graph cut with locally adaptive energy to further deal with spatially varying distributions of lymph node parenchyma and fat caused by inhomogeneous acoustic attenuation. The proposed method achieved Dice similarity coefficients of 0.937+-0.035 when compared to expert manual segmentation on a representative dataset consisting of 115 three-dimensional lymph node images obtained from colorectal cancer patients.



### What are the Receptive, Effective Receptive, and Projective Fields of Neurons in Convolutional Neural Networks?
- **Arxiv ID**: http://arxiv.org/abs/1705.07049v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07049v2)
- **Published**: 2017-05-19 15:25:03+00:00
- **Updated**: 2018-04-07 13:18:48+00:00
- **Authors**: Hung Le, Ali Borji
- **Comment**: Fix typo mistake on equations (2) and (3). The "summation" should be
  the "product" instead
- **Journal**: None
- **Summary**: In this work, we explain in detail how receptive fields, effective receptive fields, and projective fields of neurons in different layers, convolution or pooling, of a Convolutional Neural Network (CNN) are calculated. While our focus here is on CNNs, the same operations, but in the reverse order, can be used to calculate these quantities for deconvolutional neural networks. These are important concepts, not only for better understanding and analyzing convolutional and deconvolutional networks, but also for optimizing their performance in real-world applications.



### MRI-PET Registration with Automated Algorithm in Pre-clinical Studies
- **Arxiv ID**: http://arxiv.org/abs/1705.07062v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07062v2)
- **Published**: 2017-05-19 15:46:30+00:00
- **Updated**: 2017-05-23 13:42:39+00:00
- **Authors**: Nathanael L. Baisa, Stéphanie Bricq, Alain Lalande
- **Comment**: None
- **Journal**: None
- **Summary**: Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) automatic 3-D registration is implemented and validated for small animal image volumes so that the high-resolution anatomical MRI information can be fused with the low spatial resolution of functional PET information for the localization of lesion that is currently in high demand in the study of tumor of cancer (oncology) and its corresponding preparation of pharmaceutical drugs. Though many registration algorithms are developed and applied on human brain volumes, these methods may not be as efficient on small animal datasets due to lack of intensity information and often the high anisotropy in voxel dimensions. Therefore, a fully automatic registration algorithm which can register not only assumably rigid small animal volumes such as brain but also deformable organs such as kidney, cardiac and chest is developed using a combination of global affine and local B-spline transformation models in which mutual information is used as a similarity criterion. The global affine registration uses a multi-resolution pyramid on image volumes of 3 levels whereas in local B-spline registration, a multi-resolution scheme is applied on the B-spline grid of 2 levels on the finest resolution of the image volumes in which only the transform itself is affected rather than the image volumes. Since mutual information lacks sufficient spatial information, PCA is used to inject it by estimating initial translation and rotation parameters. It is computationally efficient since it is implemented using C++ and ITK library, and is qualitatively and quantitatively shown that this PCA-initialized global registration followed by local registration is in close agreement with expert manual registration and outperforms the one without PCA initialization tested on small animal brain and kidney.



### What do We Learn by Semantic Scene Understanding for Remote Sensing imagery in CNN framework?
- **Arxiv ID**: http://arxiv.org/abs/1705.07077v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1705.07077v1)
- **Published**: 2017-05-19 16:23:53+00:00
- **Updated**: 2017-05-19 16:23:53+00:00
- **Authors**: Haifeng Li, Jian Peng, Chao Tao, Jie Chen, Min Deng
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, deep convolutional neural network (DCNN) achieved increasingly remarkable success and rapidly developed in the field of natural image recognition. Compared with the natural image, the scale of remote sensing image is larger and the scene and the object it represents are more macroscopic. This study inquires whether remote sensing scene and natural scene recognitions differ and raises the following questions: What are the key factors in remote sensing scene recognition? Is the DCNN recognition mechanism centered on object recognition still applicable to the scenarios of remote sensing scene understanding? We performed several experiments to explore the influence of the DCNN structure and the scale of remote sensing scene understanding from the perspective of scene complexity. Our experiment shows that understanding a complex scene depends on an in-depth network and multiple-scale perception. Using a visualization method, we qualitatively and quantitatively analyze the recognition mechanism in a complex remote sensing scene and demonstrate the importance of multi-objective joint semantic support.



### Bitwise Operations of Cellular Automaton on Gray-scale Images
- **Arxiv ID**: http://arxiv.org/abs/1705.07080v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07080v1)
- **Published**: 2017-05-19 16:34:29+00:00
- **Updated**: 2017-05-19 16:34:29+00:00
- **Authors**: Karttikeya Mangalam, K S Venkatesh
- **Comment**: 5 Pages. The code is available at :
  https://github.com/karttikeya/Bitwise-CA-Opeartions/
- **Journal**: None
- **Summary**: Cellular Automata (CA) theory is a discrete model that represents the state of each of its cells from a finite set of possible values which evolve in time according to a pre-defined set of transition rules. CA have been applied to a number of image processing tasks such as Convex Hull Detection, Image Denoising etc. but mostly under the limitation of restricting the input to binary images. In general, a gray-scale image may be converted to a number of different binary images which are finally recombined after CA operations on each of them individually. We have developed a multinomial regression based weighed summation method to recombine binary images for better performance of CA based Image Processing algorithms. The recombination algorithm is tested for the specific case of denoising Salt and Pepper Noise to test against standard benchmark algorithms such as the Median Filter for various images and noise levels. The results indicate several interesting invariances in the application of the CA, such as the particular noise realization and the choice of sub-sampling of pixels to determine recombination weights. Additionally, it appears that simpler algorithms for weight optimization which seek local minima work as effectively as those that seek global minima such as Simulated Annealing.



### Matching neural paths: transfer from recognition to correspondence search
- **Arxiv ID**: http://arxiv.org/abs/1705.08272v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1705.08272v3)
- **Published**: 2017-05-19 16:40:35+00:00
- **Updated**: 2017-11-05 22:33:22+00:00
- **Authors**: Nikolay Savinov, Lubor Ladicky, Marc Pollefeys
- **Comment**: Accepted at NIPS 2017
- **Journal**: None
- **Summary**: Many machine learning tasks require finding per-part correspondences between objects. In this work we focus on low-level correspondences - a highly ambiguous matching problem. We propose to use a hierarchical semantic representation of the objects, coming from a convolutional neural network, to solve this ambiguity. Training it for low-level correspondence prediction directly might not be an option in some domains where the ground-truth correspondences are hard to obtain. We show how transfer from recognition can be used to avoid such training. Our idea is to mark parts as "matching" if their features are close to each other at all the levels of convolutional feature hierarchy (neural paths). Although the overall number of such paths is exponential in the number of layers, we propose a polynomial algorithm for aggregating all of them in a single backward pass. The empirical validation is done on the task of stereo correspondence and demonstrates that we achieve competitive results among the methods which do not use labeled target domain data.



### CNN-Based Joint Clustering and Representation Learning with Feature Drift Compensation for Large-Scale Image Data
- **Arxiv ID**: http://arxiv.org/abs/1705.07091v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07091v2)
- **Published**: 2017-05-19 17:01:38+00:00
- **Updated**: 2017-08-11 07:31:48+00:00
- **Authors**: Chih-Chung Hsu, Chia-Wen Lin
- **Comment**: 9 pages to appear in IEEE Transactions on Multimedia (Special Issue
  on Large-Scale Multimedia Data Retrieval, Classification, and Understanding)
- **Journal**: None
- **Summary**: Given a large unlabeled set of images, how to efficiently and effectively group them into clusters based on extracted visual representations remains a challenging problem. To address this problem, we propose a convolutional neural network (CNN) to jointly solve clustering and representation learning in an iterative manner. In the proposed method, given an input image set, we first randomly pick k samples and extract their features as initial cluster centroids using the proposed CNN with an initial model pre-trained from the ImageNet dataset. Mini-batch k-means is then performed to assign cluster labels to individual input samples for a mini-batch of images randomly sampled from the input image set until all images are processed. Subsequently, the proposed CNN simultaneously updates the parameters of the proposed CNN and the centroids of image clusters iteratively based on stochastic gradient descent. We also proposed a feature drift compensation scheme to mitigate the drift error caused by feature mismatch in representation learning. Experimental results demonstrate the proposed method outperforms start-of-the-art clustering schemes in terms of accuracy and storage complexity on large-scale image sets containing millions of images.



### Snapshot Difference Imaging using Time-of-Flight Sensors
- **Arxiv ID**: http://arxiv.org/abs/1705.07108v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1705.07108v1)
- **Published**: 2017-05-19 17:39:43+00:00
- **Updated**: 2017-05-19 17:39:43+00:00
- **Authors**: Clara Callenberg, Felix Heide, Gordon Wetzstein, Matthias Hullin
- **Comment**: None
- **Journal**: None
- **Summary**: Computational photography encompasses a diversity of imaging techniques, but one of the core operations performed by many of them is to compute image differences. An intuitive approach to computing such differences is to capture several images sequentially and then process them jointly. Usually, this approach leads to artifacts when recording dynamic scenes. In this paper, we introduce a snapshot difference imaging approach that is directly implemented in the sensor hardware of emerging time-of-flight cameras. With a variety of examples, we demonstrate that the proposed snapshot difference imaging technique is useful for direct-global illumination separation, for direct imaging of spatial and temporal image gradients, for direct depth edge imaging, and more.



### Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics
- **Arxiv ID**: http://arxiv.org/abs/1705.07115v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07115v3)
- **Published**: 2017-05-19 17:56:57+00:00
- **Updated**: 2018-04-24 06:42:35+00:00
- **Authors**: Alex Kendall, Yarin Gal, Roberto Cipolla
- **Comment**: CVPR 2018
- **Journal**: None
- **Summary**: Numerous deep learning applications benefit from multi-task learning with multiple regression and classification objectives. In this paper we make the observation that the performance of such systems is strongly dependent on the relative weighting between each task's loss. Tuning these weights by hand is a difficult and expensive process, making multi-task learning prohibitive in practice. We propose a principled approach to multi-task deep learning which weighs multiple loss functions by considering the homoscedastic uncertainty of each task. This allows us to simultaneously learn various quantities with different units or scales in both classification and regression settings. We demonstrate our model learning per-pixel depth regression, semantic and instance segmentation from a monocular input image. Perhaps surprisingly, we show our model can learn multi-task weightings and outperform separate models trained individually on each task.



### Deep De-Aliasing for Fast Compressive Sensing MRI
- **Arxiv ID**: http://arxiv.org/abs/1705.07137v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07137v1)
- **Published**: 2017-05-19 18:17:46+00:00
- **Updated**: 2017-05-19 18:17:46+00:00
- **Authors**: Simiao Yu, Hao Dong, Guang Yang, Greg Slabaugh, Pier Luigi Dragotti, Xujiong Ye, Fangde Liu, Simon Arridge, Jennifer Keegan, David Firmin, Yike Guo
- **Comment**: 15 pages, 5 figures
- **Journal**: None
- **Summary**: Fast Magnetic Resonance Imaging (MRI) is highly in demand for many clinical applications in order to reduce the scanning cost and improve the patient experience. This can also potentially increase the image quality by reducing the motion artefacts and contrast washout. However, once an image field of view and the desired resolution are chosen, the minimum scanning time is normally determined by the requirement of acquiring sufficient raw data to meet the Nyquist-Shannon sampling criteria. Compressive Sensing (CS) theory has been perfectly matched to the MRI scanning sequence design with much less required raw data for the image reconstruction. Inspired by recent advances in deep learning for solving various inverse problems, we propose a conditional Generative Adversarial Networks-based deep learning framework for de-aliasing and reconstructing MRI images from highly undersampled data with great promise to accelerate the data acquisition process. By coupling an innovative content loss with the adversarial loss our de-aliasing results are more realistic. Furthermore, we propose a refinement learning procedure for training the generator network, which can stabilise the training with fast convergence and less parameter tuning. We demonstrate that the proposed framework outperforms state-of-the-art CS-MRI methods, in terms of reconstruction error and perceptual image quality. In addition, our method can reconstruct each image in 0.22ms--0.37ms, which is promising for real-time applications.



### Simultaneous Multiple Surface Segmentation Using Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1705.07142v1
- **DOI**: 10.1007/978-3-319-67558-9_1
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07142v1)
- **Published**: 2017-05-19 18:43:07+00:00
- **Updated**: 2017-05-19 18:43:07+00:00
- **Authors**: Abhay Shah, Michael Abramoff, Xiaodong Wu
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: The task of automatically segmenting 3-D surfaces representing boundaries of objects is important for quantitative analysis of volumetric images, and plays a vital role in biomedical image analysis. Recently, graph-based methods with a global optimization property have been developed and optimized for various medical imaging applications. Despite their widespread use, these require human experts to design transformations, image features, surface smoothness priors, and re-design for a different tissue, organ or imaging modality. Here, we propose a Deep Learning based approach for segmentation of the surfaces in volumetric medical images, by learning the essential features and transformations from training data, without any human expert intervention. We employ a regional approach to learn the local surface profiles. The proposed approach was evaluated on simultaneous intraretinal layer segmentation of optical coherence tomography (OCT) images of normal retinas and retinas affected by age related macular degeneration (AMD). The proposed approach was validated on 40 retina OCT volumes including 20 normal and 20 AMD subjects. The experiments showed statistically significant improvement in accuracy for our approach compared to state-of-the-art graph based optimal surface segmentation with convex priors (G-OSC). A single Convolution Neural Network (CNN) was used to learn the surfaces for both normal and diseased images. The mean unsigned surface positioning errors obtained by G-OSC method 2.31 voxels (95% CI 2.02-2.60 voxels) was improved to $1.27$ voxels (95% CI 1.14-1.40 voxels) using our new approach. On average, our approach takes 94.34 s, requiring 95.35 MB memory, which is much faster than the 2837.46 s and 6.87 GB memory required by the G-OSC method on the same computer system.



### A New 3D Segmentation Methodology for Lumbar Vertebral Bodies for the Measurement of BMD and Geometry
- **Arxiv ID**: http://arxiv.org/abs/1705.07143v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07143v1)
- **Published**: 2017-05-19 18:49:18+00:00
- **Updated**: 2017-05-19 18:49:18+00:00
- **Authors**: Andre Mastmeyer, Klaus Engelke, Willi Kalender
- **Comment**: 4 pages,2 figures, MIUA05 conference
- **Journal**: None
- **Summary**: In this paper a new technique is presented that extracts the geometry of lumbar vertebral bodies from spiral CT scans. Our new multi-step segmentation approach yields highly accurate and precise measurement of the bone mineral density (BMD) in different volumes of interest which are defined relative to a local anatomical coordinate systems. The approach also enables the analysis of the geometry of the relevant vertebrae. Intra- and inter operator precision for segmentation, BMD measurement and position of the coordinate system are below 1.5% in patient data, accuracy errors are below 1.5% for BMD and below 4% for volume in phantom data. The long-term goal of the approach is to improve fracture prediction in osteoporosis.



### Sparse Coding on Stereo Video for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1705.07144v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07144v2)
- **Published**: 2017-05-19 18:52:55+00:00
- **Updated**: 2017-11-30 21:41:55+00:00
- **Authors**: Sheng Y. Lundquist, Melanie Mitchell, Garrett T. Kenyon
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (DCNN) require millions of labeled training examples for image classification and object detection tasks, which restrict these models to domains where such datasets are available. In this paper, we explore the use of unsupervised sparse coding applied to stereo-video data to help alleviate the need for large amounts of labeled data. We show that replacing a typical supervised convolutional layer with an unsupervised sparse-coding layer within a DCNN allows for better performance on a car detection task when only a limited number of labeled training examples is available. Furthermore, the network that incorporates sparse coding allows for more consistent performance over varying initializations and ordering of training examples when compared to a fully supervised DCNN. Finally, we compare activations between the unsupervised sparse-coding layer and the supervised convolutional layer, and show that the sparse representation exhibits an encoding that is depth selective, whereas encodings from the convolutional layer do not exhibit such selectivity. These result indicates promise for using unsupervised sparse-coding approaches in real-world computer vision tasks in domains with limited labeled training data.



### A New 3D Method to Segment the Lumbar Vertebral Bodies and to Determine Bone Mineral Density and Geometry
- **Arxiv ID**: http://arxiv.org/abs/1705.07146v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07146v2)
- **Published**: 2017-05-19 18:59:05+00:00
- **Updated**: 2020-12-10 07:52:58+00:00
- **Authors**: Andre Mastmeyer, Klaus Engelke, Sebastian Meller, Willi Kalender
- **Comment**: 8 pages, 6 figures, 1 table, MICCAI 2005. arXiv admin note: text
  overlap with arXiv:1705.07143
- **Journal**: None
- **Summary**: In this paper we present a new 3D segmentation approach for the vertebrae of the lower thoracic and the lumbar spine in spiral computed tomography datasets. We implemented a multi-step procedure. Its main components are deformable models, volume growing, and morphological operations. The performance analysis that included an evaluation of accuracy using the European Spine Phantom, and of intra-operator precision using clinical CT datasets from 10 patients highlight the potential for clinical use. The intra-operator precision of the segmentation procedure was better than 1% for Bone Mineral Density (BMD) and better than 1.8% for volume. The long-term goal of this work is to enable better fracture prediction and improved patient monitoring in the field of osteoporosis. A true 3D segmentation also enables an accurate measurement of geometrical parameters that can augment the classical measurement of BMD.



### A New 3D Segmentation Technique for QCT Scans of the Lumbar Spine to Determine BMD and Vertebral Geometry
- **Arxiv ID**: http://arxiv.org/abs/1705.08273v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.08273v1)
- **Published**: 2017-05-19 19:13:38+00:00
- **Updated**: 2017-05-19 19:13:38+00:00
- **Authors**: Andre Mastmeyer, Klaus Engelke, Christina Fuchs, Willi Kalender
- **Comment**: 2 pages, 2 figures, International Congress of Medical Physics 2005
- **Journal**: None
- **Summary**: Quantitative computed tomography (QCT) is a standard method to determine bone mineral density (BMD) in the spine. Traditionally single 8 - 10 mm thick slices have been analyzed only. Current spiral CT scanners provide true 3D acquisition schemes allowing for a more differential BMD analysis and an assessment of geometric parameters, which may improve fracture prediction. We developed a novel 3D segmentation approach that combines deformable balloons, multi seeded volume growing, and dedicated morphological operations to extract the vertebral bodies. An anatomy-oriented coordinate system attached automatically to each vertebra is used to define volumes of interest. We analyzed intra-operator precision of the segmentation procedure using abdominal scans from 10 patients (60 mAs, 120 kV, slice thickness 1mm, B40s, Siemens Sensation 16). Our new segmentation method shows excellent precision errors in the order of < 1 % for BMD and < 2 % for volume.



### A Lightweight Approach for On-the-Fly Reflectance Estimation
- **Arxiv ID**: http://arxiv.org/abs/1705.07162v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07162v2)
- **Published**: 2017-05-19 19:45:57+00:00
- **Updated**: 2018-04-02 05:21:39+00:00
- **Authors**: Kihwan Kim, Jinwei Gu, Stephen Tyree, Pavlo Molchanov, Matthias Nießner, Jan Kautz
- **Comment**: ICCV 2017
- **Journal**: None
- **Summary**: Estimating surface reflectance (BRDF) is one key component for complete 3D scene capture, with wide applications in virtual reality, augmented reality, and human computer interaction. Prior work is either limited to controlled environments (\eg gonioreflectometers, light stages, or multi-camera domes), or requires the joint optimization of shape, illumination, and reflectance, which is often computationally too expensive (\eg hours of running time) for real-time applications. Moreover, most prior work requires HDR images as input which further complicates the capture process. In this paper, we propose a lightweight approach for surface reflectance estimation directly from $8$-bit RGB images in real-time, which can be easily plugged into any 3D scanning-and-fusion system with a commodity RGBD sensor. Our method is learning-based, with an inference time of less than 90ms per scene and a model size of less than 340K bytes. We propose two novel network architectures, HemiCNN and Grouplet, to deal with the unstructured input data from multiple viewpoints under unknown illumination. We further design a loss function to resolve the color-constancy and scale ambiguity. In addition, we have created a large synthetic dataset, SynBRDF, which comprises a total of $500$K RGBD images rendered with a physically-based ray tracer under a variety of natural illumination, covering $5000$ materials and $5000$ shapes. SynBRDF is the first large-scale benchmark dataset for reflectance estimation. Experiments on both synthetic data and real data show that the proposed method effectively recovers surface reflectance, and outperforms prior work for reflectance estimation in uncontrolled environments.



### Espresso: Efficient Forward Propagation for BCNNs
- **Arxiv ID**: http://arxiv.org/abs/1705.07175v2
- **DOI**: None
- **Categories**: **cs.DC**, cs.CV, cs.LG, cs.NE, 62M45, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/1705.07175v2)
- **Published**: 2017-05-19 20:29:42+00:00
- **Updated**: 2018-03-07 17:59:16+00:00
- **Authors**: Fabrizio Pedersoli, George Tzanetakis, Andrea Tagliasacchi
- **Comment**: 10 pages, 4 figures
- **Journal**: None
- **Summary**: There are many applications scenarios for which the computational performance and memory footprint of the prediction phase of Deep Neural Networks (DNNs) needs to be optimized. Binary Neural Networks (BDNNs) have been shown to be an effective way of achieving this objective. In this paper, we show how Convolutional Neural Networks (CNNs) can be implemented using binary representations. Espresso is a compact, yet powerful library written in C/CUDA that features all the functionalities required for the forward propagation of CNNs, in a binary file less than 400KB, without any external dependencies. Although it is mainly designed to take advantage of massive GPU parallelism, Espresso also provides an equivalent CPU implementation for CNNs. Espresso provides special convolutional and dense layers for BCNNs, leveraging bit-packing and bit-wise computations for efficient execution. These techniques provide a speed-up of matrix-multiplication routines, and at the same time, reduce memory usage when storing parameters and activations. We experimentally show that Espresso is significantly faster than existing implementations of optimized binary neural networks ($\approx$ 2 orders of magnitude). Espresso is released under the Apache 2.0 license and is available at http://github.com/fpeder/espresso.



### Multi-Stage Variational Auto-Encoders for Coarse-to-Fine Image Generation
- **Arxiv ID**: http://arxiv.org/abs/1705.07202v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1705.07202v1)
- **Published**: 2017-05-19 21:51:30+00:00
- **Updated**: 2017-05-19 21:51:30+00:00
- **Authors**: Lei Cai, Hongyang Gao, Shuiwang Ji
- **Comment**: None
- **Journal**: None
- **Summary**: Variational auto-encoder (VAE) is a powerful unsupervised learning framework for image generation. One drawback of VAE is that it generates blurry images due to its Gaussianity assumption and thus L2 loss. To allow the generation of high quality images by VAE, we increase the capacity of decoder network by employing residual blocks and skip connections, which also enable efficient optimization. To overcome the limitation of L2 loss, we propose to generate images in a multi-stage manner from coarse to fine. In the simplest case, the proposed multi-stage VAE divides the decoder into two components in which the second component generates refined images based on the course images generated by the first component. Since the second component is independent of the VAE model, it can employ other loss functions beyond the L2 loss and different model architectures. The proposed framework can be easily generalized to contain more than two components. Experiment results on the MNIST and CelebA datasets demonstrate that the proposed multi-stage VAE can generate sharper images as compared to those from the original VAE.



### Multiple-Human Parsing in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1705.07206v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07206v2)
- **Published**: 2017-05-19 21:59:09+00:00
- **Updated**: 2018-03-15 03:09:48+00:00
- **Authors**: Jianshu Li, Jian Zhao, Yunchao Wei, Congyan Lang, Yidong Li, Terence Sim, Shuicheng Yan, Jiashi Feng
- **Comment**: The first two authors are with equal contribution
- **Journal**: None
- **Summary**: Human parsing is attracting increasing research attention. In this work, we aim to push the frontier of human parsing by introducing the problem of multi-human parsing in the wild. Existing works on human parsing mainly tackle single-person scenarios, which deviates from real-world applications where multiple persons are present simultaneously with interaction and occlusion. To address the multi-human parsing problem, we introduce a new multi-human parsing (MHP) dataset and a novel multi-human parsing model named MH-Parser. The MHP dataset contains multiple persons captured in real-world scenes with pixel-level fine-grained semantic annotations in an instance-aware setting. The MH-Parser generates global parsing maps and person instance masks simultaneously in a bottom-up fashion with the help of a new Graph-GAN model. We envision that the MHP dataset will serve as a valuable data resource to develop new multi-human parsing models, and the MH-Parser offers a strong baseline to drive future research for multi-human parsing in the wild.



### PixColor: Pixel Recursive Colorization
- **Arxiv ID**: http://arxiv.org/abs/1705.07208v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1705.07208v2)
- **Published**: 2017-05-19 22:10:51+00:00
- **Updated**: 2017-06-05 18:38:01+00:00
- **Authors**: Sergio Guadarrama, Ryan Dahl, David Bieber, Mohammad Norouzi, Jonathon Shlens, Kevin Murphy
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel approach to automatically produce multiple colorized versions of a grayscale image. Our method results from the observation that the task of automated colorization is relatively easy given a low-resolution version of the color image. We first train a conditional PixelCNN to generate a low resolution color for a given grayscale image. Then, given the generated low-resolution color image and the original grayscale image as inputs, we train a second CNN to generate a high-resolution colorization of an image. We demonstrate that our approach produces more diverse and plausible colorizations than existing methods, as judged by human raters in a "Visual Turing Test".



### On Convergence and Stability of GANs
- **Arxiv ID**: http://arxiv.org/abs/1705.07215v5
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.GT, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1705.07215v5)
- **Published**: 2017-05-19 22:41:56+00:00
- **Updated**: 2017-12-10 15:24:13+00:00
- **Authors**: Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira
- **Comment**: Analysis of convergence and mode collapse by studying GAN training
  process as regret minimization. Some new results
- **Journal**: None
- **Summary**: We propose studying GAN training dynamics as regret minimization, which is in contrast to the popular view that there is consistent minimization of a divergence between real and generated distributions. We analyze the convergence of GAN training from this new point of view to understand why mode collapse happens. We hypothesize the existence of undesirable local equilibria in this non-convex game to be responsible for mode collapse. We observe that these local equilibria often exhibit sharp gradients of the discriminator function around some real data points. We demonstrate that these degenerate local equilibria can be avoided with a gradient penalty scheme called DRAGAN. We show that DRAGAN enables faster training, achieves improved stability with fewer mode collapses, and leads to generator networks with better modeling performance across a variety of architectures and objective functions.



### Quadruplet Network with One-Shot Learning for Fast Visual Object Tracking
- **Arxiv ID**: http://arxiv.org/abs/1705.07222v3
- **DOI**: 10.1109/TIP.2019.2898567
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07222v3)
- **Published**: 2017-05-19 23:37:54+00:00
- **Updated**: 2019-07-14 11:26:12+00:00
- **Authors**: Xingping Dong, Jianbing Shen, Dongming Wu, Kan Guo, Xiaogang Jin, Fatih Porikli
- **Comment**: None
- **Journal**: IEEE Transactions on Image Processing ( Volume: 28 , Issue: 7 ,
  July 2019 )
- **Summary**: In the same vein of discriminative one-shot learning, Siamese networks allow recognizing an object from a single exemplar with the same class label. However, they do not take advantage of the underlying structure of the data and the relationship among the multitude of samples as they only rely on pairs of instances for training. In this paper, we propose a new quadruplet deep network to examine the potential connections among the training instances, aiming to achieve a more powerful representation. We design four shared networks that receive multi-tuple of instances as inputs and are connected by a novel loss function consisting of pair-loss and triplet-loss. According to the similarity metric, we select the most similar and the most dissimilar instances as the positive and negative inputs of triplet loss from each multi-tuple. We show that this scheme improves the training performance. Furthermore, we introduce a new weight layer to automatically select suitable combination weights, which will avoid the conflict between triplet and pair loss leading to worse performance. We evaluate our quadruplet framework by model-free tracking-by-detection of objects from a single initial exemplar in several Visual Object Tracking benchmarks. Our extensive experimental analysis demonstrates that our tracker achieves superior performance with a real-time processing speed of 78 frames-per-second (fps).



