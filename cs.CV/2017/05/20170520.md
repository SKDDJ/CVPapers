# Arxiv Papers in cs.CV on 2017-05-20
### Recurrent Scene Parsing with Perspective Understanding in the Loop
- **Arxiv ID**: http://arxiv.org/abs/1705.07238v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07238v2)
- **Published**: 2017-05-20 00:49:01+00:00
- **Updated**: 2017-12-06 00:05:17+00:00
- **Authors**: Shu Kong, Charless Fowlkes
- **Comment**: None
- **Journal**: None
- **Summary**: Objects may appear at arbitrary scales in perspective images of a scene, posing a challenge for recognition systems that process images at a fixed resolution. We propose a depth-aware gating module that adaptively selects the pooling field size in a convolutional network architecture according to the object scale (inversely proportional to the depth) so that small details are preserved for distant objects while larger receptive fields are used for those nearby. The depth gating signal is provided by stereo disparity or estimated directly from monocular input. We integrate this depth-aware gating into a recurrent convolutional neural network to perform semantic segmentation. Our recurrent module iteratively refines the segmentation results, leveraging the depth and semantic predictions from the previous iterations.   Through extensive experiments on four popular large-scale RGB-D datasets, we demonstrate this approach achieves competitive semantic segmentation performance with a model which is substantially more compact. We carry out extensive analysis of this architecture including variants that operate on monocular RGB but use depth as side-information during training, unsupervised gating as a generic attentional mechanism, and multi-resolution gating. We find that gated pooling for joint semantic segmentation and depth yields state-of-the-art results for quantitative monocular depth estimation.



### End-to-end Planning of Fixed Millimeter-Wave Networks
- **Arxiv ID**: http://arxiv.org/abs/1705.07249v1
- **DOI**: None
- **Categories**: **cs.NI**, cs.CV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1705.07249v1)
- **Published**: 2017-05-20 02:53:45+00:00
- **Updated**: 2017-05-20 02:53:45+00:00
- **Authors**: Tim Danford, Onur Filiz, Jing Huang, Brian Karrer, Manohar Paluri, Guan Pang, Vish Ponnampalam, Nicolas Stier-Moses, Birce Tezel
- **Comment**: None
- **Journal**: None
- **Summary**: This article discusses a framework to support the design and end-to-end planning of fixed millimeter-wave networks. Compared to traditional techniques, the framework allows an organization to quickly plan a deployment in a cost-effective way. We start by using LiDAR data---basically, a 3D point cloud captured from a city---to estimate potential sites to deploy antennas and whether there is line-of-sight between them. With that data on hand, we use combinatorial optimization techniques to determine the optimal set of locations and how they should communicate with each other, to satisfy engineering (e.g., latency, polarity), design (e.g., reliability) and financial (e.g., total cost of operation) constraints. The primary goal is to connect as many people as possible to the network. Our methodology can be used for strategic planning when an organization is in the process of deciding whether to adopt a millimeter-wave technology or choosing between locations, or for operational planning when conducting a detailed design of the actual network to be deployed in a selected location.



### Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods
- **Arxiv ID**: http://arxiv.org/abs/1705.07263v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1705.07263v2)
- **Published**: 2017-05-20 05:59:23+00:00
- **Updated**: 2017-11-01 04:07:05+00:00
- **Authors**: Nicholas Carlini, David Wagner
- **Comment**: None
- **Journal**: None
- **Summary**: Neural networks are known to be vulnerable to adversarial examples: inputs that are close to natural inputs but classified incorrectly. In order to better understand the space of adversarial examples, we survey ten recent proposals that are designed for detection and compare their efficacy. We show that all can be defeated by constructing new loss functions. We conclude that adversarial examples are significantly harder to detect than previously appreciated, and the properties believed to be intrinsic to adversarial examples are in fact not. Finally, we propose several simple guidelines for evaluating future proposed defenses.



### Non-Linear Phase-Shifting of Haar Wavelets for Run-Time All-Frequency Lighting
- **Arxiv ID**: http://arxiv.org/abs/1705.07272v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07272v1)
- **Published**: 2017-05-20 07:42:39+00:00
- **Updated**: 2017-05-20 07:42:39+00:00
- **Authors**: Mais Alnasser, Hassan Foroosh
- **Comment**: None
- **Journal**: None
- **Summary**: This paper focuses on real-time all-frequency image-based rendering using an innovative solution for run-time computation of light transport. The approach is based on new results derived for non-linear phase shifting in the Haar wavelet domain. Although image-based methods for real-time rendering of dynamic glossy objects have been proposed, they do not truly scale to all possible frequencies and high sampling rates without trading storage, glossiness, or computational time, while varying both lighting and viewpoint. This is due to the fact that current approaches are limited to precomputed radiance transfer (PRT), which is prohibitively expensive in terms of memory requirements and real-time rendering when both varying light and viewpoint changes are required together with high sampling rates for high frequency lighting of glossy material. On the other hand, current methods cannot handle object rotation, which is one of the paramount issues for all PRT methods using wavelets. This latter problem arises because the precomputed data are defined in a global coordinate system and encoded in the wavelet domain, while the object is rotated in a local coordinate system. At the root of all the above problems is the lack of efficient run-time solution to the nontrivial problem of rotating wavelets (a non-linear phase-shift), which we solve in this paper.



### Gaze Distribution Analysis and Saliency Prediction Across Age Groups
- **Arxiv ID**: http://arxiv.org/abs/1705.07284v2
- **DOI**: 10.1371/journal.pone.0193149
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07284v2)
- **Published**: 2017-05-20 09:46:49+00:00
- **Updated**: 2017-05-31 06:33:25+00:00
- **Authors**: Onkar Krishna, Kiyoharu Aizawa, Andrea Helo, Rama Pia
- **Comment**: None
- **Journal**: PLOS ONE, 2018
- **Summary**: Knowledge of the human visual system helps to develop better computational models of visual attention. State-of-the-art models have been developed to mimic the visual attention system of young adults that, however, largely ignore the variations that occur with age. In this paper, we investigated how visual scene processing changes with age and we propose an age-adapted framework that helps to develop a computational model that can predict saliency across different age groups. Our analysis uncovers how the explorativeness of an observer varies with age, how well saliency maps of an age group agree with fixation points of observers from the same or different age groups, and how age influences the center bias. We analyzed the eye movement behavior of 82 observers belonging to four age groups while they explored visual scenes. Explorativeness was quantified in terms of the entropy of a saliency map, and area under the curve (AUC) metrics was used to quantify the agreement analysis and the center bias. These results were used to develop age adapted saliency models. Our results suggest that the proposed age-adapted saliency model outperforms existing saliency models in predicting the regions of interest across age groups.



### Forecasting Hands and Objects in Future Frames
- **Arxiv ID**: http://arxiv.org/abs/1705.07328v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07328v3)
- **Published**: 2017-05-20 16:34:55+00:00
- **Updated**: 2018-08-23 04:17:07+00:00
- **Authors**: Chenyou Fan, Jangwon Lee, Michael S. Ryoo
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents an approach to forecast future presence and location of human hands and objects. Given an image frame, the goal is to predict what objects will appear in the future frame (e.g., 5 seconds later) and where they will be located at, even when they are not visible in the current frame. The key idea is that (1) an intermediate representation of a convolutional object recognition model abstracts scene information in its frame and that (2) we can predict (i.e., regress) such representations corresponding to the future frames based on that of the current frame. We design a new two-stream convolutional neural network (CNN) architecture for videos by extending the state-of-the-art convolutional object detection network, and present a new fully convolutional regression network for predicting future scene representations. Our experiments confirm that combining the regressed future representation with our detection network allows reliable estimation of future hands and objects in videos. We obtain much higher accuracy compared to the state-of-the-art future object presence forecast method on a public dataset.



### Critical Contours: An Invariant Linking Image Flow with Salient Surface Organization
- **Arxiv ID**: http://arxiv.org/abs/1705.07329v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07329v2)
- **Published**: 2017-05-20 16:54:41+00:00
- **Updated**: 2018-07-26 21:17:47+00:00
- **Authors**: Benjamin S. Kunsberg, Steven W. Zucker
- **Comment**: Version 2: A reorganized version with the same results. Technical
  details are placed in the Appendix
- **Journal**: None
- **Summary**: We exploit a key result from visual psychophysics---that individuals perceive shape qualitatively---to develop the use of a geometrical/topological "invariant'' (the Morse--Smale complex) relating image structure with surface structure. Differences across individuals are minimal near certain configurations such as ridges and boundaries, and it is these configurations that are often represented in line drawings. In particular, we introduce a method for inferring a qualitative three-dimensional shape from shading patterns that link the shape-from-shading inference with shape-from-contour inference. For a given shape, certain shading patches approach "line drawings'' in a well-defined limit. Under this limit, and invariably with respect to rendering choices, these shading patterns provide a qualitative description of the surface. We further show that, under this model, the contours partition the surface into meaningful parts using the Morse--Smale complex. These critical contours are the (perceptually) stable parts of this complex and are invariant over a wide class of rendering models. Intuitively, our main result shows that critical contours partition smooth surfaces into bumps and valleys, in effect providing a scaffold on the image from which a full surface can be interpolated.



### Phase-Shifting Separable Haar Wavelets and Applications
- **Arxiv ID**: http://arxiv.org/abs/1705.07340v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07340v1)
- **Published**: 2017-05-20 17:53:25+00:00
- **Updated**: 2017-05-20 17:53:25+00:00
- **Authors**: Mais Alnasser, Hassan Foroosh
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a new approach for tackling the shift-invariance problem in the discrete Haar domain, without trading off any of its desirable properties, such as compression, separability, orthogonality, and symmetry. The paper presents several key theoretical contributions. First, we derive closed form expressions for phase shifting in the Haar domain both in partially decimated and fully decimated transforms. Second, it is shown that the wavelet coefficients of the shifted signal can be computed solely by using the coefficients of the original transformed signal. Third, we derive closed-form expressions for non-integer shifts, which have not been previously reported in the literature. Fourth, we establish the complexity of the proposed phase shifting approach using the derived analytic expressions. As an application example of these results, we apply the new formulae to image rotation and interpolation, and evaluate its performance against standard methods.



### Structural Compression of Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1705.07356v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.07356v4)
- **Published**: 2017-05-20 20:12:07+00:00
- **Updated**: 2020-03-25 10:49:13+00:00
- **Authors**: Reza Abbasi-Asl, Bin Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Deep convolutional neural networks (CNNs) have been successful in many tasks in machine vision, however, millions of weights in the form of thousands of convolutional filters in CNNs makes them difficult for human intepretation or understanding in science. In this article, we introduce CAR, a greedy structural compression scheme to obtain smaller and more interpretable CNNs, while achieving close to original accuracy. The compression is based on pruning filters with the least contribution to the classification accuracy. We demonstrate the interpretability of CAR-compressed CNNs by showing that our algorithm prunes filters with visually redundant functionalities such as color filters. These compressed networks are easier to interpret because they retain the filter diversity of uncompressed networks with order of magnitude less filters. Finally, a variant of CAR is introduced to quantify the importance of each image category to each CNN filter. Specifically, the most and the least important class labels are shown to be meaningful interpretations of each filter.



### Isomorphism between Differential and Moment Invariants under Affine Transform
- **Arxiv ID**: http://arxiv.org/abs/1705.08264v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1705.08264v2)
- **Published**: 2017-05-20 20:34:44+00:00
- **Updated**: 2017-05-24 19:07:19+00:00
- **Authors**: Erbo Li, Hua Li
- **Comment**: None
- **Journal**: None
- **Summary**: The invariant is one of central topics in science, technology and engineering. The differential invariant is essential in understanding or describing some important phenomena or procedures in mathematics, physics, chemistry, biology or computer science etc. The derivation of differential invariants is usually difficult or complicated. This paper reports a discovery that under the affine transform, differential invariants have similar structures with moment invariants up to a scalar function of transform parameters. If moment invariants are known, relative differential invariants can be obtained by the substitution of moments by derivatives with the same order. Whereas moment invariants can be calculated by multiple integrals, this method provides a simple way to derive differential invariants without the need to resolve any equation system. Since the definition of moments on different manifolds or in different dimension of spaces is well established, differential invariants on or in them will also be well defined. Considering that moments have a strong background in mathematics and physics, this technique offers a new view angle to the inner structure of invariants. Projective differential invariants can also be found in this way with a screening process.



### Stabilizing Adversarial Nets With Prediction Methods
- **Arxiv ID**: http://arxiv.org/abs/1705.07364v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1705.07364v3)
- **Published**: 2017-05-20 22:27:19+00:00
- **Updated**: 2018-02-08 21:57:54+00:00
- **Authors**: Abhay Yadav, Sohil Shah, Zheng Xu, David Jacobs, Tom Goldstein
- **Comment**: Accepted at ICLR 2018
- **Journal**: None
- **Summary**: Adversarial neural networks solve many important problems in data science, but are notoriously difficult to train. These difficulties come from the fact that optimal weights for adversarial nets correspond to saddle points, and not minimizers, of the loss function. The alternating stochastic gradient methods typically used for such problems do not reliably converge to saddle points, and when convergence does happen it is often highly sensitive to learning rates. We propose a simple modification of stochastic gradient descent that stabilizes adversarial networks. We show, both in theory and practice, that the proposed method reliably converges to saddle points, and is stable with a wider range of training parameters than a non-prediction method. This makes adversarial networks less likely to "collapse," and enables faster training with larger learning rates.



