# Arxiv Papers in cs.CV on 2017-01-27
### Quasi-homography warps in image stitching
- **Arxiv ID**: http://arxiv.org/abs/1701.08006v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08006v2)
- **Published**: 2017-01-27 10:45:45+00:00
- **Updated**: 2018-03-18 13:38:06+00:00
- **Authors**: Nan Li, Yifang Xu, Chao Wang
- **Comment**: 10 pages, 9 figures
- **Journal**: None
- **Summary**: The naturalness of warps is gaining extensive attentions in image stitching. Recent warps such as SPHP and AANAP, use global similarity warps to mitigate projective distortion (which enlarges regions), however, they necessarily bring in perspective distortion (which generates inconsistencies). In this paper, we propose a novel quasi-homography warp, which effectively balances the perspective distortion against the projective distortion in the non-overlapping region to create a more natural-looking panorama. Our approach formulates the warp as the solution of a bivariate system, where perspective distortion and projective distortion are characterized as slope preservation and scale linearization respectively. Because our proposed warp only relies on a global homography, thus it is totally parameter-free. A comprehensive experiment shows that a quasi-homography warp outperforms some state-of-the-art warps in urban scenes, including homography, AutoStitch and SPHP. A user study demonstrates that it wins most users' favor, comparing to homography and SPHP.



### UmUTracker: A versatile MATLAB program for automated particle tracking of 2D light microscopy or 3D digital holography data
- **Arxiv ID**: http://arxiv.org/abs/1701.08025v2
- **DOI**: 10.1016/j.cpc.2017.05.029
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08025v2)
- **Published**: 2017-01-27 12:20:45+00:00
- **Updated**: 2017-04-21 08:53:23+00:00
- **Authors**: Hanqing Zhang, Tim Stangner, Krister Wiklund, Alvaro Rodriguez, Magnus Andersson
- **Comment**: Manuscript including supplementary materials
- **Journal**: None
- **Summary**: We present a versatile and fast MATLAB program (UmUTracker) that automatically detects and tracks particles by analyzing video sequences acquired by either light microscopy or digital in-line holographic microscopy. Our program detects the 2D lateral positions of particles with an algorithm based on the isosceles triangle transform, and reconstructs their 3D axial positions by a fast implementation of the Rayleigh-Sommerfeld model using a radial intensity profile. To validate the accuracy and performance of our program, we first track the 2D position of polystyrene particles using bright field and digital holographic microscopy. Second, we determine the 3D particle position by analyzing synthetic and experimentally acquired holograms. Finally, to highlight the full program features, we profile the microfluidic flow in a 100 micrometer high flow chamber. This result agrees with computational fluid dynamic simulations. On a regular desktop computer UmUTracker can detect, analyze, and track multiple particles at 5 frames per second for a template size of 201 x 201 in a 1024 x 1024 image. To enhance usability and to make it easy to implement new functions we used object-oriented programming. UmUTracker is suitable for studies related to: particle dynamics, cell localization, colloids and microfluidic flow measurement.



### Document Decomposition of Bangla Printed Text
- **Arxiv ID**: http://arxiv.org/abs/1701.08706v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1701.08706v1)
- **Published**: 2017-01-27 12:54:52+00:00
- **Updated**: 2017-01-27 12:54:52+00:00
- **Authors**: Md. Fahad Hasan, Tasmin Afroz, Sabir Ismail, Md. Saiful Islam
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: Today all kind of information is getting digitized and along with all this digitization, the huge archive of various kinds of documents is being digitized too. We know that, Optical Character Recognition is the method through which, newspapers and other paper documents convert into digital resources. But, it is a fact that this method works on texts only. As a result, if we try to process any document which contains non-textual zones, then we will get garbage texts as output. That is why; in order to digitize documents properly they should be prepossessed carefully. And while preprocessing, segmenting document in different regions according to the category properly is most important. But, the Optical Character Recognition processes available for Bangla language have no such algorithm that can categorize a newspaper/book page fully. So we worked to decompose a document into its several parts like headlines, sub headlines, columns, images etc. And if the input is skewed and rotated, then the input was also deskewed and de-rotated. To decompose any Bangla document we found out the edges of the input image. Then we find out the horizontal and vertical area of every pixel where it lies in. Later on the input image was cut according to these areas. Then we pick each and every sub image and found out their height-width ratio, line height. Then according to these values the sub images were categorized. To deskew the image we found out the skew angle and de skewed the image according to this angle. To de-rotate the image we used the line height, matra line, pixel ratio of matra line.



### Double-sided probing by map of Asplund's distances using Logarithmic Image Processing in the framework of Mathematical Morphology
- **Arxiv ID**: http://arxiv.org/abs/1701.08092v5
- **DOI**: 10.1007/978-3-319-57240-6_33
- **Categories**: **cs.CV**, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1701.08092v5)
- **Published**: 2017-01-27 15:55:51+00:00
- **Updated**: 2018-01-25 07:57:28+00:00
- **Authors**: Guillaume Noyel, Michel Jourlin
- **Comment**: The final publication is available at link.springer.com
- **Journal**: 13th International Symposium on Mathematical Morphology, ISMM
  2017, May 2017, Fontainebleau, France. Springer International Publishing,
  pp.408-420, 2017, Mathematical Morphology and Its Applications to Signal and
  Image Processing: 13th International Symposium, ISMM 2017, Fontainebleau,
  France, May 15--17, 2017, Proceedings. http://cmm.ensmp.fr/ismm2017/
- **Summary**: We establish the link between Mathematical Morphology and the map of Asplund's distances between a probe and a grey scale function, using the Logarithmic Image Processing scalar multiplication. We demonstrate that the map is the logarithm of the ratio between a dilation and an erosion of the function by a structuring function: the probe. The dilations and erosions are mappings from the lattice of the images into the lattice of the positive functions. Using a flat structuring element, the expression of the map of Asplund's distances can be simplified with a dilation and an erosion of the image; these mappings stays in the lattice of the images. We illustrate our approach by an example of pattern matching with a non-flat structuring function.



### Deconvolution and Restoration of Optical Endomicroscopy Images
- **Arxiv ID**: http://arxiv.org/abs/1701.08107v3
- **DOI**: 10.1109/TCI.2018.2811939
- **Categories**: **cs.CV**, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1701.08107v3)
- **Published**: 2017-01-27 16:37:03+00:00
- **Updated**: 2018-08-28 13:44:54+00:00
- **Authors**: Ahmed Karam Eldaly, Yoann Altmann, Antonios Perperidis, Nikola Krstajic, Tushar Choudhary, Kevin Dhaliwal, Stephen McLaughlin
- **Comment**: None
- **Journal**: None
- **Summary**: Optical endomicroscopy (OEM) is an emerging technology platform with preclinical and clinical imaging applications. Pulmonary OEM via fibre bundles has the potential to provide in vivo, in situ molecular signatures of disease such as infection and inflammation. However, enhancing the quality of data acquired by this technique for better visualization and subsequent analysis remains a challenging problem. Cross coupling between fiber cores and sparse sampling by imaging fiber bundles are the main reasons for image degradation, and poor detection performance (i.e., inflammation, bacteria, etc.). In this work, we address the problem of deconvolution and restoration of OEM data. We propose a hierarchical Bayesian model to solve this problem and compare three estimation algorithms to exploit the resulting joint posterior distribution. The first method is based on Markov chain Monte Carlo (MCMC) methods, however, it exhibits a relatively long computational time. The second and third algorithms deal with this issue and are based on a variational Bayes (VB) approach and an alternating direction method of multipliers (ADMM) algorithm respectively. Results on both synthetic and real datasets illustrate the effectiveness of the proposed methods for restoration of OEM images.



### Camera-trap images segmentation using multi-layer robust principal component analysis
- **Arxiv ID**: http://arxiv.org/abs/1701.08180v2
- **DOI**: 10.1007/s00371-017-1463-9
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08180v2)
- **Published**: 2017-01-27 19:41:29+00:00
- **Updated**: 2017-12-30 22:15:32+00:00
- **Authors**: Jhony-Heriberto Giraldo-Zuluaga, Alexander Gomez, Augusto Salazar, Ang√©lica Diaz-Pulido
- **Comment**: This is a pre-print of an article published in The Visual Computer.
  The final authenticated version is available online at:
  https://doi.org/10.1007/s00371-017-1463-9
- **Journal**: The Visual Computer, 1-13 (2017)
- **Summary**: The segmentation of animals from camera-trap images is a difficult task. To illustrate, there are various challenges due to environmental conditions and hardware limitation in these images. We proposed a multi-layer robust principal component analysis (multi-layer RPCA) approach for background subtraction. Our method computes sparse and low-rank images from a weighted sum of descriptors, using color and texture features as case of study for camera-trap images segmentation. The segmentation algorithm is composed of histogram equalization or Gaussian filtering as pre-processing, and morphological filters with active contour as post-processing. The parameters of our multi-layer RPCA were optimized with an exhaustive search. The database consists of camera-trap images from the Colombian forest taken by the Instituto de Investigaci\'on de Recursos Biol\'ogicos Alexander von Humboldt. We analyzed the performance of our method in inherent and therefore challenging situations of camera-trap images. Furthermore, we compared our method with some state-of-the-art algorithms of background subtraction, where our multi-layer RPCA outperformed these other methods. Our multi-layer RPCA reached 76.17 and 69.97% of average fine-grained F-measure for color and infrared sequences, respectively. To our best knowledge, this paper is the first work proposing multi-layer RPCA and using it for camera-trap images segmentation.



### Sampling Without Time: Recovering Echoes of Light via Temporal Phase Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1701.08222v1
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1701.08222v1)
- **Published**: 2017-01-27 23:52:08+00:00
- **Updated**: 2017-01-27 23:52:08+00:00
- **Authors**: Ayush Bhandari, Aurelien Bourquard, Ramesh Raskar
- **Comment**: 12 pages, 4 figures, to appear at the 42nd IEEE International
  Conference on Acoustics, Speech, and Signal Processing (ICASSP)
- **Journal**: None
- **Summary**: This paper considers the problem of sampling and reconstruction of a continuous-time sparse signal without assuming the knowledge of the sampling instants or the sampling rate. This topic has its roots in the problem of recovering multiple echoes of light from its low-pass filtered and auto-correlated, time-domain measurements. Our work is closely related to the topic of sparse phase retrieval and in this context, we discuss the advantage of phase-free measurements. While this problem is ill-posed, cues based on physical constraints allow for its appropriate regularization. We validate our theory with experiments based on customized, optical time-of-flight imaging sensors. What singles out our approach is that our sensing method allows for temporal phase retrieval as opposed to the usual case of spatial phase retrieval. Preliminary experiments and results demonstrate a compelling capability of our phase-retrieval based imaging device.



