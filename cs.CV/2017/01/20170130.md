# Arxiv Papers in cs.CV on 2017-01-30
### Scalable Nearest Neighbor Search based on kNN Graph
- **Arxiv ID**: http://arxiv.org/abs/1701.08475v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.DB
- **Links**: [PDF](http://arxiv.org/pdf/1701.08475v2)
- **Published**: 2017-01-30 03:51:28+00:00
- **Updated**: 2017-02-03 09:37:53+00:00
- **Authors**: Wan-Lei Zhao, Jie Yang, Cheng-Hao Deng
- **Comment**: 7 pages, 3 figures
- **Journal**: None
- **Summary**: Nearest neighbor search is known as a challenging issue that has been studied for several decades. Recently, this issue becomes more and more imminent in viewing that the big data problem arises from various fields. In this paper, a scalable solution based on hill-climbing strategy with the support of k-nearest neighbor graph (kNN) is presented. Two major issues have been considered in the paper. Firstly, an efficient kNN graph construction method based on two means tree is presented. For the nearest neighbor search, an enhanced hill-climbing procedure is proposed, which sees considerable performance boost over original procedure. Furthermore, with the support of inverted indexing derived from residue vector quantization, our method achieves close to 100% recall with high speed efficiency in two state-of-the-art evaluation benchmarks. In addition, a comparative study on both the compressional and traditional nearest neighbor search methods is presented. We show that our method achieves the best trade-off between search quality, efficiency and memory complexity.



### CNN as Guided Multi-layer RECOS Transform
- **Arxiv ID**: http://arxiv.org/abs/1701.08481v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08481v3)
- **Published**: 2017-01-30 04:39:36+00:00
- **Updated**: 2017-02-19 07:42:24+00:00
- **Authors**: C. -C. Jay Kuo
- **Comment**: None
- **Journal**: None
- **Summary**: There is a resurging interest in developing a neural-network-based solution to the supervised machine learning problem. The convolutional neural network (CNN) will be studied in this note. To begin with, we introduce a RECOS transform as a basic building block of CNNs. The "RECOS" is an acronym for "REctified-COrrelations on a Sphere". It consists of two main concepts: 1) data clustering on a sphere and 2) rectification. Afterwards, we interpret a CNN as a network that implements the guided multi-layer RECOS transform with three highlights. First, we compare the traditional single-layer and modern multi-layer signal analysis approaches, point out key ingredients that enable the multi-layer approach, and provide a full explanation to the operating principle of CNNs. Second, we discuss how guidance is provided by labels through backpropagation (BP) in the training. Third, we show that a trained network can be greatly simplified in the testing stage demanding only one-bit representation for both filter weights and inputs.



### A Survey of Structure from Motion
- **Arxiv ID**: http://arxiv.org/abs/1701.08493v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08493v2)
- **Published**: 2017-01-30 06:47:44+00:00
- **Updated**: 2017-05-09 01:19:41+00:00
- **Authors**: Onur Ozyesil, Vladislav Voroninski, Ronen Basri, Amit Singer
- **Comment**: 40 pages, 16 figures; Updated title and abstract
- **Journal**: None
- **Summary**: The structure from motion (SfM) problem in computer vision is the problem of recovering the three-dimensional ($3$D) structure of a stationary scene from a set of projective measurements, represented as a collection of two-dimensional ($2$D) images, via estimation of motion of the cameras corresponding to these images. In essence, SfM involves the three main stages of (1) extraction of features in images (e.g., points of interest, lines, etc.) and matching these features between images, (2) camera motion estimation (e.g., using relative pairwise camera positions estimated from the extracted features), and (3) recovery of the $3$D structure using the estimated motion and features (e.g., by minimizing the so-called reprojection error). This survey mainly focuses on relatively recent developments in the literature pertaining to stages (2) and (3). More specifically, after touching upon the early factorization-based techniques for motion and structure estimation, we provide a detailed account of some of the recent camera location estimation methods in the literature, followed by discussion of notable techniques for $3$D structure recovery. We also cover the basics of the simultaneous localization and mapping (SLAM) problem, which can be viewed as a specific case of the SfM problem. Further, our survey includes a review of the fundamentals of feature extraction and matching (i.e., stage (1) above), various recent methods for handling ambiguities in $3$D scenes, SfM techniques involving relatively uncommon camera models and image features, and popular sources of data and SfM software.



### Self-Adaptation of Activity Recognition Systems to New Sensors
- **Arxiv ID**: http://arxiv.org/abs/1701.08528v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML, 68T05, K.3.2
- **Links**: [PDF](http://arxiv.org/pdf/1701.08528v1)
- **Published**: 2017-01-30 10:01:38+00:00
- **Updated**: 2017-01-30 10:01:38+00:00
- **Authors**: David Bannach, Martin Jänicke, Vitor F. Rey, Sven Tomforde, Bernhard Sick, Paul Lukowicz
- **Comment**: 26 pages, very descriptive figures, comprehensive evaluation on
  real-life datasets
- **Journal**: None
- **Summary**: Traditional activity recognition systems work on the basis of training, taking a fixed set of sensors into account. In this article, we focus on the question how pattern recognition can leverage new information sources without any, or with minimal user input. Thus, we present an approach for opportunistic activity recognition, where ubiquitous sensors lead to dynamically changing input spaces. Our method is a variation of well-established principles of machine learning, relying on unsupervised clustering to discover structure in data and inferring cluster labels from a small number of labeled dates in a semi-supervised manner. Elaborating the challenges, evaluations of over 3000 sensor combinations from three multi-user experiments are presented in detail and show the potential benefit of our approach.



### Peduncle Detection of Sweet Pepper for Autonomous Crop Harvesting - Combined Colour and 3D Information
- **Arxiv ID**: http://arxiv.org/abs/1701.08608v1
- **DOI**: 10.1109/LRA.2017.2651952
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1701.08608v1)
- **Published**: 2017-01-30 14:17:59+00:00
- **Updated**: 2017-01-30 14:17:59+00:00
- **Authors**: Inkyu Sa, Chris Lehnert, Andrew English, Chris McCool, Feras Dayoub, Ben Upcroft, Tristan Perez
- **Comment**: 8 pages, 14 figures, Robotics and Automation Letters
- **Journal**: None
- **Summary**: This paper presents a 3D visual detection method for the challenging task of detecting peduncles of sweet peppers (Capsicum annuum) in the field. Cutting the peduncle cleanly is one of the most difficult stages of the harvesting process, where the peduncle is the part of the crop that attaches it to the main stem of the plant. Accurate peduncle detection in 3D space is therefore a vital step in reliable autonomous harvesting of sweet peppers, as this can lead to precise cutting while avoiding damage to the surrounding plant. This paper makes use of both colour and geometry information acquired from an RGB-D sensor and utilises a supervised-learning approach for the peduncle detection task. The performance of the proposed method is demonstrated and evaluated using qualitative and quantitative results (the Area-Under-the-Curve (AUC) of the detection precision-recall curve). We are able to achieve an AUC of 0.71 for peduncle detection on field-grown sweet peppers. We release a set of manually annotated 3D sweet pepper and peduncle images to assist the research community in performing further research on this topic.



### Fully Convolutional Architectures for Multi-Class Segmentation in Chest Radiographs
- **Arxiv ID**: http://arxiv.org/abs/1701.08816v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1701.08816v4)
- **Published**: 2017-01-30 20:21:57+00:00
- **Updated**: 2018-02-13 16:12:40+00:00
- **Authors**: Alexey A. Novikov, Dimitrios Lenis, David Major, Jiri Hladůvka, Maria Wimmer, Katja Bühler
- **Comment**: Final pre-print version accepted for publication in TMI Added new
  content: * additional evaluations * additional figures * improving the old
  content
- **Journal**: None
- **Summary**: The success of deep convolutional neural networks on image classification and recognition tasks has led to new applications in very diversified contexts, including the field of medical imaging. In this paper we investigate and propose neural network architectures for automated multi-class segmentation of anatomical organs in chest radiographs, namely for lungs, clavicles and heart. We address several open challenges including model overfitting, reducing number of parameters and handling of severely imbalanced data in CXR by fusing recent concepts in convolutional networks and adapting them to the segmentation problem task in CXR. We demonstrate that our architecture combining delayed subsampling, exponential linear units, highly restrictive regularization and a large number of high resolution low level abstract features outperforms state-of-the-art methods on all considered organs, as well as the human observer on lungs and heart. The models use a multi-class configuration with three target classes and are trained and tested on the publicly available JSRT database, consisting of 247 X-ray images the ground-truth masks for which are available in the SCR database. Our best performing model, trained with the loss function based on the Dice coefficient, reached mean Jaccard overlap scores of 95.0\% for lungs, 86.8\% for clavicles and 88.2\% for heart. This architecture outperformed the human observer results for lungs and heart.



### Language Independent Single Document Image Super-Resolution using CNN for improved recognition
- **Arxiv ID**: http://arxiv.org/abs/1701.08835v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08835v1)
- **Published**: 2017-01-30 21:37:00+00:00
- **Updated**: 2017-01-30 21:37:00+00:00
- **Authors**: Ram Krishna Pandey, A G Ramakrishnan
- **Comment**: None
- **Journal**: None
- **Summary**: Recognition of document images have important applications in restoring old and classical texts. The problem involves quality improvement before passing it to a properly trained OCR to get accurate recognition of the text. The image enhancement and quality improvement constitute important steps as subsequent recognition depends upon the quality of the input image. There are scenarios when high resolution images are not available and our experiments show that the OCR accuracy reduces significantly with decrease in the spatial resolution of document images. Thus the only option is to improve the resolution of such document images. The goal is to construct a high resolution image, given a single low resolution binary image, which constitutes the problem of single image super-resolution. Most of the previous work in super-resolution deal with natural images which have more information-content than the document images. Here, we use Convolution Neural Network to learn the mapping between low and the corresponding high resolution images. We experiment with different number of layers, parameter settings and non-linear functions to build a fast end-to-end framework for document image super-resolution. Our proposed model shows a very good PSNR improvement of about 4 dB on 75 dpi Tamil images, resulting in a 3 % improvement of word level accuracy by the OCR. It takes less time than the recent sparse based natural image super-resolution technique, making it useful for real-time document recognition applications.



### Emergence of Selective Invariance in Hierarchical Feed Forward Networks
- **Arxiv ID**: http://arxiv.org/abs/1701.08837v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1701.08837v1)
- **Published**: 2017-01-30 21:44:27+00:00
- **Updated**: 2017-01-30 21:44:27+00:00
- **Authors**: Dipan K. Pal, Vishnu Boddeti, Marios Savvides
- **Comment**: None
- **Journal**: None
- **Summary**: Many theories have emerged which investigate how in- variance is generated in hierarchical networks through sim- ple schemes such as max and mean pooling. The restriction to max/mean pooling in theoretical and empirical studies has diverted attention away from a more general way of generating invariance to nuisance transformations. We con- jecture that hierarchically building selective invariance (i.e. carefully choosing the range of the transformation to be in- variant to at each layer of a hierarchical network) is im- portant for pattern recognition. We utilize a novel pooling layer called adaptive pooling to find linear pooling weights within networks. These networks with the learnt pooling weights have performances on object categorization tasks that are comparable to max/mean pooling networks. In- terestingly, adaptive pooling can converge to mean pooling (when initialized with random pooling weights), find more general linear pooling schemes or even decide not to pool at all. We illustrate the general notion of selective invari- ance through object categorization experiments on large- scale datasets such as SVHN and ILSVRC 2012.



### 3D Shape Retrieval via Irrelevance Filtering and Similarity Ranking (IF/SR)
- **Arxiv ID**: http://arxiv.org/abs/1701.08869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08869v1)
- **Published**: 2017-01-30 23:04:57+00:00
- **Updated**: 2017-01-30 23:04:57+00:00
- **Authors**: Xiaqing Pan, Yueru Chen, C. -C. Jay Kuo
- **Comment**: arXiv admin note: text overlap with arXiv:1603.01942
- **Journal**: None
- **Summary**: A novel solution for the content-based 3D shape retrieval problem using an unsupervised clustering approach, which does not need any label information of 3D shapes, is presented in this work. The proposed shape retrieval system consists of two modules in cascade: the irrelevance filtering (IF) module and the similarity ranking (SR) module. The IF module attempts to cluster gallery shapes that are similar to each other by examining global and local features simultaneously. However, shapes that are close in the local feature space can be distant in the global feature space, and vice versa. To resolve this issue, we propose a joint cost function that strikes a balance between two distances. Irrelevant samples that are close in the local feature space but distant in the global feature space can be removed in this stage. The remaining gallery samples are ranked in the SR module using the local feature. The superior performance of the proposed IF/SR method is demonstrated by extensive experiments conducted on the popular SHREC12 dataset.



