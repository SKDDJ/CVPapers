# Arxiv Papers in cs.CV on 2017-01-22
### Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a Changing World
- **Arxiv ID**: http://arxiv.org/abs/1701.06106v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1701.06106v2)
- **Published**: 2017-01-22 00:35:24+00:00
- **Updated**: 2017-02-19 08:15:55+00:00
- **Authors**: Sahil Garg, Irina Rish, Guillermo Cecchi, Aurelie Lozano
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we focus on online representation learning in non-stationary environments which may require continuous adaptation of model architecture. We propose a novel online dictionary-learning (sparse-coding) framework which incorporates the addition and deletion of hidden units (dictionary elements), and is inspired by the adult neurogenesis phenomenon in the dentate gyrus of the hippocampus, known to be associated with improved cognitive function and adaptation to new environments. In the online learning setting, where new input instances arrive sequentially in batches, the neuronal-birth is implemented by adding new units with random initial weights (random dictionary elements); the number of new units is determined by the current performance (representation error) of the dictionary, higher error causing an increase in the birth rate. Neuronal-death is implemented by imposing l1/l2-regularization (group sparsity) on the dictionary within the block-coordinate descent optimization at each iteration of our online alternating minimization scheme, which iterates between the code and dictionary updates. Finally, hidden unit connectivity adaptation is facilitated by introducing sparsity in dictionary elements. Our empirical evaluation on several real-life datasets (images and language) as well as on synthetic data demonstrates that the proposed approach can considerably outperform the state-of-art fixed-size (nonadaptive) online sparse coding of Mairal et al. (2009) in the presence of nonstationary data. Moreover, we identify certain properties of the data (e.g., sparse inputs with nearly non-overlapping supports) and of the model (e.g., dictionary sparsity) associated with such improvements.



### DeadNet: Identifying Phototoxicity from Label-free Microscopy Images of Cells using Deep ConvNets
- **Arxiv ID**: http://arxiv.org/abs/1701.06109v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1701.06109v1)
- **Published**: 2017-01-22 01:43:05+00:00
- **Updated**: 2017-01-22 01:43:05+00:00
- **Authors**: David Richmond, Anna Payne-Tobin Jost, Talley Lambert, Jennifer Waters, Hunter Elliott
- **Comment**: None
- **Journal**: None
- **Summary**: Exposure to intense illumination light is an unavoidable consequence of fluorescence microscopy, and poses a risk to the health of the sample in every live-cell fluorescence microscopy experiment. Furthermore, the possible side-effects of phototoxicity on the scientific conclusions that are drawn from an imaging experiment are often unaccounted for. Previously, controlling for phototoxicity in imaging experiments required additional labels and experiments, limiting its widespread application. Here we provide a proof-of-principle demonstration that the phototoxic effects of an imaging experiment can be identified directly from a single phase-contrast image using deep convolutional neural networks (ConvNets). This lays the groundwork for an automated tool for assessing cell health in a wide range of imaging experiments. Interpretability of such a method is crucial for its adoption. We take steps towards interpreting the classification mechanism of the trained ConvNet by visualizing salient features of images that contribute to accurate classification.



### Multimodal Fusion via a Series of Transfers for Noise Removal
- **Arxiv ID**: http://arxiv.org/abs/1701.06121v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.06121v1)
- **Published**: 2017-01-22 04:46:34+00:00
- **Updated**: 2017-01-22 04:46:34+00:00
- **Authors**: Chang-Hwan Son, Xiao-Ping Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Near-infrared imaging has been considered as a solution to provide high quality photographs in dim lighting conditions. This imaging system captures two types of multimodal images: one is near-infrared gray image (NGI) and the other is the visible color image (VCI). NGI is noise-free but it is grayscale, whereas the VCI has colors but it contains noise. Moreover, there exist serious edge and brightness discrepancies between NGI and VCI. To deal with this problem, a new transfer-based fusion method is proposed for noise removal. Different from conventional fusion approaches, the proposed method conducts a series of transfers: contrast, detail, and color transfers. First, the proposed contrast and detail transfers aim at solving the serious discrepancy problem, thereby creating a new noise-free and detail-preserving NGI. Second, the proposed color transfer models the unknown colors from the denoised VCI via a linear transform, and then transfers natural-looking colors into the newly generated NGI. Experimental results show that the proposed transfer-based fusion method is highly successful in solving the discrepancy problem, thereby describing edges and textures clearly as well as removing noise completely on the fused images. Most of all, the proposed method is superior to conventional fusion methods and guided filtering, and even the state-of-the-art fusion methods based on scale map and layer decomposition.



### Optimization on Product Submanifolds of Convolution Kernels
- **Arxiv ID**: http://arxiv.org/abs/1701.06123v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1701.06123v2)
- **Published**: 2017-01-22 05:35:39+00:00
- **Updated**: 2017-11-27 09:08:19+00:00
- **Authors**: Mete Ozay, Takayuki Okatani
- **Comment**: 7 pages
- **Journal**: None
- **Summary**: Recent advances in optimization methods used for training convolutional neural networks (CNNs) with kernels, which are normalized according to particular constraints, have shown remarkable success. This work introduces an approach for training CNNs using ensembles of joint spaces of kernels constructed using different constraints. For this purpose, we address a problem of optimization on ensembles of products of submanifolds (PEMs) of convolution kernels. To this end, we first propose three strategies to construct ensembles of PEMs in CNNs. Next, we expound their geometric properties (metric and curvature properties) in CNNs. We make use of our theoretical results by developing a geometry-aware SGD algorithm (G-SGD) for optimization on ensembles of PEMs to train CNNs. Moreover, we analyze convergence properties of G-SGD considering geometric properties of PEMs. In the experimental analyses, we employ G-SGD to train CNNs on Cifar-10, Cifar-100 and Imagenet datasets. The results show that geometric adaptive step size computation methods of G-SGD can improve training loss and convergence properties of CNNs. Moreover, we observe that classification performance of baseline CNNs can be boosted using G-SGD on ensembles of PEMs identified by multiple constraints.



### Perception-based energy functions in seam-cutting
- **Arxiv ID**: http://arxiv.org/abs/1701.06141v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.06141v1)
- **Published**: 2017-01-22 09:25:34+00:00
- **Updated**: 2017-01-22 09:25:34+00:00
- **Authors**: Nan Li, Tianli Liao, Chao Wang
- **Comment**: 5 pages, 6 figures
- **Journal**: None
- **Summary**: Image stitching is challenging in consumer-level photography, due to alignment difficulties in unconstrained shooting environment. Recent studies show that seam-cutting approaches can effectively relieve artifacts generated by local misalignment. Normally, seam-cutting is described in terms of energy minimization, however, few of existing methods consider human perception in their energy functions, which sometimes causes that a seam with minimum energy is not most invisible in the overlapping region. In this paper, we propose a novel perception-based energy function in the seam-cutting framework, which considers the nonlinearity and the nonuniformity of human perception in energy minimization. Our perception-based approach adopts a sigmoid metric to characterize the perception of color discrimination, and a saliency weight to simulate that human eyes incline to pay more attention to salient objects. In addition, our seam-cutting composition can be easily implemented into other stitching pipelines. Experiments show that our method outperforms the seam-cutting method of the normal energy function, and a user study demonstrates that our composed results are more consistent with human perception.



### Large Scale Novel Object Discovery in 3D
- **Arxiv ID**: http://arxiv.org/abs/1701.07046v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.07046v2)
- **Published**: 2017-01-22 12:58:52+00:00
- **Updated**: 2018-02-20 11:39:15+00:00
- **Authors**: Siddharth Srivastava, Gaurav Sharma, Brejesh Lall
- **Comment**: Accepted for publication at IEEE Winter Conference on Applications of
  Computer Vision (WACV 2018)
- **Journal**: None
- **Summary**: We present a method for discovering never-seen-before objects in 3D point clouds obtained from sensors like Microsoft Kinect. We generate supervoxels directly from the point cloud data and use them with a Siamese network, built on a recently proposed 3D convolutional neural network architecture. We use known objects to train a non-linear embedding of supervoxels, by optimizing the criteria that supervoxels which fall on the same object should be closer than those which fall on different objects, in the embedding space. We test on unknown objects, which were not seen during training, and perform clustering in the learned embedding space of supervoxels to effectively perform novel object discovery. We validate the method with extensive experiments, quantitatively showing that it can discover numerous unseen objects while being trained on only a few dense 3D models. We also show very good qualitative results of object discovery in point cloud data when the test objects, either specific instances or even categories, were never seen during training.



### Greedy Structure Learning of Hierarchical Compositional Models
- **Arxiv ID**: http://arxiv.org/abs/1701.06171v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.06171v4)
- **Published**: 2017-01-22 14:56:31+00:00
- **Updated**: 2019-04-14 13:05:08+00:00
- **Authors**: Adam Kortylewski, Aleksander Wieczorek, Mario Wieser, Clemens Blumer, Sonali Parbhoo, Andreas Morel-Forster, Volker Roth, Thomas Vetter
- **Comment**: CVPR 2019
- **Journal**: None
- **Summary**: In this work, we consider the problem of learning a hierarchical generative model of an object from a set of images which show examples of the object in the presence of variable background clutter. Existing approaches to this problem are limited by making strong a-priori assumptions about the object's geometric structure and require segmented training data for learning. In this paper, we propose a novel framework for learning hierarchical compositional models (HCMs) which do not suffer from the mentioned limitations. We present a generalized formulation of HCMs and describe a greedy structure learning framework that consists of two phases: Bottom-up part learning and top-down model composition. Our framework integrates the foreground-background segmentation problem into the structure learning task via a background model. As a result, we can jointly optimize for the number of layers in the hierarchy, the number of parts per layer and a foreground-background segmentation based on class labels only. We show that the learned HCMs are semantically meaningful and achieve competitive results when compared to other generative object models at object classification on a standard transfer learning dataset.



### Image Compression with SVD : A New Quality Metric Based On Energy Ratio
- **Arxiv ID**: http://arxiv.org/abs/1701.06183v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.06183v1)
- **Published**: 2017-01-22 16:23:42+00:00
- **Updated**: 2017-01-22 16:23:42+00:00
- **Authors**: Henri Bruno Razafindradina, Paul Auguste Randriamitantsoa, Nicolas Raft Razafindrakoto
- **Comment**: 6 pages, International Journal of Computer Science and Network,
  Volume 5, Issue 6, December 2016
- **Journal**: None
- **Summary**: Digital image compression is a technique that allows to reduce the size of an image in order to increase the capacity storage devices and to optimize the use of network bandwidth. The quality of compressed images with the techniques based on the discrete cosine transform or the wavelet transform is generally measured with PSNR or SSIM. Theses metrics are not suitable to images compressed with the singular values decomposition. This paper presents a new metric based on the energy ratio to measure the quality of the images coded with the SVD. A series of tests on 512 * 512 pixels images show that, for a rank k = 40 corresponding to a SSIM = 0,94 or PSNR = 35 dB, 99,9% of the energy are restored. Three areas of image quality assessments were identified. This new metric is also very accurate and could overcome the weaknesses of PSNR and SSIM.



### A New Convolutional Network-in-Network Structure and Its Applications in Skin Detection, Semantic Segmentation, and Artifact Reduction
- **Arxiv ID**: http://arxiv.org/abs/1701.06190v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.06190v1)
- **Published**: 2017-01-22 17:16:53+00:00
- **Updated**: 2017-01-22 17:16:53+00:00
- **Authors**: Yoonsik Kim, Insung Hwang, Nam Ik Cho
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: The inception network has been shown to provide good performance on image classification problems, but there are not much evidences that it is also effective for the image restoration or pixel-wise labeling problems. For image restoration problems, the pooling is generally not used because the decimated features are not helpful for the reconstruction of an image as the output. Moreover, most deep learning architectures for the restoration problems do not use dense prediction that need lots of training parameters. From these observations, for enjoying the performance of inception-like structure on the image based problems we propose a new convolutional network-in-network structure. The proposed network can be considered a modification of inception structure where pool projection and pooling layer are removed for maintaining the entire feature map size, and a larger kernel filter is added instead. Proposed network greatly reduces the number of parameters on account of removed dense prediction and pooling, which is an advantage, but may also reduce the receptive field in each layer. Hence, we add a larger kernel than the original inception structure for not increasing the depth of layers. The proposed structure is applied to typical image-to-image learning problems, i.e., the problems where the size of input and output are same such as skin detection, semantic segmentation, and compression artifacts reduction. Extensive experiments show that the proposed network brings comparable or better results than the state-of-the-art convolutional neural networks for these problems.



