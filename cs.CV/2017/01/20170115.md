# Arxiv Papers in cs.CV on 2017-01-15
### Density-Wise Two Stage Mammogram Classification using Texture Exploiting Descriptors
- **Arxiv ID**: http://arxiv.org/abs/1701.04010v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.04010v4)
- **Published**: 2017-01-15 08:59:06+00:00
- **Updated**: 2018-01-03 04:34:02+00:00
- **Authors**: Aditya A. Shastri, Deepti Tamrakar, Kapil Ahuja
- **Comment**: 28 Pages, 8 Figures, and 7 Tables
- **Journal**: None
- **Summary**: Breast cancer is becoming pervasive with each passing day. Hence, its early detection is a big step in saving the life of any patient. Mammography is a common tool in breast cancer diagnosis. The most important step here is classification of mammogram patches as normal-abnormal and benign-malignant.   Texture of a breast in a mammogram patch plays a significant role in these classifications. We propose a variation of Histogram of Gradients (HOG) and Gabor filter combination called Histogram of Oriented Texture (HOT) that exploits this fact. We also revisit the Pass Band - Discrete Cosine Transform (PB-DCT) descriptor that captures texture information well. All features of a mammogram patch may not be useful. Hence, we apply a feature selection technique called Discrimination Potentiality (DP). Our resulting descriptors, DP-HOT and DP-PB-DCT, are compared with the standard descriptors.   Density of a mammogram patch is important for classification, and has not been studied exhaustively. The Image Retrieval in Medical Application (IRMA) database from RWTH Aachen, Germany is a standard database that provides mammogram patches, and most researchers have tested their frameworks only on a subset of patches from this database. We apply our two new descriptors on all images of the IRMA database for density wise classification, and compare with the standard descriptors. We achieve higher accuracy than all of the existing standard descriptors (more than 92%).



### Boosting Dictionary Learning with Error Codes
- **Arxiv ID**: http://arxiv.org/abs/1701.04018v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.04018v1)
- **Published**: 2017-01-15 10:12:36+00:00
- **Updated**: 2017-01-15 10:12:36+00:00
- **Authors**: Yigit Oktar, Mehmet Turkan
- **Comment**: 5 pages, 5 figures
- **Journal**: None
- **Summary**: In conventional sparse representations based dictionary learning algorithms, initial dictionaries are generally assumed to be proper representatives of the system at hand. However, this may not be the case, especially in some systems restricted to random initializations. Therefore, a supposedly optimal state-update based on such an improper model might lead to undesired effects that will be conveyed to successive iterations. In this paper, we propose a dictionary learning method which includes a general feedback process that codes the intermediate error left over from a less intensive initial learning attempt, and then adjusts sparse codes accordingly. Experimental observations show that such an additional step vastly improves rates of convergence in high-dimensional cases, also results in better converged states in the case of random initializations. Improvements also scale up with more lenient sparsity constraints.



### Iterative Block Tensor Singular Value Thresholding for Extraction of Low Rank Component of Image Data
- **Arxiv ID**: http://arxiv.org/abs/1701.04043v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.04043v1)
- **Published**: 2017-01-15 13:48:27+00:00
- **Updated**: 2017-01-15 13:48:27+00:00
- **Authors**: Longxi Chen, Yipeng Liu, Ce Zhu
- **Comment**: accepted by ICASSP 2017
- **Journal**: None
- **Summary**: Tensor principal component analysis (TPCA) is a multi-linear extension of principal component analysis which converts a set of correlated measurements into several principal components. In this paper, we propose a new robust TPCA method to extract the princi- pal components of the multi-way data based on tensor singular value decomposition. The tensor is split into a number of blocks of the same size. The low rank component of each block tensor is extracted using iterative tensor singular value thresholding method. The prin- cipal components of the multi-way data are the concatenation of all the low rank components of all the block tensors. We give the block tensor incoherence conditions to guarantee the successful decom- position. This factorization has similar optimality properties to that of low rank matrix derived from singular value decomposition. Ex- perimentally, we demonstrate its effectiveness in two applications, including motion separation for surveillance videos and illumination normalization for face images.



### Embedding Watermarks into Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1701.04082v2
- **DOI**: 10.1145/3078971.3078974
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.04082v2)
- **Published**: 2017-01-15 17:32:02+00:00
- **Updated**: 2017-04-20 17:54:13+00:00
- **Authors**: Yusuke Uchida, Yuki Nagai, Shigeyuki Sakazawa, Shin'ichi Satoh
- **Comment**: None
- **Journal**: ICMR '17 Proceedings of the 2017 ACM on International Conference
  on Multimedia Retrieval Pages 269-277
- **Summary**: Deep neural networks have recently achieved significant progress. Sharing trained models of these deep neural networks is very important in the rapid progress of researching or developing deep neural network systems. At the same time, it is necessary to protect the rights of shared trained models. To this end, we propose to use a digital watermarking technology to protect intellectual property or detect intellectual property infringement of trained models. Firstly, we formulate a new problem: embedding watermarks into deep neural networks. We also define requirements, embedding situations, and attack types for watermarking to deep neural networks. Secondly, we propose a general framework to embed a watermark into model parameters using a parameter regularizer. Our approach does not hurt the performance of networks into which a watermark is embedded. Finally, we perform comprehensive experiments to reveal the potential of watermarking to deep neural networks as a basis of this new problem. We show that our framework can embed a watermark in the situations of training a network from scratch, fine-tuning, and distilling without hurting the performance of a deep neural network. The embedded watermark does not disappear even after fine-tuning or parameter pruning; the watermark completely remains even after removing 65% of parameters were pruned. The implementation of this research is: https://github.com/yu4u/dnn-watermark



### Light Source Estimation with Analytical Path-tracing
- **Arxiv ID**: http://arxiv.org/abs/1701.04101v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.04101v1)
- **Published**: 2017-01-15 19:15:39+00:00
- **Updated**: 2017-01-15 19:15:39+00:00
- **Authors**: Mike Kasper, Nima Keivan, Gabe Sibley, Christoffer Heckman
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel algorithm for light source estimation in scenes reconstructed with a RGB-D camera based on an analytically-derived formulation of path-tracing. Our algorithm traces the reconstructed scene with a custom path-tracer and computes the analytical derivatives of the light transport equation from principles in optics. These derivatives are then used to perform gradient descent, minimizing the photometric error between one or more captured reference images and renders of our current lighting estimation using an environment map parameterization for light sources. We show that our approach of modeling all light sources as points at infinity approximates lights located near the scene with surprising accuracy. Due to the analytical formulation of derivatives, optimization to the solution is considerably accelerated. We verify our algorithm using both real and synthetic data.



### Understanding the Effective Receptive Field in Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1701.04128v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1701.04128v2)
- **Published**: 2017-01-15 23:52:49+00:00
- **Updated**: 2017-01-25 06:32:29+00:00
- **Authors**: Wenjie Luo, Yujia Li, Raquel Urtasun, Richard Zemel
- **Comment**: None
- **Journal**: None
- **Summary**: We study characteristics of receptive fields of units in deep convolutional networks. The receptive field size is a crucial issue in many visual tasks, as the output must respond to large enough areas in the image to capture information about large objects. We introduce the notion of an effective receptive field, and show that it both has a Gaussian distribution and only occupies a fraction of the full theoretical receptive field. We analyze the effective receptive field in several architecture designs, and the effect of nonlinear activations, dropout, sub-sampling and skip connections on it. This leads to suggestions for ways to address its tendency to be too small.



