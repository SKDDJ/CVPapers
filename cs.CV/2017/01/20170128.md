# Arxiv Papers in cs.CV on 2017-01-28
### An Efficient Algebraic Solution to the Perspective-Three-Point Problem
- **Arxiv ID**: http://arxiv.org/abs/1701.08237v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08237v1)
- **Published**: 2017-01-28 02:16:48+00:00
- **Updated**: 2017-01-28 02:16:48+00:00
- **Authors**: Tong Ke, Stergios Roumeliotis
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we present an algebraic solution to the classical perspective-3-point (P3P) problem for determining the position and attitude of a camera from observations of three known reference points. In contrast to previous approaches, we first directly determine the camera's attitude by employing the corresponding geometric constraints to formulate a system of trigonometric equations. This is then efficiently solved, following an algebraic approach, to determine the unknown rotation matrix and subsequently the camera's position. As compared to recent alternatives, our method avoids computing unnecessary (and potentially numerically unstable) intermediate results, and thus achieves higher numerical accuracy and robustness at a lower computational cost. These benefits are validated through extensive Monte-Carlo simulations for both nominal and close-to-singular geometric configurations.



### Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation
- **Arxiv ID**: http://arxiv.org/abs/1701.08251v2
- **DOI**: None
- **Categories**: **cs.CL**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1701.08251v2)
- **Published**: 2017-01-28 05:06:11+00:00
- **Updated**: 2017-04-20 00:36:35+00:00
- **Authors**: Nasrin Mostafazadeh, Chris Brockett, Bill Dolan, Michel Galley, Jianfeng Gao, Georgios P. Spithourakis, Lucy Vanderwende
- **Comment**: None
- **Journal**: None
- **Summary**: The popularity of image sharing on social media and the engagement it creates between users reflects the important role that visual context plays in everyday conversations. We present a novel task, Image-Grounded Conversations (IGC), in which natural-sounding conversations are generated about a shared image. To benchmark progress, we introduce a new multiple-reference dataset of crowd-sourced, event-centric conversations on images. IGC falls on the continuum between chit-chat and goal-directed conversation models, where visual grounding constrains the topic of conversation to event-driven utterances. Experiments with models trained on social media data show that the combination of visual and textual context enhances the quality of generated conversational turns. In human evaluation, the gap between human performance and that of both neural and retrieval architectures suggests that multi-modal IGC presents an interesting challenge for dialogue research.



### Detection of Face using Viola Jones and Recognition using Back Propagation Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1701.08257v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08257v1)
- **Published**: 2017-01-28 05:51:44+00:00
- **Updated**: 2017-01-28 05:51:44+00:00
- **Authors**: Smriti Tikoo, Nitin Malik
- **Comment**: ISSN 2320-088X, 8 pages, 5 figures, 1 table
- **Journal**: Int J. Computer Science and Mobile Computing, vol. 5, issue 5, pp.
  288-295 (May 2016)
- **Summary**: Detection and recognition of the facial images of people is an intricate problem which has garnered much attention during recent years due to its ever increasing applications in numerous fields. It continues to pose a challenge in finding a robust solution to it. Its scope extends to catering the security, commercial and law enforcement applications. Research for moreover a decade on this subject has brought about remarkable development with the modus operandi like human computer interaction, biometric analysis and content based coding of images, videos and surveillance. A trivial task for brain but cumbersome to be imitated artificially. The commonalities in faces does pose a problem on various grounds but features such as skin color, gender differentiate a person from the other. In this paper the facial detection has been carried out using Viola-Jones algorithm and recognition of face has been done using Back Propagation Neural Network (BPNN).



### Detection, Segmentation and Recognition of Face and its Features Using Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1701.08259v1
- **DOI**: 10.4172/2155-6210.1000210
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1701.08259v1)
- **Published**: 2017-01-28 06:44:31+00:00
- **Updated**: 2017-01-28 06:44:31+00:00
- **Authors**: Smriti Tikoo, Nitin Malik
- **Comment**: Google Scholar Indexed Journal, 5 pages, 10 figures, Journal of
  Biosensors and Bioelectronics, vol. 7, no. 2, June-Sept 2016
- **Journal**: None
- **Summary**: Face detection and recognition has been prevalent with research scholars and diverse approaches have been incorporated till date to serve purpose. The rampant advent of biometric analysis systems, which may be full body scanners, or iris detection and recognition systems and the finger print recognition systems, and surveillance systems deployed for safety and security purposes have contributed to inclination towards same. Advances has been made with frontal view, lateral view of the face or using facial expressions such as anger, happiness and gloominess, still images and video image to be used for detection and recognition. This led to newer methods for face detection and recognition to be introduced in achieving accurate results and economically feasible and extremely secure. Techniques such as Principal Component analysis (PCA), Independent component analysis (ICA), Linear Discriminant Analysis (LDA), have been the predominant ones to be used. But with improvements needed in the previous approaches Neural Networks based recognition was like boon to the industry. It not only enhanced the recognition but also the efficiency of the process. Choosing Backpropagation as the learning method was clearly out of its efficiency to recognize nonlinear faces with an acceptance ratio of more than 90% and execution time of only few seconds.



### Exploiting saliency for object segmentation from image level labels
- **Arxiv ID**: http://arxiv.org/abs/1701.08261v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08261v2)
- **Published**: 2017-01-28 06:58:40+00:00
- **Updated**: 2017-07-14 09:05:11+00:00
- **Authors**: Seong Joon Oh, Rodrigo Benenson, Anna Khoreva, Zeynep Akata, Mario Fritz, Bernt Schiele
- **Comment**: CVPR 2017
- **Journal**: None
- **Summary**: There have been remarkable improvements in the semantic labelling task in the recent years. However, the state of the art methods rely on large-scale pixel-level annotations. This paper studies the problem of training a pixel-wise semantic labeller network from image-level annotations of the present object classes. Recently, it has been shown that high quality seeds indicating discriminative object regions can be obtained from image-level labels. Without additional information, obtaining the full extent of the object is an inherently ill-posed problem due to co-occurrences. We propose using a saliency model as additional information and hereby exploit prior knowledge on the object extent and image statistics. We show how to combine both information sources in order to recover 80% of the fully supervised performance - which is the new state of the art in weakly supervised training for pixel-wise semantic labelling. The code is available at https://goo.gl/KygSeb.



### Pruned non-local means
- **Arxiv ID**: http://arxiv.org/abs/1701.08280v2
- **DOI**: 10.1049/iet-ipr.2016.0331
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08280v2)
- **Published**: 2017-01-28 10:57:01+00:00
- **Updated**: 2017-02-16 12:11:05+00:00
- **Authors**: Sanjay Ghosh, Amit K. Mandal, Kunal N. Chaudhury
- **Comment**: Published in IET Image Processing
- **Journal**: None
- **Summary**: In Non-Local Means (NLM), each pixel is denoised by performing a weighted averaging of its neighboring pixels, where the weights are computed using image patches. We demonstrate that the denoising performance of NLM can be improved by pruning the neighboring pixels, namely, by rejecting neighboring pixels whose weights are below a certain threshold $\lambda$. While pruning can potentially reduce pixel averaging in uniform-intensity regions, we demonstrate that there is generally an overall improvement in the denoising performance. In particular, the improvement comes from pixels situated close to edges and corners. The success of the proposed method strongly depends on the choice of the global threshold $\lambda$, which in turn depends on the noise level and the image characteristics. We show how Stein's unbiased estimator of the mean-squared error can be used to optimally tune $\lambda$, at a marginal computational overhead. We present some representative denoising results to demonstrate the superior performance of the proposed method over NLM and its variants.



### Face Detection using Deep Learning: An Improved Faster RCNN Approach
- **Arxiv ID**: http://arxiv.org/abs/1701.08289v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.08289v1)
- **Published**: 2017-01-28 13:33:24+00:00
- **Updated**: 2017-01-28 13:33:24+00:00
- **Authors**: Xudong Sun, Pengcheng Wu, Steven C. H. Hoi
- **Comment**: None
- **Journal**: None
- **Summary**: In this report, we present a new face detection scheme using deep learning and achieve the state-of-the-art detection performance on the well-known FDDB face detetion benchmark evaluation. In particular, we improve the state-of-the-art faster RCNN framework by combining a number of strategies, including feature concatenation, hard negative mining, multi-scale training, model pretraining, and proper calibration of key parameters. As a consequence, the proposed scheme obtained the state-of-the-art face detection performance, making it the best model in terms of ROC curves among all the published methods on the FDDB benchmark.



### Treelogy: A Novel Tree Classifier Utilizing Deep and Hand-crafted Representations
- **Arxiv ID**: http://arxiv.org/abs/1701.08291v1
- **DOI**: None
- **Categories**: **cs.CV**, 68-06
- **Links**: [PDF](http://arxiv.org/pdf/1701.08291v1)
- **Published**: 2017-01-28 13:41:49+00:00
- **Updated**: 2017-01-28 13:41:49+00:00
- **Authors**: İlke Çuğu, Eren Şener, Çağrı Erciyes, Burak Balcı, Emre Akın, Itır Önal, Ahmet Oğuz Akyüz
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel tree classification system called Treelogy, that fuses deep representations with hand-crafted features obtained from leaf images to perform leaf-based plant classification. Key to this system are segmentation of the leaf from an untextured background, using convolutional neural networks (CNNs) for learning deep representations, extracting hand-crafted features with a number of image processing techniques, training a linear SVM with feature vectors, merging SVM and CNN results, and identifying the species from a dataset of 57 trees. Our classification results show that fusion of deep representations with hand-crafted features leads to the highest accuracy. The proposed algorithm is embedded in a smart-phone application, which is publicly available. Furthermore, our novel dataset comprised of 5408 leaf images is also made public for use of other researchers.



