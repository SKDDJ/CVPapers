# Arxiv Papers in cs.CV on 2017-01-26
### Super-resolution Using Constrained Deep Texture Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1701.07604v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.07604v1)
- **Published**: 2017-01-26 07:52:57+00:00
- **Updated**: 2017-01-26 07:52:57+00:00
- **Authors**: Libin Sun, James Hays
- **Comment**: 13 pages, 11 figures
- **Journal**: None
- **Summary**: Hallucinating high frequency image details in single image super-resolution is a challenging task. Traditional super-resolution methods tend to produce oversmoothed output images due to the ambiguity in mapping between low and high resolution patches. We build on recent success in deep learning based texture synthesis and show that this rich feature space can facilitate successful transfer and synthesis of high frequency image details to improve the visual quality of super-resolution results on a wide variety of natural textures and images.



### Sparse Ternary Codes for similarity search have higher coding gain than dense binary codes
- **Arxiv ID**: http://arxiv.org/abs/1701.07675v2
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, cs.IR, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1701.07675v2)
- **Published**: 2017-01-26 12:41:58+00:00
- **Updated**: 2017-04-25 09:58:45+00:00
- **Authors**: Sohrab Ferdowsi, Slava Voloshynovskiy, Dimche Kostadinov, Taras Holotyak
- **Comment**: Accepted at 2017 IEEE International Symposium on Information Theory
  (ISIT'17)
- **Journal**: None
- **Summary**: This paper addresses the problem of Approximate Nearest Neighbor (ANN) search in pattern recognition where feature vectors in a database are encoded as compact codes in order to speed-up the similarity search in large-scale databases. Considering the ANN problem from an information-theoretic perspective, we interpret it as an encoding, which maps the original feature vectors to a less entropic sparse representation while requiring them to be as informative as possible. We then define the coding gain for ANN search using information-theoretic measures. We next show that the classical approach to this problem, which consists of binarization of the projected vectors is sub-optimal. Instead, a properly designed ternary encoding achieves higher coding gains and lower complexity.



### Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in vitro
- **Arxiv ID**: http://arxiv.org/abs/1701.07717v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.07717v5)
- **Published**: 2017-01-26 14:30:40+00:00
- **Updated**: 2017-08-22 01:21:10+00:00
- **Authors**: Zhedong Zheng, Liang Zheng, Yi Yang
- **Comment**: 9 pages, 6 figures, accepted by ICCV 2017
- **Journal**: None
- **Summary**: The main contribution of this paper is a simple semi-supervised pipeline that only uses the original training set without collecting extra data. It is challenging in 1) how to obtain more training data only from the training set and 2) how to use the newly generated data. In this work, the generative adversarial network (GAN) is used to generate unlabeled samples. We propose the label smoothing regularization for outliers (LSRO). This method assigns a uniform label distribution to the unlabeled images, which regularizes the supervised model and improves the baseline. We verify the proposed method on a practical problem: person re-identification (re-ID). This task aims to retrieve a query person from other cameras. We adopt the deep convolutional generative adversarial network (DCGAN) for sample generation, and a baseline convolutional neural network (CNN) for representation learning. Experiments show that adding the GAN-generated data effectively improves the discriminative ability of learned CNN embeddings. On three large-scale datasets, Market-1501, CUHK03 and DukeMTMC-reID, we obtain +4.37%, +1.6% and +2.46% improvement in rank-1 precision over the baseline CNN, respectively. We additionally apply the proposed method to fine-grained bird recognition and achieve a +0.6% improvement over a strong baseline. The code is available at https://github.com/layumi/Person-reID_GAN.



### Pose Invariant Embedding for Deep Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1701.07732v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.07732v1)
- **Published**: 2017-01-26 14:59:19+00:00
- **Updated**: 2017-01-26 14:59:19+00:00
- **Authors**: Liang Zheng, Yujia Huang, Huchuan Lu, Yi Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Pedestrian misalignment, which mainly arises from detector errors and pose variations, is a critical problem for a robust person re-identification (re-ID) system. With bad alignment, the background noise will significantly compromise the feature learning and matching process. To address this problem, this paper introduces the pose invariant embedding (PIE) as a pedestrian descriptor. First, in order to align pedestrians to a standard pose, the PoseBox structure is introduced, which is generated through pose estimation followed by affine transformations. Second, to reduce the impact of pose estimation errors and information loss during PoseBox construction, we design a PoseBox fusion (PBF) CNN architecture that takes the original image, the PoseBox, and the pose estimation confidence as input. The proposed PIE descriptor is thus defined as the fully connected layer of the PBF network for the retrieval task. Experiments are conducted on the Market-1501, CUHK03, and VIPeR datasets. We show that PoseBox alone yields decent re-ID accuracy and that when integrated in the PBF network, the learned PIE descriptor produces competitive performance compared with the state-of-the-art approaches.



### Structural Connectome Validation Using Pairwise Classification
- **Arxiv ID**: http://arxiv.org/abs/1701.07847v2
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1701.07847v2)
- **Published**: 2017-01-26 19:13:36+00:00
- **Updated**: 2017-01-30 19:55:15+00:00
- **Authors**: Dmitry Petrov, Boris Gutman, Alexander Ivanov, Joshua Faskowitz, Neda Jahanshad, Mikhail Belyaev, Paul Thompson
- **Comment**: Accepted for IEEE International Symposium on Biomedical Imaging 2017
- **Journal**: None
- **Summary**: In this work, we study the extent to which structural connectomes and topological derivative measures are unique to individual changes within human brains. To do so, we classify structural connectome pairs from two large longitudinal datasets as either belonging to the same individual or not. Our data is comprised of 227 individuals from the Alzheimer's Disease Neuroimaging Initiative (ADNI) and 226 from the Parkinson's Progression Markers Initiative (PPMI). We achieve 0.99 area under the ROC curve score for features which represent either weights or network structure of the connectomes (node degrees, PageRank and local efficiency). Our approach may be useful for eliminating noisy features as a preprocessing step in brain aging studies and early diagnosis classification problems.



### A Radically New Theory of how the Brain Represents and Computes with Probabilities
- **Arxiv ID**: http://arxiv.org/abs/1701.07879v4
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1701.07879v4)
- **Published**: 2017-01-26 21:16:32+00:00
- **Updated**: 2018-02-21 23:00:01+00:00
- **Authors**: Gerard Rinkus
- **Comment**: 33 pages, 10 figures - Sec. explaining single cell tuning fns as
  artifacts of embedding SDRs in superposition removed (for future paper) -
  Clarified that a given SDR code represents the whole likelihood distribution
  over stored hypotheses at a coarsely-ranked level of fidelity (Submitted for
  review)
- **Journal**: None
- **Summary**: The brain is believed to implement probabilistic reasoning and to represent information via population, or distributed, coding. Most previous population-based probabilistic (PPC) theories share several basic properties: 1) continuous-valued neurons; 2) fully(densely)-distributed codes, i.e., all(most) units participate in every code; 3) graded synapses; 4) rate coding; 5) units have innate unimodal tuning functions (TFs); 6) intrinsically noisy units; and 7) noise/correlation is considered harmful. We present a radically different theory that assumes: 1) binary units; 2) only a small subset of units, i.e., a sparse distributed representation (SDR) (cell assembly), comprises any individual code; 3) binary synapses; 4) signaling formally requires only single (i.e., first) spikes; 5) units initially have completely flat TFs (all weights zero); 6) units are far less intrinsically noisy than traditionally thought; rather 7) noise is a resource generated/used to cause similar inputs to map to similar codes, controlling a tradeoff between storage capacity and embedding the input space statistics in the pattern of intersections over stored codes, epiphenomenally determining correlation patterns across neurons. The theory, Sparsey, was introduced 20+ years ago as a canonical cortical circuit/algorithm model achieving efficient sequence learning/recognition, but not elaborated as an alternative to PPC theories. Here, we show that: a) the active SDR simultaneously represents both the most similar/likely input and the entire (coarsely-ranked) similarity likelihood/distribution over all stored inputs (hypotheses); and b) given an input, the SDR code selection algorithm, which underlies both learning and inference, updates both the most likely hypothesis and the entire likelihood distribution (cf. belief update) with a number of steps that remains constant as the number of stored items increases.



### Deep Region Hashing for Efficient Large-scale Instance Search from Images
- **Arxiv ID**: http://arxiv.org/abs/1701.07901v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.07901v1)
- **Published**: 2017-01-26 23:18:58+00:00
- **Updated**: 2017-01-26 23:18:58+00:00
- **Authors**: Jingkuan Song, Tao He, Lianli Gao, Xing Xu, Heng Tao Shen
- **Comment**: None
- **Journal**: None
- **Summary**: Instance Search (INS) is a fundamental problem for many applications, while it is more challenging comparing to traditional image search since the relevancy is defined at the instance level.   Existing works have demonstrated the success of many complex ensemble systems that are typically conducted by firstly generating object proposals, and then extracting handcrafted and/or CNN features of each proposal for matching. However, object bounding box proposals and feature extraction are often conducted in two separated steps, thus the effectiveness of these methods collapses. Also, due to the large amount of generated proposals, matching speed becomes the bottleneck that limits its application to large-scale datasets. To tackle these issues, in this paper we propose an effective and efficient Deep Region Hashing (DRH) approach for large-scale INS using an image patch as the query. Specifically, DRH is an end-to-end deep neural network which consists of object proposal, feature extraction, and hash code generation. DRH shares full-image convolutional feature map with the region proposal network, thus enabling nearly cost-free region proposals. Also, each high-dimensional, real-valued region features are mapped onto a low-dimensional, compact binary codes for the efficient object region level matching on large-scale dataset. Experimental results on four datasets show that our DRH can achieve even better performance than the state-of-the-arts in terms of MAP, while the efficiency is improved by nearly 100 times.



