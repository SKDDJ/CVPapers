# Arxiv Papers in cs.CV on 2017-01-14
### Learning Linear Dynamical Systems with High-Order Tensor Data for Skeleton based Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1701.03869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1701.03869v1)
- **Published**: 2017-01-14 02:07:23+00:00
- **Updated**: 2017-01-14 02:07:23+00:00
- **Authors**: Wenwen Ding, Kai Liu
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, there has been renewed interest in developing methods for skeleton-based human action recognition. A skeleton sequence can be naturally represented as a high-order tensor time series. In this paper, we model and analyze tensor time series with Linear Dynamical System (LDS) which is the most common for encoding spatio-temporal time-series data in various disciplines dut to its relative simplicity and efficiency. However, the traditional LDS treats the latent and observation state at each frame of video as a column vector. Such a vector representation fails to take into account the curse of dimensionality as well as valuable structural information with human action. Considering this fact, we propose generalized Linear Dynamical System (gLDS) for modeling tensor observation in the time series and employ Tucker decomposition to estimate the LDS parameters as action descriptors. Therefore, an action can be represented as a subspace corresponding to a point on a Grassmann manifold. Then we perform classification using dictionary learning and sparse coding over Grassmann manifold. Experiments on MSR Action3D Dataset, UCF Kinect Dataset and Northwestern-UCLA Multiview Action3D Dataset demonstrate that our proposed method achieves superior performance to the state-of-the-art algorithms.



### On Hölder projective divergences
- **Arxiv ID**: http://arxiv.org/abs/1701.03916v1
- **DOI**: 10.3390/e19030122
- **Categories**: **cs.LG**, cs.CV, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1701.03916v1)
- **Published**: 2017-01-14 12:57:44+00:00
- **Updated**: 2017-01-14 12:57:44+00:00
- **Authors**: Frank Nielsen, Ke Sun, Stéphane Marchand-Maillet
- **Comment**: 25 pages
- **Journal**: None
- **Summary**: We describe a framework to build distances by measuring the tightness of inequalities, and introduce the notion of proper statistical divergences and improper pseudo-divergences. We then consider the H\"older ordinary and reverse inequalities, and present two novel classes of H\"older divergences and pseudo-divergences that both encapsulate the special case of the Cauchy-Schwarz divergence. We report closed-form formulas for those statistical dissimilarities when considering distributions belonging to the same exponential family provided that the natural parameter space is a cone (e.g., multivariate Gaussians), or affine (e.g., categorical distributions). Those new classes of H\"older distances are invariant to rescaling, and thus do not require distributions to be normalized. Finally, we show how to compute statistical H\"older centroids with respect to those divergences, and carry out center-based clustering toy experiments on a set of Gaussian distributions that demonstrate empirically that symmetrized H\"older divergences outperform the symmetric Cauchy-Schwarz divergence.



