# Arxiv Papers in cs.CV on 2017-10-21
### ADA: A Game-Theoretic Perspective on Data Augmentation for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1710.07735v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GT
- **Links**: [PDF](http://arxiv.org/pdf/1710.07735v2)
- **Published**: 2017-10-21 00:51:49+00:00
- **Updated**: 2017-12-12 15:20:22+00:00
- **Authors**: Sima Behpour, Kris M. Kitani, Brian D. Ziebart
- **Comment**: None
- **Journal**: None
- **Summary**: The use of random perturbations of ground truth data, such as random translation or scaling of bounding boxes, is a common heuristic used for data augmentation that has been shown to prevent overfitting and improve generalization. Since the design of data augmentation is largely guided by reported best practices, it is difficult to understand if those design choices are optimal. To provide a more principled perspective, we develop a game-theoretic interpretation of data augmentation in the context of object detection. We aim to find an optimal adversarial perturbations of the ground truth data (i.e., the worst case perturbations) that forces the object bounding box predictor to learn from the hardest distribution of perturbed examples for better test-time performance. We establish that the game theoretic solution, the Nash equilibrium, provides both an optimal predictor and optimal data augmentation distribution. We show that our adversarial method of training a predictor can significantly improve test time performance for the task of object detection. On the ImageNet object detection task, our adversarial approach improves performance by over 16\% compared to the best performing data augmentation method



### An efficient deep learning hashing neural network for mobile visual search
- **Arxiv ID**: http://arxiv.org/abs/1710.07750v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.07750v1)
- **Published**: 2017-10-21 04:37:23+00:00
- **Updated**: 2017-10-21 04:37:23+00:00
- **Authors**: Heng Qi, Wu Liu, Liang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Mobile visual search applications are emerging that enable users to sense their surroundings with smart phones. However, because of the particular challenges of mobile visual search, achieving a high recognition bitrate has becomes a consistent target of previous related works. In this paper, we propose a few-parameter, low-latency, and high-accuracy deep hashing approach for constructing binary hash codes for mobile visual search. First, we exploit the architecture of the MobileNet model, which significantly decreases the latency of deep feature extraction by reducing the number of model parameters while maintaining accuracy. Second, we add a hash-like layer into MobileNet to train the model on labeled mobile visual data. Evaluations show that the proposed system can exceed state-of-the-art accuracy performance in terms of the MAP. More importantly, the memory consumption is much less than that of other deep learning models. The proposed method requires only $13$ MB of memory for the neural network and achieves a MAP of $97.80\%$ on the mobile location recognition dataset used for testing.



### Image Disguise based on Generative Model
- **Arxiv ID**: http://arxiv.org/abs/1710.07782v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.07782v4)
- **Published**: 2017-10-21 10:26:44+00:00
- **Updated**: 2018-01-02 13:44:55+00:00
- **Authors**: Xintao Duan, Haoxian Song, En Zhang, Jingjing Liu
- **Comment**: 4 pages,9 figures
- **Journal**: None
- **Summary**: To protect image contents, most existing encryption algorithms are designed to transform an original image into a texture-like or noise-like image, which is, however, an obvious visual sign indicating the presence of an encrypted image, results in a significantly large number of attacks. To solve this problem, in this paper, we propose a new image encryption method to generate a visually same image as the original one by sending a meaning-normal and independent image to a corresponding well-trained generative model to achieve the effect of disguising the original image. This image disguise method not only solves the problem of obvious visual implication, but also guarantees the security of the information.



### Incomplete Dot Products for Dynamic Computation Scaling in Neural Network Inference
- **Arxiv ID**: http://arxiv.org/abs/1710.07830v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.07830v1)
- **Published**: 2017-10-21 17:37:11+00:00
- **Updated**: 2017-10-21 17:37:11+00:00
- **Authors**: Bradley McDanel, Surat Teerapittayanon, H. T. Kung
- **Comment**: None
- **Journal**: None
- **Summary**: We propose the use of incomplete dot products (IDP) to dynamically adjust the number of input channels used in each layer of a convolutional neural network during feedforward inference. IDP adds monotonically non-increasing coefficients, referred to as a "profile", to the channels during training. The profile orders the contribution of each channel in non-increasing order. At inference time, the number of channels used can be dynamically adjusted to trade off accuracy for lowered power consumption and reduced latency by selecting only a beginning subset of channels. This approach allows for a single network to dynamically scale over a computation range, as opposed to training and deploying multiple networks to support different levels of computation scaling. Additionally, we extend the notion to multiple profiles, each optimized for some specific range of computation scaling. We present experiments on the computation and accuracy trade-offs of IDP for popular image classification models and datasets. We demonstrate that, for MNIST and CIFAR-10, IDP reduces computation significantly, e.g., by 75%, without significantly compromising accuracy. We argue that IDP provides a convenient and effective means for devices to lower computation costs dynamically to reflect the current computation budget of the system. For example, VGG-16 with 50% IDP (using only the first 50% of channels) achieves 70% in accuracy on the CIFAR-10 dataset compared to the standard network which achieves only 35% accuracy when using the reduced channel set.



### A Generative Restricted Boltzmann Machine Based Method for High-Dimensional Motion Data Modeling
- **Arxiv ID**: http://arxiv.org/abs/1710.07831v1
- **DOI**: 10.1016/j.cviu.2014.12.005
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1710.07831v1)
- **Published**: 2017-10-21 17:40:12+00:00
- **Updated**: 2017-10-21 17:40:12+00:00
- **Authors**: Siqi Nie, Ziheng Wang, Qiang Ji
- **Comment**: None
- **Journal**: Computer Vision and Image Understanding 136 (2015): 14-22
- **Summary**: Many computer vision applications involve modeling complex spatio-temporal patterns in high-dimensional motion data. Recently, restricted Boltzmann machines (RBMs) have been widely used to capture and represent spatial patterns in a single image or temporal patterns in several time slices. To model global dynamics and local spatial interactions, we propose to theoretically extend the conventional RBMs by introducing another term in the energy function to explicitly model the local spatial interactions in the input data. A learning method is then proposed to perform efficient learning for the proposed model. We further introduce a new method for multi-class classification that can effectively estimate the infeasible partition functions of different RBMs such that RBM is treated as a generative model for classification purpose. The improved RBM model is evaluated on two computer vision applications: facial expression recognition and human action recognition. Experimental results on benchmark databases demonstrate the effectiveness of the proposed algorithm.



### Heat Kernel Smoothing in Irregular Image Domains
- **Arxiv ID**: http://arxiv.org/abs/1710.07849v1
- **DOI**: None
- **Categories**: **stat.ME**, cs.CV, eess.IV, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/1710.07849v1)
- **Published**: 2017-10-21 19:53:36+00:00
- **Updated**: 2017-10-21 19:53:36+00:00
- **Authors**: Moo K. Chung, Yanli Wang, Gurong Wu
- **Comment**: None
- **Journal**: None
- **Summary**: We present the discrete version of heat kernel smoothing on graph data structure. The method is used to smooth data in an irregularly shaped domains in 3D images.   New statistical properties are derived. As an application, we show how to filter out data in the lung blood vessel trees obtained from computed tomography. The method can be further used in representing the complex vessel trees parametrically and extracting the skeleton representation of the trees.



### Feature-Guided Black-Box Safety Testing of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.07859v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.07859v2)
- **Published**: 2017-10-21 22:20:06+00:00
- **Updated**: 2018-02-20 07:51:56+00:00
- **Authors**: Matthew Wicker, Xiaowei Huang, Marta Kwiatkowska
- **Comment**: 35 pages, 5 tables, 23 figures
- **Journal**: None
- **Summary**: Despite the improved accuracy of deep neural networks, the discovery of adversarial examples has raised serious safety concerns. Most existing approaches for crafting adversarial examples necessitate some knowledge (architecture, parameters, etc.) of the network at hand. In this paper, we focus on image classifiers and propose a feature-guided black-box approach to test the safety of deep neural networks that requires no such knowledge. Our algorithm employs object detection techniques such as SIFT (Scale Invariant Feature Transform) to extract features from an image. These features are converted into a mutable saliency distribution, where high probability is assigned to pixels that affect the composition of the image with respect to the human visual system. We formulate the crafting of adversarial examples as a two-player turn-based stochastic game, where the first player's objective is to minimise the distance to an adversarial example by manipulating the features, and the second player can be cooperative, adversarial, or random. We show that, theoretically, the two-player game can con- verge to the optimal strategy, and that the optimal strategy represents a globally minimal adversarial image. For Lipschitz networks, we also identify conditions that provide safety guarantees that no adversarial examples exist. Using Monte Carlo tree search we gradually explore the game state space to search for adversarial examples. Our experiments show that, despite the black-box setting, manipulations guided by a perception-based saliency distribution are competitive with state-of-the-art methods that rely on white-box saliency matrices or sophisticated optimization procedures. Finally, we show how our method can be used to evaluate robustness of neural networks in safety-critical applications such as traffic sign recognition in self-driving cars.



