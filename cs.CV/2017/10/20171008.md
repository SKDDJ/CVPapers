# Arxiv Papers in cs.CV on 2017-10-08
### Micro-Expression Spotting: A Benchmark
- **Arxiv ID**: http://arxiv.org/abs/1710.02820v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02820v1)
- **Published**: 2017-10-08 11:21:29+00:00
- **Updated**: 2017-10-08 11:21:29+00:00
- **Authors**: Xiaopeng Hong, Thuong-Khanh Tran, Guoying Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Micro-expressions are rapid and involuntary facial expressions, which indicate the suppressed or concealed emotions. Recently, the research on automatic micro-expression (ME) spotting obtains increasing attention. ME spotting is a crucial step prior to further ME analysis tasks. The spotting results can be used as important cues to assist many other human-oriented tasks and thus have many potential applications. In this paper, by investigating existing ME spotting methods, we recognize the immediacy of standardizing the performance evaluation of micro-expression spotting methods. To this end, we construct a micro-expression spotting benchmark (MESB). Firstly, we set up a sliding window based multi-scale evaluation framework. Secondly, we introduce a series of protocols. Thirdly, we also provide baseline results of popular methods. The MESB facilitates the research on ME spotting with fairer and more comprehensive evaluation and also enables to leverage the cutting-edge machine learning tools widely.



### Reconstruction of Hidden Representation for Robust Feature Extraction
- **Arxiv ID**: http://arxiv.org/abs/1710.02844v2
- **DOI**: 10.1145/3284174
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.02844v2)
- **Published**: 2017-10-08 15:48:37+00:00
- **Updated**: 2018-10-23 15:51:57+00:00
- **Authors**: Zeng Yu, Tianrui Li, Ning Yu, Yi Pan, Hongmei Chen, Bing Liu
- **Comment**: This article has been accepted for publication in a future issue of
  ACM Transactions on Intelligent Systems and Technology
- **Journal**: None
- **Summary**: This paper aims to develop a new and robust approach to feature representation. Motivated by the success of Auto-Encoders, we first theoretical summarize the general properties of all algorithms that are based on traditional Auto-Encoders: 1) The reconstruction error of the input can not be lower than a lower bound, which can be viewed as a guiding principle for reconstructing the input. Additionally, when the input is corrupted with noises, the reconstruction error of the corrupted input also can not be lower than a lower bound. 2) The reconstruction of a hidden representation achieving its ideal situation is the necessary condition for the reconstruction of the input to reach the ideal state. 3) Minimizing the Frobenius norm of the Jacobian matrix of the hidden representation has a deficiency and may result in a much worse local optimum value. We believe that minimizing the reconstruction error of the hidden representation is more robust than minimizing the Frobenius norm of the Jacobian matrix of the hidden representation. Based on the above analysis, we propose a new model termed Double Denoising Auto-Encoders (DDAEs), which uses corruption and reconstruction on both the input and the hidden representation. We demonstrate that the proposed model is highly flexible and extensible and has a potentially better capability to learn invariant and robust feature representations. We also show that our model is more robust than Denoising Auto-Encoders (DAEs) for dealing with noises or inessential features. Furthermore, we detail how to train DDAEs with two different pre-training methods by optimizing the objective function in a combined and separate manner, respectively. Comparative experiments illustrate that the proposed model is significantly better for representation learning than the state-of-the-art models.



### Gender and Ethnicity Classification of Iris Images using Deep Class-Encoder
- **Arxiv ID**: http://arxiv.org/abs/1710.02856v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02856v1)
- **Published**: 2017-10-08 17:01:37+00:00
- **Updated**: 2017-10-08 17:01:37+00:00
- **Authors**: Maneet Singh, Shruti Nagpal, Mayank Vatsa, Richa Singh, Afzel Noore, Angshul Majumdar
- **Comment**: International Joint Conference on Biometrics, 2017
- **Journal**: None
- **Summary**: Soft biometric modalities have shown their utility in different applications including reducing the search space significantly. This leads to improved recognition performance, reduced computation time, and faster processing of test samples. Some common soft biometric modalities are ethnicity, gender, age, hair color, iris color, presence of facial hair or moles, and markers. This research focuses on performing ethnicity and gender classification on iris images. We present a novel supervised autoencoder based approach, Deep Class-Encoder, which uses class labels to learn discriminative representation for the given sample by mapping the learned feature vector to its label. The proposed model is evaluated on two datasets each for ethnicity and gender classification. The results obtained using the proposed Deep Class-Encoder demonstrate its effectiveness in comparison to existing approaches and state-of-the-art methods.



### On Matching Skulls to Digital Face Images: A Preliminary Approach
- **Arxiv ID**: http://arxiv.org/abs/1710.02866v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02866v1)
- **Published**: 2017-10-08 18:05:10+00:00
- **Updated**: 2017-10-08 18:05:10+00:00
- **Authors**: Shruti Nagpal, Maneet Singh, Arushi Jain, Richa Singh, Mayank Vatsa, Afzel Noore
- **Comment**: International Joint Conference on Biometrics, 2017
- **Journal**: None
- **Summary**: Forensic application of automatically matching skull with face images is an important research area linking biometrics with practical applications in forensics. It is an opportunity for biometrics and face recognition researchers to help the law enforcement and forensic experts in giving an identity to unidentified human skulls. It is an extremely challenging problem which is further exacerbated due to lack of any publicly available database related to this problem. This is the first research in this direction with a two-fold contribution: (i) introducing the first of its kind skull-face image pair database, IdentifyMe, and (ii) presenting a preliminary approach using the proposed semi-supervised formulation of transform learning. The experimental results and comparison with existing algorithms showcase the challenging nature of the problem. We assert that the availability of the database will inspire researchers to build sophisticated skull-to-face matching algorithms.



