# Arxiv Papers in cs.CV on 2017-10-27
### Sound Source Localization in a Multipath Environment Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.10948v1
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/1710.10948v1)
- **Published**: 2017-10-27 01:14:51+00:00
- **Updated**: 2017-10-27 01:14:51+00:00
- **Authors**: Eric L. Ferguson, Stefan B. Williams, Craig T. Jin
- **Comment**: 5 pages, 5 figures, Final draft of paper submitted to 2018 IEEE
  International Conference on Acoustics, Speech and Signal Processing (ICASSP)
  15-20 April 2018 in Calgary, Alberta, Canada. arXiv admin note: text overlap
  with arXiv:1612.03505
- **Journal**: None
- **Summary**: The propagation of sound in a shallow water environment is characterized by boundary reflections from the sea surface and sea floor. These reflections result in multiple (indirect) sound propagation paths, which can degrade the performance of passive sound source localization methods. This paper proposes the use of convolutional neural networks (CNNs) for the localization of sources of broadband acoustic radiated noise (such as motor vessels) in shallow water multipath environments. It is shown that CNNs operating on cepstrogram and generalized cross-correlogram inputs are able to more reliably estimate the instantaneous range and bearing of transiting motor vessels when the source localization performance of conventional passive ranging methods is degraded. The ensuing improvement in source localization performance is demonstrated using real data collected during an at-sea experiment.



### Stochastic Conjugate Gradient Algorithm with Variance Reduction
- **Arxiv ID**: http://arxiv.org/abs/1710.09979v2
- **DOI**: 10.1109/TNNLS.2018.2868835
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.09979v2)
- **Published**: 2017-10-27 03:47:41+00:00
- **Updated**: 2018-10-16 11:33:01+00:00
- **Authors**: Xiao-Bo Jin, Xu-Yao Zhang, Kaizhu Huang, Guang-Gang Geng
- **Comment**: 10 pages, 4 figures, appeared in IEEE TRANSACTIONS ON NEURAL NETWORKS
  AND LEARNING SYSTEMS, CGVR algorithm is available on github:
  https://github.com/xbjin/cgvr
- **Journal**: IEEE Transactions on Neural Networks and Learning Systems,2018
- **Summary**: Conjugate gradient (CG) methods are a class of important methods for solving linear equations and nonlinear optimization problems. In this paper, we propose a new stochastic CG algorithm with variance reduction and we prove its linear convergence with the Fletcher and Reeves method for strongly convex and smooth functions. We experimentally demonstrate that the CG with variance reduction algorithm converges faster than its counterparts for four learning models, which may be convex, nonconvex or nonsmooth. In addition, its area under the curve performance on six large-scale data sets is comparable to that of the LIBLINEAR solver for the L2-regularized L2-loss but with a significant improvement in computational efficiency



### PoseTrack: A Benchmark for Human Pose Estimation and Tracking
- **Arxiv ID**: http://arxiv.org/abs/1710.10000v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10000v2)
- **Published**: 2017-10-27 06:20:30+00:00
- **Updated**: 2018-04-10 18:20:56+00:00
- **Authors**: Mykhaylo Andriluka, Umar Iqbal, Eldar Insafutdinov, Leonid Pishchulin, Anton Milan, Juergen Gall, Bernt Schiele
- **Comment**: www.posetrack.net
- **Journal**: None
- **Summary**: Human poses and motions are important cues for analysis of videos with people and there is strong evidence that representations based on body pose are highly effective for a variety of tasks such as activity recognition, content retrieval and social signal processing. In this work, we aim to further advance the state of the art by establishing "PoseTrack", a new large-scale benchmark for video-based human pose estimation and articulated tracking, and bringing together the community of researchers working on visual human analysis. The benchmark encompasses three competition tracks focusing on i) single-frame multi-person pose estimation, ii) multi-person pose estimation in videos, and iii) multi-person articulated tracking. To facilitate the benchmark and challenge we collect, annotate and release a new %large-scale benchmark dataset that features videos with multiple people labeled with person tracks and articulated pose. A centralized evaluation server is provided to allow participants to evaluate on a held-out test set. We envision that the proposed benchmark will stimulate productive research both by providing a large and representative training dataset as well as providing a platform to objectively evaluate and compare the proposed methods. The benchmark is freely accessible at https://posetrack.net.



### Deterministic Approximate Methods for Maximum Consensus Robust Fitting
- **Arxiv ID**: http://arxiv.org/abs/1710.10003v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10003v2)
- **Published**: 2017-10-27 06:40:26+00:00
- **Updated**: 2018-10-23 04:56:16+00:00
- **Authors**: Huu Le, Tat-Jun Chin, Anders Eriksson, Thanh-Toan Do, David Suter
- **Comment**: None
- **Journal**: None
- **Summary**: Maximum consensus estimation plays a critically important role in robust fitting problems in computer vision. Currently, the most prevalent algorithms for consensus maximization draw from the class of randomized hypothesize-and-verify algorithms, which are cheap but can usually deliver only rough approximate solutions. On the other extreme, there are exact algorithms which are exhaustive search in nature and can be costly for practical-sized inputs. This paper fills the gap between the two extremes by proposing deterministic algorithms to approximately optimize the maximum consensus criterion. Our work begins by reformulating consensus maximization with linear complementarity constraints. Then, we develop two novel algorithms: one based on non-smooth penalty method with a Frank-Wolfe style optimization scheme, the other based on the Alternating Direction Method of Multipliers (ADMM). Both algorithms solve convex subproblems to efficiently perform the optimization. We demonstrate the capability of our algorithms to greatly improve a rough initial estimate, such as those obtained using least squares or a randomized algorithm. Compared to the exact algorithms, our approach is much more practical on realistic input sizes. Further, our approach is naturally applicable to estimation problems with geometric residuals



### Deep Learning for Accelerated Ultrasound Imaging
- **Arxiv ID**: http://arxiv.org/abs/1710.10006v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.10006v1)
- **Published**: 2017-10-27 06:49:37+00:00
- **Updated**: 2017-10-27 06:49:37+00:00
- **Authors**: Yeo Hun Yoon, Jong Chul Ye
- **Comment**: Invited paper for ICASSP 2018 Special Session for "Machine Learning
  in Medical Imaging: from Measurement to Diagnosis"
- **Journal**: None
- **Summary**: In portable, 3-D, or ultra-fast ultrasound (US) imaging systems, there is an increasing demand to reconstruct high quality images from limited number of data. However, the existing solutions require either hardware changes or computationally expansive algorithms. To overcome these limitations, here we propose a novel deep learning approach that interpolates the missing RF data by utilizing the sparsity of the RF data in the Fourier domain. Extensive experimental results from sub-sampled RF data from a real US system confirmed that the proposed method can effectively reduce the data rate without sacrificing the image quality.



### Fine-grained Pattern Matching Over Streaming Time Series
- **Arxiv ID**: http://arxiv.org/abs/1710.10088v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DB
- **Links**: [PDF](http://arxiv.org/pdf/1710.10088v3)
- **Published**: 2017-10-27 11:45:14+00:00
- **Updated**: 2017-12-01 23:45:48+00:00
- **Authors**: Rong Kang, Chen Wang, Peng Wang, Yuting Ding, Jianmin Wang
- **Comment**: 14 pages, 14 figures, 29 conference
- **Journal**: None
- **Summary**: Pattern matching of streaming time series with lower latency under limited computing resource comes to a critical problem, especially as the growth of Industry 4.0 and Industry Internet of Things. However, against traditional single pattern matching problem, a pattern may contain multiple segments representing different statistical properties or physical meanings for more precise and expressive matching in real world. Hence, we formulate a new problem, called "fine-grained pattern matching", which allows users to specify varied granularities of matching deviation to different segments of a given pattern, and fuzzy regions for adaptive breakpoints determination between consecutive segments. In this paper, we propose a novel two-phase approach. In the pruning phase, we introduce Equal-Length Block (ELB) representation together with Block-Skipping Pruning (BSP) policy, which guarantees low cost feature calculation, effective pruning and no false dismissals. In the post-processing phase, a delta-function is proposed to enable us to conduct exact matching in linear complexity. Extensive experiments are conducted to evaluate on synthetic and real-world datasets, which illustrates that our algorithm outperforms the brute-force method and MSM, a multi-step filter mechanism over the multi-scaled representation.



### SceneFlowFields: Dense Interpolation of Sparse Scene Flow Correspondences
- **Arxiv ID**: http://arxiv.org/abs/1710.10096v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10096v1)
- **Published**: 2017-10-27 12:03:37+00:00
- **Updated**: 2017-10-27 12:03:37+00:00
- **Authors**: René Schuster, Oliver Wasenmüller, Georg Kuschk, Christian Bailer, Didier Stricker
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2018
- **Journal**: None
- **Summary**: While most scene flow methods use either variational optimization or a strong rigid motion assumption, we show for the first time that scene flow can also be estimated by dense interpolation of sparse matches. To this end, we find sparse matches across two stereo image pairs that are detected without any prior regularization and perform dense interpolation preserving geometric and motion boundaries by using edge information. A few iterations of variational energy minimization are performed to refine our results, which are thoroughly evaluated on the KITTI benchmark and additionally compared to state-of-the-art on MPI Sintel. For application in an automotive context, we further show that an optional ego-motion model helps to boost performance and blends smoothly into our approach to produce a segmentation of the scene into static and dynamic parts.



### Image matting with normalized weight and semi-supervised learning
- **Arxiv ID**: http://arxiv.org/abs/1710.10101v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10101v1)
- **Published**: 2017-10-27 12:14:47+00:00
- **Updated**: 2017-10-27 12:14:47+00:00
- **Authors**: Ping Li, Tingyan Duan, Yongfeng Cao
- **Comment**: None
- **Journal**: None
- **Summary**: Image matting is an important vision problem. The main stream methods for it combine sampling-based methods and propagation-based methods. In this paper, we deal with the combination with a normalized weighting parameter, which could well control the relative relationship between information from sampling and from propagation. A reasonable value range for this parameter is given based on statistics from the standard benchmark dataset. The matting is further improved by introducing semi-supervised learning iterations, which automatically refine the trimap without user's interaction. This is especially beneficial when the trimap is coarse. The experimental results on standard benchmark dataset have shown that both the normalized weighting parameter and the semi-supervised learning iteration could significantly improve the matting performance.



### On the Taut String Interpretation of the One-dimensional Rudin-Osher-Fatemi Model: A New Proof, a Fundamental Estimate and Some Applications
- **Arxiv ID**: http://arxiv.org/abs/1710.10985v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1710.10985v1)
- **Published**: 2017-10-27 12:59:56+00:00
- **Updated**: 2017-10-27 12:59:56+00:00
- **Authors**: Niels Chr. Overgaard
- **Comment**: 19 pages, 2 figures, 1 appendix
- **Journal**: None
- **Summary**: A new proof of the equivalence of the Taut String Algorithm and the one-dimensional Rudin-Osher-Fatemi model is presented. Based on duality and the projection theorem in Hilbert space, the proof is strictly elementary. Existence and uniqueness of solutions to both denoising models follow as by-products. The standard convergence properties of the denoised signal, as the regularizing parameter tends to zero, are recalled and efficient proofs provided. Moreover, a new and fundamental bound on the denoised signal is derived. This bound implies, among other things, the strong convergence (in the space of functions of bounded variation) of the denoised signal to the insignal as the regularization parameter vanishes. The methods developed in the paper can be modified to cover other interesting applications such as isotonic regression.



### Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations
- **Arxiv ID**: http://arxiv.org/abs/1710.10121v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.10121v3)
- **Published**: 2017-10-27 13:19:59+00:00
- **Updated**: 2020-03-23 04:20:58+00:00
- **Authors**: Yiping Lu, Aoxiao Zhong, Quanzheng Li, Bin Dong
- **Comment**: None
- **Journal**: None
- **Summary**: In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress ($>50$\%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.



### High-Quality Facial Photo-Sketch Synthesis Using Multi-Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.10182v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10182v2)
- **Published**: 2017-10-27 14:56:45+00:00
- **Updated**: 2018-03-03 03:30:48+00:00
- **Authors**: Lidan Wang, Vishwanath A. Sindagi, Vishal M. Patel
- **Comment**: Accepted by 2018 13th IEEE International Conference on Automatic Face
  & Gesture Recognition (FG 2018)(Oral)
- **Journal**: None
- **Summary**: Synthesizing face sketches from real photos and its inverse have many applications. However, photo/sketch synthesis remains a challenging problem due to the fact that photo and sketch have different characteristics. In this work, we consider this task as an image-to-image translation problem and explore the recently popular generative models (GANs) to generate high-quality realistic photos from sketches and sketches from photos. Recent GAN-based methods have shown promising results on image-to-image translation problems and photo-to-sketch synthesis in particular, however, they are known to have limited abilities in generating high-resolution realistic images. To this end, we propose a novel synthesis framework called Photo-Sketch Synthesis using Multi-Adversarial Networks, (PS2-MAN) that iteratively generates low resolution to high resolution images in an adversarial way. The hidden layers of the generator are supervised to first generate lower resolution images followed by implicit refinement in the network to generate higher resolution images. Furthermore, since photo-sketch synthesis is a coupled/paired translation problem, we leverage the pair information using CycleGAN framework. Both Image Quality Assessment (IQA) and Photo-Sketch Matching experiments are conducted to demonstrate the superior performance of our framework in comparison to existing state-of-the-art solutions. Code available at: https://github.com/lidan1/PhotoSketchMAN.



### Enhanced Biologically Inspired Model for Image Recognition Based on a Novel Patch Selection Method with Moment
- **Arxiv ID**: http://arxiv.org/abs/1710.10188v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10188v1)
- **Published**: 2017-10-27 15:04:45+00:00
- **Updated**: 2017-10-27 15:04:45+00:00
- **Authors**: Yan-Feng Lu, Li-Hao Jia, Hong Qaio, Yi Li
- **Comment**: None
- **Journal**: None
- **Summary**: Biologically inspired model (BIM) for image recognition is a robust computational architecture, which has attracted widespread attention. BIM can be described as a four-layer structure based on the mechanisms of the visual cortex. Although the performance of BIM for image recognition is robust, it takes the randomly selected ways for the patch selection, which is sightless, and results in heavy computing burden. To address this issue, we propose a novel patch selection method with oriented Gaussian-Hermite moment (PSGHM), and we enhanced the BIM based on the proposed PSGHM, named as PBIM. In contrast to the conventional BIM which adopts the random method to select patches within the feature representation layers processed by multi-scale Gabor filter banks, the proposed PBIM takes the PSGHM way to extract a small number of representation features while offering promising distinctiveness. To show the effectiveness of the proposed PBIM, experimental studies on object categorization are conducted on the CalTech05, TU Darmstadt (TUD), and GRAZ01 databases. Experimental results demonstrate that the performance of PBIM is a significant improvement on that of the conventional BIM.



### Dual Path Networks for Multi-Person Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1710.10192v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10192v1)
- **Published**: 2017-10-27 15:16:51+00:00
- **Updated**: 2017-10-27 15:16:51+00:00
- **Authors**: Guanghan Ning, Zhihai He
- **Comment**: ICCV 2017 Workshop on PoseTrack Challenge. Challenge results
  available at:
  https://posetrack.net/workshops/iccv2017/posetrack-challenge-results.html
- **Journal**: None
- **Summary**: The task of multi-person human pose estimation in natural scenes is quite challenging. Existing methods include both top-down and bottom-up approaches. The main advantage of bottom-up methods is its excellent tradeoff between estimation accuracy and computational cost. We follow this path and aim to design smaller, faster, and more accurate neural networks for the regression of keypoints and limb association vectors. These two regression tasks are naturally dependent on each other. In this work, we propose a dual-path network specially designed for multi-person human pose estimation, and compare our performance with the openpose network in aspects of model size, forward speed, and estimation accuracy.



### Detection and Analysis of Human Emotions through Voice and Speech Pattern Processing
- **Arxiv ID**: http://arxiv.org/abs/1710.10198v1
- **DOI**: 10.14445/22312803/IJCTT-V52P101
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10198v1)
- **Published**: 2017-10-27 15:30:30+00:00
- **Updated**: 2017-10-27 15:30:30+00:00
- **Authors**: Poorna Banerjee Dasgupta
- **Comment**: 3 pages, Published with International Journal of Computer Trends and
  Technology (IJCTT), Volume-52 Number-1, 2017
- **Journal**: International Journal of Computer Trends and Technology (IJCTT)
  V52(1):01-03, October 2017
- **Summary**: The ability to modulate vocal sounds and generate speech is one of the features which set humans apart from other living beings. The human voice can be characterized by several attributes such as pitch, timbre, loudness, and vocal tone. It has often been observed that humans express their emotions by varying different vocal attributes during speech generation. Hence, deduction of human emotions through voice and speech analysis has a practical plausibility and could potentially be beneficial for improving human conversational and persuasion skills. This paper presents an algorithmic approach for detection and analysis of human emotions with the help of voice and speech processing. The proposed approach has been developed with the objective of incorporation with futuristic artificial intelligence systems for improving human-computer interactions.



### Separation of Water and Fat Magnetic Resonance Imaging Signals Using Deep Learning with Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1711.00107v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1711.00107v1)
- **Published**: 2017-10-27 17:36:36+00:00
- **Updated**: 2017-10-27 17:36:36+00:00
- **Authors**: James W Goldfarb
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose: A new method for magnetic resonance (MR) imaging water-fat separation using a convolutional neural network (ConvNet) and deep learning (DL) is presented. Feasibility of the method with complex and magnitude images is demonstrated with a series of patient studies and accuracy of predicted quantitative values is analyzed.   Methods: Water-fat separation of 1200 gradient-echo acquisitions from 90 imaging sessions (normal, acute and chronic myocardial infarction) was performed using a conventional model based method with modeling of R2* and off-resonance and a multi-peak fat spectrum. A U-Net convolutional neural network for calculation of water-only, fat-only, R2* and off-resonance images was trained with 900 gradient-echo Multiple and single-echo complex and magnitude input data algorithms were studied and compared to conventional extended echo modeling.   Results: The U-Net ConvNet was easily trained and provided water-fat separation results visually comparable to conventional methods. Myocardial fat deposition in chronic myocardial infarction and intramyocardial hemorrhage in acute myocardial infarction were well visualized in the DL results. Predicted values for R2*, off-resonance, water and fat signal intensities were well correlated with conventional model based water fat separation (R2>=0.97, p<0.001). DL images had a 14% higher signal-to-noise ratio (p<0.001) when compared to the conventional method.   Conclusion: Deep learning utilizing ConvNets is a feasible method for MR water-fat separationimaging with complex, magnitude and single echo image data. A trained U-Net can be efficiently used for MR water-fat separation, providing results comparable to conventional model based methods.



### Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions
- **Arxiv ID**: http://arxiv.org/abs/1710.10304v4
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1710.10304v4)
- **Published**: 2017-10-27 18:58:51+00:00
- **Updated**: 2018-02-28 18:00:49+00:00
- **Authors**: Scott Reed, Yutian Chen, Thomas Paine, Aäron van den Oord, S. M. Ali Eslami, Danilo Rezende, Oriol Vinyals, Nando de Freitas
- **Comment**: None
- **Journal**: None
- **Summary**: Deep autoregressive models have shown state-of-the-art performance in density estimation for natural images on large-scale datasets such as ImageNet. However, such models require many thousands of gradient-based weight updates and unique image examples for training. Ideally, the models would rapidly learn visual concepts from only a handful of examples, similar to the manner in which humans learns across many vision tasks. In this paper, we show how 1) neural attention and 2) meta learning techniques can be used in combination with autoregressive models to enable effective few-shot density estimation. Our proposed modifications to PixelCNN result in state-of-the art few-shot density estimation on the Omniglot dataset. Furthermore, we visualize the learned attention policy and find that it learns intuitive algorithms for simple tasks such as image mirroring on ImageNet and handwriting on Omniglot without supervision. Finally, we extend the model to natural images and demonstrate few-shot image generation on the Stanford Online Products dataset.



### Multi-modal Aggregation for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1710.10330v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10330v1)
- **Published**: 2017-10-27 20:56:35+00:00
- **Updated**: 2017-10-27 20:56:35+00:00
- **Authors**: Chen Chen, Xiaowei Zhao, Yang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a solution to Large-Scale Video Classification Challenge (LSVC2017) [1] that ranked the 1st place. We focused on a variety of modalities that cover visual, motion and audio. Also, we visualized the aggregation process to better understand how each modality takes effect. Among the extracted modalities, we found Temporal-Spatial features calculated by 3D convolution quite promising that greatly improved the performance. We attained the official metric mAP 0.8741 on the testing set with the ensemble model.



### Multi-level Residual Networks from Dynamical Systems View
- **Arxiv ID**: http://arxiv.org/abs/1710.10348v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1710.10348v2)
- **Published**: 2017-10-27 22:06:58+00:00
- **Updated**: 2018-02-01 23:25:10+00:00
- **Authors**: Bo Chang, Lili Meng, Eldad Haber, Frederick Tung, David Begert
- **Comment**: Published as a conference paper at ICLR 2018
- **Journal**: None
- **Summary**: Deep residual networks (ResNets) and their variants are widely used in many computer vision applications and natural language processing tasks. However, the theoretical principles for designing and training ResNets are still not fully understood. Recently, several points of view have emerged to try to interpret ResNet theoretically, such as unraveled view, unrolled iterative estimation and dynamical systems view. In this paper, we adopt the dynamical systems point of view, and analyze the lesioning properties of ResNet both theoretically and experimentally. Based on these analyses, we additionally propose a novel method for accelerating ResNet training. We apply the proposed method to train ResNets and Wide ResNets for three image classification benchmarks, reducing training time by more than 40% with superior or on-par accuracy.



