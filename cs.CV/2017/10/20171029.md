# Arxiv Papers in cs.CV on 2017-10-29
### A Novel Approach to Artistic Textual Visualization via GAN
- **Arxiv ID**: http://arxiv.org/abs/1710.10553v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10553v1)
- **Published**: 2017-10-29 02:39:16+00:00
- **Updated**: 2017-10-29 02:39:16+00:00
- **Authors**: Yichi Ma, Muhan Ma
- **Comment**: 6 pages, 3 figures
- **Journal**: None
- **Summary**: While the visualization of statistical data tends to a mature technology, the visualization of textual data is still in its infancy, especially for the artistic text. Due to the fact that visualization of artistic text is valuable and attractive in both art and information science, we attempt to realize this tentative idea in this article. We propose the Generative Adversarial Network based Artistic Textual Visualization (GAN-ATV) which can create paintings after analyzing the semantic content of existing poems. Our GAN-ATV consists of two main sections: natural language analysis section and visual information synthesis section. In natural language analysis section, we use Bag-of-Word (BoW) feature descriptors and a two-layer network to mine and analyze the high-level semantic information from poems. In visual information synthesis section, we design a cross-modal semantic understanding module and integrate it with Generative Adversarial Network (GAN) to create paintings, whose content are corresponding to the original poems. Moreover, in order to train our GAN-ATV and verify its performance, we establish a cross-modal artistic dataset named "Cross-Art". In the Cross-Art dataset, there are six topics and each topic has their corresponding paintings and poems. The experimental results on Cross-Art dataset are shown in this article.



### A Bayesian Data Augmentation Approach for Learning Deep Models
- **Arxiv ID**: http://arxiv.org/abs/1710.10564v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1710.10564v1)
- **Published**: 2017-10-29 05:02:14+00:00
- **Updated**: 2017-10-29 05:02:14+00:00
- **Authors**: Toan Tran, Trung Pham, Gustavo Carneiro, Lyle Palmer, Ian Reid
- **Comment**: Accepted to NISP 2017
- **Journal**: None
- **Summary**: Data augmentation is an essential part of the training process applied to deep learning models. The motivation is that a robust training process for deep learning models depends on large annotated datasets, which are expensive to be acquired, stored and processed. Therefore a reasonable alternative is to be able to automatically generate new annotated training samples using a process known as data augmentation. The dominant data augmentation approach in the field assumes that new training samples can be obtained via random geometric or appearance transformations applied to annotated training samples, but this is a strong assumption because it is unclear if this is a reliable generative model for producing new training samples. In this paper, we provide a novel Bayesian formulation to data augmentation, where new annotated training points are treated as missing variables and generated based on the distribution learned from the training set. For learning, we introduce a theoretically sound algorithm --- generalised Monte Carlo expectation maximisation, and demonstrate one possible implementation via an extension of the Generative Adversarial Network (GAN). Classification results on MNIST, CIFAR-10 and CIFAR-100 show the better performance of our proposed method compared to the current dominant data augmentation approach mentioned above --- the results also show that our approach produces better classification results than similar GAN models.



### Synthetic Iris Presentation Attack using iDCGAN
- **Arxiv ID**: http://arxiv.org/abs/1710.10565v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10565v1)
- **Published**: 2017-10-29 05:19:49+00:00
- **Updated**: 2017-10-29 05:19:49+00:00
- **Authors**: Naman Kohli, Daksha Yadav, Mayank Vatsa, Richa Singh, Afzel Noore
- **Comment**: International Joint Conference on Biometrics 2017
- **Journal**: None
- **Summary**: Reliability and accuracy of iris biometric modality has prompted its large-scale deployment for critical applications such as border control and national ID projects. The extensive growth of iris recognition systems has raised apprehensions about susceptibility of these systems to various attacks. In the past, researchers have examined the impact of various iris presentation attacks such as textured contact lenses and print attacks. In this research, we present a novel presentation attack using deep learning based synthetic iris generation. Utilizing the generative capability of deep convolutional generative adversarial networks and iris quality metrics, we propose a new framework, named as iDCGAN (iris deep convolutional generative adversarial network) for generating realistic appearing synthetic iris images. We demonstrate the effect of these synthetically generated iris images as presentation attack on iris recognition by using a commercial system. The state-of-the-art presentation attack detection framework, DESIST is utilized to analyze if it can discriminate these synthetically generated iris images from real images. The experimental results illustrate that mitigating the proposed synthetic presentation attack is of paramount importance.



### Examining CNN Representations with respect to Dataset Bias
- **Arxiv ID**: http://arxiv.org/abs/1710.10577v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10577v2)
- **Published**: 2017-10-29 08:25:51+00:00
- **Updated**: 2017-11-22 02:19:32+00:00
- **Authors**: Quanshi Zhang, Wenguan Wang, Song-Chun Zhu
- **Comment**: in AAAI 2018
- **Journal**: None
- **Summary**: Given a pre-trained CNN without any testing samples, this paper proposes a simple yet effective method to diagnose feature representations of the CNN. We aim to discover representation flaws caused by potential dataset bias. More specifically, when the CNN is trained to estimate image attributes, we mine latent relationships between representations of different attributes inside the CNN. Then, we compare the mined attribute relationships with ground-truth attribute relationships to discover the CNN's blind spots and failure modes due to dataset bias. In fact, representation flaws caused by dataset bias cannot be examined by conventional evaluation strategies based on testing images, because testing images may also have a similar bias. Experiments have demonstrated the effectiveness of our method.



### Automatic Knee Osteoarthritis Diagnosis from Plain Radiographs: A Deep Learning-Based Approach
- **Arxiv ID**: http://arxiv.org/abs/1710.10589v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10589v1)
- **Published**: 2017-10-29 10:11:14+00:00
- **Updated**: 2017-10-29 10:11:14+00:00
- **Authors**: Aleksei Tiulpin, Jérôme Thevenot, Esa Rahtu, Petri Lehenkari, Simo Saarakkala
- **Comment**: None
- **Journal**: None
- **Summary**: Knee osteoarthritis (OA) is the most common musculoskeletal disorder. OA diagnosis is currently conducted by assessing symptoms and evaluating plain radiographs, but this process suffers from subjectivity. In this study, we present a new transparent computer-aided diagnosis method based on the Deep Siamese Convolutional Neural Network to automatically score knee OA severity according to the Kellgren-Lawrence grading scale. We trained our method using the data solely from the Multicenter Osteoarthritis Study and validated it on randomly selected 3,000 subjects (5,960 knees) from Osteoarthritis Initiative dataset. Our method yielded a quadratic Kappa coefficient of 0.83 and average multiclass accuracy of 66.71\% compared to the annotations given by a committee of clinical experts. Here, we also report a radiological OA diagnosis area under the ROC curve of 0.93. We also present attention maps -- given as a class probability distribution -- highlighting the radiological features affecting the network decision. This information makes the decision process transparent for the practitioner, which builds better trust toward automatic methods. We believe that our model is useful for clinical decision making and for OA research; therefore, we openly release our training codes and the data set created in this study.



### Using the quantization error from Self-Organized Map (SOM) output for detecting critical variability in large bodies of image time series in less than a minute
- **Arxiv ID**: http://arxiv.org/abs/1710.10648v1
- **DOI**: None
- **Categories**: **cs.CY**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1710.10648v1)
- **Published**: 2017-10-29 17:05:12+00:00
- **Updated**: 2017-10-29 17:05:12+00:00
- **Authors**: Birgitta Dresp-Langley, John Mwangi Wandeto
- **Comment**: 12 pages, 10 Figures
- **Journal**: None
- **Summary**: The quantization error (QE) from SOM applied on time series of spatial contrast images with variable relative amount of white and dark pixel contents, as in monochromatic medical images or satellite images, is proven a reliable indicator of potentially critical changes in image homogeneity. The QE is shown to increase linearly with the variability in spatial contrast contents across time when contrast intensity is kept constant.



### A Study on Topological Descriptors for the Analysis of 3D Surface Texture
- **Arxiv ID**: http://arxiv.org/abs/1710.10662v1
- **DOI**: 10.1016/j.cviu.2017.10.012
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10662v1)
- **Published**: 2017-10-29 18:27:35+00:00
- **Updated**: 2017-10-29 18:27:35+00:00
- **Authors**: Matthias Zeppelzauer, Bartosz Zielinski, Mateusz Juda, Markus Seidl
- **Comment**: Preprint of Article "A Study on Topological Descriptors for the
  Analysis of 3D Surface Texture" in Elsevier Journal on Computer Vision and
  Image Understanding (CVIU): https://doi.org/10.1016/j.cviu.2017.10.012, 17
  Pages, 19 Figures, 4 Tables
- **Journal**: None
- **Summary**: Methods from computational topology are becoming more and more popular in computer vision and have shown to improve the state-of-the-art in several tasks. In this paper, we investigate the applicability of topological descriptors in the context of 3D surface analysis for the classification of different surface textures. We present a comprehensive study on topological descriptors, investigate their robustness and expressiveness and compare them with state-of-the-art methods including Convolutional Neural Networks (CNNs). Results show that class-specific information is reflected well in topological descriptors. The investigated descriptors can directly compete with non-topological descriptors and capture complementary information. As a consequence they improve the state-of-the-art when combined with non-topological descriptors.



### Discovery Radiomics with CLEAR-DR: Interpretable Computer Aided Diagnosis of Diabetic Retinopathy
- **Arxiv ID**: http://arxiv.org/abs/1710.10675v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1710.10675v1)
- **Published**: 2017-10-29 19:26:19+00:00
- **Updated**: 2017-10-29 19:26:19+00:00
- **Authors**: Devinder Kumar, Graham W. Taylor, Alexander Wong
- **Comment**: None
- **Journal**: None
- **Summary**: Objective: Radiomics-driven Computer Aided Diagnosis (CAD) has shown considerable promise in recent years as a potential tool for improving clinical decision support in medical oncology, particularly those based around the concept of Discovery Radiomics, where radiomic sequencers are discovered through the analysis of medical imaging data. One of the main limitations with current CAD approaches is that it is very difficult to gain insight or rationale as to how decisions are made, thus limiting their utility to clinicians. Methods: In this study, we propose CLEAR-DR, a novel interpretable CAD system based on the notion of CLass-Enhanced Attentive Response Discovery Radiomics for the purpose of clinical decision support for diabetic retinopathy. Results: In addition to disease grading via the discovered deep radiomic sequencer, the CLEAR-DR system also produces a visual interpretation of the decision-making process to provide better insight and understanding into the decision-making process of the system. Conclusion: We demonstrate the effectiveness and utility of the proposed CLEAR-DR system of enhancing the interpretability of diagnostic grading results for the application of diabetic retinopathy grading. Significance: CLEAR-DR can act as a potential powerful tool to address the uninterpretability issue of current CAD systems, thus improving their utility to clinicians.



### Regularization for Deep Learning: A Taxonomy
- **Arxiv ID**: http://arxiv.org/abs/1710.10686v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, stat.ML, 62M45, I.2.6; I.5
- **Links**: [PDF](http://arxiv.org/pdf/1710.10686v1)
- **Published**: 2017-10-29 20:27:51+00:00
- **Updated**: 2017-10-29 20:27:51+00:00
- **Authors**: Jan Kukačka, Vladimir Golkov, Daniel Cremers
- **Comment**: None
- **Journal**: None
- **Summary**: Regularization is one of the crucial ingredients of deep learning, yet the term regularization has various definitions, and regularization methods are often studied separately from each other. In our work we present a systematic, unifying taxonomy to categorize existing methods. We distinguish methods that affect data, network architectures, error terms, regularization terms, and optimization procedures. We do not provide all details about the listed methods; instead, we present an overview of how the methods can be sorted into meaningful categories and sub-categories. This helps revealing links and fundamental similarities between them. Finally, we include practical recommendations both for users and for developers of new regularization methods.



### High-Precision Localization Using Ground Texture
- **Arxiv ID**: http://arxiv.org/abs/1710.10687v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1710.10687v3)
- **Published**: 2017-10-29 20:39:22+00:00
- **Updated**: 2019-06-26 22:48:48+00:00
- **Authors**: Linguang Zhang, Adam Finkelstein, Szymon Rusinkiewicz
- **Comment**: None
- **Journal**: None
- **Summary**: Location-aware applications play an increasingly critical role in everyday life. However, satellite-based localization (e.g., GPS) has limited accuracy and can be unusable in dense urban areas and indoors. We introduce an image-based global localization system that is accurate to a few millimeters and performs reliable localization both indoors and outside. The key idea is to capture and index distinctive local keypoints in ground textures. This is based on the observation that ground textures including wood, carpet, tile, concrete, and asphalt may look random and homogeneous, but all contain cracks, scratches, or unique arrangements of fibers. These imperfections are persistent, and can serve as local features. Our system incorporates a downward-facing camera to capture the fine texture of the ground, together with an image processing pipeline that locates the captured texture patch in a compact database constructed offline. We demonstrate the capability of our system to robustly, accurately, and quickly locate test images on various types of outdoor and indoor ground surfaces.



### Multilinear Class-Specific Discriminant Analysis
- **Arxiv ID**: http://arxiv.org/abs/1710.10695v1
- **DOI**: 10.1016/j.patrec.2017.10.027
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10695v1)
- **Published**: 2017-10-29 21:17:09+00:00
- **Updated**: 2017-10-29 21:17:09+00:00
- **Authors**: Dat Thanh Tran, Moncef Gabbouj, Alexandros Iosifidis
- **Comment**: accepted in PRL
- **Journal**: Pattern Recognition Letters, vol. 100, pp. 131-136, 2017
- **Summary**: There has been a great effort to transfer linear discriminant techniques that operate on vector data to high-order data, generally referred to as Multilinear Discriminant Analysis (MDA) techniques. Many existing works focus on maximizing the inter-class variances to intra-class variances defined on tensor data representations. However, there has not been any attempt to employ class-specific discrimination criteria for the tensor data. In this paper, we propose a multilinear subspace learning technique suitable for applications requiring class-specific tensor models. The method maximizes the discrimination of each individual class in the feature space while retains the spatial structure of the input. We evaluate the efficiency of the proposed method on two problems, i.e. facial image analysis and stock price prediction based on limit order book data.



### On Pre-Trained Image Features and Synthetic Images for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1710.10710v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10710v2)
- **Published**: 2017-10-29 22:48:58+00:00
- **Updated**: 2017-11-16 21:46:24+00:00
- **Authors**: Stefan Hinterstoisser, Vincent Lepetit, Paul Wohlhart, Kurt Konolige
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Learning methods usually require huge amounts of training data to perform at their full potential, and often require expensive manual labeling. Using synthetic images is therefore very attractive to train object detectors, as the labeling comes for free, and several approaches have been proposed to combine synthetic and real images for training.   In this paper, we show that a simple trick is sufficient to train very effectively modern object detectors with synthetic images only: We freeze the layers responsible for feature extraction to generic layers pre-trained on real images, and train only the remaining layers with plain OpenGL rendering. Our experiments with very recent deep architectures for object recognition (Faster-RCNN, R-FCN, Mask-RCNN) and image feature extractors (InceptionResnet and Resnet) show this simple approach performs surprisingly well.



### A Saak Transform Approach to Efficient, Scalable and Robust Handwritten Digits Recognition
- **Arxiv ID**: http://arxiv.org/abs/1710.10714v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.10714v1)
- **Published**: 2017-10-29 23:05:03+00:00
- **Updated**: 2017-10-29 23:05:03+00:00
- **Authors**: Yueru Chen, Zhuwei Xu, Shanshan Cai, Yujian Lang, C. -C. Jay Kuo
- **Comment**: 5 pages, 5 figures, 5 tables
- **Journal**: None
- **Summary**: An efficient, scalable and robust approach to the handwritten digits recognition problem based on the Saak transform is proposed in this work. First, multi-stage Saak transforms are used to extract a family of joint spatial-spectral representations of input images. Then, the Saak coefficients are used as features and fed into the SVM classifier for the classification task. In order to control the size of Saak coefficients, we adopt a lossy Saak transform that uses the principal component analysis (PCA) to select a smaller set of transform kernels. The handwritten digits recognition problem is well solved by the convolutional neural network (CNN) such as the LeNet-5. We conduct a comparative study on the performance of the LeNet-5 and the Saak-transform-based solutions in terms of scalability and robustness as well as the efficiency of lossless and lossy Saak transforms under a comparable accuracy level.



