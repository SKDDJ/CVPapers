# Arxiv Papers in cs.CV on 2017-10-15
### MR fingerprinting Deep RecOnstruction NEtwork (DRONE)
- **Arxiv ID**: http://arxiv.org/abs/1710.05267v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.05267v3)
- **Published**: 2017-10-15 02:58:14+00:00
- **Updated**: 2018-04-24 21:51:19+00:00
- **Authors**: Ouri Cohen, Bo Zhu, Matthew S. Rosen
- **Comment**: 21 pages, 7 figures
- **Journal**: None
- **Summary**: PURPOSE: Demonstrate a novel fast method for reconstruction of multi-dimensional MR Fingerprinting (MRF) data using Deep Learning methods.   METHODS: A neural network (NN) is defined using the TensorFlow framework and trained on simulated MRF data computed using the Bloch equations. The accuracy of the NN reconstruction of noisy data is compared to conventional MRF template matching as a function of training data size, and quantified in a both simulated numerical brain phantom data and acquired data from the ISMRM/NIST phantom. The utility of the method is demonstrated in a healthy subject in vivo at 1.5 T.   RESULTS: Network training required 10 minutes and once trained, data reconstruction required approximately 10 ms. Reconstruction of simulated brain data using the NN resulted in a root-mean-square error (RMSE) of 3.5 ms for T1 and 7.8 ms for T2. The RMSE for the NN trained on sparse dictionaries was approximately 6 fold lower for T1 and 2 fold lower for T2 than conventional MRF dot-product dictionary matching on the same dictionaries. Phantom measurements yielded good agreement (R2=0.99) between the T1 and T2 estimated by the NN and reference values from the ISMRM/NIST phantom.   CONCLUSION: Reconstruction of MRF data with a NN is accurate, 300 fold faster and more robust to noise and undersampling than conventional MRF dictionary matching.



### Self-Supervised Visual Planning with Temporal Skip Connections
- **Arxiv ID**: http://arxiv.org/abs/1710.05268v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1710.05268v1)
- **Published**: 2017-10-15 02:58:20+00:00
- **Updated**: 2017-10-15 02:58:20+00:00
- **Authors**: Frederik Ebert, Chelsea Finn, Alex X. Lee, Sergey Levine
- **Comment**: accepted at the Conference on Robot Learning (CoRL) 2017
- **Journal**: None
- **Summary**: In order to autonomously learn wide repertoires of complex skills, robots must be able to learn from their own autonomously collected data, without human supervision. One learning signal that is always available for autonomously collected data is prediction: if a robot can learn to predict the future, it can use this predictive model to take actions to produce desired outcomes, such as moving an object to a particular location. However, in complex open-world scenarios, designing a representation for prediction is difficult. In this work, we instead aim to enable self-supervised robotic learning through direct video prediction: instead of attempting to design a good representation, we directly predict what the robot will see next, and then use this model to achieve desired goals. A key challenge in video prediction for robotic manipulation is handling complex spatial arrangements such as occlusions. To that end, we introduce a video prediction model that can keep track of objects through occlusion by incorporating temporal skip-connections. Together with a novel planning criterion and action space formulation, we demonstrate that this model substantially outperforms prior work on video prediction-based control. Our results show manipulation of objects not seen during training, handling multiple objects, and pushing objects around obstructions. These results represent a significant advance in the range and complexity of skills that can be performed entirely with self-supervised robotic learning.



### CNNComparator: Comparative Analytics of Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.05285v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, H.1.2
- **Links**: [PDF](http://arxiv.org/pdf/1710.05285v1)
- **Published**: 2017-10-15 06:43:29+00:00
- **Updated**: 2017-10-15 06:43:29+00:00
- **Authors**: Haipeng Zeng, Hammad Haleem, Xavier Plantaz, Nan Cao, Huamin Qu
- **Comment**: 5 pages. This paper has been accepted by VADL 2017: Workshop on
  Visual Analytics for Deep Learning
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) are widely used in many image recognition tasks due to their extraordinary performance. However, training a good CNN model can still be a challenging task. In a training process, a CNN model typically learns a large number of parameters over time, which usually results in different performance. Often, it is difficult to explore the relationships between the learned parameters and the model performance due to a large number of parameters and different random initializations. In this paper, we present a visual analytics approach to compare two different snapshots of a trained CNN model taken after different numbers of epochs, so as to provide some insight into the design or the training of a better CNN model. Our system compares snapshots by exploring the differences in operation parameters and the corresponding blob data at different levels. A case study has been conducted to demonstrate the effectiveness of our system.



### Vector Quantization using the Improved Differential Evolution Algorithm for Image Compression
- **Arxiv ID**: http://arxiv.org/abs/1710.05311v1
- **DOI**: 10.17605/OSF.IO/M9RNZ
- **Categories**: **cs.CV**, cs.MM, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1710.05311v1)
- **Published**: 2017-10-15 10:31:52+00:00
- **Updated**: 2017-10-15 10:31:52+00:00
- **Authors**: Sayan Nag
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: Vector Quantization, VQ is a popular image compression technique with a simple decoding architecture and high compression ratio. Codebook designing is the most essential part in Vector Quantization. LindeBuzoGray, LBG is a traditional method of generation of VQ Codebook which results in lower PSNR value. A Codebook affects the quality of image compression, so the choice of an appropriate codebook is a must. Several optimization techniques have been proposed for global codebook generation to enhance the quality of image compression. In this paper, a novel algorithm called IDE-LBG is proposed which uses Improved Differential Evolution Algorithm coupled with LBG for generating optimum VQ Codebooks. The proposed IDE works better than the traditional DE with modifications in the scaling factor and the boundary control mechanism. The IDE generates better solutions by efficient exploration and exploitation of the search space. Then the best optimal solution obtained by the IDE is provided as the initial Codebook for the LBG. This approach produces an efficient Codebook with less computational time and the consequences include excellent PSNR values and superior quality reconstructed images. It is observed that the proposed IDE-LBG find better VQ Codebooks as compared to IPSO-LBG, BA-LBG and FA-LBG.



### Towards Automatic Abdominal Multi-Organ Segmentation in Dual Energy CT using Cascaded 3D Fully Convolutional Network
- **Arxiv ID**: http://arxiv.org/abs/1710.05379v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.05379v1)
- **Published**: 2017-10-15 18:56:08+00:00
- **Updated**: 2017-10-15 18:56:08+00:00
- **Authors**: Shuqing Chen, Holger Roth, Sabrina Dorn, Matthias May, Alexander Cavallaro, Michael M. Lell, Marc Kachelrie√ü, Hirohisa Oda, Kensaku Mori, Andreas Maier
- **Comment**: 5 pagens, 4 figures, conference
- **Journal**: None
- **Summary**: Automatic multi-organ segmentation of the dual energy computed tomography (DECT) data can be beneficial for biomedical research and clinical applications. However, it is a challenging task. Recent advances in deep learning showed the feasibility to use 3-D fully convolutional networks (FCN) for voxel-wise dense predictions in single energy computed tomography (SECT). In this paper, we proposed a 3D FCN based method for automatic multi-organ segmentation in DECT. The work was based on a cascaded FCN and a general model for the major organs trained on a large set of SECT data. We preprocessed the DECT data by using linear weighting and fine-tuned the model for the DECT data. The method was evaluated using 42 torso DECT data acquired with a clinical dual-source CT system. Four abdominal organs (liver, spleen, left and right kidneys) were evaluated. Cross-validation was tested. Effect of the weight on the accuracy was researched. In all the tests, we achieved an average Dice coefficient of 93% for the liver, 90% for the spleen, 91% for the right kidney and 89% for the left kidney, respectively. The results show our method is feasible and promising.



### A systematic study of the class imbalance problem in convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1710.05381v2
- **DOI**: 10.1016/j.neunet.2018.07.011
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1710.05381v2)
- **Published**: 2017-10-15 19:01:43+00:00
- **Updated**: 2018-10-13 02:02:17+00:00
- **Authors**: Mateusz Buda, Atsuto Maki, Maciej A. Mazurowski
- **Comment**: None
- **Journal**: None
- **Summary**: In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.



