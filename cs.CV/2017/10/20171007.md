# Arxiv Papers in cs.CV on 2017-10-07
### A Transfer-Learning Approach for Accelerated MRI using Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1710.02615v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02615v3)
- **Published**: 2017-10-07 01:22:24+00:00
- **Updated**: 2019-05-04 09:43:36+00:00
- **Authors**: Salman Ul Hassan Dar, Muzaffer Özbey, Ahmet Burak Çatlı, Tolga Çukur
- **Comment**: None
- **Journal**: None
- **Summary**: Purpose: Neural networks have received recent interest for reconstruction of undersampled MR acquisitions. Ideally network performance should be optimized by drawing the training and testing data from the same domain. In practice, however, large datasets comprising hundreds of subjects scanned under a common protocol are rare. The goal of this study is to introduce a transfer-learning approach to address the problem of data scarcity in training deep networks for accelerated MRI.   Methods: Neural networks were trained on thousands of samples from public datasets of either natural images or brain MR images. The networks were then fine-tuned using only few tens of brain MR images in a distinct testing domain. Domain-transferred networks were compared to networks trained directly in the testing domain. Network performance was evaluated for varying acceleration factors (2-10), number of training samples (0.5-4k) and number of fine-tuning samples (0-100).   Results: The proposed approach achieves successful domain transfer between MR images acquired with different contrasts (T1- and T2-weighted images), and between natural and MR images (ImageNet and T1- or T2-weighted images). Networks obtained via transfer-learning using only tens of images in the testing domain achieve nearly identical performance to networks trained directly in the testing domain using thousands of images.   Conclusion: The proposed approach might facilitate the use of neural networks for MRI reconstruction without the need for collection of extensive imaging datasets.



### Deep Self-Paced Learning for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1710.05711v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1710.05711v1)
- **Published**: 2017-10-07 01:32:38+00:00
- **Updated**: 2017-10-07 01:32:38+00:00
- **Authors**: Sanping Zhou, Jinjun Wang, Deyu Meng, Xiaomeng Xin, Yubing Li, Yihong Gong, Nanning Zheng
- **Comment**: Accepted by Pattern Recognition
- **Journal**: None
- **Summary**: Person re-identification (Re-ID) usually suffers from noisy samples with background clutter and mutual occlusion, which makes it extremely difficult to distinguish different individuals across the disjoint camera views. In this paper, we propose a novel deep self-paced learning (DSPL) algorithm to alleviate this problem, in which we apply a self-paced constraint and symmetric regularization to help the relative distance metric training the deep neural network, so as to learn the stable and discriminative features for person Re-ID. Firstly, we propose a soft polynomial regularizer term which can derive the adaptive weights to samples based on both the training loss and model age. As a result, the high-confidence fidelity samples will be emphasized and the low-confidence noisy samples will be suppressed at early stage of the whole training process. Such a learning regime is naturally implemented under a self-paced learning (SPL) framework, in which samples weights are adaptively updated based on both model age and sample loss using an alternative optimization method. Secondly, we introduce a symmetric regularizer term to revise the asymmetric gradient back-propagation derived by the relative distance metric, so as to simultaneously minimize the intra-class distance and maximize the inter-class distance in each triplet unit. Finally, we build a part-based deep neural network, in which the features of different body parts are first discriminately learned in the lower convolutional layers and then fused in the higher fully connected layers. Experiments on several benchmark datasets have demonstrated the superior performance of our method as compared with the state-of-the-art approaches.



### Image Matching Using SIFT, SURF, BRIEF and ORB: Performance Comparison for Distorted Images
- **Arxiv ID**: http://arxiv.org/abs/1710.02726v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02726v1)
- **Published**: 2017-10-07 19:22:59+00:00
- **Updated**: 2017-10-07 19:22:59+00:00
- **Authors**: Ebrahim Karami, Siva Prasad, Mohamed Shehata
- **Comment**: 5 pages, 6 figures, In Proceedings of the 2015 Newfoundland
  Electrical and Computer Engineering Conference,St. johns, Canada, November,
  2015
- **Journal**: None
- **Summary**: Fast and robust image matching is a very important task with various applications in computer vision and robotics. In this paper, we compare the performance of three different image matching techniques, i.e., SIFT, SURF, and ORB, against different kinds of transformations and deformations such as scaling, rotation, noise, fish eye distortion, and shearing. For this purpose, we manually apply different types of transformations on original images and compute the matching evaluation parameters such as the number of key points in images, the matching rate, and the execution time required for each algorithm and we will show that which algorithm is the best more robust against each kind of distortion. Index Terms-Image matching, scale invariant feature transform (SIFT), speed up robust feature (SURF), robust independent elementary features (BRIEF), oriented FAST, rotated BRIEF (ORB).



### Image Identification Using SIFT Algorithm: Performance Analysis against Different Image Deformations
- **Arxiv ID**: http://arxiv.org/abs/1710.02728v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02728v2)
- **Published**: 2017-10-07 19:27:33+00:00
- **Updated**: 2018-03-13 22:26:39+00:00
- **Authors**: Ebrahim Karami, Mohamed Shehata, Andrew Smith
- **Comment**: 4 pages, 11 figures, In Proceedings of the 2015 Newfoundland
  Electrical and Computer Engineering Conference,St. johns, Canada, November,
  2015
- **Journal**: None
- **Summary**: Image identification is one of the most challenging tasks in different areas of computer vision. Scale-invariant feature transform is an algorithm to detect and describe local features in images to further use them as an image matching criteria. In this paper, the performance of the SIFT matching algorithm against various image distortions such as rotation, scaling, fisheye and motion distortion are evaluated and false and true positive rates for a large number of image pairs are calculated and presented. We also evaluate the distribution of the matched keypoint orientation difference for each image deformation.



### Texture Fuzzy Segmentation using Skew Divergence Adaptive Affinity Functions
- **Arxiv ID**: http://arxiv.org/abs/1710.02754v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1710.02754v1)
- **Published**: 2017-10-07 22:10:08+00:00
- **Updated**: 2017-10-07 22:10:08+00:00
- **Authors**: José F. S. Neto, Waldson P. N. Leandro, Matheus A. Gadelha, Tiago S. Santos, Bruno M. Carvalho, Edgar Garduño
- **Comment**: None
- **Journal**: None
- **Summary**: Digital image segmentation is the process of assigning distinct labels to different objects in a digital image, and the fuzzy segmentation algorithm has been successfully used in the segmentation of images from a wide variety of sources. However, the traditional fuzzy segmentation algorithm fails to segment objects that are characterized by textures whose patterns cannot be successfully described by simple statistics computed over a very restricted area. In this paper, we propose an extension of the fuzzy segmentation algorithm that uses adaptive textural affinity functions to perform the segmentation of such objects on bidimensional images. The adaptive affinity functions compute their appropriate neighborhood size as they compute the texture descriptors surrounding the seed spels (spatial elements), according to the characteristics of the texture being processed. The algorithm then segments the image with an appropriate neighborhood for each object. We performed experiments on mosaic images that were composed using images from the Brodatz database, and compared our results with the ones produced by a recently published texture segmentation algorithm, showing the applicability of our method.



### A New Spectral Clustering Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1710.02756v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, physics.geo-ph
- **Links**: [PDF](http://arxiv.org/pdf/1710.02756v1)
- **Published**: 2017-10-07 22:59:13+00:00
- **Updated**: 2017-10-07 22:59:13+00:00
- **Authors**: W. R. Casper, Balu Nadiga
- **Comment**: 12 pages, 9 figures
- **Journal**: None
- **Summary**: We present a new clustering algorithm that is based on searching for natural gaps in the components of the lowest energy eigenvectors of the Laplacian of a graph. In comparing the performance of the proposed method with a set of other popular methods (KMEANS, spectral-KMEANS, and an agglomerative method) in the context of the Lancichinetti-Fortunato-Radicchi (LFR) Benchmark for undirected weighted overlapping networks, we find that the new method outperforms the other spectral methods considered in certain parameter regimes. Finally, in an application to climate data involving one of the most important modes of interannual climate variability, the El Nino Southern Oscillation phenomenon, we demonstrate the ability of the new algorithm to readily identify different flavors of the phenomenon.



### Keynote: Small Neural Nets Are Beautiful: Enabling Embedded Systems with Small Deep-Neural-Network Architectures
- **Arxiv ID**: http://arxiv.org/abs/1710.02759v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1710.02759v1)
- **Published**: 2017-10-07 23:33:31+00:00
- **Updated**: 2017-10-07 23:33:31+00:00
- **Authors**: Forrest Iandola, Kurt Keutzer
- **Comment**: Keynote at Embedded Systems Week (ESWEEK) 2017
- **Journal**: None
- **Summary**: Over the last five years Deep Neural Nets have offered more accurate solutions to many problems in speech recognition, and computer vision, and these solutions have surpassed a threshold of acceptability for many applications. As a result, Deep Neural Networks have supplanted other approaches to solving problems in these areas, and enabled many new applications. While the design of Deep Neural Nets is still something of an art form, in our work we have found basic principles of design space exploration used to develop embedded microprocessor architectures to be highly applicable to the design of Deep Neural Net architectures. In particular, we have used these design principles to create a novel Deep Neural Net called SqueezeNet that requires as little as 480KB of storage for its model parameters. We have further integrated all these experiences to develop something of a playbook for creating small Deep Neural Nets for embedded systems.



