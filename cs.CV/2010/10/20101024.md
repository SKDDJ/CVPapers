# Arxiv Papers in cs.CV on 2010-10-24
### Local Component Analysis for Nonparametric Bayes Classifier
- **Arxiv ID**: http://arxiv.org/abs/1010.4951v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1010.4951v2)
- **Published**: 2010-10-24 11:28:11+00:00
- **Updated**: 2012-07-20 01:17:25+00:00
- **Authors**: Mahmoud Khademi, Mohammad T. Manzuri-Shalmani, Meharn safayani
- **Comment**: This paper has been withdrawn by the author due to an error in
  experimental results
- **Journal**: None
- **Summary**: The decision boundaries of Bayes classifier are optimal because they lead to maximum probability of correct decision. It means if we knew the prior probabilities and the class-conditional densities, we could design a classifier which gives the lowest probability of error. However, in classification based on nonparametric density estimation methods such as Parzen windows, the decision regions depend on the choice of parameters such as window width. Moreover, these methods suffer from curse of dimensionality of the feature space and small sample size problem which severely restricts their practical applications. In this paper, we address these problems by introducing a novel dimension reduction and classification method based on local component analysis. In this method, by adopting an iterative cross-validation algorithm, we simultaneously estimate the optimal transformation matrices (for dimension reduction) and classifier parameters based on local information. The proposed method can classify the data with complicated boundary and also alleviate the course of dimensionality dilemma. Experiments on real data show the superiority of the proposed algorithm in term of classification accuracies for pattern classification applications like age, facial expression and character recognition. Keywords: Bayes classifier, curse of dimensionality dilemma, Parzen window, pattern classification, subspace learning.



