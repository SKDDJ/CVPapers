# Arxiv Papers in cs.CV on 2010-10-19
### Joint interpretation of on-board vision and static GPS cartography for determination of correct speed limit
- **Arxiv ID**: http://arxiv.org/abs/1010.3867v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1010.3867v1)
- **Published**: 2010-10-19 12:03:16+00:00
- **Updated**: 2010-10-19 12:03:16+00:00
- **Authors**: Alexandre Bargeton, Fabien Moutarde, Fawzi Nashashibi, Anne-Sophie Puthon
- **Comment**: None
- **Journal**: 17th ITS world congress (ITSwc'2010), Busan : Korea, Republic Of
  (2010)
- **Summary**: We present here a first prototype of a "Speed Limit Support" Advance Driving Assistance System (ADAS) producing permanent reliable information on the current speed limit applicable to the vehicle. Such a module can be used either for information of the driver, or could even serve for automatic setting of the maximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on a joint interpretation of cartographic information (for static reference information) with on-board vision, used for traffic sign detection and recognition (including supplementary sub-signs) and visual road lines localization (for detection of lane changes). The visual traffic sign detection part is quite robust (90% global correct detection and recognition for main speed signs, and 80% for exit-lane sub-signs detection). Our approach for joint interpretation with cartography is original, and logic-based rather than probability-based, which allows correct behaviour even in cases, which do happen, when both vision and cartography may provide the same erroneous information.



### 3-D Rigid Models from Partial Views - Global Factorization
- **Arxiv ID**: http://arxiv.org/abs/1010.3935v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1010.3935v1)
- **Published**: 2010-10-19 14:45:55+00:00
- **Updated**: 2010-10-19 14:45:55+00:00
- **Authors**: Pedro M. Q. Aguiar, Rui F. C. Guerreiro, Bruno B. Gonçalves
- **Comment**: 21 pages, 16 figures
- **Journal**: None
- **Summary**: The so-called factorization methods recover 3-D rigid structure from motion by factorizing an observation matrix that collects 2-D projections of features. These methods became popular due to their robustness - they use a large number of views, which constrains adequately the solution - and computational simplicity - the large number of unknowns is computed through an SVD, avoiding non-linear optimization. However, they require that all the entries of the observation matrix are known. This is unlikely to happen in practice, due to self-occlusion and limited field of view. Also, when processing long videos, regions that become occluded often appear again later. Current factorization methods process these as new regions, leading to less accurate estimates of 3-D structure. In this paper, we propose a global factorization method that infers complete 3-D models directly from the 2-D projections in the entire set of available video frames. Our method decides whether a region that has become visible is a region that was seen before, or a previously unseen region, in a global way, i.e., by seeking the simplest rigid object that describes well the entire set of observations. This global approach increases significantly the accuracy of the estimates of the 3-D shape of the scene and the 3-D motion of the camera. Experiments with artificial and real videos illustrate the good performance of our method.



### Maximum Likelihood Mosaics
- **Arxiv ID**: http://arxiv.org/abs/1010.3947v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1010.3947v1)
- **Published**: 2010-10-19 15:13:40+00:00
- **Updated**: 2010-10-19 15:13:40+00:00
- **Authors**: Bernardo Esteves Pires, Pedro M. Q. Aguiar
- **Comment**: 13 pages, 8 figures
- **Journal**: None
- **Summary**: The majority of the approaches to the automatic recovery of a panoramic image from a set of partial views are suboptimal in the sense that the input images are aligned, or registered, pair by pair, e.g., consecutive frames of a video clip. These approaches lead to propagation errors that may be very severe, particularly when dealing with videos that show the same region at disjoint time intervals. Although some authors have proposed a post-processing step to reduce the registration errors in these situations, there have not been attempts to compute the optimal solution, i.e., the registrations leading to the panorama that best matches the entire set of partial views}. This is our goal. In this paper, we use a generative model for the partial views of the panorama and develop an algorithm to compute in an efficient way the Maximum Likelihood estimate of all the unknowns involved: the parameters describing the alignment of all the images and the panorama itself.



### ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of Unlabeled Points)
- **Arxiv ID**: http://arxiv.org/abs/1010.4021v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1010.4021v1)
- **Published**: 2010-10-19 19:48:41+00:00
- **Updated**: 2010-10-19 19:48:41+00:00
- **Authors**: José J. Rodrigues, João M. F. Xavier, Pedro M. Q. Aguiar
- **Comment**: None
- **Journal**: None
- **Summary**: In image analysis, many tasks require representing two-dimensional (2D) shape, often specified by a set of 2D points, for comparison purposes. The challenge of the representation is that it must not only capture the characteristics of the shape but also be invariant to relevant transformations. Invariance to geometric transformations, such as translation, rotation, and scale, has received attention in the past, usually under the assumption that the points are previously labeled, i.e., that the shape is characterized by an ordered set of landmarks. However, in many practical scenarios, the points describing the shape are obtained from automatic processes, e.g., edge or corner detection, thus without labels or natural ordering. Obviously, the combinatorial problem of computing the correspondences between the points of two shapes in the presence of the aforementioned geometrical distortions becomes a quagmire when the number of points is large. We circumvent this problem by representing shapes in a way that is invariant to the permutation of the landmarks, i.e., we represent bags of unlabeled 2D points. Within our framework, a shape is mapped to an analytic function on the complex plane, leading to what we call its analytic signature (ANSIG). To store an ANSIG, it suffices to sample it along a closed contour in the complex plane. We show that the ANSIG is a maximal invariant with respect to the permutation group, i.e., that different shapes have different ANSIGs and shapes that differ by a permutation (or re-labeling) of the landmarks have the same ANSIG. We further show how easy it is to factor out geometric transformations when comparing shapes using the ANSIG representation. Finally, we illustrate these capabilities with shape-based image classification experiments.



### Multiplierless Modules for Forward and Backward Integer Wavelet Transform
- **Arxiv ID**: http://arxiv.org/abs/1010.4059v3
- **DOI**: 10.1145/973620.973667
- **Categories**: **cs.AR**, cs.CV, 68-xx, 42Cxx, 65Txx, 54Hxx, 94Axx, 94-XX, 47AXX,, B.1; B.2; B.4; B.7; C.1; C.5; E.3; E.4; G.1; I.4; I.5; I.6; J.3;
  J.6; J.7
- **Links**: [PDF](http://arxiv.org/pdf/1010.4059v3)
- **Published**: 2010-10-19 21:58:14+00:00
- **Updated**: 2021-08-18 22:41:16+00:00
- **Authors**: Vasil Kolev
- **Comment**: 7 pages, The ACM proceedings of CompSysTech 2003
- **Journal**: None
- **Summary**: This article is about the architecture of a lossless wavelet filter bank with reprogrammable logic. It is based on second generation of wavelets with a reduced of number of operations. A new basic structure for parallel architecture and modules to forward and backward integer discrete wavelet transform is proposed.



