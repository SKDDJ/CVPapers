# Arxiv Papers in cs.CV on 2010-04-01
### A stochastic model of human visual attention with a dynamic Bayesian network
- **Arxiv ID**: http://arxiv.org/abs/1004.0085v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM, cs.NE, stat.ML, 68U10, I.4.8; I.4.10; I.5.1; I.6.8; I.2.10; I.4.4; I.2.9; I.3.1
- **Links**: [PDF](http://arxiv.org/pdf/1004.0085v1)
- **Published**: 2010-04-01 08:51:32+00:00
- **Updated**: 2010-04-01 08:51:32+00:00
- **Authors**: Akisato kimura, Derek Pang, Tatsuto Takeuchi, Kouji Miyazato, Junji Yamato, Kunio Kashino
- **Comment**: 24 pages, single-column, 13 figures excluding portlaits, submitted to
  IEEE Transactions on Pattern Analysis and Machine Intelligence.
- **Journal**: None
- **Summary**: Recent studies in the field of human vision science suggest that the human responses to the stimuli on a visual display are non-deterministic. People may attend to different locations on the same visual input at the same time. Based on this knowledge, we propose a new stochastic model of visual attention by introducing a dynamic Bayesian network to predict the likelihood of where humans typically focus on a video scene. The proposed model is composed of a dynamic Bayesian network with 4 layers. Our model provides a framework that simulates and combines the visual saliency response and the cognitive state of a person to estimate the most probable attended regions. Sample-based inference with Markov chain Monte-Carlo based particle filter and stream processing with multi-core processors enable us to estimate human visual attention in near real time. Experimental results have demonstrated that our model performs significantly better in predicting human visual attention compared to the previous deterministic models.



### Trends and Techniques in Visual Gaze Analysis
- **Arxiv ID**: http://arxiv.org/abs/1004.0258v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, cs.GR, cs.MM, 00A66, H.5.1; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1004.0258v1)
- **Published**: 2010-04-01 23:48:23+00:00
- **Updated**: 2010-04-01 23:48:23+00:00
- **Authors**: Sophie Stellmach, Lennart E. Nacke, Raimund Dachselt, Craig A. Lindley
- **Comment**: pages 89-93, The 5th Conference on Communication by Gaze Interaction
  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:
  978-87-643-0475-6
- **Journal**: None
- **Summary**: Visualizing gaze data is an effective way for the quick interpretation of eye tracking results. This paper presents a study investigation benefits and limitations of visual gaze analysis among eye tracking professionals and researchers. The results were used to create a tool for visual gaze analysis within a Master's project.



