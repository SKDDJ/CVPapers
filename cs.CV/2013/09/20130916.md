# Arxiv Papers in cs.CV on 2013-09-16
### Visual-Semantic Scene Understanding by Sharing Labels in a Context Network
- **Arxiv ID**: http://arxiv.org/abs/1309.3809v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1309.3809v1)
- **Published**: 2013-09-16 00:22:01+00:00
- **Updated**: 2013-09-16 00:22:01+00:00
- **Authors**: Ishani Chakraborty, Ahmed Elgammal
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the problem of naming objects in complex, natural scenes containing widely varying object appearance and subtly different names. Informed by cognitive research, we propose an approach based on sharing context based object hypotheses between visual and lexical spaces. To this end, we present the Visual Semantic Integration Model (VSIM) that represents object labels as entities shared between semantic and visual contexts and infers a new image by updating labels through context switching. At the core of VSIM is a semantic Pachinko Allocation Model and a visual nearest neighbor Latent Dirichlet Allocation Model. For inference, we derive an iterative Data Augmentation algorithm that pools the label probabilities and maximizes the joint label posterior of an image. Our model surpasses the performance of state-of-art methods in several visual tasks on the challenging SUN09 dataset.



### An iterative algorithm for computed tomography image reconstruction from limited-angle projections
- **Arxiv ID**: http://arxiv.org/abs/1310.7448v1
- **DOI**: 10.1007/s12204-015-1608-9
- **Categories**: **cs.CV**, G.1.1
- **Links**: [PDF](http://arxiv.org/pdf/1310.7448v1)
- **Published**: 2013-09-16 07:52:16+00:00
- **Updated**: 2013-09-16 07:52:16+00:00
- **Authors**: Yuli Sun, Jinxu Tao, Conggui Liu
- **Comment**: 14 pages, 1 figure, 1 table
- **Journal**: None
- **Summary**: In application of tomography imaging, limited-angle problem is a quite practical and important issue. In this paper, an iterative reprojection-reconstruction (IRR) algorithm using a modified Papoulis-Gerchberg (PG) iterative scheme is developed for reconstruction from limited-angle projections which contain noise. The proposed algorithm has two iterative update processes, one is the extrapolation of unknown data, and the other is the modification of the known noisy observation data. And the algorithm introduces scaling factors to control the two processes, respectively. The convergence of the algorithm is guaranteed, and the method of choosing the scaling factors is given with energy constraints. The simulation result demonstrates our conclusions and indicates that the algorithm proposed in this paper can obviously improve the reconstruction quality.



### Estimation of intrinsic volumes from digital grey-scale images
- **Arxiv ID**: http://arxiv.org/abs/1309.3842v1
- **DOI**: 10.1007/s10851-013-0469-9
- **Categories**: **math.ST**, cs.CV, stat.TH, 62H35
- **Links**: [PDF](http://arxiv.org/pdf/1309.3842v1)
- **Published**: 2013-09-16 07:56:12+00:00
- **Updated**: 2013-09-16 07:56:12+00:00
- **Authors**: Anne Marie Svane
- **Comment**: 33 pages
- **Journal**: None
- **Summary**: Local algorithms are common tools for estimating intrinsic volumes from black-and-white digital images. However, these algorithms are typically biased in the design based setting, even when the resolution tends to infinity. Moreover, images recorded in practice are most often blurred grey-scale images rather than black-and-white. In this paper, an extended definition of local algorithms, applying directly to grey-scale images without thresholding, is suggested. We investigate the asymptotics of these new algorithms when the resolution tends to infinity and apply this to construct estimators for surface area and integrated mean curvature that are asymptotically unbiased in certain natural settings.



### SEEDS: Superpixels Extracted via Energy-Driven Sampling
- **Arxiv ID**: http://arxiv.org/abs/1309.3848v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1309.3848v1)
- **Published**: 2013-09-16 08:23:10+00:00
- **Updated**: 2013-09-16 08:23:10+00:00
- **Authors**: Michael Van den Bergh, Xavier Boix, Gemma Roig, Luc Van Gool
- **Comment**: None
- **Journal**: None
- **Summary**: Superpixel algorithms aim to over-segment the image by grouping pixels that belong to the same object. Many state-of-the-art superpixel algorithms rely on minimizing objective functions to enforce color ho- mogeneity. The optimization is accomplished by sophis- ticated methods that progressively build the superpix- els, typically by adding cuts or growing superpixels. As a result, they are computationally too expensive for real-time applications. We introduce a new approach based on a simple hill-climbing optimization. Starting from an initial superpixel partitioning, it continuously refines the superpixels by modifying the boundaries. We define a robust and fast to evaluate energy function, based on enforcing color similarity between the bound- aries and the superpixel color histogram. In a series of experiments, we show that we achieve an excellent com- promise between accuracy and efficiency. We are able to achieve a performance comparable to the state-of- the-art, but in real-time on a single Intel i7 CPU at 2.8GHz.



### The Cyborg Astrobiologist: Matching of Prior Textures by Image Compression for Geological Mapping and Novelty Detection
- **Arxiv ID**: http://arxiv.org/abs/1309.4024v1
- **DOI**: 10.1017/S1473550413000372
- **Categories**: **cs.CV**, astro-ph.EP, astro-ph.IM, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1309.4024v1)
- **Published**: 2013-09-16 16:32:35+00:00
- **Updated**: 2013-09-16 16:32:35+00:00
- **Authors**: P. C. McGuire, A. Bonnici, K. R. Bruner, C. Gross, J. Orm√∂, R. A. Smosna, S. Walter, L. Wendt
- **Comment**: 27 pages, 3 figures, 2 tables, accepted for publication in the
  International Journal of Astrobiology
- **Journal**: International Journal of Astrobiology, 13(03), pp. 191-202 (2014)
- **Summary**: (abridged) We describe an image-comparison technique of Heidemann and Ritter that uses image compression, and is capable of: (i) detecting novel textures in a series of images, as well as of: (ii) alerting the user to the similarity of a new image to a previously-observed texture. This image-comparison technique has been implemented and tested using our Astrobiology Phone-cam system, which employs Bluetooth communication to send images to a local laptop server in the field for the image-compression analysis. We tested the system in a field site displaying a heterogeneous suite of sandstones, limestones, mudstones and coalbeds. Some of the rocks are partly covered with lichen. The image-matching procedure of this system performed very well with data obtained through our field test, grouping all images of yellow lichens together and grouping all images of a coal bed together, and giving a 91% accuracy for similarity detection. Such similarity detection could be employed to make maps of different geological units. The novelty-detection performance of our system was also rather good (a 64% accuracy). Such novelty detection may become valuable in searching for new geological units, which could be of astrobiological interest. The image-comparison technique is an unsupervised technique that is not capable of directly classifying an image as containing a particular geological feature; labeling of such geological features is done post facto by human geologists associated with this study, for the purpose of analyzing the system's performance. By providing more advanced capabilities for similarity detection and novelty detection, this image-compression technique could be useful in giving more scientific autonomy to robotic planetary rovers, and in assisting human astronauts in their geological exploration and assessment.



### Learning a Loopy Model For Semantic Segmentation Exactly
- **Arxiv ID**: http://arxiv.org/abs/1309.4061v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1309.4061v1)
- **Published**: 2013-09-16 18:30:41+00:00
- **Updated**: 2013-09-16 18:30:41+00:00
- **Authors**: Andreas Christian Mueller, Sven Behnke
- **Comment**: None
- **Journal**: None
- **Summary**: Learning structured models using maximum margin techniques has become an indispensable tool for com- puter vision researchers, as many computer vision applications can be cast naturally as an image labeling problem. Pixel-based or superpixel-based conditional random fields are particularly popular examples. Typ- ically, neighborhood graphs, which contain a large number of cycles, are used. As exact inference in loopy graphs is NP-hard in general, learning these models without approximations is usually deemed infeasible. In this work we show that, despite the theoretical hardness, it is possible to learn loopy models exactly in practical applications. To this end, we analyze the use of multiple approximate inference techniques together with cutting plane training of structural SVMs. We show that our proposed method yields exact solutions with an optimality guarantees in a computer vision application, for little additional computational cost. We also propose a dynamic caching scheme to accelerate training further, yielding runtimes that are comparable with approximate methods. We hope that this insight can lead to a reconsideration of the tractability of loopy models in computer vision.



### On Convergent Finite Difference Schemes for Variational - PDE Based Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1310.7443v1
- **DOI**: 10.1007/s40314-016-0414-9
- **Categories**: **cs.CV**, math.NA, 65N06, 65N22, 68U10, I.4.3
- **Links**: [PDF](http://arxiv.org/pdf/1310.7443v1)
- **Published**: 2013-09-16 23:07:39+00:00
- **Updated**: 2013-09-16 23:07:39+00:00
- **Authors**: V. B. S. Prasath, Juan C. Moreno
- **Comment**: 23 pages, 12 figures, 2 tables
- **Journal**: Computational and Applied Mathematics, 2017
- **Summary**: We study an adaptive anisotropic Huber functional based image restoration scheme. By using a combination of L2-L1 regularization functions, an adaptive Huber functional based energy minimization model provides denoising with edge preservation in noisy digital images. We study a convergent finite difference scheme based on continuous piecewise linear functions and use a variable splitting scheme, namely the Split Bregman, to obtain the discrete minimizer. Experimental results are given in image denoising and comparison with additive operator splitting, dual fixed point, and projected gradient schemes illustrate that the best convergence rates are obtained for our algorithm.



