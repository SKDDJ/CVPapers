# Arxiv Papers in cs.CV on 2013-08-01
### Compositional Dictionaries for Domain Adaptive Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1308.0271v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1308.0271v2)
- **Published**: 2013-08-01 17:27:31+00:00
- **Updated**: 2015-09-12 20:55:51+00:00
- **Authors**: Qiang Qiu, Rama Chellappa
- **Comment**: Transactions on Image Processing, 2015
- **Journal**: None
- **Summary**: We present a dictionary learning approach to compensate for the transformation of faces due to changes in view point, illumination, resolution, etc. The key idea of our approach is to force domain-invariant sparse coding, i.e., design a consistent sparse representation of the same face in different domains. In this way, classifiers trained on the sparse codes in the source domain consisting of frontal faces for example can be applied to the target domain (consisting of faces in different poses, illumination conditions, etc) without much loss in recognition accuracy. The approach is to first learn a domain base dictionary, and then describe each domain shift (identity, pose, illumination) using a sparse representation over the base dictionary. The dictionary adapted to each domain is expressed as sparse linear combinations of the base dictionary. In the context of face recognition, with the proposed compositional dictionary approach, a face image can be decomposed into sparse representations for a given subject, pose and illumination respectively. This approach has three advantages: first, the extracted sparse representation for a subject is consistent across domains and enables pose and illumination insensitive face recognition. Second, sparse representations for pose and illumination can subsequently be used to estimate the pose and illumination condition of a face image. Finally, by composing sparse representations for subject and the different domains, we can also perform pose alignment and illumination normalization. Extensive experiments using two public face datasets are presented to demonstrate the effectiveness of our approach for face recognition.



### Learning Robust Subspace Clustering
- **Arxiv ID**: http://arxiv.org/abs/1308.0273v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1308.0273v1)
- **Published**: 2013-08-01 17:31:37+00:00
- **Updated**: 2013-08-01 17:31:37+00:00
- **Authors**: Qiang Qiu, Guillermo Sapiro
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a low-rank transformation-learning framework to robustify subspace clustering. Many high-dimensional data, such as face images and motion sequences, lie in a union of low-dimensional subspaces. The subspace clustering problem has been extensively studied in the literature to partition such high-dimensional data into clusters corresponding to their underlying low-dimensional subspaces. However, low-dimensional intrinsic structures are often violated for real-world observations, as they can be corrupted by errors or deviate from ideal models. We propose to address this by learning a linear transformation on subspaces using matrix rank, via its convex surrogate nuclear norm, as the optimization criteria. The learned linear transformation restores a low-rank structure for data from the same subspace, and, at the same time, forces a high-rank structure for data from different subspaces. In this way, we reduce variations within the subspaces, and increase separations between the subspaces for more accurate subspace clustering. This proposed learned robust subspace clustering framework significantly enhances the performance of existing subspace clustering methods. To exploit the low-rank structures of the transformed subspaces, we further introduce a subspace clustering technique, called Robust Sparse Subspace Clustering, which efficiently combines robust PCA with sparse modeling. We also discuss the online learning of the transformation, and learning of the transformation while simultaneously reducing the data dimensionality. Extensive experiments using public datasets are presented, showing that the proposed approach significantly outperforms state-of-the-art subspace clustering methods.



### Domain-invariant Face Recognition using Learned Low-rank Transformation
- **Arxiv ID**: http://arxiv.org/abs/1308.0275v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1308.0275v1)
- **Published**: 2013-08-01 17:34:36+00:00
- **Updated**: 2013-08-01 17:34:36+00:00
- **Authors**: Qiang Qiu, Guillermo Sapiro, Ching-Hui Chen
- **Comment**: None
- **Journal**: None
- **Summary**: We present a low-rank transformation approach to compensate for face variations due to changes in visual domains, such as pose and illumination. The key idea is to learn discriminative linear transformations for face images using matrix rank as the optimization criteria. The learned linear transformations restore a shared low-rank structure for faces from the same subject, and, at the same time, force a high-rank structure for faces from different subjects. In this way, among the transformed faces, we reduce variations caused by domain changes within the classes, and increase separations between the classes for better face recognition across domains. Extensive experiments using public datasets are presented to demonstrate the effectiveness of our approach for face recognition across domains. The potential of the approach for feature extraction in generic object recognition and coded aperture design are discussed as well.



### Sparse Dictionary-based Attributes for Action Recognition and Summarization
- **Arxiv ID**: http://arxiv.org/abs/1308.0290v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1308.0290v1)
- **Published**: 2013-08-01 18:25:16+00:00
- **Updated**: 2013-08-01 18:25:16+00:00
- **Authors**: Qiang Qiu, Zhuolin Jiang, Rama Chellappa
- **Comment**: None
- **Journal**: None
- **Summary**: We present an approach for dictionary learning of action attributes via information maximization. We unify the class distribution and appearance information into an objective function for learning a sparse dictionary of action attributes. The objective function maximizes the mutual information between what has been learned and what remains to be learned in terms of appearance information and class distribution for each dictionary atom. We propose a Gaussian Process (GP) model for sparse representation to optimize the dictionary objective function. The sparse coding property allows a kernel with compact support in GP to realize a very efficient dictionary learning process. Hence we can describe an action video by a set of compact and discriminative action attributes. More importantly, we can recognize modeled action categories in a sparse feature space, which can be generalized to unseen and unmodeled action categories. Experimental results demonstrate the effectiveness of our approach in action recognition and summarization.



### MAS for video objects segmentation and tracking based on active contours and SURF descriptor
- **Arxiv ID**: http://arxiv.org/abs/1308.0315v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1308.0315v1)
- **Published**: 2013-08-01 19:45:23+00:00
- **Updated**: 2013-08-01 19:45:23+00:00
- **Authors**: Mohamed Chakroun, Ali Wali, Adel M. Alimi
- **Comment**: 6 pages
- **Journal**: IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, No 3, March 2013
- **Summary**: In computer vision, video segmentation and tracking is an important challenging issue. In this paper, we describe a new video sequences segmentation and tracking algorithm based on MAS "multi-agent systems" and SURF "Speeded Up Robust Features". Our approach consists in modelling a multi-agent system for segmenting the first image from a video sequence and tracking objects in the video sequences. The used agents are supervisor and explorator agents, they are communicating between them and they inspire in their behavior from active contours approaches. The tracking of objects is based on SURF descriptors "Speed Up Robust Features". We used the DIMA platform and "API Ateji PX" (an extension of the Java language to facilitate parallel programming on heterogeneous architectures) to implement this algorithm. The experimental results indicate that the proposed algorithm is more robust and faster than previous approaches.



### Hybrid Focal Stereo Networks for Pattern Analysis in Homogeneous Scenes
- **Arxiv ID**: http://arxiv.org/abs/1308.0365v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1308.0365v1)
- **Published**: 2013-08-01 21:58:33+00:00
- **Updated**: 2013-08-01 21:58:33+00:00
- **Authors**: Emanuel Aldea, Khurom H. Kiyani
- **Comment**: 13 pages, 6 figures, submitted to Machine Vision and Applications
- **Journal**: None
- **Summary**: In this paper we address the problem of multiple camera calibration in the presence of a homogeneous scene, and without the possibility of employing calibration object based methods. The proposed solution exploits salient features present in a larger field of view, but instead of employing active vision we replace the cameras with stereo rigs featuring a long focal analysis camera, as well as a short focal registration camera. Thus, we are able to propose an accurate solution which does not require intrinsic variation models as in the case of zooming cameras. Moreover, the availability of the two views simultaneously in each rig allows for pose re-estimation between rigs as often as necessary. The algorithm has been successfully validated in an indoor setting, as well as on a difficult scene featuring a highly dense pilgrim crowd in Makkah.



### Sparse arrays of signatures for online character recognition
- **Arxiv ID**: http://arxiv.org/abs/1308.0371v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1308.0371v2)
- **Published**: 2013-08-01 22:29:41+00:00
- **Updated**: 2013-12-01 17:17:06+00:00
- **Authors**: Benjamin Graham
- **Comment**: 10 pages, 2 figures
- **Journal**: None
- **Summary**: In mathematics the signature of a path is a collection of iterated integrals, commonly used for solving differential equations. We show that the path signature, used as a set of features for consumption by a convolutional neural network (CNN), improves the accuracy of online character recognition---that is the task of reading characters represented as a collection of paths. Using datasets of letters, numbers, Assamese and Chinese characters, we show that the first, second, and even the third iterated integrals contain useful information for consumption by a CNN.   On the CASIA-OLHWDB1.1 3755 Chinese character dataset, our approach gave a test error of 3.58%, compared with 5.61% for a traditional CNN [Ciresan et al.]. A CNN trained on the CASIA-OLHWDB1.0-1.2 datasets won the ICDAR2013 Online Isolated Chinese Character recognition competition.   Computationally, we have developed a sparse CNN implementation that make it practical to train CNNs with many layers of max-pooling. Extending the MNIST dataset by translations, our sparse CNN gets a test error of 0.31%.



