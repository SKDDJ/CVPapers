# Arxiv Papers in cs.CV on 2013-03-03
### Learning Stable Multilevel Dictionaries for Sparse Representations
- **Arxiv ID**: http://arxiv.org/abs/1303.0448v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1303.0448v2)
- **Published**: 2013-03-03 01:49:56+00:00
- **Updated**: 2013-09-25 19:21:54+00:00
- **Authors**: Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy, Andreas Spanias
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse representations using learned dictionaries are being increasingly used with success in several data processing and machine learning applications. The availability of abundant training data necessitates the development of efficient, robust and provably good dictionary learning algorithms. Algorithmic stability and generalization are desirable characteristics for dictionary learning algorithms that aim to build global dictionaries which can efficiently model any test data similar to the training samples. In this paper, we propose an algorithm to learn dictionaries for sparse representations from large scale data, and prove that the proposed learning algorithm is stable and generalizable asymptotically. The algorithm employs a 1-D subspace clustering procedure, the K-hyperline clustering, in order to learn a hierarchical dictionary with multiple levels. We also propose an information-theoretic scheme to estimate the number of atoms needed in each level of learning and develop an ensemble approach to learn robust dictionaries. Using the proposed dictionaries, the sparse code for novel test data can be computed using a low-complexity pursuit procedure. We demonstrate the stability and generalization characteristics of the proposed algorithm using simulations. We also evaluate the utility of the multilevel dictionaries in compressed recovery and subspace learning applications.



### Genetic Programming for Document Segmentation and Region Classification Using Discipulus
- **Arxiv ID**: http://arxiv.org/abs/1303.0460v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1303.0460v1)
- **Published**: 2013-03-03 05:31:42+00:00
- **Updated**: 2013-03-03 05:31:42+00:00
- **Authors**: N. Priyadharshini, M. S. Vijaya
- **Comment**: 8 pages,13 figures
- **Journal**: (IJARAI) International Journal of Advanced Research in Artificial
  Intelligence, Vol. 2, No. 2, 2013
- **Summary**: Document segmentation is a method of rending the document into distinct regions. A document is an assortment of information and a standard mode of conveying information to others. Pursuance of data from documents involves ton of human effort, time intense and might severely prohibit the usage of data systems. So, automatic information pursuance from the document has become a big issue. It is been shown that document segmentation will facilitate to beat such problems. This paper proposes a new approach to segment and classify the document regions as text, image, drawings and table. Document image is divided into blocks using Run length smearing rule and features are extracted from every blocks. Discipulus tool has been used to construct the Genetic programming based classifier model and located 97.5% classification accuracy.



### Scale Selection of Adaptive Kernel Regression by Joint Saliency Map for Nonrigid Image Registration
- **Arxiv ID**: http://arxiv.org/abs/1303.0479v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1303.0479v2)
- **Published**: 2013-03-03 09:15:25+00:00
- **Updated**: 2013-04-03 17:32:36+00:00
- **Authors**: Zhuangming Shen, Jiuai Sun, Hui Zhang, Binjie Qin
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Joint saliency map (JSM) [1] was developed to assign high joint saliency values to the corresponding saliency structures (called Joint Saliency Structures, JSSs) but zero or low joint saliency values to the outliers (or mismatches) that are introduced by missing correspondence or local large deformations between the reference and moving images to be registered. JSM guides the local structure matching in nonrigid registration by emphasizing these JSSs' sparse deformation vectors in adaptive kernel regression of hierarchical sparse deformation vectors for iterative dense deformation reconstruction. By designing an effective superpixel-based local structure scale estimator to compute the reference structure's structure scale, we further propose to determine the scale (the width) of kernels in the adaptive kernel regression through combining the structure scales to JSM-based scales of mismatch between the local saliency structures. Therefore, we can adaptively select the sample size of sparse deformation vectors to reconstruct the dense deformation vectors for accurately matching the every local structures in the two images. The experimental results demonstrate better accuracy of our method in aligning two images with missing correspondence and local large deformation than the state-of-the-art methods.



### Multiple Kernel Sparse Representations for Supervised and Unsupervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1303.0582v2
- **DOI**: 10.1109/TIP.2014.2322938
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1303.0582v2)
- **Published**: 2013-03-03 23:41:34+00:00
- **Updated**: 2013-10-04 22:06:06+00:00
- **Authors**: Jayaraman J. Thiagarajan, Karthikeyan Natesan Ramamurthy, Andreas Spanias
- **Comment**: None
- **Journal**: None
- **Summary**: In complex visual recognition tasks it is typical to adopt multiple descriptors, that describe different aspects of the images, for obtaining an improved recognition performance. Descriptors that have diverse forms can be fused into a unified feature space in a principled manner using kernel methods. Sparse models that generalize well to the test data can be learned in the unified kernel space, and appropriate constraints can be incorporated for application in supervised and unsupervised learning. In this paper, we propose to perform sparse coding and dictionary learning in the multiple kernel space, where the weights of the ensemble kernel are tuned based on graph-embedding principles such that class discrimination is maximized. In our proposed algorithm, dictionaries are inferred using multiple levels of 1-D subspace clustering in the kernel space, and the sparse codes are obtained using a simple levelwise pursuit scheme. Empirical results for object recognition and image clustering show that our algorithm outperforms existing sparse coding based approaches, and compares favorably to other state-of-the-art methods.



