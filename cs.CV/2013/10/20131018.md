# Arxiv Papers in cs.CV on 2013-10-18
### Dictionary Learning and Sparse Coding on Grassmann Manifolds: An Extrinsic Solution
- **Arxiv ID**: http://arxiv.org/abs/1310.4891v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1310.4891v1)
- **Published**: 2013-10-18 03:04:47+00:00
- **Updated**: 2013-10-18 03:04:47+00:00
- **Authors**: Mehrtash Harandi, Conrad Sanderson, Chunhua Shen, Brian C. Lovell
- **Comment**: 9 pages. Appearing in Int. Conf. Computer Vision, 2013, Australia
- **Journal**: None
- **Summary**: Recent advances in computer vision and machine learning suggest that a wide range of problems can be addressed more appropriately by considering non-Euclidean geometry. In this paper we explore sparse dictionary learning over the space of linear subspaces, which form Riemannian structures known as Grassmann manifolds. To this end, we propose to embed Grassmann manifolds into the space of symmetric matrices by an isometric mapping, which enables us to devise a closed-form solution for updating a Grassmann dictionary, atom by atom. Furthermore, to handle non-linearity in data, we propose a kernelised version of the dictionary learning algorithm. Experiments on several classification tasks (face recognition, action recognition, dynamic texture classification) show that the proposed approach achieves considerable improvements in discrimination accuracy, in comparison to state-of-the-art methods such as kernelised Affine Hull Method and graph-embedding Grassmann discriminant analysis.



### A novel sparsity and clustering regularization
- **Arxiv ID**: http://arxiv.org/abs/1310.4945v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1310.4945v2)
- **Published**: 2013-10-18 08:31:54+00:00
- **Updated**: 2014-02-20 16:41:40+00:00
- **Authors**: Xiangrong Zeng, Mário A. T. Figueiredo
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel SPARsity and Clustering (SPARC) regularizer, which is a modified version of the previous octagonal shrinkage and clustering algorithm for regression (OSCAR), where, the proposed regularizer consists of a $K$-sparse constraint and a pair-wise $\ell_{\infty}$ norm restricted on the $K$ largest components in magnitude. The proposed regularizer is able to separably enforce $K$-sparsity and encourage the non-zeros to be equal in magnitude. Moreover, it can accurately group the features without shrinking their magnitude. In fact, SPARC is closely related to OSCAR, so that the proximity operator of the former can be efficiently computed based on that of the latter, allowing using proximal splitting algorithms to solve problems with SPARC regularization. Experiments on synthetic data and with benchmark breast cancer data show that SPARC is a competitive group-sparsity inducing regularizer for regression and classification.



### On the Suitable Domain for SVM Training in Image Coding
- **Arxiv ID**: http://arxiv.org/abs/1310.5082v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1310.5082v1)
- **Published**: 2013-10-18 16:34:04+00:00
- **Updated**: 2013-10-18 16:34:04+00:00
- **Authors**: Gustavo Camps-Valls, Juan Gutiérrez, Gabriel Gómez-Pérez, Jesús Malo
- **Comment**: None
- **Journal**: Journal of Machine Learning Research, JMLR, 9(1), 49-66, 2008
- **Summary**: Conventional SVM-based image coding methods are founded on independently restricting the distortion in every image coefficient at some particular image representation. Geometrically, this implies allowing arbitrary signal distortions in an $n$-dimensional rectangle defined by the $\varepsilon$-insensitivity zone in each dimension of the selected image representation domain. Unfortunately, not every image representation domain is well-suited for such a simple, scalar-wise, approach because statistical and/or perceptual interactions between the coefficients may exist. These interactions imply that scalar approaches may induce distortions that do not follow the image statistics and/or are perceptually annoying. Taking into account these relations would imply using non-rectangular $\varepsilon$-insensitivity regions (allowing coupled distortions in different coefficients), which is beyond the conventional SVM formulation.   In this paper, we report a condition on the suitable domain for developing efficient SVM image coding schemes. We analytically demonstrate that no linear domain fulfills this condition because of the statistical and perceptual inter-coefficient relations that exist in these domains. This theoretical result is experimentally confirmed by comparing SVM learning in previously reported linear domains and in a recently proposed non-linear perceptual domain that simultaneously reduces the statistical and perceptual relations (so it is closer to fulfilling the proposed condition). These results highlight the relevance of an appropriate choice of the image representation before SVM learning.



### Advances in Hyperspectral Image Classification: Earth monitoring with statistical learning methods
- **Arxiv ID**: http://arxiv.org/abs/1310.5107v1
- **DOI**: 10.1109/MSP.2013.2279179
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1310.5107v1)
- **Published**: 2013-10-18 17:49:45+00:00
- **Updated**: 2013-10-18 17:49:45+00:00
- **Authors**: Gustavo Camps-Valls, Devis Tuia, Lorenzo Bruzzone, Jón Atli Benediktsson
- **Comment**: IEEE Signal Processing Magazine, 2013
- **Journal**: None
- **Summary**: Hyperspectral images show similar statistical properties to natural grayscale or color photographic images. However, the classification of hyperspectral images is more challenging because of the very high dimensionality of the pixels and the small number of labeled examples typically available for learning. These peculiarities lead to particular signal processing problems, mainly characterized by indetermination and complex manifolds. The framework of statistical learning has gained popularity in the last decade. New methods have been presented to account for the spatial homogeneity of images, to include user's interaction via active learning, to take advantage of the manifold structure with semisupervised learning, to extract and encode invariances, or to adapt classifiers and image representations to unseen yet similar scenes. This tutuorial reviews the main advances for hyperspectral remote sensing image classification through illustrative examples.



