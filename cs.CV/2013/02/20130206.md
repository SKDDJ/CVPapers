# Arxiv Papers in cs.CV on 2013-02-06
### Image Interpolation Using Kriging Technique for Spatial Data
- **Arxiv ID**: http://arxiv.org/abs/1302.1294v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1302.1294v1)
- **Published**: 2013-02-06 09:22:58+00:00
- **Updated**: 2013-02-06 09:22:58+00:00
- **Authors**: Firas Ajil Jassim, Fawzi Hasan Altaany
- **Comment**: 6 pages, 8 figures, 3 tables
- **Journal**: Canadian Journal on Image Processing and Computer Vision, Vol. 4
  No. 2, February 2013
- **Summary**: Image interpolation has been used spaciously by customary interpolation techniques. Recently, Kriging technique has been widely implemented in simulation area and geostatistics for prediction. In this article, Kriging technique was used instead of the classical interpolation methods to predict the unknown points in the digital image array. The efficiency of the proposed technique was proven using the PSNR and compared with the traditional interpolation techniques. The results showed that Kriging technique is almost accurate as cubic interpolation and in some images Kriging has higher accuracy. A miscellaneous test images have been used to consolidate the proposed technique.



### Hybrid Image Segmentation using Discerner Cluster in FCM and Histogram Thresholding
- **Arxiv ID**: http://arxiv.org/abs/1302.1296v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1302.1296v1)
- **Published**: 2013-02-06 09:31:59+00:00
- **Updated**: 2013-02-06 09:31:59+00:00
- **Authors**: Firas Ajil Jassim
- **Comment**: 4 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1005.4020 by other authors
- **Journal**: International Journal of Graphics & Image Processing, Vol 2, issue
  4, November 2012
- **Summary**: Image thresholding has played an important role in image segmentation. This paper presents a hybrid approach for image segmentation based on the thresholding by fuzzy c-means (THFCM) algorithm for image segmentation. The goal of the proposed approach is to find a discerner cluster able to find an automatic threshold. The algorithm is formulated by applying the standard FCM clustering algorithm to the frequencies (y-values) on the smoothed histogram. Hence, the frequencies of an image can be used instead of the conventional whole data of image. The cluster that has the highest peak which represents the maximum frequency in the image histogram will play as an excellent role in determining a discerner cluster to the grey level image. Then, the pixels belong to the discerner cluster represent an object in the gray level histogram while the other clusters represent a background. Experimental results with standard test images have been obtained through the proposed approach (THFCM).



### Kriging Interpolation Filter to Reduce High Density Salt and Pepper Noise
- **Arxiv ID**: http://arxiv.org/abs/1302.1300v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1302.1300v1)
- **Published**: 2013-02-06 09:45:18+00:00
- **Updated**: 2013-02-06 09:45:18+00:00
- **Authors**: Firas Ajil Jassim
- **Comment**: 6 pages, 10 figures, 2 tables
- **Journal**: World of Computer Science and Information Technology Journal
  (WCSIT), Vol. 3, No. 1, pp.8-14, 2013
- **Summary**: Image denoising is a critical issue in the field of digital image processing. This paper proposes a novel Salt & Pepper noise suppression by developing a Kriging Interpolation Filter (KIF) for image denoising. Gray-level images degraded with Salt & Pepper noise have been considered. A sequential search for noise detection was made using kXk window size to determine non-noisy pixels only. The non-noisy pixels are passed into Kriging interpolation method to predict their absent neighbor pixels that were noisy pixels at the first phase. The utilization of Kriging interpolation filter proves that it is very impressive to suppress high noise density. It has been found that Kriging Interpolation filter achieves noise reduction without loss of edges and detailed information. Comparisons with existing algorithms are done using quality metrics like PSNR and MSE to assess the proposed filter.



### Cloud Computing framework for Computer Vision Research:An Introduction
- **Arxiv ID**: http://arxiv.org/abs/1302.1326v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/1302.1326v1)
- **Published**: 2013-02-06 11:41:26+00:00
- **Updated**: 2013-02-06 11:41:26+00:00
- **Authors**: Yu Zhou
- **Comment**: 3 pages
- **Journal**: None
- **Summary**: Cloud computing offers the potential to help scientists to process massive number of computing resources often required in machine learning application such as computer vision problems. This proposal would like to show that which benefits can be obtained from cloud in order to help medical image analysis users (including scientists, clinicians, and research institutes). As security and privacy of algorithms are important for most of algorithms inventors, these algorithms can be hidden in a cloud to allow the users to use the algorithms as a package without any access to see/change their inside. In another word, in the user part, users send their images to the cloud and configure the algorithm via an interface. In the cloud part, the algorithms are applied to this image and the results are returned back to the user. My proposal has two parts: (1) investigate the potential of cloud computing for computer vision problems and (2) study the components of a proposed cloud-based framework for medical image analysis application and develop them (depending on the length of the internship). The investigation part will involve a study on several aspects of the problem including security, usability (for medical end users of the service), appropriate programming abstractions for vision problems, scalability and resource requirements. In the second part of this proposal I am going to thoroughly study of the proposed framework components and their relations and develop them. The proposed cloud-based framework includes an integrated environment to enable scientists and clinicians to access to the previous and current medical image analysis algorithms using a handful user interface without any access to the algorithm codes and procedures.



### Image Segmentation in Video Sequences: A Probabilistic Approach
- **Arxiv ID**: http://arxiv.org/abs/1302.1539v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1302.1539v1)
- **Published**: 2013-02-06 15:55:26+00:00
- **Updated**: 2013-02-06 15:55:26+00:00
- **Authors**: Nir Friedman, Stuart Russell
- **Comment**: Appears in Proceedings of the Thirteenth Conference on Uncertainty in
  Artificial Intelligence (UAI1997)
- **Journal**: None
- **Summary**: "Background subtraction" is an old technique for finding moving objects in a video sequence for example, cars driving on a freeway. The idea is that subtracting the current image from a timeaveraged background image will leave only nonstationary objects. It is, however, a crude approximation to the task of classifying each pixel of the current image; it fails with slow-moving objects and does not distinguish shadows from moving objects. The basic idea of this paper is that we can classify each pixel using a model of how that pixel looks when it is part of different classes. We learn a mixture-of-Gaussians classification model for each pixel using an unsupervised technique- an efficient, incremental version of EM. Unlike the standard image-averaging approach, this automatically updates the mixture component for each class according to likelihood of membership; hence slow-moving objects are handled perfectly. Our approach also identifies and eliminates shadows much more effectively than other techniques such as thresholding. Application of this method as part of the Roadwatch traffic surveillance project is expected to result in significant improvements in vehicle identification and tracking.



### Adaptive low rank and sparse decomposition of video using compressive sensing
- **Arxiv ID**: http://arxiv.org/abs/1302.1610v2
- **DOI**: 10.1109/ICIP.2013.6738210
- **Categories**: **cs.IT**, cs.CV, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1302.1610v2)
- **Published**: 2013-02-06 23:19:07+00:00
- **Updated**: 2013-05-31 20:45:03+00:00
- **Authors**: Fei Yang, Hong Jiang, Zuowei Shen, Wei Deng, Dimitris Metaxas
- **Comment**: Accepted ICIP 2013
- **Journal**: IEEE International Conference on Image Processing, ICIP 2013,
  Paper #1870
- **Summary**: We address the problem of reconstructing and analyzing surveillance videos using compressive sensing. We develop a new method that performs video reconstruction by low rank and sparse decomposition adaptively. Background subtraction becomes part of the reconstruction. In our method, a background model is used in which the background is learned adaptively as the compressive measurements are processed. The adaptive method has low latency, and is more robust than previous methods. We will present experimental results to demonstrate the advantages of the proposed method.



