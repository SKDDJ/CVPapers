# Arxiv Papers in cs.CV on 2013-02-07
### Eye-GUIDE (Eye-Gaze User Interface Design) Messaging for Physically-Impaired People
- **Arxiv ID**: http://arxiv.org/abs/1302.1649v1
- **DOI**: 10.5121/ijdps.2013.4104
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1302.1649v1)
- **Published**: 2013-02-07 06:47:54+00:00
- **Updated**: 2013-02-07 06:47:54+00:00
- **Authors**: Rommel Anacan, James Greggory Alcayde, Retchel Antegra, Leah Luna
- **Comment**: None
- **Journal**: None
- **Summary**: Eye-GUIDE is an assistive communication tool designed for the paralyzed or physically impaired people who were unable to move parts of their bodies especially people whose communications are limited only to eye movements. The prototype consists of a camera and a computer. Camera captures images then it will be send to the computer, where the computer will be the one to interpret the data. Thus, Eye-GUIDE focuses on camera-based gaze tracking. The proponent designed the prototype to perform simple tasks and provides graphical user interface in order the paralyzed or physically impaired person can easily use it.



### A Fast Learning Algorithm for Image Segmentation with Max-Pooling Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1302.1690v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1302.1690v1)
- **Published**: 2013-02-07 10:17:07+00:00
- **Updated**: 2013-02-07 10:17:07+00:00
- **Authors**: Jonathan Masci, Alessandro Giusti, Dan Cireşan, Gabriel Fricout, Jürgen Schmidhuber
- **Comment**: None
- **Journal**: None
- **Summary**: We present a fast algorithm for training MaxPooling Convolutional Networks to segment images. This type of network yields record-breaking performance in a variety of tasks, but is normally trained on a computationally expensive patch-by-patch basis. Our new method processes each training image in a single pass, which is vastly more efficient.   We validate the approach in different scenarios and report a 1500-fold speed-up. In an application to automated steel defect detection and segmentation, we obtain excellent performance with short training times.



### Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1302.1700v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1302.1700v1)
- **Published**: 2013-02-07 10:33:47+00:00
- **Updated**: 2013-02-07 10:33:47+00:00
- **Authors**: Alessandro Giusti, Dan C. Cireşan, Jonathan Masci, Luca M. Gambardella, Jürgen Schmidhuber
- **Comment**: 11 pages, 2 figures, 3 tables, 21 references, submitted to ICIP 2013
- **Journal**: International Conference on Image Processing (ICIP) 2013,
  Melbourne
- **Summary**: Deep Neural Networks now excel at image classification, detection and segmentation. When used to scan images by means of a sliding window, however, their high computational complexity can bring even the most powerful hardware to its knees. We show how dynamic programming can speedup the process by orders of magnitude, even when max-pooling layers are present.



### An ANN-based Method for Detecting Vocal Fold Pathology
- **Arxiv ID**: http://arxiv.org/abs/1302.1772v1
- **DOI**: 10.5120/10089-4722
- **Categories**: **cs.LG**, cs.CV, cs.SD
- **Links**: [PDF](http://arxiv.org/pdf/1302.1772v1)
- **Published**: 2013-02-07 15:03:24+00:00
- **Updated**: 2013-02-07 15:03:24+00:00
- **Authors**: Vahid Majidnezhad, Igor Kheidorov
- **Comment**: 4 pages, 3 figures, Published with International Journal of Computer
  Applications (IJCA)
- **Journal**: International Journal of Computer Applications 62(7):1-4, January
  2013
- **Summary**: There are different algorithms for vocal fold pathology diagnosis. These algorithms usually have three stages which are Feature Extraction, Feature Reduction and Classification. While the third stage implies a choice of a variety of machine learning methods, the first and second stages play a critical role in performance and accuracy of the classification system. In this paper we present initial study of feature extraction and feature reduction in the task of vocal fold pathology diagnosis. A new type of feature vector, based on wavelet packet decomposition and Mel-Frequency-Cepstral-Coefficients (MFCCs), is proposed. Also Principal Component Analysis (PCA) is used for feature reduction. An Artificial Neural Network is used as a classifier for evaluating the performance of our proposed method.



### Lensless Compressive Sensing Imaging
- **Arxiv ID**: http://arxiv.org/abs/1302.1789v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1302.1789v1)
- **Published**: 2013-02-07 16:00:35+00:00
- **Updated**: 2013-02-07 16:00:35+00:00
- **Authors**: Gang Huang, Hong Jiang, Kim Matthews, Paul Wilford
- **Comment**: 12 pages, 13 figures
- **Journal**: None
- **Summary**: In this paper, we propose a lensless compressive sensing imaging architecture. The architecture consists of two components, an aperture assembly and a sensor. No lens is used. The aperture assembly consists of a two dimensional array of aperture elements. The transmittance of each aperture element is independently controllable. The sensor is a single detection element, such as a single photo-conductive cell. Each aperture element together with the sensor defines a cone of a bundle of rays, and the cones of the aperture assembly define the pixels of an image. Each pixel value of an image is the integration of the bundle of rays in a cone. The sensor is used for taking compressive measurements. Each measurement is the integration of rays in the cones modulated by the transmittance of the aperture elements. A compressive sensing matrix is implemented by adjusting the transmittance of the individual aperture elements according to the values of the sensing matrix. The proposed architecture is simple and reliable because no lens is used. Furthermore, the sharpness of an image from our device is only limited by the resolution of the aperture assembly, but not affected by blurring due to defocus. The architecture can be used for capturing images of visible lights, and other spectra such as infrared, or millimeter waves. Such devices may be used in surveillance applications for detecting anomalies or extracting features such as speed of moving objects. Multiple sensors may be used with a single aperture assembly to capture multi-view images simultaneously. A prototype was built by using a LCD panel and a photoelectric sensor for capturing images of visible spectrum.



