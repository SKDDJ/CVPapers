# Arxiv Papers in cs.CV on 2013-04-09
### Kernel Reconstruction ICA for Sparse Representation
- **Arxiv ID**: http://arxiv.org/abs/1304.2490v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1304.2490v1)
- **Published**: 2013-04-09 08:45:57+00:00
- **Updated**: 2013-04-09 08:45:57+00:00
- **Authors**: Yanhui Xiao, Zhenfeng Zhu, Yao Zhao
- **Comment**: 10 pages, 5 figures
- **Journal**: None
- **Summary**: Independent Component Analysis (ICA) is an effective unsupervised tool to learn statistically independent representation. However, ICA is not only sensitive to whitening but also difficult to learn an over-complete basis. Consequently, ICA with soft Reconstruction cost(RICA) was presented to learn sparse representations with over-complete basis even on unwhitened data. Whereas RICA is infeasible to represent the data with nonlinear structure due to its intrinsic linearity. In addition, RICA is essentially an unsupervised method and can not utilize the class information. In this paper, we propose a kernel ICA model with reconstruction constraint (kRICA) to capture the nonlinear features. To bring in the class information, we further extend the unsupervised kRICA to a supervised one by introducing a discrimination constraint, namely d-kRICA. This constraint leads to learn a structured basis consisted of basis vectors from different basis subsets corresponding to different class labels. Then each subset will sparsely represent well for its own class but not for the others. Furthermore, data samples belonging to the same class will have similar representations, and thereby the learned sparse representations can take more discriminative power. Experimental results validate the effectiveness of kRICA and d-kRICA for image classification.



### Image Classification by Feature Dimension Reduction and Graph based Ranking
- **Arxiv ID**: http://arxiv.org/abs/1304.2683v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1304.2683v1)
- **Published**: 2013-04-09 18:11:08+00:00
- **Updated**: 2013-04-09 18:11:08+00:00
- **Authors**: Yao Nan, Qian Feng, Sun Zuolei
- **Comment**: 4 pages
- **Journal**: None
- **Summary**: Dimensionality reduction (DR) of image features plays an important role in image retrieval and classification tasks. Recently, two types of methods have been proposed to improve the both the accuracy and efficiency for the dimensionality reduction problem. One uses Non-negative matrix factorization (NMF) to describe the image distribution on the space of base matrix. Another one for dimension reduction trains a subspace projection matrix to project original data space into some low-dimensional subspaces which have deep architecture, so that the low-dimensional codes would be learned. At the same time, the graph based similarity learning algorithm which tries to exploit contextual information for improving the effectiveness of image rankings is also proposed for image class and retrieval problem. In this paper, after above two methods mentioned are utilized to reduce the high-dimensional features of images respectively, we learn the graph based similarity for the image classification problem. This paper compares the proposed approach with other approaches on an image database.



