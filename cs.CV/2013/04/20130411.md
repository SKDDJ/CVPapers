# Arxiv Papers in cs.CV on 2013-04-11
### Rotational Projection Statistics for 3D Local Surface Description and Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1304.3192v1
- **DOI**: 10.1007/s11263-013-0627-y
- **Categories**: **cs.CV**, I.4; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1304.3192v1)
- **Published**: 2013-04-11 04:26:52+00:00
- **Updated**: 2013-04-11 04:26:52+00:00
- **Authors**: Yulan Guo, Ferdous Sohel, Mohammed Bennamoun, Min Lu, Jianwei Wan
- **Comment**: The final publication is available at link.springer.com International
  Journal of Computer Vision 2013
- **Journal**: None
- **Summary**: Recognizing 3D objects in the presence of noise, varying mesh resolution, occlusion and clutter is a very challenging task. This paper presents a novel method named Rotational Projection Statistics (RoPS). It has three major modules: Local Reference Frame (LRF) definition, RoPS feature description and 3D object recognition. We propose a novel technique to define the LRF by calculating the scatter matrix of all points lying on the local surface. RoPS feature descriptors are obtained by rotationally projecting the neighboring points of a feature point onto 2D planes and calculating a set of statistics (including low-order central moments and entropy) of the distribution of these projected points. Using the proposed LRF and RoPS descriptor, we present a hierarchical 3D object recognition algorithm. The performance of the proposed LRF, RoPS descriptor and object recognition algorithm was rigorously tested on a number of popular and publicly available datasets. Our proposed techniques exhibited superior performance compared to existing techniques. We also showed that our method is robust with respect to noise and varying mesh resolution. Our RoPS based algorithm achieved recognition rates of 100%, 98.9%, 95.4% and 96.0% respectively when tested on the Bologna, UWA, Queen's and Ca' Foscari Venezia Datasets.



### Merging Satellite Measurements of Rainfall Using Multi-scale Imagery Technique
- **Arxiv ID**: http://arxiv.org/abs/1304.3406v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR, 94A12 (Primary), 62P12, I.4; I.4.5; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1304.3406v1)
- **Published**: 2013-04-11 19:31:57+00:00
- **Updated**: 2013-04-11 19:31:57+00:00
- **Authors**: Seyed Hamed Alemohammad, Dara Entekhabi
- **Comment**: 6 pages, 10 Figures, WCRP Open Science Conference, 2011
- **Journal**: None
- **Summary**: Several passive microwave satellites orbit the Earth and measure rainfall. These measurements have the advantage of almost full global coverage when compared to surface rain gauges. However, these satellites have low temporal revisit and missing data over some regions. Image fusion is a useful technique to fill in the gaps of one image (one satellite measurement) using another one. The proposed algorithm uses an iterative fusion scheme to integrate information from two satellite measurements. The algorithm is implemented on two datasets for 7 years of half-hourly data. The results show significant improvements in rain detection and rain intensity in the merged measurements.



