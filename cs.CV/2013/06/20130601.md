# Arxiv Papers in cs.CV on 2013-06-01
### Image Inpainting by Kriging Interpolation Technique
- **Arxiv ID**: http://arxiv.org/abs/1306.0139v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1306.0139v1)
- **Published**: 2013-06-01 19:16:43+00:00
- **Updated**: 2013-06-01 19:16:43+00:00
- **Authors**: Firas A. Jassim
- **Comment**: 6 pages, 9 figures, 1 table
- **Journal**: World of Computer Science and Information Technology Journal
  (WCSIT),Vol. 3, No. 5, pp.91-96, 2013
- **Summary**: Image inpainting is the art of predicting damaged regions of an image. The manual way of image inpainting is a time consuming. Therefore, there must be an automatic digital method for image inpainting that recovers the image from the damaged regions. In this paper, a novel statistical image inpainting algorithm based on Kriging interpolation technique was proposed. Kriging technique automatically fills the damaged region in an image using the information available from its surrounding regions in such away that it uses the spatial correlation structure of points inside the k-by-k block. Kriging has the ability to face the challenge of keeping the structure and texture information as the size of damaged region heighten. Experimental results showed that, Kriging has a high PSNR value when recovering a variety of test images from scratches and text as damaged regions.



### An Analysis of the Connections Between Layers of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1306.0152v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1306.0152v1)
- **Published**: 2013-06-01 21:37:25+00:00
- **Updated**: 2013-06-01 21:37:25+00:00
- **Authors**: Eugenio Culurciello, Jonghoon Jin, Aysegul Dundar, Jordan Bates
- **Comment**: None
- **Journal**: None
- **Summary**: We present an analysis of different techniques for selecting the connection be- tween layers of deep neural networks. Traditional deep neural networks use ran- dom connection tables between layers to keep the number of connections small and tune to different image features. This kind of connection performs adequately in supervised deep networks because their values are refined during the training. On the other hand, in unsupervised learning, one cannot rely on back-propagation techniques to learn the connections between layers. In this work, we tested four different techniques for connecting the first layer of the network to the second layer on the CIFAR and SVHN datasets and showed that the accuracy can be im- proved up to 3% depending on the technique used. We also showed that learning the connections based on the co-occurrences of the features does not confer an advantage over a random connection table in small networks. This work is helpful to improve the efficiency of connections between the layers of unsupervised deep neural networks.



