# Arxiv Papers in cs.CV on 2013-06-29
### Approximate Bayesian Image Interpretation using Generative Probabilistic Graphics Programs
- **Arxiv ID**: http://arxiv.org/abs/1307.0060v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1307.0060v1)
- **Published**: 2013-06-29 02:36:45+00:00
- **Updated**: 2013-06-29 02:36:45+00:00
- **Authors**: Vikash K. Mansinghka, Tejas D. Kulkarni, Yura N. Perov, Joshua B. Tenenbaum
- **Comment**: The first two authors contributed equally to this work
- **Journal**: None
- **Summary**: The idea of computer vision as the Bayesian inverse problem to computer graphics has a long history and an appealing elegance, but it has proved difficult to directly implement. Instead, most vision tasks are approached via complex bottom-up processing pipelines. Here we show that it is possible to write short, simple probabilistic graphics programs that define flexible generative models and to automatically invert them to interpret real-world images. Generative probabilistic graphics programs consist of a stochastic scene generator, a renderer based on graphics software, a stochastic likelihood model linking the renderer's output and the data, and latent variables that adjust the fidelity of the renderer and the tolerance of the likelihood model. Representations and algorithms from computer graphics, originally designed to produce high-quality images, are instead used as the deterministic backbone for highly approximate and stochastic generative models. This formulation combines probabilistic programming, computer graphics, and approximate Bayesian computation, and depends only on general-purpose, automatic inference techniques. We describe two applications: reading sequences of degraded and adversarially obscured alphanumeric characters, and inferring 3D road models from vehicle-mounted camera images. Each of the probabilistic graphics programs we present relies on under 20 lines of probabilistic code, and supports accurate, approximately Bayesian inferences about ambiguous real-world images.



### Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint
- **Arxiv ID**: http://arxiv.org/abs/1307.0129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1307.0129v1)
- **Published**: 2013-06-29 16:57:44+00:00
- **Updated**: 2013-06-29 16:57:44+00:00
- **Authors**: Roozbeh Rajabi, Hassan Ghassemian
- **Comment**: 4 pages, conference
- **Journal**: None
- **Summary**: Hyperspectral images contain mixed pixels due to low spatial resolution of hyperspectral sensors. Mixed pixels are pixels containing more than one distinct material called endmembers. The presence percentages of endmembers in mixed pixels are called abundance fractions. Spectral unmixing problem refers to decomposing these pixels into a set of endmembers and abundance fractions. Due to nonnegativity constraint on abundance fractions, nonnegative matrix factorization methods (NMF) have been widely used for solving spectral unmixing problem. In this paper we have used graph regularized (GNMF) method with sparseness constraint to unmix hyperspectral data. This method applied on simulated data using AVIRIS Indian Pines dataset and USGS library and results are quantified based on AAD and SAD measures. Results in comparison with other methods show that the proposed method can unmix data more effectively.



