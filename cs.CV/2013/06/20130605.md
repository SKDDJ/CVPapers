# Arxiv Papers in cs.CV on 2013-06-05
### Distributed Bayesian inference for consistent labeling of tracked objects in non-overlapping camera networks
- **Arxiv ID**: http://arxiv.org/abs/1306.0974v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1306.0974v1)
- **Published**: 2013-06-05 03:50:58+00:00
- **Updated**: 2013-06-05 03:50:58+00:00
- **Authors**: Jiuqing Wan, Li Liu
- **Comment**: 19 pages, 8 figures
- **Journal**: None
- **Summary**: One of the fundamental requirements for visual surveillance using non-overlapping camera networks is the correct labeling of tracked objects on each camera in a consistent way,in the sense that the captured tracklets, or observations in this paper, of the same object at different cameras should be assigned with the same label. In this paper, we formulate this task as a Bayesian inference problem and propose a distributed inference framework in which the posterior distribution of labeling variable corresponding to each observation, conditioned on all history appearance and spatio-temporal evidence made in the whole networks, is calculated based solely on local information processing on each camera and mutual information exchanging between neighboring cameras. In our framework, the number of objects presenting in the monitored region, i.e. the sampling space of labeling variables, does not need to be specified beforehand. Instead, it can be determined automatically on the fly. In addition, we make no assumption about the appearance distribution of a single object, but use similarity scores between appearance pairs, given by advanced object re-identification algorithm, as appearance likelihood for inference. This feature makes our method very flexible and competitive when observing condition undergoes large changes across camera views. To cope with the problem of missing detection, which is critical for distributed inference, we consider an enlarged neighborhood of each camera during inference and use a mixture model to describe the higher order spatio-temporal constraints. The robustness of the algorithm against missing detection is improved at the cost of slightly increased computation and communication burden at each camera node. Finally, we demonstrate the effectiveness of our method through experiments on an indoor Office Building dataset and an outdoor Campus Garden dataset.



### Quaternion Fourier Transform on Quaternion Fields and Generalizations
- **Arxiv ID**: http://arxiv.org/abs/1306.1023v1
- **DOI**: 10.1007/s00006-007-0037-8
- **Categories**: **math.RA**, cs.CV, math-ph, math.MP, Primary 42A38, Secondary 11R52
- **Links**: [PDF](http://arxiv.org/pdf/1306.1023v1)
- **Published**: 2013-06-05 09:10:52+00:00
- **Updated**: 2013-06-05 09:10:52+00:00
- **Authors**: Eckhard Hitzer
- **Comment**: 21 pages
- **Journal**: Advances in Applied Clifford Algebras, olume 17, Issue 3 , pp.
  497-517 (2007)
- **Summary**: We treat the quaternionic Fourier transform (QFT) applied to quaternion fields and investigate QFT properties useful for applications. Different forms of the QFT lead us to different Plancherel theorems. We relate the QFT computation for quaternion fields to the QFT of real signals. We research the general linear ($GL$) transformation behavior of the QFT with matrices, Clifford geometric algebra and with examples. We finally arrive at wide-ranging non-commutative multivector FT generalizations of the QFT. Examples given are new volume-time and spacetime algebra Fourier transformations.



### ROTUNDE - A Smart Meeting Cinematography Initiative: Tools, Datasets, and Benchmarks for Cognitive Interpretation and Control
- **Arxiv ID**: http://arxiv.org/abs/1306.1034v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1306.1034v1)
- **Published**: 2013-06-05 09:40:24+00:00
- **Updated**: 2013-06-05 09:40:24+00:00
- **Authors**: Mehul Bhatt, Jakob Suchan, Christian Freksa
- **Comment**: Appears in AAAI-2013 Workshop on: Space, Time, and Ambient
  Intelligence (STAMI 2013)
- **Journal**: None
- **Summary**: We construe smart meeting cinematography with a focus on professional situations such as meetings and seminars, possibly conducted in a distributed manner across socio-spatially separated groups. The basic objective in smart meeting cinematography is to interpret professional interactions involving people, and automatically produce dynamic recordings of discussions, debates, presentations etc in the presence of multiple communication modalities. Typical modalities include gestures (e.g., raising one's hand for a question, applause), voice and interruption, electronic apparatus (e.g., pressing a button), movement (e.g., standing-up, moving around) etc. ROTUNDE, an instance of smart meeting cinematography concept, aims to: (a) develop functionality-driven benchmarks with respect to the interpretation and control capabilities of human-cinematographers, real-time video editors, surveillance personnel, and typical human performance in everyday situations; (b) Develop general tools for the commonsense cognitive interpretation of dynamic scenes from the viewpoint of visuo-spatial cognition centred perceptual narrativisation. Particular emphasis is placed on declarative representations and interfacing mechanisms that seamlessly integrate within large-scale cognitive (interaction) systems and companion technologies consisting of diverse AI sub-components. For instance, the envisaged tools would provide general capabilities for high-level commonsense reasoning about space, events, actions, change, and interaction.



### Discriminative Parameter Estimation for Random Walks Segmentation: Technical Report
- **Arxiv ID**: http://arxiv.org/abs/1306.1083v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1306.1083v1)
- **Published**: 2013-06-05 12:48:02+00:00
- **Updated**: 2013-06-05 12:48:02+00:00
- **Authors**: Pierre-Yves Baudin, Danny Goodman, Puneet Kumar, Noura Azzabou, Pierre G. Carlier, Nikos Paragios, M. Pawan Kumar
- **Comment**: None
- **Journal**: None
- **Summary**: The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use probabilistic segmentation methods. By combining contrast terms with prior terms, it provides accurate segmentations of medical images in a fully automated manner. However, one of the main drawbacks of using the RW algorithm is that its parameters have to be hand-tuned. we propose a novel discriminative learning framework that estimates the parameters using a training dataset. The main challenge we face is that the training samples are not fully supervised. Speci cally, they provide a hard segmentation of the images, instead of a proba-bilistic segmentation. We overcome this challenge by treating the optimal probabilistic segmentation that is compatible with the given hard segmentation as a latent variable. This allows us to employ the latent support vector machine formulation for parameter estimation. We show that our approach signi cantly outperforms the baseline methods on a challenging dataset consisting of real clinical 3D MRI volumes of skeletal muscles.



