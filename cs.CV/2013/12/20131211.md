# Arxiv Papers in cs.CV on 2013-12-11
### Heat kernel coupling for multiple graph analysis
- **Arxiv ID**: http://arxiv.org/abs/1312.3035v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.3035v1)
- **Published**: 2013-12-11 04:59:49+00:00
- **Updated**: 2013-12-11 04:59:49+00:00
- **Authors**: Michael M. Bronstein, Klaus Glashoff
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce heat kernel coupling (HKC) as a method of constructing multimodal spectral geometry on weighted graphs of different size without vertex-wise bijective correspondence. We show that Laplacian averaging can be derived as a limit case of HKC, and demonstrate its applications on several problems from the manifold learning and pattern recognition domain.



### Fast Approximate $K$-Means via Cluster Closures
- **Arxiv ID**: http://arxiv.org/abs/1312.3061v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.3061v1)
- **Published**: 2013-12-11 08:02:09+00:00
- **Updated**: 2013-12-11 08:02:09+00:00
- **Authors**: Jingdong Wang, Jing Wang, Qifa Ke, Gang Zeng, Shipeng Li
- **Comment**: None
- **Journal**: None
- **Summary**: $K$-means, a simple and effective clustering algorithm, is one of the most widely used algorithms in multimedia and computer vision community. Traditional $k$-means is an iterative algorithm---in each iteration new cluster centers are computed and each data point is re-assigned to its nearest center. The cluster re-assignment step becomes prohibitively expensive when the number of data points and cluster centers are large.   In this paper, we propose a novel approximate $k$-means algorithm to greatly reduce the computational complexity in the assignment step. Our approach is motivated by the observation that most active points changing their cluster assignments at each iteration are located on or near cluster boundaries. The idea is to efficiently identify those active points by pre-assembling the data into groups of neighboring points using multiple random spatial partition trees, and to use the neighborhood information to construct a closure for each cluster, in such a way only a small number of cluster candidates need to be considered when assigning a data point to its nearest cluster. Using complexity analysis, image data clustering, and applications to image retrieval, we show that our approach out-performs state-of-the-art approximate $k$-means algorithms in terms of clustering quality and efficiency.



### Fast Neighborhood Graph Search using Cartesian Concatenation
- **Arxiv ID**: http://arxiv.org/abs/1312.3062v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.3062v1)
- **Published**: 2013-12-11 08:02:29+00:00
- **Updated**: 2013-12-11 08:02:29+00:00
- **Authors**: Jingdong Wang, Jing Wang, Gang Zeng, Rui Gan, Shipeng Li, Baining Guo
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a new data structure for approximate nearest neighbor search. This structure augments the neighborhood graph with a bridge graph. We propose to exploit Cartesian concatenation to produce a large set of vectors, called bridge vectors, from several small sets of subvectors. Each bridge vector is connected with a few reference vectors near to it, forming a bridge graph. Our approach finds nearest neighbors by simultaneously traversing the neighborhood graph and the bridge graph in the best-first strategy. The success of our approach stems from two factors: the exact nearest neighbor search over a large number of bridge vectors can be done quickly, and the reference vectors connected to a bridge (reference) vector near the query are also likely to be near the query. Experimental results on searching over large scale datasets (SIFT, GIST and HOG) show that our approach outperforms state-of-the-art ANN search algorithms in terms of efficiency and accuracy. The combination of our approach with the IVFADC system also shows superior performance over the BIGANN dataset of $1$ billion SIFT features compared with the best previously published result.



### Thickness Mapping of Eleven Retinal Layers in Normal Eyes Using Spectral Domain Optical Coherence Tomography
- **Arxiv ID**: http://arxiv.org/abs/1312.3199v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.3199v1)
- **Published**: 2013-12-11 15:00:53+00:00
- **Updated**: 2013-12-11 15:00:53+00:00
- **Authors**: Raheleh Kafieh, Hossein Rabbani, Fedra Hajizadeh, Michael D. Abramoff, Milan Sonka
- **Comment**: 32 pages, 10 figures
- **Journal**: None
- **Summary**: Purpose. This study was conducted to determine the thickness map of eleven retinal layers in normal subjects by spectral domain optical coherence tomography (SD-OCT) and evaluate their association with sex and age. Methods. Mean regional retinal thickness of 11 retinal layers were obtained by automatic three-dimensional diffusion-map-based method in 112 normal eyes of 76 Iranian subjects. Results. The thickness map of central foveal area in layer 1, 3, and 4 displayed the minimum thickness (P<0.005 for all). Maximum thickness was observed in nasal to the fovea of layer 1 (P<0.001) and in a circular pattern in the parafoveal retinal area of layers 2, 3 and 4 and in central foveal area of layer 6 (P<0.001). Temporal and inferior quadrants of the total retinal thickness and most of other quadrants of layer 1 were significantly greater in the men than in the women. Surrounding eight sectors of total retinal thickness and a limited number of sectors in layer 1 and 4 significantly correlated with age. Conclusion. SD-OCT demonstrated the three-dimensional thickness distribution of retinal layers in normal eyes. Thickness of layers varied with sex and age and in different sectors. These variables should be considered while evaluating macular thickness.



### Associative embeddings for large-scale knowledge transfer with self-assessment
- **Arxiv ID**: http://arxiv.org/abs/1312.3240v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.3240v2)
- **Published**: 2013-12-11 16:59:21+00:00
- **Updated**: 2014-07-30 13:21:36+00:00
- **Authors**: Alexander Vezhnevets, Vittorio Ferrari
- **Comment**: A final CVPR version with a correction in (1). IEEE Computer Vision
  and Pattern Recognition, 2014
- **Journal**: None
- **Summary**: We propose a method for knowledge transfer between semantically related classes in ImageNet. By transferring knowledge from the images that have bounding-box annotations to the others, our method is capable of automatically populating ImageNet with many more bounding-boxes and even pixel-level segmentations. The underlying assumption that objects from semantically related classes look alike is formalized in our novel Associative Embedding (AE) representation. AE recovers the latent low-dimensional space of appearance variations among image windows. The dimensions of AE space tend to correspond to aspects of window appearance (e.g. side view, close up, background). We model the overlap of a window with an object using Gaussian Processes (GP) regression, which spreads annotation smoothly through AE space. The probabilistic nature of GP allows our method to perform self-assessment, i.e. assigning a quality estimate to its own output. It enables trading off the amount of returned annotations for their quality. A large scale experiment on 219 classes and 0.5 million images demonstrates that our method outperforms state-of-the-art methods and baselines for both object localization and segmentation. Using self-assessment we can automatically return bounding-box annotations for 30% of all images with high localization accuracy (i.e.~73% average overlap with ground-truth).



