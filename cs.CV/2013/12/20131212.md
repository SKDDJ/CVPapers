# Arxiv Papers in cs.CV on 2013-12-12
### Unsupervised learning of depth and motion
- **Arxiv ID**: http://arxiv.org/abs/1312.3429v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1312.3429v2)
- **Published**: 2013-12-12 10:03:47+00:00
- **Updated**: 2013-12-16 16:11:52+00:00
- **Authors**: Kishore Konda, Roland Memisevic
- **Comment**: None
- **Journal**: None
- **Summary**: We present a model for the joint estimation of disparity and motion. The model is based on learning about the interrelations between images from multiple cameras, multiple frames in a video, or the combination of both. We show that learning depth and motion cues, as well as their combinations, from data is possible within a single type of architecture and a single type of learning algorithm, by using biologically inspired "complex cell" like units, which encode correlations between the pixels across image pairs. Our experimental results show that the learning of depth and motion makes it possible to achieve state-of-the-art performance in 3-D activity analysis, and to outperform existing hand-engineered 3-D motion features by a very large margin.



### Sparse Matrix-based Random Projection for Classification
- **Arxiv ID**: http://arxiv.org/abs/1312.3522v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1312.3522v3)
- **Published**: 2013-12-12 15:26:57+00:00
- **Updated**: 2014-10-12 22:10:13+00:00
- **Authors**: Weizhi Lu, Weiyu Li, Kidiyo Kpalma, Joseph Ronsin
- **Comment**: None
- **Journal**: None
- **Summary**: As a typical dimensionality reduction technique, random projection can be simply implemented with linear projection, while maintaining the pairwise distances of high-dimensional data with high probability. Considering this technique is mainly exploited for the task of classification, this paper is developed to study the construction of random matrix from the viewpoint of feature selection, rather than of traditional distance preservation. This yields a somewhat surprising theoretical result, that is, the sparse random matrix with exactly one nonzero element per column, can present better feature selection performance than other more dense matrices, if the projection dimension is sufficiently large (namely, not much smaller than the number of feature elements); otherwise, it will perform comparably to others. For random projection, this theoretical result implies considerable improvement on both complexity and performance, which is widely confirmed with the classification experiments on both synthetic data and real data.



