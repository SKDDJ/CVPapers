# Arxiv Papers in cs.CV on 2013-12-19
### Some Improvements on Deep Convolutional Neural Network Based Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1312.5402v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.5402v1)
- **Published**: 2013-12-19 04:23:23+00:00
- **Updated**: 2013-12-19 04:23:23+00:00
- **Authors**: Andrew G. Howard
- **Comment**: None
- **Journal**: None
- **Summary**: We investigate multiple techniques to improve upon the current state of the art deep convolutional neural network based image classification pipeline. The techiques include adding more image transformations to training data, adding more transformations to generate additional predictions at test time and using complementary models applied to higher resolution images. This paper summarizes our entry in the Imagenet Large Scale Visual Recognition Challenge 2013. Our system achieved a top 5 classification error rate of 13.55% using no external data which is over a 20% relative improvement on the previous year's winner.



### Delegating Custom Object Detection Tasks to a Universal Classification System
- **Arxiv ID**: http://arxiv.org/abs/1401.6126v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T10, I.2.10; I.4.7; I.4.8; I.4.9; I.5; I.5.2; I.5.4; I.5.5
- **Links**: [PDF](http://arxiv.org/pdf/1401.6126v1)
- **Published**: 2013-12-19 08:17:24+00:00
- **Updated**: 2013-12-19 08:17:24+00:00
- **Authors**: Andrew Gleibman
- **Comment**: 3 pages, 2 figures, 6 refs. arXiv admin note: substantial text
  overlap with arXiv:1310.7170
- **Journal**: None
- **Summary**: In this paper, a concept of multipurpose object detection system, recently introduced in our previous work, is clarified. The business aspect of this method is transformation of a classifier into an object detector/locator via an image grid. This is a universal framework for locating objects of interest through classification. The framework standardizes and simplifies implementation of custom systems by doing only a custom analysis of the classification results on the image grid.



### Sparse similarity-preserving hashing
- **Arxiv ID**: http://arxiv.org/abs/1312.5479v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DS
- **Links**: [PDF](http://arxiv.org/pdf/1312.5479v3)
- **Published**: 2013-12-19 11:04:40+00:00
- **Updated**: 2014-02-16 20:37:10+00:00
- **Authors**: Jonathan Masci, Alex M. Bronstein, Michael M. Bronstein, Pablo Sprechmann, Guillermo Sapiro
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, a lot of attention has been devoted to efficient nearest neighbor search by means of similarity-preserving hashing. One of the plights of existing hashing techniques is the intrinsic trade-off between performance and computational complexity: while longer hash codes allow for lower false positive rates, it is very difficult to increase the embedding dimensionality without incurring in very high false negatives rates or prohibiting computational costs. In this paper, we propose a way to overcome this limitation by enforcing the hash codes to be sparse. Sparse high-dimensional codes enjoy from the low false positive rates typical of long hashes, while keeping the false negative rates similar to those of a shorter dense hashing scheme with equal number of degrees of freedom. We use a tailored feed-forward neural network for the hashing function. Extensive experimental evaluation involving visual and multi-modal data shows the benefits of the proposed method.



### An Adaptive Dictionary Learning Approach for Modeling Dynamical Textures
- **Arxiv ID**: http://arxiv.org/abs/1312.5568v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.5568v1)
- **Published**: 2013-12-19 14:41:29+00:00
- **Updated**: 2013-12-19 14:41:29+00:00
- **Authors**: Xian Wei, Hao Shen, Martin Kleinsteuber
- **Comment**: None
- **Journal**: None
- **Summary**: Video representation is an important and challenging task in the computer vision community. In this paper, we assume that image frames of a moving scene can be modeled as a Linear Dynamical System. We propose a sparse coding framework, named adaptive video dictionary learning (AVDL), to model a video adaptively. The developed framework is able to capture the dynamics of a moving scene by exploring both sparse properties and the temporal correlations of consecutive video frames. The proposed method is compared with state of the art video processing methods on several benchmark data sequences, which exhibit appearance changes and heavy occlusions.



### Learning Transformations for Classification Forests
- **Arxiv ID**: http://arxiv.org/abs/1312.5604v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1312.5604v2)
- **Published**: 2013-12-19 16:01:41+00:00
- **Updated**: 2014-02-06 12:24:54+00:00
- **Authors**: Qiang Qiu, Guillermo Sapiro
- **Comment**: arXiv admin note: text overlap with arXiv:1309.2074
- **Journal**: None
- **Summary**: This work introduces a transformation-based learner model for classification forests. The weak learner at each split node plays a crucial role in a classification tree. We propose to optimize the splitting objective by learning a linear transformation on subspaces using nuclear norm as the optimization criteria. The learned linear transformation restores a low-rank structure for data from the same class, and, at the same time, maximizes the separation between different classes, thereby improving the performance of the split function. Theoretical and experimental results support the proposed framework.



### Using Web Co-occurrence Statistics for Improving Image Categorization
- **Arxiv ID**: http://arxiv.org/abs/1312.5697v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1312.5697v2)
- **Published**: 2013-12-19 18:53:47+00:00
- **Updated**: 2013-12-20 18:12:16+00:00
- **Authors**: Samy Bengio, Jeff Dean, Dumitru Erhan, Eugene Ie, Quoc Le, Andrew Rabinovich, Jonathon Shlens, Yoram Singer
- **Comment**: None
- **Journal**: None
- **Summary**: Object recognition and localization are important tasks in computer vision. The focus of this work is the incorporation of contextual information in order to improve object recognition and localization. For instance, it is natural to expect not to see an elephant to appear in the middle of an ocean. We consider a simple approach to encapsulate such common sense knowledge using co-occurrence statistics from web documents. By merely counting the number of times nouns (such as elephants, sharks, oceans, etc.) co-occur in web documents, we obtain a good estimate of expected co-occurrences in visual data. We then cast the problem of combining textual co-occurrence statistics with the predictions of image-based classifiers as an optimization problem. The resulting optimization problem serves as a surrogate for our inference procedure. Albeit the simplicity of the resulting optimization problem, it is effective in improving both recognition and localization accuracy. Concretely, we observe significant improvements in recognition and localization rates for both ImageNet Detection 2012 and Sun 2012 datasets.



