# Arxiv Papers in cs.CV on 2013-12-18
### Evaluation of Plane Detection with RANSAC According to Density of 3D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/1312.5033v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1312.5033v1)
- **Published**: 2013-12-18 03:33:14+00:00
- **Updated**: 2013-12-18 03:33:14+00:00
- **Authors**: Tomofumi Fujiwara, Tetsushi Kamegawa, Akio Gofuku
- **Comment**: 3 pages
- **Journal**: None
- **Summary**: We have implemented a method that detects planar regions from 3D scan data using Random Sample Consensus (RANSAC) algorithm to address the issue of a trade-off between the scanning speed and the point density of 3D scanning. However, the limitation of the implemented method has not been clear yet. In this paper, we conducted an additional experiment to evaluate the implemented method by changing its parameter and environments in both high and low point density data. As a result, the number of detected planes in high point density data was different from that in low point density data with the same parameter value.



### Comparative analysis of evolutionary algorithms for image enhancement
- **Arxiv ID**: http://arxiv.org/abs/1312.5045v1
- **DOI**: 10.1504/IJMHEUR.2012.048219
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1312.5045v1)
- **Published**: 2013-12-18 05:33:27+00:00
- **Updated**: 2013-12-18 05:33:27+00:00
- **Authors**: Anupriya Gogna, Akash Tayal
- **Comment**: None
- **Journal**: International Journal of Metaheuristics Volume 2 Issue 1, July
  2012 Pages 80-100
- **Summary**: Evolutionary algorithms are metaheuristic techniques that derive inspiration from the natural process of evolution. They can efficiently solve (generate acceptable quality of solution in reasonable time) complex optimization (NP-Hard) problems. In this paper, automatic image enhancement is considered as an optimization problem and three evolutionary algorithms (Genetic Algorithm, Differential Evolution and Self Organizing Migration Algorithm) are employed to search for an optimum solution. They are used to find an optimum parameter set for an image enhancement transfer function. The aim is to maximize a fitness criterion which is a measure of image contrast and the visibility of details in the enhanced image. The enhancement results obtained using all three evolutionary algorithms are compared amongst themselves and also with the output of histogram equalization method.



### Stable Camera Motion Estimation Using Convex Programming
- **Arxiv ID**: http://arxiv.org/abs/1312.5047v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.5047v3)
- **Published**: 2013-12-18 06:04:26+00:00
- **Updated**: 2015-01-15 22:46:03+00:00
- **Authors**: Onur Ozyesil, Amit Singer, Ronen Basri
- **Comment**: 40 pages, 12 figures, 6 tables; notation and some unclear parts
  updated, some typos corrected
- **Journal**: None
- **Summary**: We study the inverse problem of estimating n locations $t_1, ..., t_n$ (up to global scale, translation and negation) in $R^d$ from noisy measurements of a subset of the (unsigned) pairwise lines that connect them, that is, from noisy measurements of $\pm (t_i - t_j)/\|t_i - t_j\|$ for some pairs (i,j) (where the signs are unknown). This problem is at the core of the structure from motion (SfM) problem in computer vision, where the $t_i$'s represent camera locations in $R^3$. The noiseless version of the problem, with exact line measurements, has been considered previously under the general title of parallel rigidity theory, mainly in order to characterize the conditions for unique realization of locations. For noisy pairwise line measurements, current methods tend to produce spurious solutions that are clustered around a few locations. This sensitivity of the location estimates is a well-known problem in SfM, especially for large, irregular collections of images.   In this paper we introduce a semidefinite programming (SDP) formulation, specially tailored to overcome the clustering phenomenon. We further identify the implications of parallel rigidity theory for the location estimation problem to be well-posed, and prove exact (in the noiseless case) and stable location recovery results. We also formulate an alternating direction method to solve the resulting semidefinite program, and provide a distributed version of our formulation for large numbers of locations. Specifically for the camera location estimation problem, we formulate a pairwise line estimation method based on robust camera orientation and subspace estimation. Lastly, we demonstrate the utility of our algorithm through experiments on real images.



### Unsupervised feature learning by augmenting single images
- **Arxiv ID**: http://arxiv.org/abs/1312.5242v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1312.5242v3)
- **Published**: 2013-12-18 17:44:17+00:00
- **Updated**: 2014-02-16 13:07:23+00:00
- **Authors**: Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox
- **Comment**: ICLR 2014 workshop track submission (7 pages, 4 figures, 1 table)
- **Journal**: None
- **Summary**: When deep learning is applied to visual object recognition, data augmentation is often used to generate additional training data without extra labeling cost. It helps to reduce overfitting and increase the performance of the algorithm. In this paper we investigate if it is possible to use data augmentation as the main component of an unsupervised feature learning architecture. To that end we sample a set of random image patches and declare each of them to be a separate single-image surrogate class. We then extend these trivial one-element classes by applying a variety of transformations to the initial 'seed' patches. Finally we train a convolutional neural network to discriminate between these surrogate classes. The feature representation learned by the network can then be used in various vision tasks. We find that this simple feature learning algorithm is surprisingly successful, achieving competitive classification results on several popular vision datasets (STL-10, CIFAR-10, Caltech-101).



### Generative NeuroEvolution for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1312.5355v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1312.5355v1)
- **Published**: 2013-12-18 22:14:31+00:00
- **Updated**: 2013-12-18 22:14:31+00:00
- **Authors**: Phillip Verbancsics, Josh Harguess
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: An important goal for the machine learning (ML) community is to create approaches that can learn solutions with human-level capability. One domain where humans have held a significant advantage is visual processing. A significant approach to addressing this gap has been machine learning approaches that are inspired from the natural systems, such as artificial neural networks (ANNs), evolutionary computation (EC), and generative and developmental systems (GDS). Research into deep learning has demonstrated that such architectures can achieve performance competitive with humans on some visual tasks; however, these systems have been primarily trained through supervised and unsupervised learning algorithms. Alternatively, research is showing that evolution may have a significant role in the development of visual systems. Thus this paper investigates the role neuro-evolution (NE) can take in deep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting Topologies is a NE approach that can effectively learn large neural structures by training an indirect encoding that compresses the ANN weight pattern as a function of geometry. The results show that HyperNEAT struggles with performing image classification by itself, but can be effective in training a feature extractor that other ML approaches can learn from. Thus NeuroEvolution combined with other ML methods provides an intriguing area of research that can replicate the processes in nature.



