# Arxiv Papers in cs.CV on 2013-12-15
### A robust Iris recognition method on adverse conditions
- **Arxiv ID**: http://arxiv.org/abs/1312.4124v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.4124v1)
- **Published**: 2013-12-15 08:54:45+00:00
- **Updated**: 2013-12-15 08:54:45+00:00
- **Authors**: Maryam Soltanali Khalili, Hamed Sadjedi
- **Comment**: None
- **Journal**: International Journal of Computer Science, Engineering and
  Information Technology (IJCSEIT), Vol.3,No.5,October 2013
- **Summary**: As a stable biometric system, iris has recently attracted great attention among the researchers. However, research is still needed to provide appropriate solutions to ensure the resistance of the system against error factors. The present study has tried to apply a mask to the image so that the unexpected factors affecting the location of the iris can be removed. So, pupil localization will be faster and robust. Then to locate the exact location of the iris, a simple stage of boundary displacement due to the Canny edge detector has been applied. Then, with searching left and right IRIS edge point, outer radios of IRIS will be detect. Through the process of extracting the iris features, it has been sought to obtain the distinctive iris texture features by using a discrete stationary wavelets transform 2-D (DSWT2). Using DSWT2 tool and symlet 4 wavelet, distinctive features are extracted. To reduce the computational cost, the features obtained from the application of the wavelet have been investigated and a feature selection procedure, using similarity criteria, has been implemented. Finally, the iris matching has been performed using a semi-correlation criterion. The accuracy of the proposed method for localization on CASIA-v1, CASIA-v3 is 99.73%, 98.24% and 97.04%, respectively. The accuracy of the feature extraction proposed method for CASIA3 iris images database is 97.82%, which confirms the efficiency of the proposed method.



### Face Detection from still and Video Images using Unsupervised Cellular Automata with K means clustering algorithm
- **Arxiv ID**: http://arxiv.org/abs/1312.6834v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.6834v1)
- **Published**: 2013-12-15 15:43:52+00:00
- **Updated**: 2013-12-15 15:43:52+00:00
- **Authors**: P. Kiran Sree, I. Ramesh Babu
- **Comment**: ICGST-GVIP Journal, ISSN: 1687-398X, Volume 8, Issue 2, July 2008
- **Journal**: None
- **Summary**: Pattern recognition problem rely upon the features inherent in the pattern of images. Face detection and recognition is one of the challenging research areas in the field of computer vision. In this paper, we present a method to identify skin pixels from still and video images using skin color. Face regions are identified from this skin pixel region. Facial features such as eyes, nose and mouth are then located. Faces are recognized from color images using an RBF based neural network. Unsupervised Cellular Automata with K means clustering algorithm is used to locate different facial elements. Orientation is corrected by using eyes. Parameters like inter eye distance, nose length, mouth position, Discrete Cosine Transform (DCT) coefficients etc. are computed and used for a Radial Basis Function (RBF) based neural network. This approach reliably works for face sequence with orientation in head, expressions etc.



### One-Shot-Learning Gesture Recognition using HOG-HOF Features
- **Arxiv ID**: http://arxiv.org/abs/1312.4190v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1312.4190v2)
- **Published**: 2013-12-15 20:58:21+00:00
- **Updated**: 2014-02-15 17:47:11+00:00
- **Authors**: Jakub Konečný, Michal Hagara
- **Comment**: 20 pages, 10 figures, 2 tables To appear in Journal of Machine
  Learning Research subject to minor revision
- **Journal**: None
- **Summary**: The purpose of this paper is to describe one-shot-learning gesture recognition systems developed on the \textit{ChaLearn Gesture Dataset}. We use RGB and depth images and combine appearance (Histograms of Oriented Gradients) and motion descriptors (Histogram of Optical Flow) for parallel temporal segmentation and recognition. The Quadratic-Chi distance family is used to measure differences between histograms to capture cross-bin relationships. We also propose a new algorithm for trimming videos --- to remove all the unimportant frames from videos. We present two methods that use combination of HOG-HOF descriptors together with variants of Dynamic Time Warping technique. Both methods outperform other published methods and help narrow down the gap between human performance and algorithms on this task. The code has been made publicly available in the MLOSS repository.



