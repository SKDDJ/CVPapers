# Arxiv Papers in cs.CV on 2013-07-04
### Further results on dissimilarity spaces for hyperspectral images RF-CBIR
- **Arxiv ID**: http://arxiv.org/abs/1307.1289v1
- **DOI**: 10.1016/j.patrec.2013.05.025
- **Categories**: **cs.IR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1307.1289v1)
- **Published**: 2013-07-04 11:58:04+00:00
- **Updated**: 2013-07-04 11:58:04+00:00
- **Authors**: Miguel Angel Veganzones, Mihai Datcu, Manuel Gra√±a
- **Comment**: In Pattern Recognition Letters (2013)
- **Journal**: Pattern Recognition Letters 34, 14 (2013) 1659-1668
- **Summary**: Content-Based Image Retrieval (CBIR) systems are powerful search tools in image databases that have been little applied to hyperspectral images. Relevance feedback (RF) is an iterative process that uses machine learning techniques and user's feedback to improve the CBIR systems performance. We pursued to expand previous research in hyperspectral CBIR systems built on dissimilarity functions defined either on spectral and spatial features extracted by spectral unmixing techniques, or on dictionaries extracted by dictionary-based compressors. These dissimilarity functions were not suitable for direct application in common machine learning techniques. We propose to use a RF general approach based on dissimilarity spaces which is more appropriate for the application of machine learning algorithms to the hyperspectral RF-CBIR. We validate the proposed RF method for hyperspectral CBIR systems over a real hyperspectral dataset.



### Toward Guaranteed Illumination Models for Non-Convex Objects
- **Arxiv ID**: http://arxiv.org/abs/1307.1437v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1307.1437v1)
- **Published**: 2013-07-04 18:08:19+00:00
- **Updated**: 2013-07-04 18:08:19+00:00
- **Authors**: Yuqian Zhang, Cun Mu, Han-wen Kuo, John Wright
- **Comment**: None
- **Journal**: None
- **Summary**: Illumination variation remains a central challenge in object detection and recognition. Existing analyses of illumination variation typically pertain to convex, Lambertian objects, and guarantee quality of approximation in an average case sense. We show that it is possible to build V(vertex)-description convex cone models with worst-case performance guarantees, for non-convex Lambertian objects. Namely, a natural verification test based on the angle to the constructed cone guarantees to accept any image which is sufficiently well-approximated by an image of the object under some admissible lighting condition, and guarantees to reject any image that does not have a sufficiently good approximation. The cone models are generated by sampling point illuminations with sufficient density, which follows from a new perturbation bound for point images in the Lambertian model. As the number of point images required for guaranteed verification may be large, we introduce a new formulation for cone preserving dimensionality reduction, which leverages tools from sparse and low-rank decomposition to reduce the complexity, while controlling the approximation error with respect to the original cone.



