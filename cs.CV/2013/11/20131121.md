# Arxiv Papers in cs.CV on 2013-11-21
### Texture descriptor combining fractal dimension and artificial crawlers
- **Arxiv ID**: http://arxiv.org/abs/1311.5290v1
- **DOI**: 10.1016/j.physa.2013.10.011
- **Categories**: **physics.data-an**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1311.5290v1)
- **Published**: 2013-11-21 01:51:03+00:00
- **Updated**: 2013-11-21 01:51:03+00:00
- **Authors**: Wesley Nunes Gon√ßalves, Bruno Brandoli Machado, Odemir Martinez Bruno
- **Comment**: 12 pages 9 figures. Paper in press: Physica A: Statistical Mechanics
  and its Applications
- **Journal**: None
- **Summary**: Texture is an important visual attribute used to describe images. There are many methods available for texture analysis. However, they do not capture the details richness of the image surface. In this paper, we propose a new method to describe textures using the artificial crawler model. This model assumes that each agent can interact with the environment and each other. Since this swarm system alone does not achieve a good discrimination, we developed a new method to increase the discriminatory power of artificial crawlers, together with the fractal dimension theory. Here, we estimated the fractal dimension by the Bouligand-Minkowski method due to its precision in quantifying structural properties of images. We validate our method on two texture datasets and the experimental results reveal that our method leads to highly discriminative textural features. The results indicate that our method can be used in different texture applications.



### Adaptive Learning of Region-based pLSA Model for Total Scene Annotation
- **Arxiv ID**: http://arxiv.org/abs/1311.5590v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1311.5590v1)
- **Published**: 2013-11-21 21:36:23+00:00
- **Updated**: 2013-11-21 21:36:23+00:00
- **Authors**: Yuzhu Zhou, Le Li, Honggang Zhang
- **Comment**: Volume 2, Page 131-136. 2010 International Conference on Information
  and Multimedia Technology
- **Journal**: None
- **Summary**: In this paper, we present a region-based pLSA model to accomplish the task of total scene annotation. To be more specific, we not only properly generate a list of tags for each image, but also localizing each region with its corresponding tag. We integrate advantages of different existing region-based works: employ efficient and powerful JSEG algorithm for segmentation so that each region can easily express meaningful object information; the introduction of pLSA model can help better capturing semantic information behind the low-level features. Moreover, we also propose an adaptive padding mechanism to automatically choose the optimal padding strategy for each region, which directly increases the overall system performance. Finally we conduct 3 experiments to verify our ideas on Corel database and demonstrate the effectiveness and accuracy of our system.



### PANDA: Pose Aligned Networks for Deep Attribute Modeling
- **Arxiv ID**: http://arxiv.org/abs/1311.5591v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1311.5591v2)
- **Published**: 2013-11-21 21:43:12+00:00
- **Updated**: 2014-05-05 21:32:36+00:00
- **Authors**: Ning Zhang, Manohar Paluri, Marc'Aurelio Ranzato, Trevor Darrell, Lubomir Bourdev
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: We propose a method for inferring human attributes (such as gender, hair style, clothes style, expression, action) from images of people under large variation of viewpoint, pose, appearance, articulation and occlusion. Convolutional Neural Nets (CNN) have been shown to perform very well on large scale object recognition problems. In the context of attribute classification, however, the signal is often subtle and it may cover only a small part of the image, while the image is dominated by the effects of pose and viewpoint. Discounting for pose variation would require training on very large labeled datasets which are not presently available. Part-based models, such as poselets and DPM have been shown to perform well for this problem but they are limited by shallow low-level features. We propose a new method which combines part-based models and deep learning by training pose-normalized CNNs. We show substantial improvement vs. state-of-the-art methods on challenging attribute classification tasks in unconstrained settings. Experiments confirm that our method outperforms both the best part-based methods on this problem and conventional CNNs trained on the full bounding box of the person.



