# Arxiv Papers in cs.CV on 2013-01-21
### Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots
- **Arxiv ID**: http://arxiv.org/abs/1301.4862v1
- **DOI**: 10.1016/j.robot.2012.05.008
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1301.4862v1)
- **Published**: 2013-01-21 13:26:07+00:00
- **Updated**: 2013-01-21 13:26:07+00:00
- **Authors**: Adrien Baranes, Pierre-Yves Oudeyer
- **Comment**: None
- **Journal**: Baranes, A., Oudeyer, P-Y. (2013) Active Learning of Inverse
  Models with Intrinsically Motivated Goal Exploration in Robots, Robotics and
  Autonomous Systems, 61(1), pp. 49-73
- **Summary**: We introduce the Self-Adaptive Goal Generation - Robust Intelligent Adaptive Curiosity (SAGG-RIAC) architecture as an intrinsi- cally motivated goal exploration mechanism which allows active learning of inverse models in high-dimensional redundant robots. This allows a robot to efficiently and actively learn distributions of parameterized motor skills/policies that solve a corresponding distribution of parameterized tasks/goals. The architecture makes the robot sample actively novel parameterized tasks in the task space, based on a measure of competence progress, each of which triggers low-level goal-directed learning of the motor policy pa- rameters that allow to solve it. For both learning and generalization, the system leverages regression techniques which allow to infer the motor policy parameters corresponding to a given novel parameterized task, and based on the previously learnt correspondences between policy and task parameters. We present experiments with high-dimensional continuous sensorimotor spaces in three different robotic setups: 1) learning the inverse kinematics in a highly-redundant robotic arm, 2) learning omnidirectional locomotion with motor primitives in a quadruped robot, 3) an arm learning to control a fishing rod with a flexible wire. We show that 1) exploration in the task space can be a lot faster than exploration in the actuator space for learning inverse models in redundant robots; 2) selecting goals maximizing competence progress creates developmental trajectories driving the robot to progressively focus on tasks of increasing complexity and is statistically significantly more efficient than selecting tasks randomly, as well as more efficient than different standard active motor babbling methods; 3) this architecture allows the robot to actively discover which parts of its task space it can learn to reach and which part it cannot.



