# Arxiv Papers in cs.CV on 2013-01-28
### Image registration with sparse approximations in parametric dictionaries
- **Arxiv ID**: http://arxiv.org/abs/1301.6646v2
- **DOI**: 10.1137/130907872
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.6646v2)
- **Published**: 2013-01-28 19:06:44+00:00
- **Updated**: 2013-07-04 14:21:42+00:00
- **Authors**: Alhussein Fawzi, Pascal Frossard
- **Comment**: None
- **Journal**: SIAM Journal on Imaging Sciences 2013 6:4, 2370-2403
- **Summary**: We examine in this paper the problem of image registration from the new perspective where images are given by sparse approximations in parametric dictionaries of geometric functions. We propose a registration algorithm that looks for an estimate of the global transformation between sparse images by examining the set of relative geometrical transformations between the respective features. We propose a theoretical analysis of our registration algorithm and we derive performance guarantees based on two novel important properties of redundant dictionaries, namely the robust linear independence and the transformation inconsistency. We propose several illustrations and insights about the importance of these dictionary properties and show that common properties such as coherence or restricted isometry property fail to provide sufficient information in registration problems. We finally show with illustrative experiments on simple visual objects and handwritten digits images that our algorithm outperforms baseline competitor methods in terms of transformation-invariant distance computation and classification.



### Guarantees of Total Variation Minimization for Signal Recovery
- **Arxiv ID**: http://arxiv.org/abs/1301.6791v6
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, cs.LG, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1301.6791v6)
- **Published**: 2013-01-28 22:01:22+00:00
- **Updated**: 2013-10-11 16:47:24+00:00
- **Authors**: Jian-Feng Cai, Weiyu Xu
- **Comment**: lower bounds added; version with Gaussian width, improved bounds;
  stability results added
- **Journal**: None
- **Summary**: In this paper, we consider using total variation minimization to recover signals whose gradients have a sparse support, from a small number of measurements. We establish the proof for the performance guarantee of total variation (TV) minimization in recovering \emph{one-dimensional} signal with sparse gradient support. This partially answers the open problem of proving the fidelity of total variation minimization in such a setting \cite{TVMulti}. In particular, we have shown that the recoverable gradient sparsity can grow linearly with the signal dimension when TV minimization is used. Recoverable sparsity thresholds of TV minimization are explicitly computed for 1-dimensional signal by using the Grassmann angle framework. We also extend our results to TV minimization for multidimensional signals. Stability of recovering signal itself using 1-D TV minimization has also been established through a property called "almost Euclidean property for 1-dimensional TV norm". We further give a lower bound on the number of random Gaussian measurements for recovering 1-dimensional signal vectors with $N$ elements and $K$-sparse gradients. Interestingly, the number of needed measurements is lower bounded by $\Omega((NK)^{\frac{1}{2}})$, rather than the $O(K\log(N/K))$ bound frequently appearing in recovering $K$-sparse signal vectors.



