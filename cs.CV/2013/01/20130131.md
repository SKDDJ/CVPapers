# Arxiv Papers in cs.CV on 2013-01-31
### Multi-scale Discriminant Saliency with Wavelet-based Hidden Markov Tree Modelling
- **Arxiv ID**: http://arxiv.org/abs/1301.7641v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.7641v2)
- **Published**: 2013-01-31 15:20:17+00:00
- **Updated**: 2013-06-06 05:33:16+00:00
- **Authors**: Anh Cat Le Ngo, Kenneth Li-Minn Ang, Guoping Qiu, Jasmine Kah-Phooi Seng
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1301.3964
- **Journal**: None
- **Summary**: The bottom-up saliency, an early stage of humans' visual attention, can be considered as a binary classification problem between centre and surround classes. Discriminant power of features for the classification is measured as mutual information between distributions of image features and corresponding classes . As the estimated discrepancy very much depends on considered scale level, multi-scale structure and discriminant power are integrated by employing discrete wavelet features and Hidden Markov Tree (HMT). With wavelet coefficients and Hidden Markov Tree parameters, quad-tree like label structures are constructed and utilized in maximum a posterior probability (MAP) of hidden class variables at corresponding dyadic sub-squares. Then, a saliency value for each square block at each scale level is computed with discriminant power principle. Finally, across multiple scales is integrated the final saliency map by an information maximization rule. Both standard quantitative tools such as NSS, LCC, AUC and qualitative assessments are used for evaluating the proposed multi-scale discriminant saliency (MDIS) method against the well-know information based approach AIM on its released image collection with eye-tracking data. Simulation results are presented and analysed to verify the validity of MDIS as well as point out its limitation for further research direction.



### Fast non parametric entropy estimation for spatial-temporal saliency method
- **Arxiv ID**: http://arxiv.org/abs/1301.7661v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.7661v1)
- **Published**: 2013-01-31 16:05:26+00:00
- **Updated**: 2013-01-31 16:05:26+00:00
- **Authors**: Anh Cat Le Ngo, Guoping Qiu, Geoff Underwood, Kenneth Li-Minn Ang, Jasmine Kah-Phooi Seng
- **Comment**: None
- **Journal**: None
- **Summary**: This paper formulates bottom-up visual saliency as center surround conditional entropy and presents a fast and efficient technique for the computation of such a saliency map. It is shown that the new saliency formulation is consistent with self-information based saliency, decision-theoretic saliency and Bayesian definition of surprises but also faces the same significant computational challenge of estimating probability density in very high dimensional spaces with limited samples. We have developed a fast and efficient nonparametric method to make the practical implementation of these types of saliency maps possible. By aligning pixels from the center and surround regions and treating their location coordinates as random variables, we use a k-d partitioning method to efficiently estimating the center surround conditional entropy. We present experimental results on two publicly available eye tracking still image databases and show that the new technique is competitive with state of the art bottom-up saliency computational methods. We have also extended the technique to compute spatiotemporal visual saliency of video and evaluate the bottom-up spatiotemporal saliency against eye tracking data on a video taken onboard a moving vehicle with the driver's eye being tracked by a head mounted eye-tracker.



