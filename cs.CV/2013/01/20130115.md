# Arxiv Papers in cs.CV on 2013-01-15
### Learning Graphical Model Parameters with Approximate Marginal Inference
- **Arxiv ID**: http://arxiv.org/abs/1301.3193v1
- **DOI**: 10.1109/TPAMI.2013.31
- **Categories**: **cs.LG**, cs.CV, I.2.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1301.3193v1)
- **Published**: 2013-01-15 01:07:14+00:00
- **Updated**: 2013-01-15 01:07:14+00:00
- **Authors**: Justin Domke
- **Comment**: To Appear, IEEE Transactions on Pattern Analysis and Machine
  Intelligence
- **Journal**: None
- **Summary**: Likelihood based-learning of graphical models faces challenges of computational-complexity and robustness to model mis-specification. This paper studies methods that fit parameters directly to maximize a measure of the accuracy of predicted marginals, taking into account both model and inference approximations at training time. Experiments on imaging problems suggest marginalization-based learning performs better than likelihood-based approximations on difficult problems where the model being fit is approximate in nature.



### Auto-pooling: Learning to Improve Invariance of Image Features from Image Sequences
- **Arxiv ID**: http://arxiv.org/abs/1301.3323v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1301.3323v4)
- **Published**: 2013-01-15 12:47:39+00:00
- **Updated**: 2013-03-18 07:19:31+00:00
- **Authors**: Sainbayar Sukhbaatar, Takaki Makino, Kazuyuki Aihara
- **Comment**: 9 pages, 10 figures. Submission for ICLR 2013
- **Journal**: None
- **Summary**: Learning invariant representations from images is one of the hardest challenges facing computer vision. Spatial pooling is widely used to create invariance to spatial shifting, but it is restricted to convolutional models. In this paper, we propose a novel pooling method that can learn soft clustering of features from image sequences. It is trained to improve the temporal coherence of features, while keeping the information loss at minimum. Our method does not use spatial information, so it can be used with non-convolutional models too. Experiments on images extracted from natural videos showed that our method can cluster similar features together. When trained by convolutional features, auto-pooling outperformed traditional spatial pooling on an image classification task, even though it does not use the spatial topology of features.



### Barnes-Hut-SNE
- **Arxiv ID**: http://arxiv.org/abs/1301.3342v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1301.3342v2)
- **Published**: 2013-01-15 13:44:18+00:00
- **Updated**: 2013-03-08 11:00:32+00:00
- **Authors**: Laurens van der Maaten
- **Comment**: None
- **Journal**: None
- **Summary**: The paper presents an O(N log N)-implementation of t-SNE -- an embedding technique that is commonly used for the visualization of high-dimensional data in scatter plots and that normally runs in O(N^2). The new implementation uses vantage-point trees to compute sparse pairwise similarities between the input data objects, and it uses a variant of the Barnes-Hut algorithm - an algorithm used by astronomers to perform N-body simulations - to approximate the forces between the corresponding points in the embedding. Our experiments show that the new algorithm, called Barnes-Hut-SNE, leads to substantial computational advantages over standard t-SNE, and that it makes it possible to learn embeddings of data sets with millions of objects.



### Recurrent Online Clustering as a Spatio-Temporal Feature Extractor in DeSTIN
- **Arxiv ID**: http://arxiv.org/abs/1301.3385v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.3385v2)
- **Published**: 2013-01-15 15:34:07+00:00
- **Updated**: 2013-01-16 14:56:44+00:00
- **Authors**: Steven R. Young, Itamar Arel
- **Comment**: 3 pages, 2 figures, Submitted to ICLR 2013
- **Journal**: None
- **Summary**: This paper presents a basic enhancement to the DeSTIN deep learning architecture by replacing the explicitly calculated transition tables that are used to capture temporal features with a simpler, more scalable mechanism. This mechanism uses feedback of state information to cluster over a space comprised of both the spatial input and the current state. The resulting architecture achieves state-of-the-art results on the MNIST classification benchmark.



### Pooling-Invariant Image Feature Learning
- **Arxiv ID**: http://arxiv.org/abs/1302.5056v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1302.5056v1)
- **Published**: 2013-01-15 18:47:11+00:00
- **Updated**: 2013-01-15 18:47:11+00:00
- **Authors**: Yangqing Jia, Oriol Vinyals, Trevor Darrell
- **Comment**: None
- **Journal**: None
- **Summary**: Unsupervised dictionary learning has been a key component in state-of-the-art computer vision recognition architectures. While highly effective methods exist for patch-based dictionary learning, these methods may learn redundant features after the pooling stage in a given early vision architecture. In this paper, we offer a novel dictionary learning scheme to efficiently take into account the invariance of learned features after the spatial pooling stage. The algorithm is built on simple clustering, and thus enjoys efficiency and scalability. We discuss the underlying mechanism that justifies the use of clustering algorithms, and empirically show that the algorithm finds better dictionaries than patch-based methods with the same dictionary size.



### A Geometric Descriptor for Cell-Division Detection
- **Arxiv ID**: http://arxiv.org/abs/1301.3457v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1301.3457v2)
- **Published**: 2013-01-15 19:18:52+00:00
- **Updated**: 2013-04-10 18:32:07+00:00
- **Authors**: Marcelo Cicconet, Italo Lima, Davi Geiger, Kris Gunsalus
- **Comment**: This paper has been withdrawn by the author since the review process
  for the conference to which it was applied ended
- **Journal**: None
- **Summary**: We describe a method for cell-division detection based on a geometric-driven descriptor that can be represented as a 5-layers processing network, based mainly on wavelet filtering and a test for mirror symmetry between pairs of pixels. After the centroids of the descriptors are computed for a sequence of frames, the two-steps piecewise constant function that best fits the sequence of centroids determines the frame where the division occurs.



### Factorized Topic Models
- **Arxiv ID**: http://arxiv.org/abs/1301.3461v7
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1301.3461v7)
- **Published**: 2013-01-15 19:32:20+00:00
- **Updated**: 2013-04-23 08:13:55+00:00
- **Authors**: Cheng Zhang, Carl Henrik Ek, Andreas Damianou, Hedvig Kjellstrom
- **Comment**: ICLR 2013
- **Journal**: None
- **Summary**: In this paper we present a modification to a latent topic model, which makes the model exploit supervision to produce a factorized representation of the observed data. The structured parameterization separately encodes variance that is shared between classes from variance that is private to each class by the introduction of a new prior over the topic space. The approach allows for a more eff{}icient inference and provides an intuitive interpretation of the data in terms of an informative signal together with structured noise. The factorized representation is shown to enhance inference performance for image, text, and video classification.



### Boltzmann Machines and Denoising Autoencoders for Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1301.3468v6
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1301.3468v6)
- **Published**: 2013-01-15 19:45:27+00:00
- **Updated**: 2013-03-04 10:41:34+00:00
- **Authors**: Kyunghyun Cho
- **Comment**: None
- **Journal**: None
- **Summary**: Image denoising based on a probabilistic model of local image patches has been employed by various researchers, and recently a deep (denoising) autoencoder has been proposed by Burger et al. [2012] and Xie et al. [2012] as a good model for this. In this paper, we propose that another popular family of models in the field of deep learning, called Boltzmann machines, can perform image denoising as well as, or in certain cases of high level of noise, better than denoising autoencoders. We empirically evaluate the two models on three different sets of images with different types and levels of noise. Throughout the experiments we also examine the effect of the depth of the models. The experiments confirmed our claim and revealed that the performance can be improved by adding more hidden layers, especially when the level of noise is high.



### Pushing Stochastic Gradient towards Second-Order Methods -- Backpropagation Learning with Transformations in Nonlinearities
- **Arxiv ID**: http://arxiv.org/abs/1301.3476v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1301.3476v3)
- **Published**: 2013-01-15 20:21:54+00:00
- **Updated**: 2013-03-11 18:00:00+00:00
- **Authors**: Tommi Vatanen, Tapani Raiko, Harri Valpola, Yann LeCun
- **Comment**: 10 pages, 5 figures, ICLR2013
- **Journal**: None
- **Summary**: Recently, we proposed to transform the outputs of each hidden neuron in a multi-layer perceptron network to have zero output and zero slope on average, and use separate shortcut connections to model the linear dependencies instead. We continue the work by firstly introducing a third transformation to normalize the scale of the outputs of each hidden neuron, and secondly by analyzing the connections to second order optimization methods. We show that the transformations make a simple stochastic gradient behave closer to second-order optimization methods and thus speed up learning. This is shown both in theory and with experiments. The experiments on the third transformation show that while it further increases the speed of learning, it can also hurt performance by converging to a worse local optimum, where both the inputs and outputs of many hidden neurons are close to zero.



### Why Size Matters: Feature Coding as Nystrom Sampling
- **Arxiv ID**: http://arxiv.org/abs/1301.5348v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1301.5348v2)
- **Published**: 2013-01-15 21:36:06+00:00
- **Updated**: 2013-04-16 00:17:54+00:00
- **Authors**: Oriol Vinyals, Yangqing Jia, Trevor Darrell
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, the computer vision and machine learning community has been in favor of feature extraction pipelines that rely on a coding step followed by a linear classifier, due to their overall simplicity, well understood properties of linear classifiers, and their computational efficiency. In this paper we propose a novel view of this pipeline based on kernel methods and Nystrom sampling. In particular, we focus on the coding of a data point with a local representation based on a dictionary with fewer elements than the number of data points, and view it as an approximation to the actual function that would compute pair-wise similarity to all data points (often too many to compute in practice), followed by a Nystrom sampling step to select a subset of all data points.   Furthermore, since bounds are known on the approximation power of Nystrom sampling as a function of how many samples (i.e. dictionary size) we consider, we can derive bounds on the approximation of the exact (but expensive to compute) kernel matrix, and use it as a proxy to predict accuracy as a function of the dictionary size, which has been observed to increase but also to saturate as we increase its size. This model may help explaining the positive effect of the codebook size and justifying the need to stack more layers (often referred to as deep learning), as flat models empirically saturate as we add more complexity.



### Learnable Pooling Regions for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1301.3516v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1301.3516v3)
- **Published**: 2013-01-15 22:15:06+00:00
- **Updated**: 2015-05-05 18:12:46+00:00
- **Authors**: Mateusz Malinowski, Mario Fritz
- **Comment**: None
- **Journal**: None
- **Summary**: Biologically inspired, from the early HMAX model to Spatial Pyramid Matching, pooling has played an important role in visual recognition pipelines. Spatial pooling, by grouping of local codes, equips these methods with a certain degree of robustness to translation and deformation yet preserving important spatial information. Despite the predominance of this approach in current recognition systems, we have seen little progress to fully adapt the pooling strategy to the task at hand. This paper proposes a model for learning task dependent pooling scheme -- including previously proposed hand-crafted pooling schemes as a particular instantiation. In our work, we investigate the role of different regularization terms showing that the smooth regularization term is crucial to achieve strong performance using the presented architecture. Finally, we propose an efficient and parallel method to train the model. Our experiments show improved performance over hand-crafted pooling schemes on the CIFAR-10 and CIFAR-100 datasets -- in particular improving the state-of-the-art to 56.29% on the latter.



### The Neural Representation Benchmark and its Evaluation on Brain and Machine
- **Arxiv ID**: http://arxiv.org/abs/1301.3530v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1301.3530v2)
- **Published**: 2013-01-15 23:42:21+00:00
- **Updated**: 2013-01-25 20:39:46+00:00
- **Authors**: Charles F. Cadieu, Ha Hong, Dan Yamins, Nicolas Pinto, Najib J. Majaj, James J. DiCarlo
- **Comment**: The v1 version contained incorrectly computed kernel analysis curves
  and KA-AUC values for V4, IT, and the HT-L3 models. They have been corrected
  in this version
- **Journal**: None
- **Summary**: A key requirement for the development of effective learning representations is their evaluation and comparison to representations we know to be effective. In natural sensory domains, the community has viewed the brain as a source of inspiration and as an implicit benchmark for success. However, it has not been possible to directly test representational learning algorithms directly against the representations contained in neural systems. Here, we propose a new benchmark for visual representations on which we have directly tested the neural representation in multiple visual cortical areas in macaque (utilizing data from [Majaj et al., 2012]), and on which any computer vision algorithm that produces a feature space can be tested. The benchmark measures the effectiveness of the neural or machine representation by computing the classification loss on the ordered eigendecomposition of a kernel matrix [Montavon et al., 2011]. In our analysis we find that the neural representation in visual area IT is superior to visual area V4. In our analysis of representational learning algorithms, we find that three-layer models approach the representational performance of V4 and the algorithm in [Le et al., 2012] surpasses the performance of V4. Impressively, we find that a recent supervised algorithm [Krizhevsky et al., 2012] achieves performance comparable to that of IT for an intermediate level of image variation difficulty, and surpasses IT at a higher difficulty level. We believe this result represents a major milestone: it is the first learning algorithm we have found that exceeds our current estimate of IT representation performance. We hope that this benchmark will assist the community in matching the representational performance of visual cortex and will serve as an initial rallying point for further correspondence between representations derived in brains and machines.



