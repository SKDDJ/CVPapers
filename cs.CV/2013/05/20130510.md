# Arxiv Papers in cs.CV on 2013-05-10
### Multi-q Pattern Classification of Polarization Curves
- **Arxiv ID**: http://arxiv.org/abs/1305.2876v1
- **DOI**: 10.1016/j.physa.2013.09.048
- **Categories**: **cs.CE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1305.2876v1)
- **Published**: 2013-05-10 04:31:49+00:00
- **Updated**: 2013-05-10 04:31:49+00:00
- **Authors**: Ricardo Fabbri, Ivan N. Bastos, Francisco D. Moura Neto, Francisco J. P. Lopes, Wesley N. Goncalves, Odemir M. Bruno
- **Comment**: 12 pages, 7 figures
- **Journal**: None
- **Summary**: Several experimental measurements are expressed in the form of one-dimensional profiles, for which there is a scarcity of methodologies able to classify the pertinence of a given result to a specific group. The polarization curves that evaluate the corrosion kinetics of electrodes in corrosive media are an application where the behavior is chiefly analyzed from profiles. Polarization curves are indeed a classic method to determine the global kinetics of metallic electrodes, but the strong nonlinearity from different metals and alloys can overlap and the discrimination becomes a challenging problem. Moreover, even finding a typical curve from replicated tests requires subjective judgement. In this paper we used the so-called multi-q approach based on the Tsallis statistics in a classification engine to separate multiple polarization curve profiles of two stainless steels. We collected 48 experimental polarization curves in aqueous chloride medium of two stainless steel types, with different resistance against localized corrosion. Multi-q pattern analysis was then carried out on a wide potential range, from cathodic up to anodic regions. An excellent classification rate was obtained, at a success rate of 90%, 80%, and 83% for low (cathodic), high (anodic), and both potential ranges, respectively, using only 2% of the original profile data. These results show the potential of the proposed approach towards efficient, robust, systematic and automatic classification of highly non-linear profile curves.



### Beyond Physical Connections: Tree Models in Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1305.2269v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.2269v1)
- **Published**: 2013-05-10 07:09:14+00:00
- **Updated**: 2013-05-10 07:09:14+00:00
- **Authors**: Fang Wang, Yi Li
- **Comment**: CVPR 2013
- **Journal**: None
- **Summary**: Simple tree models for articulated objects prevails in the last decade. However, it is also believed that these simple tree models are not capable of capturing large variations in many scenarios, such as human pose estimation. This paper attempts to address three questions: 1) are simple tree models sufficient? more specifically, 2) how to use tree models effectively in human pose estimation? and 3) how shall we use combined parts together with single parts efficiently?   Assuming we have a set of single parts and combined parts, and the goal is to estimate a joint distribution of their locations. We surprisingly find that no latent variables are introduced in the Leeds Sport Dataset (LSP) during learning latent trees for deformable model, which aims at approximating the joint distributions of body part locations using minimal tree structure. This suggests one can straightforwardly use a mixed representation of single and combined parts to approximate their joint distribution in a simple tree model. As such, one only needs to build Visual Categories of the combined parts, and then perform inference on the learned latent tree. Our method outperformed the state of the art on the LSP, both in the scenarios when the training images are from the same dataset and from the PARSE dataset. Experiments on animal images from the VOC challenge further support our findings.



### Image Optimization and Prediction
- **Arxiv ID**: http://arxiv.org/abs/1305.2828v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.2828v1)
- **Published**: 2013-05-10 08:43:59+00:00
- **Updated**: 2013-05-10 08:43:59+00:00
- **Authors**: Shweta Jain, Urmila Shrawankar
- **Comment**: Pages: 08 Figures: 02, Proceedings of International Conferences
  CAAM-09 BITS, Durg, India, 10 Jan 2009
- **Journal**: None
- **Summary**: Image Processing, Optimization and Prediction of an Image play a key role in Computer Science. Image processing provides a way to analyze and identify an image .Many areas like medical image processing, Satellite images, natural images and artificial images requires lots of analysis and research on optimization. In Image Optimization and Prediction we are combining the features of Query Optimization, Image Processing and Prediction . Image optimization is used in Pattern analysis, object recognition, in medical Image processing to predict the type of diseases, in satellite images for predicting weather forecast, availability of water or mineral etc. Image Processing, Optimization and analysis is a wide open area for research .Lots of research has been conducted in the area of Image analysis and many techniques are available for image analysis but, a single technique is not yet identified for image analysis and prediction .our research is focused on identifying a global technique for image analysis and Prediction.



### Human Mood Detection For Human Computer Interaction
- **Arxiv ID**: http://arxiv.org/abs/1305.2827v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.2827v1)
- **Published**: 2013-05-10 08:58:01+00:00
- **Updated**: 2013-05-10 08:58:01+00:00
- **Authors**: Preeti Badar, Urmila Shrawankar
- **Comment**: Pages: 04 Figures: 06 Tables: 01, Proceedings of ICETETS-08, Rajkot,
  India, 13-14 January 2008
- **Journal**: None
- **Summary**: In this paper we propose an easiest approach for facial expression recognition. Here we are using concept of SVM for Expression Classification. Main problem is sub divided in three main modules. First one is Face detection in which we are using skin filter and Face segmentation. We are given more stress on feature Extraction. This method is effective enough for application where fast execution is required. Second, Facial Feature Extraction which is essential part for expression recognition. In this module we used Edge Projection Analysis. Finally extracted features vector is passed towards SVM classifier for Expression Recognition. We are considering six basic Expressions (Anger, Fear, Disgust, Joy, Sadness, and Surprise)



### Revisiting Bayesian Blind Deconvolution
- **Arxiv ID**: http://arxiv.org/abs/1305.2362v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1305.2362v1)
- **Published**: 2013-05-10 15:09:11+00:00
- **Updated**: 2013-05-10 15:09:11+00:00
- **Authors**: David Wipf, Haichao Zhang
- **Comment**: This paper has been submitted to JMLR. A conference version will
  appear at EMMCVPR 2013
- **Journal**: None
- **Summary**: Blind deconvolution involves the estimation of a sharp signal or image given only a blurry observation. Because this problem is fundamentally ill-posed, strong priors on both the sharp image and blur kernel are required to regularize the solution space. While this naturally leads to a standard MAP estimation framework, performance is compromised by unknown trade-off parameter settings, optimization heuristics, and convergence issues stemming from non-convexity and/or poor prior selections. To mitigate some of these problems, a number of authors have recently proposed substituting a variational Bayesian (VB) strategy that marginalizes over the high-dimensional image space leading to better estimates of the blur kernel. However, the underlying cost function now involves both integrals with no closed-form solution and complex, function-valued arguments, thus losing the transparency of MAP. Beyond standard Bayesian-inspired intuitions, it thus remains unclear by exactly what mechanism these methods are able to operate, rendering understanding, improvements and extensions more difficult. To elucidate these issues, we demonstrate that the VB methodology can be recast as an unconventional MAP problem with a very particular penalty/prior that couples the image, blur kernel, and noise level in a principled way. This unique penalty has a number of useful characteristics pertaining to relative concavity, local minima avoidance, and scale-invariance that allow us to rigorously explain the success of VB including its existing implementational heuristics and approximations. It also provides strict criteria for choosing the optimal image prior that, perhaps counter-intuitively, need not reflect the statistics of natural scenes. In so doing we challenge the prevailing notion of why VB is successful for blind deconvolution while providing a transparent platform for introducing enhancements.



### Shape Reconstruction and Recognition with Isolated Non-directional Cues
- **Arxiv ID**: http://arxiv.org/abs/1305.2395v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.2395v1)
- **Published**: 2013-05-10 17:35:02+00:00
- **Updated**: 2013-05-10 17:35:02+00:00
- **Authors**: Toshiro Kubota, Jessica Ranck, Briley Acker, Herman De Haan
- **Comment**: 28 pages, 14 figures, 4 tables
- **Journal**: None
- **Summary**: The paper investigates a hypothesis that our visual system groups visual cues based on how they form a surface, or more specifically triangulation derived from the visual cues. To test our hypothesis, we compare shape recognition with three different representations of visual cues: a set of isolated dots delineating the outline of the shape, a set of triangles obtained from Delaunay triangulation of the set of dots, and a subset of Delaunay triangles excluding those outside of the shape. Each participant was assigned to one particular representation type and increased the number of dots (and consequentially triangles) until the underlying shape could be identified. We compare the average number of dots needed for identification among three types of representations. Our hypothesis predicts that the results from the three representations will be similar. However, they show statistically significant differences. The paper also presents triangulation based algorithms for reconstruction and recognition of a shape from a set of isolated dots. Experiments showed that the algorithms were more effective and perceptually agreeable than similar contour based ones. From these experiments, we conclude that triangulation does affect our shape recognition. However, the surface based approach presents a number of computational advantages over the contour based one and should be studied further.



