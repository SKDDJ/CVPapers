# Arxiv Papers in cs.CV on 2013-05-17
### Sparse Norm Filtering
- **Arxiv ID**: http://arxiv.org/abs/1305.3971v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1305.3971v1)
- **Published**: 2013-05-17 03:13:28+00:00
- **Updated**: 2013-05-17 03:13:28+00:00
- **Authors**: Chengxi Ye, Dacheng Tao, Mingli Song, David W. Jacobs, Min Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Optimization-based filtering smoothes an image by minimizing a fidelity function and simultaneously preserves edges by exploiting a sparse norm penalty over gradients. It has obtained promising performance in practical problems, such as detail manipulation, HDR compression and deblurring, and thus has received increasing attentions in fields of graphics, computer vision and image processing. This paper derives a new type of image filter called sparse norm filter (SNF) from optimization-based filtering. SNF has a very simple form, introduces a general class of filtering techniques, and explains several classic filters as special implementations of SNF, e.g. the averaging filter and the median filter. It has advantages of being halo free, easy to implement, and low time and memory costs (comparable to those of the bilateral filter). Thus, it is more generic than a smoothing operator and can better adapt to different tasks. We validate the proposed SNF by a wide variety of applications including edge-preserving smoothing, outlier tolerant filtering, detail manipulation, HDR compression, non-blind deconvolution, image segmentation, and colorization.



### Font Acknowledgment and Character Extraction of Digital and Scanned Images
- **Arxiv ID**: http://arxiv.org/abs/1305.4064v1
- **DOI**: 10.5120/11979-7850
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.4064v1)
- **Published**: 2013-05-17 13:05:31+00:00
- **Updated**: 2013-05-17 13:05:31+00:00
- **Authors**: Syed Muhammad Arsalan Bashir
- **Comment**: 5 pages, 5 figures, 1 table, Published with International Journal of
  Computer Applications (IJCA)
- **Journal**: International Journal of Computer Applications 70(8):1-5, May 2013
- **Summary**: The font recognition and character extraction is of immense importance as these are many scenarios where data are in such a form, which cannot be processed like in image form or as a hard copy. So the procedure developed in this paper is basically related to identifying the font (Times New Roman, Arial and Comic Sans MS) and afterwards recovering the text using simple correlation based method where the binary templates are correlated to the input image text characters. All of this extraction is done in the presence of a little noise as images may have noisy patterns due to photocopying. The significance of this method exists in extraction of data from various monitoring (Surveillance) camera footages or even more. The method is developed on Matlab\c{opyright} which takes input image and recovers text and font information from it in a text file.



### Indexing Medical Images based on Collaborative Experts Reports
- **Arxiv ID**: http://arxiv.org/abs/1305.4077v2
- **DOI**: 10.5120/11955-7787
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1305.4077v2)
- **Published**: 2013-05-17 13:43:57+00:00
- **Updated**: 2013-07-05 18:01:35+00:00
- **Authors**: Abir Messaoudi, Riadh Bouslimi, Jalel Akaichi
- **Comment**: 9 pages, 8 figures. International Journal of Computer Applications,
  May 2013
- **Journal**: None
- **Summary**: A patient is often willing to quickly get, from his physician, reliable analysis and concise explanation according to provided linked medical images. The fact of making choices individually by the patient's physician may lead to malpractices and consequently generates unforeseeable damages. The Institute of Medicine of the National Sciences Academy(IMNAS) in USA published a study estimating that up to 98,000 hospital deathseach year can be attributed to medical malpractice [1]. Moreover, physician, in charge of medical image analysis, might be unavailable at the right time, which may complicate the patient's state. The goal of this paper is to provide to physicians and patients, a social network that permits to foster cooperation and to overcome the problem of unavailability of doctors on site any time. Therefore, patients can submit their medical images to be diagnosed and commented by several experts instantly. Consequently, the need to process opinions and to extract information automatically from the proposed social network became a necessity due to the huge number of comments expressing specialist's reviews. For this reason, we propose a kind of comments' summary keywords-based method which extracts the major current terms and relevant words existing on physicians' annotations. The extracted keywords will present a new and robust method for image indexation. In fact, significant extracted terms will be used later to index images in order to facilitate their discovery for any appropriate use. To overcome this challenge, we propose our Terminology Extraction of Annotation (TEA) mixed approach which focuses on algorithms mainly based on statistical methods and on external semantic resources.



### Flying Triangulation - towards the 3D movie camera
- **Arxiv ID**: http://arxiv.org/abs/1305.4168v1
- **DOI**: None
- **Categories**: **cs.CV**, physics.optics
- **Links**: [PDF](http://arxiv.org/pdf/1305.4168v1)
- **Published**: 2013-05-17 19:52:32+00:00
- **Updated**: 2013-05-17 19:52:32+00:00
- **Authors**: Florian Willomitzer, Svenja Ettl, Christian Faber, Gerd HÃ¤usler
- **Comment**: Proceedings of the 7th International Fringe Workshop on Advanced
  Optical Imaging and Metrology, 2013, N\"urtingen, Germany
- **Journal**: None
- **Summary**: Flying Triangulation sensors enable a free-hand and motion-robust 3D data acquisition of complex shaped objects. The measurement principle is based on a multi-line light-sectioning approach and uses sophisticated algorithms for real-time registration (S. Ettl et al., Appl. Opt. 51 (2012) 281-289). As "single-shot principle", light sectioning enables the option to get surface data from one single camera exposure. But there is a drawback: A pixel-dense measurement is not possible because of fundamental information-theoretical reasons. By "pixel-dense" we understand that each pixel displays individually measured distance information, neither interpolated from its neighbour pixels nor using lateral context information. Hence, for monomodal single-shot principles, the 3D data generated from one 2D raw image display a significantly lower space-bandwidth than the camera permits. This is the price one must pay for motion robustness. Currently, our sensors project about 10 lines (each with 1000 pixels), reaching an considerable lower data efficiency than theoretically possible for a single-shot sensor. Our aim is to push Flying Triangulation to its information-theoretical limits. Therefore, the line density as well as the measurement depth needs to be significantly increased. This causes serious indexing ambiguities. On the road to a single-shot 3D movie camera, we are working on solutions to overcome the problem of false line indexing by utilizing yet unexploited information. We will present several approaches and will discuss profound information-theoretical questions about the information efficiency of 3D sensors.



### Machine learning on images using a string-distance
- **Arxiv ID**: http://arxiv.org/abs/1305.4204v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1305.4204v1)
- **Published**: 2013-05-17 22:40:14+00:00
- **Updated**: 2013-05-17 22:40:14+00:00
- **Authors**: Uzi Chester, Joel Ratsaby
- **Comment**: None
- **Journal**: None
- **Summary**: We present a new method for image feature-extraction which is based on representing an image by a finite-dimensional vector of distances that measure how different the image is from a set of image prototypes. We use the recently introduced Universal Image Distance (UID) \cite{RatsabyChesterIEEE2012} to compare the similarity between an image and a prototype image. The advantage in using the UID is the fact that no domain knowledge nor any image analysis need to be done. Each image is represented by a finite dimensional feature vector whose components are the UID values between the image and a finite set of image prototypes from each of the feature categories. The method is automatic since once the user selects the prototype images, the feature vectors are automatically calculated without the need to do any image analysis. The prototype images can be of different size, in particular, different than the image size. Based on a collection of such cases any supervised or unsupervised learning algorithm can be used to train and produce an image classifier or image cluster analysis. In this paper we present the image feature-extraction method and use it on several supervised and unsupervised learning experiments for satellite image data.



