# Arxiv Papers in cs.CV on 2013-05-01
### Video Segmentation via Diffusion Bases
- **Arxiv ID**: http://arxiv.org/abs/1305.0218v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1305.0218v1)
- **Published**: 2013-05-01 16:22:55+00:00
- **Updated**: 2013-05-01 16:22:55+00:00
- **Authors**: Dina Dushnik, Alon Schclar, Amir Averbuch
- **Comment**: 29 pages, 11 figures
- **Journal**: None
- **Summary**: Identifying moving objects in a video sequence, which is produced by a static camera, is a fundamental and critical task in many computer-vision applications. A common approach performs background subtraction, which identifies moving objects as the portion of a video frame that differs significantly from a background model. A good background subtraction algorithm has to be robust to changes in the illumination and it should avoid detecting non-stationary background objects such as moving leaves, rain, snow, and shadows. In addition, the internal background model should quickly respond to changes in background such as objects that start to move or stop. We present a new algorithm for video segmentation that processes the input video sequence as a 3D matrix where the third axis is the time domain. Our approach identifies the background by reducing the input dimension using the \emph{diffusion bases} methodology. Furthermore, we describe an iterative method for extracting and deleting the background. The algorithm has two versions and thus covers the complete range of backgrounds: one for scenes with static backgrounds and the other for scenes with dynamic (moving) backgrounds.



### An Adaptive Descriptor Design for Object Recognition in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1305.0311v1
- **DOI**: 10.1109/ICCV.2013.319
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1305.0311v1)
- **Published**: 2013-05-01 23:11:36+00:00
- **Updated**: 2013-05-01 23:11:36+00:00
- **Authors**: Zhenyu Guo, Z. Jane Wang
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: Digital images nowadays have various styles of appearance, in the aspects of color tones, contrast, vignetting, and etc. These 'picture styles' are directly related to the scene radiance, image pipeline of the camera, and post processing functions. Due to the complexity and nonlinearity of these causes, popular gradient-based image descriptors won't be invariant to different picture styles, which will decline the performance of object recognition. Given that images shared online or created by individual users are taken with a wide range of devices and may be processed by various post processing functions, to find a robust object recognition system is useful and challenging. In this paper, we present the first study on the influence of picture styles for object recognition, and propose an adaptive approach based on the kernel view of gradient descriptors and multiple kernel learning, without estimating or specifying the styles of images used in training and testing. We conduct experiments on Domain Adaptation data set and Oxford Flower data set. The experiments also include several variants of the flower data set by processing the images with popular photo effects. The results demonstrate that our proposed method improve from standard descriptors in all cases.



