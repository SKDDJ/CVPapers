# Arxiv Papers in cs.CV on 2014-07-22
### Learning Rich Features from RGB-D Images for Object Detection and Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1407.5736v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1407.5736v1)
- **Published**: 2014-07-22 05:31:32+00:00
- **Updated**: 2014-07-22 05:31:32+00:00
- **Authors**: Saurabh Gupta, Ross Girshick, Pablo Arbel√°ez, Jitendra Malik
- **Comment**: To appear in the European Conference on Computer Vision (ECCV), 2014
- **Journal**: None
- **Summary**: In this paper we study the problem of object detection for RGB-D images using semantically rich image and depth features. We propose a new geocentric embedding for depth images that encodes height above ground and angle with gravity for each pixel in addition to the horizontal disparity. We demonstrate that this geocentric embedding works better than using raw depth images for learning feature representations with convolutional neural networks. Our final object detection system achieves an average precision of 37.3%, which is a 56% relative improvement over existing methods. We then focus on the task of instance segmentation where we label pixels belonging to object instances found by our detector. For this task, we propose a decision forest approach that classifies pixels in the detection window as foreground or background using a family of unary and binary tests that query shape and geocentric pose features. Finally, we use the output from our object detectors in an existing superpixel classification framework for semantic scene segmentation and achieve a 24% relative improvement over current state-of-the-art for the object categories that we study. We believe advances such as those represented in this paper will facilitate the use of perception in fields like robotics.



### Tree-based iterated local search for Markov random fields with applications in image analysis
- **Arxiv ID**: http://arxiv.org/abs/1407.5754v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1407.5754v1)
- **Published**: 2014-07-22 06:43:41+00:00
- **Updated**: 2014-07-22 06:43:41+00:00
- **Authors**: Truyen Tran, Dinh Phung, Svetha Venkatesh
- **Comment**: None
- **Journal**: None
- **Summary**: The \emph{maximum a posteriori} (MAP) assignment for general structure Markov random fields (MRFs) is computationally intractable. In this paper, we exploit tree-based methods to efficiently address this problem. Our novel method, named Tree-based Iterated Local Search (T-ILS) takes advantage of the tractability of tree-structures embedded within MRFs to derive strong local search in an ILS framework. The method efficiently explores exponentially large neighborhood and does so with limited memory without any requirement on the cost functions. We evaluate the T-ILS in a simulation of Ising model and two real-world problems in computer vision: stereo matching, image denoising. Experimental results demonstrate that our methods are competitive against state-of-the-art rivals with a significant computational gain.



### Aggregation of local parametric candidates with exemplar-based occlusion handling for optical flow
- **Arxiv ID**: http://arxiv.org/abs/1407.5759v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.5759v1)
- **Published**: 2014-07-22 06:50:40+00:00
- **Updated**: 2014-07-22 06:50:40+00:00
- **Authors**: Denis Fortun, Patrick Bouthemy, Charles Kervrann
- **Comment**: Submission,IEEE Transactions on Image Processing (2014)
- **Journal**: None
- **Summary**: Handling all together large displacements, motion details and occlusions remains an open issue for reliable computation of optical flow in a video sequence. We propose a two-step aggregation paradigm to address this problem. The idea is to supply local motion candidates at every pixel in a first step, and then to combine them to determine the global optical flow field in a second step. We exploit local parametric estimations combined with patch correspondences and we experimentally demonstrate that they are sufficient to produce highly accurate motion candidates. The aggregation step is designed as the discrete optimization of a global regularized energy. The occlusion map is estimated jointly with the flow field throughout the two steps. We propose a generic exemplar-based approach for occlusion filling with motion vectors. We achieve state-of-the-art results in computer vision benchmarks, with particularly significant improvements in the case of large displacements and occlusions.



### Detection of Sclerotic Spine Metastases via Random Aggregation of Deep Convolutional Neural Network Classifications
- **Arxiv ID**: http://arxiv.org/abs/1407.5976v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.5976v1)
- **Published**: 2014-07-22 19:06:50+00:00
- **Updated**: 2014-07-22 19:06:50+00:00
- **Authors**: Holger R. Roth, Jianhua Yao, Le Lu, James Stieger, Joseph E. Burns, Ronald M. Summers
- **Comment**: This paper will be presented at "Computational Methods and Clinical
  Applications for Spine Imaging" workshop held in conjunction with MICCAI 2014
- **Journal**: None
- **Summary**: Automated detection of sclerotic metastases (bone lesions) in Computed Tomography (CT) images has potential to be an important tool in clinical practice and research. State-of-the-art methods show performance of 79% sensitivity or true-positive (TP) rate, at 10 false-positives (FP) per volume. We design a two-tiered coarse-to-fine cascade framework to first operate a highly sensitive candidate generation system at a maximum sensitivity of ~92% but with high FP level (~50 per patient). Regions of interest (ROI) for lesion candidates are generated in this step and function as input for the second tier. In the second tier we generate N 2D views, via scale, random translations, and rotations with respect to each ROI centroid coordinates. These random views are used to train a deep Convolutional Neural Network (CNN) classifier. In testing, the CNN is employed to assign individual probabilities for a new set of N random views that are averaged at each ROI to compute a final per-candidate classification probability. This second tier behaves as a highly selective process to reject difficult false positives while preserving high sensitivities. We validate the approach on CT images of 59 patients (49 with sclerotic metastases and 10 normal controls). The proposed method reduces the number of FP/vol. from 4 to 1.2, 7 to 3, and 12 to 9.5 when comparing a sensitivity rates of 60%, 70%, and 80% respectively in testing. The Area-Under-the-Curve (AUC) is 0.834. The results show marked improvement upon previous work.



### The U-curve optimization problem: improvements on the original algorithm and time complexity analysis
- **Arxiv ID**: http://arxiv.org/abs/1407.6067v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, 68T10, I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1407.6067v1)
- **Published**: 2014-07-22 23:18:08+00:00
- **Updated**: 2014-07-22 23:18:08+00:00
- **Authors**: Marcelo S. Reis, Carlos E. Ferreira, Junior Barrera
- **Comment**: Original results from the Ph.D. thesis of Marcelo S. Reis. This
  thesis can be accessed through the following link:
  http://www.teses.usp.br/teses/disponiveis/45/45134/tde-05022013-123757/en.php
- **Journal**: None
- **Summary**: The U-curve optimization problem is characterized by a decomposable in U-shaped curves cost function over the chains of a Boolean lattice. This problem can be applied to model the classical feature selection problem in Machine Learning. Recently, the U-Curve algorithm was proposed to give optimal solutions to the U-curve problem. In this article, we point out that the U-Curve algorithm is in fact suboptimal, and introduce the U-Curve-Search (UCS) algorithm, which is actually optimal. We also present the results of optimal and suboptimal experiments, in which UCS is compared with the UBB optimal branch-and-bound algorithm and the SFFS heuristic, respectively. We show that, in both experiments, $\proc{UCS}$ had a better performance than its competitor. Finally, we analyze the obtained results and point out improvements on UCS that might enhance the performance of this algorithm.



