# Arxiv Papers in cs.CV on 2014-07-14
### Optimizing Auto-correlation for Fast Target Search in Large Search Space
- **Arxiv ID**: http://arxiv.org/abs/1407.3535v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.3535v2)
- **Published**: 2014-07-14 03:57:57+00:00
- **Updated**: 2014-07-25 00:47:47+00:00
- **Authors**: Arif Mahmood, Ajmal Mian, Robyn Owens
- **Comment**: None
- **Journal**: None
- **Summary**: In remote sensing image-blurring is induced by many sources such as atmospheric scatter, optical aberration, spatial and temporal sensor integration. The natural blurring can be exploited to speed up target search by fast template matching. In this paper, we synthetically induce additional non-uniform blurring to further increase the speed of the matching process. To avoid loss of accuracy, the amount of synthetic blurring is varied spatially over the image according to the underlying content. We extend transitive algorithm for fast template matching by incorporating controlled image blur. To this end we propose an Efficient Group Size (EGS) algorithm which minimizes the number of similarity computations for a particular search image. A larger efficient group size guarantees less computations and more speedup. EGS algorithm is used as a component in our proposed Optimizing auto-correlation (OptA) algorithm. In OptA a search image is iteratively non-uniformly blurred while ensuring no accuracy degradation at any image location. In each iteration efficient group size and overall computations are estimated by using the proposed EGS algorithm. The OptA algorithm stops when the number of computations cannot be further decreased without accuracy degradation. The proposed algorithm is compared with six existing state of the art exhaustive accuracy techniques using correlation coefficient as the similarity measure. Experiments on satellite and aerial image datasets demonstrate the effectiveness of the proposed algorithm.



### Measuring Atmospheric Scattering from Digital Images of Urban Scenery using Temporal Polarization-Based Vision
- **Arxiv ID**: http://arxiv.org/abs/1407.3540v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.3540v1)
- **Published**: 2014-07-14 04:36:31+00:00
- **Updated**: 2014-07-14 04:36:31+00:00
- **Authors**: Tarek El-Gaaly, Joshua Gluckman
- **Comment**: Masters in Computer Science Thesis
- **Journal**: None
- **Summary**: Particulate Matter (PM) is a form of air pollution that visually degrades urban scenery and is hazardous to human health and the environment. Current monitoring devices are limited in measuring average PM over large areas. Quantifying the visual effects of haze in digital images of urban scenery and correlating these effects to PM levels is a vital step in more practically monitoring our environment. Current image haze extraction algorithms remove haze from the scene for the sole purpose of enhancing vision. We present two algorithms which bridge the gap between image haze extraction and environmental monitoring. We provide a means of measuring atmospheric scattering from images of urban scenery by incorporating temporal knowledge. In doing so, we also present a method of recovering an accurate depthmap of the scene and recovering the scene without the visual effects of haze. We compare our algorithm to three known haze removal methods. The algorithms are composed of an optimization over a model of haze formation in images and an optimization using a constraint of constant depth over a sequence of images taken over time. These algorithms not only measure atmospheric scattering, but also recover a more accurate depthmap and dehazed image. The measurements of atmospheric scattering this research produces, can be directly correlated to PM levels and therefore pave the way to monitoring the health of the environment by visual means. Accurate atmospheric sensing from digital images is a challenging and under-researched problem. This work provides an important step towards a more practical and accurate visual means of measuring PM from digital images.



### Self Organization Map based Texture Feature Extraction for Efficient Medical Image Categorization
- **Arxiv ID**: http://arxiv.org/abs/1408.4143v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1408.4143v1)
- **Published**: 2014-07-14 13:43:19+00:00
- **Updated**: 2014-07-14 13:43:19+00:00
- **Authors**: Marghny H. Mohamed, Mohammed M. Abdelsamea
- **Comment**: In Proceedings of the 4th ACM International Conference on Intelligent
  Computing and Information Systems, ICICIS 2009, Cairo, Egypt 2009
- **Journal**: None
- **Summary**: Texture is one of the most important properties of visual surface that helps in discriminating one object from another or an object from background. The self-organizing map (SOM) is an excellent tool in exploratory phase of data mining. It projects its input space on prototypes of a low-dimensional regular grid that can be effectively utilized to visualize and explore properties of the data. This paper proposes an enhancement extraction method for accurate extracting features for efficient image representation it based on SOM neural network. In this approach, we apply three different partitioning approaches as a region of interested (ROI) selection methods for extracting different accurate textural features from medical image as a primary step of our extraction method. Fisherfaces feature selection is used, for selecting discriminated features form extracted textural features. Experimental result showed the high accuracy of medical image categorization with our proposed extraction method. Experiments held on Mammographic Image Analysis Society (MIAS) dataset.



### An Enhancement Neighborhood connected Segmentation for 2D-Cellular Image
- **Arxiv ID**: http://arxiv.org/abs/1407.3664v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.3664v1)
- **Published**: 2014-07-14 14:21:38+00:00
- **Updated**: 2014-07-14 14:21:38+00:00
- **Authors**: Mohammed M. Abdelsamea
- **Comment**: International Journal of International Journal of Bioscience,
  Biochemistry and Bioinformatics, 2011. arXiv admin note: text overlap with
  arXiv:1406.0074 by other authors
- **Journal**: None
- **Summary**: A good segmentation result depends on a set of "correct" choice for the seeds. When the input images are noisy, the seeds may fall on atypical pixels that are not representative of the region statistics. This can lead to erroneous segmentation results. In this paper, an automatic seeded region growing algorithm is proposed for cellular image segmentation. First, the regions of interest (ROIs) extracted from the preprocessed image. Second, the initial seeds are automatically selected based on ROIs extracted from the image. Third, the most reprehensive seeds are selected using a machine learning algorithm. Finally, the cellular image is segmented into regions where each region corresponds to a seed. The aim of the proposed is to automatically extract the Region of Interests (ROI) from in the cellular images in terms of overcoming the explosion, under segmentation and over segmentation problems. Experimental results show that the proposed algorithm can improve the segmented image and the segmented results are less noisy as compared to some existing algorithms.



### Spatiotemporal Stacked Sequential Learning for Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1407.3686v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.3686v1)
- **Published**: 2014-07-14 15:03:01+00:00
- **Updated**: 2014-07-14 15:03:01+00:00
- **Authors**: Alejandro González, Sebastian Ramos, David Vázquez, Antonio M. López, Jaume Amores
- **Comment**: 8 pages, 5 figure, 1 table
- **Journal**: None
- **Summary**: Pedestrian classifiers decide which image windows contain a pedestrian. In practice, such classifiers provide a relatively high response at neighbor windows overlapping a pedestrian, while the responses around potential false positives are expected to be lower. An analogous reasoning applies for image sequences. If there is a pedestrian located within a frame, the same pedestrian is expected to appear close to the same location in neighbor frames. Therefore, such a location has chances of receiving high classification scores during several frames, while false positives are expected to be more spurious. In this paper we propose to exploit such correlations for improving the accuracy of base pedestrian classifiers. In particular, we propose to use two-stage classifiers which not only rely on the image descriptors required by the base classifiers but also on the response of such base classifiers in a given spatiotemporal neighborhood. More specifically, we train pedestrian classifiers using a stacked sequential learning (SSL) paradigm. We use a new pedestrian dataset we have acquired from a car to evaluate our proposal at different frame rates. We also test on a well known dataset: Caltech. The obtained results show that our SSL proposal boosts detection accuracy significantly with a minimal impact on the computational cost. Interestingly, SSL improves more the accuracy at the most dangerous situations, i.e. when a pedestrian is close to the camera.



### Depth Reconstruction from Sparse Samples: Representation, Algorithm, and Sampling
- **Arxiv ID**: http://arxiv.org/abs/1407.3840v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.3840v4)
- **Published**: 2014-07-14 22:52:05+00:00
- **Updated**: 2015-02-12 01:39:27+00:00
- **Authors**: Lee-Kang Liu, Stanley H. Chan, Truong Q. Nguyen
- **Comment**: None
- **Journal**: None
- **Summary**: The rapid development of 3D technology and computer vision applications have motivated a thrust of methodologies for depth acquisition and estimation. However, most existing hardware and software methods have limited performance due to poor depth precision, low resolution and high computational cost. In this paper, we present a computationally efficient method to recover dense depth maps from sparse measurements. We make three contributions. First, we provide empirical evidence that depth maps can be encoded much more sparsely than natural images by using common dictionaries such as wavelets and contourlets. We also show that a combined wavelet-contourlet dictionary achieves better performance than using either dictionary alone. Second, we propose an alternating direction method of multipliers (ADMM) to achieve fast reconstruction. A multi-scale warm start procedure is proposed to speed up the convergence. Third, we propose a two-stage randomized sampling scheme to optimally choose the sampling locations, thus maximizing the reconstruction performance for any given sampling budget. Experimental results show that the proposed method produces high quality dense depth estimates, and is robust to noisy measurements. Applications to real data in stereo matching are demonstrated.



