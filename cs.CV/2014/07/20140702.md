# Arxiv Papers in cs.CV on 2014-07-02
### Geometric Tight Frame based Stylometry for Art Authentication of van Gogh Paintings
- **Arxiv ID**: http://arxiv.org/abs/1407.0439v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1407.0439v3)
- **Published**: 2014-07-02 01:55:37+00:00
- **Updated**: 2015-01-13 07:20:12+00:00
- **Authors**: Haixia Liu, Raymond H. Chan, Yuan Yao
- **Comment**: 14 pages, 13 figures
- **Journal**: None
- **Summary**: This paper is about authenticating genuine van Gogh paintings from forgeries. The authentication process depends on two key steps: feature extraction and outlier detection. In this paper, a geometric tight frame and some simple statistics of the tight frame coefficients are used to extract features from the paintings. Then a forward stage-wise rank boosting is used to select a small set of features for more accurate classification so that van Gogh paintings are highly concentrated towards some center point while forgeries are spread out as outliers. Numerical results show that our method can achieve 86.08% classification accuracy under the leave-one-out cross-validation procedure. Our method also identifies five features that are much more predominant than other features. Using just these five features for classification, our method can give 88.61% classification accuracy which is the highest so far reported in literature. Evaluation of the five features is also performed on two hundred datasets generated by bootstrap sampling with replacement. The median and the mean are 88.61% and 87.77% respectively. Our results show that a small set of statistics of the tight frame coefficients along certain orientations can serve as discriminative features for van Gogh paintings. It is more important to look at the tail distributions of such directional coefficients than mean values and standard deviations. It reflects a highly consistent style in van Gogh's brushstroke movements, where many forgeries demonstrate a more diverse spread in these features.



### A Data-Driven Approach for Tag Refinement and Localization in Web Videos
- **Arxiv ID**: http://arxiv.org/abs/1407.0623v3
- **DOI**: 10.1016/j.cviu.2015.05.009
- **Categories**: **cs.CV**, cs.IR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1407.0623v3)
- **Published**: 2014-07-02 15:48:37+00:00
- **Updated**: 2015-05-28 17:12:54+00:00
- **Authors**: Lamberto Ballan, Marco Bertini, Giuseppe Serra, Alberto Del Bimbo
- **Comment**: Preprint submitted to Computer Vision and Image Understanding (CVIU)
- **Journal**: None
- **Summary**: Tagging of visual content is becoming more and more widespread as web-based services and social networks have popularized tagging functionalities among their users. These user-generated tags are used to ease browsing and exploration of media collections, e.g. using tag clouds, or to retrieve multimedia content. However, not all media are equally tagged by users. Using the current systems is easy to tag a single photo, and even tagging a part of a photo, like a face, has become common in sites like Flickr and Facebook. On the other hand, tagging a video sequence is more complicated and time consuming, so that users just tag the overall content of a video. In this paper we present a method for automatic video annotation that increases the number of tags originally provided by users, and localizes them temporally, associating tags to keyframes. Our approach exploits collective knowledge embedded in user-generated tags and web sources, and visual similarity of keyframes and images uploaded to social sites like YouTube and Flickr, as well as web sources like Google and Bing. Given a keyframe, our method is able to select on the fly from these visual sources the training exemplars that should be the most relevant for this test sample, and proceeds to transfer labels across similar images. Compared to existing video tagging approaches that require training classifiers for each tag, our system has few parameters, is easy to implement and can deal with an open vocabulary scenario. We demonstrate the approach on tag refinement and localization on DUT-WEBV, a large dataset of web videos, and show state-of-the-art results.



### Deep Poselets for Human Detection
- **Arxiv ID**: http://arxiv.org/abs/1407.0717v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.0717v1)
- **Published**: 2014-07-02 20:28:22+00:00
- **Updated**: 2014-07-02 20:28:22+00:00
- **Authors**: Lubomir Bourdev, Fei Yang, Rob Fergus
- **Comment**: None
- **Journal**: None
- **Summary**: We address the problem of detecting people in natural scenes using a part approach based on poselets. We propose a bootstrapping method that allows us to collect millions of weakly labeled examples for each poselet type. We use these examples to train a Convolutional Neural Net to discriminate different poselet types and separate them from the background class. We then use the trained CNN as a way to represent poselet patches with a Pose Discriminative Feature (PDF) vector -- a compact 256-dimensional feature vector that is effective at discriminating pose from appearance. We train the poselet model on top of PDF features and combine them with object-level CNNs for detection and bounding box prediction. The resulting model leads to state-of-the-art performance for human detection on the PASCAL datasets.



### Cortical spatio-temporal dimensionality reduction for visual grouping
- **Arxiv ID**: http://arxiv.org/abs/1407.0733v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, q-bio.NC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1407.0733v2)
- **Published**: 2014-07-02 22:07:06+00:00
- **Updated**: 2014-10-03 16:46:41+00:00
- **Authors**: Giacomo Cocci, Davide Barbieri, Giovanna Citti, Alessandro Sarti
- **Comment**: None
- **Journal**: None
- **Summary**: The visual systems of many mammals, including humans, is able to integrate the geometric information of visual stimuli and to perform cognitive tasks already at the first stages of the cortical processing. This is thought to be the result of a combination of mechanisms, which include feature extraction at single cell level and geometric processing by means of cells connectivity. We present a geometric model of such connectivities in the space of detected features associated to spatio-temporal visual stimuli, and show how they can be used to obtain low-level object segmentation. The main idea is that of defining a spectral clustering procedure with anisotropic affinities over datasets consisting of embeddings of the visual stimuli into higher dimensional spaces. Neural plausibility of the proposed arguments will be discussed.



