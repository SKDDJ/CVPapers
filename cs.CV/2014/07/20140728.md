# Arxiv Papers in cs.CV on 2014-07-28
### A unified framework for thermal face recognition
- **Arxiv ID**: http://arxiv.org/abs/1407.7317v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.7317v1)
- **Published**: 2014-07-28 04:20:24+00:00
- **Updated**: 2014-07-28 04:20:24+00:00
- **Authors**: Reza Shoja Ghiass, Ognjen Arandjelovic, Hakim Bendada, Xavier Maldague
- **Comment**: International Conference on Neural Information Processing, 2014
- **Journal**: None
- **Summary**: The reduction of the cost of infrared (IR) cameras in recent years has made IR imaging a highly viable modality for face recognition in practice. A particularly attractive advantage of IR-based over conventional, visible spectrum-based face recognition stems from its invariance to visible illumination. In this paper we argue that the main limitation of previous work on face recognition using IR lies in its ad hoc approach to treating different nuisance factors which affect appearance, prohibiting a unified approach that is capable of handling concurrent changes in multiple (or indeed all) major extrinsic sources of variability, which is needed in practice. We describe the first approach that attempts to achieve this - the framework we propose achieves outstanding recognition performance in the presence of variable (i) pose, (ii) facial expression, (iii) physiological state, (iv) partial occlusion due to eye-wear, and (v) quasi-occlusion due to facial hair growth.



### Discovering Discriminative Cell Attributes for HEp-2 Specimen Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1407.7330v1
- **DOI**: 10.1109/WACV.2014.6836071
- **Categories**: **cs.CV**, cs.CE
- **Links**: [PDF](http://arxiv.org/pdf/1407.7330v1)
- **Published**: 2014-07-28 06:03:03+00:00
- **Updated**: 2014-07-28 06:03:03+00:00
- **Authors**: Arnold Wiliem, Peter Hobson, Brian C. Lovell
- **Comment**: WACV 2014: IEEE Winter Conference on Applications of Computer Vision
- **Journal**: None
- **Summary**: Recently, there has been a growing interest in developing Computer Aided Diagnostic (CAD) systems for improving the reliability and consistency of pathology test results. This paper describes a novel CAD system for the Anti-Nuclear Antibody (ANA) test via Indirect Immunofluorescence protocol on Human Epithelial Type 2 (HEp-2) cells. While prior works have primarily focused on classifying cell images extracted from ANA specimen images, this work takes a further step by focussing on the specimen image classification problem itself. Our system is able to efficiently classify specimen images as well as producing meaningful descriptions of ANA pattern class which helps physicians to understand the differences between various ANA patterns. We achieve this goal by designing a specimen-level image descriptor that: (1) is highly discriminative; (2) has small descriptor length and (3) is semantically meaningful at the cell level. In our work, a specimen image descriptor is represented by its overall cell attribute descriptors. As such, we propose two max-margin based learning schemes to discover cell attributes whilst still maintaining the discrimination of the specimen image descriptor. Our learning schemes differ from the existing discriminative attribute learning approaches as they primarily focus on discovering image-level attributes. Comparative evaluations were undertaken to contrast the proposed approach to various state-of-the-art approaches on a novel HEp-2 cell dataset which was specifically proposed for the specimen-level classification. Finally, we showcase the ability of the proposed approach to provide textual descriptions to explain ANA patterns.



### Beyond KernelBoost
- **Arxiv ID**: http://arxiv.org/abs/1407.8518v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1407.8518v1)
- **Published**: 2014-07-28 09:07:03+00:00
- **Updated**: 2014-07-28 09:07:03+00:00
- **Authors**: Roberto Rigamonti, Vincent Lepetit, Pascal Fua
- **Comment**: None
- **Journal**: None
- **Summary**: In this Technical Report we propose a set of improvements with respect to the KernelBoost classifier presented in [Becker et al., MICCAI 2013]. We start with a scheme inspired by Auto-Context, but that is suitable in situations where the lack of large training sets poses a potential problem of overfitting. The aim is to capture the interactions between neighboring image pixels to better regularize the boundaries of segmented regions. As in Auto-Context [Tu et al., PAMI 2009] the segmentation process is iterative and, at each iteration, the segmentation results for the previous iterations are taken into account in conjunction with the image itself. However, unlike in [Tu et al., PAMI 2009], we organize our recursion so that the classifiers can progressively focus on difficult-to-classify locations. This lets us exploit the power of the decision-tree paradigm while avoiding over-fitting. In the context of this architecture, KernelBoost represents a powerful building block due to its ability to learn on the score maps coming from previous iterations. We first introduce two important mechanisms to empower the KernelBoost classifier, namely pooling and the clustering of positive samples based on the appearance of the corresponding ground-truth. These operations significantly contribute to increase the effectiveness of the system on biomedical images, where texture plays a major role in the recognition of the different image components. We then present some other techniques that can be easily integrated in the KernelBoost framework to further improve the accuracy of the final segmentation. We show extensive results on different medical image datasets, including some multi-label tasks, on which our method is shown to outperform state-of-the-art approaches. The resulting segmentations display high accuracy, neat contours, and reduced noise.



### Non-parametric Image Registration of Airborne LiDAR, Hyperspectral and Photographic Imagery of Forests
- **Arxiv ID**: http://arxiv.org/abs/1410.0226v1
- **DOI**: 10.1109/TGRS.2015.2431692
- **Categories**: **cs.CV**, I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1410.0226v1)
- **Published**: 2014-07-28 11:21:57+00:00
- **Updated**: 2014-07-28 11:21:57+00:00
- **Authors**: Juheon Lee, Xiaohao Cai, Carola-Bibiane Schonlieb, David Coomes
- **Comment**: 11 pages, 5 figures
- **Journal**: None
- **Summary**: There is much current interest in using multi-sensor airborne remote sensing to monitor the structure and biodiversity of forests. This paper addresses the application of non-parametric image registration techniques to precisely align images obtained from multimodal imaging, which is critical for the successful identification of individual trees using object recognition approaches. Non-parametric image registration, in particular the technique of optimizing one objective function containing data fidelity and regularization terms, provides flexible algorithms for image registration. Using a survey of woodlands in southern Spain as an example, we show that non-parametric image registration can be successful at fusing datasets when there is little prior knowledge about how the datasets are interrelated (i.e. in the absence of ground control points). The validity of non-parametric registration methods in airborne remote sensing is demonstrated by a series of experiments. Precise data fusion is a prerequisite to accurate recognition of objects within airborne imagery, so non-parametric image registration could make a valuable contribution to the analysis pipeline.



### A discussion on the validation tests employed to compare human action recognition methods using the MSR Action3D dataset
- **Arxiv ID**: http://arxiv.org/abs/1407.7390v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.7390v3)
- **Published**: 2014-07-28 11:59:30+00:00
- **Updated**: 2015-06-16 19:57:45+00:00
- **Authors**: José Ramón Padilla-López, Alexandros André Chaaraoui, Francisco Flórez-Revuelta
- **Comment**: 16 pages and 7 tables
- **Journal**: None
- **Summary**: This paper aims to determine which is the best human action recognition method based on features extracted from RGB-D devices, such as the Microsoft Kinect. A review of all the papers that make reference to MSR Action3D, the most used dataset that includes depth information acquired from a RGB-D device, has been performed. We found that the validation method used by each work differs from the others. So, a direct comparison among works cannot be made. However, almost all the works present their results comparing them without taking into account this issue. Therefore, we present different rankings according to the methodology used for the validation in orden to clarify the existing confusion.



### A Fast Hierarchical Method for Multi-script and Arbitrary Oriented Scene Text Extraction
- **Arxiv ID**: http://arxiv.org/abs/1407.7504v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1407.7504v1)
- **Published**: 2014-07-28 19:21:53+00:00
- **Updated**: 2014-07-28 19:21:53+00:00
- **Authors**: Lluis Gomez, Dimosthenis Karatzas
- **Comment**: Manuscript Preprint. 11 pages. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible
- **Journal**: None
- **Summary**: Typography and layout lead to the hierarchical organisation of text in words, text lines, paragraphs. This inherent structure is a key property of text in any script and language, which has nonetheless been minimally leveraged by existing text detection methods. This paper addresses the problem of text segmentation in natural scenes from a hierarchical perspective. Contrary to existing methods, we make explicit use of text structure, aiming directly to the detection of region groupings corresponding to text within a hierarchy produced by an agglomerative similarity clustering process over individual regions. We propose an optimal way to construct such an hierarchy introducing a feature space designed to produce text group hypotheses with high recall and a novel stopping rule combining a discriminative classifier and a probabilistic measure of group meaningfulness based in perceptual organization. Results obtained over four standard datasets, covering text in variable orientations and different languages, demonstrate that our algorithm, while being trained in a single mixed dataset, outperforms state of the art methods in unconstrained scenarios.



### Entropic one-class classifiers
- **Arxiv ID**: http://arxiv.org/abs/1407.7556v3
- **DOI**: 10.1109/TNNLS.2015.2418332
- **Categories**: **cs.CV**, cs.LG, stat.ML, I.2.6; K.2.3
- **Links**: [PDF](http://arxiv.org/pdf/1407.7556v3)
- **Published**: 2014-07-28 20:26:24+00:00
- **Updated**: 2015-01-11 16:27:23+00:00
- **Authors**: Lorenzo Livi, Alireza Sadeghian, Witold Pedrycz
- **Comment**: To appear in IEEE-TNNLS
- **Journal**: None
- **Summary**: The one-class classification problem is a well-known research endeavor in pattern recognition. The problem is also known under different names, such as outlier and novelty/anomaly detection. The core of the problem consists in modeling and recognizing patterns belonging only to a so-called target class. All other patterns are termed non-target, and therefore they should be recognized as such. In this paper, we propose a novel one-class classification system that is based on an interplay of different techniques. Primarily, we follow a dissimilarity representation based approach; we embed the input data into the dissimilarity space by means of an appropriate parametric dissimilarity measure. This step allows us to process virtually any type of data. The dissimilarity vectors are then represented through a weighted Euclidean graphs, which we use to (i) determine the entropy of the data distribution in the dissimilarity space, and at the same time (ii) derive effective decision regions that are modeled as clusters of vertices. Since the dissimilarity measure for the input data is parametric, we optimize its parameters by means of a global optimization scheme, which considers both mesoscopic and structural characteristics of the data represented through the graphs. The proposed one-class classifier is designed to provide both hard (Boolean) and soft decisions about the recognition of test patterns, allowing an accurate description of the classification process. We evaluate the performance of the system on different benchmarking datasets, containing either feature-based or structured patterns. Experimental results demonstrate the effectiveness of the proposed technique.



