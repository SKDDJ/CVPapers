# Arxiv Papers in cs.CV on 2014-12-03
### Gradient Boundary Histograms for Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1412.1194v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1194v1)
- **Published**: 2014-12-03 05:23:03+00:00
- **Updated**: 2014-12-03 05:23:03+00:00
- **Authors**: Feng Shi, Robert Laganiere, Emil Petriu
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a high efficient local spatiotemporal descriptor, called gradient boundary histograms (GBH). The proposed GBH descriptor is built on simple spatio-temporal gradients, which are fast to compute. We demonstrate that it can better represent local structure and motion than other gradient-based descriptors, and significantly outperforms them on large realistic datasets. A comprehensive evaluation shows that the recognition accuracy is preserved while the spatial resolution is greatly reduced, which yields both high efficiency and low memory usage.



### Simple Two-Dimensional Object Tracking based on a Graph Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1412.1216v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1216v1)
- **Published**: 2014-12-03 07:16:13+00:00
- **Updated**: 2014-12-03 07:16:13+00:00
- **Authors**: Alexandra Heidsieck
- **Comment**: None
- **Journal**: None
- **Summary**: The visual observation and tracking of cells and other micrometer-sized objects has many different biomedical applications. The automation of those tasks based on computer methods helps in the evaluation of such measurements. In this work, we present a general purpose algorithm that excels at evaluating deterministic behavior of micrometer-sized objects. Our concrete application is the tracking of fast moving objects over large distances along deterministic trajectories in a microscopic video. Thereby, we are able to determine characteristic properties of the objects. For this purpose, we use a set of basic algorithms, including blob recognition, feature-based shape recognition and a graph algorithm, and combined them in a novel way. An evaluation of the algorithms performance shows a high accuracy in the recognition of objects as well as of complete trajectories. Moreover, a direct comparison to a similar algorithm shows superior recognition rates.



### Colorisation et texturation temps réel d'environnements urbains par système mobile avec scanner laser et caméra fish-eye
- **Arxiv ID**: http://arxiv.org/abs/1412.1219v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1412.1219v1)
- **Published**: 2014-12-03 07:37:04+00:00
- **Updated**: 2014-12-03 07:37:04+00:00
- **Authors**: Jean-Emmanuel Deschaud, Xavier Brun, François Goulette
- **Comment**: in French
- **Journal**: Revue Francaise de Photogrammetrie et de Teledetection, Revue
  Francaise de Photogrammetrie et de Teledetection, 2010, pp.29-37
- **Summary**: We present here a real time mobile mapping system mounted on a vehicle. The terrestrial acquisition system is based on a geolocation system and two sensors, namely, a laser scanner and a camera with a fish-eye lens. We produce 3D colored points cloud and textured models of the environment. Once the system has been calibrated, the data acquisition and processing are done "on the way". This article mainly presents our methods of colorization of point cloud, triangulation and texture mapping.



### Deeply learned face representations are sparse, selective, and robust
- **Arxiv ID**: http://arxiv.org/abs/1412.1265v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1265v1)
- **Published**: 2014-12-03 10:37:13+00:00
- **Updated**: 2014-12-03 10:37:13+00:00
- **Authors**: Yi Sun, Xiaogang Wang, Xiaoou Tang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper designs a high-performance deep convolutional network (DeepID2+) for face recognition. It is learned with the identification-verification supervisory signal. By increasing the dimension of hidden representations and adding supervision to early convolutional layers, DeepID2+ achieves new state-of-the-art on LFW and YouTube Faces benchmarks. Through empirical studies, we have discovered three properties of its deep neural activations critical for the high performance: sparsity, selectiveness and robustness. (1) It is observed that neural activations are moderately sparse. Moderate sparsity maximizes the discriminative power of the deep net as well as the distance between images. It is surprising that DeepID2+ still can achieve high recognition accuracy even after the neural responses are binarized. (2) Its neurons in higher layers are highly selective to identities and identity-related attributes. We can identify different subsets of neurons which are either constantly excited or inhibited when different identities or attributes are present. Although DeepID2+ is not taught to distinguish attributes during training, it has implicitly learned such high-level concepts. (3) It is much more robust to occlusions, although occlusion patterns are not included in the training set.



### Convolutional Feature Masking for Joint Object and Stuff Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1412.1283v4
- **DOI**: 10.1109/CVPR.2015.7299025
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1283v4)
- **Published**: 2014-12-03 11:45:34+00:00
- **Updated**: 2015-04-02 04:12:26+00:00
- **Authors**: Jifeng Dai, Kaiming He, Jian Sun
- **Comment**: IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2015
- **Journal**: None
- **Summary**: The topic of semantic segmentation has witnessed considerable progress due to the powerful features learned by convolutional neural networks (CNNs). The current leading approaches for semantic segmentation exploit shape information by extracting CNN features from masked image regions. This strategy introduces artificial boundaries on the images and may impact the quality of the extracted features. Besides, the operations on the raw image domain require to compute thousands of networks on a single image, which is time-consuming. In this paper, we propose to exploit shape information via masking convolutional features. The proposal segments (e.g., super-pixels) are treated as masks on the convolutional feature maps. The CNN features of segments are directly masked out from these maps and used to train classifiers for recognition. We further propose a joint method to handle objects and "stuff" (e.g., grass, sky, water) in the same framework. State-of-the-art results are demonstrated on benchmarks of PASCAL VOC and new PASCAL-CONTEXT, with a compelling computational speed.



### Scalable, High-Quality Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1412.1441v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1441v3)
- **Published**: 2014-12-03 19:03:55+00:00
- **Updated**: 2015-12-09 03:41:42+00:00
- **Authors**: Christian Szegedy, Scott Reed, Dumitru Erhan, Dragomir Anguelov, Sergey Ioffe
- **Comment**: None
- **Journal**: None
- **Summary**: Current high-quality object detection approaches use the scheme of salience-based object proposal methods followed by post-classification using deep convolutional features. This spurred recent research in improving object proposal methods. However, domain agnostic proposal generation has the principal drawback that the proposals come unranked or with very weak ranking, making it hard to trade-off quality for running time. This raises the more fundamental question of whether high-quality proposal generation requires careful engineering or can be derived just from data alone. We demonstrate that learning-based proposal methods can effectively match the performance of hand-engineered methods while allowing for very efficient runtime-quality trade-offs. Using the multi-scale convolutional MultiBox (MSC-MultiBox) approach, we substantially advance the state-of-the-art on the ILSVRC 2014 detection challenge data set, with $0.5$ mAP for a single model and $0.52$ mAP for an ensemble of two models. MSC-Multibox significantly improves the proposal quality over its predecessor MultiBox~method: AP increases from $0.42$ to $0.53$ for the ILSVRC detection challenge. Finally, we demonstrate improved bounding-box recall compared to Multiscale Combinatorial Grouping with less proposals on the Microsoft-COCO data set.



### Memory Bounded Deep Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1412.1442v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1442v1)
- **Published**: 2014-12-03 19:08:38+00:00
- **Updated**: 2014-12-03 19:08:38+00:00
- **Authors**: Maxwell D. Collins, Pushmeet Kohli
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we investigate the use of sparsity-inducing regularizers during training of Convolution Neural Networks (CNNs). These regularizers encourage that fewer connections in the convolution and fully connected layers take non-zero values and in effect result in sparse connectivity between hidden units in the deep network. This in turn reduces the memory and runtime cost involved in deploying the learned CNNs. We show that training with such regularization can still be performed using stochastic gradient descent implying that it can be used easily in existing codebases. Experimental evaluation of our approach on MNIST, CIFAR, and ImageNet datasets shows that our regularizers can result in dramatic reductions in memory requirements. For instance, when applied on AlexNet, our method can reduce the memory consumption by a factor of four with minimal loss in accuracy.



### Event Retrieval Using Motion Barcodes
- **Arxiv ID**: http://arxiv.org/abs/1412.1455v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.1455v3)
- **Published**: 2014-12-03 19:53:08+00:00
- **Updated**: 2015-05-12 19:10:51+00:00
- **Authors**: Gil Ben-Artzi, Michael Werman, Shmuel Peleg
- **Comment**: None
- **Journal**: Proc. ICIP'15, Quebec City, Sept. 2015, pp 2621-2625
- **Summary**: We introduce a simple and effective method for retrieval of videos showing a specific event, even when the videos of that event were captured from significantly different viewpoints. Appearance-based methods fail in such cases, as appearances change with large changes of viewpoints.   Our method is based on a pixel-based feature, "motion barcode", which records the existence/non-existence of motion as a function of time. While appearance, motion magnitude, and motion direction can vary greatly between disparate viewpoints, the existence of motion is viewpoint invariant. Based on the motion barcode, a similarity measure is developed for videos of the same event taken from very different viewpoints. This measure is robust to occlusions common under different viewpoints, and can be computed efficiently.   Event retrieval is demonstrated using challenging videos from stationary and hand held cameras.



### Textural Approach for Mass Abnormality Segmentation in Mammographic Images
- **Arxiv ID**: http://arxiv.org/abs/1412.1506v1
- **DOI**: None
- **Categories**: **cs.CV**, 68U10
- **Links**: [PDF](http://arxiv.org/pdf/1412.1506v1)
- **Published**: 2014-12-03 22:08:15+00:00
- **Updated**: 2014-12-03 22:08:15+00:00
- **Authors**: Khamsa Djaroudib, Abdelmalik Taleb Ahmed, Abdelmadjid Zidani
- **Comment**: 07 pages, 11 figures, 1 tableau, 07 equations, 34 references. appears
  in IJCSI International Journal of Computer Science Issues november 2013
- **Journal**: None
- **Summary**: Mass abnormality segmentation is a vital step for the medical diagnostic process and is attracting more and more the interest of many research groups. Currently, most of the works achieved in this area have used the Gray Level Co-occurrence Matrix (GLCM) as texture features with a region-based approach. These features come in previous phase for segmentation stage or are using as inputs to classification stage. The work discussed in this paper attempts to experiment the GLCM method under a contour-based approach. Besides, we experiment the proposed approach on various tissues densities to bring more significant results. At this end, we explored some challenging breast images from BIRADS medical Data Base. Our first experimentations showed promising results with regard to the edges mass segmentation methods. This paper discusses first the main works achieved in this area. Sections 2 and 3 present materials and our methodology. The main results are showed and evaluated before concluding our paper.



