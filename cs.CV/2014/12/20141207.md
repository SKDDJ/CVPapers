# Arxiv Papers in cs.CV on 2014-12-07
### Deep Visual-Semantic Alignments for Generating Image Descriptions
- **Arxiv ID**: http://arxiv.org/abs/1412.2306v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.2306v2)
- **Published**: 2014-12-07 02:36:07+00:00
- **Updated**: 2015-04-14 05:02:53+00:00
- **Authors**: Andrej Karpathy, Li Fei-Fei
- **Comment**: None
- **Journal**: None
- **Summary**: We present a model that generates natural language descriptions of images and their regions. Our approach leverages datasets of images and their sentence descriptions to learn about the inter-modal correspondences between language and visual data. Our alignment model is based on a novel combination of Convolutional Neural Networks over image regions, bidirectional Recurrent Neural Networks over sentences, and a structured objective that aligns the two modalities through a multimodal embedding. We then describe a Multimodal Recurrent Neural Network architecture that uses the inferred alignments to learn to generate novel descriptions of image regions. We demonstrate that our alignment model produces state of the art results in retrieval experiments on Flickr8K, Flickr30K and MSCOCO datasets. We then show that the generated descriptions significantly outperform retrieval baselines on both full images and on a new dataset of region-level annotations.



### Visual Causal Feature Learning
- **Arxiv ID**: http://arxiv.org/abs/1412.2309v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1412.2309v2)
- **Published**: 2014-12-07 03:13:27+00:00
- **Updated**: 2015-06-04 22:35:30+00:00
- **Authors**: Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt
- **Comment**: Accepted at UAI 2015
- **Journal**: None
- **Summary**: We provide a rigorous definition of the visual cause of a behavior that is broadly applicable to the visually driven behavior in humans, animals, neurons, robots and other perceiving systems. Our framework generalizes standard accounts of causal learning to settings in which the causal variables need to be constructed from micro-variables. We prove the Causal Coarsening Theorem, which allows us to gain causal knowledge from observational data with minimal experimental effort. The theorem provides a connection to standard inference techniques in machine learning that identify features of an image that correlate with, but may not cause, the target behavior. Finally, we propose an active learning scheme to learn a manipulator function that performs optimal manipulations on the image to automatically identify the visual cause of a target behavior. We illustrate our inference and learning algorithms in experiments based on both synthetic and real data.



### Bayesian Image Restoration for Poisson Corrupted Image using a Latent Variational Method with Gaussian MRF
- **Arxiv ID**: http://arxiv.org/abs/1412.2342v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.2342v1)
- **Published**: 2014-12-07 10:59:55+00:00
- **Updated**: 2014-12-07 10:59:55+00:00
- **Authors**: Hayaru Shouno
- **Comment**: 9 pages, 6 figures, The of this manuscript is submitting to the
  Information Processing Society of Japan(IPSJ), Transactions on Mathematical
  Modeling and its Applications (TOM)
- **Journal**: None
- **Summary**: We treat an image restoration problem with a Poisson noise chan- nel using a Bayesian framework. The Poisson randomness might be appeared in observation of low contrast object in the field of imaging. The noise observation is often hard to treat in a theo- retical analysis. In our formulation, we interpret the observation through the Poisson noise channel as a likelihood, and evaluate the bound of it with a Gaussian function using a latent variable method. We then introduce a Gaussian Markov random field (GMRF) as the prior for the Bayesian approach, and derive the posterior as a Gaussian distribution. The latent parameters in the likelihood and the hyperparameter in the GMRF prior could be treated as hid- den parameters, so that, we propose an algorithm to infer them in the expectation maximization (EM) framework using loopy belief propagation(LBP). We confirm the ability of our algorithm in the computer simulation, and compare it with the results of other im- age restoration frameworks.



### Nearest Descent, In-Tree, and Clustering
- **Arxiv ID**: http://arxiv.org/abs/1412.5902v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1412.5902v2)
- **Published**: 2014-12-07 11:38:55+00:00
- **Updated**: 2018-01-25 14:57:28+00:00
- **Authors**: Teng Qiu, Kaifu Yang, Chaoyi Li, Yongjie Li
- **Comment**: 28 pages: text part(1-14), supplementary material(15-28)
- **Journal**: None
- **Summary**: In this paper, we propose a physically inspired graph-theoretical clustering method, which first makes the data points organized into an attractive graph, called In-Tree, via a physically inspired rule, called Nearest Descent (ND). In particular, the rule of ND works to select the nearest node in the descending direction of potential as the parent node of each node, which is in essence different from the classical Gradient Descent or Steepest Descent. The constructed In-Tree proves a very good candidate for clustering due to its particular features and properties. In the In-Tree, the original clustering problem is reduced to a problem of removing a very few of undesired edges from this graph. Pleasingly, the undesired edges in In-Tree are so distinguishable that they can be easily determined in either automatic or interactive way, which is in stark contrast to the cases in the widely used Minimal Spanning Tree and k-nearest-neighbor graph. The cluster number in the proposed method can be easily determined based on some intermediate plots, and the cluster assignment for each node is easily made by quickly searching its root node in each sub-graph (also an In-Tree). The proposed method is extensively evaluated on both synthetic and real-world datasets. Overall, the proposed clustering method is a density-based one, but shows significant differences and advantages in comparison to the traditional ones. The proposed method is simple yet efficient and reliable, and is applicable to various datasets with diverse shapes, attributes and any high dimensionality



