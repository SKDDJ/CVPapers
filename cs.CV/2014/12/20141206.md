# Arxiv Papers in cs.CV on 2014-12-06
### Risk Estimation Without Using Stein's Lemma -- Application to Image Denoising
- **Arxiv ID**: http://arxiv.org/abs/1412.2210v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.2210v2)
- **Published**: 2014-12-06 08:00:19+00:00
- **Updated**: 2015-01-27 09:22:18+00:00
- **Authors**: Sagar Venkatesh Gubbi, Chandra Sekhar Seelamantula
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: We address the problem of image denoising in additive white noise without placing restrictive assumptions on its statistical distribution. In the recent literature, specific noise distributions have been considered and correspondingly, optimal denoising techniques have been developed. One of the successful approaches for denoising relies on the notion of unbiased risk estimation, which enables one to obtain a useful substitute for the mean-square error. For the case of additive white Gaussian noise contamination, the risk estimation procedure relies on Stein's lemma. Sophisticated wavelet-based denoising techniques, which are essentially nonlinear, have been developed with the help of the lemma. We show that, for linear, shift-invariant denoisers, it is possible to obtain unbiased risk estimates of the mean-square error without using Stein's lemma. An interesting consequence of this development is that the unbiased risk estimator becomes agnostic to the statistical distribution of the noise. As a proof of principle, we show how the new methodology can be used to optimize the parameters of a simple Gaussian smoother. By locally adapting the parameters of the Gaussian smoother, we obtain a shift-variant smoother, which has a denoising performance (quantified by the improvement in peak signal-to-noise ratio (PSNR)) that is competitive to far more sophisticated methods reported in the literature. The proposed solution exhibits considerable parallelism, which we exploit in a Graphics Processing Unit (GPU) implementation.



### Generalized Singular Value Thresholding
- **Arxiv ID**: http://arxiv.org/abs/1412.2231v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NA, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1412.2231v2)
- **Published**: 2014-12-06 13:08:29+00:00
- **Updated**: 2018-05-27 05:56:25+00:00
- **Authors**: Canyi Lu, Changbo Zhu, Chunyan Xu, Shuicheng Yan, Zhouchen Lin
- **Comment**: Proceedings of the AAAI Conference on Artificial Intelligence (AAAI),
  2015
- **Journal**: None
- **Summary**: This work studies the Generalized Singular Value Thresholding (GSVT) operator ${\text{Prox}}_{g}^{{\sigma}}(\cdot)$, \begin{equation*}   {\text{Prox}}_{g}^{{\sigma}}(B)=\arg\min\limits_{X}\sum_{i=1}^{m}g(\sigma_{i}(X)) + \frac{1}{2}||X-B||_{F}^{2}, \end{equation*} associated with a nonconvex function $g$ defined on the singular values of $X$. We prove that GSVT can be obtained by performing the proximal operator of $g$ (denoted as $\text{Prox}_g(\cdot)$) on the singular values since $\text{Prox}_g(\cdot)$ is monotone when $g$ is lower bounded. If the nonconvex $g$ satisfies some conditions (many popular nonconvex surrogate functions, e.g., $\ell_p$-norm, $0<p<1$, of $\ell_0$-norm are special cases), a general solver to find $\text{Prox}_g(b)$ is proposed for any $b\geq0$. GSVT greatly generalizes the known Singular Value Thresholding (SVT) which is a basic subroutine in many convex low rank minimization methods. We are able to solve the nonconvex low rank minimization problem by using GSVT in place of SVT.



### Adjusted least squares fitting of algebraic hypersurfaces
- **Arxiv ID**: http://arxiv.org/abs/1412.2291v2
- **DOI**: 10.1016/j.laa.2015.07.023
- **Categories**: **stat.CO**, cs.CG, cs.CV, math.NA, 15A22, 15B05, 33C45, 62H12, 65D10, 65F15, 68U05
- **Links**: [PDF](http://arxiv.org/pdf/1412.2291v2)
- **Published**: 2014-12-06 22:22:33+00:00
- **Updated**: 2015-08-20 17:00:19+00:00
- **Authors**: Konstantin Usevich, Ivan Markovsky
- **Comment**: 30 pages, 10 figures
- **Journal**: None
- **Summary**: We consider the problem of fitting a set of points in Euclidean space by an algebraic hypersurface. We assume that points on a true hypersurface, described by a polynomial equation, are corrupted by zero mean independent Gaussian noise, and we estimate the coefficients of the true polynomial equation. The adjusted least squares estimator accounts for the bias present in the ordinary least squares estimator. The adjusted least squares estimator is based on constructing a quasi-Hankel matrix, which is a bias-corrected matrix of moments. For the case of unknown noise variance, the estimator is defined as a solution of a polynomial eigenvalue problem. In this paper, we present new results on invariance properties of the adjusted least squares estimator and an improved algorithm for computing the estimator for an arbitrary set of monomials in the polynomial equation.



