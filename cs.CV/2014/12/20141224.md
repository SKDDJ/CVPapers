# Arxiv Papers in cs.CV on 2014-12-24
### An Effective Semi-supervised Divisive Clustering Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1412.7625v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1412.7625v2)
- **Published**: 2014-12-24 08:55:50+00:00
- **Updated**: 2015-01-06 09:35:39+00:00
- **Authors**: Teng Qiu, Yongjie Li
- **Comment**: 8 pages, 4 figures, a new (6th) member of the in-tree clustering
  family
- **Journal**: None
- **Summary**: Nowadays, data are generated massively and rapidly from scientific fields as bioinformatics, neuroscience and astronomy to business and engineering fields. Cluster analysis, as one of the major data analysis tools, is therefore more significant than ever. We propose in this work an effective Semi-supervised Divisive Clustering algorithm (SDC). Data points are first organized by a minimal spanning tree. Next, this tree structure is transitioned to the in-tree structure, and then divided into sub-trees under the supervision of the labeled data, and in the end, all points in the sub-trees are directly associated with specific cluster centers. SDC is fully automatic, non-iterative, involving no free parameter, insensitive to noise, able to detect irregularly shaped cluster structures, applicable to the data sets of high dimensionality and different attributes. The power of SDC is demonstrated on several datasets.



### AltecOnDB: A Large-Vocabulary Arabic Online Handwriting Recognition Database
- **Arxiv ID**: http://arxiv.org/abs/1412.7626v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.7626v1)
- **Published**: 2014-12-24 08:58:10+00:00
- **Updated**: 2014-12-24 08:58:10+00:00
- **Authors**: Ibrahim Abdelaziz, Sherif Abdou
- **Comment**: The preprint is in submission
- **Journal**: None
- **Summary**: Arabic is a semitic language characterized by a complex and rich morphology. The exceptional degree of ambiguity in the writing system, the rich morphology, and the highly complex word formation process of roots and patterns all contribute to making computational approaches to Arabic very challenging. As a result, a practical handwriting recognition system should support large vocabulary to provide a high coverage and use the context information for disambiguation. Several research efforts have been devoted for building online Arabic handwriting recognition systems. Most of these methods are either using their small private test data sets or a standard database with limited lexicon and coverage. A large scale handwriting database is an essential resource that can advance the research of online handwriting recognition. Currently, there is no online Arabic handwriting database with large lexicon, high coverage, large number of writers and training/testing data.   In this paper, we introduce AltecOnDB, a large scale online Arabic handwriting database. AltecOnDB has 98% coverage of all the possible PAWS of the Arabic language. The collected samples are complete sentences that include digits and punctuation marks. The collected data is available on sentence, word and character levels, hence, high-level linguistic models can be used for performance improvements. Data is collected from more than 1000 writers with different backgrounds, genders and ages. Annotation and verification tools are developed to facilitate the annotation and verification phases. We built an elementary recognition system to test our database and show the existing difficulties when handling a large vocabulary and dealing with large amounts of styles variations in the collected data.



### Transformation Properties of Learned Visual Representations
- **Arxiv ID**: http://arxiv.org/abs/1412.7659v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1412.7659v3)
- **Published**: 2014-12-24 13:19:20+00:00
- **Updated**: 2015-04-07 21:20:04+00:00
- **Authors**: Taco S. Cohen, Max Welling
- **Comment**: T.S. Cohen & M. Welling, Transformation Properties of Learned Visual
  Representations. In International Conference on Learning Representations
  (ICLR), 2015
- **Journal**: Proceedings of the International Conference on Learning
  Representations, 2015
- **Summary**: When a three-dimensional object moves relative to an observer, a change occurs on the observer's image plane and in the visual representation computed by a learned model. Starting with the idea that a good visual representation is one that transforms linearly under scene motions, we show, using the theory of group representations, that any such representation is equivalent to a combination of the elementary irreducible representations. We derive a striking relationship between irreducibility and the statistical dependency structure of the representation, by showing that under restricted conditions, irreducible representations are decorrelated. Under partial observability, as induced by the perspective projection of a scene onto the image plane, the motion group does not have a linear action on the space of images, so that it becomes necessary to perform inference over a latent representation that does transform linearly. This idea is demonstrated in a model of rotating NORB objects that employs a latent representation of the non-commutative 3D rotation group SO(3).



### A Fuzzy Based Model to Identify Printed Sinhala Characters (ICIAfS14)
- **Arxiv ID**: http://arxiv.org/abs/1412.7680v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.7680v1)
- **Published**: 2014-12-24 14:56:54+00:00
- **Updated**: 2014-12-24 14:56:54+00:00
- **Authors**: G. I. Gunarathna, M. A. P. Chamikara, R. G. Ragel
- **Comment**: The 7th International Conference on Information and Automation for
  Sustainability (ICIAfS) 2014
- **Journal**: None
- **Summary**: Character recognition techniques for printed documents are widely used for English language. However, the systems that are implemented to recognize Asian languages struggle to increase the accuracy of recognition. Among other Asian languages (such as Arabic, Tamil, Chinese), Sinhala characters are unique, mainly because they are round in shape. This unique feature makes it a challenge to extend the prevailing techniques to improve recognition of Sinhala characters. Therefore, a little attention has been given to improve the accuracy of Sinhala character recognition. A novel method, which makes use of this unique feature, could be advantageous over other methods. This paper describes the use of a fuzzy inference system to recognize Sinhala characters. Feature extraction is mainly focused on distance and intersection measurements in different directions from the center of the letter making use of the round shape of characters. The results showed an overall accuracy of 90.7% for 140 instances of letters tested, much better than similar systems.



### Locating Tables in Scanned Documents for Reconstructing and Republishing (ICIAfS14)
- **Arxiv ID**: http://arxiv.org/abs/1412.7689v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.7689v1)
- **Published**: 2014-12-24 15:29:13+00:00
- **Updated**: 2014-12-24 15:29:13+00:00
- **Authors**: Akmal Jahan Mac, Roshan G Ragel
- **Comment**: The 7th International Conference on Information and Automation for
  Sustainability (ICIAfS) 2014
- **Journal**: None
- **Summary**: Pool of knowledge available to the mankind depends on the source of learning resources, which can vary from ancient printed documents to present electronic material. The rapid conversion of material available in traditional libraries to digital form needs a significant amount of work if we are to maintain the format and the look of the electronic documents as same as their printed counterparts. Most of the printed documents contain not only characters and its formatting but also some associated non text objects such as tables, charts and graphical objects. It is challenging to detect them and to concentrate on the format preservation of the contents while reproducing them. To address this issue, we propose an algorithm using local thresholds for word space and line height to locate and extract all categories of tables from scanned document images. From the experiments performed on 298 documents, we conclude that our algorithm has an overall accuracy of about 75% in detecting tables from the scanned document images. Since the algorithm does not completely depend on rule lines, it can detect all categories of tables in a range of scanned documents with different font types, styles and sizes to extract their formatting features. Moreover, the algorithm can be applied to locate tables in multi column layouts with small modification in layout analysis. Treating tables with their existing formatting features will tremendously help the reproducing of printed documents for reprinting and updating purposes.



### Automatic Photo Adjustment Using Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1412.7725v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1412.7725v2)
- **Published**: 2014-12-24 17:51:17+00:00
- **Updated**: 2015-05-16 03:49:35+00:00
- **Authors**: Zhicheng Yan, Hao Zhang, Baoyuan Wang, Sylvain Paris, Yizhou Yu
- **Comment**: TOG minor revision
- **Journal**: None
- **Summary**: Photo retouching enables photographers to invoke dramatic visual impressions by artistically enhancing their photos through stylistic color and tone adjustments. However, it is also a time-consuming and challenging task that requires advanced skills beyond the abilities of casual photographers. Using an automated algorithm is an appealing alternative to manual work but such an algorithm faces many hurdles. Many photographic styles rely on subtle adjustments that depend on the image content and even its semantics. Further, these adjustments are often spatially varying. Because of these characteristics, existing automatic algorithms are still limited and cover only a subset of these challenges. Recently, deep machine learning has shown unique abilities to address hard problems that resisted machine algorithms for long. This motivated us to explore the use of deep learning in the context of photo editing. In this paper, we explain how to formulate the automatic photo adjustment problem in a way suitable for this approach. We also introduce an image descriptor that accounts for the local semantics of an image. Our experiments demonstrate that our deep learning formulation applied using these descriptors successfully capture sophisticated photographic styles. In particular and unlike previous techniques, it can model local adjustments that depend on the image semantics. We show on several examples that this yields results that are qualitatively and quantitatively better than previous work.



### Multiple Object Recognition with Visual Attention
- **Arxiv ID**: http://arxiv.org/abs/1412.7755v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1412.7755v2)
- **Published**: 2014-12-24 20:58:23+00:00
- **Updated**: 2015-04-23 16:49:23+00:00
- **Authors**: Jimmy Ba, Volodymyr Mnih, Koray Kavukcuoglu
- **Comment**: None
- **Journal**: None
- **Summary**: We present an attention-based model for recognizing multiple objects in images. The proposed model is a deep recurrent neural network trained with reinforcement learning to attend to the most relevant regions of the input image. We show that the model learns to both localize and recognize multiple objects despite being given only class labels during training. We evaluate the model on the challenging task of transcribing house number sequences from Google Street View images and show that it is both more accurate than the state-of-the-art convolutional networks and uses fewer parameters and less computation.



