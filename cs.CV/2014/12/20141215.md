# Arxiv Papers in cs.CV on 2014-12-15
### Inexact Alternating Direction Method Based on Newton descent algorithm with Application to Poisson Image Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1412.4433v2
- **DOI**: None
- **Categories**: **cs.CV**, 68U10, 90C90, 65T60
- **Links**: [PDF](http://arxiv.org/pdf/1412.4433v2)
- **Published**: 2014-12-15 00:57:44+00:00
- **Updated**: 2015-03-16 07:05:59+00:00
- **Authors**: Dai-Qiang Chen
- **Comment**: 23 pages, 7 figures
- **Journal**: None
- **Summary**: The recovery of images from the observations that are degraded by a linear operator and further corrupted by Poisson noise is an important task in modern imaging applications such as astronomical and biomedical ones. Gradient-based regularizers involve the popular total variation semi-norm have become standard techniques for Poisson image restoration due to its edge-preserving ability. Various efficient algorithms have been developed for solving the corresponding minimization problem with non-smooth regularization terms. In this paper, motivated by the idea of the alternating direction minimization algorithm and the Newton's method with upper convergent rate, we further propose inexact alternating direction methods utilizing the proximal Hessian matrix information of the objective function, in a way reminiscent of Newton descent methods. Besides, we also investigate the global convergence of the proposed algorithms under certain conditions. Finally, we illustrate that the proposed algorithms outperform the current state-of-the-art algorithms through numerical experiments on Poisson image deblurring.



### Fixed Point Algorithm Based on Quasi-Newton Method for Convex Minimization Problem with Application to Image Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1412.4438v1
- **DOI**: None
- **Categories**: **cs.CV**, 68U10, 90C90, 65T60
- **Links**: [PDF](http://arxiv.org/pdf/1412.4438v1)
- **Published**: 2014-12-15 01:12:09+00:00
- **Updated**: 2014-12-15 01:12:09+00:00
- **Authors**: Dai-Qiang Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Solving an optimization problem whose objective function is the sum of two convex functions has received considerable interests in the context of image processing recently. In particular, we are interested in the scenario when a non-differentiable convex function such as the total variation (TV) norm is included in the objective function due to many variational models established in image processing have this nature. In this paper, we propose a fast fixed point algorithm based on the quasi-Newton method for solving this class of problem, and apply it in the field of TV-based image deblurring. The novel method is derived from the idea of the quasi-Newton method, and the fixed-point algorithms based on the proximity operator, which were widely investigated very recently. Utilizing the non-expansion property of the proximity operator we further investigate the global convergence of the proposed algorithm. Numerical experiments on image deblurring problem with additive or multiplicative noise are presented to demonstrate that the proposed algorithm is superior to the recently developed fixed-point algorithm in the computational efficiency.



### Automatic video scene segmentation based on spatial-temporal clues and rhythm
- **Arxiv ID**: http://arxiv.org/abs/1412.4470v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.4470v1)
- **Published**: 2014-12-15 06:12:47+00:00
- **Updated**: 2014-12-15 06:12:47+00:00
- **Authors**: Walid Mahdi, Liming Chen, Mohsen Ardebilian
- **Comment**: 25 pages, 12 figures
- **Journal**: Video DATA Hermes Science Publishing, 2002
- **Summary**: With ever increasing computing power and data storage capacity, the potential for large digital video libraries is growing rapidly.However, the massive use of video for the moment is limited by its opaque characteristics. Indeed, a user who has to handle and retrieve sequentially needs too much time in order to find out segments of interest within a video. Therefore, providing an environment both convenient and efficient for video storing and retrieval, especially for content-based searching as this exists in traditional textbased database systems, has been the focus of recent and important efforts of a large research community   In this paper, we propose a new automatic video scene segmentation method that explores two main video features; these are spatial-temporal relationship and rhythm of shots. The experimental evidence we obtained from a 80 minutevideo showed that our prototype provides very high accuracy for video segmentation.



### CITlab ARGUS for historical data tables
- **Arxiv ID**: http://arxiv.org/abs/1412.6012v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, 68T05, 68T10
- **Links**: [PDF](http://arxiv.org/pdf/1412.6012v1)
- **Published**: 2014-12-15 06:54:47+00:00
- **Updated**: 2014-12-15 06:54:47+00:00
- **Authors**: Gundram Leifert, Tobias Grüning, Tobias Strauß, Roger Labahn
- **Comment**: arXiv admin note: text overlap with arXiv:1412.3949
- **Journal**: None
- **Summary**: We describe CITlab's recognition system for the ANWRESH-2014 competition attached to the 14. International Conference on Frontiers in Handwriting Recognition, ICFHR 2014. The task comprises word recognition from segmented historical documents. The core components of our system are based on multi-dimensional recurrent neural networks (MDRNN) and connectionist temporal classification (CTC). The software modules behind that as well as the basic utility technologies are essentially powered by PLANET's ARGUS framework for intelligent text recognition and image processing.



### CITlab ARGUS for Arabic Handwriting
- **Arxiv ID**: http://arxiv.org/abs/1412.6061v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE, 68T10, 68T05
- **Links**: [PDF](http://arxiv.org/pdf/1412.6061v1)
- **Published**: 2014-12-15 06:55:28+00:00
- **Updated**: 2014-12-15 06:55:28+00:00
- **Authors**: Gundram Leifert, Roger Labahn, Tobias Strauß
- **Comment**: http://www.nist.gov/itl/iad/mig/upload/OpenHaRT2013_SysDesc_CITLAB.pdf
- **Journal**: None
- **Summary**: In the recent years it turned out that multidimensional recurrent neural networks (MDRNN) perform very well for offline handwriting recognition tasks like the OpenHaRT 2013 evaluation DIR. With suitable writing preprocessing and dictionary lookup, our ARGUS software completed this task with an error rate of 26.27% in its primary setup.



### Highly Efficient Forward and Backward Propagation of Convolutional Neural Networks for Pixelwise Classification
- **Arxiv ID**: http://arxiv.org/abs/1412.4526v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.4526v2)
- **Published**: 2014-12-15 10:36:49+00:00
- **Updated**: 2014-12-16 02:35:23+00:00
- **Authors**: Hongsheng Li, Rui Zhao, Xiaogang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: We present highly efficient algorithms for performing forward and backward propagation of Convolutional Neural Network (CNN) for pixelwise classification on images. For pixelwise classification tasks, such as image segmentation and object detection, surrounding image patches are fed into CNN for predicting the classes of centered pixels via forward propagation and for updating CNN parameters via backward propagation. However, forward and backward propagation was originally designed for whole-image classification. Directly applying it to pixelwise classification in a patch-by-patch scanning manner is extremely inefficient, because surrounding patches of pixels have large overlaps, which lead to a lot of redundant computation.   The proposed algorithms eliminate all the redundant computation in convolution and pooling on images by introducing novel d-regularly sparse kernels. It generates exactly the same results as those by patch-by-patch scanning. Convolution and pooling operations with such kernels are able to continuously access memory and can run efficiently on GPUs. A fraction of patches of interest can be chosen from each training image for backward propagation by applying a mask to the error map at the last CNN layer. Its computation complexity is constant with respect to the number of patches sampled from the image. Experiments have shown that our proposed algorithms speed up commonly used patch-by-patch scanning over 1500 times in both forward and backward propagation. The speedup increases with the sizes of images and patches.



### MatConvNet - Convolutional Neural Networks for MATLAB
- **Arxiv ID**: http://arxiv.org/abs/1412.4564v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MS, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1412.4564v3)
- **Published**: 2014-12-15 12:23:35+00:00
- **Updated**: 2016-05-05 14:31:06+00:00
- **Authors**: Andrea Vedaldi, Karel Lenc
- **Comment**: Updated for release v1.0-beta20
- **Journal**: None
- **Summary**: MatConvNet is an implementation of Convolutional Neural Networks (CNNs) for MATLAB. The toolbox is designed with an emphasis on simplicity and flexibility. It exposes the building blocks of CNNs as easy-to-use MATLAB functions, providing routines for computing linear convolutions with filter banks, feature pooling, and many more. In this manner, MatConvNet allows fast prototyping of new CNN architectures; at the same time, it supports efficient computation on CPU and GPU allowing to train complex models on large datasets such as ImageNet ILSVRC. This document provides an overview of CNNs and how they are implemented in MatConvNet and gives the technical details of each computational block in the toolbox.



### Finding a sparse vector in a subspace: Linear sparsity using alternating directions
- **Arxiv ID**: http://arxiv.org/abs/1412.4659v3
- **DOI**: 10.1109/TIT.2016.2601599
- **Categories**: **cs.IT**, cs.CV, cs.LG, math.IT, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1412.4659v3)
- **Published**: 2014-12-15 16:27:29+00:00
- **Updated**: 2016-07-20 00:54:41+00:00
- **Authors**: Qing Qu, Ju Sun, John Wright
- **Comment**: Accepted by IEEE Trans. Information Theory. The paper has been
  revised by the reviewers' comments. The proofs have been streamlined
- **Journal**: IEEE Transaction on Information Theory, 62(10):5855 - 5880, 2016
- **Summary**: Is it possible to find the sparsest vector (direction) in a generic subspace $\mathcal{S} \subseteq \mathbb{R}^p$ with $\mathrm{dim}(\mathcal{S})= n < p$? This problem can be considered a homogeneous variant of the sparse recovery problem, and finds connections to sparse dictionary learning, sparse PCA, and many other problems in signal processing and machine learning. In this paper, we focus on a **planted sparse model** for the subspace: the target sparse vector is embedded in an otherwise random subspace. Simple convex heuristics for this planted recovery problem provably break down when the fraction of nonzero entries in the target sparse vector substantially exceeds $O(1/\sqrt{n})$. In contrast, we exhibit a relatively simple nonconvex approach based on alternating directions, which provably succeeds even when the fraction of nonzero entries is $\Omega(1)$. To the best of our knowledge, this is the first practical algorithm to achieve linear scaling under the planted sparse model. Empirically, our proposed algorithm also succeeds in more challenging data models, e.g., sparse dictionary learning.



### Translating Videos to Natural Language Using Deep Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1412.4729v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1412.4729v3)
- **Published**: 2014-12-15 19:21:50+00:00
- **Updated**: 2015-04-30 04:22:06+00:00
- **Authors**: Subhashini Venugopalan, Huijuan Xu, Jeff Donahue, Marcus Rohrbach, Raymond Mooney, Kate Saenko
- **Comment**: NAACL-HLT 2015 camera ready
- **Journal**: None
- **Summary**: Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure. Described video datasets are scarce, and most existing methods have been applied to toy domains with a small vocabulary of possible words. By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies. We compare our approach with recent work using language generation metrics, subject, verb, and object prediction accuracy, and a human evaluation.



