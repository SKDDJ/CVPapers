# Arxiv Papers in cs.CV on 2014-12-17
### Iranian cashes recognition using mobile
- **Arxiv ID**: http://arxiv.org/abs/1412.5275v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5275v1)
- **Published**: 2014-12-17 07:51:56+00:00
- **Updated**: 2014-12-17 07:51:56+00:00
- **Authors**: Ismail Nojavani, Azade Rezaeezade, Amirhassan Monadjemi
- **Comment**: arXiv #133709
- **Journal**: International Journal of Computer Science & Information
  Technology, volume 6, issue 6, pp.61-71, 2014
- **Summary**: In economical societies of today, using cash is an inseparable aspect of human life. People use cashes for marketing, services, entertainments, bank operations and so on. This huge amount of contact with cash and the necessity of knowing the monetary value of it caused one of the most challenging problems for visually impaired people. In this paper we propose a mobile phone based approach to identify monetary value of a picture taken from cashes using some image processing and machine vision techniques. While the developed approach is very fast, it can recognize the value of cash by average accuracy of about 95% and can overcome different challenges like rotation, scaling, collision, illumination changes, perspective, and some others.



### An Algebraical Model for Gray Level Images
- **Arxiv ID**: http://arxiv.org/abs/1412.5322v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5322v1)
- **Published**: 2014-12-17 10:21:10+00:00
- **Updated**: 2014-12-17 10:21:10+00:00
- **Authors**: Vasile Patrascu
- **Comment**: The 7th International Conference, Exhibition on Optimization of
  Electrical and Electronic Equipment, OPTIM 2000, Bra\c{s}ov, Rom\^ania 11-12
  May, 2000
- **Journal**: None
- **Summary**: In this paper we propose a new algebraical model for the gray level images. It can be used for digital image processing. The model adresses to those images which are generated in improper light conditions (very low or high level). The vector space structure is able to illustrate some features into the image using modified level of contrast and luminosity. Also, the defined structure could be used in image enhancement. The general approach is presented with experimental results to demonstrate image enhancement.



### Color Image Enhancement In the Framework of Logarithmic Models
- **Arxiv ID**: http://arxiv.org/abs/1412.5325v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5325v1)
- **Published**: 2014-12-17 10:32:07+00:00
- **Updated**: 2014-12-17 10:32:07+00:00
- **Authors**: Vasile Patrascu, Vasile Buzuloiu
- **Comment**: The 8th IEEE International Conference on Telecommunications, Vol. 1,
  pp. 199-204, IEEE ICT2001, June 4 - 7, 2001, Bucharest,Romania
- **Journal**: None
- **Summary**: In this paper, we propose a mathematical model for color image processing. It is a logarithmical one. We consider the cube (-1,1)x(-1,1)x(-1,1) as the set of values for the color space. We define two operations: addition <+> and real scalar multiplication <x>. With these operations the space of colors becomes a real vector space. Then, defining the scalar product (.|.) and the norm || . ||, we obtain a (logarithmic) Euclidean space. We show how we can use this model for color image enhancement and we present some experimental results.



### A Mathematical Model for Logarithmic Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1412.5328v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5328v1)
- **Published**: 2014-12-17 10:50:25+00:00
- **Updated**: 2014-12-17 10:50:25+00:00
- **Authors**: Vasile Patrascu, Vasile Buzuloiu
- **Comment**: The 5th World Multi-Conference on Systemics, Cybernetics and
  Informatics, Vol 13, pp. 117-122, SCI2001, July 22-25, 2001, Orlando, USA
- **Journal**: None
- **Summary**: In this paper, we propose a new mathematical model for image processing. It is a logarithmical one. We consider the bounded interval (-1, 1) as the set of gray levels. Firstly, we define two operations: addition <+> and real scalar multiplication <x>. With these operations, the set of gray levels becomes a real vector space. Then, defining the scalar product (.|.) and the norm || . ||, we obtain an Euclidean space of the gray levels. Secondly, we extend these operations and functions for color images. We finally show the effect of various simple operations on an image.



### The Affine Transforms for Image Enhancement in the Context of Logarithmic Models
- **Arxiv ID**: http://arxiv.org/abs/1412.5334v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5334v1)
- **Published**: 2014-12-17 10:58:46+00:00
- **Updated**: 2014-12-17 10:58:46+00:00
- **Authors**: Vasile Patrascu, Vasile Buzuloiu
- **Comment**: International Conference on Computer Vision and Graphics, ICCVG2002,
  25-29 September, 2002, Zakopane, Poland
- **Journal**: None
- **Summary**: The logarithmic model offers new tools for image processing. An efficient method for image enhancement is to use an affine transformation with the logarithmic operations: addition and scalar multiplication. We define some criteria for automatically determining the parameters of the processing and this is done via mean and variance computed by logarithmic operations.



### Full-reference image quality assessment by combining global and local distortion measures
- **Arxiv ID**: http://arxiv.org/abs/1412.5488v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5488v1)
- **Published**: 2014-12-17 17:15:12+00:00
- **Updated**: 2014-12-17 17:15:12+00:00
- **Authors**: Ashirbani Saha, Q. M. Jonathan Wu
- **Comment**: 31 pages, 8 figures, 2 tables
- **Journal**: None
- **Summary**: Full-reference image quality assessment (FR-IQA) techniques compare a reference and a distorted/test image and predict the perceptual quality of the test image in terms of a scalar value representing an objective score. The evaluation of FR-IQA techniques is carried out by comparing the objective scores from the techniques with the subjective scores (obtained from human observers) provided in the image databases used for the IQA. Hence, we reasonably assume that the goal of a human observer is to rate the distortion present in the test image. The goal oriented tasks are processed by the human visual system (HVS) through top-down processing which actively searches for local distortions driven by the goal. Therefore local distortion measures in an image are important for the top-down processing. At the same time, bottom-up processing also takes place signifying spontaneous visual functions in the HVS. To account for this, global perceptual features can be used. Therefore, we hypothesize that the resulting objective score for an image can be derived from the combination of local and global distortion measures calculated from the reference and test images. We calculate the local distortion by measuring the local correlation differences from the gradient and contrast information. For global distortion, dissimilarity of the saliency maps computed from a bottom-up model of saliency is used. The motivation behind the proposed approach has been thoroughly discussed, accompanied by an intuitive analysis. Finally, experiments are conducted in six benchmark databases suggesting the effectiveness of the proposed approach that achieves competitive performance with the state-of-the-art methods providing an improvement in the overall performance.



### High Frequency Content based Stimulus for Perceptual Sharpness Assessment in Natural Images
- **Arxiv ID**: http://arxiv.org/abs/1412.5490v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1412.5490v2)
- **Published**: 2014-12-17 17:28:53+00:00
- **Updated**: 2014-12-18 02:57:51+00:00
- **Authors**: Ashirbani Saha, Q. M. Jonathan Wu
- **Comment**: 13 pages, 6 figures, 3 tables
- **Journal**: None
- **Summary**: A blind approach to evaluate the perceptual sharpness present in a natural image is proposed. Though the literature demonstrates a set of variegated visual cues to detect or evaluate the absence or presence of sharpness, we emphasize in the current work that high frequency content and local standard deviation can form strong features to compute perceived sharpness in any natural image, and can be considered an able alternative for the existing cues. Unsharp areas in a natural image happen to exhibit uniform intensity or lack of sharp changes between regions. Sharp region transitions in an image are caused by the presence of spatial high frequency content. Therefore, in the proposed approach, we hypothesize that using the high frequency content as the principal stimulus, the perceived sharpness can be quantified in an image. When an image is convolved with a high pass filter, higher values at any pixel location signify the presence of high frequency content at those locations. Considering these values as the stimulus, the exponent of the stimulus is weighted by local standard deviation to impart the contribution of the local contrast within the formation of the sharpness map. The sharpness map highlights the relatively sharper regions in the image and is used to calculate the perceived sharpness score of the image. The advantages of the proposed method lie in its use of simple visual cues of high frequency content and local contrast to arrive at the perceptual score, and requiring no training with the images. The promise of the proposed method is demonstrated by its ability to compute perceived sharpness for within image and across image sharpness changes and for blind evaluation of perceptual degradation resulting due to presence of blur. Experiments conducted on several databases demonstrate improved performance of the proposed method over that of the state-of-the-art techniques.



### DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1412.5661v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1412.5661v2)
- **Published**: 2014-12-17 22:41:35+00:00
- **Updated**: 2015-06-02 03:24:08+00:00
- **Authors**: Wanli Ouyang, Xiaogang Wang, Xingyu Zeng, Shi Qiu, Ping Luo, Yonglong Tian, Hongsheng Li, Shuo Yang, Zhe Wang, Chen-Change Loy, Xiaoou Tang
- **Comment**: CVPR15, arXiv admin note: substantial text overlap with
  arXiv:1409.3505
- **Journal**: None
- **Summary**: In this paper, we propose deformable deep convolutional neural networks for generic object detection. This new deep learning object detection framework has innovations in multiple aspects. In the proposed new deep architecture, a new deformation constrained pooling (def-pooling) layer models the deformation of object parts with geometric constraint and penalty. A new pre-training strategy is proposed to learn feature representations more suitable for the object detection task and with good generalization capability. By changing the net structures, training strategies, adding and removing some key components in the detection pipeline, a set of models with large diversity are obtained, which significantly improves the effectiveness of model averaging. The proposed approach improves the mean averaged precision obtained by RCNN \cite{girshick2014rich}, which was the state-of-the-art, from 31\% to 50.3\% on the ILSVRC2014 detection test set. It also outperforms the winner of ILSVRC2014, GoogLeNet, by 6.1\%. Detailed component-wise analysis is also provided through extensive experimental evaluation, which provide a global view for people to understand the deep learning object detection pipeline.



