# Arxiv Papers in cs.CV on 2014-06-17
### Replicating Kernels with a Short Stride Allows Sparse Reconstructions with Fewer Independent Kernels
- **Arxiv ID**: http://arxiv.org/abs/1406.4205v1
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1406.4205v1)
- **Published**: 2014-06-17 01:07:48+00:00
- **Updated**: 2014-06-17 01:07:48+00:00
- **Authors**: Peter F. Schultz, Dylan M. Paiton, Wei Lu, Garrett T. Kenyon
- **Comment**: None
- **Journal**: None
- **Summary**: In sparse coding it is common to tile an image into nonoverlapping patches, and then use a dictionary to create a sparse representation of each tile independently. In this situation, the overcompleteness of the dictionary is the number of dictionary elements divided by the patch size. In deconvolutional neural networks (DCNs), dictionaries learned on nonoverlapping tiles are replaced by a family of convolution kernels. Hence adjacent points in the feature maps (V1 layers) have receptive fields in the image that are translations of each other. The translational distance is determined by the dimensions of V1 in comparison to the dimensions of the image space. We refer to this translational distance as the stride.   We implement a type of DCN using a modified Locally Competitive Algorithm (LCA) to investigate the relationship between the number of kernels, the stride, the receptive field size, and the quality of reconstruction. We find, for example, that for 16x16-pixel receptive fields, using eight kernels and a stride of 2 leads to sparse reconstructions of comparable quality as using 512 kernels and a stride of 16 (the nonoverlapping case). We also find that for a given stride and number of kernels, the patch size does not significantly affect reconstruction quality. Instead, the learned convolution kernels have a natural support radius independent of the patch size.



### Person Re-identification by Local Maximal Occurrence Representation and Metric Learning
- **Arxiv ID**: http://arxiv.org/abs/1406.4216v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.4216v2)
- **Published**: 2014-06-17 01:53:37+00:00
- **Updated**: 2015-05-06 14:01:28+00:00
- **Authors**: Shengcai Liao, Yang Hu, Xiangyu Zhu, Stan Z. Li
- **Comment**: This paper has been accepted by CVPR 2015. For source codes and
  extracted features please visit
  http://www.cbsr.ia.ac.cn/users/scliao/projects/lomo_xqda/
- **Journal**: None
- **Summary**: Person re-identification is an important technique towards automatic search of a person's presence in a surveillance video. Two fundamental problems are critical for person re-identification, feature representation and metric learning. An effective feature representation should be robust to illumination and viewpoint changes, and a discriminant metric should be learned to match various person images. In this paper, we propose an effective feature representation called Local Maximal Occurrence (LOMO), and a subspace and metric learning method called Cross-view Quadratic Discriminant Analysis (XQDA). The LOMO feature analyzes the horizontal occurrence of local features, and maximizes the occurrence to make a stable representation against viewpoint changes. Besides, to handle illumination variations, we apply the Retinex transform and a scale invariant texture operator. To learn a discriminant metric, we propose to learn a discriminant low dimensional subspace by cross-view quadratic discriminant analysis, and simultaneously, a QDA metric is learned on the derived subspace. We also present a practical computation method for XQDA, as well as its regularization. Experiments on four challenging person re-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, show that the proposed method improves the state-of-the-art rank-1 identification rates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively.



### Self-Learning Camera: Autonomous Adaptation of Object Detectors to Unlabeled Video Streams
- **Arxiv ID**: http://arxiv.org/abs/1406.4296v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.4296v2)
- **Published**: 2014-06-17 09:51:18+00:00
- **Updated**: 2014-06-18 12:33:22+00:00
- **Authors**: Adrien Gaidon, Gloria Zen, Jose A. Rodriguez-Serrano
- **Comment**: None
- **Journal**: None
- **Summary**: Learning object detectors requires massive amounts of labeled training samples from the specific data source of interest. This is impractical when dealing with many different sources (e.g., in camera networks), or constantly changing ones such as mobile cameras (e.g., in robotics or driving assistant systems). In this paper, we address the problem of self-learning detectors in an autonomous manner, i.e. (i) detectors continuously updating themselves to efficiently adapt to streaming data sources (contrary to transductive algorithms), (ii) without any labeled data strongly related to the target data stream (contrary to self-paced learning), and (iii) without manual intervention to set and update hyper-parameters. To that end, we propose an unsupervised, on-line, and self-tuning learning algorithm to optimize a multi-task learning convex objective. Our method uses confident but laconic oracles (high-precision but low-recall off-the-shelf generic detectors), and exploits the structure of the problem to jointly learn on-line an ensemble of instance-level trackers, from which we derive an adapted category-level object detector. Our approach is validated on real-world publicly available video object datasets.



### Block matching algorithm based on Harmony Search optimization for motion estimation
- **Arxiv ID**: http://arxiv.org/abs/1406.4484v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.4484v1)
- **Published**: 2014-06-17 19:13:40+00:00
- **Updated**: 2014-06-17 19:13:40+00:00
- **Authors**: Erik Cuevas
- **Comment**: 25 Pages. arXiv admin note: substantial text overlap with
  arXiv:1405.4721
- **Journal**: Applied Intelligence, 39 (1), (2013), pp. 165-183
- **Summary**: Motion estimation is one of the major problems in developing video coding applications. Among all motion estimation approaches, Block-matching (BM) algorithms are the most popular methods due to their effectiveness and simplicity for both software and hardware implementations. A BM approach assumes that the movement of pixels within a defined region of the current frame can be modeled as a translation of pixels contained in the previous frame. In this procedure, the motion vector is obtained by minimizing a certain matching metric that is produced for the current frame over a determined search window from the previous frame. Unfortunately, the evaluation of such matching measurement is computationally expensive and represents the most consuming operation in the BM process. Therefore, BM motion estimation can be viewed as an optimization problem whose goal is to find the best-matching block within a search space. The simplest available BM method is the Full Search Algorithm (FSA) which finds the most accurate motion vector through an exhaustive computation of all the elements of the search space. Recently, several fast BM algorithms have been proposed to reduce the search positions by calculating only a fixed subset of motion vectors despite lowering its accuracy. On the other hand, the Harmony Search (HS) algorithm is a population-based optimization method that is inspired by the music improvisation process in which a musician searches for harmony and continues to polish the pitches to obtain a better harmony. In this paper, a new BM algorithm that combines HS with a fitness approximation model is proposed. The approach uses motion vectors belonging to the search window as potential solutions. A fitness function evaluates the matching quality of each motion vector candidate.



