# Arxiv Papers in cs.CV on 2014-06-10
### Optimization Methods for Convolutional Sparse Coding
- **Arxiv ID**: http://arxiv.org/abs/1406.2407v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.2407v1)
- **Published**: 2014-06-10 02:41:03+00:00
- **Updated**: 2014-06-10 02:41:03+00:00
- **Authors**: Hilton Bristow, Simon Lucey
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse and convolutional constraints form a natural prior for many optimization problems that arise from physical processes. Detecting motifs in speech and musical passages, super-resolving images, compressing videos, and reconstructing harmonic motions can all leverage redundancies introduced by convolution. Solving problems involving sparse and convolutional constraints remains a difficult computational problem, however. In this paper we present an overview of convolutional sparse coding in a consistent framework. The objective involves iteratively optimizing a convolutional least-squares term for the basis functions, followed by an L1-regularized least squares term for the sparse coefficients. We discuss a range of optimization methods for solving the convolutional sparse coding objective, and the properties that make each method suitable for different applications. In particular, we concentrate on computational complexity, speed to {\epsilon} convergence, memory usage, and the effect of implied boundary conditions. We present a broad suite of examples covering different signal and application domains to illustrate the general applicability of convolutional sparse coding, and the efficacy of the available optimization methods.



### Why do linear SVMs trained on HOG features perform so well?
- **Arxiv ID**: http://arxiv.org/abs/1406.2419v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.2419v1)
- **Published**: 2014-06-10 04:34:43+00:00
- **Updated**: 2014-06-10 04:34:43+00:00
- **Authors**: Hilton Bristow, Simon Lucey
- **Comment**: None
- **Journal**: None
- **Summary**: Linear Support Vector Machines trained on HOG features are now a de facto standard across many visual perception tasks. Their popularisation can largely be attributed to the step-change in performance they brought to pedestrian detection, and their subsequent successes in deformable parts models. This paper explores the interactions that make the HOG-SVM symbiosis perform so well. By connecting the feature extraction and learning processes rather than treating them as disparate plugins, we show that HOG features can be viewed as doing two things: (i) inducing capacity in, and (ii) adding prior to a linear SVM trained on pixels. From this perspective, preserving second-order statistics and locality of interactions are key to good performance. We demonstrate surprising accuracy on expression recognition and pedestrian detection tasks, by assuming only the importance of preserving such local second-order interactions.



### Denosing Using Wavelets and Projections onto the L1-Ball
- **Arxiv ID**: http://arxiv.org/abs/1406.2528v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1406.2528v1)
- **Published**: 2014-06-10 12:42:44+00:00
- **Updated**: 2014-06-10 12:42:44+00:00
- **Authors**: A. Enis Cetin, Mohammad Tofighi
- **Comment**: Submitted to Signal Processing Magazine
- **Journal**: None
- **Summary**: Both wavelet denoising and denosing methods using the concept of sparsity are based on soft-thresholding. In sparsity based denoising methods, it is assumed that the original signal is sparse in some transform domains such as the wavelet domain and the wavelet subsignals of the noisy signal are projected onto L1-balls to reduce noise. In this lecture note, it is shown that the size of the L1-ball or equivalently the soft threshold value can be determined using linear algebra. The key step is an orthogonal projection onto the epigraph set of the L1-norm cost function.



### Identification of Orchid Species Using Content-Based Flower Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1406.2580v1
- **DOI**: 10.1109/IC3INA.2013.6819148
- **Categories**: **cs.CV**, cs.IR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.2580v1)
- **Published**: 2014-06-10 15:11:27+00:00
- **Updated**: 2014-06-10 15:11:27+00:00
- **Authors**: D. H. Apriyanti, A. A. Arymurthy, L. T. Handoko
- **Comment**: Proceeding of International Conference on Computer, Control,
  Informatics and its Applications 2013, pp. 53-57
- **Journal**: None
- **Summary**: In this paper, we developed the system for recognizing the orchid species by using the images of flower. We used MSRM (Maximal Similarity based on Region Merging) method for segmenting the flower object from the background and extracting the shape feature such as the distance from the edge to the centroid point of the flower, aspect ratio, roundness, moment invariant, fractal dimension and also extract color feature. We used HSV color feature with ignoring the V value. To retrieve the image, we used Support Vector Machine (SVM) method. Orchid is a unique flower. It has a part of flower called lip (labellum) that distinguishes it from other flowers even from other types of orchids. Thus, in this paper, we proposed to do feature extraction not only on flower region but also on lip (labellum) region. The result shows that our proposed method can increase the accuracy value of content based flower image retrieval for orchid species up to $\pm$ 14%. The most dominant feature is Centroid Contour Distance, Moment Invariant and HSV Color. The system accuracy is 85,33% in validation phase and 79,33% in testing phase.



### Graph Approximation and Clustering on a Budget
- **Arxiv ID**: http://arxiv.org/abs/1406.2602v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.2602v1)
- **Published**: 2014-06-10 15:49:05+00:00
- **Updated**: 2014-06-10 15:49:05+00:00
- **Authors**: Ethan Fetaya, Ohad Shamir, Shimon Ullman
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the problem of learning from a similarity matrix (such as spectral clustering and lowd imensional embedding), when computing pairwise similarities are costly, and only a limited number of entries can be observed. We provide a theoretical analysis using standard notions of graph approximation, significantly generalizing previous results (which focused on spectral clustering with two clusters). We also propose a new algorithmic approach based on adaptive sampling, which experimentally matches or improves on previous methods, while being considerably more general and computationally cheaper.



### Deep Epitomic Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1406.2732v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.2732v1)
- **Published**: 2014-06-10 22:07:01+00:00
- **Updated**: 2014-06-10 22:07:01+00:00
- **Authors**: George Papandreou
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Deep convolutional neural networks have recently proven extremely competitive in challenging image recognition tasks. This paper proposes the epitomic convolution as a new building block for deep neural networks. An epitomic convolution layer replaces a pair of consecutive convolution and max-pooling layers found in standard deep convolutional neural networks. The main version of the proposed model uses mini-epitomes in place of filters and computes responses invariant to small translations by epitomic search instead of max-pooling over image positions. The topographic version of the proposed model uses large epitomes to learn filter maps organized in translational topographies. We show that error back-propagation can successfully learn multiple epitomic layers in a supervised fashion. The effectiveness of the proposed method is assessed in image classification tasks on standard benchmarks. Our experiments on Imagenet indicate improved recognition performance compared to standard convolutional neural networks of similar architecture. Our models pre-trained on Imagenet perform excellently on Caltech-101. We also obtain competitive image classification results on the small-image MNIST and CIFAR-10 datasets.



