# Arxiv Papers in cs.CV on 2014-06-11
### The Secrets of Salient Object Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1406.2807v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.2807v2)
- **Published**: 2014-06-11 07:46:03+00:00
- **Updated**: 2014-06-12 17:35:08+00:00
- **Authors**: Yin Li, Xiaodi Hou, Christof Koch, James M. Rehg, Alan L. Yuille
- **Comment**: 15 pages, 8 figures. Conference version was accepted by CVPR 2014
- **Journal**: None
- **Summary**: In this paper we provide an extensive evaluation of fixation prediction and salient object segmentation algorithms as well as statistics of major datasets. Our analysis identifies serious design flaws of existing salient object benchmarks, called the dataset design bias, by over emphasizing the stereotypical concepts of saliency. The dataset design bias does not only create the discomforting disconnection between fixations and salient object segmentation, but also misleads the algorithm designing. Based on our analysis, we propose a new high quality dataset that offers both fixation and salient object segmentation ground-truth. With fixations and salient object being presented simultaneously, we are able to bridge the gap between fixations and salient objects, and propose a novel method for salient object segmentation. Finally, we report significant benchmark progress on three existing datasets of segmenting salient objects



### Acoustic Gait-based Person Identification using Hidden Markov Models
- **Arxiv ID**: http://arxiv.org/abs/1406.2895v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1406.2895v1)
- **Published**: 2014-06-11 13:14:32+00:00
- **Updated**: 2014-06-11 13:14:32+00:00
- **Authors**: Jürgen T. Geiger, Maximilian Kneißl, Björn Schuller, Gerhard Rigoll
- **Comment**: None
- **Journal**: None
- **Summary**: We present a system for identifying humans by their walking sounds. This problem is also known as acoustic gait recognition. The goal of the system is to analyse sounds emitted by walking persons (mostly the step sounds) and identify those persons. These sounds are characterised by the gait pattern and are influenced by the movements of the arms and legs, but also depend on the type of shoe. We extract cepstral features from the recorded audio signals and use hidden Markov models for dynamic classification. A cyclic model topology is employed to represent individual gait cycles. This topology allows to model and detect individual steps, leading to very promising identification rates. For experimental validation, we use the publicly available TUM GAID database, which is a large gait recognition database containing 3050 recordings of 305 subjects in three variations. In the best setup, an identification rate of 65.5 % is achieved out of 155 subjects. This is a relative improvement of almost 30 % compared to our previous work, which used various audio features and support vector machines.



### Bird Species Categorization Using Pose Normalized Deep Convolutional Nets
- **Arxiv ID**: http://arxiv.org/abs/1406.2952v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.2952v1)
- **Published**: 2014-06-11 16:14:42+00:00
- **Updated**: 2014-06-11 16:14:42+00:00
- **Authors**: Steve Branson, Grant Van Horn, Serge Belongie, Pietro Perona
- **Comment**: None
- **Journal**: None
- **Summary**: We propose an architecture for fine-grained visual categorization that approaches expert human performance in the classification of bird species. Our architecture first computes an estimate of the object's pose; this is used to compute local image features which are, in turn, used for classification. The features are computed by applying deep convolutional nets to image patches that are located and normalized by the pose. We perform an empirical study of a number of pose normalization schemes, including an investigation of higher order geometric warping functions. We propose a novel graph-based clustering algorithm for learning a compact pose normalization space. We perform a detailed investigation of state-of-the-art deep convolutional feature implementations and fine-tuning feature learning for fine-grained classification. We observe that a model that integrates lower-level feature layers with pose-normalized extraction routines and higher-level feature layers with unaligned image features works best. Our experiments advance state-of-the-art performance on bird species recognition, with a large improvement of correct classification rates over previous methods (75% vs. 55-65%).



### Truncated Nuclear Norm Minimization for Image Restoration Based On Iterative Support Detection
- **Arxiv ID**: http://arxiv.org/abs/1406.2969v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1406.2969v1)
- **Published**: 2014-06-11 17:18:25+00:00
- **Updated**: 2014-06-11 17:18:25+00:00
- **Authors**: Yilun Wang, Xinhua Su
- **Comment**: None
- **Journal**: None
- **Summary**: Recovering a large matrix from limited measurements is a challenging task arising in many real applications, such as image inpainting, compressive sensing and medical imaging, and this kind of problems are mostly formulated as low-rank matrix approximation problems. Due to the rank operator being non-convex and discontinuous, most of the recent theoretical studies use the nuclear norm as a convex relaxation and the low-rank matrix recovery problem is solved through minimization of the nuclear norm regularized problem. However, a major limitation of nuclear norm minimization is that all the singular values are simultaneously minimized and the rank may not be well approximated \cite{hu2012fast}. Correspondingly, in this paper, we propose a new multi-stage algorithm, which makes use of the concept of Truncated Nuclear Norm Regularization (TNNR) proposed in \citep{hu2012fast} and Iterative Support Detection (ISD) proposed in \citep{wang2010sparse} to overcome the above limitation. Besides matrix completion problems considered in \citep{hu2012fast}, the proposed method can be also extended to the general low-rank matrix recovery problems. Extensive experiments well validate the superiority of our new algorithms over other state-of-the-art methods.



### Joint Training of a Convolutional Network and a Graphical Model for Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1406.2984v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.2984v2)
- **Published**: 2014-06-11 18:16:29+00:00
- **Updated**: 2014-09-17 22:43:45+00:00
- **Authors**: Jonathan Tompson, Arjun Jain, Yann LeCun, Christoph Bregler
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.



### "Mental Rotation" by Optimizing Transforming Distance
- **Arxiv ID**: http://arxiv.org/abs/1406.3010v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1406.3010v2)
- **Published**: 2014-06-11 19:38:05+00:00
- **Updated**: 2014-12-05 17:55:09+00:00
- **Authors**: Weiguang Ding, Graham W. Taylor
- **Comment**: None
- **Journal**: None
- **Summary**: The human visual system is able to recognize objects despite transformations that can drastically alter their appearance. To this end, much effort has been devoted to the invariance properties of recognition systems. Invariance can be engineered (e.g. convolutional nets), or learned from data explicitly (e.g. temporal coherence) or implicitly (e.g. by data augmentation). One idea that has not, to date, been explored is the integration of latent variables which permit a search over a learned space of transformations. Motivated by evidence that people mentally simulate transformations in space while comparing examples, so-called "mental rotation", we propose a transforming distance. Here, a trained relational model actively transforms pairs of examples so that they are maximally similar in some feature space yet respect the learned transformational constraints. We apply our method to nearest-neighbour problems on the Toronto Face Database and NORB.



