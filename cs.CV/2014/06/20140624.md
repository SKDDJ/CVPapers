# Arxiv Papers in cs.CV on 2014-06-24
### Offline Handwritten MODI Character Recognition Using HU, Zernike Moments and Zoning
- **Arxiv ID**: http://arxiv.org/abs/1406.6140v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6140v4)
- **Published**: 2014-06-24 05:40:43+00:00
- **Updated**: 2014-10-27 13:17:41+00:00
- **Authors**: Sadanand A. Kulkarni, Prashant L. Borde, Ramesh R. Manza, Pravin L. Yannawar
- **Comment**: This paper has been withdrawn by the author due to the paper was
  rejected by journal with a reson "paper was not suitable for the journal"
- **Journal**: None
- **Summary**: HOCR is abbreviated as Handwritten Optical Character Recognition. HOCR is a process of recognition of different handwritten characters from a digital image of documents. Handwritten automatic character recognition has attracted many researchers all over the world to contribute handwritten character recognition domain. Shape identification and feature extraction is very important part of any character recognition system and success of method is highly dependent on selection of features. However feature extraction is the most important step in defining the shape of the character as precisely and as uniquely as possible. This is indeed the most important step and complex task as well and achieved success by using invariance property, irrespective of position and orientation. Zernike moments describes shape, identify rotation invariant due to its Orthogonality property. MODI is an ancient script of India had cursive and complex representation of characters. The work described in this paper presents efficiency of Zernike moments over Hu 7 moment with zoning for automatic recognition of handwritten MODI characters. Offline approach is used in this paper because MODI Script was very popular and widely used for writing purpose till 19th century before Devanagari was officially adopted.



### Fast, Robust and Non-convex Subspace Recovery
- **Arxiv ID**: http://arxiv.org/abs/1406.6145v2
- **DOI**: 10.1093/imaiai/iax012
- **Categories**: **cs.LG**, cs.CV, stat.AP, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1406.6145v2)
- **Published**: 2014-06-24 06:15:07+00:00
- **Updated**: 2016-06-09 22:58:10+00:00
- **Authors**: Gilad Lerman, Tyler Maunu
- **Comment**: None
- **Journal**: Information and Inference: A Journal of the IMA 7 (2018) 277-336
- **Summary**: This work presents a fast and non-convex algorithm for robust subspace recovery. The data sets considered include inliers drawn around a low-dimensional subspace of a higher dimensional ambient space, and a possibly large portion of outliers that do not lie nearby this subspace. The proposed algorithm, which we refer to as Fast Median Subspace (FMS), is designed to robustly determine the underlying subspace of such data sets, while having lower computational complexity than existing methods. We prove convergence of the FMS iterates to a stationary point. Further, under a special model of data, FMS converges to a point which is near to the global minimum with overwhelming probability. Under this model, we show that the iteration complexity is globally bounded and locally $r$-linear. The latter theorem holds for any fixed fraction of outliers (less than 1) and any fixed positive distance between the limit point and the global minimum. Numerical experiments on synthetic and real data demonstrate its competitive speed and accuracy.



### Incorporating Near-Infrared Information into Semantic Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1406.6147v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6147v1)
- **Published**: 2014-06-24 06:28:50+00:00
- **Updated**: 2014-06-24 06:28:50+00:00
- **Authors**: Neda Salamati, Diane Larlus, Gabriela Csurka, Sabine SÃ¼sstrunk
- **Comment**: None
- **Journal**: None
- **Summary**: Recent progress in computational photography has shown that we can acquire near-infrared (NIR) information in addition to the normal visible (RGB) band, with only slight modifications to standard digital cameras. Due to the proximity of the NIR band to visible radiation, NIR images share many properties with visible images. However, as a result of the material dependent reflection in the NIR part of the spectrum, such images reveal different characteristics of the scene. We investigate how to effectively exploit these differences to improve performance on the semantic image segmentation task. Based on a state-of-the-art segmentation framework and a novel manually segmented image database (both indoor and outdoor scenes) that contain 4-channel images (RGB+NIR), we study how to best incorporate the specific characteristics of the NIR response. We show that adding NIR leads to improved performance for classes that correspond to a specific type of material in both outdoor and indoor scenes. We also discuss the results with respect to the physical properties of the NIR response.



### Saccadic Eye Movements and the Generalized Pareto Distribution
- **Arxiv ID**: http://arxiv.org/abs/1406.6201v1
- **DOI**: None
- **Categories**: **cs.CV**, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1406.6201v1)
- **Published**: 2014-06-24 10:57:50+00:00
- **Updated**: 2014-06-24 10:57:50+00:00
- **Authors**: Reiner Lenz
- **Comment**: None
- **Journal**: None
- **Summary**: We describe a statistical analysis of the eye tracker measurements in a database with 15 observers viewing 1003 images under free-viewing conditions. In contrast to the common approach of investigating the properties of the fixation points we analyze the properties of the transition phases between fixations. We introduce hyperbolic geometry as a tool to measure the step length between consecutive eye positions. We show that the step lengths, measured in hyperbolic and euclidean geometry, follow a generalized Pareto distribution. The results based on the hyperbolic distance are more robust than those based on euclidean geometry. We show how the structure of the space of generalized Pareto distributions can be used to characterize and identify individual observers.



### Recurrent Models of Visual Attention
- **Arxiv ID**: http://arxiv.org/abs/1406.6247v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1406.6247v1)
- **Published**: 2014-06-24 14:16:56+00:00
- **Updated**: 2014-06-24 14:16:56+00:00
- **Authors**: Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu
- **Comment**: None
- **Journal**: None
- **Summary**: Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.



### Image Completion for View Synthesis Using Markov Random Fields and Efficient Belief Propagation
- **Arxiv ID**: http://arxiv.org/abs/1406.6273v1
- **DOI**: 10.1109/ICIP.2013.6738439
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6273v1)
- **Published**: 2014-06-24 15:12:55+00:00
- **Updated**: 2014-06-24 15:12:55+00:00
- **Authors**: Julian Habigt, Klaus Diepold
- **Comment**: Published version:
  http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6738439
- **Journal**: Proc. 20th IEEE International Conference on Image Processing
  (2013) 2131-2134
- **Summary**: View synthesis is a process for generating novel views from a scene which has been recorded with a 3-D camera setup. It has important applications in 3-D post-production and 2-D to 3-D conversion. However, a central problem in the generation of novel views lies in the handling of disocclusions. Background content, which was occluded in the original view, may become unveiled in the synthesized view. This leads to missing information in the generated view which has to be filled in a visually plausible manner. We present an inpainting algorithm for disocclusion filling in synthesized views based on Markov random fields and efficient belief propagation. We compare the result to two state-of-the-art algorithms and demonstrate a significant improvement in image quality.



### Dense Correspondences Across Scenes and Scales
- **Arxiv ID**: http://arxiv.org/abs/1406.6323v1
- **DOI**: 10.1109/TPAMI.2015.2474356
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6323v1)
- **Published**: 2014-06-24 17:49:09+00:00
- **Updated**: 2014-06-24 17:49:09+00:00
- **Authors**: Moria Tau, Tal Hassner
- **Comment**: A longer version of this paper is in submission. Please see author
  homepage for an updated version
- **Journal**: None
- **Summary**: We seek a practical method for establishing dense correspondences between two images with similar content, but possibly different 3D scenes. One of the challenges in designing such a system is the local scale differences of objects appearing in the two images. Previous methods often considered only small subsets of image pixels; matching only pixels for which stable scales may be reliably estimated. More recently, others have considered dense correspondences, but with substantial costs associated with generating, storing and matching scale invariant descriptors. Our work here is motivated by the observation that pixels in the image have contexts -- the pixels around them -- which may be exploited in order to estimate local scales reliably and repeatably. Specifically, we make the following contributions. (i) We show that scales estimated in sparse interest points may be propagated to neighboring pixels where this information cannot be reliably determined. Doing so allows scale invariant descriptors to be extracted anywhere in the image, not just in detected interest points. (ii) We present three different means for propagating this information: using only the scales at detected interest points, using the underlying image information to guide the propagation of this information across each image, separately, and using both images simultaneously. Finally, (iii), we provide extensive results, both qualitative and quantitative, demonstrating that accurate dense correspondences can be obtained even between very different images, with little computational costs beyond those required by existing methods.



### A multilevel thresholding algorithm using Electromagnetism Optimization
- **Arxiv ID**: http://arxiv.org/abs/1406.6336v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6336v1)
- **Published**: 2014-06-24 19:01:28+00:00
- **Updated**: 2014-06-24 19:01:28+00:00
- **Authors**: Diego Oliva, Erik Cuevas, Gonzalo Pajares, Daniel Zaldivar, Valentin Osuna
- **Comment**: The figures have been shortened in order to fulfill the submission
  requirements
- **Journal**: Neurocomputing, 139, (2014), 357-381
- **Summary**: Segmentation is one of the most important tasks in image processing. It consist in classify the pixels into two or more groups depending on their intensity levels and a threshold value. The quality of the segmentation depends on the method applied to select the threshold. The use of the classical implementations for multilevel thresholding is computationally expensive since they exhaustively search the best values to optimize the objective function. Under such conditions, the use of optimization evolutionary approaches has been extended. The Electromagnetism Like algorithm (EMO) is an evolutionary method which mimics the attraction repulsion mechanism among charges to evolve the members of a population. Different to other algorithms, EMO exhibits interesting search capabilities whereas maintains a low computational overhead. In this paper, a multilevel thresholding (MT) algorithm based on the EMO is introduced. The approach combines the good search capabilities of EMO algorithm with objective functions proposed by the popular MT methods of Otsu and Kapur. The algorithm takes random samples from a feasible search space inside the image histogram. Such samples build each particle in the EMO context whereas its quality is evaluated considering the objective that is function employed by the Otsu or Kapur method. Guided by these objective values the set of candidate solutions are evolved through the EMO operators until an optimal solution is found. The approach generates a multilevel segmentation algorithm which can effectively identify the threshold values of a digital image in a reduced number of iterations. Experimental results show performance evidence of the implementation of EMO for digital image segmentation.



### Image patch analysis and clustering of sunspots: a dimensionality reduction approach
- **Arxiv ID**: http://arxiv.org/abs/1406.6390v1
- **DOI**: 10.1109/ICIP.2014.7025325
- **Categories**: **cs.CV**, astro-ph.SR
- **Links**: [PDF](http://arxiv.org/pdf/1406.6390v1)
- **Published**: 2014-06-24 20:48:19+00:00
- **Updated**: 2014-06-24 20:48:19+00:00
- **Authors**: Kevin R. Moon, Jimmy J. Li, Veronique Delouille, Fraser Watson, Alfred O. Hero III
- **Comment**: 5 pages, 7 figures, accepted to ICIP 2014
- **Journal**: K.R. Moon, J.J. Li, V. Delouille, F. Watson, and A.O. Hero III,
  "Image patch analysis and clustering of sunspots: a dimensionality reduction
  approach," In Image Processing (ICIP), 2014 IEEE Conference on, pp.
  1623-1627, 2014
- **Summary**: Sunspots, as seen in white light or continuum images, are associated with regions of high magnetic activity on the Sun, visible on magnetogram images. Their complexity is correlated with explosive solar activity and so classifying these active regions is useful for predicting future solar activity. Current classification of sunspot groups is visually based and suffers from bias. Supervised learning methods can reduce human bias but fail to optimally capitalize on the information present in sunspot images. This paper uses two image modalities (continuum and magnetogram) to characterize the spatial and modal interactions of sunspot and magnetic active region images and presents a new approach to cluster the images. Specifically, in the framework of image patch analysis, we estimate the number of intrinsic parameters required to describe the spatial and modal dependencies, the correlation between the two modalities and the corresponding spatial patterns, and examine the phenomena at different scales within the images. To do this, we use linear and nonlinear intrinsic dimension estimators, canonical correlation analysis, and multiresolution analysis of intrinsic dimension.



