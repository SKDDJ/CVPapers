# Arxiv Papers in cs.CV on 2014-06-26
### Face Image Classification by Pooling Raw Features
- **Arxiv ID**: http://arxiv.org/abs/1406.6811v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6811v2)
- **Published**: 2014-06-26 08:56:55+00:00
- **Updated**: 2014-09-17 06:40:29+00:00
- **Authors**: Fumin Shen, Chunhua Shen, Heng Tao Shen
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: We propose a very simple, efficient yet surprisingly effective feature extraction method for face recognition (about 20 lines of Matlab code), which is mainly inspired by spatial pyramid pooling in generic image classification. We show that features formed by simply pooling local patches over a multi-level pyramid, coupled with a linear classifier, can significantly outperform most recent face recognition methods. The simplicity of our feature extraction procedure is demonstrated by the fact that no learning is involved (except PCA whitening). We show that, multi-level spatial pooling and dense extraction of multi-scale patches play critical roles in face image classification. The extracted facial features can capture strong structural information of individual faces with no label information being used. We also find that, pre-processing on local image patches such as contrast normalization can have an important impact on the classification accuracy. In particular, on the challenging face recognition datasets of FERET and LFW-a, our method improves previous best results by more than 10% and 20%, respectively.



### Face Identification with Second-Order Pooling
- **Arxiv ID**: http://arxiv.org/abs/1406.6818v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6818v2)
- **Published**: 2014-06-26 09:21:42+00:00
- **Updated**: 2014-09-17 06:41:40+00:00
- **Authors**: Fumin Shen, Chunhua Shen, Heng Tao Shen
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Automatic face recognition has received significant performance improvement by developing specialised facial image representations. On the other hand, generic object recognition has rarely been applied to the face recognition. Spatial pyramid pooling of features encoded by an over-complete dictionary has been the key component of many state-of-the-art image classification systems. Inspired by its success, in this work we develop a new face image representation method inspired by the second-order pooling in Carreira et al. [1], which was originally proposed for image segmentation. The proposed method differs from the previous methods in that, we encode the densely extracted local patches by a small-size dictionary; and the facial image signatures are obtained by pooling the second-order statistics of the encoded features. We show the importance of pooling on encoded features, which is bypassed by the original second-order pooling method to avoid the high computational cost. Equipped with a simple linear classifier, the proposed method outperforms the state-of-the-art face identification performance by large margins. For example, on the LFW databases, the proposed method performs better than the previous best by around 13% accuracy.



### A Fully Automated Latent Fingerprint Matcher with Embedded Self-learning Segmentation Module
- **Arxiv ID**: http://arxiv.org/abs/1406.6854v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1406.6854v1)
- **Published**: 2014-06-26 11:51:56+00:00
- **Updated**: 2014-06-26 11:51:56+00:00
- **Authors**: Jinwei Xu, Jiankun Hu, Xiuping Jia
- **Comment**: None
- **Journal**: None
- **Summary**: Latent fingerprint has the practical value to identify the suspects who have unintentionally left a trace of fingerprint in the crime scenes. However, designing a fully automated latent fingerprint matcher is a very challenging task as it needs to address many challenging issues including the separation of overlapping structured patterns over the partial and poor quality latent fingerprint image, and finding a match against a large background database that would have different resolutions. Currently there is no fully automated latent fingerprint matcher available to the public and most literature reports have utilized a specialized latent fingerprint matcher COTS3 which is not accessible to the public. This will make it infeasible to assess and compare the relevant research work which is vital for this research community. In this study, we target to develop a fully automated latent matcher for adaptive detection of the region of interest and robust matching of latent prints. Unlike the manually conducted matching procedure, the proposed latent matcher can run like a sealed black box without any manual intervention. This matcher consists of the following two modules: (i) the dictionary learning-based region of interest (ROI) segmentation scheme; and (ii) the genetic algorithm-based minutiae set matching unit. Experimental results on NIST SD27 latent fingerprint database demonstrates that the proposed matcher outperforms the currently public state-of-art latent fingerprint matcher.



### Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1406.6909v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1406.6909v2)
- **Published**: 2014-06-26 15:07:14+00:00
- **Updated**: 2015-06-19 11:43:36+00:00
- **Authors**: Alexey Dosovitskiy, Philipp Fischer, Jost Tobias Springenberg, Martin Riedmiller, Thomas Brox
- **Comment**: PAMI submission. Includes matching experiments as in
  arXiv:1405.5769v1. Also includes new network architectures, experiments on
  Caltech-256, experiment on combining Exemplar-CNN with clustering
- **Journal**: None
- **Summary**: Deep convolutional networks have proven to be very successful in learning task specific features that allow for unprecedented performance on various computer vision tasks. Training of such networks follows mostly the supervised learning paradigm, where sufficiently many input-output pairs are required for training. Acquisition of large training sets is one of the key challenges, when approaching a new task. In this paper, we aim for generic feature learning and present an approach for training a convolutional network using only unlabeled data. To this end, we train the network to discriminate between a set of surrogate classes. Each surrogate class is formed by applying a variety of transformations to a randomly sampled 'seed' image patch. In contrast to supervised network training, the resulting feature representation is not class specific. It rather provides robustness to the transformations that have been applied during training. This generic feature representation allows for classification results that outperform the state of the art for unsupervised learning on several popular datasets (STL-10, CIFAR-10, Caltech-101, Caltech-256). While such generic features cannot compete with class specific features from supervised training on a classification task, we show that they are advantageous on geometric matching problems, where they also outperform the SIFT descriptor.



### An improved computer vision method for detecting white blood cells
- **Arxiv ID**: http://arxiv.org/abs/1406.6946v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6946v2)
- **Published**: 2014-06-26 17:01:32+00:00
- **Updated**: 2014-06-27 13:20:21+00:00
- **Authors**: Erik Cuevas, Margarita Diaz, Miguel Manzanares, Daniel Zaldivar, Marco Perez
- **Comment**: 20 Pages. arXiv admin note: text overlap with arXiv:1405.5164
- **Journal**: Computational and Mathematical Methods in Medicine, 2013, art. no.
  137392
- **Summary**: The automatic detection of White Blood Cells (WBC) still remains as an unsolved issue in medical imaging. The analysis of WBC images has engaged researchers from fields of medicine and computer vision alike. Since WBC can be approximated by an ellipsoid form, an ellipse detector algorithm may be successfully applied in order to recognize them. This paper presents an algorithm for the automatic detection of WBC embedded into complicated and cluttered smear images that considers the complete process as a multi-ellipse detection problem. The approach, based on the Differential Evolution (DE) algorithm, transforms the detection task into an optimization problem where individuals emulate candidate ellipses. An objective function evaluates if such candidate ellipses are really present in the edge image of the smear. Guided by the values of such function, the set of encoded candidate ellipses (individuals) are evolved using the DE algorithm so that they can fit into the WBC enclosed within the edge-only map of the image. Experimental results from white blood cell images with a varying range of complexity are included to validate the efficiency of the proposed technique in terms of accuracy and robustness.



### Deep Learning Multi-View Representation for Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1406.6947v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6947v1)
- **Published**: 2014-06-26 17:09:25+00:00
- **Updated**: 2014-06-26 17:09:25+00:00
- **Authors**: Zhenyao Zhu, Ping Luo, Xiaogang Wang, Xiaoou Tang
- **Comment**: None
- **Journal**: None
- **Summary**: Various factors, such as identities, views (poses), and illuminations, are coupled in face images. Disentangling the identity and view representations is a major challenge in face recognition. Existing face recognition systems either use handcrafted features or learn features discriminatively to improve recognition accuracy. This is different from the behavior of human brain. Intriguingly, even without accessing 3D data, human not only can recognize face identity, but can also imagine face images of a person under different viewpoints given a single 2D image, making face perception in the brain robust to view changes. In this sense, human brain has learned and encoded 3D face models from 2D images. To take into account this instinct, this paper proposes a novel deep neural net, named multi-view perceptron (MVP), which can untangle the identity and view features, and infer a full spectrum of multi-view images in the meanwhile, given a single 2D face image. The identity features of MVP achieve superior performance on the MultiPIE dataset. MVP is also capable to interpolate and predict images under viewpoints that are unobserved in the training data.



### How good are detection proposals, really?
- **Arxiv ID**: http://arxiv.org/abs/1406.6962v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6962v2)
- **Published**: 2014-06-26 18:00:56+00:00
- **Updated**: 2014-07-22 15:11:02+00:00
- **Authors**: Jan Hosang, Rodrigo Benenson, Bernt Schiele
- **Comment**: None
- **Journal**: None
- **Summary**: Current top performing Pascal VOC object detectors employ detection proposals to guide the search for objects thereby avoiding exhaustive sliding window search across images. Despite the popularity of detection proposals, it is unclear which trade-offs are made when using them during object detection. We provide an in depth analysis of ten object proposal methods along with four baselines regarding ground truth annotation recall (on Pascal VOC 2007 and ImageNet 2013), repeatability, and impact on DPM detector performance. Our findings show common weaknesses of existing methods, and provide insights to choose the most adequate method for different settings.



