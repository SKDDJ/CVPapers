# Arxiv Papers in cs.CV on 2014-06-25
### Compressive Imaging and Characterization of Sparse Light Deflection Maps
- **Arxiv ID**: http://arxiv.org/abs/1406.6425v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6425v2)
- **Published**: 2014-06-25 00:46:10+00:00
- **Updated**: 2015-07-14 18:17:21+00:00
- **Authors**: Prasad Sudhakar, Laurent Jacques, Xavier Dubois, Philippe Antoine, Luc Joannes
- **Comment**: 35 pages, 17 figures. Accepted for publication in SIAM Journal on
  Imaging Sciences
- **Journal**: None
- **Summary**: Light rays incident on a transparent object of uniform refractive index undergo deflections, which uniquely characterize the surface geometry of the object. Associated with each point on the surface is a deflection map (or spectrum) which describes the pattern of deflections in various directions. This article presents a novel method to efficiently acquire and reconstruct sparse deflection spectra induced by smooth object surfaces. To this end, we leverage the framework of Compressed Sensing (CS) in a particular implementation of a schlieren deflectometer, i.e., an optical system providing linear measurements of deflection spectra with programmable spatial light modulation patterns. We design those modulation patterns on the principle of spread spectrum CS for reducing the number of observations. The ability of our device to simultaneously observe the deflection spectra on a dense discretization of the object surface is related to a Multiple Measurement Vector (MMV) model. This scheme allows us to estimate both the noise power and the instrumental point spread function.   We formulate the spectrum reconstruction task as the solving of a linear inverse problem regularized by an analysis sparsity prior using a translation invariant wavelet frame. Our results demonstrate the capability and advantages of using a CS based approach for deflectometric imaging both on simulated data and experimental deflectometric data.   Finally, the paper presents an extension of our method showing how we can extract the main deflection direction in each point of the object surface from a few compressive measurements, without needing any costly reconstruction procedures. This compressive characterization is then confirmed with experimental results on simple plano-convex and multifocal intra-ocular lenses studying the evolution of the main deflection as a function of the object point location.



### Weakly-supervised Discovery of Visual Pattern Configurations
- **Arxiv ID**: http://arxiv.org/abs/1406.6507v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1406.6507v1)
- **Published**: 2014-06-25 09:35:40+00:00
- **Updated**: 2014-06-25 09:35:40+00:00
- **Authors**: Hyun Oh Song, Yong Jae Lee, Stefanie Jegelka, Trevor Darrell
- **Comment**: None
- **Journal**: None
- **Summary**: The increasing prominence of weakly labeled data nurtures a growing demand for object detection methods that can cope with minimal supervision. We propose an approach that automatically identifies discriminative configurations of visual patterns that are characteristic of a given object class. We formulate the problem as a constrained submodular optimization problem and demonstrate the benefits of the discovered configurations in remedying mislocalizations and finding informative positive and negative training examples. Together, these lead to state-of-the-art weakly-supervised detection results on the challenging PASCAL VOC dataset.



### A Bimodal Co-Sparse Analysis Model for Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1406.6538v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6538v1)
- **Published**: 2014-06-25 12:28:55+00:00
- **Updated**: 2014-06-25 12:28:55+00:00
- **Authors**: Martin Kiechle, Tim Habigt, Simon Hawe, Martin Kleinsteuber
- **Comment**: None
- **Journal**: None
- **Summary**: The success of many computer vision tasks lies in the ability to exploit the interdependency between different image modalities such as intensity and depth. Fusing corresponding information can be achieved on several levels, and one promising approach is the integration at a low level. Moreover, sparse signal models have successfully been used in many vision applications. Within this area of research, the so called co-sparse analysis model has attracted considerably less attention than its well-known counterpart, the sparse synthesis model, although it has been proven to be very useful in various image processing applications. In this paper, we propose a co-sparse analysis model that is able to capture the interdependency of two image modalities. It is based on the assumption that a pair of analysis operators exists, so that the co-supports of the corresponding bimodal image structures are correlated. We propose an algorithm that is able to learn such a coupled pair of operators from registered and noise-free training data. Furthermore, we explain how this model can be applied to solve linear inverse problems in image processing and how it can be used for image registration tasks. This paper extends the work of some of the authors by two major contributions. Firstly, a modification of the learning process is proposed that a priori guarantees unit norm and zero-mean of the rows of the operator. This accounts for the intuition that contrast in image modalities carries the most information. Secondly, the model is used in a novel bimodal image registration algorithm which estimates the transformation parameters of unregistered images of different modalities.



### $ N^4 $-Fields: Neural Network Nearest Neighbor Fields for Image Transforms
- **Arxiv ID**: http://arxiv.org/abs/1406.6558v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6558v2)
- **Published**: 2014-06-25 13:10:56+00:00
- **Updated**: 2014-07-03 08:07:52+00:00
- **Authors**: Yaroslav Ganin, Victor Lempitsky
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a new architecture for difficult image processing operations, such as natural edge detection or thin object segmentation. The architecture is based on a simple combination of convolutional neural networks with the nearest neighbor search.   We focus our attention on the situations when the desired image transformation is too hard for a neural network to learn explicitly. We show that in such situations, the use of the nearest neighbor search on top of the network output allows to improve the results considerably and to account for the underfitting effect during the neural network training. The approach is validated on three challenging benchmarks, where the performance of the proposed architecture matches or exceeds the state-of-the-art.



### Multi Circle Detection on Images Using Artificial Bee Colony (ABC) Optimization
- **Arxiv ID**: http://arxiv.org/abs/1406.6560v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1406.6560v1)
- **Published**: 2014-06-25 13:15:08+00:00
- **Updated**: 2014-06-25 13:15:08+00:00
- **Authors**: Erik Cuevas, Felipe Sencion-Echauri, Daniel Zaldivar, Marco Perez Cisneros
- **Comment**: 19 Pages
- **Journal**: Soft Computing, 16 (2), (2012), pp. 281-296
- **Summary**: Hough transform (HT) has been the most common method for circle detection, exhibiting robustness, but adversely demanding considerable computational effort and large memory requirements. Alternative approaches include heuristic methods that employ iterative optimization procedures for detecting multiple circles. Since only one circle can be marked at each optimization cycle, multiple executions must be enforced in order to achieve multi detection. This paper presents an algorithm for automatic detection of multiple circular shapes that considers the overall process as a multi-modal optimization problem. The approach is based on the artificial bee colony (ABC) algorithm, a swarm optimization algorithm inspired by the intelligent foraging behavior of honey bees. Unlike the original ABC algorithm, the proposed approach presents the addition of a memory for discarded solutions. Such memory allows holding important information regarding other local optima which might have emerged during the optimization process. The detector uses a combination of three non-collinear edge points as parameters to determine circle candidates. A matching function (nectar- amount) determines if such circle candidates (bee-food-sources) are actually present in the image. Guided by the values of such matching functions, the set of encoded candidate circles are evolved through the ABC algorithm so that the best candidate (global optimum) can be fitted into an actual circle within the edge only image. Then, an analysis of the incorporated memory is executed in order to identify potential local optima, i.e., other circles.



### Support vector machine classification of dimensionally reduced structural MRI images for dementia
- **Arxiv ID**: http://arxiv.org/abs/1406.6568v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1406.6568v1)
- **Published**: 2014-06-25 13:50:18+00:00
- **Updated**: 2014-06-25 13:50:18+00:00
- **Authors**: V. A. Miller, S. Erlien, J. Piersol
- **Comment**: technical note
- **Journal**: None
- **Summary**: We classify very-mild to moderate dementia in patients (CDR ranging from 0 to 2) using a support vector machine classifier acting on dimensionally reduced feature set derived from MRI brain scans of the 416 subjects available in the OASIS-Brains dataset. We use image segmentation and principal component analysis to reduce the dimensionality of the data. Our resulting feature set contains 11 features for each subject. Performance of the classifiers is evaluated using 10-fold cross-validation. Using linear and (gaussian) kernels, we obtain a training classification accuracy of 86.4% (90.1%), test accuracy of 85.0% (85.7%), test precision of 68.7% (68.5%), test recall of 68.0% (74.0%), and test Matthews correlation coefficient of 0.594 (0.616).



### 3DUNDERWORLD-SLS: An Open-Source Structured-Light Scanning System for Rapid Geometry Acquisition
- **Arxiv ID**: http://arxiv.org/abs/1406.6595v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.6595v2)
- **Published**: 2014-06-25 14:51:21+00:00
- **Updated**: 2016-08-20 04:59:55+00:00
- **Authors**: Qing Gu, Kyriakos Herakleous, Charalambos Poullis
- **Comment**: 30 pages describing the 3DUNDERWORLD-SLS open source software by the
  ICT lab (www.theICTlab.org)
- **Journal**: None
- **Summary**: Recently, there has been an increase in the demand of virtual 3D objects representing real-life objects. A plethora of methods and systems have already been proposed for the acquisition of the geometry of real-life objects ranging from those which employ active sensor technology, passive sensor technology or a combination of various techniques.   In this paper we present the development of a 3D scanning system which is based on the principle of structured-light, without having particular requirements for specialized equipment. We discuss the intrinsic details and inherent difficulties of structured-light scanning techniques and present our solutions. Finally, we introduce our open-source scanning software system "3DUNDERWORLD-SLS" which implements the proposed techniques both in CPU and GPU. We have performed extensive testing with a wide range of models and report the results. Furthermore, we present a comprehensive evaluation of the system and a comparison with a high-end commercial 3D scanner.



