# Arxiv Papers in cs.CV on 2014-02-28
### Visual Saliency Model using SIFT and Comparison of Learning Approaches
- **Arxiv ID**: http://arxiv.org/abs/1402.7162v1
- **DOI**: 10.5121/csit.2014.4223
- **Categories**: **cs.CV**, I.2.10; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1402.7162v1)
- **Published**: 2014-02-28 08:33:17+00:00
- **Updated**: 2014-02-28 08:33:17+00:00
- **Authors**: Hamdi Yalin Yalic
- **Comment**: 8 pages, 6 figures, 2 tables
- **Journal**: Computer Science & Information Technology, Volume 4, Number 2,
  2014, page 275-282
- **Summary**: Humans' ability to detect and locate salient objects on images is remarkably fast and successful. Performing this process by using eye tracking equipment is expensive and cannot be easily applied, and computer modeling of this human behavior is still a problem to be solved. In our study, one of the largest public eye-tracking databases which has fixation points of 15 observers on 1003 images is used. In addition to low, medium and high-level features which have been used in previous studies, SIFT features extracted from the images are used to improve the classification accuracy of the models. A second contribution of this paper is the comparison and statistical analysis of different machine learning methods that can be used to train our model. As a result, a best feature set and learning model to predict where humans look at images, is determined.



