# Arxiv Papers in cs.CV on 2014-11-27
### Bi-objective Optimization for Robust RGB-D Visual Odometry
- **Arxiv ID**: http://arxiv.org/abs/1411.7445v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1411.7445v1)
- **Published**: 2014-11-27 02:37:41+00:00
- **Updated**: 2014-11-27 02:37:41+00:00
- **Authors**: Tao Han, Chao Xu, Ryan Loxton, Lei Xie
- **Comment**: None
- **Journal**: None
- **Summary**: This paper considers a new bi-objective optimization formulation for robust RGB-D visual odometry. We investigate two methods for solving the proposed bi-objective optimization problem: the weighted sum method (in which the objective functions are combined into a single objective function) and the bounded objective method (in which one of the objective functions is optimized and the value of the other objective function is bounded via a constraint). Our experimental results for the open source TUM RGB-D dataset show that the new bi-objective optimization formulation is superior to several existing RGB-D odometry methods. In particular, the new formulation yields more accurate motion estimates and is more robust when textural or structural features in the image sequence are lacking.



### The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1411.7466v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7466v1)
- **Published**: 2014-11-27 04:12:57+00:00
- **Updated**: 2014-11-27 04:12:57+00:00
- **Authors**: Lingqiao Liu, Chunhua Shen, Anton van den Hengel
- **Comment**: None
- **Journal**: None
- **Summary**: A number of recent studies have shown that a Deep Convolutional Neural Network (DCNN) pretrained on a large dataset can be adopted as a universal image description which leads to astounding performance in many visual classification tasks. Most of these studies, if not all, adopt activations of the fully-connected layer of a DCNN as the image or region representation and it is believed that convolutional layer activations are less discriminative.   This paper, however, advocates that if used appropriately convolutional layer activations can be turned into a powerful image representation which enjoys many advantages over fully-connected layer activations. This is achieved by adopting a new technique proposed in this paper called cross-convolutional-layer pooling. More specifically, it extracts subarrays of feature maps of one convolutional layer as local features and pools the extracted features with the guidance of feature maps of the successive convolutional layer. Compared with exising methods that apply DCNNs in the local feature setting, the proposed method is significantly faster since it requires much fewer times of DCNN forward computation. Moreover, it avoids the domain mismatch issue which is usually encountered when applying fully connected layer activations to describe local regions. By applying our method to four popular visual classification tasks, it is demonstrated that the proposed method can achieve comparable or in some cases significantly better performance than existing fully-connected layer based image representations while incurring much lower computational cost.



### Large-scale Binary Quadratic Optimization Using Semidefinite Relaxation and Applications
- **Arxiv ID**: http://arxiv.org/abs/1411.7564v4
- **DOI**: 10.1109/TPAMI.2016.2541146
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7564v4)
- **Published**: 2014-11-27 12:05:06+00:00
- **Updated**: 2016-05-02 00:32:58+00:00
- **Authors**: Peng Wang, Chunhua Shen, Anton van den Hengel, Philip H. S. Torr
- **Comment**: Fixed some typos. 18 pages. Accepted to IEEE Transactions on Pattern
  Analysis and Machine Intelligence
- **Journal**: None
- **Summary**: In computer vision, many problems such as image segmentation, pixel labelling, and scene parsing can be formulated as binary quadratic programs (BQPs). For submodular problems, cuts based methods can be employed to efficiently solve large-scale problems. However, general nonsubmodular problems are significantly more challenging to solve. Finding a solution when the problem is of large size to be of practical interest, however, typically requires relaxation. Two standard relaxation methods are widely used for solving general BQPs--spectral methods and semidefinite programming (SDP), each with their own advantages and disadvantages. Spectral relaxation is simple and easy to implement, but its bound is loose. Semidefinite relaxation has a tighter bound, but its computational complexity is high, especially for large scale problems. In this work, we present a new SDP formulation for BQPs, with two desirable properties. First, it has a similar relaxation bound to conventional SDP formulations. Second, compared with conventional SDP methods, the new SDP formulation leads to a significantly more efficient and scalable dual optimization approach, which has the same degree of complexity as spectral methods. We then propose two solvers, namely, quasi-Newton and smoothing Newton methods, for the dual problem. Both of them are significantly more efficiently than standard interior-point methods. In practice, the smoothing Newton solver is faster than the quasi-Newton solver for dense or medium-sized problems, while the quasi-Newton solver is preferable for large sparse/structured problems. Our experiments on a few computer vision applications including clustering, image segmentation, co-segmentation and registration show the potential of our SDP formulation for solving large-scale BQPs.



### An Egocentric Look at Video Photographer Identity
- **Arxiv ID**: http://arxiv.org/abs/1411.7591v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7591v3)
- **Published**: 2014-11-27 13:30:53+00:00
- **Updated**: 2015-11-08 16:37:31+00:00
- **Authors**: Yedid Hoshen, Shmuel Peleg
- **Comment**: None
- **Journal**: Proc. CVPR'16, Las Vegas, June 2016, pp. 4284-4292
- **Summary**: Egocentric cameras are being worn by an increasing number of users, among them many security forces worldwide. GoPro cameras already penetrated the mass market, reporting substantial increase in sales every year. As head-worn cameras do not capture the photographer, it may seem that the anonymity of the photographer is preserved even when the video is publicly distributed.   We show that camera motion, as can be computed from the egocentric video, provides unique identity information. The photographer can be reliably recognized from a few seconds of video captured when walking. The proposed method achieves more than 90% recognition accuracy in cases where the random success rate is only 3%.   Applications can include theft prevention by locking the camera when not worn by its rightful owner. Searching video sharing services (e.g. YouTube) for egocentric videos shot by a specific photographer may also become possible. An important message in this paper is that photographers should be aware that sharing egocentric video will compromise their anonymity, even when their face is not visible.



### A statistical reduced-reference method for color image quality assessment
- **Arxiv ID**: http://arxiv.org/abs/1411.7655v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7655v1)
- **Published**: 2014-11-27 17:24:59+00:00
- **Updated**: 2014-11-27 17:24:59+00:00
- **Authors**: Mounir Omari, Mohammed El Hassouni, Abdelkaher Ait Abdelouahad, Hocine Cherifi
- **Comment**: None
- **Journal**: None
- **Summary**: Although color is a fundamental feature of human visual perception, it has been largely unexplored in the reduced-reference (RR) image quality assessment (IQA) schemes. In this paper, we propose a natural scene statistic (NSS) method, which efficiently uses this information. It is based on the statistical deviation between the steerable pyramid coefficients of the reference color image and the degraded one. We propose and analyze the multivariate generalized Gaussian distribution (MGGD) to model the underlying statistics. In order to quantify the degradation, we develop and evaluate two measures based respectively on the Geodesic distance between two MGGDs and on the closed-form of the Kullback Leibler divergence. We performed an extensive evaluation of both metrics in various color spaces (RGB, HSV, CIELAB and YCrCb) using the TID 2008 benchmark and the FRTV Phase I validation process. Experimental results demonstrate the effectiveness of the proposed framework to achieve a good consistency with human visual perception. Furthermore, the best configuration is obtained with CIELAB color space associated to KLD deviation measure.



### Visual Representations: Defining Properties and Deep Approximations
- **Arxiv ID**: http://arxiv.org/abs/1411.7676v9
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7676v9)
- **Published**: 2014-11-27 18:42:49+00:00
- **Updated**: 2016-02-29 18:37:32+00:00
- **Authors**: Stefano Soatto, Alessandro Chiuso
- **Comment**: UCLA CSD TR140023, Nov. 12, 2014, revised April 13, 2015, November
  13, 2015, February 28, 2016
- **Journal**: None
- **Summary**: Visual representations are defined in terms of minimal sufficient statistics of visual data, for a class of tasks, that are also invariant to nuisance variability. Minimal sufficiency guarantees that we can store a representation in lieu of raw data with smallest complexity and no performance loss on the task at hand. Invariance guarantees that the statistic is constant with respect to uninformative transformations of the data. We derive analytical expressions for such representations and show they are related to feature descriptors commonly used in computer vision, as well as to convolutional neural networks. This link highlights the assumptions and approximations tacitly assumed by these methods and explains empirical practices such as clamping, pooling and joint normalization.



### On color image quality assessment using natural image statistics
- **Arxiv ID**: http://arxiv.org/abs/1411.7682v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7682v1)
- **Published**: 2014-11-27 19:04:30+00:00
- **Updated**: 2014-11-27 19:04:30+00:00
- **Authors**: Mounir Omari, Mohammed El Hassouni, Hocine Cherifi, Abdelkaher Ait Abdelouahad
- **Comment**: None
- **Journal**: None
- **Summary**: Color distortion can introduce a significant damage in visual quality perception, however, most of existing reduced-reference quality measures are designed for grayscale images. In this paper, we consider a basic extension of well-known image-statistics based quality assessment measures to color images. In order to evaluate the impact of color information on the measures efficiency, two color spaces are investigated: RGB and CIELAB. Results of an extensive evaluation using TID 2013 benchmark demonstrates that significant improvement can be achieved for a great number of distortion type when the CIELAB color representation is used.



### Features in Concert: Discriminative Feature Selection meets Unsupervised Clustering
- **Arxiv ID**: http://arxiv.org/abs/1411.7714v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7714v1)
- **Published**: 2014-11-27 22:37:58+00:00
- **Updated**: 2014-11-27 22:37:58+00:00
- **Authors**: Marius Leordeanu, Alexandra Radu, Rahul Sukthankar
- **Comment**: None
- **Journal**: None
- **Summary**: Feature selection is an essential problem in computer vision, important for category learning and recognition. Along with the rapid development of a wide variety of visual features and classifiers, there is a growing need for efficient feature selection and combination methods, to construct powerful classifiers for more complex and higher-level recognition tasks. We propose an algorithm that efficiently discovers sparse, compact representations of input features or classifiers, from a vast sea of candidates, with important optimality properties, low computational cost and excellent accuracy in practice. Different from boosting, we start with a discriminant linear classification formulation that encourages sparse solutions. Then we obtain an equivalent unsupervised clustering problem that jointly discovers ensembles of diverse features. They are independently valuable but even more powerful when united in a cluster of classifiers. We evaluate our method on the task of large-scale recognition in video and show that it significantly outperforms classical selection approaches, such as AdaBoost and greedy forward-backward selection, and powerful classifiers such as SVMs, in speed of training and performance, especially in the case of limited training data.



### Flying Objects Detection from a Single Moving Camera
- **Arxiv ID**: http://arxiv.org/abs/1411.7715v1
- **DOI**: 10.1109/CVPR.2015.7299040
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.7715v1)
- **Published**: 2014-11-27 22:39:50+00:00
- **Updated**: 2014-11-27 22:39:50+00:00
- **Authors**: Artem Rozantsev, Vincent Lepetit, Pascal Fua
- **Comment**: None
- **Journal**: None
- **Summary**: We propose an approach to detect flying objects such as UAVs and aircrafts when they occupy a small portion of the field of view, possibly moving against complex backgrounds, and are filmed by a camera that itself moves.   Solving such a difficult problem requires combining both appearance and motion cues. To this end we propose a regression-based approach to motion stabilization of local image patches that allows us to achieve effective classification on spatio-temporal image cubes and outperform state-of-the-art techniques.   As the problem is relatively new, we collected two challenging datasets for UAVs and Aircrafts, which can be used as benchmarks for flying objects detection and vision-guided collision avoidance.



