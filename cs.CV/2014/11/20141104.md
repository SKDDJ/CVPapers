# Arxiv Papers in cs.CV on 2014-11-04
### State-of-the-Art in Retinal Optical Coherence Tomography Image Analysis
- **Arxiv ID**: http://arxiv.org/abs/1411.0740v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.0740v2)
- **Published**: 2014-11-04 00:10:57+00:00
- **Updated**: 2014-11-17 20:36:38+00:00
- **Authors**: Ahmadreza Baghaie, Roshan M. D'souza, Zeyun Yu
- **Comment**: Added references, corrected typos
- **Journal**: None
- **Summary**: Optical Coherence Tomography (OCT) is one of the most emerging imaging modalities that has been used widely in the field of biomedical imaging. From its emergence in 1990's, plenty of hardware and software improvements have been made. Its applications range from ophthalmology to dermatology to coronary imaging etc. Here, the focus is on applications of OCT in ophthalmology and retinal imaging. OCT is able to non-invasively produce cross-sectional volume images of the tissues which are further used for analysis of the tissue structure and its properties. Due to the underlying physics, OCT images usually suffer from a granular pattern, called speckle noise, which restricts the process of interpretation, hence requiring specialized noise reduction techniques to remove the noise while preserving image details. Also, given the fact that OCT images are in the $\mu m$ -level, further analysis in needed to distinguish between the different structures in the imaged volume. Therefore the use of different segmentation techniques are of high importance. The movement of the tissue under imaging or the progression of disease in the tissue also imposes further implications both on the quality and the proper interpretation of the acquired images. Thus, use of image registration techniques can be very helpful. In this work, an overview of such image analysis techniques will be given.



### A Weighted Common Subgraph Matching Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1411.0763v1
- **DOI**: None
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1411.0763v1)
- **Published**: 2014-11-04 02:39:46+00:00
- **Updated**: 2014-11-04 02:39:46+00:00
- **Authors**: Xu Yang, Hong Qiao, Zhi-Yong Liu
- **Comment**: 6 pages, 5 figures, the second round revision in IEEE TNNLS
- **Journal**: None
- **Summary**: We propose a weighted common subgraph (WCS) matching algorithm to find the most similar subgraphs in two labeled weighted graphs. WCS matching, as a natural generalization of the equal-sized graph matching or subgraph matching, finds wide applications in many computer vision and machine learning tasks. In this paper, the WCS matching is first formulated as a combinatorial optimization problem over the set of partial permutation matrices. Then it is approximately solved by a recently proposed combinatorial optimization framework - Graduated NonConvexity and Concavity Procedure (GNCCP). Experimental comparisons on both synthetic graphs and real world images validate its robustness against noise level, problem size, outlier number, and edge density.



### A Robust Point Sets Matching Method
- **Arxiv ID**: http://arxiv.org/abs/1411.0791v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.0791v1)
- **Published**: 2014-11-04 05:53:45+00:00
- **Updated**: 2014-11-04 05:53:45+00:00
- **Authors**: Xiao Liu, Congying Han, Tiande Guo
- **Comment**: 9 pages, 3 figures, 4 tables
- **Journal**: None
- **Summary**: Point sets matching method is very important in computer vision, feature extraction, fingerprint matching, motion estimation and so on. This paper proposes a robust point sets matching method. We present an iterative algorithm that is robust to noise case. Firstly, we calculate all transformations between two points. Then similarity matrix are computed to measure the possibility that two transformation are both true. We iteratively update the matching score matrix by using the similarity matrix. By using matching algorithm on graph, we obtain the matching result. Experimental results obtained by our approach show robustness to outlier and jitter.



### Simultaneous Localization, Mapping, and Manipulation for Unsupervised Object Discovery
- **Arxiv ID**: http://arxiv.org/abs/1411.0802v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1411.0802v1)
- **Published**: 2014-11-04 06:46:30+00:00
- **Updated**: 2014-11-04 06:46:30+00:00
- **Authors**: Lu Ma, Mahsa Ghafarianzadeh, Dave Coleman, Nikolaus Correll, Gabe Sibley
- **Comment**: None
- **Journal**: None
- **Summary**: We present an unsupervised framework for simultaneous appearance-based object discovery, detection, tracking and reconstruction using RGBD cameras and a robot manipulator. The system performs dense 3D simultaneous localization and mapping concurrently with unsupervised object discovery. Putative objects that are spatially and visually coherent are manipulated by the robot to gain additional motion-cues. The robot uses appearance alone, followed by structure and motion cues, to jointly discover, verify, learn and improve models of objects. Induced motion segmentation reinforces learned models which are represented implicitly as 2D and 3D level sets to capture both shape and appearance. We compare three different approaches for appearance-based object discovery and find that a novel form of spatio-temporal super-pixels gives the highest quality candidate object models in terms of precision and recall. Live experiments with a Baxter robot demonstrate a holistic pipeline capable of automatic discovery, verification, detection, tracking and reconstruction of unknown objects.



### A random algorithm for low-rank decomposition of large-scale matrices with missing entries
- **Arxiv ID**: http://arxiv.org/abs/1411.0814v1
- **DOI**: 10.1109/TIP.2015.2458176
- **Categories**: **cs.NA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1411.0814v1)
- **Published**: 2014-11-04 07:43:15+00:00
- **Updated**: 2014-11-04 07:43:15+00:00
- **Authors**: Yiguang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: A Random SubMatrix method (RSM) is proposed to calculate the low-rank decomposition of large-scale matrices with known entry percentage \rho. RSM is very fast as the floating-point operations (flops) required are compared favorably with the state-of-the-art algorithms. Meanwhile RSM is very memory-saving. With known entries homogeneously distributed in the given matrix, sub-matrices formed by known entries are randomly selected. According to the just proved theorem that subspace related to smaller singular values is less perturbed by noise, the null vectors or the right singular vectors associated with the minor singular values are calculated for each submatrix. The vectors are the null vectors of the corresponding submatrix in the ground truth of the given large-scale matrix. If enough sub-matrices are randomly chosen, the low-rank decomposition is estimated. The experimental results on random synthetical matrices with sizes such as 131072X1024 and on real data sets indicate that RSM is much faster and memory-saving, and, meanwhile, has considerable high precision achieving or approximating to the best.



### Deep Gaze I: Boosting Saliency Prediction with Feature Maps Trained on ImageNet
- **Arxiv ID**: http://arxiv.org/abs/1411.1045v4
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1411.1045v4)
- **Published**: 2014-11-04 20:56:51+00:00
- **Updated**: 2015-04-09 09:48:11+00:00
- **Authors**: Matthias KÃ¼mmerer, Lucas Theis, Matthias Bethge
- **Comment**: None
- **Journal**: None
- **Summary**: Recent results suggest that state-of-the-art saliency models perform far from optimal in predicting fixations. This lack in performance has been attributed to an inability to model the influence of high-level image features such as objects. Recent seminal advances in applying deep neural networks to tasks like object recognition suggests that they are able to capture this kind of structure. However, the enormous amount of training data necessary to train these networks makes them difficult to apply directly to saliency prediction. We present a novel way of reusing existing neural networks that have been pretrained on the task of object recognition in models of fixation prediction. Using the well-known network of Krizhevsky et al. (2012), we come up with a new saliency model that significantly outperforms all state-of-the-art models on the MIT Saliency Benchmark. We show that the structure of this network allows new insights in the psychophysics of fixation selection and potentially their neural implementation. To train our network, we build on recent work on the modeling of saliency as point processes.



### Do Convnets Learn Correspondence?
- **Arxiv ID**: http://arxiv.org/abs/1411.1091v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1411.1091v1)
- **Published**: 2014-11-04 21:35:55+00:00
- **Updated**: 2014-11-04 21:35:55+00:00
- **Authors**: Jonathan Long, Ning Zhang, Trevor Darrell
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural nets (convnets) trained from massive labeled datasets have substantially improved the state-of-the-art in image classification and object detection. However, visual understanding requires establishing correspondence on a finer level than object category. Given their large pooling regions and training from whole-image labels, it is not clear that convnets derive their success from an accurate correspondence model which could be used for precise localization. In this paper, we study the effectiveness of convnet activation features for tasks requiring correspondence. We present evidence that convnet features localize at a much finer scale than their receptive field sizes, that they can be used to perform intraclass alignment as well as conventional hand-engineered features, and that they outperform conventional features in keypoint prediction on objects from PASCAL VOC 2011.



