# Arxiv Papers in cs.CV on 2014-11-25
### Deep convolutional filter banks for texture recognition and segmentation
- **Arxiv ID**: http://arxiv.org/abs/1411.6836v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.6836v2)
- **Published**: 2014-11-25 12:36:23+00:00
- **Updated**: 2015-07-09 18:25:43+00:00
- **Authors**: Mircea Cimpoi, Subhransu Maji, Andrea Vedaldi
- **Comment**: Accepted to CVPR15
- **Journal**: None
- **Summary**: Research in texture recognition often concentrates on the problem of material recognition in uncluttered conditions, an assumption rarely met by applications. In this work we conduct a first study of material and describable texture at- tributes recognition in clutter, using a new dataset derived from the OpenSurface texture repository. Motivated by the challenge posed by this problem, we propose a new texture descriptor, D-CNN, obtained by Fisher Vector pooling of a Convolutional Neural Network (CNN) filter bank. D-CNN substantially improves the state-of-the-art in texture, mate- rial and scene recognition. Our approach achieves 82.3% accuracy on Flickr material dataset and 81.1% accuracy on MIT indoor scenes, providing absolute gains of more than 10% over existing approaches. D-CNN easily trans- fers across domains without requiring feature adaptation as for methods that build on the fully-connected layers of CNNs. Furthermore, D-CNN can seamlessly incorporate multi-scale information and describe regions of arbitrary shapes and sizes. Our approach is particularly suited at lo- calizing stuff categories and obtains state-of-the-art re- sults on MSRC segmentation dataset, as well as promising results on recognizing materials and surface attributes in clutter on the OpenSurfaces dataset.



### Similarity- based approach for outlier detection
- **Arxiv ID**: http://arxiv.org/abs/1411.6850v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.6850v1)
- **Published**: 2014-11-25 13:13:47+00:00
- **Updated**: 2014-11-25 13:13:47+00:00
- **Authors**: Amina Dik, Khalid Jebari, Abdelaziz Bouroumi, Aziz Ettouhami
- **Comment**: International Journal of Computer Science Issues 2014
- **Journal**: None
- **Summary**: This paper presents a new approach for detecting outliers by introducing the notion of object's proximity. The main idea is that normal point has similar characteristics with several neighbors. So the point in not an outlier if it has a high degree of proximity and its neighbors are several. The performance of this approach is illustrated through real datasets



### Design, Implementation and Simulation of a Cloud Computing System for Enhancing Real-time Video Services by using VANET and Onboard Navigation Systems
- **Arxiv ID**: http://arxiv.org/abs/1412.6149v1
- **DOI**: None
- **Categories**: **cs.NI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1412.6149v1)
- **Published**: 2014-11-25 13:52:07+00:00
- **Updated**: 2014-11-25 13:52:07+00:00
- **Authors**: Karim Hammoudi, Nabil Ajam, Mohamed Kasraoui, Fadi Dornaika, Karan Radhakrishnan, Karthik Bandi, Qing Cai, Sai Liu
- **Comment**: paper accepted for publication in the proceedings of the "17\`eme
  Colloque Compression et Repr\'esentation des Signaux Audiovisuels" (CORESA),
  5p., Reims, France, 2014. (preprint)
- **Journal**: None
- **Summary**: In this paper, we propose a design for novel and experimental cloud computing systems. The proposed system aims at enhancing computational, communicational and annalistic capabilities of road navigation services by merging several independent technologies, namely vision-based embedded navigation systems, prominent Cloud Computing Systems (CCSs) and Vehicular Ad-hoc NETwork (VANET). This work presents our initial investigations by describing the design of a global generic system. The designed system has been experimented with various scenarios of video-based road services. Moreover, the associated architecture has been implemented on a small-scale simulator of an in-vehicle embedded system. The implemented architecture has been experimented in the case of a simulated road service to aid the police agency. The goal of this service is to recognize and track searched individuals and vehicles in a real-time monitoring system remotely connected to moving cars. The presented work demonstrates the potential of our system for efficiently enhancing and diversifying real-time video services in road environments.



### An Automated Images-to-Graphs Framework for High Resolution Connectomics
- **Arxiv ID**: http://arxiv.org/abs/1411.6880v2
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1411.6880v2)
- **Published**: 2014-11-25 14:37:47+00:00
- **Updated**: 2015-04-30 06:04:10+00:00
- **Authors**: William Gray Roncal, Dean M. Kleissas, Joshua T. Vogelstein, Priya Manavalan, Kunal Lillaney, Michael Pekala, Randal Burns, R. Jacob Vogelstein, Carey E. Priebe, Mark A. Chevillet, Gregory D. Hager
- **Comment**: 13 pages, first two authors contributed equally V2: Added additional
  experiments and clarifications; added information on infrastructure and
  pipeline environment
- **Journal**: None
- **Summary**: Reconstructing a map of neuronal connectivity is a critical challenge in contemporary neuroscience. Recent advances in high-throughput serial section electron microscopy (EM) have produced massive 3D image volumes of nanoscale brain tissue for the first time. The resolution of EM allows for individual neurons and their synaptic connections to be directly observed. Recovering neuronal networks by manually tracing each neuronal process at this scale is unmanageable, and therefore researchers are developing automated image processing modules. Thus far, state-of-the-art algorithms focus only on the solution to a particular task (e.g., neuron segmentation or synapse identification).   In this manuscript we present the first fully automated images-to-graphs pipeline (i.e., a pipeline that begins with an imaged volume of neural tissue and produces a brain graph without any human interaction). To evaluate overall performance and select the best parameters and methods, we also develop a metric to assess the quality of the output graphs. We evaluate a set of algorithms and parameters, searching possible operating points to identify the best available brain graph for our assessment metric. Finally, we deploy a reference end-to-end version of the pipeline on a large, publicly available data set. This provides a baseline result and framework for community analysis and future algorithm development and testing. All code and data derivatives have been made publicly available toward eventually unlocking new biofidelic computational primitives and understanding of neuropathologies.



### Image Classification and Retrieval from User-Supplied Tags
- **Arxiv ID**: http://arxiv.org/abs/1411.6909v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1411.6909v1)
- **Published**: 2014-11-25 16:17:09+00:00
- **Updated**: 2014-11-25 16:17:09+00:00
- **Authors**: Hamid Izadinia, Ali Farhadi, Aaron Hertzmann, Matthew D. Hoffman
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes direct learning of image classification from user-supplied tags, without filtering. Each tag is supplied by the user who shared the image online. Enormous numbers of these tags are freely available online, and they give insight about the image categories important to users and to image classification. Our approach is complementary to the conventional approach of manual annotation, which is extremely costly. We analyze of the Flickr 100 Million Image dataset, making several useful observations about the statistics of these tags. We introduce a large-scale robust classification algorithm, in order to handle the inherent noise in these tags, and a calibration procedure to better predict objective annotations. We show that freely available, user-supplied tags can obtain similar or superior results to large databases of costly manual annotations.



### Post-acquisition image based compensation for thickness variation in microscopy section series
- **Arxiv ID**: http://arxiv.org/abs/1411.6970v2
- **DOI**: 10.1109/ISBI.2015.7163922
- **Categories**: **cs.CV**, q-bio.QM, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1411.6970v2)
- **Published**: 2014-11-25 19:01:12+00:00
- **Updated**: 2015-05-27 19:39:10+00:00
- **Authors**: Philipp Hanslovsky, John A. Bogovic, Stephan Saalfeld
- **Comment**: None
- **Journal**: IEEE International Symposium on Biomedical Imaging, 2015, pages
  507--511
- **Summary**: Serial section Microscopy is an established method for volumetric anatomy reconstruction. Section series imaged with Electron Microscopy are currently vital for the reconstruction of the synaptic connectivity of entire animal brains such as that of Drosophila melanogaster. The process of removing ultrathin layers from a solid block containing the specimen, however, is a fragile procedure and has limited precision with respect to section thickness. We have developed a method to estimate the relative z-position of each individual section as a function of signal change across the section series. First experiments show promising results on both serial section Transmission Electron Microscopy (ssTEM) data and Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) series. We made our solution available as Open Source plugins for the TrakEM2 software and the ImageJ distribution Fiji.



