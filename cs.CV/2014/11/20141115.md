# Arxiv Papers in cs.CV on 2014-11-15
### GASP : Geometric Association with Surface Patches
- **Arxiv ID**: http://arxiv.org/abs/1411.4098v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1411.4098v1)
- **Published**: 2014-11-15 01:31:55+00:00
- **Updated**: 2014-11-15 01:31:55+00:00
- **Authors**: Rahul Sawhney, Fuxin Li, Henrik I. Christensen
- **Comment**: International Conference on 3D Vision, 2014
- **Journal**: None
- **Summary**: A fundamental challenge to sensory processing tasks in perception and robotics is the problem of obtaining data associations across views. We present a robust solution for ascertaining potentially dense surface patch (superpixel) associations, requiring just range information. Our approach involves decomposition of a view into regularized surface patches. We represent them as sequences expressing geometry invariantly over their superpixel neighborhoods, as uniquely consistent partial orderings. We match these representations through an optimal sequence comparison metric based on the Damerau-Levenshtein distance - enabling robust association with quadratic complexity (in contrast to hitherto employed joint matching formulations which are NP-complete). The approach is able to perform under wide baselines, heavy rotations, partial overlaps, significant occlusions and sensor noise.   The technique does not require any priors -- motion or otherwise, and does not make restrictive assumptions on scene structure and sensor movement. It does not require appearance -- is hence more widely applicable than appearance reliant methods, and invulnerable to related ambiguities such as textureless or aliased content. We present promising qualitative and quantitative results under diverse settings, along with comparatives with popular approaches based on range as well as RGB-D data.



### Deep Deconvolutional Networks for Scene Parsing
- **Arxiv ID**: http://arxiv.org/abs/1411.4101v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1411.4101v1)
- **Published**: 2014-11-15 02:03:14+00:00
- **Updated**: 2014-11-15 02:03:14+00:00
- **Authors**: Rahul Mohan
- **Comment**: None
- **Journal**: None
- **Summary**: Scene parsing is an important and challenging prob- lem in computer vision. It requires labeling each pixel in an image with the category it belongs to. Tradition- ally, it has been approached with hand-engineered features from color information in images. Recently convolutional neural networks (CNNs), which automatically learn hierar- chies of features, have achieved record performance on the task. These approaches typically include a post-processing technique, such as superpixels, to produce the final label- ing. In this paper, we propose a novel network architecture that combines deep deconvolutional neural networks with CNNs. Our experiments show that deconvolutional neu- ral networks are capable of learning higher order image structure beyond edge primitives in comparison to CNNs. The new network architecture is employed for multi-patch training, introduced as part of this work. Multi-patch train- ing makes it possible to effectively learn spatial priors from scenes. The proposed approach yields state-of-the-art per- formance on four scene parsing datasets, namely Stanford Background, SIFT Flow, CamVid, and KITTI. In addition, our system has the added advantage of having a training system that can be completely automated end-to-end with- out requiring any post-processing.



### Anisotropic Agglomerative Adaptive Mean-Shift
- **Arxiv ID**: http://arxiv.org/abs/1411.4102v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1411.4102v1)
- **Published**: 2014-11-15 02:05:22+00:00
- **Updated**: 2014-11-15 02:05:22+00:00
- **Authors**: Rahul Sawhney, Henrik I. Christensen, Gary R. Bradski
- **Comment**: British Machine Vision Conference, 2014
- **Journal**: None
- **Summary**: Mean Shift today, is widely used for mode detection and clustering. The technique though, is challenged in practice due to assumptions of isotropicity and homoscedasticity. We present an adaptive Mean Shift methodology that allows for full anisotropic clustering, through unsupervised local bandwidth selection. The bandwidth matrices evolve naturally, adapting locally through agglomeration, and in turn guiding further agglomeration. The online methodology is practical and effecive for low-dimensional feature spaces, preserving better detail and clustering salience. Additionally, conventional Mean Shift either critically depends on a per instance choice of bandwidth, or relies on offline methods which are inflexible and/or again data instance specific. The presented approach, due to its adaptive design, also alleviates this issue - with a default form performing generally well. The methodology though, allows for effective tuning of results.



### Definition of Visual Speech Element and Research on a Method of Extracting Feature Vector for Korean Lip-Reading
- **Arxiv ID**: http://arxiv.org/abs/1411.4114v1
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1411.4114v1)
- **Published**: 2014-11-15 05:44:10+00:00
- **Updated**: 2014-11-15 05:44:10+00:00
- **Authors**: Ha Jong Won, Li Gwang Chol, Kim Hyok Chol, Li Kum Song
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we defined the viseme (visual speech element) and described about the method of extracting visual feature vector. We defined the 10 visemes based on vowel by analyzing of Korean utterance and proposed the method of extracting the 20-dimensional visual feature vector, combination of static features and dynamic features. Lastly, we took an experiment in recognizing words based on 3-viseme HMM and evaluated the efficiency.



