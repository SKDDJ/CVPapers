# Arxiv Papers in cs.CV on 2014-09-08
### Real Time Fabric Defect Detection System on an Embedded DSP Platform
- **Arxiv ID**: http://arxiv.org/abs/1410.0371v1
- **DOI**: 10.1016/j.ijleo.2013.03.038
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.0371v1)
- **Published**: 2014-09-08 02:49:07+00:00
- **Updated**: 2014-09-08 02:49:07+00:00
- **Authors**: J. L. Raheja, B. Ajay, Ankit Chaudhary
- **Comment**: Optik Elsevier 2013
- **Journal**: None
- **Summary**: In industrial fabric productions, automated real time systems are needed to find out the minor defects. It will save the cost by not transporting defected products and also would help in making compmay image of quality fabrics by sending out only undefected products. A real time fabric defect detection system (FDDS), implementd on an embedded DSP platform is presented here. Textural features of fabric image are extracted based on gray level co-occurrence matrix (GLCM). A sliding window technique is used for defect detection where window moves over the whole image computing a textural energy from the GLCM of the fabric image. The energy values are compared to a reference and the deviations beyond a threshold are reported as defects and also visually represented by a window. The implementation is carried out on a TI TMS320DM642 platform and programmed using code composer studio software. The real time output of this implementation was shown on a monitor.



### When coding meets ranking: A joint framework based on local learning
- **Arxiv ID**: http://arxiv.org/abs/1409.2232v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1409.2232v2)
- **Published**: 2014-09-08 08:10:37+00:00
- **Updated**: 2016-11-02 07:33:51+00:00
- **Authors**: Jim Jing-Yan Wang, Xuefeng Cui, Ge Yu, Lili Guo, Xin Gao
- **Comment**: None
- **Journal**: None
- **Summary**: Sparse coding, which represents a data point as a sparse reconstruction code with regard to a dictionary, has been a popular data representation method. Meanwhile, in database retrieval problems, learning the ranking scores from data points plays an important role. Up to now, these two problems have always been considered separately, assuming that data coding and ranking are two independent and irrelevant problems. However, is there any internal relationship between sparse coding and ranking score learning? If yes, how to explore and make use of this internal relationship? In this paper, we try to answer these questions by developing the first joint sparse coding and ranking score learning algorithm. To explore the local distribution in the sparse code space, and also to bridge coding and ranking problems, we assume that in the neighborhood of each data point, the ranking scores can be approximated from the corresponding sparse codes by a local linear function. By considering the local approximation error of ranking scores, the reconstruction error and sparsity of sparse coding, and the query information provided by the user, we construct a unified objective function for learning of sparse codes, the dictionary and ranking scores. We further develop an iterative algorithm to solve this optimization problem.



### Variational Inference for Uncertainty on the Inputs of Gaussian Process Models
- **Arxiv ID**: http://arxiv.org/abs/1409.2287v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.AI, cs.CV, cs.LG, 60G15 (Primary), 58E30, G.3; G.1.2; I.2.6; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1409.2287v1)
- **Published**: 2014-09-08 10:47:23+00:00
- **Updated**: 2014-09-08 10:47:23+00:00
- **Authors**: Andreas C. Damianou, Michalis K. Titsias, Neil D. Lawrence
- **Comment**: 51 pages (of which 10 is Appendix), 19 figures
- **Journal**: None
- **Summary**: The Gaussian process latent variable model (GP-LVM) provides a flexible approach for non-linear dimensionality reduction that has been widely applied. However, the current approach for training GP-LVMs is based on maximum likelihood, where the latent projection variables are maximized over rather than integrated out. In this paper we present a Bayesian method for training GP-LVMs by introducing a non-standard variational inference framework that allows to approximately integrate out the latent variables and subsequently train a GP-LVM by maximizing an analytic lower bound on the exact marginal likelihood. We apply this method for learning a GP-LVM from iid observations and for learning non-linear dynamical systems where the observations are temporally correlated. We show that a benefit of the variational Bayesian procedure is its robustness to overfitting and its ability to automatically select the dimensionality of the nonlinear latent space. The resulting framework is generic, flexible and easy to extend for other purposes, such as Gaussian process regression with uncertain inputs and semi-supervised Gaussian processes. We demonstrate our method on synthetic data and standard machine learning benchmarks, as well as challenging real world datasets, including high resolution video data.



### Comparing Feature Detectors: A bias in the repeatability criteria, and how to correct it
- **Arxiv ID**: http://arxiv.org/abs/1409.2465v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.2465v2)
- **Published**: 2014-09-08 19:02:01+00:00
- **Updated**: 2014-09-09 08:12:35+00:00
- **Authors**: Ives Rey-Otero, Mauricio Delbracio, Jean-Michel Morel
- **Comment**: Fixed typo in affiliations
- **Journal**: None
- **Summary**: Most computer vision application rely on algorithms finding local correspondences between different images. These algorithms detect and compare stable local invariant descriptors centered at scale-invariant keypoints. Because of the importance of the problem, new keypoint detectors and descriptors are constantly being proposed, each one claiming to perform better (or to be complementary) to the preceding ones. This raises the question of a fair comparison between very diverse methods. This evaluation has been mainly based on a repeatability criterion of the keypoints under a series of image perturbations (blur, illumination, noise, rotations, homotheties, homographies, etc). In this paper, we argue that the classic repeatability criterion is biased towards algorithms producing redundant overlapped detections. To compensate this bias, we propose a variant of the repeatability rate taking into account the descriptors overlap. We apply this variant to revisit the popular benchmark by Mikolajczyk et al., on classic and new feature detectors. Experimental evidence shows that the hierarchy of these feature detectors is severely disrupted by the amended comparator.



