# Arxiv Papers in cs.CV on 2014-09-22
### Spatially-sparse convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1409.6070v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1409.6070v1)
- **Published**: 2014-09-22 02:39:27+00:00
- **Updated**: 2014-09-22 02:39:27+00:00
- **Authors**: Benjamin Graham
- **Comment**: 13 pages
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) perform well on problems such as handwriting recognition and image classification. However, the performance of the networks is often limited by budget and time constraints, particularly when trying to train deep networks.   Motivated by the problem of online handwriting recognition, we developed a CNN for processing spatially-sparse inputs; a character drawn with a one-pixel wide pen on a high resolution grid looks like a sparse matrix. Taking advantage of the sparsity allowed us more efficiently to train and test large, deep CNNs. On the CASIA-OLHWDB1.1 dataset containing 3755 character classes we get a test error of 3.82%.   Although pictures are not sparse, they can be thought of as sparse by adding padding. Applying a deep convolutional network using sparsity has resulted in a substantial reduction in test error on the CIFAR small picture datasets: 6.28% on CIFAR-10 and 24.30% for CIFAR-100.



### Temporally Coherent Bayesian Models for Entity Discovery in Videos by Tracklet Clustering
- **Arxiv ID**: http://arxiv.org/abs/1409.6080v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.6080v2)
- **Published**: 2014-09-22 04:31:12+00:00
- **Updated**: 2015-02-06 19:34:08+00:00
- **Authors**: Adway Mitra, Soma Biswas, Chiranjib Bhattacharyya
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: A video can be represented as a sequence of tracklets, each spanning 10-20 frames, and associated with one entity (eg. a person). The task of \emph{Entity Discovery} in videos can be naturally posed as tracklet clustering. We approach this task by leveraging \emph{Temporal Coherence}(TC): the fundamental property of videos that each tracklet is likely to be associated with the same entity as its temporal neighbors. Our major contributions are the first Bayesian nonparametric models for TC at tracklet-level. We extend Chinese Restaurant Process (CRP) to propose TC-CRP, and further to Temporally Coherent Chinese Restaurant Franchise (TC-CRF) to jointly model short temporal segments. On the task of discovering persons in TV serial videos without meta-data like scripts, these methods show considerable improvement in cluster purity and person coverage compared to state-of-the-art approaches to tracklet clustering. We represent entities with mixture components, and tracklets with vectors of very generic features, which can work for any type of entity (not necessarily person). The proposed methods can perform online tracklet clustering on streaming videos with little performance deterioration unlike existing approaches, and can automatically reject tracklets resulting from false detections. Finally we discuss entity-driven video summarization- where some temporal segments of the video are selected automatically based on the discovered entities.



### 1-HKUST: Object Detection in ILSVRC 2014
- **Arxiv ID**: http://arxiv.org/abs/1409.6155v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.6155v3)
- **Published**: 2014-09-22 12:42:08+00:00
- **Updated**: 2014-10-05 13:05:24+00:00
- **Authors**: Cewu Lu, Hao Chen, Qifeng Chen, Hei Law, Yao Xiao, Chi-Keung Tang
- **Comment**: 3 pages; Author list fixed
- **Journal**: None
- **Summary**: The Imagenet Large Scale Visual Recognition Challenge (ILSVRC) is the one of the most important big data challenges to date. We participated in the object detection track of ILSVRC 2014 and received the fourth place among the 38 teams. We introduce in our object detection system a number of novel techniques in localization and recognition. For localization, initial candidate proposals are generated using selective search, and a novel bounding boxes regression method is used for better object localization. For recognition, to represent a candidate proposal, we adopt three features, namely, RCNN feature, IFV feature, and DPM feature. Given these features, category-specific combination functions are learned to improve the object recognition rate. In addition, object context in the form of background priors and object interaction priors are learned and applied in our system. Our ILSVRC 2014 results are reported alongside with the results of other participating teams.



### Fast Low-rank Representation based Spatial Pyramid Matching for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1409.5786v2
- **DOI**: 10.1016/j.knosys.2015.10.005
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5786v2)
- **Published**: 2014-09-22 13:35:34+00:00
- **Updated**: 2015-10-02 14:12:58+00:00
- **Authors**: Xi Peng, Rui Yan, Bo Zhao, Huajin Tang, Zhang Yi
- **Comment**: accepted into knowledge based systems, 2015
- **Journal**: Knowledge based Systems, 2015, 90, p.14-22
- **Summary**: Spatial Pyramid Matching (SPM) and its variants have achieved a lot of success in image classification. The main difference among them is their encoding schemes. For example, ScSPM incorporates Sparse Code (SC) instead of Vector Quantization (VQ) into the framework of SPM. Although the methods achieve a higher recognition rate than the traditional SPM, they consume more time to encode the local descriptors extracted from the image. In this paper, we propose using Low Rank Representation (LRR) to encode the descriptors under the framework of SPM. Different from SC, LRR considers the group effect among data points instead of sparsity. Benefiting from this property, the proposed method (i.e., LrrSPM) can offer a better performance. To further improve the generalizability and robustness, we reformulate the rank-minimization problem as a truncated projection problem. Extensive experimental studies show that LrrSPM is more efficient than its counterparts (e.g., ScSPM) while achieving competitive recognition rates on nine image data sets.



### Detecting People in Cubist Art
- **Arxiv ID**: http://arxiv.org/abs/1409.6235v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.6235v1)
- **Published**: 2014-09-22 16:37:57+00:00
- **Updated**: 2014-09-22 16:37:57+00:00
- **Authors**: Shiry Ginosar, Daniel Haas, Timothy Brown, Jitendra Malik
- **Comment**: None
- **Journal**: None
- **Summary**: Although the human visual system is surprisingly robust to extreme distortion when recognizing objects, most evaluations of computer object detection methods focus only on robustness to natural form deformations such as people's pose changes. To determine whether algorithms truly mirror the flexibility of human vision, they must be compared against human vision at its limits. For example, in Cubist abstract art, painted objects are distorted by object fragmentation and part-reorganization, to the point that human vision often fails to recognize them. In this paper, we evaluate existing object detection methods on these abstract renditions of objects, comparing human annotators to four state-of-the-art object detectors on a corpus of Picasso paintings. Our results demonstrate that while human perception significantly outperforms current methods, human perception and part-based models exhibit a similarly graceful degradation in object detection performance as the objects become increasingly abstract and fragmented, corroborating the theory of part-based object representation in the brain.



