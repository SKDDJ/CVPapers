# Arxiv Papers in cs.CV on 2014-09-26
### Two-stage Geometric Information Guided Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1409.7450v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1409.7450v2)
- **Published**: 2014-09-26 00:49:04+00:00
- **Updated**: 2021-02-16 22:17:35+00:00
- **Authors**: Jing Qin, Weihong Guo
- **Comment**: None
- **Journal**: None
- **Summary**: In compressive sensing, it is challenging to reconstruct image of high quality from very few noisy linear projections. Existing methods mostly work well on piecewise constant images but not so well on piecewise smooth images such as natural images, medical images that contain a lot of details. We propose a two-stage method called GeoCS to recover images with rich geometric information from very limited amount of noisy measurements. The method adopts the shearlet transform that is mathematically proven to be optimal in sparsely representing images containing anisotropic features such as edges, corners, spikes etc. It also uses the weighted total variation (TV) sparsity with spatially variant weights to preserve sharp edges but to reduce the staircase effects of TV. Geometric information extracted from the results of stage I serves as an initial prior for stage II which alternates image reconstruction and geometric information update in a mutually beneficial way. GeoCS has been tested on incomplete spectral Fourier samples. It is applicable to other types of measurements as well. Experimental results on various complicated images show that GeoCS is efficient and generates high-quality images.



### Extracting man-made objects from remote sensing images via fast level set evolutions
- **Arxiv ID**: http://arxiv.org/abs/1409.7474v1
- **DOI**: 10.1109/TGRS.2015.2454251
- **Categories**: **cs.CV**, 68T10, 68T45, B.2.4; I.4.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1409.7474v1)
- **Published**: 2014-09-26 06:17:23+00:00
- **Updated**: 2014-09-26 06:17:23+00:00
- **Authors**: Zhongbin Li, Wenzhong Shi, Qunming Wang, Zelang Miao
- **Comment**: This paper includes 31 pages and 12 figures
- **Journal**: IEEE Transactions on Geoscience and Remote Sensing, Vol.53(2),
  pp.883-899, 2015
- **Summary**: Object extraction from remote sensing images has long been an intensive research topic in the field of surveying and mapping. Most existing methods are devoted to handling just one type of object and little attention has been paid to improving the computational efficiency. In recent years, level set evolution (LSE) has been shown to be very promising for object extraction in the community of image processing and computer vision because it can handle topological changes automatically while achieving high accuracy. However, the application of state-of-the-art LSEs is compromised by laborious parameter tuning and expensive computation. In this paper, we proposed two fast LSEs for man-made object extraction from high spatial resolution remote sensing images. The traditional mean curvature-based regularization term is replaced by a Gaussian kernel and it is mathematically sound to do that. Thus a larger time step can be used in the numerical scheme to expedite the proposed LSEs. In contrast to existing methods, the proposed LSEs are significantly faster. Most importantly, they involve much fewer parameters while achieving better performance. The advantages of the proposed LSEs over other state-of-the-art approaches have been verified by a range of experiments.



### Generalized Twin Gaussian Processes using Sharma-Mittal Divergence
- **Arxiv ID**: http://arxiv.org/abs/1409.7480v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1409.7480v5)
- **Published**: 2014-09-26 06:46:38+00:00
- **Updated**: 2015-06-01 06:30:29+00:00
- **Authors**: Mohamed Elhoseiny, Ahmed Elgammal
- **Comment**: This work got accepted for Publication in the Machine Learning
  Journal 2015. The work is scheduled for presentation at ECML-PKDD 2015
  journal track papers
- **Journal**: None
- **Summary**: There has been a growing interest in mutual information measures due to their wide range of applications in Machine Learning and Computer Vision. In this paper, we present a generalized structured regression framework based on Shama-Mittal divergence, a relative entropy measure, which is introduced to the Machine Learning community in this work. Sharma-Mittal (SM) divergence is a generalized mutual information measure for the widely used R\'enyi, Tsallis, Bhattacharyya, and Kullback-Leibler (KL) relative entropies. Specifically, we study Sharma-Mittal divergence as a cost function in the context of the Twin Gaussian Processes (TGP)~\citep{Bo:2010}, which generalizes over the KL-divergence without computational penalty. We show interesting properties of Sharma-Mittal TGP (SMTGP) through a theoretical analysis, which covers missing insights in the traditional TGP formulation. However, we generalize this theory based on SM-divergence instead of KL-divergence which is a special case. Experimentally, we evaluated the proposed SMTGP framework on several datasets. The results show that SMTGP reaches better predictions than KL-based TGP, since it offers a bigger class of models through its parameters that we learn from the data.



### Location Recognition Over Large Time Lags
- **Arxiv ID**: http://arxiv.org/abs/1409.7556v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.7556v3)
- **Published**: 2014-09-26 12:36:54+00:00
- **Updated**: 2015-05-26 03:14:19+00:00
- **Authors**: Basura Fernando, Tatiana Tommasi, Tinne Tuytelaars
- **Comment**: None
- **Journal**: None
- **Summary**: Would it be possible to automatically associate ancient pictures to modern ones and create fancy cultural heritage city maps? We introduce here the task of recognizing the location depicted in an old photo given modern annotated images collected from the Internet. We present an extensive analysis on different features, looking for the most discriminative and most robust to the image variability induced by large time lags. Moreover, we show that the described task benefits from domain adaptation.



### Multiple Object Tracking: A Literature Review
- **Arxiv ID**: http://arxiv.org/abs/1409.7618v5
- **DOI**: 10.1016/j.artint.2020.103448
- **Categories**: **cs.CV**, I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1409.7618v5)
- **Published**: 2014-09-26 16:15:32+00:00
- **Updated**: 2022-02-11 17:54:27+00:00
- **Authors**: Wenhan Luo, Junliang Xing, Anton Milan, Xiaoqin Zhang, Wei Liu, Tae-Kyun Kim
- **Comment**: Accepted by Artificial Intelligence
- **Journal**: None
- **Summary**: Multiple Object Tracking (MOT) has gained increasing attention due to its academic and commercial potential. Although different approaches have been proposed to tackle this problem, it still remains challenging due to factors like abrupt appearance changes and severe object occlusions. In this work, we contribute the first comprehensive and most recent review on this problem. We inspect the recent advances in various aspects and propose some interesting directions for future research. To the best of our knowledge, there has not been any extensive review on this topic in the community. We endeavor to provide a thorough review on the development of this problem in recent decades. The main contributions of this review are fourfold: 1) Key aspects in an MOT system, including formulation, categorization, key principles, evaluation of MOT are discussed; 2) Instead of enumerating individual works, we discuss existing approaches according to various aspects, in each of which methods are divided into different groups and each group is discussed in detail for the principles, advances and drawbacks; 3) We examine experiments of existing publications and summarize results on popular datasets to provide quantitative and comprehensive comparisons. By analyzing the results from different perspectives, we have verified some basic agreements in the field; and 4) We provide a discussion about issues of MOT research, as well as some interesting directions which will become potential research effort in the future.



### How close are we to understanding image-based saliency?
- **Arxiv ID**: http://arxiv.org/abs/1409.7686v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1409.7686v1)
- **Published**: 2014-09-26 19:59:44+00:00
- **Updated**: 2014-09-26 19:59:44+00:00
- **Authors**: Matthias KÃ¼mmerer, Thomas Wallis, Matthias Bethge
- **Comment**: None
- **Journal**: None
- **Summary**: Within the set of the many complex factors driving gaze placement, the properities of an image that are associated with fixations under free viewing conditions have been studied extensively. There is a general impression that the field is close to understanding this particular association. Here we frame saliency models probabilistically as point processes, allowing the calculation of log-likelihoods and bringing saliency evaluation into the domain of information. We compared the information gain of state-of-the-art models to a gold standard and find that only one third of the explainable spatial information is captured. We additionally provide a principled method to show where and how models fail to capture information in the fixations. Thus, contrary to previous assertions, purely spatial saliency remains a significant challenge.



