# Arxiv Papers in cs.CV on 2014-09-03
### Bypassing Captcha By Machine A Proof For Passing The Turing Test
- **Arxiv ID**: http://arxiv.org/abs/1409.0925v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1409.0925v1)
- **Published**: 2014-09-03 00:05:28+00:00
- **Updated**: 2014-09-03 00:05:28+00:00
- **Authors**: Ahmad B. A. Hassanat
- **Comment**: European Scientific Journal May 2014 edition vol.10, No.15 ISSN:
  1857-7881 (Print) e-ISSN 1857-7431
- **Journal**: None
- **Summary**: For the last ten years, CAPTCHAs have been widely used by websites to prevent their data being automatically updated by machines. By supposedly allowing only humans to do so, CAPTCHAs take advantage of the reverse Turing test (TT), knowing that humans are more intelligent than machines. Generally, CAPTCHAs have defeated machines, but things are changing rapidly as technology improves. Hence, advanced research into optical character recognition (OCR) is overtaking attempts to strengthen CAPTCHAs against machine-based attacks. This paper investigates the immunity of CAPTCHA, which was built on the failure of the TT. We show that some CAPTCHAs are easily broken using a simple OCR machine built for the purpose of this study. By reviewing other techniques, we show that even more difficult CAPTCHAs can be broken using advanced OCR machines. Current advances in OCR should enable machines to pass the TT in the image recognition domain, which is exactly where machines are seeking to overcome CAPTCHAs. We enhance traditional CAPTCHAs by employing not only characters, but also natural language and multiple objects within the same CAPTCHA. The proposed CAPTCHAs might be able to hold out against machines, at least until the advent of a machine that passes the TT completely.



### Visual Speech Recognition
- **Arxiv ID**: http://arxiv.org/abs/1409.1411v1
- **DOI**: 10.5772/19361
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.1411v1)
- **Published**: 2014-09-03 00:19:42+00:00
- **Updated**: 2014-09-03 00:19:42+00:00
- **Authors**: Ahmad B. A. Hassanat
- **Comment**: Speech and Language Technologies (Book), Prof. Ivo Ipsic (Ed.), ISBN:
  978-953-307-322-4, InTech (2011)
- **Journal**: None
- **Summary**: Lip reading is used to understand or interpret speech without hearing it, a technique especially mastered by people with hearing difficulties. The ability to lip read enables a person with a hearing impairment to communicate with others and to engage in social activities, which otherwise would be difficult. Recent advances in the fields of computer vision, pattern recognition, and signal processing has led to a growing interest in automating this challenging task of lip reading. Indeed, automating the human ability to lip read, a process referred to as visual speech recognition (VSR) (or sometimes speech reading), could open the door for other novel related applications. VSR has received a great deal of attention in the last decade for its potential use in applications such as human-computer interaction (HCI), audio-visual speech recognition (AVSR), speaker recognition, talking heads, sign language recognition and video surveillance. Its main aim is to recognise spoken word(s) by using only the visual signal that is produced during speech. Hence, VSR deals with the visual domain of speech and involves image processing, artificial intelligence, object detection, pattern recognition, statistical modelling, etc.



### Constructing a Non-Negative Low Rank and Sparse Graph with Data-Adaptive Features
- **Arxiv ID**: http://arxiv.org/abs/1409.0964v1
- **DOI**: 10.1109/TIP.2015.2441632
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1409.0964v1)
- **Published**: 2014-09-03 06:45:11+00:00
- **Updated**: 2014-09-03 06:45:11+00:00
- **Authors**: Liansheng Zhuang, Shenghua Gao, Jinhui Tang, Jingjing Wang, Zhouchen Lin, Yi Ma
- **Comment**: None
- **Journal**: None
- **Summary**: This paper aims at constructing a good graph for discovering intrinsic data structures in a semi-supervised learning setting. Firstly, we propose to build a non-negative low-rank and sparse (referred to as NNLRS) graph for the given data representation. Specifically, the weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph can capture both the global mixture of subspaces structure (by the low rankness) and the locally linear structure (by the sparseness) of the data, hence is both generative and discriminative. Secondly, as good features are extremely important for constructing a good graph, we propose to learn the data embedding matrix and construct the graph jointly within one framework, which is termed as NNLRS with embedded features (referred to as NNLRS-EF). Extensive experiments on three publicly available datasets demonstrate that the proposed method outperforms the state-of-the-art graph construction method by a large margin for both semi-supervised classification and discriminative analysis, which verifies the effectiveness of our proposed method.



### Structured Low-Rank Matrix Factorization with Missing and Grossly Corrupted Observations
- **Arxiv ID**: http://arxiv.org/abs/1409.1062v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1409.1062v1)
- **Published**: 2014-09-03 12:36:25+00:00
- **Updated**: 2014-09-03 12:36:25+00:00
- **Authors**: Fanhua Shang, Yuanyuan Liu, Hanghang Tong, James Cheng, Hong Cheng
- **Comment**: 28 pages, 9 figures
- **Journal**: None
- **Summary**: Recovering low-rank and sparse matrices from incomplete or corrupted observations is an important problem in machine learning, statistics, bioinformatics, computer vision, as well as signal and image processing. In theory, this problem can be solved by the natural convex joint/mixed relaxations (i.e., l_{1}-norm and trace norm) under certain conditions. However, all current provable algorithms suffer from superlinear per-iteration cost, which severely limits their applicability to large-scale problems. In this paper, we propose a scalable, provable structured low-rank matrix factorization method to recover low-rank and sparse matrices from missing and grossly corrupted data, i.e., robust matrix completion (RMC) problems, or incomplete and grossly corrupted measurements, i.e., compressive principal component pursuit (CPCP) problems. Specifically, we first present two small-scale matrix trace norm regularized bilinear structured factorization models for RMC and CPCP problems, in which repetitively calculating SVD of a large-scale matrix is replaced by updating two much smaller factor matrices. Then, we apply the alternating direction method of multipliers (ADMM) to efficiently solve the RMC problems. Finally, we provide the convergence analysis of our algorithm, and extend it to address general CPCP problems. Experimental results verified both the efficiency and effectiveness of our method compared with the state-of-the-art methods.



### Focused Proofreading: Efficiently Extracting Connectomes from Segmented EM Images
- **Arxiv ID**: http://arxiv.org/abs/1409.1199v1
- **DOI**: None
- **Categories**: **q-bio.QM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1409.1199v1)
- **Published**: 2014-09-03 19:14:13+00:00
- **Updated**: 2014-09-03 19:14:13+00:00
- **Authors**: Stephen M. Plaza
- **Comment**: None
- **Journal**: None
- **Summary**: Identifying complex neural circuitry from electron microscopic (EM) images may help unlock the mysteries of the brain. However, identifying this circuitry requires time-consuming, manual tracing (proofreading) due to the size and intricacy of these image datasets, thus limiting state-of-the-art analysis to very small brain regions. Potential avenues to improve scalability include automatic image segmentation and crowd sourcing, but current efforts have had limited success. In this paper, we propose a new strategy, focused proofreading, that works with automatic segmentation and aims to limit proofreading to the regions of a dataset that are most impactful to the resulting circuit. We then introduce a novel workflow, which exploits biological information such as synapses, and apply it to a large dataset in the fly optic lobe. With our techniques, we achieve significant tracing speedups of 3-5x without sacrificing the quality of the resulting circuit. Furthermore, our methodology makes the task of proofreading much more accessible and hence potentially enhances the effectiveness of crowd sourcing.



