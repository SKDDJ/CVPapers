# Arxiv Papers in cs.CV on 2014-09-17
### Going Deeper with Convolutions
- **Arxiv ID**: http://arxiv.org/abs/1409.4842v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.4842v1)
- **Published**: 2014-09-17 01:03:11+00:00
- **Updated**: 2014-09-17 01:03:11+00:00
- **Authors**: Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.



### Tensity Research Based on the Information of Eye Movement
- **Arxiv ID**: http://arxiv.org/abs/1409.4958v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1409.4958v1)
- **Published**: 2014-09-17 11:52:36+00:00
- **Updated**: 2014-09-17 11:52:36+00:00
- **Authors**: Yi Wang
- **Comment**: None
- **Journal**: None
- **Summary**: User's mental state is concerned gradually, during the interaction course of human robot. As the measurement and identification method of psychological state, tension, has certain practical significance role. At presents there is no suitable method of measuring the tension. Firstly, sum up some availability of eye movement index. And then parameters extraction on eye movement characteristics of normal illumination is studied, including the location of the face, eyes location, access to the pupil diameter, the eye pupil center characteristic parameters. And with the judgment of the tension in eye images, extract exact information of gaze direction. Finally, through the experiment to prove the proposed method is effective.



### Adaptive Tag Selection for Image Annotation
- **Arxiv ID**: http://arxiv.org/abs/1409.4995v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.4995v1)
- **Published**: 2014-09-17 13:50:37+00:00
- **Updated**: 2014-09-17 13:50:37+00:00
- **Authors**: Xixi He, Xirong Li, Gang Yang, Jieping Xu, Qin Jin
- **Comment**: None
- **Journal**: None
- **Summary**: Not all tags are relevant to an image, and the number of relevant tags is image-dependent. Although many methods have been proposed for image auto-annotation, the question of how to determine the number of tags to be selected per image remains open. The main challenge is that for a large tag vocabulary, there is often a lack of ground truth data for acquiring optimal cutoff thresholds per tag. In contrast to previous works that pre-specify the number of tags to be selected, we propose in this paper adaptive tag selection. The key insight is to divide the vocabulary into two disjoint subsets, namely a seen set consisting of tags having ground truth available for optimizing their thresholds and a novel set consisting of tags without any ground truth. Such a division allows us to estimate how many tags shall be selected from the novel set according to the tags that have been selected from the seen set. The effectiveness of the proposed method is justified by our participation in the ImageCLEF 2014 image annotation task. On a set of 2,065 test images with ground truth available for 207 tags, the benchmark evaluation shows that compared to the popular top-$k$ strategy which obtains an F-score of 0.122, adaptive tag selection achieves a higher F-score of 0.223. Moreover, by treating the underlying image annotation system as a black box, the new method can be used as an easy plug-in to boost the performance of existing systems.



### A Survey on Heterogeneous Face Recognition: Sketch, Infra-red, 3D and Low-resolution
- **Arxiv ID**: http://arxiv.org/abs/1409.5114v2
- **DOI**: None
- **Categories**: **cs.CV**, A.1; I.4.9; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1409.5114v2)
- **Published**: 2014-09-17 19:55:34+00:00
- **Updated**: 2014-10-10 13:23:30+00:00
- **Authors**: Shuxin Ouyang, Timothy Hospedales, Yi-Zhe Song, Xueming Li
- **Comment**: survey paper(35 pages)
- **Journal**: None
- **Summary**: Heterogeneous face recognition (HFR) refers to matching face imagery across different domains. It has received much interest from the research community as a result of its profound implications in law enforcement. A wide variety of new invariant features, cross-modality matching models and heterogeneous datasets being established in recent years. This survey provides a comprehensive review of established techniques and recent developments in HFR. Moreover, we offer a detailed account of datasets and benchmarks commonly used for evaluation. We finish by assessing the state of the field and discussing promising directions for future research.



### Visual Words for Automatic Lip-Reading
- **Arxiv ID**: http://arxiv.org/abs/1409.6689v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.6689v1)
- **Published**: 2014-09-17 21:58:02+00:00
- **Updated**: 2014-09-17 21:58:02+00:00
- **Authors**: Ahmad Basheer Hassanat
- **Comment**: None
- **Journal**: PhD thesis, the University of Buckingham, 2009
- **Summary**: Lip reading is used to understand or interpret speech without hearing it, a technique especially mastered by people with hearing difficulties. The ability to lip read enables a person with a hearing impairment to communicate with others and to engage in social activities, which otherwise would be difficult. Recent advances in the fields of computer vision, pattern recognition, and signal processing has led to a growing interest in automating this challenging task of lip reading. Indeed, automating the human ability to lip read, a process referred to as visual speech recognition, could open the door for other novel applications. This thesis investigates various issues faced by an automated lip-reading system and proposes a novel "visual words" based approach to automatic lip reading. The proposed approach includes a novel automatic face localisation scheme and a lip localisation method.



