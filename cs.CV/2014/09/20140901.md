# Arxiv Papers in cs.CV on 2014-09-01
### Multi-tensor Completion for Estimating Missing Values in Video Data
- **Arxiv ID**: http://arxiv.org/abs/1409.0347v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.0347v1)
- **Published**: 2014-09-01 09:46:52+00:00
- **Updated**: 2014-09-01 09:46:52+00:00
- **Authors**: Chao Li, Lili Guo, Andrzej Cichocki
- **Comment**: None
- **Journal**: None
- **Summary**: Many tensor-based data completion methods aim to solve image and video in-painting problems. But, all methods were only developed for a single dataset. In most of real applications, we can usually obtain more than one dataset to reflect one phenomenon, and all the datasets are mutually related in some sense. Thus one question raised whether such the relationship can improve the performance of data completion or not? In the paper, we proposed a novel and efficient method by exploiting the relationship among datasets for multi-video data completion. Numerical results show that the proposed method significantly improve the performance of video in-painting, particularly in the case of very high missing percentage.



### ImageNet Large Scale Visual Recognition Challenge
- **Arxiv ID**: http://arxiv.org/abs/1409.0575v3
- **DOI**: None
- **Categories**: **cs.CV**, I.4.8; I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1409.0575v3)
- **Published**: 2014-09-01 22:29:38+00:00
- **Updated**: 2015-01-30 01:23:59+00:00
- **Authors**: Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei
- **Comment**: 43 pages, 16 figures. v3 includes additional comparisons with PASCAL
  VOC (per-category comparisons in Table 3, distribution of localization
  difficulty in Fig 16), a list of queries used for obtaining object detection
  images (Appendix C), and some additional references
- **Journal**: None
- **Summary**: The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions.   This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.



