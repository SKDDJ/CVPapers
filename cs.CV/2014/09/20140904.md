# Arxiv Papers in cs.CV on 2014-09-04
### The Evolution of First Person Vision Methods: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1409.1484v3
- **DOI**: 10.1109/TCSVT.2015.2409731
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.1484v3)
- **Published**: 2014-09-04 16:38:43+00:00
- **Updated**: 2015-04-03 10:00:17+00:00
- **Authors**: Alejandro Betancourt, Pietro Morerio, Carlo S. Regazzoni, Matthias Rauterberg
- **Comment**: First Person Vision, Egocentric Vision, Wearable Devices, Smart
  Glasses, Computer Vision, Video Analytics, Human-machine Interaction
- **Journal**: Betancourt, A., Morerio, P., Regazzoni, C. S., & Rauterberg, M.
  (2015). The Evolution of First Person Vision Methods: A Survey. IEEE
  Transactions on Circuits and Systems for Video Technology,
  doi:10.1109/TCSVT.2015.2409731
- **Summary**: The emergence of new wearable technologies such as action cameras and smart-glasses has increased the interest of computer vision scientists in the First Person perspective. Nowadays, this field is attracting attention and investments of companies aiming to develop commercial devices with First Person Vision recording capabilities. Due to this interest, an increasing demand of methods to process these videos, possibly in real-time, is expected. Current approaches present a particular combinations of different image features and quantitative methods to accomplish specific objectives like object detection, activity recognition, user machine interaction and so on. This paper summarizes the evolution of the state of the art in First Person Vision video analysis between 1997 and 2014, highlighting, among others, most commonly used features, methods, challenges and opportunities within the field.



### Very Deep Convolutional Networks for Large-Scale Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1409.1556v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.1556v6)
- **Published**: 2014-09-04 19:48:04+00:00
- **Updated**: 2015-04-10 16:25:04+00:00
- **Authors**: Karen Simonyan, Andrew Zisserman
- **Comment**: None
- **Journal**: None
- **Summary**: In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.



