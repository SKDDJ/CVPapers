# Arxiv Papers in cs.CV on 2014-09-18
### Deeply-Supervised Nets
- **Arxiv ID**: http://arxiv.org/abs/1409.5185v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1409.5185v2)
- **Published**: 2014-09-18 04:08:25+00:00
- **Updated**: 2014-09-25 05:03:06+00:00
- **Authors**: Chen-Yu Lee, Saining Xie, Patrick Gallagher, Zhengyou Zhang, Zhuowen Tu
- **Comment**: Patent disclosure, UCSD Docket No. SD2014-313, filed on May 22, 2014
- **Journal**: None
- **Summary**: Our proposed deeply-supervised nets (DSN) method simultaneously minimizes classification error while making the learning process of hidden layers direct and transparent. We make an attempt to boost the classification performance by studying a new formulation in deep networks. Three aspects in convolutional neural networks (CNN) style architectures are being looked at: (1) transparency of the intermediate layers to the overall classification; (2) discriminativeness and robustness of learned features, especially in the early layers; (3) effectiveness in training due to the presence of the exploding and vanishing gradients. We introduce "companion objective" to the individual hidden layers, in addition to the overall objective at the output layer (a different strategy to layer-wise pre-training). We extend techniques from stochastic gradient methods to analyze our algorithm. The advantage of our method is evident and our experimental result on benchmark datasets shows significant performance gain over existing methods (e.g. all state-of-the-art results on MNIST, CIFAR-10, CIFAR-100, and SVHN).



### Fingerprint Classification Based on Depth Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1409.5188v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5188v1)
- **Published**: 2014-09-18 04:36:19+00:00
- **Updated**: 2014-09-18 04:36:19+00:00
- **Authors**: Ruxin Wang, Congying Han, Yanping Wu, Tiande Guo
- **Comment**: 14 pages, 19 figures
- **Journal**: None
- **Summary**: Fingerprint classification is an effective technique for reducing the candidate numbers of fingerprints in the stage of matching in automatic fingerprint identification system (AFIS). In recent years, deep learning is an emerging technology which has achieved great success in many fields, such as image processing, natural language processing and so on. In this paper, we only choose the orientation field as the input feature and adopt a new method (stacked sparse autoencoders) based on depth neural network for fingerprint classification. For the four-class problem, we achieve a classification of 93.1 percent using the depth network structure which has three hidden layers (with 1.8% rejection) in the NIST-DB4 database. And then we propose a novel method using two classification probabilities for fuzzy classification which can effectively enhance the accuracy of classification. By only adjusting the probability threshold, we get the accuracy of classification is 96.1% (setting threshold is 0.85), 97.2% (setting threshold is 0.90) and 98.0% (setting threshold is 0.95). Using the fuzzy method, we obtain higher accuracy than other methods.



### Pedestrian Detection with Spatially Pooled Features and Structured Ensemble Learning
- **Arxiv ID**: http://arxiv.org/abs/1409.5209v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1409.5209v3)
- **Published**: 2014-09-18 07:14:33+00:00
- **Updated**: 2015-06-28 10:15:37+00:00
- **Authors**: Sakrapee Paisitkriangkrai, Chunhua Shen, Anton van den Hengel
- **Comment**: 19 pages
- **Journal**: None
- **Summary**: Many typical applications of object detection operate within a prescribed false-positive range. In this situation the performance of a detector should be assessed on the basis of the area under the ROC curve over that range, rather than over the full curve, as the performance outside the range is irrelevant. This measure is labelled as the partial area under the ROC curve (pAUC). We propose a novel ensemble learning method which achieves a maximal detection rate at a user-defined range of false positive rates by directly optimizing the partial AUC using structured learning.   In order to achieve a high object detection performance, we propose a new approach to extract low-level visual features based on spatial pooling. Incorporating spatial pooling improves the translational invariance and thus the robustness of the detection process. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our approach, and we show that it is possible to train state-of-the-art pedestrian detectors using the proposed structured ensemble learning method with spatially pooled features. The result is the current best reported performance on the Caltech-USA pedestrian detection dataset.



### Deep Regression for Face Alignment
- **Arxiv ID**: http://arxiv.org/abs/1409.5230v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5230v1)
- **Published**: 2014-09-18 09:10:28+00:00
- **Updated**: 2014-09-18 09:10:28+00:00
- **Authors**: Baoguang Shi, Xiang Bai, Wenyu Liu, Jingdong Wang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a deep regression approach for face alignment. The deep architecture consists of a global layer and multi-stage local layers. We apply the back-propagation algorithm with the dropout strategy to jointly optimize the regression parameters. We show that the resulting deep regressor gradually and evenly approaches the true facial landmarks stage by stage, avoiding the tendency to yield over-strong early stage regressors while over-weak later stage regressors. Experimental results show that our approach achieves the state-of-the-art



### Subspace Alignment For Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1409.5241v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5241v2)
- **Published**: 2014-09-18 09:57:41+00:00
- **Updated**: 2014-10-23 08:40:06+00:00
- **Authors**: Basura Fernando, Amaury Habrard, Marc Sebban, Tinne Tuytelaars
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a new domain adaptation (DA) algorithm where the source and target domains are represented by subspaces spanned by eigenvectors. Our method seeks a domain invariant feature space by learning a mapping function which aligns the source subspace with the target one. We show that the solution of the corresponding optimization problem can be obtained in a simple closed form, leading to an extremely fast algorithm. We present two approaches to determine the only hyper-parameter in our method corresponding to the size of the subspaces. In the first approach we tune the size of subspaces using a theoretical bound on the stability of the obtained result. In the second approach, we use maximum likelihood estimation to determine the subspace size, which is particularly useful for high dimensional data. Apart from PCA, we propose a subspace creation method that outperform partial least squares (PLS) and linear discriminant analysis (LDA) in domain adaptation. We test our method on various datasets and show that, despite its intrinsic simplicity, it outperforms state of the art DA methods.



### Visual Landmark Recognition from Internet Photo Collections: A Large-Scale Evaluation
- **Arxiv ID**: http://arxiv.org/abs/1409.5400v1
- **DOI**: 10.1016/j.cviu.2015.02.002
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5400v1)
- **Published**: 2014-09-18 18:28:20+00:00
- **Updated**: 2014-09-18 18:28:20+00:00
- **Authors**: Tobias Weyand, Bastian Leibe
- **Comment**: None
- **Journal**: None
- **Summary**: The task of a visual landmark recognition system is to identify photographed buildings or objects in query photos and to provide the user with relevant information on them. With their increasing coverage of the world's landmark buildings and objects, Internet photo collections are now being used as a source for building such systems in a fully automatic fashion. This process typically consists of three steps: clustering large amounts of images by the objects they depict; determining object names from user-provided tags; and building a robust, compact, and efficient recognition index. To this date, however, there is little empirical information on how well current approaches for those steps perform in a large-scale open-set mining and recognition task. Furthermore, there is little empirical information on how recognition performance varies for different types of landmark objects and where there is still potential for improvement. With this paper, we intend to fill these gaps. Using a dataset of 500k images from Paris, we analyze each component of the landmark recognition pipeline in order to answer the following questions: How many and what kinds of objects can be discovered automatically? How can we best use the resulting image clusters to recognize the object in a query? How can the object be efficiently represented in memory for recognition? How reliably can semantic information be extracted? And finally: What are the limiting factors in the resulting pipeline from query to semantics? We evaluate how different choices of methods and parameters for the individual pipeline steps affect overall system performance and examine their effects for different query categories such as buildings, paintings or sculptures.



### Deformable Part Models are Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1409.5403v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1409.5403v2)
- **Published**: 2014-09-18 18:34:10+00:00
- **Updated**: 2014-10-01 18:44:14+00:00
- **Authors**: Ross Girshick, Forrest Iandola, Trevor Darrell, Jitendra Malik
- **Comment**: None
- **Journal**: None
- **Summary**: Deformable part models (DPMs) and convolutional neural networks (CNNs) are two widely used tools for visual recognition. They are typically viewed as distinct approaches: DPMs are graphical models (Markov random fields), while CNNs are "black-box" non-linear classifiers. In this paper, we show that a DPM can be formulated as a CNN, thus providing a novel synthesis of the two ideas. Our construction involves unrolling the DPM inference algorithm and mapping each step to an equivalent (and at times novel) CNN layer. From this perspective, it becomes natural to replace the standard image features used in DPM with a learned feature extractor. We call the resulting model DeepPyramid DPM and experimentally validate it on PASCAL VOC. DeepPyramid DPM significantly outperforms DPMs based on histograms of oriented gradients features (HOG) and slightly outperforms a comparable version of the recently introduced R-CNN detection system, while running an order of magnitude faster.



