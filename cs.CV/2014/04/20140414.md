# Arxiv Papers in cs.CV on 2014-04-14
### Proceedings of The 38th Annual Workshop of the Austrian Association for Pattern Recognition (Ã–AGM), 2014
- **Arxiv ID**: http://arxiv.org/abs/1404.3538v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.3538v2)
- **Published**: 2014-04-14 11:01:04+00:00
- **Updated**: 2014-04-30 09:53:00+00:00
- **Authors**: Vladimir Kolmogorov, Christoph Lampert, Emilie Morvant, Rustem Takhanov
- **Comment**: None
- **Journal**: None
- **Summary**: The 38th Annual Workshop of the Austrian Association for Pattern Recognition (\"OAGM) will be held at IST Austria, on May 22-23, 2014. The workshop provides a platform for researchers and industry to discuss traditional and new areas of computer vision. This year the main topic is: Pattern Recognition: interdisciplinary challenges and opportunities.



### Recover Canonical-View Faces in the Wild with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1404.3543v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.3543v2)
- **Published**: 2014-04-14 11:32:17+00:00
- **Updated**: 2014-04-16 04:35:34+00:00
- **Authors**: Zhenyao Zhu, Ping Luo, Xiaogang Wang, Xiaoou Tang
- **Comment**: None
- **Journal**: None
- **Summary**: Face images in the wild undergo large intra-personal variations, such as poses, illuminations, occlusions, and low resolutions, which cause great challenges to face-related applications. This paper addresses this challenge by proposing a new deep learning framework that can recover the canonical view of face images. It dramatically reduces the intra-person variances, while maintaining the inter-person discriminativeness. Unlike the existing face reconstruction methods that were either evaluated in controlled 2D environment or employed 3D information, our approach directly learns the transformation from the face images with a complex set of variations to their canonical views. At the training stage, to avoid the costly process of labeling canonical-view images from the training set by hand, we have devised a new measurement to automatically select or synthesize a canonical-view image for each identity. As an application, this face recovery approach is used for face verification. Facial features are learned from the recovered canonical-view face images by using a facial component-based convolutional neural network. Our approach achieves the state-of-the-art performance on the LFW dataset.



### Face Detection with a 3D Model
- **Arxiv ID**: http://arxiv.org/abs/1404.3596v7
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.3596v7)
- **Published**: 2014-04-14 14:31:32+00:00
- **Updated**: 2015-11-03 16:28:03+00:00
- **Authors**: Adrian Barbu, Nathan Lay, Gary Gramajo
- **Comment**: 14 pages, 11 figures
- **Journal**: Academic Press Library in Signal Processing Volume 6: Image and
  Video Processing and Analysis and Computer Vision, pp 237-259, 2018. Editors:
  R. Chellappa and S. Theodoridis
- **Summary**: This paper presents a part-based face detection approach where the spatial relationship between the face parts is represented by a hidden 3D model with six parameters. The computational complexity of the search in the six dimensional pose space is addressed by proposing meaningful 3D pose candidates by image-based regression from detected face keypoint locations. The 3D pose candidates are evaluated using a parameter sensitive classifier based on difference features relative to the 3D pose. A compatible subset of candidates is then obtained by non-maximal suppression. Experiments on two standard face detection datasets show that the proposed 3D model based approach obtains results comparable to or better than state of the art.



### PCANet: A Simple Deep Learning Baseline for Image Classification?
- **Arxiv ID**: http://arxiv.org/abs/1404.3606v2
- **DOI**: 10.1109/TIP.2015.2475625
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1404.3606v2)
- **Published**: 2014-04-14 15:02:17+00:00
- **Updated**: 2014-08-28 15:20:44+00:00
- **Authors**: Tsung-Han Chan, Kui Jia, Shenghua Gao, Jiwen Lu, Zinan Zeng, Yi Ma
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we propose a very simple deep learning network for image classification which comprises only the very basic data processing components: cascaded principal component analysis (PCA), binary hashing, and block-wise histograms. In the proposed architecture, PCA is employed to learn multistage filter banks. It is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus named as a PCA network (PCANet) and can be designed and learned extremely easily and efficiently. For comparison and better understanding, we also introduce and study two simple variations to the PCANet, namely the RandNet and LDANet. They share the same topology of PCANet but their cascaded filters are either selected randomly or learned from LDA. We have tested these basic networks extensively on many benchmark visual datasets for different tasks, such as LFW for face verification, MultiPIE, Extended Yale B, AR, FERET datasets for face recognition, as well as MNIST for hand-written digits recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state of the art features, either prefixed, highly hand-crafted or carefully learned (by DNNs). Even more surprisingly, it sets new records for many classification tasks in Extended Yale B, AR, FERET datasets, and MNIST variations. Additional experiments on other public datasets also demonstrate the potential of the PCANet serving as a simple but highly competitive baseline for texture classification and object recognition.



