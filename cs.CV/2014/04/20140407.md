# Arxiv Papers in cs.CV on 2014-04-07
### Icon Based Information Retrieval and Disease Identification in Agriculture
- **Arxiv ID**: http://arxiv.org/abs/1404.1664v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, cs.CY, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1404.1664v1)
- **Published**: 2014-04-07 06:20:53+00:00
- **Updated**: 2014-04-07 06:20:53+00:00
- **Authors**: Namita Mittal, Basant Agarwal, Ajay Gupta, Hemant Madhur
- **Comment**: Iconic Interface, Image Processing, Pattern Recognition, Data Mining,
  Information Retrieval
- **Journal**: International Journal of Advanced Studies in Computer Science &
  Engineering IJASCSE, Volume 3, Issue 3, 2014
- **Summary**: Recent developments in the ICT industry in past few decades has enabled the quick and easy access to the information available on the internet. But, digital literacy is the pre-requisite for its use. The main purpose of this paper is to provide an interface for digitally illiterate users, especially farmers to efficiently and effectively retrieve information through Internet. In addition, to enable the farmers to identify the disease in their crop, its cause and symptoms using digital image processing and pattern recognition instantly without waiting for an expert to visit the farms and identify the disease.



### Pseudo-Zernike Based Multi-Pass Automatic Target Recognition From Multi-Channel SAR
- **Arxiv ID**: http://arxiv.org/abs/1404.1682v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.1682v3)
- **Published**: 2014-04-07 08:00:59+00:00
- **Updated**: 2014-08-06 08:13:26+00:00
- **Authors**: Carmine Clemente, Luca Pallotta, Ian Proudler, Antonio De Maio, John J. Soraghan, Alfonso Farina
- **Comment**: The paper has been withdrawn due to conceptual errors in the
  performance analysis and to the fact that a substantial restructuring of the
  paper is required
- **Journal**: None
- **Summary**: The capability to exploit multiple sources of information is of fundamental importance in a battlefield scenario. Information obtained from different sources, and separated in space and time, provide the opportunity to exploit diversities in order to mitigate uncertainty. For the specific challenge of Automatic Target Recognition (ATR) from radar platforms, both channel (e.g. polarization) and spatial diversity can provide useful information for such a specific and critical task. In this paper the use of pseudo-Zernike moments applied to multi-channel multi-pass data is presented exploiting diversities and invariant properties leading to high confidence ATR, small computational complexity and data transfer requirements. The effectiveness of the proposed approach, in different configurations and data source availability is demonstrated using real data.



### Neural Codes for Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1404.1777v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.1777v2)
- **Published**: 2014-04-07 13:08:08+00:00
- **Updated**: 2014-07-07 07:51:04+00:00
- **Authors**: Artem Babenko, Anton Slesarev, Alexandr Chigorin, Victor Lempitsky
- **Comment**: to appear at ECCV 2014
- **Journal**: None
- **Summary**: It has been shown that the activations invoked by an image within the top layers of a large convolutional neural network provide a high-level descriptor of the visual content of the image. In this paper, we investigate the use of such descriptors (neural codes) within the image retrieval application. In the experiments with several standard retrieval benchmarks, we establish that neural codes perform competitively even when the convolutional neural network has been trained for an unrelated classification task (e.g.\ Image-Net). We also evaluate the improvement in the retrieval performance of neural codes, when the network is retrained on a dataset of images that are similar to images encountered at test time.   We further evaluate the performance of the compressed neural codes and show that a simple PCA compression provides very good short codes that give state-of-the-art accuracy on a number of datasets. In general, neural codes turn out to be much more resilient to such compression in comparison other state-of-the-art descriptors. Finally, we show that discriminative dimensionality reduction trained on a dataset of pairs of matched photographs improves the performance of PCA-compressed neural codes even further. Overall, our quantitative experiments demonstrate the promise of neural codes as visual descriptors for image retrieval.



### Improving Bilayer Product Quantization for Billion-Scale Approximate Nearest Neighbors in High Dimensions
- **Arxiv ID**: http://arxiv.org/abs/1404.1831v1
- **DOI**: None
- **Categories**: **cs.CV**, H.3.3
- **Links**: [PDF](http://arxiv.org/pdf/1404.1831v1)
- **Published**: 2014-04-07 16:08:13+00:00
- **Updated**: 2014-04-07 16:08:13+00:00
- **Authors**: Artem Babenko, Victor Lempitsky
- **Comment**: None
- **Journal**: None
- **Summary**: The top-performing systems for billion-scale high-dimensional approximate nearest neighbor (ANN) search are all based on two-layer architectures that include an indexing structure and a compressed datapoints layer. An indexing structure is crucial as it allows to avoid exhaustive search, while the lossy data compression is needed to fit the dataset into RAM. Several of the most successful systems use product quantization (PQ) for both the indexing and the dataset compression layers. These systems are however limited in the way they exploit the interaction of product quantization processes that happen at different stages of these systems.   Here we introduce and evaluate two approximate nearest neighbor search systems that both exploit the synergy of product quantization processes in a more efficient way. The first system, called Fast Bilayer Product Quantization (FBPQ), speeds up the runtime of the baseline system (Multi-D-ADC) by several times, while achieving the same accuracy. The second system, Hierarchical Bilayer Product Quantization (HBPQ) provides a significantly better recall for the same runtime at a cost of small memory footprint increase. For the BIGANN dataset of billion SIFT descriptors, the 10% increase in Recall@1 and the 17% increase in Recall@10 is observed.



### DenseNet: Implementing Efficient ConvNet Descriptor Pyramids
- **Arxiv ID**: http://arxiv.org/abs/1404.1869v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.1869v1)
- **Published**: 2014-04-07 18:08:56+00:00
- **Updated**: 2014-04-07 18:08:56+00:00
- **Authors**: Forrest Iandola, Matt Moskewicz, Sergey Karayev, Ross Girshick, Trevor Darrell, Kurt Keutzer
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) can provide accurate object classification. They can be extended to perform object detection by iterating over dense or selected proposed object regions. However, the runtime of such detectors scales as the total number and/or area of regions to examine per image, and training such detectors may be prohibitively slow. However, for some CNN classifier topologies, it is possible to share significant work among overlapping regions to be classified. This paper presents DenseNet, an open source system that computes dense, multiscale features from the convolutional layers of a CNN based object classifier. Future work will involve training efficient object detectors with DenseNet feature descriptors.



