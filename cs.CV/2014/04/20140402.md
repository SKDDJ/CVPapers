# Arxiv Papers in cs.CV on 2014-04-02
### Theory and Application of Shapelets to the Analysis of Surface Self-assembly Imaging
- **Arxiv ID**: http://arxiv.org/abs/1404.0437v1
- **DOI**: 10.1103/PhysRevE.00.003300
- **Categories**: **cs.CV**, physics.data-an
- **Links**: [PDF](http://arxiv.org/pdf/1404.0437v1)
- **Published**: 2014-04-02 03:01:39+00:00
- **Updated**: 2014-04-02 03:01:39+00:00
- **Authors**: Robert Suderman, Daniel Lizotte, Nasser Mohieddin Abukhdeir
- **Comment**: 11 pages, 8 figures, submitted to the Journal of Computational
  Physics
- **Journal**: None
- **Summary**: A method for quantitative analysis of local pattern strength and defects in surface self-assembly imaging is presented and applied to images of stripe and hexagonal ordered domains. The presented method uses "shapelet" functions which were originally developed for quantitative analysis of images of galaxies ($\propto 10^{20}\mathrm{m}$). In this work, they are used instead to quantify the presence of translational order in surface self-assembled films ($\propto 10^{-9}\mathrm{m}$) through reformulation into "steerable" filters. The resulting method is both computationally efficient (with respect to the number of filter evaluations), robust to variation in pattern feature shape, and, unlike previous approaches, is applicable to a wide variety of pattern types. An application of the method is presented which uses a nearest-neighbour analysis to distinguish between uniform (defect-free) and non-uniform (strained, defect-containing) regions within imaged self-assembled domains, both with striped and hexagonal patterns.



### Thoughts on a Recursive Classifier Graph: a Multiclass Network for Deep Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1404.2903v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1404.2903v1)
- **Published**: 2014-04-02 11:38:35+00:00
- **Updated**: 2014-04-02 11:38:35+00:00
- **Authors**: Marius Leordeanu, Rahul Sukthankar
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a general multi-class visual recognition model, termed the Classifier Graph, which aims to generalize and integrate ideas from many of today's successful hierarchical recognition approaches. Our graph-based model has the advantage of enabling rich interactions between classes from different levels of interpretation and abstraction. The proposed multi-class system is efficiently learned using step by step updates. The structure consists of simple logistic linear layers with inputs from features that are automatically selected from a large pool. Each newly learned classifier becomes a potential new feature. Thus, our feature pool can consist both of initial manually designed features as well as learned classifiers from previous steps (graph nodes), each copied many times at different scales and locations. In this manner we can learn and grow both a deep, complex graph of classifiers and a rich pool of features at different levels of abstraction and interpretation. Our proposed graph of classifiers becomes a multi-class system with a recursive structure, suitable for deep detection and recognition of several classes simultaneously.



### A Comparative Study of Modern Inference Techniques for Structured Discrete Energy Minimization Problems
- **Arxiv ID**: http://arxiv.org/abs/1404.0533v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.0533v1)
- **Published**: 2014-04-02 12:27:27+00:00
- **Updated**: 2014-04-02 12:27:27+00:00
- **Authors**: Jörg H. Kappes, Bjoern Andres, Fred A. Hamprecht, Christoph Schnörr, Sebastian Nowozin, Dhruv Batra, Sungwoong Kim, Bernhard X. Kausler, Thorben Kröger, Jan Lellmann, Nikos Komodakis, Bogdan Savchynskyy, Carsten Rother
- **Comment**: None
- **Journal**: None
- **Summary**: Szeliski et al. published an influential study in 2006 on energy minimization methods for Markov Random Fields (MRF). This study provided valuable insights in choosing the best optimization technique for certain classes of problems. While these insights remain generally useful today, the phenomenal success of random field models means that the kinds of inference problems that have to be solved changed significantly. Specifically, the models today often include higher order interactions, flexible connectivity structures, large la\-bel-spaces of different cardinalities, or learned energy tables. To reflect these changes, we provide a modernized and enlarged study. We present an empirical comparison of 32 state-of-the-art optimization techniques on a corpus of 2,453 energy minimization instances from diverse applications in computer vision. To ensure reproducibility, we evaluate all methods in the OpenGM 2 framework and report extensive results regarding runtime and solution quality. Key insights from our study agree with the results of Szeliski et al. for the types of models they studied. However, on new and challenging types of models our findings disagree and suggest that polyhedral methods and integer programming solvers are competitive in terms of runtime and solution quality over a large range of model types.



### MBIS: Multivariate Bayesian Image Segmentation Tool
- **Arxiv ID**: http://arxiv.org/abs/1404.0600v2
- **DOI**: 10.1016/j.cmpb.2014.03.003
- **Categories**: **cs.CV**, 62P10, 62F15
- **Links**: [PDF](http://arxiv.org/pdf/1404.0600v2)
- **Published**: 2014-04-02 16:10:39+00:00
- **Updated**: 2014-04-07 11:12:12+00:00
- **Authors**: Oscar Esteban, Gert Wollny, Subrahmanyam Gorthi, Maria-J. Ledesma-Carbayo, Jean-Philippe Thiran, Andres Santos, Meritxell Bach-Cuadra
- **Comment**: None
- **Journal**: Comput. Meth. Prog. Bio. 115(2):76-94 (2014)
- **Summary**: We present MBIS (Multivariate Bayesian Image Segmentation tool), a clustering tool based on the mixture of multivariate normal distributions model. MBIS supports multi-channel bias field correction based on a B-spline model. A second methodological novelty is the inclusion of graph-cuts optimization for the stationary anisotropic hidden Markov random field model. Along with MBIS, we release an evaluation framework that contains three different experiments on multi-site data. We first validate the accuracy of segmentation and the estimated bias field for each channel. MBIS outperforms a widely used segmentation tool in a cross-comparison evaluation. The second experiment demonstrates the robustness of results on atlas-free segmentation of two image sets from scan-rescan protocols on 21 healthy subjects. Multivariate segmentation is more replicable than the monospectral counterpart on T1-weighted images. Finally, we provide a third experiment to illustrate how MBIS can be used in a large-scale study of tissue volume change with increasing age in 584 healthy subjects. This last result is meaningful as multivariate segmentation performs robustly without the need for prior knowledge



### Extraction of Projection Profile, Run-Histogram and Entropy Features Straight from Run-Length Compressed Text-Documents
- **Arxiv ID**: http://arxiv.org/abs/1404.0627v1
- **DOI**: 10.1109/ACPR.2013.147
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1404.0627v1)
- **Published**: 2014-04-02 17:34:13+00:00
- **Updated**: 2014-04-02 17:34:13+00:00
- **Authors**: Mohammed Javed, P. Nagabhushan, B. B. Chaudhuri
- **Comment**: Published by IEEE in Proceedings of ACPR-2013. arXiv admin note: text
  overlap with arXiv:1403.7783
- **Journal**: 2013 Second IAPR Asian Conference on Pattern Recognition, Pages
  813-817
- **Summary**: Document Image Analysis, like any Digital Image Analysis requires identification and extraction of proper features, which are generally extracted from uncompressed images, though in reality images are made available in compressed form for the reasons such as transmission and storage efficiency. However, this implies that the compressed image should be decompressed, which indents additional computing resources. This limitation induces the motivation to research in extracting features directly from the compressed image. In this research, we propose to extract essential features such as projection profile, run-histogram and entropy for text document analysis directly from run-length compressed text-documents. The experimentation illustrates that features are extracted directly from the compressed image without going through the stage of decompression, because of which the computing time is reduced. The feature values so extracted are exactly identical to those extracted from uncompressed images.



### Exploiting Linear Structure Within Convolutional Networks for Efficient Evaluation
- **Arxiv ID**: http://arxiv.org/abs/1404.0736v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1404.0736v2)
- **Published**: 2014-04-02 23:31:12+00:00
- **Updated**: 2014-06-09 15:53:55+00:00
- **Authors**: Emily Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, Rob Fergus
- **Comment**: None
- **Journal**: None
- **Summary**: We present techniques for speeding up the test-time evaluation of large convolutional networks, designed for object recognition tasks. These models deliver impressive accuracy but each image evaluation requires millions of floating point operations, making their deployment on smartphones and Internet-scale clusters problematic. The computation is dominated by the convolution operations in the lower layers of the model. We exploit the linear structure present within the convolutional filters to derive approximations that significantly reduce the required computation. Using large state-of-the-art models, we demonstrate we demonstrate speedups of convolutional layers on both CPU and GPU by a factor of 2x, while keeping the accuracy within 1% of the original model.



