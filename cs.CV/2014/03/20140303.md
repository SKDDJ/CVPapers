# Arxiv Papers in cs.CV on 2014-03-03
### Bayes Merging of Multiple Vocabularies for Scalable Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1403.0284v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.0284v2)
- **Published**: 2014-03-03 00:51:29+00:00
- **Updated**: 2014-04-13 10:14:54+00:00
- **Authors**: Liang Zheng, Shengjin Wang, Wengang Zhou, Qi Tian
- **Comment**: 8 pages, 7 figures, 6 tables, accepted to CVPR 2014
- **Journal**: None
- **Summary**: The Bag-of-Words (BoW) representation is well applied to recent state-of-the-art image retrieval works. Typically, multiple vocabularies are generated to correct quantization artifacts and improve recall. However, this routine is corrupted by vocabulary correlation, i.e., overlapping among different vocabularies. Vocabulary correlation leads to an over-counting of the indexed features in the overlapped area, or the intersection set, thus compromising the retrieval accuracy. In order to address the correlation problem while preserve the benefit of high recall, this paper proposes a Bayes merging approach to down-weight the indexed features in the intersection set. Through explicitly modeling the correlation problem in a probabilistic view, a joint similarity on both image- and feature-level is estimated for the indexed features in the intersection set.   We evaluate our method through extensive experiments on three benchmark datasets. Albeit simple, Bayes merging can be well applied in various merging tasks, and consistently improves the baselines on multi-vocabulary merging. Moreover, Bayes merging is efficient in terms of both time and memory cost, and yields competitive performance compared with the state-of-the-art methods.



### Multiview Hessian regularized logistic regression for action recognition
- **Arxiv ID**: http://arxiv.org/abs/1403.0829v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1403.0829v1)
- **Published**: 2014-03-03 01:11:40+00:00
- **Updated**: 2014-03-03 01:11:40+00:00
- **Authors**: W. Liu, H. Liu, D. Tao, Y. Wang, Ke Lu
- **Comment**: 13 pages,2 figures, submitted to signal processing
- **Journal**: None
- **Summary**: With the rapid development of social media sharing, people often need to manage the growing volume of multimedia data such as large scale video classification and annotation, especially to organize those videos containing human activities. Recently, manifold regularized semi-supervised learning (SSL), which explores the intrinsic data probability distribution and then improves the generalization ability with only a small number of labeled data, has emerged as a promising paradigm for semiautomatic video classification. In addition, human action videos often have multi-modal content and different representations. To tackle the above problems, in this paper we propose multiview Hessian regularized logistic regression (mHLR) for human action recognition. Compared with existing work, the advantages of mHLR lie in three folds: (1) mHLR combines multiple Hessian regularization, each of which obtained from a particular representation of instance, to leverage the exploring of local geometry; (2) mHLR naturally handle multi-view instances with multiple representations; (3) mHLR employs a smooth loss function and then can be effectively optimized. We carefully conduct extensive experiments on the unstructured social activity attribute (USAA) dataset and the experimental results demonstrate the effectiveness of the proposed multiview Hessian regularized logistic regression for human action recognition.



### Object Tracking via Non-Euclidean Geometry: A Grassmann Approach
- **Arxiv ID**: http://arxiv.org/abs/1403.0309v1
- **DOI**: 10.1109/WACV.2014.6836008
- **Categories**: **cs.CV**, math.MG, stat.ML, I.2.10; I.4.6; I.4.7; I.4.8; I.5.1; I.5.4; G.3
- **Links**: [PDF](http://arxiv.org/pdf/1403.0309v1)
- **Published**: 2014-03-03 04:46:44+00:00
- **Updated**: 2014-03-03 04:46:44+00:00
- **Authors**: Sareh Shirazi, Mehrtash T. Harandi, Brian C. Lovell, Conrad Sanderson
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2014
- **Journal**: None
- **Summary**: A robust visual tracking system requires an object appearance model that is able to handle occlusion, pose, and illumination variations in the video stream. This can be difficult to accomplish when the model is trained using only a single image. In this paper, we first propose a tracking approach based on affine subspaces (constructed from several images) which are able to accommodate the abovementioned variations. We use affine subspaces not only to represent the object, but also the candidate areas that the object may occupy. We furthermore propose a novel approach to measure affine subspace-to-subspace distance via the use of non-Euclidean geometry of Grassmann manifolds. The tracking problem is then considered as an inference task in a Markov Chain Monte Carlo framework via particle filtering. Quantitative evaluation on challenging video sequences indicates that the proposed approach obtains considerably better performance than several recent state-of-the-art methods such as Tracking-Learning-Detection and MILtrack.



### Summarisation of Short-Term and Long-Term Videos using Texture and Colour
- **Arxiv ID**: http://arxiv.org/abs/1403.0315v1
- **DOI**: 10.1109/WACV.2014.6836025
- **Categories**: **cs.CV**, stat.AP, I.4.6; I.4.7; I.4.9; I.5.4; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1403.0315v1)
- **Published**: 2014-03-03 05:19:10+00:00
- **Updated**: 2014-03-03 05:19:10+00:00
- **Authors**: Johanna Carvajal, Chris McCool, Conrad Sanderson
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2014
- **Journal**: None
- **Summary**: We present a novel approach to video summarisation that makes use of a Bag-of-visual-Textures (BoT) approach. Two systems are proposed, one based solely on the BoT approach and another which exploits both colour information and BoT features. On 50 short-term videos from the Open Video Project we show that our BoT and fusion systems both achieve state-of-the-art performance, obtaining an average F-measure of 0.83 and 0.86 respectively, a relative improvement of 9% and 13% when compared to the previous state-of-the-art. When applied to a new underwater surveillance dataset containing 33 long-term videos, the proposed system reduces the amount of footage by a factor of 27, with only minor degradation in the information content. This order of magnitude reduction in video data represents significant savings in terms of time and potential labour cost when manually reviewing such footage.



### Cross-Scale Cost Aggregation for Stereo Matching
- **Arxiv ID**: http://arxiv.org/abs/1403.0316v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.0316v1)
- **Published**: 2014-03-03 05:20:28+00:00
- **Updated**: 2014-03-03 05:20:28+00:00
- **Authors**: Kang Zhang, Yuqiang Fang, Dongbo Min, Lifeng Sun, Shiqiang Yang. Shuicheng Yan, Qi Tian
- **Comment**: To Appear in 2013 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR). 2014 (poster, 29.88%)
- **Journal**: None
- **Summary**: Human beings process stereoscopic correspondence across multiple scales. However, this bio-inspiration is ignored by state-of-the-art cost aggregation methods for dense stereo correspondence. In this paper, a generic cross-scale cost aggregation framework is proposed to allow multi-scale interaction in cost aggregation. We firstly reformulate cost aggregation from a unified optimization perspective and show that different cost aggregation methods essentially differ in the choices of similarity kernels. Then, an inter-scale regularizer is introduced into optimization and solving this new optimization problem leads to the proposed framework. Since the regularization term is independent of the similarity kernel, various cost aggregation methods can be integrated into the proposed general framework. We show that the cross-scale framework is important as it effectively and efficiently expands state-of-the-art cost aggregation methods and leads to significant improvements, when evaluated on Middlebury, KITTI and New Tsukuba datasets.



### Matching Image Sets via Adaptive Multi Convex Hull
- **Arxiv ID**: http://arxiv.org/abs/1403.0320v1
- **DOI**: 10.1109/WACV.2014.6835985
- **Categories**: **cs.CV**, stat.ML, I.5; I.5.1; I.5.4; G.3
- **Links**: [PDF](http://arxiv.org/pdf/1403.0320v1)
- **Published**: 2014-03-03 06:19:45+00:00
- **Updated**: 2014-03-03 06:19:45+00:00
- **Authors**: Shaokang Chen, Arnold Wiliem, Conrad Sanderson, Brian C. Lovell
- **Comment**: IEEE Winter Conference on Applications of Computer Vision (WACV),
  2014
- **Journal**: None
- **Summary**: Traditional nearest points methods use all the samples in an image set to construct a single convex or affine hull model for classification. However, strong artificial features and noisy data may be generated from combinations of training samples when significant intra-class variations and/or noise occur in the image set. Existing multi-model approaches extract local models by clustering each image set individually only once, with fixed clusters used for matching with various image sets. This may not be optimal for discrimination, as undesirable environmental conditions (eg. illumination and pose variations) may result in the two closest clusters representing different characteristics of an object (eg. frontal face being compared to non-frontal face). To address the above problem, we propose a novel approach to enhance nearest points based methods by integrating affine/convex hull classification with an adapted multi-model approach. We first extract multiple local convex hulls from a query image set via maximum margin clustering to diminish the artificial variations and constrain the noise in local convex hulls. We then propose adaptive reference clustering (ARC) to constrain the clustering of each gallery image set by forcing the clusters to have resemblance to the clusters in the query image set. By applying ARC, noisy clusters in the query set can be discarded. Experiments on Honda, MoBo and ETH-80 datasets show that the proposed method outperforms single model approaches and other recent techniques, such as Sparse Approximated Nearest Points, Mutual Subspace Method and Manifold Discriminant Analysis.



### Face Recognition Methods & Applications
- **Arxiv ID**: http://arxiv.org/abs/1403.0485v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.0485v1)
- **Published**: 2014-03-03 16:56:53+00:00
- **Updated**: 2014-03-03 16:56:53+00:00
- **Authors**: Divyarajsinh N. Parmar, Brijesh B. Mehta
- **Comment**: 3 pages, 1 figure
- **Journal**: International Journal of Computer Technology & Applications, Vol 4
  (1), pp. 84-86, Jan-Feb 2013
- **Summary**: Face recognition presents a challenging problem in the field of image analysis and computer vision. The security of information is becoming very significant and difficult. Security cameras are presently common in airports, Offices, University, ATM, Bank and in any locations with a security system. Face recognition is a biometric system used to identify or verify a person from a digital image. Face Recognition system is used in security. Face recognition system should be able to automatically detect a face in an image. This involves extracts its features and then recognize it, regardless of lighting, expression, illumination, ageing, transformations (translate, rotate and scale image) and pose, which is a difficult task. This paper contains three sections. The first section describes the common methods like holistic matching method, feature extraction method and hybrid methods. The second section describes applications with examples and finally third section describes the future research directions of face recognition.



