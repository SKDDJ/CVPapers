# Arxiv Papers in cs.CV on 2014-03-12
### Learning Deep Face Representation
- **Arxiv ID**: http://arxiv.org/abs/1403.2802v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1403.2802v1)
- **Published**: 2014-03-12 03:47:18+00:00
- **Updated**: 2014-03-12 03:47:18+00:00
- **Authors**: Haoqiang Fan, Zhimin Cao, Yuning Jiang, Qi Yin, Chinchilla Doudou
- **Comment**: None
- **Journal**: None
- **Summary**: Face representation is a crucial step of face recognition systems. An optimal face representation should be discriminative, robust, compact, and very easy-to-implement. While numerous hand-crafted and learning-based representations have been proposed, considerable room for improvement is still present. In this paper, we present a very easy-to-implement deep learning framework for face representation. Our method bases on a new structure of deep network (called Pyramid CNN). The proposed Pyramid CNN adopts a greedy-filter-and-down-sample operation, which enables the training procedure to be very fast and computation-efficient. In addition, the structure of Pyramid CNN can naturally incorporate feature sharing across multi-scale face representations, increasing the discriminative ability of resulting representation. Our basic network is capable of achieving high recognition accuracy ($85.8\%$ on LFW benchmark) with only 8 dimension representation. When extended to feature-sharing Pyramid CNN, our system achieves the state-of-the-art performance ($97.3\%$) on LFW benchmark. We also introduce a new benchmark of realistic face images on social network and validate our proposed representation has a good ability of generalization.



### Shape-Based Plagiarism Detection for Flowchart Figures in Texts
- **Arxiv ID**: http://arxiv.org/abs/1403.2871v1
- **DOI**: 10.5121/ijcsit.2014.6108
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1403.2871v1)
- **Published**: 2014-03-12 10:21:25+00:00
- **Updated**: 2014-03-12 10:21:25+00:00
- **Authors**: Senosy Arrish, Fadhil Noer Afif, Ahmadu Maidorawa, Naomie Salim
- **Comment**: 12 pages
- **Journal**: International Journal of Computer Science & Information Technology
  (IJCSIT) Vol 6, No 1, February 2014
- **Summary**: Plagiarism detection is well known phenomenon in the academic arena. Copying other people is considered as serious offence that needs to be checked. There are many plagiarism detection systems such as turn-it-in that has been developed to provide this checks. Most, if not all, discard the figures and charts before checking for plagiarism. Discarding the figures and charts results in look holes that people can take advantage. That means people can plagiarized figures and charts easily without the current plagiarism systems detecting it. There are very few papers which talks about flowcharts plagiarism detection. Therefore, there is a need to develop a system that will detect plagiarism in figures and charts. This paper presents a method for detecting flow chart figure plagiarism based on shape-based image processing and multimedia retrieval. The method managed to retrieve flowcharts with ranked similarity according to different matching sets.



### Indoor 3D Video Monitoring Using Multiple Kinect Depth-Cameras
- **Arxiv ID**: http://arxiv.org/abs/1403.2895v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.2895v1)
- **Published**: 2014-03-12 12:01:24+00:00
- **Updated**: 2014-03-12 12:01:24+00:00
- **Authors**: M. Martínez-Zarzuela, M. Pedraza-Hueso, F. J. Díaz-Pernas, D. González-Ortega, M. Antón-Rodríguez
- **Comment**: None
- **Journal**: International Journal of Multimedia & Its Applications 6(2014)
- **Summary**: This article describes the design and development of a system for remote indoor 3D monitoring using an undetermined number of Microsoft(R) Kinect sensors. In the proposed client-server system, the Kinect cameras can be connected to different computers, addressing this way the hardware limitation of one sensor per USB controller. The reason behind this limitation is the high bandwidth needed by the sensor, which becomes also an issue for the distributed system TCP/IP communications. Since traffic volume is too high, 3D data has to be compressed before it can be sent over the network. The solution consists in selfcoding the Kinect data into RGB images and then using a standard multimedia codec to compress color maps. Information from different sources is collected into a central client computer, where point clouds are transformed to reconstruct the scene in 3D. An algorithm is proposed to merge the skeletons detected locally by each Kinect conveniently, so that monitoring of people is robust to self and inter-user occlusions. Final skeletons are labeled and trajectories of every joint can be saved for event reconstruction or further analysis.



### 3D Well-composed Polyhedral Complexes
- **Arxiv ID**: http://arxiv.org/abs/1403.2980v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.2980v1)
- **Published**: 2014-03-12 15:44:17+00:00
- **Updated**: 2014-03-12 15:44:17+00:00
- **Authors**: Rocio Gonzalez-Diaz, Maria-Jose Jimenez, Belen Medrano
- **Comment**: None
- **Journal**: None
- **Summary**: A binary three-dimensional (3D) image $I$ is well-composed if the boundary surface of its continuous analog is a 2D manifold. Since 3D images are not often well-composed, there are several voxel-based methods ("repairing" algorithms) for turning them into well-composed ones but these methods either do not guarantee the topological equivalence between the original image and its corresponding well-composed one or involve sub-sampling the whole image.   In this paper, we present a method to locally "repair" the cubical complex $Q(I)$ (embedded in $\mathbb{R}^3$) associated to $I$ to obtain a polyhedral complex $P(I)$ homotopy equivalent to $Q(I)$ such that the boundary of every connected component of $P(I)$ is a 2D manifold. The reparation is performed via a new codification system for $P(I)$ under the form of a 3D grayscale image that allows an efficient access to cells and their faces.



### Image reconstruction from limited range projections using orthogonal moments
- **Arxiv ID**: http://arxiv.org/abs/1403.3021v1
- **DOI**: 10.1016/j.patcog.2006.05.035
- **Categories**: **cs.CV**, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1403.3021v1)
- **Published**: 2014-03-12 16:44:20+00:00
- **Updated**: 2014-03-12 16:44:20+00:00
- **Authors**: Huazhong Shu, Jian Zhou, Guo-Niu Han, Limin M. Luo, Jean-Louis Coatrieux
- **Comment**: None
- **Journal**: Pattern Recognition 40, 2 (2007) 670-680
- **Summary**: A set of orthonormal polynomials is proposed for image reconstruction from projection data. The relationship between the projection moments and image moments is discussed in detail, and some interesting properties are demonstrated. Simulation results are provided to validate the method and to compare its performance with previous works.



### Efficient Legendre moment computation for grey level images
- **Arxiv ID**: http://arxiv.org/abs/1403.3022v1
- **DOI**: 10.1016/j.patcog.2005.08.008
- **Categories**: **cs.CV**, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1403.3022v1)
- **Published**: 2014-03-12 16:44:47+00:00
- **Updated**: 2014-03-12 16:44:47+00:00
- **Authors**: Guanyu Yang, Huazhong Shu, Christine Toumoulin, Guo-Niu Han, Limin M. Luo
- **Comment**: None
- **Journal**: Pattern Recognition 39, 1 (2006) 74-80
- **Summary**: Legendre orthogonal moments have been widely used in the field of image analysis. Because their computation by a direct method is very time expensive, recent efforts have been devoted to the reduction of computational complexity. Nevertheless, the existing algorithms are mainly focused on binary images. We propose here a new fast method for computing the Legendre moments, which is not only suitable for binary images but also for grey levels. We first set up the recurrence formula of one-dimensional (1D) Legendre moments by using the recursive property of Legendre polynomials. As a result, the 1D Legendre moments of order p, Lp = Lp(0), can be expressed as a linear combination of Lp-1(1) and Lp-2(0). Based on this relationship, the 1D Legendre moments Lp(0) is thus obtained from the array of L1(a) and L0(a) where a is an integer number less than p. To further decrease the computation complexity, an algorithm, in which no multiplication is required, is used to compute these quantities. The method is then extended to the calculation of the two-dimensional Legendre moments Lpq. We show that the proposed method is more efficient than the direct method.



### Evaluation of Image Segmentation and Filtering With ANN in the Papaya Leaf
- **Arxiv ID**: http://arxiv.org/abs/1403.3057v1
- **DOI**: 10.5121/ijcsit.2014.6104
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1403.3057v1)
- **Published**: 2014-03-12 18:32:16+00:00
- **Updated**: 2014-03-12 18:32:16+00:00
- **Authors**: Maicon A. Sartin, Alexandre C. R. da Silva
- **Comment**: 12 pages
- **Journal**: International Journal of Computer Science & Information Technology
  (IJCSIT) Vol 6 No 1 (2014) 47-58
- **Summary**: Precision agriculture is area with lack of cheap technology. The refinement of the production system brings large advantages to the producer and the use of images makes the monitoring a more cheap methodology. Macronutrients monitoring can to determine the health and vulnerability of the plant in specific stages. In this paper is analyzed the method based on computational intelligence to work with image segmentation in the identification of symptoms of plant nutrient deficiency. Artificial neural networks are evaluated for image segmentation and filtering, several variations of parameters and insertion impulsive noise were evaluated too. Satisfactory results are achieved with artificial neural for segmentation same with high noise levels.



### Parallel WiSARD object tracker: a ram-based tracking system
- **Arxiv ID**: http://arxiv.org/abs/1403.3118v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.3118v1)
- **Published**: 2014-03-12 21:23:52+00:00
- **Updated**: 2014-03-12 21:23:52+00:00
- **Authors**: Rodrigo da Silva Moreira, Nelson Francisco Favilla Ebecken
- **Comment**: 15 pages, 7 figures
- **Journal**: Computer Science & Engineering: An International Journal (CSEIJ),
  Vol. 4, No. 1, February 2014
- **Summary**: This paper proposes the Parallel WiSARD Object Tracker (PWOT), a new object tracker based on the WiSARD weightless neural network that is robust against quantization errors. Object tracking in video is an important and challenging task in many applications. Difficulties can arise due to weather conditions, target trajectory and appearance, occlusions, lighting conditions and noise. Tracking is a high-level application and requires the object location frame by frame in real time. This paper proposes a fast hybrid image segmentation (threshold and edge detection) in YcbCr color model and a parallel RAM based discriminator that improves efficiency when quantization errors occur. The original WiSARD training algorithm was changed to allow the tracking.



