# Arxiv Papers in cs.CV on 2014-03-26
### Image Retargeting by Content-Aware Synthesis
- **Arxiv ID**: http://arxiv.org/abs/1403.6566v2
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1403.6566v2)
- **Published**: 2014-03-26 03:29:25+00:00
- **Updated**: 2014-08-21 06:16:01+00:00
- **Authors**: Weiming Dong, Fuzhang Wu, Yan Kong, Xing Mei, Tong-Yee Lee, Xiaopeng Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Real-world images usually contain vivid contents and rich textural details, which will complicate the manipulation on them. In this paper, we design a new framework based on content-aware synthesis to enhance content-aware image retargeting. By detecting the textural regions in an image, the textural image content can be synthesized rather than simply distorted or cropped. This method enables the manipulation of textural & non-textural regions with different strategy since they have different natures. We propose to retarget the textural regions by content-aware synthesis and non-textural regions by fast multi-operators. To achieve practical retargeting applications for general images, we develop an automatic and fast texture detection method that can detect multiple disjoint textural regions. We adjust the saliency of the image according to the features of the textural regions. To validate the proposed method, comparisons with state-of-the-art image targeting techniques and a user study were conducted. Convincing visual results are shown to demonstrate the effectiveness of the proposed method.



### QCMC: Quasi-conformal Parameterizations for Multiply-connected domains
- **Arxiv ID**: http://arxiv.org/abs/1403.6614v1
- **DOI**: None
- **Categories**: **cs.CG**, cs.CV, math.DG
- **Links**: [PDF](http://arxiv.org/pdf/1403.6614v1)
- **Published**: 2014-03-26 10:21:03+00:00
- **Updated**: 2014-03-26 10:21:03+00:00
- **Authors**: Kin Tat Ho, Lok Ming Lui
- **Comment**: 26 pages, 23 figures, submitted. arXiv admin note: text overlap with
  arXiv:1402.6908, arXiv:1307.2679 by other authors
- **Journal**: None
- **Summary**: This paper presents a method to compute the {\it quasi-conformal parameterization} (QCMC) for a multiply-connected 2D domain or surface. QCMC computes a quasi-conformal map from a multiply-connected domain $S$ onto a punctured disk $D_S$ associated with a given Beltrami differential. The Beltrami differential, which measures the conformality distortion, is a complex-valued function $\mu:S\to\mathbb{C}$ with supremum norm strictly less than 1. Every Beltrami differential gives a conformal structure of $S$. Hence, the conformal module of $D_S$, which are the radii and centers of the inner circles, can be fully determined by $\mu$, up to a M\"obius transformation. In this paper, we propose an iterative algorithm to simultaneously search for the conformal module and the optimal quasi-conformal parameterization. The key idea is to minimize the Beltrami energy subject to the boundary constraints. The optimal solution is our desired quasi-conformal parameterization onto a punctured disk. The parameterization of the multiply-connected domain simplifies numerical computations and has important applications in various fields, such as in computer graphics and vision. Experiments have been carried out on synthetic data together with real multiply-connected Riemann surfaces. Results show that our proposed method can efficiently compute quasi-conformal parameterizations of multiply-connected domains and outperforms other state-of-the-art algorithms. Applications of the proposed parameterization technique have also been explored.



### Beyond L2-Loss Functions for Learning Sparse Models
- **Arxiv ID**: http://arxiv.org/abs/1403.6706v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, math.OC, I.2.6; G.1.6
- **Links**: [PDF](http://arxiv.org/pdf/1403.6706v1)
- **Published**: 2014-03-26 15:16:56+00:00
- **Updated**: 2014-03-26 15:16:56+00:00
- **Authors**: Karthikeyan Natesan Ramamurthy, Aleksandr Y. Aravkin, Jayaraman J. Thiagarajan
- **Comment**: 10 pages, 6 figures
- **Journal**: None
- **Summary**: Incorporating sparsity priors in learning tasks can give rise to simple, and interpretable models for complex high dimensional data. Sparse models have found widespread use in structure discovery, recovering data from corruptions, and a variety of large scale unsupervised and supervised learning problems. Assuming the availability of sufficient data, these methods infer dictionaries for sparse representations by optimizing for high-fidelity reconstruction. In most scenarios, the reconstruction quality is measured using the squared Euclidean distance, and efficient algorithms have been developed for both batch and online learning cases. However, new application domains motivate looking beyond conventional loss functions. For example, robust loss functions such as $\ell_1$ and Huber are useful in learning outlier-resilient models, and the quantile loss is beneficial in discovering structures that are the representative of a particular quantile. These new applications motivate our work in generalizing sparse learning to a broad class of convex loss functions. In particular, we consider the class of piecewise linear quadratic (PLQ) cost functions that includes Huber, as well as $\ell_1$, quantile, Vapnik, hinge loss, and smoothed variants of these penalties. We propose an algorithm to learn dictionaries and obtain sparse codes when the data reconstruction fidelity is measured using any smooth PLQ cost function. We provide convergence guarantees for the proposed algorithm, and demonstrate the convergence behavior using empirical experiments. Furthermore, we present three case studies that require the use of PLQ cost functions: (i) robust image modeling, (ii) tag refinement for image annotation and retrieval and (iii) computing empirical confidence limits for subspace clustering.



### Optimized imaging using non-rigid registration
- **Arxiv ID**: http://arxiv.org/abs/1403.6774v1
- **DOI**: 10.1016/j.ultramic.2013.11.007
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.6774v1)
- **Published**: 2014-03-26 18:06:42+00:00
- **Updated**: 2014-03-26 18:06:42+00:00
- **Authors**: Benjamin Berkels, Peter Binev, Douglas A. Blom, Wolfgang Dahmen, Robert C. Sharpley, Thomas Vogt
- **Comment**: None
- **Journal**: Ultramicroscopy 13 (2014) 46-56
- **Summary**: The extraordinary improvements of modern imaging devices offer access to data with unprecedented information content. However, widely used image processing methodologies fall far short of exploiting the full breadth of information offered by numerous types of scanning probe, optical, and electron microscopies. In many applications, it is necessary to keep measurement intensities below a desired threshold. We propose a methodology for extracting an increased level of information by processing a series of data sets suffering, in particular, from high degree of spatial uncertainty caused by complex multiscale motion during the acquisition process. An important role is played by a nonrigid pixel-wise registration method that can cope with low signal-to-noise ratios. This is accompanied by formulating objective quality measures which replace human intervention and visual inspection in the processing chain. Scanning transmission electron microscopy of siliceous zeolite material exhibits the above-mentioned obstructions and therefore serves as orientation and a test of our procedures.



### KPCA Spatio-temporal trajectory point cloud classifier for recognizing human actions in a CBVR system
- **Arxiv ID**: http://arxiv.org/abs/1403.6794v1
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1403.6794v1)
- **Published**: 2014-03-26 19:10:53+00:00
- **Updated**: 2014-03-26 19:10:53+00:00
- **Authors**: Iván Gómez-Conde, David N. Olivieri
- **Comment**: None
- **Journal**: None
- **Summary**: We describe a content based video retrieval (CBVR) software system for identifying specific locations of a human action within a full length film, and retrieving similar video shots from a query. For this, we introduce the concept of a trajectory point cloud for classifying unique actions, encoded in a spatio-temporal covariant eigenspace, where each point is characterized by its spatial location, local Frenet-Serret vector basis, time averaged curvature and torsion and the mean osculating hyperplane. Since each action can be distinguished by their unique trajectories within this space, the trajectory point cloud is used to define an adaptive distance metric for classifying queries against stored actions. Depending upon the distance to other trajectories, the distance metric uses either large scale structure of the trajectory point cloud, such as the mean distance between cloud centroids or the difference in hyperplane orientation, or small structure such as the time averaged curvature and torsion, to classify individual points in a fuzzy-KNN. Our system can function in real-time and has an accuracy greater than 93% for multiple action recognition within video repositories. We demonstrate the use of our CBVR system in two situations: by locating specific frame positions of trained actions in two full featured films, and video shot retrieval from a database with a web search application.



### Fast Localization of Facial Landmark Points
- **Arxiv ID**: http://arxiv.org/abs/1403.6888v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1403.6888v2)
- **Published**: 2014-03-26 23:12:08+00:00
- **Updated**: 2015-01-20 12:19:05+00:00
- **Authors**: Nenad Markuš, Miroslav Frljak, Igor S. Pandžić, Jörgen Ahlberg, Robert Forchheimer
- **Comment**: None
- **Journal**: Proceedings of the Croatian Compter Vision Workshop, 2014
- **Summary**: Localization of salient facial landmark points, such as eye corners or the tip of the nose, is still considered a challenging computer vision problem despite recent efforts. This is especially evident in unconstrained environments, i.e., in the presence of background clutter and large head pose variations. Most methods that achieve state-of-the-art accuracy are slow, and, thus, have limited applications. We describe a method that can accurately estimate the positions of relevant facial landmarks in real-time even on hardware with limited processing power, such as mobile devices. This is achieved with a sequence of estimators based on ensembles of regression trees. The trees use simple pixel intensity comparisons in their internal nodes and this makes them able to process image regions very fast. We test the developed system on several publicly available datasets and analyse its processing speed on various devices. Experimental results show that our method has practical value.



