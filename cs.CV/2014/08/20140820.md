# Arxiv Papers in cs.CV on 2014-08-20
### Unsupervised Parallel Extraction based Texture for Efficient Image Representation
- **Arxiv ID**: http://arxiv.org/abs/1408.4504v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.4504v1)
- **Published**: 2014-08-20 01:10:44+00:00
- **Updated**: 2014-08-20 01:10:44+00:00
- **Authors**: Mohammed M. Abdelsamea
- **Comment**: arXiv admin note: substantial text overlap with arXiv:1408.4143
- **Journal**: 2011 International Conference on Signal, Image Processing and
  Applications With workshop of ICEEA 2011, IPCSIT vol.21 (2011), IACSIT Press,
  Singapore
- **Summary**: SOM is a type of unsupervised learning where the goal is to discover some underlying structure of the data. In this paper, a new extraction method based on the main idea of Concurrent Self-Organizing Maps (CSOM), representing a winner-takes-all collection of small SOM networks is proposed. Each SOM of the system is trained individually to provide best results for one class only. The experiments confirm that the proposed features based CSOM is capable to represent image content better than extracted features based on a single big SOM and these proposed features improve the final decision of the CAD. Experiments held on Mammographic Image Analysis Society (MIAS) dataset.



### Introduction to Clustering Algorithms and Applications
- **Arxiv ID**: http://arxiv.org/abs/1408.4576v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1408.4576v2)
- **Published**: 2014-08-20 09:25:18+00:00
- **Updated**: 2014-08-25 14:49:56+00:00
- **Authors**: Sibei Yang, Liangde Tao, Bingchen Gong
- **Comment**: This paper has been withdrawn by the author due to unsuitable content
- **Journal**: None
- **Summary**: Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines. Hence, researchers from different fields are actively working on the clustering problem. This paper provides an overview of the different representative clustering methods. In addition, application of clustering in different field is briefly introduced.



### Seeing through bag-of-visual-word glasses: towards understanding quantization effects in feature extraction methods
- **Arxiv ID**: http://arxiv.org/abs/1408.4692v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.4692v1)
- **Published**: 2014-08-20 15:16:10+00:00
- **Updated**: 2014-08-20 15:16:10+00:00
- **Authors**: Alexander Freytag, Johannes Rühle, Paul Bodesheim, Erik Rodner, Joachim Denzler
- **Comment**: An abstract version of this paper was accepted for the ICPR FEAST
  Workshop
- **Journal**: None
- **Summary**: Vector-quantized local features frequently used in bag-of-visual-words approaches are the backbone of popular visual recognition systems due to both their simplicity and their performance. Despite their success, bag-of-words-histograms basically contain low-level image statistics (e.g., number of edges of different orientations). The question remains how much visual information is "lost in quantization" when mapping visual features to code words? To answer this question, we present an in-depth analysis of the effect of local feature quantization on human recognition performance. Our analysis is based on recovering the visual information by inverting quantized local features and presenting these visualizations with different codebook sizes to human observers. Although feature inversion techniques are around for quite a while, to the best of our knowledge, our technique is the first visualizing especially the effect of feature quantization. Thereby, we are now able to compare single steps in common image classification pipelines to human counterparts.



### GIMP and Wavelets for Medical Image Processing: Enhancing Images of the Fundus of the Eye
- **Arxiv ID**: http://arxiv.org/abs/1408.4703v1
- **DOI**: 10.18483/ijSci.556
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.4703v1)
- **Published**: 2014-08-20 15:49:17+00:00
- **Updated**: 2014-08-20 15:49:17+00:00
- **Authors**: Amelia Carolina Sparavigna
- **Comment**: Keywords: Image processing, Retina, Retina Vessels, GIMP,
  AstroFracTool, Iris, Wavelets
- **Journal**: ijSciences, 2014, Volume 3, Issue 8, pages 35-47
- **Summary**: The visual analysis of retina and of its vascular characteristics is important in the diagnosis and monitoring of diseases of visual perception. In the related medical diagnoses, the digital processing of the fundus images is used to obtain the segmentation of retinal vessels. However, an image segmentation is often requiring methods based on peculiar or complex algorithms: in this paper we will show some alternative approaches obtained by applying freely available tools to enhance, without a specific segmentation, the images of the fundus of the eye. We will see in particular, that combining the use of GIMP, the GNU Image Manipulation Program, with the wavelet filter of Iris, a program well-known for processing astronomical images, the result is giving images which can be alternative of those obtained from segmentation.



### Bi-l0-l2-Norm Regularization for Blind Motion Deblurring
- **Arxiv ID**: http://arxiv.org/abs/1408.4712v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.4712v3)
- **Published**: 2014-08-20 16:18:13+00:00
- **Updated**: 2015-01-22 14:02:38+00:00
- **Authors**: Wen-Ze Shao, Hai-Bo Li, Michael Elad
- **Comment**: 32 pages, 16 figures
- **Journal**: None
- **Summary**: In blind motion deblurring, leading methods today tend towards highly non-convex approximations of the l0-norm, especially in the image regularization term. In this paper, we propose a simple, effective and fast approach for the estimation of the motion blur-kernel, through a bi-l0-l2-norm regularization imposed on both the intermediate sharp image and the blur-kernel. Compared with existing methods, the proposed regularization is shown to be more effective and robust, leading to a more accurate motion blur-kernel and a better final restored image. A fast numerical scheme is deployed for alternatingly computing the sharp image and the blur-kernel, by coupling the operator splitting and augmented Lagrangian methods. Experimental results on both a benchmark image dataset and real-world motion blurred images show that the proposed approach is highly competitive with state-of-the- art methods in both deblurring effectiveness and computational efficiency.



### Code Generation for High-Level Synthesis of Multiresolution Applications on FPGAs
- **Arxiv ID**: http://arxiv.org/abs/1408.4721v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.PL
- **Links**: [PDF](http://arxiv.org/pdf/1408.4721v1)
- **Published**: 2014-08-20 16:56:42+00:00
- **Updated**: 2014-08-20 16:56:42+00:00
- **Authors**: Moritz Schmid, Oliver Reiche, Christian Schmitt, Frank Hannig, Jürgen Teich
- **Comment**: Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)
- **Journal**: None
- **Summary**: Multiresolution Analysis (MRA) is a mathematical method that is based on working on a problem at different scales. One of its applications is medical imaging where processing at multiple scales, based on the concept of Gaussian and Laplacian image pyramids, is a well-known technique. It is often applied to reduce noise while preserving image detail on different levels of granularity without modifying the filter kernel. In scientific computing, multigrid methods are a popular choice, as they are asymptotically optimal solvers for elliptic Partial Differential Equations (PDEs). As such algorithms have a very high computational complexity that would overwhelm CPUs in the presence of real-time constraints, application-specific processors come into consideration for implementation. Despite of huge advancements in leveraging productivity in the respective fields, designers are still required to have detailed knowledge about coding techniques and the targeted architecture to achieve efficient solutions. Recently, the HIPAcc framework was proposed as a means for automatic code generation of image processing algorithms, based on a Domain-Specific Language (DSL). From the same code base, it is possible to generate code for efficient implementations on several accelerator technologies including different types of Graphics Processing Units (GPUs) as well as reconfigurable logic (FPGAs). In this work, we demonstrate the ability of HIPAcc to generate code for the implementation of multiresolution applications on FPGAs and embedded GPUs.



