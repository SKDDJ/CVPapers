# Arxiv Papers in cs.CV on 2014-08-16
### Motion Deblurring for Plenoptic Images
- **Arxiv ID**: http://arxiv.org/abs/1408.3686v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.3686v2)
- **Published**: 2014-08-16 00:18:50+00:00
- **Updated**: 2016-02-12 23:42:34+00:00
- **Authors**: Paramanand Chandramouli, Paolo Favaro, Daniele Perrone
- **Comment**: None
- **Journal**: None
- **Summary**: We address for the first time the issue of motion blur in light field images captured from plenoptic cameras. We propose a solution to the estimation of a sharp high resolution scene radiance given a blurry light field image, when the motion blur point spread function is unknown, i.e., the so-called blind deconvolution problem. In a plenoptic camera, the spatial sampling in each view is not only decimated but also defocused. Consequently, current blind deconvolution approaches for traditional cameras are not applicable. Due to the complexity of the imaging model, we investigate first the case of uniform (shift-invariant) blur of Lambertian objects, i.e., when objects are sufficiently far away from the camera to be approximately invariant to depth changes and their reflectance does not vary with the viewing direction. We introduce a highly parallelizable model for light field motion blur that is computationally and memory efficient. We then adapt a regularized blind deconvolution approach to our model and demonstrate its performance on both synthetic and real light field data. Our method handles practical issues in real cameras such as radial distortion correction and alignment within an energy minimization framework.



### Robust 3D face recognition in presence of pose and partial occlusions or missing parts
- **Arxiv ID**: http://arxiv.org/abs/1408.3709v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.3709v1)
- **Published**: 2014-08-16 06:43:30+00:00
- **Updated**: 2014-08-16 06:43:30+00:00
- **Authors**: Parama Bagchi, Debotosh Bhattacharjee, Mita Nasipuri
- **Comment**: the paper is of 15 pages, International Journal in Foundations of
  Computer Science & Technology (IJFCST), Vol.4, No.4, July 2014
- **Journal**: None
- **Summary**: In this paper, we propose a robust 3D face recognition system which can handle pose as well as occlusions in real world. The system at first takes as input, a 3D range image, simultaneously registers it using ICP(Iterative Closest Point) algorithm. ICP used in this work, registers facial surfaces to a common model by minimizing distances between a probe model and a gallery model. However the performance of ICP relies heavily on the initial conditions. Hence, it is necessary to provide an initial registration, which will be improved iteratively and finally converge to the best alignment possible. Once the faces are registered, the occlusions are automatically extracted by thresholding the depth map values of the 3D image. After the occluded regions are detected, restoration is done by Principal Component Analysis (PCA). The restored images, after the removal of occlusions, are then fed to the recognition system for classification purpose. Features are extracted from the reconstructed non-occluded face images in the form of face normals. The experimental results which were obtained on the occluded facial images from the Bosphorus 3D face database, illustrate that our occlusion compensation scheme has attained a recognition accuracy of 91.30%.



### A fast patch-dictionary method for whole image recovery
- **Arxiv ID**: http://arxiv.org/abs/1408.3740v1
- **DOI**: None
- **Categories**: **cs.CV**, math.OC, 94A08, 94A12
- **Links**: [PDF](http://arxiv.org/pdf/1408.3740v1)
- **Published**: 2014-08-16 15:09:32+00:00
- **Updated**: 2014-08-16 15:09:32+00:00
- **Authors**: Yangyang Xu, Wotao Yin
- **Comment**: None
- **Journal**: None
- **Summary**: Various algorithms have been proposed for dictionary learning. Among those for image processing, many use image patches to form dictionaries. This paper focuses on whole-image recovery from corrupted linear measurements. We address the open issue of representing an image by overlapping patches: the overlapping leads to an excessive number of dictionary coefficients to determine. With very few exceptions, this issue has limited the applications of image-patch methods to the local kind of tasks such as denoising, inpainting, cartoon-texture decomposition, super-resolution, and image deblurring, for which one can process a few patches at a time. Our focus is global imaging tasks such as compressive sensing and medical image recovery, where the whole image is encoded together, making it either impossible or very ineffective to update a few patches at a time.   Our strategy is to divide the sparse recovery into multiple subproblems, each of which handles a subset of non-overlapping patches, and then the results of the subproblems are averaged to yield the final recovery. This simple strategy is surprisingly effective in terms of both quality and speed. In addition, we accelerate computation of the learned dictionary by applying a recent block proximal-gradient method, which not only has a lower per-iteration complexity but also takes fewer iterations to converge, compared to the current state-of-the-art. We also establish that our algorithm globally converges to a stationary point. Numerical results on synthetic data demonstrate that our algorithm can recover a more faithful dictionary than two state-of-the-art methods.   Combining our whole-image recovery and dictionary-learning methods, we numerically simulate image inpainting, compressive sensing recovery, and deblurring. Our recovery is more faithful than those of a total variation method and a method based on overlapping patches.



### Real-time emotion recognition for gaming using deep convolutional network features
- **Arxiv ID**: http://arxiv.org/abs/1408.3750v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1408.3750v1)
- **Published**: 2014-08-16 17:11:44+00:00
- **Updated**: 2014-08-16 17:11:44+00:00
- **Authors**: SÃ©bastien Ouellet
- **Comment**: 6 pages, 8 figures, IEEE style
- **Journal**: None
- **Summary**: The goal of the present study is to explore the application of deep convolutional network features to emotion recognition. Results indicate that they perform similarly to other published models at a best recognition rate of 94.4%, and do so with a single still image rather than a video stream. An implementation of an affective feedback game is also described, where a classifier using these features tracks the facial expressions of a player in real-time.



### Highly Accurate Multispectral Palmprint Recognition Using Statistical and Wavelet Features
- **Arxiv ID**: http://arxiv.org/abs/1408.3772v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.3772v2)
- **Published**: 2014-08-16 21:02:44+00:00
- **Updated**: 2015-06-24 16:31:26+00:00
- **Authors**: Shervin Minaee, AmirAli Abdolrashidi
- **Comment**: 6 pages
- **Journal**: None
- **Summary**: Palmprint is one of the most useful physiological biometrics that can be used as a powerful means in personal recognition systems. The major features of the palmprints are palm lines, wrinkles and ridges, and many approaches use them in different ways towards solving the palmprint recognition problem. Here we have proposed to use a set of statistical and wavelet-based features; statistical to capture the general characteristics of palmprints; and wavelet-based to find those information not evident in the spatial domain. Also we use two different classification approaches, minimum distance classifier scheme and weighted majority voting algorithm, to perform palmprint matching. The proposed method is tested on a well-known palmprint dataset of 6000 samples and has shown an impressive accuracy rate of 99.65\%-100\% for most scenarios.



