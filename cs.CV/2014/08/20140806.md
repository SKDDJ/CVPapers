# Arxiv Papers in cs.CV on 2014-08-06
### Human Activity Learning and Segmentation using Partially Hidden Discriminative Models
- **Arxiv ID**: http://arxiv.org/abs/1408.3081v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1408.3081v1)
- **Published**: 2014-08-06 02:35:49+00:00
- **Updated**: 2014-08-06 02:35:49+00:00
- **Authors**: Truyen Tran, Hung Bui, Svetha Venkatesh
- **Comment**: HAREM 2005: Proceedings of the International Workshop on Human
  Activity Recognition and Modelling
- **Journal**: None
- **Summary**: Learning and understanding the typical patterns in the daily activities and routines of people from low-level sensory data is an important problem in many application domains such as building smart environments, or providing intelligent assistance. Traditional approaches to this problem typically rely on supervised learning and generative models such as the hidden Markov models and its extensions. While activity data can be readily acquired from pervasive sensors, e.g. in smart environments, providing manual labels to support supervised training is often extremely expensive. In this paper, we propose a new approach based on semi-supervised training of partially hidden discriminative models such as the conditional random field (CRF) and the maximum entropy Markov model (MEMM). We show that these models allow us to incorporate both labeled and unlabeled data for learning, and at the same time, provide us with the flexibility and accuracy of the discriminative framework. Our experimental results in the video surveillance domain illustrate that these models can perform better than their generative counterpart, the partially hidden Markov model, even when a substantial amount of labels are unavailable.



### Boosted Markov Networks for Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/1408.1167v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1408.1167v1)
- **Published**: 2014-08-06 02:45:51+00:00
- **Updated**: 2014-08-06 02:45:51+00:00
- **Authors**: Truyen Tran, Hung Bui, Svetha Venkatesh
- **Comment**: International Conference on Intelligent Sensors, Sensor Networks and
  Information Processing (ISSNIP)
- **Journal**: None
- **Summary**: We explore a framework called boosted Markov networks to combine the learning capacity of boosting and the rich modeling semantics of Markov networks and applying the framework for video-based activity recognition. Importantly, we extend the framework to incorporate hidden variables. We show how the framework can be applied for both model learning and feature selection. We demonstrate that boosted Markov networks with hidden variables perform comparably with the standard maximum likelihood estimation. However, our framework is able to learn sparse models, and therefore can provide computational savings when the learned models are used for classification.



### Scalable Greedy Algorithms for Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/1408.1292v4
- **DOI**: 10.1016/j.cviu.2016.09.003
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1408.1292v4)
- **Published**: 2014-08-06 14:27:57+00:00
- **Updated**: 2016-06-18 00:17:50+00:00
- **Authors**: Ilja Kuzborskij, Francesco Orabona, Barbara Caputo
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we consider the binary transfer learning problem, focusing on how to select and combine sources from a large pool to yield a good performance on a target task. Constraining our scenario to real world, we do not assume the direct access to the source data, but rather we employ the source hypotheses trained from them. We propose an efficient algorithm that selects relevant source hypotheses and feature dimensions simultaneously, building on the literature on the best subset selection problem. Our algorithm achieves state-of-the-art results on three computer vision datasets, substantially outperforming both transfer learning and popular feature selection baselines in a small-sample setting. We also present a randomized variant that achieves the same results with the computational cost independent from the number of source hypotheses and feature dimensions. Also, we theoretically prove that, under reasonable assumptions on the source hypotheses, our algorithm can learn effectively from few examples.



### A Fast and Accurate Unconstrained Face Detector
- **Arxiv ID**: http://arxiv.org/abs/1408.1656v3
- **DOI**: 10.1109/TPAMI.2015.2448075
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.1656v3)
- **Published**: 2014-08-06 15:17:33+00:00
- **Updated**: 2015-09-07 08:17:34+00:00
- **Authors**: Shengcai Liao, Anil K. Jain, Stan Z. Li
- **Comment**: This paper has been accepted by TPAMI. The source code is available
  on the project page
  http://www.cbsr.ia.ac.cn/users/scliao/projects/npdface/index.html
- **Journal**: None
- **Summary**: We propose a method to address challenges in unconstrained face detection, such as arbitrary pose variations and occlusions. First, a new image feature called Normalized Pixel Difference (NPD) is proposed. NPD feature is computed as the difference to sum ratio between two pixel values, inspired by the Weber Fraction in experimental psychology. The new feature is scale invariant, bounded, and is able to reconstruct the original image. Second, we propose a deep quadratic tree to learn the optimal subset of NPD features and their combinations, so that complex face manifolds can be partitioned by the learned rules. This way, only a single soft-cascade classifier is needed to handle unconstrained face detection. Furthermore, we show that the NPD features can be efficiently obtained from a look up table, and the detection template can be easily scaled, making the proposed face detector very fast. Experimental results on three public face datasets (FDDB, GENKI, and CMU-MIT) show that the proposed method achieves state-of-the-art performance in detecting unconstrained faces with arbitrary pose variations and occlusions in cluttered scenes.



