# Arxiv Papers in cs.CV on 2014-08-18
### Learning Deep Representation for Face Alignment with Auxiliary Attributes
- **Arxiv ID**: http://arxiv.org/abs/1408.3967v4
- **DOI**: 10.1109/TPAMI.2015.2469286
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1408.3967v4)
- **Published**: 2014-08-18 10:34:29+00:00
- **Updated**: 2015-08-11 10:08:40+00:00
- **Authors**: Zhanpeng Zhang, Ping Luo, Chen Change Loy, Xiaoou Tang
- **Comment**: to be published in the IEEE Transactions on Pattern Analysis and
  Machine Intelligence (TPAMI)
- **Journal**: None
- **Summary**: In this study, we show that landmark detection or face alignment task is not a single and independent problem. Instead, its robustness can be greatly improved with auxiliary information. Specifically, we jointly optimize landmark detection together with the recognition of heterogeneous but subtly correlated facial attributes, such as gender, expression, and appearance attributes. This is non-trivial since different attribute inference tasks have different learning difficulties and convergence rates. To address this problem, we formulate a novel tasks-constrained deep model, which not only learns the inter-task correlation but also employs dynamic task coefficients to facilitate the optimization convergence when learning multiple complex tasks. Extensive evaluations show that the proposed task-constrained learning (i) outperforms existing face alignment methods, especially in dealing with faces with severe occlusion and pose variation, and (ii) reduces model complexity drastically compared to the state-of-the-art methods based on cascaded deep model.



### Offline Signature-Based Fuzzy Vault (OSFV: Review and New Results
- **Arxiv ID**: http://arxiv.org/abs/1408.3985v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/1408.3985v1)
- **Published**: 2014-08-18 11:54:48+00:00
- **Updated**: 2014-08-18 11:54:48+00:00
- **Authors**: George S. Eskander, Robert Sabourin, Eric Granger
- **Comment**: This paper has been submitted to The 2014 IEEE Symposium on
  Computational Intelligence in Biometrics and Identity Management (CIBIM)
- **Journal**: None
- **Summary**: An offline signature-based fuzzy vault (OSFV) is a bio-cryptographic implementation that uses handwritten signature images as biometrics instead of traditional passwords to secure private cryptographic keys. Having a reliable OSFV implementation is the first step towards automating financial and legal authentication processes, as it provides greater security of confidential documents by means of the embedded handwritten signatures. The authors have recently proposed the first OSFV implementation which is reviewed in this paper. In this system, a machine learning approach based on the dissimilarity representation concept is employed to select a reliable feature representation adapted for the fuzzy vault scheme. Some variants of this system are proposed for enhanced accuracy and security. In particular, a new method that adapts user key size is presented. Performance of proposed methods are compared using the Brazilian PUCPR and GPDS signature databases and results indicate that the key-size adaptation method achieves a good compromise between security and accuracy. While average system entropy is increased from 45-bits to about 51-bits, the AER (average error rate) is decreased by about 21%.



### The Filament Sensor for Near Real-Time Detection of Cytoskeletal Fiber Structures
- **Arxiv ID**: http://arxiv.org/abs/1408.4002v3
- **DOI**: 10.1371/journal.pone.0126346
- **Categories**: **cs.CV**, I.4.3; I.4.6
- **Links**: [PDF](http://arxiv.org/pdf/1408.4002v3)
- **Published**: 2014-08-18 13:06:03+00:00
- **Updated**: 2015-07-14 08:40:32+00:00
- **Authors**: Benjamin Eltzner, Carina Wollnik, Carsten Gottschlich, Stephan Huckemann, Florian Rehfeldt
- **Comment**: 32 pages, 21 figures
- **Journal**: PLoS ONE 10(5): e0126346, May 2015
- **Summary**: A reliable extraction of filament data from microscopic images is of high interest in the analysis of acto-myosin structures as early morphological markers in mechanically guided differentiation of human mesenchymal stem cells and the understanding of the underlying fiber arrangement processes. In this paper, we propose the filament sensor (FS), a fast and robust processing sequence which detects and records location, orientation, length and width for each single filament of an image, and thus allows for the above described analysis. The extraction of these features has previously not been possible with existing methods. We evaluate the performance of the proposed FS in terms of accuracy and speed in comparison to three existing methods with respect to their limited output. Further, we provide a benchmark dataset of real cell images along with filaments manually marked by a human expert as well as simulated benchmark images. The FS clearly outperforms existing methods in terms of computational runtime and filament extraction accuracy. The implementation of the FS and the benchmark database are available as open source.



