# Arxiv Papers in cs.CV on 2014-08-15
### Parallel software implementation of recursive multidimensional digital filters for point-target detection in cluttered infrared scenes
- **Arxiv ID**: http://arxiv.org/abs/1408.3526v4
- **DOI**: 10.1109/ICASSP.2015.7178137
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.3526v4)
- **Published**: 2014-08-15 13:06:35+00:00
- **Updated**: 2015-08-21 23:57:03+00:00
- **Authors**: Hugh L. Kennedy
- **Comment**: To appear in Proc. 2015 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP). Added header and DOI
- **Journal**: None
- **Summary**: A technique for the enhancement of point targets in clutter is described. The local 3-D spectrum at each pixel is estimated recursively. An optical flow-field for the textured background is then generated using the 3-D autocorrelation function and the local velocity estimates are used to apply high-pass velocity-selective spatiotemporal filters, with finite impulse responses (FIRs), to subtract the background clutter signal, leaving the foreground target signal, plus noise. Parallel software implementations using a multicore central processing unit (CPU) and a graphical processing unit (GPU) are investigated.



### Turkish Presidential Elections TRT Publicity Speech Facial Expression Analysis
- **Arxiv ID**: http://arxiv.org/abs/1408.3573v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.3573v1)
- **Published**: 2014-08-15 15:51:29+00:00
- **Updated**: 2014-08-15 15:51:29+00:00
- **Authors**: H. Emrah Tasli, Paul Ivan
- **Comment**: 2 pages 3 figures
- **Journal**: None
- **Summary**: In this paper, facial expressions of the three Turkish presidential candidates Demirtas, Erdogan and Ihsanoglu (in alphabetical order) are analyzed during the publicity speeches featured at TRT (Turkish Radio and Television) on 03.08.2014. FaceReader is used for the analysis where 3D modeling of the face is achieved using the active appearance models (AAM). Over 500 landmark points are tracked and analyzed for obtaining the facial expressions during the whole speech. All source videos and the data are publicly available for research purposes.



