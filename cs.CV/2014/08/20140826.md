# Arxiv Papers in cs.CV on 2014-08-26
### $\ell_1$-K-SVD: A Robust Dictionary Learning Algorithm With Simultaneous Update
- **Arxiv ID**: http://arxiv.org/abs/1410.0311v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1410.0311v2)
- **Published**: 2014-08-26 07:23:04+00:00
- **Updated**: 2015-03-03 04:38:37+00:00
- **Authors**: Subhadip Mukherjee, Rupam Basu, Chandra Sekhar Seelamantula
- **Comment**: None
- **Journal**: None
- **Summary**: We develop a dictionary learning algorithm by minimizing the $\ell_1$ distortion metric on the data term, which is known to be robust for non-Gaussian noise contamination. The proposed algorithm exploits the idea of iterative minimization of weighted $\ell_2$ error. We refer to this algorithm as $\ell_1$-K-SVD, where the dictionary atoms and the corresponding sparse coefficients are simultaneously updated to minimize the $\ell_1$ objective, resulting in noise-robustness. We demonstrate through experiments that the $\ell_1$-K-SVD algorithm results in higher atom recovery rate compared with the K-SVD and the robust dictionary learning (RDL) algorithm proposed by Lu et al., both in Gaussian and non-Gaussian noise conditions. We also show that, for fixed values of sparsity, number of dictionary atoms, and data-dimension, the $\ell_1$-K-SVD algorithm outperforms the K-SVD and RDL algorithms when the training set available is small. We apply the proposed algorithm for denoising natural images corrupted by additive Gaussian and Laplacian noise. The images denoised using $\ell_1$-K-SVD are observed to have slightly higher peak signal-to-noise ratio (PSNR) over K-SVD for Laplacian noise, but the improvement in structural similarity index (SSIM) is significant (approximately $0.1$) for lower values of input PSNR, indicating the efficacy of the $\ell_1$ metric.



### Sparse Graph-based Transduction for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1408.6257v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1408.6257v2)
- **Published**: 2014-08-26 20:53:44+00:00
- **Updated**: 2014-12-12 09:53:36+00:00
- **Authors**: Sheng Huang, Dan Yang, Jia Zhou, Luwen Huangfu, Xiaohong Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Motivated by the remarkable successes of Graph-based Transduction (GT) and Sparse Representation (SR), we present a novel Classifier named Sparse Graph-based Classifier (SGC) for image classification. In SGC, SR is leveraged to measure the correlation (similarity) of each two samples and a graph is constructed for encoding these correlations. Then the Laplacian eigenmapping is adopted for deriving the graph Laplacian of the graph. Finally, SGC can be obtained by plugging the graph Laplacian into the conventional GT framework. In the image classification procedure, SGC utilizes the correlations, which are encoded in the learned graph Laplacian, to infer the labels of unlabeled images. SGC inherits the merits of both GT and SR. Compared to SR, SGC improves the robustness and the discriminating power of GT. Compared to GT, SGC sufficiently exploits the whole data. Therefore it alleviates the undercomplete dictionary issue suffered by SR. Four popular image databases are employed for evaluation. The results demonstrate that SGC can achieve a promising performance in comparison with the state-of-the-art classifiers, particularly in the small training sample size case and the noisy sample case.



