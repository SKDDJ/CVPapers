# Arxiv Papers in cs.CV on 2014-05-16
### Optimized Cartesian $K$-Means
- **Arxiv ID**: http://arxiv.org/abs/1405.4054v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1405.4054v1)
- **Published**: 2014-05-16 03:09:01+00:00
- **Updated**: 2014-05-16 03:09:01+00:00
- **Authors**: Jianfeng Wang, Jingdong Wang, Jingkuan Song, Xin-Shun Xu, Heng Tao Shen, Shipeng Li
- **Comment**: to appear in IEEE TKDE, accepted in Apr. 2014
- **Journal**: None
- **Summary**: Product quantization-based approaches are effective to encode high-dimensional data points for approximate nearest neighbor search. The space is decomposed into a Cartesian product of low-dimensional subspaces, each of which generates a sub codebook. Data points are encoded as compact binary codes using these sub codebooks, and the distance between two data points can be approximated efficiently from their codes by the precomputed lookup tables. Traditionally, to encode a subvector of a data point in a subspace, only one sub codeword in the corresponding sub codebook is selected, which may impose strict restrictions on the search accuracy. In this paper, we propose a novel approach, named Optimized Cartesian $K$-Means (OCKM), to better encode the data points for more accurate approximate nearest neighbor search. In OCKM, multiple sub codewords are used to encode the subvector of a data point in a subspace. Each sub codeword stems from different sub codebooks in each subspace, which are optimally generated with regards to the minimization of the distortion errors. The high-dimensional data point is then encoded as the concatenation of the indices of multiple sub codewords from all the subspaces. This can provide more flexibility and lower distortion errors than traditional methods. Experimental results on the standard real-life datasets demonstrate the superiority over state-of-the-art approaches for approximate nearest neighbor search.



### Computer Vision Approach for Low Cost, High Precision Measurement of Grapevine Trunk Diameter in Outdoor Conditions
- **Arxiv ID**: http://arxiv.org/abs/1406.4845v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1406.4845v2)
- **Published**: 2014-05-16 18:44:58+00:00
- **Updated**: 2016-05-09 21:10:16+00:00
- **Authors**: Diego Sebastián Pérez, Facundo Bromberg, Francisco Gonzalez Antivilo
- **Comment**: 10 pages, 5 figures
- **Journal**: None
- **Summary**: Trunk diameter is a variable of agricultural interest, used mainly in the prediction of fruit trees production. It is correlated with leaf area and biomass of trees, and consequently gives a good estimate of the potential production of the plants. This work presents a low cost, high precision method for the measurement of trunk diameter of grapevines based on Computer Vision techniques. Several methods based on Computer Vision and other techniques are introduced in the literature. These methods present different advantages for crop management: they are amenable to be operated by unknowledgeable personnel, with lower operational costs; they result in lower stress levels to knowledgeable personnel, avoiding the deterioration of the measurement quality over time; and they make the measurement process amenable to be embedded in larger autonomous systems, allowing more measurements to be taken with equivalent costs. To date, all existing autonomous methods are either of low precision, or have a prohibitive cost for massive agricultural adoption, leaving the manual Vernier caliper or tape measure as the only choice in most situations. In this work we present a semi-autonomous measurement method that is susceptible to be fully automated, cost effective for mass adoption, and its precision is competitive (with slight improvements) over the caliper manual method.



### Coarse-to-Fine Classification via Parametric and Nonparametric Models for Computer-Aided Diagnosis
- **Arxiv ID**: http://arxiv.org/abs/1405.4308v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1405.4308v1)
- **Published**: 2014-05-16 21:13:01+00:00
- **Updated**: 2014-05-16 21:13:01+00:00
- **Authors**: Meizhu Liu, Le Lu, Xiaojing Ye, Shipeng Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Classification is one of the core problems in Computer-Aided Diagnosis (CAD), targeting for early cancer detection using 3D medical imaging interpretation. High detection sensitivity with desirably low false positive (FP) rate is critical for a CAD system to be accepted as a valuable or even indispensable tool in radiologists' workflow. Given various spurious imagery noises which cause observation uncertainties, this remains a very challenging task. In this paper, we propose a novel, two-tiered coarse-to-fine (CTF) classification cascade framework to tackle this problem. We first obtain classification-critical data samples (e.g., samples on the decision boundary) extracted from the holistic data distributions using a robust parametric model (e.g., \cite{Raykar08}); then we build a graph-embedding based nonparametric classifier on sampled data, which can more accurately preserve or formulate the complex classification boundary. These two steps can also be considered as effective "sample pruning" and "feature pursuing + $k$NN/template matching", respectively. Our approach is validated comprehensively in colorectal polyp detection and lung nodule detection CAD systems, as the top two deadly cancers, using hospital scale, multi-site clinical datasets. The results show that our method achieves overall better classification/detection performance than existing state-of-the-art algorithms using single-layer classifiers, such as the support vector machine variants \cite{Wang08}, boosting \cite{Slabaugh10}, logistic regression \cite{Ravesteijn10}, relevance vector machine \cite{Raykar08}, $k$-nearest neighbor \cite{Murphy09} or spectral projections on graph \cite{Cai08}.



