# Arxiv Papers in cs.CV on 2014-05-14
### Group-based Sparse Representation for Image Restoration
- **Arxiv ID**: http://arxiv.org/abs/1405.3351v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1405.3351v1)
- **Published**: 2014-05-14 03:15:59+00:00
- **Updated**: 2014-05-14 03:15:59+00:00
- **Authors**: Jian Zhang, Debin Zhao, Wen Gao
- **Comment**: 34 pages, 6 tables, 19 figures, to be published in IEEE Transactions
  on Image Processing; Project, Code and High resolution PDF version can be
  found: http://idm.pku.edu.cn/staff/zhangjian/. arXiv admin note: text overlap
  with arXiv:1404.7566
- **Journal**: None
- **Summary**: Traditional patch-based sparse representation modeling of natural images usually suffer from two problems. First, it has to solve a large-scale optimization problem with high computational complexity in dictionary learning. Second, each patch is considered independently in dictionary learning and sparse coding, which ignores the relationship among patches, resulting in inaccurate sparse coding coefficients. In this paper, instead of using patch as the basic unit of sparse representation, we exploit the concept of group as the basic unit of sparse representation, which is composed of nonlocal patches with similar structures, and establish a novel sparse representation modeling of natural images, called group-based sparse representation (GSR). The proposed GSR is able to sparsely represent natural images in the domain of group, which enforces the intrinsic local sparsity and nonlocal self-similarity of images simultaneously in a unified framework. Moreover, an effective self-adaptive dictionary learning method for each group with low complexity is designed, rather than dictionary learning from natural images. To make GSR tractable and robust, a split Bregman based technique is developed to solve the proposed GSR-driven minimization problem for image restoration efficiently. Extensive experiments on image inpainting, image deblurring and image compressive sensing recovery manifest that the proposed GSR modeling outperforms many current state-of-the-art schemes in both PSNR and visual perception.



### Newton-Type Iterative Solver for Multiple View $L2$ Triangulation
- **Arxiv ID**: http://arxiv.org/abs/1405.3352v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1405.3352v2)
- **Published**: 2014-05-14 03:35:56+00:00
- **Updated**: 2014-06-30 23:39:32+00:00
- **Authors**: F. Lu, Z. Chen
- **Comment**: 15 pages, 1 figure, 4 tables, 30 references, C++ source codes
- **Journal**: None
- **Summary**: In this note, we show that the L2 optimal solutions to most real multiple view L2 triangulation problems can be efficiently obtained by two-stage Newton-like iterative methods, while the difficulty of such problems mainly lies in how to verify the L2 optimality. Such a working two-stage bundle adjustment approach features: first, the algorithm is initialized by symmedian point triangulation, a multiple-view generalization of the mid-point method; second, a symbolic-numeric method is employed to compute derivatives accurately; third, globalizing strategy such as line search or trust region is smoothly applied to the underlying iteration which assures algorithm robustness in general cases.   Numerical comparison with tfml method shows that the local minimizers obtained by the two-stage iterative bundle adjustment approach proposed here are also the L2 optimal solutions to all the calibrated data sets available online by the Oxford visual geometry group. Extensive numerical experiments indicate the bundle adjustment approach solves more than 99% the real triangulation problems optimally. An IEEE 754 double precision C++ implementation shows that it takes only about 0.205 second tocompute allthe 4983 points in the Oxford dinosaur data setvia Gauss-Newton iteration hybrid with a line search strategy on a computer with a 3.4GHz Intel i7 CPU.



### Active Mining of Parallel Video Streams
- **Arxiv ID**: http://arxiv.org/abs/1405.3382v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1405.3382v1)
- **Published**: 2014-05-14 07:00:38+00:00
- **Updated**: 2014-05-14 07:00:38+00:00
- **Authors**: Samaneh Khoshrou, Jaime S. Cardoso, Luis F. Teixeira
- **Comment**: None
- **Journal**: None
- **Summary**: The practicality of a video surveillance system is adversely limited by the amount of queries that can be placed on human resources and their vigilance in response. To transcend this limitation, a major effort under way is to include software that (fully or at least semi) automatically mines video footage, reducing the burden imposed to the system. Herein, we propose a semi-supervised incremental learning framework for evolving visual streams in order to develop a robust and flexible track classification system. Our proposed method learns from consecutive batches by updating an ensemble in each time. It tries to strike a balance between performance of the system and amount of data which needs to be labelled. As no restriction is considered, the system can address many practical problems in an evolving multi-camera scenario, such as concept drift, class evolution and various length of video streams which have not been addressed before. Experiments were performed on synthetic as well as real-world visual data in non-stationary environments, showing high accuracy with fairly little human collaboration.



### Return of the Devil in the Details: Delving Deep into Convolutional Nets
- **Arxiv ID**: http://arxiv.org/abs/1405.3531v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1405.3531v4)
- **Published**: 2014-05-14 15:19:22+00:00
- **Updated**: 2014-11-05 08:34:48+00:00
- **Authors**: Ken Chatfield, Karen Simonyan, Andrea Vedaldi, Andrew Zisserman
- **Comment**: Published in proceedings of BMVC 2014
- **Journal**: None
- **Summary**: The latest generation of Convolutional Neural Networks (CNN) have achieved impressive results in challenging benchmarks on image recognition and object detection, significantly raising the interest of the community in these methods. Nevertheless, it is still unclear how different CNN methods compare with each other and with previous state-of-the-art shallow representations such as the Bag-of-Visual-Words and the Improved Fisher Vector. This paper conducts a rigorous evaluation of these new techniques, exploring different deep architectures and comparing them on a common ground, identifying and disclosing important implementation details. We identify several useful properties of CNN-based representations, including the fact that the dimensionality of the CNN output layer can be reduced significantly without having an adverse effect on performance. We also identify aspects of deep and shallow methods that can be successfully shared. In particular, we show that the data augmentation techniques commonly applied to CNN-based methods can also be applied to shallow methods, and result in an analogous performance boost. Source code and models to reproduce the experiments in the paper is made publicly available.



