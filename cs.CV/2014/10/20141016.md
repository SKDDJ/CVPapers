# Arxiv Papers in cs.CV on 2014-10-16
### On the Covariance of ICP-based Scan-matching Techniques
- **Arxiv ID**: http://arxiv.org/abs/1410.7632v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO, cs.SY
- **Links**: [PDF](http://arxiv.org/pdf/1410.7632v3)
- **Published**: 2014-10-16 00:14:05+00:00
- **Updated**: 2016-03-16 23:41:00+00:00
- **Authors**: Silvère Bonnabel, Martin Barczyk, François Goulette
- **Comment**: Accepted at 2016 American Control Conference
- **Journal**: None
- **Summary**: This paper considers the problem of estimating the covariance of roto-translations computed by the Iterative Closest Point (ICP) algorithm. The problem is relevant for localization of mobile robots and vehicles equipped with depth-sensing cameras (e.g., Kinect) or Lidar (e.g., Velodyne). The closed-form formulas for covariance proposed in previous literature generally build upon the fact that the solution to ICP is obtained by minimizing a linear least-squares problem. In this paper, we show this approach needs caution because the rematching step of the algorithm is not explicitly accounted for, and applying it to the point-to-point version of ICP leads to completely erroneous covariances. We then provide a formal mathematical proof why the approach is valid in the point-to-plane version of ICP, which validates the intuition and experimental results of practitioners.



### Super-resolution method using sparse regularization for point-spread function recovery
- **Arxiv ID**: http://arxiv.org/abs/1410.7679v1
- **DOI**: 10.1051/0004-6361/201424167
- **Categories**: **cs.CV**, astro-ph.IM
- **Links**: [PDF](http://arxiv.org/pdf/1410.7679v1)
- **Published**: 2014-10-16 06:49:00+00:00
- **Updated**: 2014-10-16 06:49:00+00:00
- **Authors**: Fred Maurice Ngolè Mboula, Jean-Luc Starck, Samuel Ronayette, Koryo Okumura, Jérôme Amiaux
- **Comment**: None
- **Journal**: None
- **Summary**: In large-scale spatial surveys, such as the forthcoming ESA Euclid mission, images may be undersampled due to the optical sensors sizes. Therefore, one may consider using a super-resolution (SR) method to recover aliased frequencies, prior to further analysis. This is particularly relevant for point-source images, which provide direct measurements of the instrument point-spread function (PSF). We introduce SPRITE, SParse Recovery of InsTrumental rEsponse, which is an SR algorithm using a sparse analysis prior. We show that such a prior provides significant improvements over existing methods, especially on low SNR PSFs.



### Implicit segmentation of Kannada characters in offline handwriting recognition using hidden Markov models
- **Arxiv ID**: http://arxiv.org/abs/1410.4341v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1410.4341v1)
- **Published**: 2014-10-16 09:09:45+00:00
- **Updated**: 2014-10-16 09:09:45+00:00
- **Authors**: Manasij Venkatesh, Vikas Majjagi, Deepu Vijayasenan
- **Comment**: None
- **Journal**: None
- **Summary**: We describe a method for classification of handwritten Kannada characters using Hidden Markov Models (HMMs). Kannada script is agglutinative, where simple shapes are concatenated horizontally to form a character. This results in a large number of characters making the task of classification difficult. Character segmentation plays a significant role in reducing the number of classes. Explicit segmentation techniques suffer when overlapping shapes are present, which is common in the case of handwritten text. We use HMMs to take advantage of the agglutinative nature of Kannada script, which allows us to perform implicit segmentation of characters along with recognition. All the experiments are performed on the Chars74k dataset that consists of 657 handwritten characters collected across multiple users. Gradient-based features are extracted from individual characters and are used to train character HMMs. The use of implicit segmentation technique at the character level resulted in an improvement of around 10%. This system also outperformed an existing system tested on the same dataset by around 16%. Analysis based on learning curves showed that increasing the training data could result in better accuracy. Accordingly, we collected additional data and obtained an improvement of 4% with 6 additional samples.



### The HAWKwood Database
- **Arxiv ID**: http://arxiv.org/abs/1410.4393v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4393v2)
- **Published**: 2014-10-16 12:25:50+00:00
- **Updated**: 2014-11-11 07:07:30+00:00
- **Authors**: Christopher Herbon
- **Comment**: None
- **Journal**: None
- **Summary**: We present a database consisting of wood pile images, which can be used as a benchmark to evaluate the performance of wood pile detection and surveying algorithms. We distinguish six database cate- gories which can be used for different types of algorithms. Images of real and synthetic scenes are provided, which consist of 7655 images divided into 354 data sets. Depending on the category the data sets either include ground truth data or forestry specific measurements with which algorithms may be compared.



### Improve CAPTCHA's Security Using Gaussian Blur Filter
- **Arxiv ID**: http://arxiv.org/abs/1410.4441v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4441v1)
- **Published**: 2014-10-16 14:17:21+00:00
- **Updated**: 2014-10-16 14:17:21+00:00
- **Authors**: Ariyan Zarei
- **Comment**: None
- **Journal**: None
- **Summary**: Providing security for webservers against unwanted and automated registrations has become a big concern. To prevent these kinds of false registrations many websites use CAPTCHAs. Among all kinds of CAPTCHAs OCR-Based or visual CAPTCHAs are very common. Actually visual CAPTCHA is an image containing a sequence of characters. So far most of visual CAPTCHAs, in order to resist against OCR programs, use some common implementations such as wrapping the characters, random placement and rotations of characters, etc. In this paper we applied Gaussian Blur filter, which is an image transformation, to visual CAPTCHAs to reduce their readability by OCR programs. We concluded that this technique made CAPTCHAs almost unreadable for OCR programs but, their readability by human users still remained high.



### MKL-RT: Multiple Kernel Learning for Ratio-trace Problems via Convex Optimization
- **Arxiv ID**: http://arxiv.org/abs/1410.4470v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1410.4470v2)
- **Published**: 2014-10-16 15:51:50+00:00
- **Updated**: 2014-10-17 06:12:37+00:00
- **Authors**: Raviteja Vemulapalli, Vinay Praneeth Boda, Rama Chellappa
- **Comment**: None
- **Journal**: None
- **Summary**: In the recent past, automatic selection or combination of kernels (or features) based on multiple kernel learning (MKL) approaches has been receiving significant attention from various research communities. Though MKL has been extensively studied in the context of support vector machines (SVM), it is relatively less explored for ratio-trace problems. In this paper, we show that MKL can be formulated as a convex optimization problem for a general class of ratio-trace problems that encompasses many popular algorithms used in various computer vision applications. We also provide an optimization procedure that is guaranteed to converge to the global optimum of the proposed optimization problem. We experimentally demonstrate that the proposed MKL approach, which we refer to as MKL-RT, can be successfully used to select features for discriminative dimensionality reduction and cross-modal retrieval. We also show that the proposed convex MKL-RT approach performs better than the recently proposed non-convex MKL-DR approach.



### A Gesture Recognition System for Detecting Behavioral Patterns of ADHD
- **Arxiv ID**: http://arxiv.org/abs/1410.4485v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4485v2)
- **Published**: 2014-10-16 16:25:29+00:00
- **Updated**: 2014-11-05 10:25:13+00:00
- **Authors**: Miguel Ángel Bautista, Antonio Hernández-Vela, Sergio Escalera, Laura Igual, Oriol Pujol, Josep Moya, Verónica Violant, María Teresa Anguera
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: We present an application of gesture recognition using an extension of Dynamic Time Warping (DTW) to recognize behavioural patterns of Attention Deficit Hyperactivity Disorder (ADHD). We propose an extension of DTW using one-class classifiers in order to be able to encode the variability of a gesture category, and thus, perform an alignment between a gesture sample and a gesture class. We model the set of gesture samples of a certain gesture category using either GMMs or an approximation of Convex Hulls. Thus, we add a theoretical contribution to classical warping path in DTW by including local modeling of intra-class gesture variability. This methodology is applied in a clinical context, detecting a group of ADHD behavioural patterns defined by experts in psychology/psychiatry, to provide support to clinicians in the diagnose procedure. The proposed methodology is tested on a novel multi-modal dataset (RGB plus Depth) of ADHD children recordings with behavioural patterns. We obtain satisfying results when compared to standard state-of-the-art approaches in the DTW context.



### Reconstructive Sparse Code Transfer for Contour Detection and Semantic Labeling
- **Arxiv ID**: http://arxiv.org/abs/1410.4521v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4521v1)
- **Published**: 2014-10-16 18:09:58+00:00
- **Updated**: 2014-10-16 18:09:58+00:00
- **Authors**: Michael Maire, Stella X. Yu, Pietro Perona
- **Comment**: to appear in Asian Conference on Computer Vision (ACCV), 2014
- **Journal**: None
- **Summary**: We frame the task of predicting a semantic labeling as a sparse reconstruction procedure that applies a target-specific learned transfer function to a generic deep sparse code representation of an image. This strategy partitions training into two distinct stages. First, in an unsupervised manner, we learn a set of generic dictionaries optimized for sparse coding of image patches. We train a multilayer representation via recursive sparse dictionary learning on pooled codes output by earlier layers. Second, we encode all training images with the generic dictionaries and learn a transfer function that optimizes reconstruction of patches extracted from annotated ground-truth given the sparse codes of their corresponding image patches. At test time, we encode a novel image using the generic dictionaries and then reconstruct using the transfer function. The output reconstruction is a semantic labeling of the test image.   Applying this strategy to the task of contour detection, we demonstrate performance competitive with state-of-the-art systems. Unlike almost all prior work, our approach obviates the need for any form of hand-designed features or filters. To illustrate general applicability, we also show initial results on semantic part labeling of human faces.   The effectiveness of our approach opens new avenues for research on deep sparse representations. Our classifiers utilize this representation in a novel manner. Rather than acting on nodes in the deepest layer, they attach to nodes along a slice through multiple layers of the network in order to make predictions about local patches. Our flexible combination of a generatively learned sparse representation with discriminatively trained transfer classifiers extends the notion of sparse reconstruction to encompass arbitrary semantic labeling tasks.



