# Arxiv Papers in cs.CV on 2014-10-01
### Riemannian Multi-Manifold Modeling
- **Arxiv ID**: http://arxiv.org/abs/1410.0095v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1410.0095v1)
- **Published**: 2014-10-01 02:37:12+00:00
- **Updated**: 2014-10-01 02:37:12+00:00
- **Authors**: Xu Wang, Konstantinos Slavakis, Gilad Lerman
- **Comment**: None
- **Journal**: None
- **Summary**: This paper advocates a novel framework for segmenting a dataset in a Riemannian manifold $M$ into clusters lying around low-dimensional submanifolds of $M$. Important examples of $M$, for which the proposed clustering algorithm is computationally efficient, are the sphere, the set of positive definite matrices, and the Grassmannian. The clustering problem with these examples of $M$ is already useful for numerous application domains such as action identification in video sequences, dynamic texture clustering, brain fiber segmentation in medical imaging, and clustering of deformed images. The proposed clustering algorithm constructs a data-affinity matrix by thoroughly exploiting the intrinsic geometry and then applies spectral clustering. The intrinsic local geometry is encoded by local sparse coding and more importantly by directional information of local tangent spaces and geodesics. Theoretical guarantees are established for a simplified variant of the algorithm even when the clusters intersect. To avoid complication, these guarantees assume that the underlying submanifolds are geodesic. Extensive validation on synthetic and real data demonstrates the resiliency of the proposed method against deviations from the theoretical model as well as its superior performance over state-of-the-art techniques.



### Coupling Top-down and Bottom-up Methods for 3D Human Pose and Shape Estimation from Monocular Image Sequences
- **Arxiv ID**: http://arxiv.org/abs/1410.0117v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.0117v2)
- **Published**: 2014-10-01 06:19:05+00:00
- **Updated**: 2014-10-06 05:04:16+00:00
- **Authors**: Atul Kanaujia
- **Comment**: 13 Pages, 12 Figures
- **Journal**: None
- **Summary**: Until recently Intelligence, Surveillance, and Reconnaissance (ISR) focused on acquiring behavioral information of the targets and their activities. Continuous evolution of intelligence being gathered of the human centric activities has put increased focus on the humans, especially inferring their innate characteristics - size, shapes and physiology. These bio-signatures extracted from the surveillance sensors can be used to deduce age, ethnicity, gender and actions, and further characterize human actions in unseen scenarios. However, recovery of pose and shape of humans in such monocular videos is inherently an ill-posed problem, marked by frequent depth and view based ambiguities due to self-occlusion, foreshortening and misalignment. The likelihood function often yields a highly multimodal posterior that is difficult to propagate even using the most advanced particle filtering(PF) algorithms. Motivated by the recent success of the discriminative approaches to efficiently predict 3D poses directly from the 2D images, we present several principled approaches to integrate predictive cues using learned regression models to sustain multimodality of the posterior during tracking. Additionally, these learned priors can be actively adapted to the test data using a likelihood based feedback mechanism. Estimated 3D poses are then used to fit 3D human shape model to each frame independently for inferring anthropometric bio-signatures. The proposed system is fully automated, robust to noisy test data and has ability to swiftly recover from tracking failures even after confronting with significant errors. We evaluate the system on a large number of monocular human motion sequences.



### A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input
- **Arxiv ID**: http://arxiv.org/abs/1410.0210v4
- **DOI**: None
- **Categories**: **cs.AI**, cs.CL, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1410.0210v4)
- **Published**: 2014-10-01 12:59:16+00:00
- **Updated**: 2015-05-05 17:39:10+00:00
- **Authors**: Mateusz Malinowski, Mario Fritz
- **Comment**: Published in NIPS 2014
- **Journal**: None
- **Summary**: We propose a method for automatically answering questions about images by bringing together recent advances from natural language processing and computer vision. We combine discrete reasoning with uncertain predictions by a multi-world approach that represents uncertainty about the perceived world in a bayesian framework. Our approach can handle human questions of high complexity about realistic scenes and replies with range of answer like counts, object classes, instances and lists of them. The system is directly trained from question-answer pairs. We establish a first benchmark for this task that can be seen as a modern attempt at a visual turing test.



### Pattern Encoding on the Poincare Sphere
- **Arxiv ID**: http://arxiv.org/abs/1410.0243v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.0243v1)
- **Published**: 2014-10-01 14:41:55+00:00
- **Updated**: 2014-10-01 14:41:55+00:00
- **Authors**: Aleksandra Pizurica
- **Comment**: 26 pages, 23 figures
- **Journal**: None
- **Summary**: This paper presents a convenient graphical tool for encoding visual patterns (such as image patches and image atoms) as point constellations in a space spanned by perceptual features and with a clear geometrical interpretation. General theory and a practical pattern encoding scheme are presented, inspired by encoding polarization states of a light wave on the Poincare sphere. This new pattern encoding scheme can be useful for many applications in image processing and computer vision. Here, three possible applications are illustrated, in clustering perceptually similar patterns, visualizing properties of learned dictionaries of image atoms and generating new dictionaries of image atoms from spherical codes.



### Learning to Transfer Privileged Information
- **Arxiv ID**: http://arxiv.org/abs/1410.0389v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1410.0389v1)
- **Published**: 2014-10-01 21:29:45+00:00
- **Updated**: 2014-10-01 21:29:45+00:00
- **Authors**: Viktoriia Sharmanska, Novi Quadrianto, Christoph H. Lampert
- **Comment**: 20 pages with figures
- **Journal**: None
- **Summary**: We introduce a learning framework called learning using privileged information (LUPI) to the computer vision field. We focus on the prototypical computer vision problem of teaching computers to recognize objects in images. We want the computers to be able to learn faster at the expense of providing extra information during training time. As additional information about the image data, we look at several scenarios that have been studied in computer vision before: attributes, bounding boxes and image tags. The information is privileged as it is available at training time but not at test time. We explore two maximum-margin techniques that are able to make use of this additional source of information, for binary and multiclass object classification. We interpret these methods as learning easiness and hardness of the objects in the privileged space and then transferring this knowledge to train a better classifier in the original space. We provide a thorough analysis and comparison of information transfer from privileged to the original data spaces for both LUPI methods. Our experiments show that incorporating privileged information can improve the classification accuracy. Finally, we conduct user studies to understand which samples are easy and which are hard for human learning, and explore how this information is related to easy and hard samples when learning a classifier.



