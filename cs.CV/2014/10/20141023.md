# Arxiv Papers in cs.CV on 2014-10-23
### Capturing spatial interdependence in image features: the counting grid, an epitomic representation for bags of features
- **Arxiv ID**: http://arxiv.org/abs/1410.6264v1
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1410.6264v1)
- **Published**: 2014-10-23 07:04:22+00:00
- **Updated**: 2014-10-23 07:04:22+00:00
- **Authors**: Alessandro Perina, Nebojsa Jojic
- **Comment**: The counting grid code is available at www.alessandroperina.com
- **Journal**: None
- **Summary**: In recent scene recognition research images or large image regions are often represented as disorganized "bags" of features which can then be analyzed using models originally developed to capture co-variation of word counts in text. However, image feature counts are likely to be constrained in different ways than word counts in text. For example, as a camera pans upwards from a building entrance over its first few floors and then further up into the sky Fig. 1, some feature counts in the image drop while others rise -- only to drop again giving way to features found more often at higher elevations. The space of all possible feature count combinations is constrained both by the properties of the larger scene and the size and the location of the window into it. To capture such variation, in this paper we propose the use of the counting grid model. This generative model is based on a grid of feature counts, considerably larger than any of the modeled images, and considerably smaller than the real estate needed to tile the images next to each other tightly. Each modeled image is assumed to have a representative window in the grid in which the feature counts mimic the feature distribution in the image. We provide a learning procedure that jointly maps all images in the training set to the counting grid and estimates the appropriate local counts in it. Experimentally, we demonstrate that the resulting representation captures the space of feature count combinations more accurately than the traditional models, not only when the input images come from a panning camera, but even when modeling images of different scenes from the same category.



### Canonical Polyadic Decomposition with Auxiliary Information for Brain Computer Interface
- **Arxiv ID**: http://arxiv.org/abs/1410.6313v2
- **DOI**: 10.1109/JBHI.2015.2491645
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.6313v2)
- **Published**: 2014-10-23 10:14:05+00:00
- **Updated**: 2015-11-05 14:59:37+00:00
- **Authors**: Junhua Li, Chao Li, Andrzej Cichocki
- **Comment**: None
- **Journal**: IEEE journal of biomedical and health informatics, 2015, 21(1):
  263-271
- **Summary**: Physiological signals are often organized in the form of multiple dimensions (e.g., channel, time, task, and 3D voxel), so it is better to preserve original organization structure when processing. Unlike vector-based methods that destroy data structure, Canonical Polyadic Decomposition (CPD) aims to process physiological signals in the form of multi-way array, which considers relationships between dimensions and preserves structure information contained by the physiological signal. Nowadays, CPD is utilized as an unsupervised method for feature extraction in a classification problem. After that, a classifier, such as support vector machine, is required to classify those features. In this manner, classification task is achieved in two isolated steps. We proposed supervised Canonical Polyadic Decomposition by directly incorporating auxiliary label information during decomposition, by which a classification task can be achieved without an extra step of classifier training. The proposed method merges the decomposition and classifier learning together, so it reduces procedure of classification task compared with that of respective decomposition and classification. In order to evaluate the performance of the proposed method, three different kinds of signals, synthetic signal, EEG signal, and MEG signal, were used. The results based on evaluations of synthetic and real signals demonstrated that the proposed method is effective and efficient.



### A Regularization Approach to Blind Deblurring and Denoising of QR Barcodes
- **Arxiv ID**: http://arxiv.org/abs/1410.6333v3
- **DOI**: 10.1109/TIP.2015.2432675
- **Categories**: **cs.CV**, math.NA, 68U10, 65K10
- **Links**: [PDF](http://arxiv.org/pdf/1410.6333v3)
- **Published**: 2014-10-23 12:04:31+00:00
- **Updated**: 2017-03-24 14:51:09+00:00
- **Authors**: Yves van Gennip, Prashant Athavale, Jérôme Gilles, Rustum Choksi
- **Comment**: 14 pages, 19 figures (with a total of 57 subfigures), 1 table; v3:
  previously missing reference [35] added
- **Journal**: None
- **Summary**: QR bar codes are prototypical images for which part of the image is a priori known (required patterns). Open source bar code readers, such as ZBar, are readily available. We exploit both these facts to provide and assess purely regularization-based methods for blind deblurring of QR bar codes in the presence of noise.



### Density-Based Region Search with Arbitrary Shape for Object Localization
- **Arxiv ID**: http://arxiv.org/abs/1410.6447v1
- **DOI**: 10.1049/iet-cvi.2014.0442
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.6447v1)
- **Published**: 2014-10-23 18:41:11+00:00
- **Updated**: 2014-10-23 18:41:11+00:00
- **Authors**: Ji Zhao, Deyu Meng, Jiayi Ma
- **Comment**: None
- **Journal**: None
- **Summary**: Region search is widely used for object localization. Typically, the region search methods project the score of a classifier into an image plane, and then search the region with the maximal score. The recently proposed region search methods, such as efficient subwindow search and efficient region search, %which localize objects from the score distribution on an image are much more efficient than sliding window search. However, for some classifiers and tasks, the projected scores are nearly all positive, and hence maximizing the score of a region results in localizing nearly the entire images as objects, which is meaningless.   In this paper, we observe that the large scores are mainly concentrated on or around objects. Based on this observation, we propose a method, named level set maximum-weight connected subgraph (LS-MWCS), which localizes objects with arbitrary shapes by searching regions with the densest score rather than the maximal score. The region density can be controlled by a parameter flexibly. And we prove an important property of the proposed LS-MWCS, which guarantees that the region with the densest score can be searched. Moreover, the LS-MWCS can be efficiently optimized by belief propagation. The method is evaluated on the problem of weakly-supervised object localization, and the quantitative results demonstrate the superiorities of our LS-MWCS compared to other state-of-the-art methods.



### Foreground-Background Segmentation Based on Codebook and Edge Detector
- **Arxiv ID**: http://arxiv.org/abs/1410.6472v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.6472v1)
- **Published**: 2014-10-23 19:48:11+00:00
- **Updated**: 2014-10-23 19:48:11+00:00
- **Authors**: Mikaël A. Mousse, Eugène C. Ezin, Cina Motamed
- **Comment**: to appear in the 10th International Conference on Signal Image
  Technology & Internet Based Systems, 2014
- **Journal**: None
- **Summary**: Background modeling techniques are used for moving object detection in video. Many algorithms exist in the field of object detection with different purposes. In this paper, we propose an improvement of moving object detection based on codebook segmentation. We associate the original codebook algorithm with an edge detection algorithm. Our goal is to prove the efficiency of using an edge detection algorithm with a background modeling algorithm. Throughout our study, we compared the quality of the moving object detection when codebook segmentation algorithm is associated with some standard edge detectors. In each case, we use frame-based metrics for the evaluation of the detection. The different results are presented and analyzed.



