# Arxiv Papers in cs.CV on 2014-10-17
### Learning visual biases from human imagination
- **Arxiv ID**: http://arxiv.org/abs/1410.4627v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4627v2)
- **Published**: 2014-10-17 03:47:12+00:00
- **Updated**: 2015-11-16 14:14:22+00:00
- **Authors**: Carl Vondrick, Hamed Pirsiavash, Aude Oliva, Antonio Torralba
- **Comment**: To appear at NIPS 2015
- **Journal**: None
- **Summary**: Although the human visual system can recognize many concepts under challenging conditions, it still has some biases. In this paper, we investigate whether we can extract these biases and transfer them into a machine recognition system. We introduce a novel method that, inspired by well-known tools in human psychophysics, estimates the biases that the human visual system might use for recognition, but in computer vision feature spaces. Our experiments are surprising, and suggest that classifiers from the human visual system can be transferred into a machine with some success. Since these classifiers seem to capture favorable biases in the human visual system, we further present an SVM formulation that constrains the orientation of the SVM hyperplane to agree with the bias from human visual system. Our results suggest that transferring this human bias into machines may help object recognition systems generalize across datasets and perform better when very little training data is available.



### Randomized Structural Sparsity via Constrained Block Subsampling for Improved Sensitivity of Discriminative Voxel Identification
- **Arxiv ID**: http://arxiv.org/abs/1410.4650v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML, G.3, I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1410.4650v2)
- **Published**: 2014-10-17 07:02:47+00:00
- **Updated**: 2015-06-07 05:47:29+00:00
- **Authors**: Yilun Wang, Junjie Zheng, Sheng Zhang, Xujun Duan, Huafu Chen
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we consider voxel selection for functional Magnetic Resonance Imaging (fMRI) brain data with the aim of finding a more complete set of probably correlated discriminative voxels, thus improving interpretation of the discovered potential biomarkers. The main difficulty in doing this is an extremely high dimensional voxel space and few training samples, resulting in unreliable feature selection. In order to deal with the difficulty, stability selection has received a great deal of attention lately, especially due to its finite sample control of false discoveries and transparent principle for choosing a proper amount of regularization. However, it fails to make explicit use of the correlation property or structural information of these discriminative features and leads to large false negative rates. In other words, many relevant but probably correlated discriminative voxels are missed. Thus, we propose a new variant on stability selection "randomized structural sparsity", which incorporates the idea of structural sparsity. Numerical experiments demonstrate that our method can be superior in controlling for false negatives while also keeping the control of false positives inherited from stability selection.



### KCRC-LCD: Discriminative Kernel Collaborative Representation with Locality Constrained Dictionary for Visual Categorization
- **Arxiv ID**: http://arxiv.org/abs/1410.4673v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1410.4673v1)
- **Published**: 2014-10-17 09:40:20+00:00
- **Updated**: 2014-10-17 09:40:20+00:00
- **Authors**: Weiyang Liu, Zhiding Yu, Lijia Lu, Yandong Wen, Hui Li, Yuexian Zou
- **Comment**: None
- **Journal**: None
- **Summary**: We consider the image classification problem via kernel collaborative representation classification with locality constrained dictionary (KCRC-LCD). Specifically, we propose a kernel collaborative representation classification (KCRC) approach in which kernel method is used to improve the discrimination ability of collaborative representation classification (CRC). We then measure the similarities between the query and atoms in the global dictionary in order to construct a locality constrained dictionary (LCD) for KCRC. In addition, we discuss several similarity measure approaches in LCD and further present a simple yet effective unified similarity measure whose superiority is validated in experiments. There are several appealing aspects associated with LCD. First, LCD can be nicely incorporated under the framework of KCRC. The LCD similarity measure can be kernelized under KCRC, which theoretically links CRC and LCD under the kernel method. Second, KCRC-LCD becomes more scalable to both the training set size and the feature dimension. Example shows that KCRC is able to perfectly classify data with certain distribution, while conventional CRC fails completely. Comprehensive experiments on many public datasets also show that KCRC-LCD is a robust discriminative classifier with both excellent performance and good scalability, being comparable or outperforming many other state-of-the-art approaches.



### Large Vocabulary Arabic Online Handwriting Recognition System
- **Arxiv ID**: http://arxiv.org/abs/1410.4688v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.4688v3)
- **Published**: 2014-10-17 11:09:35+00:00
- **Updated**: 2015-10-17 09:47:28+00:00
- **Authors**: Ibrahim Abdelaziz, Sherif Abdou, Hassanin Al-Barhamtoshy
- **Comment**: Preprint submitted to Pattern Analysis and Applications Journal
- **Journal**: None
- **Summary**: Arabic handwriting is a consonantal and cursive writing. The analysis of Arabic script is further complicated due to obligatory dots/strokes that are placed above or below most letters and usually written delayed in order. Due to ambiguities and diversities of writing styles, recognition systems are generally based on a set of possible words called lexicon. When the lexicon is small, recognition accuracy is more important as the recognition time is minimal. On the other hand, recognition speed as well as the accuracy are both critical when handling large lexicons. Arabic is rich in morphology and syntax which makes its lexicon large. Therefore, a practical online handwriting recognition system should be able to handle a large lexicon with reasonable performance in terms of both accuracy and time. In this paper, we introduce a fully-fledged Hidden Markov Model (HMM) based system for Arabic online handwriting recognition that provides solutions for most of the difficulties inherent in recognizing the Arabic script. A new preprocessing technique for handling the delayed strokes is introduced. We use advanced modeling techniques for building our recognition system from the training data to provide more detailed representation for the differences between the writing units, minimize the variances between writers in the training data and have a better representation for the features space. System results are enhanced using an additional post-processing step with a higher order language model and cross-word HMM models. The system performance is evaluated using two different databases covering small and large lexicons. Our system outperforms the state-of-art systems for the small lexicon database. Furthermore, it shows promising results (accuracy and time) when supporting large lexicon with the possibility for adapting the models for specific writers to get even better results.



### Bayesian estimation of the multifractality parameter for image texture using a Whittle approximation
- **Arxiv ID**: http://arxiv.org/abs/1410.4871v2
- **DOI**: 10.1109/TIP.2015.2426021
- **Categories**: **physics.data-an**, cs.CV, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/1410.4871v2)
- **Published**: 2014-10-17 21:32:28+00:00
- **Updated**: 2015-04-09 09:13:28+00:00
- **Authors**: SÃ©bastien Combrexelle, Herwig Wendt, Nicolas Dobigeon, Jean-Yves Tourneret, Steve McLaughlin, Patrice Abry
- **Comment**: None
- **Journal**: IEEE T. Image Proces., vol. 24, no. 8, pp. 2540-2551, Aug. 2015
- **Summary**: Texture characterization is a central element in many image processing applications. Multifractal analysis is a useful signal and image processing tool, yet, the accurate estimation of multifractal parameters for image texture remains a challenge. This is due in the main to the fact that current estimation procedures consist of performing linear regressions across frequency scales of the two-dimensional (2D) dyadic wavelet transform, for which only a few such scales are computable for images. The strongly non-Gaussian nature of multifractal processes, combined with their complicated dependence structure, makes it difficult to develop suitable models for parameter estimation. Here, we propose a Bayesian procedure that addresses the difficulties in the estimation of the multifractality parameter. The originality of the procedure is threefold: The construction of a generic semi-parametric statistical model for the logarithm of wavelet leaders; the formulation of Bayesian estimators that are associated with this model and the set of parameter values admitted by multifractal theory; the exploitation of a suitable Whittle approximation within the Bayesian model which enables the otherwise infeasible evaluation of the posterior distribution associated with the model. Performance is assessed numerically for several 2D multifractal processes, for several image sizes and a large range of process parameters. The procedure yields significant benefits over current benchmark estimators in terms of estimation performance and ability to discriminate between the two most commonly used classes of multifractal process models. The gains in performance are particularly pronounced for small image sizes, notably enabling for the first time the analysis of image patches as small as 64x64 pixels.



