# Arxiv Papers in cs.CV on 2014-10-24
### A Novel Visual Word Co-occurrence Model for Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1410.6532v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.6532v1)
- **Published**: 2014-10-24 01:04:37+00:00
- **Updated**: 2014-10-24 01:04:37+00:00
- **Authors**: Ziming Zhang, Yuting Chen, Venkatesh Saligrama
- **Comment**: Accepted at ECCV Workshop on Visual Surveillance and
  Re-Identification, 2014
- **Journal**: None
- **Summary**: Person re-identification aims to maintain the identity of an individual in diverse locations through different non-overlapping camera views. The problem is fundamentally challenging due to appearance variations resulting from differing poses, illumination and configurations of camera views. To deal with these difficulties, we propose a novel visual word co-occurrence model. We first map each pixel of an image to a visual word using a codebook, which is learned in an unsupervised manner. The appearance transformation between camera views is encoded by a co-occurrence matrix of visual word joint distributions in probe and gallery images. Our appearance model naturally accounts for spatial similarities and variations caused by pose, illumination & configuration change across camera views. Linear SVMs are then trained as classifiers using these co-occurrence descriptors. On the VIPeR and CUHK Campus benchmark datasets, our method achieves 83.86% and 85.49% at rank-15 on the Cumulative Match Characteristic (CMC) curves, and beats the state-of-the-art results by 10.44% and 22.27%.



### On The Effect of Hyperedge Weights On Hypergraph Learning
- **Arxiv ID**: http://arxiv.org/abs/1410.6736v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1410.6736v1)
- **Published**: 2014-10-24 16:52:41+00:00
- **Updated**: 2014-10-24 16:52:41+00:00
- **Authors**: Sheng Huang, Ahmed Elgammal, Dan Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Hypergraph is a powerful representation in several computer vision, machine learning and pattern recognition problems. In the last decade, many researchers have been keen to develop different hypergraph models. In contrast, no much attention has been paid to the design of hyperedge weights. However, many studies on pairwise graphs show that the choice of edge weight can significantly influence the performances of such graph algorithms. We argue that this also applies to hypegraphs. In this paper, we empirically discuss the influence of hyperedge weight on hypegraph learning via proposing three novel hyperedge weights from the perspectives of geometry, multivariate statistical analysis and linear regression. Extensive experiments on ORL, COIL20, JAFFE, Sheffield, Scene15 and Caltech256 databases verify our hypothesis. Similar to graph learning, several representative hyperedge weighting schemes can be concluded by our experimental studies. Moreover, the experiments also demonstrate that the combinations of such weighting schemes and conventional hypergraph models can get very promising classification and clustering performances in comparison with some recent state-of-the-art algorithms.



### Detecting Figures and Part Labels in Patents: Competition-Based Development of Image Processing Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1410.6751v3
- **DOI**: 10.1007/s10032-016-0260-8
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1410.6751v3)
- **Published**: 2014-10-24 17:45:36+00:00
- **Updated**: 2014-11-11 14:33:11+00:00
- **Authors**: Christoph Riedl, Richard Zanibbi, Marti A. Hearst, Siyu Zhu, Michael Menietti, Jason Crusan, Ivan Metelsky, Karim R. Lakhani
- **Comment**: None
- **Journal**: None
- **Summary**: We report the findings of a month-long online competition in which participants developed algorithms for augmenting the digital version of patent documents published by the United States Patent and Trademark Office (USPTO). The goal was to detect figures and part labels in U.S. patent drawing pages. The challenge drew 232 teams of two, of which 70 teams (30%) submitted solutions. Collectively, teams submitted 1,797 solutions that were compiled on the competition servers. Participants reported spending an average of 63 hours developing their solutions, resulting in a total of 5,591 hours of development time. A manually labeled dataset of 306 patents was used for training, online system tests, and evaluation. The design and performance of the top-5 systems are presented, along with a system developed after the competition which illustrates that winning teams produced near state-of-the-art results under strict time and computation constraints. For the 1st place system, the harmonic mean of recall and precision (f-measure) was 88.57% for figure region detection, 78.81% for figure regions with correctly recognized figure titles, and 70.98% for part label detection and character recognition. Data and software from the competition are available through the online UCI Machine Learning repository to inspire follow-on work by the image processing community.



