# Arxiv Papers in cs.CV on 2015-06-01
### Learning to Answer Questions From Image Using Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1506.00333v2
- **DOI**: None
- **Categories**: **cs.CL**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.00333v2)
- **Published**: 2015-06-01 03:09:49+00:00
- **Updated**: 2015-11-13 09:54:59+00:00
- **Authors**: Lin Ma, Zhengdong Lu, Hang Li
- **Comment**: 7 pages, 4 figures. Accepted by AAAI 2016
- **Journal**: None
- **Summary**: In this paper, we propose to employ the convolutional neural network (CNN) for the image question answering (QA). Our proposed CNN provides an end-to-end framework with convolutional architectures for learning not only the image and question representations, but also their inter-modal interactions to produce the answer. More specifically, our model consists of three CNNs: one image CNN to encode the image content, one sentence CNN to compose the words of the question, and one multimodal convolution layer to learn their joint representation for the classification in the space of candidate answer words. We demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA datasets, which are two benchmark datasets for the image QA, with the performances significantly outperforming the state-of-the-art.



### RBIR using Interest Regions and Binary Signatures
- **Arxiv ID**: http://arxiv.org/abs/1506.00368v1
- **DOI**: None
- **Categories**: **cs.CV**, H.2.8; H.3.3
- **Links**: [PDF](http://arxiv.org/pdf/1506.00368v1)
- **Published**: 2015-06-01 07:27:42+00:00
- **Updated**: 2015-06-01 07:27:42+00:00
- **Authors**: Thanh The Van, Thanh Manh Le
- **Comment**: 14 pages, 8 figures
- **Journal**: Annales Univ. Sci. Budapest, Sect. Comp. 43 (2014), pp. 89-103
- **Summary**: In this paper, we introduce an approach to overcome the low accuracy of the Content-Based Image Retrieval (CBIR) (when using the global features). To increase the accuracy, we use Harris-Laplace detector to identify the interest regions of image. Then, we build the Region-Based Image Retrieval (RBIR). For the efficient image storage and retrieval, we encode images into binary signatures. The binary signature of a image is created from its interest regions. Furthermore, this paper also provides an algorithm for image retrieval on S-tree by comparing the images' signatures on a metric similarly to EMD (earth mover's distance). Finally, we evaluate the created models on COREL's images.



### Hierarchical structure-and-motion recovery from uncalibrated images
- **Arxiv ID**: http://arxiv.org/abs/1506.00395v1
- **DOI**: 10.1016/j.cviu.2015.05.011
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.00395v1)
- **Published**: 2015-06-01 08:55:54+00:00
- **Updated**: 2015-06-01 08:55:54+00:00
- **Authors**: Roberto Toldo, Riccardo Gherardi, Michela Farenzena, Andrea Fusiello
- **Comment**: Accepted for publication in CVIU
- **Journal**: Computer Vision and Image Understanding, Volume 140, November
  2015, Pages 127-143
- **Summary**: This paper addresses the structure-and-motion problem, that requires to find camera motion and 3D struc- ture from point matches. A new pipeline, dubbed Samantha, is presented, that departs from the prevailing sequential paradigm and embraces instead a hierarchical approach. This method has several advantages, like a provably lower computational complexity, which is necessary to achieve true scalability, and better error containment, leading to more stability and less drift. Moreover, a practical autocalibration procedure allows to process images without ancillary information. Experiments with real data assess the accuracy and the computational efficiency of the method.



### An Efficient Algorithm for Video Super-Resolution Based On a Sequential Model
- **Arxiv ID**: http://arxiv.org/abs/1506.00473v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.00473v3)
- **Published**: 2015-06-01 12:33:41+00:00
- **Updated**: 2016-02-15 08:22:26+00:00
- **Authors**: Patrick Héas, Angélique Drémeau, Cédric Herzet
- **Comment**: 37 pages, SIAM Journal on Imaging Sciences, 2016
- **Journal**: None
- **Summary**: In this work, we propose a novel procedure for video super-resolution, that is the recovery of a sequence of high-resolution images from its low-resolution counterpart. Our approach is based on a "sequential" model (i.e., each high-resolution frame is supposed to be a displaced version of the preceding one) and considers the use of sparsity-enforcing priors. Both the recovery of the high-resolution images and the motion fields relating them is tackled. This leads to a large-dimensional, non-convex and non-smooth problem. We propose an algorithmic framework to address the latter. Our approach relies on fast gradient evaluation methods and modern optimization techniques for non-differentiable/non-convex problems. Unlike some other previous works, we show that there exists a provably-convergent method with a complexity linear in the problem dimensions. We assess the proposed optimization method on {several video benchmarks and emphasize its good performance with respect to the state of the art.}



### Robust Face Recognition with Structural Binary Gradient Patterns
- **Arxiv ID**: http://arxiv.org/abs/1506.00481v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.00481v1)
- **Published**: 2015-06-01 12:57:07+00:00
- **Updated**: 2015-06-01 12:57:07+00:00
- **Authors**: Weilin Huang, Hujun Yin
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a computationally efficient yet powerful binary framework for robust facial representation based on image gradients. It is termed as structural binary gradient patterns (SBGP). To discover underlying local structures in the gradient domain, we compute image gradients from multiple directions and simplify them into a set of binary strings. The SBGP is derived from certain types of these binary strings that have meaningful local structures and are capable of resembling fundamental textural information. They detect micro orientational edges and possess strong orientation and locality capabilities, thus enabling great discrimination. The SBGP also benefits from the advantages of the gradient domain and exhibits profound robustness against illumination variations. The binary strategy realized by pixel correlations in a small neighborhood substantially simplifies the computational complexity and achieves extremely efficient processing with only 0.0032s in Matlab for a typical face image. Furthermore, the discrimination power of the SBGP can be enhanced on a set of defined orientational image gradient magnitudes, further enforcing locality and orientation. Results of extensive experiments on various benchmark databases illustrate significant improvements of the SBGP based representations over the existing state-of-the-art local descriptors in the terms of discrimination, robustness and complexity. Codes for the SBGP methods will be available at http://www.eee.manchester.ac.uk/research/groups/sisp/software/.



### Predicting Deep Zero-Shot Convolutional Neural Networks using Textual Descriptions
- **Arxiv ID**: http://arxiv.org/abs/1506.00511v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.00511v2)
- **Published**: 2015-06-01 14:37:06+00:00
- **Updated**: 2015-09-25 16:20:44+00:00
- **Authors**: Jimmy Ba, Kevin Swersky, Sanja Fidler, Ruslan Salakhutdinov
- **Comment**: Correct the typos in table 1 regarding [5]. To appear in ICCV 2015
- **Journal**: None
- **Summary**: One of the main challenges in Zero-Shot Learning of visual categories is gathering semantic attributes to accompany images. Recent work has shown that learning from textual descriptions, such as Wikipedia articles, avoids the problem of having to explicitly define these attributes. We present a new model that can classify unseen categories from their textual description. Specifically, we use text features to predict the output weights of both the convolutional and the fully connected layers in a deep convolutional neural network (CNN). We take advantage of the architecture of CNNs and learn features at different layers, rather than just learning an embedding space for both modalities, as is common with existing approaches. The proposed model also allows us to automatically generate a list of pseudo- attributes for each visual category consisting of words from Wikipedia articles. We train our models end-to-end us- ing the Caltech-UCSD bird and flower datasets and evaluate both ROC and Precision-Recall curves. Our empirical results show that the proposed model significantly outperforms previous methods.



### User Preferences Modeling and Learning for Pleasing Photo Collage Generation
- **Arxiv ID**: http://arxiv.org/abs/1506.00527v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV, cs.HC, H.1.2; I.4.0; G.1.6; I.2.6; I.4.9
- **Links**: [PDF](http://arxiv.org/pdf/1506.00527v1)
- **Published**: 2015-06-01 15:20:29+00:00
- **Updated**: 2015-06-01 15:20:29+00:00
- **Authors**: Simone Bianco, Gianluigi Ciocca
- **Comment**: To be published in ACM Transactions on Multimedia Computing,
  Communications, and Applications (TOMM)
- **Journal**: None
- **Summary**: In this paper we consider how to automatically create pleasing photo collages created by placing a set of images on a limited canvas area. The task is formulated as an optimization problem. Differently from existing state-of-the-art approaches, we here exploit subjective experiments to model and learn pleasantness from user preferences. To this end, we design an experimental framework for the identification of the criteria that need to be taken into account to generate a pleasing photo collage. Five different thematic photo datasets are used to create collages using state-of-the-art criteria. A first subjective experiment where several subjects evaluated the collages, emphasizes that different criteria are involved in the subjective definition of pleasantness. We then identify new global and local criteria and design algorithms to quantify them. The relative importance of these criteria are automatically learned by exploiting the user preferences, and new collages are generated. To validate our framework, we performed several psycho-visual experiments involving different users. The results shows that the proposed framework allows to learn a novel computational model which effectively encodes an inter-user definition of pleasantness. The learned definition of pleasantness generalizes well to new photo datasets of different themes and sizes not used in the learning. Moreover, compared with two state of the art approaches, the collages created using our framework are preferred by the majority of the users.



### A Riemannian low-rank method for optimization over semidefinite matrices with block-diagonal constraints
- **Arxiv ID**: http://arxiv.org/abs/1506.00575v2
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/1506.00575v2)
- **Published**: 2015-06-01 17:17:49+00:00
- **Updated**: 2016-01-06 15:01:39+00:00
- **Authors**: Nicolas Boumal
- **Comment**: 37 pages, 3 figures
- **Journal**: None
- **Summary**: We propose a new algorithm to solve optimization problems of the form $\min f(X)$ for a smooth function $f$ under the constraints that $X$ is positive semidefinite and the diagonal blocks of $X$ are small identity matrices. Such problems often arise as the result of relaxing a rank constraint (lifting). In particular, many estimation tasks involving phases, rotations, orthonormal bases or permutations fit in this framework, and so do certain relaxations of combinatorial problems such as Max-Cut. The proposed algorithm exploits the facts that (1) such formulations admit low-rank solutions, and (2) their rank-restricted versions are smooth optimization problems on a Riemannian manifold. Combining insights from both the Riemannian and the convex geometries of the problem, we characterize when second-order critical points of the smooth problem reveal KKT points of the semidefinite problem. We compare against state of the art, mature software and find that, on certain interesting problem instances, what we call the staircase method is orders of magnitude faster, is more accurate and scales better. Code is available.



