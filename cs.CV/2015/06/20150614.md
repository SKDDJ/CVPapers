# Arxiv Papers in cs.CV on 2015-06-14
### Resolving Scale Ambiguity Via XSlit Aspect Ratio Analysis
- **Arxiv ID**: http://arxiv.org/abs/1506.04338v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04338v1)
- **Published**: 2015-06-14 00:07:46+00:00
- **Updated**: 2015-06-14 00:07:46+00:00
- **Authors**: Wei Yang, Haiting Lin, Sing Bing Kang, Jingyi Yu
- **Comment**: None
- **Journal**: None
- **Summary**: In perspective cameras, images of a frontal-parallel 3D object preserve its aspect ratio invariant to its depth. Such an invariance is useful in photography but is unique to perspective projection. In this paper, we show that alternative non-perspective cameras such as the crossed-slit or XSlit cameras exhibit a different depth-dependent aspect ratio (DDAR) property that can be used to 3D recovery. We first conduct a comprehensive analysis to characterize DDAR, infer object depth from its AR, and model recoverable depth range, sensitivity, and error. We show that repeated shape patterns in real Manhattan World scenes can be used for 3D reconstruction using a single XSlit image. We also extend our analysis to model slopes of lines. Specifically, parallel 3D lines exhibit depth-dependent slopes (DDS) on their images which can also be used to infer their depths. We validate our analyses using real XSlit cameras, XSlit panoramas, and catadioptric mirrors. Experiments show that DDAR and DDS provide important depth cues and enable effective single-image scene reconstruction.



### Deep Secure Encoding: An Application to Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1506.04340v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04340v1)
- **Published**: 2015-06-14 00:39:20+00:00
- **Updated**: 2015-06-14 00:39:20+00:00
- **Authors**: Rohit Pandey, Yingbo Zhou, Venu Govindaraju
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present Deep Secure Encoding: a framework for secure classification using deep neural networks, and apply it to the task of biometric template protection for faces. Using deep convolutional neural networks (CNNs), we learn a robust mapping of face classes to high entropy secure codes. These secure codes are then hashed using standard hash functions like SHA-256 to generate secure face templates. The efficacy of the approach is shown on two face databases, namely, CMU-PIE and Extended Yale B, where we achieve state of the art matching performance, along with cancelability and high security with no unrealistic assumptions. Furthermore, the scheme can work in both identification and verification modes.



### The Artists who Forged Themselves: Detecting Creativity in Art
- **Arxiv ID**: http://arxiv.org/abs/1506.04356v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1506.04356v1)
- **Published**: 2015-06-14 06:44:34+00:00
- **Updated**: 2015-06-14 06:44:34+00:00
- **Authors**: Milan Rajković, Miloš Milovanović
- **Comment**: 26 pages, 8 figures
- **Journal**: None
- **Summary**: Creativity and the understanding of cognitive processes involved in the creative process are relevant to all of human activities. Comprehension of creativity in the arts is of special interest due to the involvement of many scientific and non scientific disciplines. Using digital representation of paintings, we show that creative process in painting art may be objectively recognized within the mathematical framework of self organization, a process characteristic of nonlinear dynamic systems and occurring in natural and social sciences. Unlike the artist identification process or the recognition of forgery, which presupposes the knowledge of the original work, our method requires no prior knowledge on the originality of the work of art. The original paintings are recognized as realizations of the creative process which, in general, is shown to correspond to self-organization of texture features which determine the aesthetic complexity of the painting. The method consists of the wavelet based statistical digital image processing and the measure of statistical complexity which represents the minimal (average) information necessary for optimal prediction. The statistical complexity is based on the properly defined causal states with optimal predictive properties. Two different time concepts related to the works of art are introduced: the internal time and the artistic time. The internal time of the artwork is determined by the span of causal dependencies between wavelet coefficients while the artistic time refers to the internal time during which complexity increases where complexity refers to compositional, aesthetic and structural arrangement of texture features. The method is illustrated by recognizing the original paintings from the copies made by the artists themselves, including the works of the famous surrealist painter Ren\'{e} Magritte.



### Reading Scene Text in Deep Convolutional Sequences
- **Arxiv ID**: http://arxiv.org/abs/1506.04395v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04395v2)
- **Published**: 2015-06-14 13:34:10+00:00
- **Updated**: 2015-12-20 21:06:23+00:00
- **Authors**: Pan He, Weilin Huang, Yu Qiao, Chen Change Loy, Xiaoou Tang
- **Comment**: To appear in the 13th AAAI Conference on Artificial Intelligence
  (AAAI-16), 2016
- **Journal**: None
- **Summary**: We develop a Deep-Text Recurrent Network (DTRN) that regards scene text reading as a sequence labelling problem. We leverage recent advances of deep convolutional neural networks to generate an ordered high-level sequence from a whole word image, avoiding the difficult character segmentation problem. Then a deep recurrent model, building on long short-term memory (LSTM), is developed to robustly recognize the generated CNN sequences, departing from most existing approaches recognising each character independently. Our model has a number of appealing properties in comparison to existing scene text recognition methods: (i) It can recognise highly ambiguous words by leveraging meaningful context information, allowing it to work reliably without either pre- or post-processing; (ii) the deep CNN feature is robust to various image distortions; (iii) it retains the explicit order information in word image, which is essential to discriminate word strings; (iv) the model does not depend on pre-defined dictionary, and it can process unknown words and arbitrary strings. Codes for the DTRN will be available.



### Compressing Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1506.04449v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.04449v1)
- **Published**: 2015-06-14 23:16:40+00:00
- **Updated**: 2015-06-14 23:16:40+00:00
- **Authors**: Wenlin Chen, James T. Wilson, Stephen Tyree, Kilian Q. Weinberger, Yixin Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNN) are increasingly used in many areas of computer vision. They are particularly attractive because of their ability to "absorb" great quantities of labeled data through millions of parameters. However, as model sizes increase, so do the storage and memory requirements of the classifiers. We present a novel network architecture, Frequency-Sensitive Hashed Nets (FreshNets), which exploits inherent redundancy in both convolutional layers and fully-connected layers of a deep learning model, leading to dramatic savings in memory and storage consumption. Based on the key observation that the weights of learned convolutional filters are typically smooth and low-frequency, we first convert filter weights to the frequency domain with a discrete cosine transform (DCT) and use a low-cost hash function to randomly group frequency parameters into hash buckets. All parameters assigned the same hash bucket share a single value learned with standard back-propagation. To further reduce model size we allocate fewer hash buckets to high-frequency components, which are generally less important. We evaluate FreshNets on eight data sets, and show that it leads to drastically better compressed performance than several relevant baselines.



