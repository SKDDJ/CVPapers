# Arxiv Papers in cs.CV on 2015-06-16
### Evaluation of Denoising Techniques for EOG signals based on SNR Estimation
- **Arxiv ID**: http://arxiv.org/abs/1506.04843v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04843v2)
- **Published**: 2015-06-16 06:07:21+00:00
- **Updated**: 2016-10-27 12:27:47+00:00
- **Authors**: Anirban Dasgupta, Suvodip Chakrborty, Aritra Chaudhuri, Aurobinda Routray
- **Comment**: in IEEE 2016 International Conference on Systems in Medicine and
  Biology (ICSMB)
- **Journal**: None
- **Summary**: This paper evaluates four algorithms for denoising raw Electrooculography (EOG) data based on the Signal to Noise Ratio (SNR). The SNR is computed using the eigenvalue method. The filtering algorithms are a) Finite Impulse Response (FIR) bandpass filters, b) Stationary Wavelet Transform, c) Empirical Mode Decomposition (EMD) d) FIR Median Hybrid Filters. An EOG dataset has been prepared where the subject is asked to perform letter cancelation test on 20 subjects.



### End-to-end people detection in crowded scenes
- **Arxiv ID**: http://arxiv.org/abs/1506.04878v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04878v3)
- **Published**: 2015-06-16 08:47:16+00:00
- **Updated**: 2015-07-08 21:55:17+00:00
- **Authors**: Russell Stewart, Mykhaylo Andriluka
- **Comment**: 9 pages, 7 figures. Submitted to NIPS 2015. Supplementary material
  video: http://www.youtube.com/watch?v=QeWl0h3kQ24
- **Journal**: None
- **Summary**: Current people detectors operate either by scanning an image in a sliding window fashion or by classifying a discrete set of proposals. We propose a model that is based on decoding an image into a set of people detections. Our system takes an image as input and directly outputs a set of distinct detection hypotheses. Because we generate predictions jointly, common post-processing steps such as non-maximum suppression are unnecessary. We use a recurrent LSTM layer for sequence generation and train our model end-to-end with a new loss function that operates on sets of detections. We demonstrate the effectiveness of our approach on the challenging task of detecting people in crowded scenes.



### Subsampled terahertz data reconstruction based on spatio-temporal dictionary learning
- **Arxiv ID**: http://arxiv.org/abs/1506.04912v1
- **DOI**: 10.1016/j.dsp.2015.04.010
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04912v1)
- **Published**: 2015-06-16 10:55:46+00:00
- **Updated**: 2015-06-16 10:55:46+00:00
- **Authors**: Vahid Abolghasemi, Hao Shen, Yaochun Shen, Lu Gan
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, the problem of terahertz pulsed imaging and reconstruction is addressed. It is assumed that an incomplete (subsampled) three dimensional THz data set has been acquired and the aim is to recover all missing samples. A sparsity-inducing approach is proposed for this purpose. First, a simple interpolation is applied to incomplete noisy data. Then, we propose a spatio-temporal dictionary learning method to obtain an appropriate sparse representation of data based on a joint sparse recovery algorithm. Then, using the sparse coefficients and the learned dictionary, the 3D data is effectively denoised by minimizing a simple cost function. We consider two types of terahertz data to evaluate the performance of the proposed approach; THz data acquired for a model sample with clear layered structures (e.g., a T-shape plastic sheet buried in a polythene pellet), and pharmaceutical tablet data (with low spatial resolution). The achieved signal-to-noise-ratio for reconstruction of T-shape data, from only 5% observation was 19 dB. Moreover, the accuracies of obtained thickness and depth measurements for pharmaceutical tablet data after reconstruction from 10% observation were 98.8%, and 99.9%, respectively. These results, along with chemical mapping analysis, presented at the end of this paper, confirm the accuracy of the proposed method.



### Decoupled Deep Neural Network for Semi-supervised Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1506.04924v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04924v2)
- **Published**: 2015-06-16 11:20:04+00:00
- **Updated**: 2015-06-17 08:38:32+00:00
- **Authors**: Seunghoon Hong, Hyeonwoo Noh, Bohyung Han
- **Comment**: Added a link to the project page for more comprehensive illustration
  of results
- **Journal**: None
- **Summary**: We propose a novel deep neural network architecture for semi-supervised semantic segmentation using heterogeneous annotations. Contrary to existing approaches posing semantic segmentation as a single task of region-based classification, our algorithm decouples classification and segmentation, and learns a separate network for each task. In this architecture, labels associated with an image are identified by classification network, and binary segmentation is subsequently performed for each identified label in segmentation network. The decoupled architecture enables us to learn classification and segmentation networks separately based on the training data with image-level and pixel-wise class labels, respectively. It facilitates to reduce search space for segmentation effectively by exploiting class-specific activation maps obtained from bridging layers. Our algorithm shows outstanding performance compared to other semi-supervised approaches even with much less training images with strong annotations in PASCAL VOC dataset.



### Post-Reconstruction Deconvolution of PET Images by Total Generalized Variation Regularization
- **Arxiv ID**: http://arxiv.org/abs/1506.04935v1
- **DOI**: None
- **Categories**: **cs.CV**, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1506.04935v1)
- **Published**: 2015-06-16 12:19:04+00:00
- **Updated**: 2015-06-16 12:19:04+00:00
- **Authors**: Stéphanie Guérit, Laurent Jacques, Benoît Macq, John A. Lee
- **Comment**: First published in the Proceedings of the 23rd European Signal
  Processing Conference (EUSIPCO-2015) in 2015, published by EURASIP
- **Journal**: None
- **Summary**: Improving the quality of positron emission tomography (PET) images, affected by low resolution and high level of noise, is a challenging task in nuclear medicine and radiotherapy. This work proposes a restoration method, achieved after tomographic reconstruction of the images and targeting clinical situations where raw data are often not accessible. Based on inverse problem methods, our contribution introduces the recently developed total generalized variation (TGV) norm to regularize PET image deconvolution. Moreover, we stabilize this procedure with additional image constraints such as positivity and photometry invariance. A criterion for updating and adjusting automatically the regularization parameter in case of Poisson noise is also presented. Experiments are conducted on both synthetic data and real patient images.



### Using Hankel Matrices for Dynamics-based Facial Emotion Recognition and Pain Detection
- **Arxiv ID**: http://arxiv.org/abs/1506.05001v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1506.05001v1)
- **Published**: 2015-06-16 15:22:46+00:00
- **Updated**: 2015-06-16 15:22:46+00:00
- **Authors**: Liliana Lo Presti, Marco La Cascia
- **Comment**: in IEEE Proceedings of Workshop on Analysis and Modeling of Face and
  Gestures (CVPRW 2015)
- **Journal**: None
- **Summary**: This paper proposes a new approach to model the temporal dynamics of a sequence of facial expressions. To this purpose, a sequence of Face Image Descriptors (FID) is regarded as the output of a Linear Time Invariant (LTI) system. The temporal dynamics of such sequence of descriptors are represented by means of a Hankel matrix. The paper presents different strategies to compute dynamics-based representation of a sequence of FID, and reports classification accuracy values of the proposed representations within different standard classification frameworks. The representations have been validated in two very challenging application domains: emotion recognition and pain detection. Experiments on two publicly available benchmarks and comparison with state-of-the-art approaches demonstrate that the dynamics-based FID representation attains competitive performance when off-the-shelf classification tools are adopted.



### Bayesian representation learning with oracle constraints
- **Arxiv ID**: http://arxiv.org/abs/1506.05011v4
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1506.05011v4)
- **Published**: 2015-06-16 15:54:59+00:00
- **Updated**: 2016-03-01 23:36:04+00:00
- **Authors**: Theofanis Karaletsos, Serge Belongie, Gunnar Rätsch
- **Comment**: 16 pages, publishes in ICLR 16
- **Journal**: None
- **Summary**: Representation learning systems typically rely on massive amounts of labeled data in order to be trained to high accuracy. Recently, high-dimensional parametric models like neural networks have succeeded in building rich representations using either compressive, reconstructive or supervised criteria. However, the semantic structure inherent in observations is oftentimes lost in the process. Human perception excels at understanding semantics but cannot always be expressed in terms of labels. Thus, \emph{oracles} or \emph{human-in-the-loop systems}, for example crowdsourcing, are often employed to generate similarity constraints using an implicit similarity function encoded in human perception. In this work we propose to combine \emph{generative unsupervised feature learning} with a \emph{probabilistic treatment of oracle information like triplets} in order to transfer implicit privileged oracle knowledge into explicit nonlinear Bayesian latent factor models of the observations. We use a fast variational algorithm to learn the joint model and demonstrate applicability to a well-known image dataset. We show how implicit triplet information can provide rich information to learn representations that outperform previous metric learning approaches as well as generative models without this side-information in a variety of predictive tasks. In addition, we illustrate that the proposed approach compartmentalizes the latent spaces semantically which allows interpretation of the latent variables.



### Histopathological Image Classification using Discriminative Feature-oriented Dictionary Learning
- **Arxiv ID**: http://arxiv.org/abs/1506.05032v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05032v5)
- **Published**: 2015-06-16 16:47:44+00:00
- **Updated**: 2016-03-29 18:09:59+00:00
- **Authors**: Tiep Huu Vu, Hojjat Seyed Mousavi, Vishal Monga, Arvind UK Rao, Ganesh Rao
- **Comment**: Accepted version to Transaction on Medical Imaging, 13 pages
- **Journal**: None
- **Summary**: In histopathological image analysis, feature extraction for classification is a challenging task due to the diversity of histology features suitable for each problem as well as presence of rich geometrical structures. In this paper, we propose an automatic feature discovery framework via learning class-specific dictionaries and present a low-complexity method for classification and disease grading in histopathology. Essentially, our Discriminative Feature-oriented Dictionary Learning (DFDL) method learns class-specific dictionaries such that under a sparsity constraint, the learned dictionaries allow representing a new image sample parsimoniously via the dictionary corresponding to the class identity of the sample. At the same time, the dictionary is designed to be poorly capable of representing samples from other classes. Experiments on three challenging real-world image databases: 1) histopathological images of intraductal breast lesions, 2) mammalian kidney, lung and spleen images provided by the Animal Diagnostics Lab (ADL) at Pennsylvania State University, and 3) brain tumor images from The Cancer Genome Atlas (TCGA) database, reveal the merits of our proposal over state-of-the-art alternatives. {Moreover, we demonstrate that DFDL exhibits a more graceful decay in classification accuracy against the number of training images which is highly desirable in practice where generous training is often not available



### Depth Perception in Autostereograms: 1/f-Noise is Best
- **Arxiv ID**: http://arxiv.org/abs/1506.05036v1
- **DOI**: 10.1364/JOSAA.33.000149
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05036v1)
- **Published**: 2015-06-16 17:06:19+00:00
- **Updated**: 2015-06-16 17:06:19+00:00
- **Authors**: Yael Yankelevsky, Ishai Shvartz, Tamar Avraham, Alfred M. Bruckstein
- **Comment**: None
- **Journal**: None
- **Summary**: An autostereogram is a single image that encodes depth information that pops out when looking at it. The trick is achieved by replicating a vertical strip that sets a basic two-dimensional pattern with disparity shifts that encode a three-dimensional scene. It is of interest to explore the dependency between the ease of perceiving depth in autostereograms and the choice of the basic pattern used for generating them. In this work we confirm a theory proposed by Bruckstein et al. to explain the process of autostereographic depth perception, providing a measure for the ease of "locking into" the depth profile, based on the spectral properties of the basic pattern used. We report the results of three sets of psychophysical experiments using autostereograms generated from two-dimensional random noise patterns having power spectra of the form $1/f^\beta$. The experiments were designed to test the ability of human subjects to identify smooth, low resolution surfaces, as well as detail, in the form of higher resolution objects in the depth profile, and to determine limits in identifying small objects as a function of their size. In accordance with the theory, we discover a significant advantage of the $1/f$ noise pattern (pink noise) for fast depth lock-in and fine detail detection, showing that such patterns are optimal choices for autostereogram design. Validating the theoretical model predictions strengthens its underlying assumptions, and contributes to a better understanding of the visual system's binocular disparity mechanisms.



### Time Series Classification using the Hidden-Unit Logistic Model
- **Arxiv ID**: http://arxiv.org/abs/1506.05085v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.05085v2)
- **Published**: 2015-06-16 19:20:00+00:00
- **Updated**: 2016-01-19 13:33:52+00:00
- **Authors**: Wenjie Pei, Hamdi Dibeklioğlu, David M. J. Tax, Laurens van der Maaten
- **Comment**: 17 pages, 4 figures, 3 tables
- **Journal**: None
- **Summary**: We present a new model for time series classification, called the hidden-unit logistic model, that uses binary stochastic hidden units to model latent structure in the data. The hidden units are connected in a chain structure that models temporal dependencies in the data. Compared to the prior models for time series classification such as the hidden conditional random field, our model can model very complex decision boundaries because the number of latent states grows exponentially with the number of hidden units. We demonstrate the strong performance of our model in experiments on a variety of (computer vision) tasks, including handwritten character recognition, speech recognition, facial expression, and action recognition. We also present a state-of-the-art system for facial action unit detection based on the hidden-unit logistic model.



### Deep Convolutional Networks on Graph-Structured Data
- **Arxiv ID**: http://arxiv.org/abs/1506.05163v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.05163v1)
- **Published**: 2015-06-16 22:31:09+00:00
- **Updated**: 2015-06-16 22:31:09+00:00
- **Authors**: Mikael Henaff, Joan Bruna, Yann LeCun
- **Comment**: None
- **Journal**: None
- **Summary**: Deep Learning's recent successes have mostly relied on Convolutional Networks, which exploit fundamental statistical properties of images, sounds and video data: the local stationarity and multi-scale compositional structure, that allows expressing long range interactions in terms of shorter, localized interactions. However, there exist other important examples, such as text documents or bioinformatic data, that may lack some or all of these strong statistical regularities.   In this paper we consider the general question of how to construct deep architectures with small learning complexity on general non-Euclidean domains, which are typically unknown and need to be estimated from the data. In particular, we develop an extension of Spectral Networks which incorporates a Graph Estimation procedure, that we test on large-scale classification problems, matching or improving over Dropout Networks with far less parameters to estimate.



