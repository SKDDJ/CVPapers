# Arxiv Papers in cs.CV on 2015-06-25
### Degenerate Motions in Multicamera Cluster SLAM with Non-overlapping Fields of View
- **Arxiv ID**: http://arxiv.org/abs/1506.07597v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1506.07597v1)
- **Published**: 2015-06-25 02:27:29+00:00
- **Updated**: 2015-06-25 02:27:29+00:00
- **Authors**: Michael J. Tribou, David W. L. Wang, Steven L. Waslander
- **Comment**: 18 pages, 18 figures
- **Journal**: None
- **Summary**: An analysis of the relative motion and point feature model configurations leading to solution degeneracy is presented, for the case of a Simultaneous Localization and Mapping system using multicamera clusters with non-overlapping fields-of-view. The SLAM optimization system seeks to minimize image space reprojection error and is formulated for a cluster containing any number of component cameras, observing any number of point features over two keyframes. The measurement Jacobian is transformed to expose a reduced-dimension representation such that the degeneracy of the system can be determined by the rank of a dense submatrix. A set of relative motions sufficient for degeneracy are identified for certain cluster configurations, independent of target model geometry. Furthermore, it is shown that increasing the number of cameras within the cluster and observing features across different cameras over the two keyframes reduces the size of the degenerate motion sets significantly.



### Generalized Majorization-Minimization
- **Arxiv ID**: http://arxiv.org/abs/1506.07613v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, cs.LG, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.07613v3)
- **Published**: 2015-06-25 04:56:50+00:00
- **Updated**: 2019-05-17 17:13:53+00:00
- **Authors**: Sobhan Naderi Parizi, Kun He, Reza Aghajani, Stan Sclaroff, Pedro Felzenszwalb
- **Comment**: None
- **Journal**: None
- **Summary**: Non-convex optimization is ubiquitous in machine learning. Majorization-Minimization (MM) is a powerful iterative procedure for optimizing non-convex functions that works by optimizing a sequence of bounds on the function. In MM, the bound at each iteration is required to \emph{touch} the objective function at the optimizer of the previous bound. We show that this touching constraint is unnecessary and overly restrictive. We generalize MM by relaxing this constraint, and propose a new optimization framework, named Generalized Majorization-Minimization (G-MM), that is more flexible. For instance, G-MM can incorporate application-specific biases into the optimization procedure without changing the objective function. We derive G-MM algorithms for several latent variable models and show empirically that they consistently outperform their MM counterparts in optimizing non-convex objectives. In particular, G-MM algorithms appear to be less sensitive to initialization.



### DeepMatching: Hierarchical Deformable Dense Matching
- **Arxiv ID**: http://arxiv.org/abs/1506.07656v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07656v2)
- **Published**: 2015-06-25 08:12:02+00:00
- **Updated**: 2015-10-08 11:37:28+00:00
- **Authors**: Jerome Revaud, Philippe Weinzaepfel, Zaid Harchaoui, Cordelia Schmid
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a novel matching algorithm, called DeepMatching, to compute dense correspondences between images. DeepMatching relies on a hierarchical, multi-layer, correlational architecture designed for matching images and was inspired by deep convolutional approaches. The proposed matching algorithm can handle non-rigid deformations and repetitive textures and efficiently determines dense correspondences in the presence of significant changes between images. We evaluate the performance of DeepMatching, in comparison with state-of-the-art matching algorithms, on the Mikolajczyk (Mikolajczyk et al 2005), the MPI-Sintel (Butler et al 2012) and the Kitti (Geiger et al 2013) datasets. DeepMatching outperforms the state-of-the-art algorithms and shows excellent results in particular for repetitive textures.We also propose a method for estimating optical flow, called DeepFlow, by integrating DeepMatching in the large displacement optical flow (LDOF) approach of Brox and Malik (2011). Compared to existing matching algorithms, additional robustness to large displacements and complex motion is obtained thanks to our matching approach. DeepFlow obtains competitive performance on public benchmarks for optical flow estimation.



### AttentionNet: Aggregating Weak Directions for Accurate Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1506.07704v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1506.07704v2)
- **Published**: 2015-06-25 11:21:04+00:00
- **Updated**: 2015-09-26 08:35:51+00:00
- **Authors**: Donggeun Yoo, Sunggyun Park, Joon-Young Lee, Anthony S. Paek, In So Kweon
- **Comment**: To appear in ICCV 2015
- **Journal**: None
- **Summary**: We present a novel detection method using a deep convolutional neural network (CNN), named AttentionNet. We cast an object detection problem as an iterative classification problem, which is the most suitable form of a CNN. AttentionNet provides quantized weak directions pointing a target object and the ensemble of iterative predictions from AttentionNet converges to an accurate object boundary box. Since AttentionNet is a unified network for object detection, it detects objects without any separated models from the object proposal to the post bounding-box regression. We evaluate AttentionNet by a human detection task and achieve the state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 with an 8-layered architecture only.



### Camera Calibration from Dynamic Silhouettes Using Motion Barcodes
- **Arxiv ID**: http://arxiv.org/abs/1506.07866v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07866v4)
- **Published**: 2015-06-25 19:37:24+00:00
- **Updated**: 2017-01-08 00:45:49+00:00
- **Authors**: Gil Ben-Artzi, Yoni Kasten, Shmuel Peleg, Michael Werman
- **Comment**: Update metadata
- **Journal**: Proc. CVPR'16, Las Vegas, June 2016, pp. 4095-4103
- **Summary**: Computing the epipolar geometry between cameras with very different viewpoints is often problematic as matching points are hard to find. In these cases, it has been proposed to use information from dynamic objects in the scene for suggesting point and line correspondences.   We propose a speed up of about two orders of magnitude, as well as an increase in robustness and accuracy, to methods computing epipolar geometry from dynamic silhouettes. This improvement is based on a new temporal signature: motion barcode for lines. Motion barcode is a binary temporal sequence for lines, indicating for each frame the existence of at least one foreground pixel on that line. The motion barcodes of two corresponding epipolar lines are very similar, so the search for corresponding epipolar lines can be limited only to lines having similar barcodes. The use of motion barcodes leads to increased speed, accuracy, and robustness in computing the epipolar geometry.



