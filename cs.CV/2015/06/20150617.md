# Arxiv Papers in cs.CV on 2015-06-17
### Robust High Quality Image Guided Depth Upsampling
- **Arxiv ID**: http://arxiv.org/abs/1506.05187v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05187v1)
- **Published**: 2015-06-17 02:38:43+00:00
- **Updated**: 2015-06-17 02:38:43+00:00
- **Authors**: Wei Liu, Yijun Li, Xiaogang Chen, Jie Yang, Qiang Wu, Jingyi Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Time-of-Flight (ToF) depth sensing camera is able to obtain depth maps at a high frame rate. However, its low resolution and sensitivity to the noise are always a concern. A popular solution is upsampling the obtained noisy low resolution depth map with the guidance of the companion high resolution color image. However, due to the constrains in the existing upsampling models, the high resolution depth map obtained in such way may suffer from either texture copy artifacts or blur of depth discontinuity. In this paper, a novel optimization framework is proposed with the brand new data term and smoothness term. The comprehensive experiments using both synthetic data and real data show that the proposed method well tackles the problem of texture copy artifacts and blur of depth discontinuity. It also demonstrates sufficient robustness to the noise. Moreover, a data driven scheme is proposed to adaptively estimate the parameter in the upsampling optimization framework. The encouraging performance is maintained even in the case of large upsampling e.g. $8\times$ and $16\times$.



### A Discriminative Representation of Convolutional Features for Indoor Scene Recognition
- **Arxiv ID**: http://arxiv.org/abs/1506.05196v1
- **DOI**: 10.1109/TIP.2016.2567076
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05196v1)
- **Published**: 2015-06-17 03:55:19+00:00
- **Updated**: 2015-06-17 03:55:19+00:00
- **Authors**: Salman H. Khan, Munawar Hayat, Mohammed Bennamoun, Roberto Togneri, Ferdous Sohel
- **Comment**: None
- **Journal**: None
- **Summary**: Indoor scene recognition is a multi-faceted and challenging problem due to the diverse intra-class variations and the confusing inter-class similarities. This paper presents a novel approach which exploits rich mid-level convolutional features to categorize indoor scenes. Traditionally used convolutional features preserve the global spatial structure, which is a desirable property for general object recognition. However, we argue that this structuredness is not much helpful when we have large variations in scene layouts, e.g., in indoor scenes. We propose to transform the structured convolutional activations to another highly discriminative feature space. The representation in the transformed space not only incorporates the discriminative aspects of the target dataset, but it also encodes the features in terms of the general object categories that are present in indoor scenes. To this end, we introduce a new large-scale dataset of 1300 object categories which are commonly present in indoor scenes. Our proposed approach achieves a significant performance boost over previous state of the art approaches on five major scene classification datasets.



### CFORB: Circular FREAK-ORB Visual Odometry
- **Arxiv ID**: http://arxiv.org/abs/1506.05257v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05257v1)
- **Published**: 2015-06-17 09:44:42+00:00
- **Updated**: 2015-06-17 09:44:42+00:00
- **Authors**: Daniel J. Mankowitz, Ehud Rivlin
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel Visual Odometry algorithm entitled Circular FREAK-ORB (CFORB). This algorithm detects features using the well-known ORB algorithm [12] and computes feature descriptors using the FREAK algorithm [14]. CFORB is invariant to both rotation and scale changes, and is suitable for use in environments with uneven terrain. Two visual geometric constraints have been utilized in order to remove invalid feature descriptor matches. These constraints have not previously been utilized in a Visual Odometry algorithm. A variation to circular matching [16] has also been implemented. This allows features to be matched between images without having to be dependent upon the epipolar constraint. This algorithm has been run on the KITTI benchmark dataset and achieves a competitive average translational error of $3.73 \%$ and average rotational error of $0.0107 deg/m$. CFORB has also been run in an indoor environment and achieved an average translational error of $3.70 \%$. After running CFORB in a highly textured environment with an approximately uniform feature spread across the images, the algorithm achieves an average translational error of $2.4 \%$ and an average rotational error of $0.009 deg/m$.



### Partial Functional Correspondence
- **Arxiv ID**: http://arxiv.org/abs/1506.05274v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05274v2)
- **Published**: 2015-06-17 10:47:20+00:00
- **Updated**: 2015-12-22 12:57:25+00:00
- **Authors**: Emanuele Rodol√†, Luca Cosmo, Michael M. Bronstein, Andrea Torsello, Daniel Cremers
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a method for computing partial functional correspondence between non-rigid shapes. We use perturbation analysis to show how removal of shape parts changes the Laplace-Beltrami eigenfunctions, and exploit it as a prior on the spectral representation of the correspondence. Corresponding parts are optimization variables in our problem and are used to weight the functional correspondence; we are looking for the largest and most regular (in the Mumford-Shah sense) parts that minimize correspondence distortion. We show that our approach can cope with very challenging correspondence settings.



### MRF-ZOOM: A Fast Dictionary Searching Algorithm for Magnetic Resonance Fingerprinting
- **Arxiv ID**: http://arxiv.org/abs/1506.05393v1
- **DOI**: 10.1109/EMBC.2017.8037551
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.05393v1)
- **Published**: 2015-06-17 17:47:18+00:00
- **Updated**: 2015-06-17 17:47:18+00:00
- **Authors**: Ze Wang
- **Comment**: 7 figures
- **Journal**: 39th Annual International Conference of the IEEE Engineering in
  Medicine and Biology Society (EMBC), 3256-3259, 2017
- **Summary**: Magnetic resonance fingerprinting (MRF) is a new technique for simultaneously quantifying multiple MR parameters using one temporally resolved MR scan. But its brute-force dictionary generating and searching (DGS) process causes a huge disk space demand and computational burden, prohibiting it from a practical multiple slice high-definition imaging. The purpose of this paper was to provide a fast and space efficient DGS algorithm for MRF. Based on an empirical analysis of properties of the distance function of the acquired MRF signal and the pre-defined MRF dictionary entries, we proposed a parameter separable MRF DGS method, which breaks the multiplicative computation complexity into an additive one and enabling a resolution scalable multi-resolution DGS process, which was dubbed as MRF ZOOM. The evaluation results showed that MRF ZOOM was hundreds or thousands of times faster than the original brute-force DGS method. The acceleration was even higher when considering the time difference for generating the dictionary. Using a high precision quantification, MRF can find the right parameter values for a 64x64 imaging slice in 117 secs. Our data also showed that spatial constraints can be used to further speed up MRF ZOOM.



### Learning with a Wasserstein Loss
- **Arxiv ID**: http://arxiv.org/abs/1506.05439v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.05439v3)
- **Published**: 2015-06-17 19:36:41+00:00
- **Updated**: 2015-12-30 01:08:11+00:00
- **Authors**: Charlie Frogner, Chiyuan Zhang, Hossein Mobahi, Mauricio Araya-Polo, Tomaso Poggio
- **Comment**: NIPS 2015; v3 updates Algorithm 1 and Equations 6, 8
- **Journal**: None
- **Summary**: Learning to predict multi-label outputs is challenging, but in many problems there is a natural metric on the outputs that can be used to improve predictions. In this paper we develop a loss function for multi-label learning, based on the Wasserstein distance. The Wasserstein distance provides a natural notion of dissimilarity for probability measures. Although optimizing with respect to the exact Wasserstein distance is costly, recent work has described a regularized approximation that is efficiently computed. We describe an efficient learning algorithm based on this regularization, as well as a novel extension of the Wasserstein distance from probability measures to unnormalized measures. We also describe a statistical learning bound for the loss. The Wasserstein loss can encourage smoothness of the predictions with respect to a chosen metric on the output space. We demonstrate this property on a real-data tag prediction problem, using the Yahoo Flickr Creative Commons dataset, outperforming a baseline that doesn't use the metric.



