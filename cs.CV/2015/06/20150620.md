# Arxiv Papers in cs.CV on 2015-06-20
### Learning to Segment Object Candidates
- **Arxiv ID**: http://arxiv.org/abs/1506.06204v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06204v2)
- **Published**: 2015-06-20 06:36:49+00:00
- **Updated**: 2015-09-01 16:03:01+00:00
- **Authors**: Pedro O. Pinheiro, Ronan Collobert, Piotr Dollar
- **Comment**: None
- **Journal**: None
- **Summary**: Recent object detection systems rely on two critical steps: (1) a set of object proposals is predicted as efficiently as possible, and (2) this set of candidate proposals is then passed to an object classifier. Such approaches have been shown they can be fast, while achieving the state of the art in detection performance. In this paper, we propose a new way to generate object proposals, introducing an approach based on a discriminative convolutional network. Our model is trained jointly with two objectives: given an image patch, the first part of the system outputs a class-agnostic segmentation mask, while the second part of the system outputs the likelihood of the patch being centered on a full object. At test time, the model is efficiently applied on the whole test image and generates a set of segmentation masks, each of them being assigned with a corresponding object likelihood score. We show that our model yields significant improvements over state-of-the-art object proposal algorithms. In particular, compared to previous approaches, our model obtains substantially higher object recall using fewer proposals. We also show that our model is able to generalize to unseen categories it has not seen during training. Unlike all previous approaches for generating object masks, we do not rely on edges, superpixels, or any other form of low-level segmentation.



### Aligning where to see and what to tell: image caption with region-based attention and scene factorization
- **Arxiv ID**: http://arxiv.org/abs/1506.06272v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.06272v1)
- **Published**: 2015-06-20 17:25:38+00:00
- **Updated**: 2015-06-20 17:25:38+00:00
- **Authors**: Junqi Jin, Kun Fu, Runpeng Cui, Fei Sha, Changshui Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Recent progress on automatic generation of image captions has shown that it is possible to describe the most salient information conveyed by images with accurate and meaningful sentences. In this paper, we propose an image caption system that exploits the parallel structures between images and sentences. In our model, the process of generating the next word, given the previously generated ones, is aligned with the visual perception experience where the attention shifting among the visual regions imposes a thread of visual ordering. This alignment characterizes the flow of "abstract meaning", encoding what is semantically shared by both the visual scene and the text description. Our system also makes another novel modeling contribution by introducing scene-specific contexts that capture higher-level semantic information encoded in an image. The contexts adapt language models for word generation to specific scene types. We benchmark our system and contrast to published results on several popular datasets. We show that using either region-based attention or scene-specific contexts improves systems without those components. Furthermore, combining these two modeling ingredients attains the state-of-the-art performance.



### 3D Reconstruction from Full-view Fisheye Camera
- **Arxiv ID**: http://arxiv.org/abs/1506.06273v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06273v1)
- **Published**: 2015-06-20 17:53:24+00:00
- **Updated**: 2015-06-20 17:53:24+00:00
- **Authors**: Chuiwen Ma, Liang Shi, Hanlu Huang, Mengyuan Yan
- **Comment**: None
- **Journal**: None
- **Summary**: In this report, we proposed a 3D reconstruction method for the full-view fisheye camera. The camera we used is Ricoh Theta, which captures spherical images and has a wide field of view (FOV). The conventional stereo apporach based on perspective camera model cannot be directly applied and instead we used a spherical camera model to depict the relation between 3D point and its corresponding observation in the image. We implemented a system that can reconstruct the 3D scene using captures from two or more cameras. A GUI is also created to allow users to control the view perspective and obtain a better intuition of how the scene is rebuilt. Experiments showed that our reconstruction results well preserved the structure of the scene in the real world.



### Pose Estimation Based on 3D Models
- **Arxiv ID**: http://arxiv.org/abs/1506.06274v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1506.06274v1)
- **Published**: 2015-06-20 17:55:49+00:00
- **Updated**: 2015-06-20 17:55:49+00:00
- **Authors**: Chuiwen Ma, Hao Su, Liang Shi
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we proposed a pose estimation system based on rendered image training set, which predicts the pose of objects in real image, with knowledge of object category and tight bounding box. We developed a patch-based multi-class classification algorithm, and an iterative approach to improve the accuracy. We achieved state-of-the-art performance on pose estimation task.



### Filtrated Algebraic Subspace Clustering
- **Arxiv ID**: http://arxiv.org/abs/1506.06289v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06289v5)
- **Published**: 2015-06-20 20:09:25+00:00
- **Updated**: 2017-03-08 18:49:41+00:00
- **Authors**: Manolis C. Tsakiris, Rene Vidal
- **Comment**: None
- **Journal**: SIAM Journal on Imaging Sciences, Volume 10, Issue 1, pp. 372-415,
  2017
- **Summary**: Subspace clustering is the problem of clustering data that lie close to a union of linear subspaces. In the abstract form of the problem, where no noise or other corruptions are present, the data are assumed to lie in general position inside the algebraic variety of a union of subspaces, and the objective is to decompose the variety into its constituent subspaces. Prior algebraic-geometric approaches to this problem require the subspaces to be of equal dimension, or the number of subspaces to be known. Subspaces of arbitrary dimensions can still be recovered in closed form, in terms of all homogeneous polynomials of degree $m$ that vanish on their union, when an upper bound m on the number of the subspaces is given. In this paper, we propose an alternative, provably correct, algorithm for addressing a union of at most $m$ arbitrary-dimensional subspaces, based on the idea of descending filtrations of subspace arrangements. Our algorithm uses the gradient of a vanishing polynomial at a point in the variety to find a hyperplane containing the subspace S passing through that point. By intersecting the variety with this hyperplane, we obtain a subvariety that contains S, and recursively applying the procedure until no non-trivial vanishing polynomial exists, our algorithm eventually identifies S. By repeating this procedure for other points, our algorithm eventually identifies all the subspaces by returning a basis for their orthogonal complement. Finally, we develop a variant of the abstract algorithm, suitable for computations with noisy data. We show by experiments on synthetic and real data that the proposed algorithm outperforms state-of-the-art methods on several occasions, thus demonstrating the merit of the idea of filtrations.



