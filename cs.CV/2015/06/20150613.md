# Arxiv Papers in cs.CV on 2015-06-13
### Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting
- **Arxiv ID**: http://arxiv.org/abs/1506.04214v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04214v2)
- **Published**: 2015-06-13 03:19:24+00:00
- **Updated**: 2015-09-19 11:02:03+00:00
- **Authors**: Xingjian Shi, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-kin Wong, Wang-chun Woo
- **Comment**: None
- **Journal**: None
- **Summary**: The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.



### Extract an essential skeleton of a character as a graph from a character image
- **Arxiv ID**: http://arxiv.org/abs/1506.05068v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05068v2)
- **Published**: 2015-06-13 14:25:54+00:00
- **Updated**: 2022-02-01 02:21:03+00:00
- **Authors**: Kazuhisa Fujita
- **Comment**: None
- **Journal**: International Journal of Computer Science Issues 10, 5, 35-39,
  2013
- **Summary**: This paper aims to make a graph representing an essential skeleton of a character from an image that includes a machine printed or a handwritten character using growing neural gas (GNG) method and relative network graph (RNG) algorithm. The visual system in our brain can recognize printed characters and handwritten characters easily, robustly, and precisely. How does our brain robustly recognize characters? The visual processing in our brain uses the essential features of an object, such as crosses and corners. These features will be helpful for character recognition by a computer. However, extraction of the features is difficult. If the skeleton of a character is represented as a graph, we can more easily extract the features. To extract the skeleton of a character as a graph from an image, this paper proposes the new approach using GNG and RNG algorithm. I achieved to extract skeleton graphs from images including distorted, noisy, and handwritten characters.



### Combinatorial Energy Learning for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1506.04304v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04304v3)
- **Published**: 2015-06-13 18:23:42+00:00
- **Updated**: 2016-09-23 20:47:55+00:00
- **Authors**: Jeremy Maitin-Shepard, Viren Jain, Michal Januszewski, Peter Li, Pieter Abbeel
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a new machine learning approach for image segmentation that uses a neural network to model the conditional energy of a segmentation given an image. Our approach, combinatorial energy learning for image segmentation (CELIS) places a particular emphasis on modeling the inherent combinatorial nature of dense image segmentation problems. We propose efficient algorithms for learning deep neural networks to model the energy function, and for local optimization of this energy in the space of supervoxel agglomerations. We extensively evaluate our method on a publicly available 3-D microscopy dataset with 25 billion voxels of ground truth data. On an 11 billion voxel test set, we find that our method improves volumetric reconstruction accuracy by more than 20% as compared to two state-of-the-art baseline methods: graph-based segmentation of the output of a 3-D convolutional neural network trained to predict boundaries, as well as a random forest classifier trained to agglomerate supervoxels that were generated by a 3-D convolutional neural network.



