# Arxiv Papers in cs.CV on 2015-06-30
### Fast ADMM Algorithm for Distributed Optimization with Adaptive Penalty
- **Arxiv ID**: http://arxiv.org/abs/1506.08928v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1506.08928v1)
- **Published**: 2015-06-30 03:37:07+00:00
- **Updated**: 2015-06-30 03:37:07+00:00
- **Authors**: Changkyu Song, Sejong Yoon, Vladimir Pavlovic
- **Comment**: 8 pages manuscript, 2 pages appendix, 5 figures
- **Journal**: None
- **Summary**: We propose new methods to speed up convergence of the Alternating Direction Method of Multipliers (ADMM), a common optimization tool in the context of large scale and distributed learning. The proposed method accelerates the speed of convergence by automatically deciding the constraint penalty needed for parameter consensus in each iteration. In addition, we also propose an extension of the method that adaptively determines the maximum number of iterations to update the penalty. We show that this approach effectively leads to an adaptive, dynamic network topology underlying the distributed optimization. The utility of the new penalty update schemes is demonstrated on both synthetic and real data, including a computer vision application of distributed structure from motion.



### Lens Factory: Automatic Lens Generation Using Off-the-shelf Components
- **Arxiv ID**: http://arxiv.org/abs/1506.08956v2
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.08956v2)
- **Published**: 2015-06-30 06:39:19+00:00
- **Updated**: 2015-07-16 23:30:45+00:00
- **Authors**: Libin Sun, Brian Guenter, Neel Joshi, Patrick Therien, James Hays
- **Comment**: 12 pages, 18 figures
- **Journal**: None
- **Summary**: Custom optics is a necessity for many imaging applications. Unfortunately, custom lens design is costly (thousands to tens of thousands of dollars), time consuming (10-12 weeks typical lead time), and requires specialized optics design expertise. By using only inexpensive, off-the-shelf lens components the Lens Factory automatic design system greatly reduces cost and time. Design, ordering of parts, delivery, and assembly can be completed in a few days, at a cost in the low hundreds of dollars. Lens design constraints, such as focal length and field of view, are specified in terms familiar to the graphics community so no optics expertise is necessary. Unlike conventional lens design systems, which only use continuous optimization methods, Lens Factory adds a discrete optimization stage. This stage searches the combinatorial space of possible combinations of lens elements to find novel designs, evolving simple canonical lens designs into more complex, better designs. Intelligent pruning rules make the combinatorial search feasible. We have designed and built several high performance optical systems which demonstrate the practicality of the system.



### A Large-Scale Car Dataset for Fine-Grained Categorization and Verification
- **Arxiv ID**: http://arxiv.org/abs/1506.08959v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1506.08959v2)
- **Published**: 2015-06-30 06:47:50+00:00
- **Updated**: 2015-09-24 09:04:24+00:00
- **Authors**: Linjie Yang, Ping Luo, Chen Change Loy, Xiaoou Tang
- **Comment**: An extension to our conference paper in CVPR 2015
- **Journal**: None
- **Summary**: Updated on 24/09/2015: This update provides preliminary experiment results for fine-grained classification on the surveillance data of CompCars. The train/test splits are provided in the updated dataset. See details in Section 6.



### Online Learning to Sample
- **Arxiv ID**: http://arxiv.org/abs/1506.09016v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NA, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.09016v2)
- **Published**: 2015-06-30 10:08:35+00:00
- **Updated**: 2016-03-15 16:08:56+00:00
- **Authors**: Guillaume Bouchard, Th√©o Trouillon, Julien Perez, Adrien Gaidon
- **Comment**: Update: removed convergence theorem and proof as there is an error.
  Submitted to UAI 2016
- **Journal**: None
- **Summary**: Stochastic Gradient Descent (SGD) is one of the most widely used techniques for online optimization in machine learning. In this work, we accelerate SGD by adaptively learning how to sample the most useful training examples at each time step. First, we show that SGD can be used to learn the best possible sampling distribution of an importance sampling estimator. Second, we show that the sampling distribution of an SGD algorithm can be estimated online by incrementally minimizing the variance of the gradient. The resulting algorithm - called Adaptive Weighted SGD (AW-SGD) - maintains a set of parameters to optimize, as well as a set of parameters to sample learning examples. We show that AWSGD yields faster convergence in three different applications: (i) image classification with deep features, where the sampling of images depends on their labels, (ii) matrix factorization, where rows and columns are not sampled uniformly, and (iii) reinforcement learning, where the optimized and exploration policies are estimated at the same time, where our approach corresponds to an off-policy gradient algorithm.



### Long-Range Motion Trajectories Extraction of Articulated Human Using Mesh Evolution
- **Arxiv ID**: http://arxiv.org/abs/1506.09075v3
- **DOI**: 10.1109/LSP.2016.2536647
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.09075v3)
- **Published**: 2015-06-30 13:18:18+00:00
- **Updated**: 2016-03-29 00:21:40+00:00
- **Authors**: Yuanyuan Wu, Xiaohai He, Byeongkeun Kang, Haiying Song, Truong Q. Nguyen
- **Comment**: IEEE Signal Processing Letters
- **Journal**: None
- **Summary**: This letter presents a novel approach to extract reliable dense and long-range motion trajectories of articulated human in a video sequence. Compared with existing approaches that emphasize temporal consistency of each tracked point, we also consider the spatial structure of tracked points on the articulated human. We treat points as a set of vertices, and build a triangle mesh to join them in image space. The problem of extracting long-range motion trajectories is changed to the issue of consistency of mesh evolution over time. First, self-occlusion is detected by a novel mesh-based method and an adaptive motion estimation method is proposed to initialize mesh between successive frames. Furthermore, we propose an iterative algorithm to efficiently adjust vertices of mesh for a physically plausible deformation, which can meet the local rigidity of mesh and silhouette constraints. Finally, we compare the proposed method with the state-of-the-art methods on a set of challenging sequences. Evaluations demonstrate that our method achieves favorable performance in terms of both accuracy and integrity of extracted trajectories.



### Forming A Random Field via Stochastic Cliques: From Random Graphs to Fully Connected Random Fields
- **Arxiv ID**: http://arxiv.org/abs/1506.09110v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.09110v1)
- **Published**: 2015-06-30 14:52:33+00:00
- **Updated**: 2015-06-30 14:52:33+00:00
- **Authors**: Mohammad Javad Shafiee, Alexander Wong, Paul Fieguth
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: Random fields have remained a topic of great interest over past decades for the purpose of structured inference, especially for problems such as image segmentation. The local nodal interactions commonly used in such models often suffer the short-boundary bias problem, which are tackled primarily through the incorporation of long-range nodal interactions. However, the issue of computational tractability becomes a significant issue when incorporating such long-range nodal interactions, particularly when a large number of long-range nodal interactions (e.g., fully-connected random fields) are modeled.   In this work, we introduce a generalized random field framework based around the concept of stochastic cliques, which addresses the issue of computational tractability when using fully-connected random fields by stochastically forming a sparse representation of the random field. The proposed framework allows for efficient structured inference using fully-connected random fields without any restrictions on the potential functions that can be utilized. Several realizations of the proposed framework using graph cuts are presented and evaluated, and experimental results demonstrate that the proposed framework can provide competitive performance for the purpose of image segmentation when compared to existing fully-connected and principled deep random field frameworks.



### Multi-Cue Structure Preserving MRF for Unconstrained Video Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1506.09124v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.09124v1)
- **Published**: 2015-06-30 15:39:37+00:00
- **Updated**: 2015-06-30 15:39:37+00:00
- **Authors**: Saehoon Yi, Vladimir Pavlovic
- **Comment**: None
- **Journal**: None
- **Summary**: Video segmentation is a stepping stone to understanding video context. Video segmentation enables one to represent a video by decomposing it into coherent regions which comprise whole or parts of objects. However, the challenge originates from the fact that most of the video segmentation algorithms are based on unsupervised learning due to expensive cost of pixelwise video annotation and intra-class variability within similar unconstrained video classes. We propose a Markov Random Field model for unconstrained video segmentation that relies on tight integration of multiple cues: vertices are defined from contour based superpixels, unary potentials from temporal smooth label likelihood and pairwise potentials from global structure of a video. Multi-cue structure is a breakthrough to extracting coherent object regions for unconstrained videos in absence of supervision. Our experiments on VSB100 dataset show that the proposed model significantly outperforms competing state-of-the-art algorithms. Qualitative analysis illustrates that video segmentation result of the proposed model is consistent with human perception of objects.



### Aging display's effect on interpretation of digital pathology slides
- **Arxiv ID**: http://arxiv.org/abs/1506.09166v1
- **DOI**: 10.1117/12.2082315
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1506.09166v1)
- **Published**: 2015-06-30 17:29:43+00:00
- **Updated**: 2015-06-30 17:29:43+00:00
- **Authors**: Ali R. N. Avanaki, Kathryn S. Espig, Sameer Sawhney, Liron Pantanowitz, Anil V. Parwani, Albert Xthona, Tom R. L. Kimpe
- **Comment**: None
- **Journal**: None
- **Summary**: It is our conjecture that the variability of colors in a pathology image effects the interpretation of pathology cases, whether it is diagnostic accuracy, diagnostic confidence, or workflow efficiency. In this paper, digital pathology images are analyzed to quantify the perceived difference in color that occurs due to display aging, in particular a change in the maximum luminance, white point, and color gamut. The digital pathology images studied include diagnostically important features, such as the conspicuity of nuclei. Three different display aging models are applied to images: aging of luminance & chrominance, aging of chrominance only, and a stabilized luminance & chrominance (i.e., no aging). These display models and images are then used to compare conspicuity of nuclei using CIE deltaE2000, a perceptual color difference metric. The effect of display aging using these display models and images is further analyzed through a human reader study designed to quantify the effects from a clinical perspective. Results from our reader study indicate significant impact of aged displays on workflow as well as diagnosis as follow. As compared to the originals (no-aging), slides with the effect of aging simulated were significantly more difficult to read (p-value of 0.0005) and took longer to score (p-value of 0.02). Moreover, luminance+chrominance aging significantly reduced inter-session percent agreement of diagnostic scores (p-value of 0.0418).



### On anthropomorphic decision making in a model observer
- **Arxiv ID**: http://arxiv.org/abs/1506.09169v1
- **DOI**: 10.1117/12.2082129
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1506.09169v1)
- **Published**: 2015-06-30 17:36:33+00:00
- **Updated**: 2015-06-30 17:36:33+00:00
- **Authors**: Ali R. N. Avanaki, Kathryn S. Espig, Tom R. L. Kimpe, Andrew D. A. Maidment
- **Comment**: None
- **Journal**: None
- **Summary**: By analyzing human readers' performance in detecting small round lesions in simulated digital breast tomosynthesis background in a location known exactly scenario, we have developed a model observer that is a better predictor of human performance with different levels of background complexity (i.e., anatomical and quantum noise). Our analysis indicates that human observers perform a lesion detection task by combining a number of sub-decisions, each an indicator of the presence of a lesion in the image stack. This is in contrast to a channelized Hotelling observer, where the detection task is conducted holistically by thresholding a single decision variable, made from an optimally weighted linear combination of channels. However, it seems that the sub-par performance of human readers compared to the CHO cannot be fully explained by their reliance on sub-decisions, or perhaps we do not consider a sufficient number of sub-decisions. To bridge the gap between the performances of human readers and the model observer based upon sub-decisions, we use an additive noise model, the power of which is modulated with the level of background complexity. The proposed model observer better predicts the fast drop in human detection performance with background complexity.



### Discovering Characteristic Landmarks on Ancient Coins using Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1506.09174v2
- **DOI**: 10.1117/1.JEI.26.1.011018
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.09174v2)
- **Published**: 2015-06-30 17:41:12+00:00
- **Updated**: 2015-07-01 01:10:13+00:00
- **Authors**: Jongpil Kim, Vladimir Pavlovic
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel method to find characteristic landmarks on ancient Roman imperial coins using deep convolutional neural network models (CNNs). We formulate an optimization problem to discover class-specific regions while guaranteeing specific controlled loss of accuracy. Analysis on visualization of the discovered region confirms that not only can the proposed method successfully find a set of characteristic regions per class, but also the discovered region is consistent with human expert annotations. We also propose a new framework to recognize the Roman coins which exploits hierarchical structure of the ancient Roman coins using the state-of-the-art classification power of the CNNs adopted to a new task of coin classification. Experimental results show that the proposed framework is able to effectively recognize the ancient Roman coins. For this research, we have collected a new Roman coin dataset where all coins are annotated and consist of observe (head) and reverse (tail) images.



### Learning to Detect Blue-white Structures in Dermoscopy Images with Weak Supervision
- **Arxiv ID**: http://arxiv.org/abs/1506.09179v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.09179v1)
- **Published**: 2015-06-30 17:49:40+00:00
- **Updated**: 2015-06-30 17:49:40+00:00
- **Authors**: Ali Madooei, Mark S. Drew, Hossein Hajimirsadeghi
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel approach to identify one of the most significant dermoscopic criteria in the diagnosis of Cutaneous Melanoma: the Blue-whitish structure. In this paper, we achieve this goal in a Multiple Instance Learning framework using only image-level labels of whether the feature is present or not. As the output, we predict the image classification label and as well localize the feature in the image. Experiments are conducted on a challenging dataset with results outperforming state-of-the-art. This study provides an improvement on the scope of modelling for computerized image analysis of skin lesions, in particular in that it puts forward a framework for identification of dermoscopic local features from weakly-labelled data.



### Unsupervised Learning from Narrated Instruction Videos
- **Arxiv ID**: http://arxiv.org/abs/1506.09215v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.5.1; I.5.4; I.2
- **Links**: [PDF](http://arxiv.org/pdf/1506.09215v4)
- **Published**: 2015-06-30 19:55:37+00:00
- **Updated**: 2016-06-28 18:43:37+00:00
- **Authors**: Jean-Baptiste Alayrac, Piotr Bojanowski, Nishant Agrawal, Josef Sivic, Ivan Laptev, Simon Lacoste-Julien
- **Comment**: Appears in: 2016 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR 2016). 21 pages
- **Journal**: None
- **Summary**: We address the problem of automatically learning the main steps to complete a certain task, such as changing a car tire, from a set of narrated instruction videos. The contributions of this paper are three-fold. First, we develop a new unsupervised learning approach that takes advantage of the complementary nature of the input video and the associated narration. The method solves two clustering problems, one in text and one in video, applied one after each other and linked by joint constraints to obtain a single coherent sequence of steps in both modalities. Second, we collect and annotate a new challenging dataset of real-world instruction videos from the Internet. The dataset contains about 800,000 frames for five different tasks that include complex interactions between people and objects, and are captured in a variety of indoor and outdoor settings. Third, we experimentally demonstrate that the proposed method can automatically discover, in an unsupervised manner, the main steps to achieve the task and locate the steps in the input videos.



### Representing data by sparse combination of contextual data points for classification
- **Arxiv ID**: http://arxiv.org/abs/1507.00019v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.00019v2)
- **Published**: 2015-06-30 20:08:26+00:00
- **Updated**: 2015-08-18 06:06:13+00:00
- **Authors**: Jingyan Wang, Yihua Zhou, Ming Yin, Shaochang Chen, Benjamin Edwards
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we study the problem of using contextual da- ta points of a data point for its classification problem. We propose to represent a data point as the sparse linear reconstruction of its context, and learn the sparse context to gather with a linear classifier in a su- pervised way to increase its discriminative ability. We proposed a novel formulation for context learning, by modeling the learning of context reconstruction coefficients and classifier in a unified objective. In this objective, the reconstruction error is minimized and the coefficient spar- sity is encouraged. Moreover, the hinge loss of the classifier is minimized and the complexity of the classifier is reduced. This objective is opti- mized by an alternative strategy in an iterative algorithm. Experiments on three benchmark data set show its advantage over state-of-the-art context-based data representation and classification methods.



