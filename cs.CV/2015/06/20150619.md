# Arxiv Papers in cs.CV on 2015-06-19
### To Know Where We Are: Vision-Based Positioning in Outdoor Environments
- **Arxiv ID**: http://arxiv.org/abs/1506.05870v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05870v1)
- **Published**: 2015-06-19 03:11:33+00:00
- **Updated**: 2015-06-19 03:11:33+00:00
- **Authors**: Kuan-Wen Chen, Chun-Hsin Wang, Xiao Wei, Qiao Liang, Ming-Hsuan Yang, Chu-Song Chen, Yi-Ping Hung
- **Comment**: 11 pages, 14 figures
- **Journal**: None
- **Summary**: Augmented reality (AR) displays become more and more popular recently, because of its high intuitiveness for humans and high-quality head-mounted display have rapidly developed. To achieve such displays with augmented information, highly accurate image registration or ego-positioning are required, but little attention have been paid for out-door environments. This paper presents a method for ego-positioning in outdoor environments with low cost monocular cameras. To reduce the computational and memory requirements as well as the communication overheads, we formulate the model compression algorithm as a weighted k-cover problem for better preserving model structures. Specifically for real-world vision-based positioning applications, we consider the issues with large scene change and propose a model update algorithm to tackle these problems. A long- term positioning dataset with more than one month, 106 sessions, and 14,275 images is constructed. Based on both local and up-to-date models constructed in our approach, extensive experimental results show that high positioning accuracy (mean ~ 30.9cm, stdev. ~ 15.4cm) can be achieved, which outperforms existing vision-based algorithms.



### New Descriptor for Glomerulus Detection in Kidney Microscopy Image
- **Arxiv ID**: http://arxiv.org/abs/1506.05920v1
- **DOI**: 10.1186/s12859-015-0739-1
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05920v1)
- **Published**: 2015-06-19 09:03:48+00:00
- **Updated**: 2015-06-19 09:03:48+00:00
- **Authors**: Tsuyoshi Kato, Raissa Relator, Hayliang Ngouv, Yoshihiro Hirohashi, Tetsuhiro Kakimoto, Kinya Okada
- **Comment**: None
- **Journal**: BMC Bioinformatics, 16:316, 2015
- **Summary**: Glomerulus detection is a key step in histopathological evaluation of microscopy images of kidneys. However, the task of automatic detection of glomeruli poses challenges due to the disparity in sizes and shapes of glomeruli in renal sections. Moreover, extensive variations of their intensities due to heterogeneity in immunohistochemistry staining are also encountered. Despite being widely recognized as a powerful descriptor for general object detection, the rectangular histogram of oriented gradients (Rectangular HOG) suffers from many false positives due to the aforementioned difficulties in the context of glomerulus detection.   A new descriptor referred to as Segmental HOG is developed to perform a comprehensive detection of hundreds of glomeruli in images of whole kidney sections. The new descriptor possesses flexible blocks that can be adaptively fitted to input images to acquire robustness to deformations of glomeruli. Moreover, the novel segmentation technique employed herewith generates high quality segmentation outputs and the algorithm is assured to converge to an optimal solution. Consequently, experiments using real world image data reveal that Segmental HOG achieves significant improvements in detection performance compared to Rectangular HOG.   The proposed descriptor and method for glomeruli detection present promising results and is expected to be useful in pathological evaluation.



### Exploring the influence of scale on artist attribution
- **Arxiv ID**: http://arxiv.org/abs/1506.05929v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05929v1)
- **Published**: 2015-06-19 09:27:08+00:00
- **Updated**: 2015-06-19 09:27:08+00:00
- **Authors**: Nanne van Noord, Eric Postma
- **Comment**: None
- **Journal**: None
- **Summary**: Previous work has shown that the artist of an artwork can be identified by use of computational methods that analyse digital images. However, the digitised artworks are often investigated at a coarse scale discarding many of the important details that may define an artist's style. In recent years high resolution images of artworks have become available, which, combined with increased processing power and new computational techniques, allow us to analyse digital images of artworks at a very fine scale. In this work we train and evaluate a Convolutional Neural Network (CNN) on the task of artist attribution using artwork images of varying resolutions. To this end, we combine two existing methods to enable the application of high resolution images to CNNs. By comparing the attribution performances obtained at different scales, we find that in most cases finer scales are beneficial to the attribution performance, whereas for a minority of the artists, coarser scales appear to be preferable. We conclude that artist attribution would benefit from a multi-scale CNN approach which vastly expands the possibilities for computational art forensics.



### Scene-adaptive Coded Apertures Imaging
- **Arxiv ID**: http://arxiv.org/abs/1506.05942v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.05942v2)
- **Published**: 2015-06-19 10:09:45+00:00
- **Updated**: 2015-12-18 02:13:08+00:00
- **Authors**: Xuehui Wang, Jinli Suo, Jingyi Yu, Yongdong Zhang, Qionghai Dai
- **Comment**: This paper has been withdrawn by the author due to bad motivation
  proof and poor experiment performance
- **Journal**: None
- **Summary**: Coded aperture imaging systems have recently shown great success in recovering scene depth and extending the depth-of-field. The ideal pattern, however, would have to serve two conflicting purposes: 1) be broadband to ensure robust deconvolution and 2) has sufficient zero-crossings for a high depth discrepancy. This paper presents a simple but effective scene-adaptive coded aperture solution to bridge this gap. We observe that the geometric structures in a natural scene often exhibit only a few edge directions, and the successive frames are closely correlated. Therefore we adopt a spatial partitioning and temporal propagation scheme. In each frame, we address one principal direction by applying depth-discriminative codes along it and broadband codes along its orthogonal direction. Since within a frame only the regions with edge direction corresponding to its aperture code behaves well, we utilize the close among-frame correlation to propagate the high quality single frame results temporally to obtain high performance over the whole image lattice. To physically implement this scheme, we use a Liquid Crystal on Silicon (LCoS) microdisplay that permits fast changing pattern codes. Firstly, we capture the scene with a pinhole and analyze the scene content to determine primary edge orientations. Secondly, we sequentially apply the proposed coding scheme with these orientations in the following frames. Experiments on both synthetic and real scenes show that our technique is able to combine advantages of the state-of-the-art patterns for recovering better quality depth map and all-focus images.



### Stereoscopic Cinema
- **Arxiv ID**: http://arxiv.org/abs/1506.06001v1
- **DOI**: 10.1007/978-3-642-12392-4
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06001v1)
- **Published**: 2015-06-19 13:46:23+00:00
- **Updated**: 2015-06-19 13:46:23+00:00
- **Authors**: Frédéric Devernay, Paul Beardsley
- **Comment**: Published as Ronfard, R\'emi and Taubin, Gabriel. Image and Geometry
  Processing for 3-D Cinematography, 5, Springer Berlin Heidelberg, pp.11-51,
  2010, Geometry and Computing, 978-3-642-12392-4
- **Journal**: None
- **Summary**: Stereoscopic cinema has seen a surge of activity in recent years, and for the first time all of the major Hollywood studios released 3-D movies in 2009. This is happening alongside the adoption of 3-D technology for sports broadcasting, and the arrival of 3-D TVs for the home. Two previous attempts to introduce 3-D cinema in the 1950s and the 1980s failed because the contemporary technology was immature and resulted in viewer discomfort. But current technologies -- such as accurately-adjustable 3-D camera rigs with onboard computers to automatically inform a camera operator of inappropriate stereoscopic shots, digital processing for post-shooting rectification of the 3-D imagery, digital projectors for accurate positioning of the two stereo projections on the cinema screen, and polarized silver screens to reduce cross-talk between the viewers left- and right-eyes -- mean that the viewer experience is at a much higher level of quality than in the past. Even so, creation of stereoscopic cinema is an open, active research area, and there are many challenges from acquisition to post-production to automatic adaptation for different-sized display. This chapter describes the current state-of-the-art in stereoscopic cinema, and directions of future work.



### Crowd Flow Segmentation in Compressed Domain using CRF
- **Arxiv ID**: http://arxiv.org/abs/1506.06006v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06006v1)
- **Published**: 2015-06-19 14:01:24+00:00
- **Updated**: 2015-06-19 14:01:24+00:00
- **Authors**: Srinivas S. S. Kruthiventi, R. Venkatesh Babu
- **Comment**: In IEEE International Conference on Image Processing (ICIP), 2015
- **Journal**: None
- **Summary**: Crowd flow segmentation is an important step in many video surveillance tasks. In this work, we propose an algorithm for segmenting flows in H.264 compressed videos in a completely unsupervised manner. Our algorithm works on motion vectors which can be obtained by partially decoding the compressed video without extracting any additional features. Our approach is based on modelling the motion vector field as a Conditional Random Field (CRF) and obtaining oriented motion segments by finding the optimal labelling which minimises the global energy of CRF. These oriented motion segments are recursively merged based on gradient across their boundaries to obtain the final flow segments. This work in compressed domain can be easily extended to pixel domain by substituting motion vectors with motion based features like optical flow. The proposed algorithm is experimentally evaluated on a standard crowd flow dataset and its superior performance in both accuracy and computational time are demonstrated through quantitative results.



### moco: Fast Motion Correction for Calcium Imaging
- **Arxiv ID**: http://arxiv.org/abs/1506.06039v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.06039v1)
- **Published**: 2015-06-19 15:03:13+00:00
- **Updated**: 2015-06-19 15:03:13+00:00
- **Authors**: Alexander Dubbs, James Guevara, Darcy S. Peterka, Rafael Yuste
- **Comment**: None
- **Journal**: None
- **Summary**: Motion correction is the first in a pipeline of algorithms to analyze calcium imaging videos and extract biologically relevant information, for example the network structure of the neurons therein. Fast motion correction would be especially critical for closed-loop activity triggered stimulation experiments, where accurate detection and targeting of specific cells in necessary. Our algorithm uses a Fourier-transform approach, and its efficiency derives from a combination of judicious downsampling and the accelerated computation of many $L_2$ norms using dynamic programming and two-dimensional, fft-accelerated convolutions. Its accuracy is comparable to that of established community-used algorithms, and it is more stable to large translational motions. It is programmed in Java and is compatible with ImageJ.



### A general framework for the IT-based clustering methods
- **Arxiv ID**: http://arxiv.org/abs/1506.06068v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.06068v1)
- **Published**: 2015-06-19 16:03:31+00:00
- **Updated**: 2015-06-19 16:03:31+00:00
- **Authors**: Teng Qiu, Yongjie Li
- **Comment**: 17 pages
- **Journal**: None
- **Summary**: Previously, we proposed a physically inspired rule to organize the data points in a sparse yet effective structure, called the in-tree (IT) graph, which is able to capture a wide class of underlying cluster structures in the datasets, especially for the density-based datasets. Although there are some redundant edges or lines between clusters requiring to be removed by computer, this IT graph has a big advantage compared with the k-nearest-neighborhood (k-NN) or the minimal spanning tree (MST) graph, in that the redundant edges in the IT graph are much more distinguishable and thus can be easily determined by several methods previously proposed by us.   In this paper, we propose a general framework to re-construct the IT graph, based on an initial neighborhood graph, such as the k-NN or MST, etc, and the corresponding graph distances. For this general framework, our previous way of constructing the IT graph turns out to be a special case of it. This general framework 1) can make the IT graph capture a wider class of underlying cluster structures in the datasets, especially for the manifolds, and 2) should be more effective to cluster the sparse or graph-based datasets.



### Graph-based compression of dynamic 3D point cloud sequences
- **Arxiv ID**: http://arxiv.org/abs/1506.06096v1
- **DOI**: 10.1109/TIP.2016.2529506
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1506.06096v1)
- **Published**: 2015-06-19 17:31:34+00:00
- **Updated**: 2015-06-19 17:31:34+00:00
- **Authors**: Dorina Thanou, Philip A. Chou, Pascal Frossard
- **Comment**: None
- **Journal**: None
- **Summary**: This paper addresses the problem of compression of 3D point cloud sequences that are characterized by moving 3D positions and color attributes. As temporally successive point cloud frames are similar, motion estimation is key to effective compression of these sequences. It however remains a challenging problem as the point cloud frames have varying numbers of points without explicit correspondence information. We represent the time-varying geometry of these sequences with a set of graphs, and consider 3D positions and color attributes of the points clouds as signals on the vertices of the graphs. We then cast motion estimation as a feature matching problem between successive graphs. The motion is estimated on a sparse set of representative vertices using new spectral graph wavelet descriptors. A dense motion field is eventually interpolated by solving a graph-based regularization problem. The estimated motion is finally used for removing the temporal redundancy in the predictive coding of the 3D positions and the color characteristics of the point cloud sequences. Experimental results demonstrate that our method is able to accurately estimate the motion between consecutive frames. Moreover, motion estimation is shown to bring significant improvement in terms of the overall compression performance of the sequence. To the best of our knowledge, this is the first paper that exploits both the spatial correlation inside each frame (through the graph) and the temporal correlation between the frames (through the motion estimation) to compress the color and the geometry of 3D point cloud sequences in an efficient way.



### CO2 Forest: Improved Random Forest by Continuous Optimization of Oblique Splits
- **Arxiv ID**: http://arxiv.org/abs/1506.06155v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.06155v2)
- **Published**: 2015-06-19 20:42:47+00:00
- **Updated**: 2015-06-24 21:23:43+00:00
- **Authors**: Mohammad Norouzi, Maxwell D. Collins, David J. Fleet, Pushmeet Kohli
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel algorithm for optimizing multivariate linear threshold functions as split functions of decision trees to create improved Random Forest classifiers. Standard tree induction methods resort to sampling and exhaustive search to find good univariate split functions. In contrast, our method computes a linear combination of the features at each node, and optimizes the parameters of the linear combination (oblique) split functions by adopting a variant of latent variable SVM formulation. We develop a convex-concave upper bound on the classification loss for a one-level decision tree, and optimize the bound by stochastic gradient descent at each internal node of the tree. Forests of up to 1000 Continuously Optimized Oblique (CO2) decision trees are created, which significantly outperform Random Forest with univariate splits and previous techniques for constructing oblique trees. Experimental results are reported on multi-class classification benchmarks and on Labeled Faces in the Wild (LFW) dataset.



