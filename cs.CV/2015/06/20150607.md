# Arxiv Papers in cs.CV on 2015-06-07
### Describing Common Human Visual Actions in Images
- **Arxiv ID**: http://arxiv.org/abs/1506.02203v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.02203v1)
- **Published**: 2015-06-07 00:33:23+00:00
- **Updated**: 2015-06-07 00:33:23+00:00
- **Authors**: Matteo Ruggero Ronchi, Pietro Perona
- **Comment**: None
- **Journal**: None
- **Summary**: Which common human actions and interactions are recognizable in monocular still images? Which involve objects and/or other people? How many is a person performing at a time? We address these questions by exploring the actions and interactions that are detectable in the images of the MS COCO dataset. We make two main contributions. First, a list of 140 common `visual actions', obtained by analyzing the largest on-line verb lexicon currently available for English (VerbNet) and human sentences used to describe images in MS COCO. Second, a complete set of annotations for those `visual actions', composed of subject-object and associated verb, which we call COCO-a (a for `actions'). COCO-a is larger than existing action datasets in terms of number of actions and instances of these actions, and is unique because it is data-driven, rather than experimenter-biased. Other unique features are that it is exhaustive, and that all subjects and objects are localized. A statistical analysis of the accuracy of our annotations and of each action, interaction and subject-object combination is provided.



### Boosting Optical Character Recognition: A Super-Resolution Approach
- **Arxiv ID**: http://arxiv.org/abs/1506.02211v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.3; I.4.9
- **Links**: [PDF](http://arxiv.org/pdf/1506.02211v1)
- **Published**: 2015-06-07 02:29:45+00:00
- **Updated**: 2015-06-07 02:29:45+00:00
- **Authors**: Chao Dong, Ximei Zhu, Yubin Deng, Chen Change Loy, Yu Qiao
- **Comment**: 5 pages, 8 figures
- **Journal**: None
- **Summary**: Text image super-resolution is a challenging yet open research problem in the computer vision community. In particular, low-resolution images hamper the performance of typical optical character recognition (OCR) systems. In this article, we summarize our entry to the ICDAR2015 Competition on Text Image Super-Resolution. Experiments are based on the provided ICDAR2015 TextSR dataset and the released Tesseract-OCR 3.02 system. We report that our winning entry of text image super-resolution framework has largely improved the OCR performance with low-resolution images used as input, reaching an OCR accuracy score of 77.19%, which is comparable with that of using the original high-resolution images 78.80%.



### Well-posedness of a nonlinear integro-differential problem and its rearranged formulation
- **Arxiv ID**: http://arxiv.org/abs/1506.02247v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.02247v2)
- **Published**: 2015-06-07 10:23:58+00:00
- **Updated**: 2016-04-08 10:11:18+00:00
- **Authors**: Gonzalo Galiano, Emanuele Schiavi, Juli√°n Velasco
- **Comment**: Final version. To appear in Nolinear Analysis Real World Applications
  (2016)
- **Journal**: None
- **Summary**: We study the existence and uniqueness of solutions of a nonlinear integro-differential problem which we reformulate introducing the notion of the decreasing rearrangement of the solution. A dimensional reduction of the problem is obtained and a detailed analysis of the properties of the solutions of the model is provided. Finally, a fast numerical method is devised and implemented to show the performance of the model when typical image processing tasks such as filtering and segmentation are performed.



### Visual Learning of Arithmetic Operations
- **Arxiv ID**: http://arxiv.org/abs/1506.02264v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.02264v2)
- **Published**: 2015-06-07 13:44:15+00:00
- **Updated**: 2015-11-27 12:18:48+00:00
- **Authors**: Yedid Hoshen, Shmuel Peleg
- **Comment**: To appear in AAAI 2016
- **Journal**: Proc. AAAI'16, Phoenix, Feb. 2016, pp. 3733-3739
- **Summary**: A simple Neural Network model is presented for end-to-end visual learning of arithmetic operations from pictures of numbers. The input consists of two pictures, each showing a 7-digit number. The output, also a picture, displays the number showing the result of an arithmetic operation (e.g., addition or subtraction) on the two input numbers. The concepts of a number, or of an operator, are not explicitly introduced. This indicates that addition is a simple cognitive task, which can be learned visually using a very small number of neurons.   Other operations, e.g., multiplication, were not learnable using this architecture. Some tasks were not learnable end-to-end (e.g., addition with Roman numerals), but were easily learnable once broken into two separate sub-tasks: a perceptual \textit{Character Recognition} and cognitive \textit{Arithmetic} sub-tasks. This indicates that while some tasks may be easily learnable end-to-end, other may need to be broken into sub-tasks.



### Randomized Structural Sparsity based Support Identification with Applications to Locating Activated or Discriminative Brain Areas: A Multi-center Reproducibility Study
- **Arxiv ID**: http://arxiv.org/abs/1506.02265v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T01, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1506.02265v1)
- **Published**: 2015-06-07 13:53:54+00:00
- **Updated**: 2015-06-07 13:53:54+00:00
- **Authors**: Yilun Wang, Sheng Zhang, Junjie Zheng, Heng Chen, Huafu Chen
- **Comment**: arXiv admin note: text overlap with arXiv:1410.4650
- **Journal**: None
- **Summary**: In this paper, we focus on how to locate the relevant or discriminative brain regions related with external stimulus or certain mental decease, which is also called support identification, based on the neuroimaging data. The main difficulty lies in the extremely high dimensional voxel space and relatively few training samples, easily resulting in an unstable brain region discovery (or called feature selection in context of pattern recognition). When the training samples are from different centers and have betweencenter variations, it will be even harder to obtain a reliable and consistent result. Corresponding, we revisit our recently proposed algorithm based on stability selection and structural sparsity. It is applied to the multi-center MRI data analysis for the first time. A consistent and stable result is achieved across different centers despite the between-center data variation while many other state-of-the-art methods such as two sample t-test fail. Moreover, we have empirically showed that the performance of this algorithm is robust and insensitive to several of its key parameters. In addition, the support identification results on both functional MRI and structural MRI are interpretable and can be the potential biomarkers.



