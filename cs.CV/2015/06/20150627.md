# Arxiv Papers in cs.CV on 2015-06-27
### A Novel Approach for Stable Selection of Informative Redundant Features from High Dimensional fMRI Data
- **Arxiv ID**: http://arxiv.org/abs/1506.08301v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML, I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1506.08301v2)
- **Published**: 2015-06-27 15:28:31+00:00
- **Updated**: 2016-05-25 02:37:39+00:00
- **Authors**: Yilun Wang, Zhiqiang Li, Yifeng Wang, Xiaona Wang, Junjie Zheng, Xujuan Duan, Huafu Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Feature selection is among the most important components because it not only helps enhance the classification accuracy, but also or even more important provides potential biomarker discovery. However, traditional multivariate methods is likely to obtain unstable and unreliable results in case of an extremely high dimensional feature space and very limited training samples, where the features are often correlated or redundant. In order to improve the stability, generalization and interpretations of the discovered potential biomarker and enhance the robustness of the resultant classifier, the redundant but informative features need to be also selected. Therefore we introduced a novel feature selection method which combines a recent implementation of the stability selection approach and the elastic net approach. The advantage in terms of better control of false discoveries and missed discoveries of our approach, and the resulted better interpretability of the obtained potential biomarker is verified in both synthetic and real fMRI experiments. In addition, we are among the first to demonstrate the robustness of feature selection benefiting from the incorporation of stability selection and also among the first to demonstrate the possible unrobustness of the classical univariate two-sample t-test method. Specifically, we show the robustness of our feature selection results in existence of noisy (wrong) training labels, as well as the robustness of the resulted classifier based on our feature selection results in the existence of data variation, demonstrated by a multi-center attention-deficit/hyperactivity disorder (ADHD) fMRI data.



### Keypoint Encoding for Improved Feature Extraction from Compressed Video at Low Bitrates
- **Arxiv ID**: http://arxiv.org/abs/1506.08316v2
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1506.08316v2)
- **Published**: 2015-06-27 17:33:34+00:00
- **Updated**: 2016-03-04 16:43:42+00:00
- **Authors**: Jianshu Chao, Eckehard Steinbach
- **Comment**: None
- **Journal**: None
- **Summary**: In many mobile visual analysis applications, compressed video is transmitted over a communication network and analyzed by a server. Typical processing steps performed at the server include keypoint detection, descriptor calculation, and feature matching. Video compression has been shown to have an adverse effect on feature-matching performance. The negative impact of compression can be reduced by using the keypoints extracted from the uncompressed video to calculate descriptors from the compressed video. Based on this observation, we propose to provide these keypoints to the server as side information and to extract only the descriptors from the compressed video. First, we introduce four different frame types for keypoint encoding to address different types of changes in video content. These frame types represent a new scene, the same scene, a slowly changing scene, or a rapidly moving scene and are determined by comparing features between successive video frames. Then, we propose Intra, Skip and Inter modes of encoding the keypoints for different frame types. For example, keypoints for new scenes are encoded using the Intra mode, and keypoints for unchanged scenes are skipped. As a result, the bitrate of the side information related to keypoint encoding is significantly reduced. Finally, we present pairwise matching and image retrieval experiments conducted to evaluate the performance of the proposed approach using the Stanford mobile augmented reality dataset and 720p format videos. The results show that the proposed approach offers significantly improved feature matching and image retrieval performance at a given bitrate.



