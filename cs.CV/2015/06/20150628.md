# Arxiv Papers in cs.CV on 2015-06-28
### Occlusion Coherence: Detecting and Localizing Occluded Faces
- **Arxiv ID**: http://arxiv.org/abs/1506.08347v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.08347v2)
- **Published**: 2015-06-28 03:12:34+00:00
- **Updated**: 2016-08-25 00:27:35+00:00
- **Authors**: Golnaz Ghiasi, Charless C. Fowlkes
- **Comment**: None
- **Journal**: None
- **Summary**: The presence of occluders significantly impacts object recognition accuracy. However, occlusion is typically treated as an unstructured source of noise and explicit models for occluders have lagged behind those for object appearance and shape. In this paper we describe a hierarchical deformable part model for face detection and landmark localization that explicitly models part occlusion. The proposed model structure makes it possible to augment positive training data with large numbers of synthetically occluded instances. This allows us to easily incorporate the statistics of occlusion patterns in a discriminatively trained model. We test the model on several benchmarks for landmark localization and detection including challenging new data sets featuring significant occlusion. We find that the addition of an explicit occlusion model yields a detection system that outperforms existing approaches for occluded instances while maintaining competitive accuracy in detection and landmark localization for unoccluded instances.



### A note on patch-based low-rank minimization for fast image denoising
- **Arxiv ID**: http://arxiv.org/abs/1506.08353v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.08353v2)
- **Published**: 2015-06-28 03:52:42+00:00
- **Updated**: 2018-02-21 03:14:36+00:00
- **Authors**: Haijuan Hu, Jacques Froment, Quansheng Liu
- **Comment**: 4pages (two columns)
- **Journal**: None
- **Summary**: Patch-based low-rank minimization for image processing attracts much attention in recent years. The minimization of the matrix rank coupled with the Frobenius norm data fidelity can be solved by the hard thresholding filter with principle component analysis (PCA) or singular value decomposition (SVD). Based on this idea, we propose a patch-based low-rank minimization method for image denoising. The main denoising process is stated in three equivalent way: PCA, SVD and low-rank minimization. Compared to recent patch-based sparse representation methods, experiments demonstrate that the proposed method is rather rapid, and it is effective for a variety of natural grayscale images and color images, especially for texture parts in images. Further improvements of this method are also given. In addition, due to the simplicity of this method, we could provide an explanation of the choice of the threshold parameter, estimation of PSNR values, and give other insights into this method.



### Deep-Plant: Plant Identification with convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1506.08425v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.08425v1)
- **Published**: 2015-06-28 16:58:47+00:00
- **Updated**: 2015-06-28 16:58:47+00:00
- **Authors**: Sue Han Lee, Chee Seng Chan, Paul Wilkin, Paolo Remagnino
- **Comment**: 6 pages, 8 figures, accepted as oral presentation in ICIP2015,
  Qu\'ebec City, Canada
- **Journal**: None
- **Summary**: This paper studies convolutional neural networks (CNN) to learn unsupervised feature representations for 44 different plant species, collected at the Royal Botanic Gardens, Kew, England. To gain intuition on the chosen features from the CNN model (opposed to a 'black box' solution), a visualisation technique based on the deconvolutional networks (DN) is utilized. It is found that venations of different order have been chosen to uniquely represent each of the plant species. Experimental results using these CNN features with different classifiers show consistency and superiority compared to the state-of-the art solutions which rely on hand-crafted features.



### Unsupervised Semantic Parsing of Video Collections
- **Arxiv ID**: http://arxiv.org/abs/1506.08438v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.08438v4)
- **Published**: 2015-06-28 19:16:38+00:00
- **Updated**: 2016-01-27 12:54:15+00:00
- **Authors**: Ozan Sener, Amir Zamir, Silvio Savarese, Ashutosh Saxena
- **Comment**: None
- **Journal**: None
- **Summary**: Human communication typically has an underlying structure. This is reflected in the fact that in many user generated videos, a starting point, ending, and certain objective steps between these two can be identified. In this paper, we propose a method for parsing a video into such semantic steps in an unsupervised way. The proposed method is capable of providing a semantic "storyline" of the video composed of its objective steps. We accomplish this using both visual and language cues in a joint generative model. The proposed method can also provide a textual description for each of the identified semantic steps and video segments. We evaluate this method on a large number of complex YouTube videos and show results of unprecedented quality for this intricate and impactful problem.



