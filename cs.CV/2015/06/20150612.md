# Arxiv Papers in cs.CV on 2015-06-12
### Place classification with a graph regularized deep neural network model
- **Arxiv ID**: http://arxiv.org/abs/1506.03899v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1506.03899v1)
- **Published**: 2015-06-12 05:45:36+00:00
- **Updated**: 2015-06-12 05:45:36+00:00
- **Authors**: Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Place classification is a fundamental ability that a robot should possess to carry out effective human-robot interactions. It is a nontrivial classification problem which has attracted many research. In recent years, there is a high exploitation of Artificial Intelligent algorithms in robotics applications. Inspired by the recent successes of deep learning methods, we propose an end-to-end learning approach for the place classification problem. With the deep architectures, this methodology automatically discovers features and contributes in general to higher classification accuracies. The pipeline of our approach is composed of three parts. Firstly, we construct multiple layers of laser range data to represent the environment information in different levels of granularity. Secondly, each layer of data is fed into a deep neural network model for classification, where a graph regularization is imposed to the deep architecture for keeping local consistency between adjacent samples. Finally, the predicted labels obtained from all the layers are fused based on confidence trees to maximize the overall confidence. Experimental results validate the effective- ness of our end-to-end place classification framework in which both the multi-layer structure and the graph regularization promote the classification performance. Furthermore, results show that the features automatically learned from the raw input range data can achieve competitive results to the features constructed based on statistical and geometrical information.



### A Novel Hybrid Approach for Cephalometric Landmark Detection
- **Arxiv ID**: http://arxiv.org/abs/1506.03936v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.03936v1)
- **Published**: 2015-06-12 08:40:38+00:00
- **Updated**: 2015-06-12 08:40:38+00:00
- **Authors**: Mahshid Majd, Farzaneh Shoeleh
- **Comment**: None
- **Journal**: None
- **Summary**: Cephalometric analysis has an important role in dentistry and especially in orthodontics as a treatment planning tool to gauge the size and special relationships of the teeth, jaws and cranium. The first step of using such analyses is localizing some important landmarks known as cephalometric landmarks on craniofacial in x-ray image. The past decade has seen a growing interest in automating this process. In this paper, a novel hybrid approach is proposed for automatic detection of cephalometric landmarks. Here, the landmarks are categorized into three main sets according to their anatomical characteristics and usage in well-known cephalometric analyses. Consequently, to have a reliable and accurate detection system, three methods named edge tracing, weighted template matching, and analysis based estimation are designed, each of which is consistent and well-suited for one category. Edge tracing method is suggested to predict those landmarks which are located on edges. Weighted template matching method is well-suited for landmarks located in an obvious and specific structure which can be extracted or searchable in a given x-ray image. The last but not the least method is named analysis based estimation. This method is based on the fact that in cephalometric analyses the relations between landmarks are used and the locations of some landmarks are never used individually. Therefore the third suggested method has a novelty in estimating the desired relations directly. The effectiveness of the proposed approach is compared with the state of the art methods and the results were promising especially in real world applications.



### Technical Report: Image Captioning with Semantically Similar Images
- **Arxiv ID**: http://arxiv.org/abs/1506.03995v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.03995v1)
- **Published**: 2015-06-12 11:51:16+00:00
- **Updated**: 2015-06-12 11:51:16+00:00
- **Authors**: Martin Kolář, Michal Hradiš, Pavel Zemčík
- **Comment**: 3 pages
- **Journal**: None
- **Summary**: This report presents our submission to the MS COCO Captioning Challenge 2015. The method uses Convolutional Neural Network activations as an embedding to find semantically similar images. From these images, the most typical caption is selected based on unigram frequencies. Although the method received low scores with automated evaluation metrics and in human assessed average correctness, it is competitive in the ratio of captions which pass the Turing test and which are assessed as better or equal to human captions.



### Sparse Multi-layer Image Approximation: Facial Image Compression
- **Arxiv ID**: http://arxiv.org/abs/1506.03998v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1506.03998v1)
- **Published**: 2015-06-12 12:10:57+00:00
- **Updated**: 2015-06-12 12:10:57+00:00
- **Authors**: Sohrab Ferdowsi, Svyatoslav Voloshynovskiy, Dimche Kostadinov
- **Comment**: Submitted to the MLSP 2015
- **Journal**: None
- **Summary**: We propose a scheme for multi-layer representation of images. The problem is first treated from an information-theoretic viewpoint where we analyze the behavior of different sources of information under a multi-layer data compression framework and compare it with a single-stage (shallow) structure. We then consider the image data as the source of information and link the proposed representation scheme to the problem of multi-layer dictionary learning for visual data. For the current work we focus on the problem of image compression for a special class of images where we report a considerable performance boost in terms of PSNR at high compression ratios in comparison with the JPEG2000 codec.



### Towards Benchmarking Scene Background Initialization
- **Arxiv ID**: http://arxiv.org/abs/1506.04051v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04051v1)
- **Published**: 2015-06-12 15:52:46+00:00
- **Updated**: 2015-06-12 15:52:46+00:00
- **Authors**: Lucia Maddalena, Alfredo Petrosino
- **Comment**: 6 pages, SBI dataset, SBMI2015 Workshop
- **Journal**: None
- **Summary**: Given a set of images of a scene taken at different times, the availability of an initial background model that describes the scene without foreground objects is the prerequisite for a wide range of applications, ranging from video surveillance to computational photography. Even though several methods have been proposed for scene background initialization, the lack of a common groundtruthed dataset and of a common set of metrics makes it difficult to compare their performance. To move first steps towards an easy and fair comparison of these methods, we assembled a dataset of sequences frequently adopted for background initialization, selected or created ground truths for quantitative evaluation through a selected suite of metrics, and compared results obtained by some existing methods, making all the material publicly available.



### CloudCV: Large Scale Distributed Computer Vision as a Cloud Service
- **Arxiv ID**: http://arxiv.org/abs/1506.04130v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC
- **Links**: [PDF](http://arxiv.org/pdf/1506.04130v3)
- **Published**: 2015-06-12 19:50:07+00:00
- **Updated**: 2017-02-13 07:30:56+00:00
- **Authors**: Harsh Agrawal, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali, Prakriti Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra
- **Comment**: None
- **Journal**: None
- **Summary**: We are witnessing a proliferation of massive visual data. Unfortunately scaling existing computer vision algorithms to large datasets leaves researchers repeatedly solving the same algorithmic, logistical, and infrastructural problems. Our goal is to democratize computer vision; one should not have to be a computer vision, big data and distributed computing expert to have access to state-of-the-art distributed computer vision algorithms. We present CloudCV, a comprehensive system to provide access to state-of-the-art distributed computer vision algorithms as a cloud service through a Web Interface and APIs.



### Deep Structured Models For Group Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/1506.04191v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.04191v1)
- **Published**: 2015-06-12 22:18:08+00:00
- **Updated**: 2015-06-12 22:18:08+00:00
- **Authors**: Zhiwei Deng, Mengyao Zhai, Lei Chen, Yuhao Liu, Srikanth Muralidharan, Mehrsan Javan Roshtkhari, Greg Mori
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a deep neural-network-based hierarchical graphical model for individual and group activity recognition in surveillance scenes. Deep networks are used to recognize the actions of individual people in a scene. Next, a neural-network-based hierarchical graphical model refines the predicted labels for each class by considering dependencies between the classes. This refinement step mimics a message-passing step similar to inference in a probabilistic graphical model. We show that this approach can be effective in group activity recognition, with the deep graphical model improving recognition rates over baseline methods.



