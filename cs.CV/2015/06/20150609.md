# Arxiv Papers in cs.CV on 2015-06-09
### Inverting Visual Representations with Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1506.02753v4
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1506.02753v4)
- **Published**: 2015-06-09 02:31:40+00:00
- **Updated**: 2016-04-26 23:30:11+00:00
- **Authors**: Alexey Dosovitskiy, Thomas Brox
- **Comment**: Version 4 - final version to appear in CVPR-2016. Visually better
  results obtained with feature similarity and adversarial training are in a
  different paper - arXiv:1602.02644
- **Journal**: None
- **Summary**: Feature representations, both hand-designed and learned ones, are often hard to analyze and interpret, even when they are extracted from visual data. We propose a new approach to study image representations by inverting them with an up-convolutional neural network. We apply the method to shallow representations (HOG, SIFT, LBP), as well as to deep networks. For shallow representations our approach provides significantly better reconstructions than existing methods, revealing that there is surprisingly rich information contained in these features. Inverting a deep network trained on ImageNet provides several insights into the properties of the feature representation learned by the network. Most strikingly, the colors and the rough contours of an image can be reconstructed from activations in higher network layers and even from the predicted class probabilities.



### Fast Geometric Fit Algorithm for Sphere Using Exact Solution
- **Arxiv ID**: http://arxiv.org/abs/1506.02776v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.02776v1)
- **Published**: 2015-06-09 05:03:47+00:00
- **Updated**: 2015-06-09 05:03:47+00:00
- **Authors**: Sumith YD
- **Comment**: None
- **Journal**: None
- **Summary**: Sphere fitting is a common problem in almost all science and engineering disciplines. Most of methods available are iterative in behavior. This involves fitting of the parameters in a least square sense or in a geometric sense. Here we extend the methods of Thomas Chan and Landau who fitted the 2D data using circle. This work closely resemble their work in redefining the error estimate and solving the sphere fitting problem exactly. The solutions for center and radius of the sphere can be found exactly and the equations can be hard coded for high performance. We have also shown some comparison with other popular methods and how this method behaves.



### Flowing ConvNets for Human Pose Estimation in Videos
- **Arxiv ID**: http://arxiv.org/abs/1506.02897v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.02897v2)
- **Published**: 2015-06-09 13:17:33+00:00
- **Updated**: 2015-11-08 16:52:59+00:00
- **Authors**: Tomas Pfister, James Charles, Andrew Zisserman
- **Comment**: ICCV'15
- **Journal**: None
- **Summary**: The objective of this work is human pose estimation in videos, where multiple frames are available. We investigate a ConvNet architecture that is able to benefit from temporal context by combining information across the multiple frames using optical flow.   To this end we propose a network architecture with the following novelties: (i) a deeper network than previously investigated for regressing heatmaps; (ii) spatial fusion layers that learn an implicit spatial model; (iii) optical flow is used to align heatmap predictions from neighbouring frames; and (iv) a final parametric pooling layer which learns to combine the aligned heatmaps into a pooled confidence map.   We show that this architecture outperforms a number of others, including one that uses optical flow solely at the input layers, one that regresses joint coordinates directly, and one that predicts heatmaps without spatial fusion.   The new architecture outperforms the state of the art by a large margin on three video pose estimation datasets, including the very challenging Poses in the Wild dataset, and outperforms other deep methods that don't use a graphical model on the single-image FLIC benchmark (and also Chen & Yuille and Tompson et al. in the high precision region).



### Compact Shape Trees: A Contribution to the Forest of Shape Correspondences and Matching Methods
- **Arxiv ID**: http://arxiv.org/abs/1506.02923v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.02923v1)
- **Published**: 2015-06-09 14:18:01+00:00
- **Updated**: 2015-06-09 14:18:01+00:00
- **Authors**: Abdulrahman Oladipupo Ibraheem
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel technique, termed compact shape trees, for computing correspondences of single-boundary 2-D shapes in O(n2) time. Together with zero or more features defined at each of n sample points on the shape's boundary, the compact shape tree of a shape comprises the O(n) collection of vectors emanating from any of the sample points on the shape's boundary to the rest of the sample points on the boundary. As it turns out, compact shape trees have a number of elegant properties both in the spatial and frequency domains. In particular, via a simple vector-algebraic argument, we show that the O(n) collection of vectors in a compact shape tree possesses at least the same discriminatory power as the O(n2) collection of lines emanating from each sample point to every other sample point on a shape's boundary. In addition, we describe neat approaches for achieving scale and rotation invariance with compact shape trees in the spatial domain; by viewing compact shape trees as aperiodic discrete signals, we also prove scale and rotation invariance properties for them in the Fourier domain. Towards these, along the way, using concepts from differential geometry and the Calculus, we propose a novel theory for sampling 2-D shape boundaries in a scale and rotation invariant manner. Finally, we propose a number of shape recognition experiments to test the efficacy of our concept.



### Learning to Linearize Under Uncertainty
- **Arxiv ID**: http://arxiv.org/abs/1506.03011v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.03011v2)
- **Published**: 2015-06-09 17:22:17+00:00
- **Updated**: 2015-09-10 15:20:38+00:00
- **Authors**: Ross Goroshin, Michael Mathieu, Yann LeCun
- **Comment**: To appear at NIPS 2015
- **Journal**: None
- **Summary**: Training deep feature hierarchies to solve supervised learning tasks has achieved state of the art performance on many problems in computer vision. However, a principled way in which to train such hierarchies in the unsupervised setting has remained elusive. In this work we suggest a new architecture and loss for training deep feature hierarchies that linearize the transformations observed in unlabeled natural video sequences. This is done by training a generative model to predict video frames. We also address the problem of inherent uncertainty in prediction by introducing latent variables that are non-deterministic functions of the input into the network architecture.



### Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1506.03099v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.03099v3)
- **Published**: 2015-06-09 20:33:47+00:00
- **Updated**: 2015-09-23 16:35:42+00:00
- **Authors**: Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer
- **Comment**: None
- **Journal**: None
- **Summary**: Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used successfully in our winning entry to the MSCOCO image captioning challenge, 2015.



### Multiscale edge detection and parametric shape modeling for boundary delineation in optoacoustic images
- **Arxiv ID**: http://arxiv.org/abs/1506.03124v1
- **DOI**: 10.1109/EMBC.2015.7318460
- **Categories**: **physics.med-ph**, cs.CV, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/1506.03124v1)
- **Published**: 2015-06-09 22:44:26+00:00
- **Updated**: 2015-06-09 22:44:26+00:00
- **Authors**: Subhamoy Mandal, Viswanath Pamulakanty Sudarshan, Yeshaswini Nagaraj, Xose Luis Dean Ben, Daniel Razansky
- **Comment**: Engineering in Medicine and Biology Society (EMBC), 2015 37th Annual
  International Conference of the IEEE (Accepted version)
- **Journal**: Engineering in Medicine and Biology Society (EMBC), 2015 37th
  Annual International Conference of the IEEE , vol., no., pp.707-710, 25-29
  Aug. 2015
- **Summary**: In this article, we present a novel scheme for segmenting the image boundary (with the background) in optoacoustic small animal in vivo imaging systems. The method utilizes a multiscale edge detection algorithm to generate a binary edge map. A scale dependent morphological operation is employed to clean spurious edges. Thereafter, an ellipse is fitted to the edge map through constrained parametric transformations and iterative goodness of fit calculations. The method delimits the tissue edges through the curve fitting model, which has shown high levels of accuracy. Thus, this method enables segmentation of optoacoutic images with minimal human intervention, by eliminating need of scale selection for multiscale processing and seed point determination for contour mapping.



