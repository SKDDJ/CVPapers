# Arxiv Papers in cs.CV on 2015-06-24
### Deep CNN Ensemble with Data Augmentation for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1506.07224v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07224v1)
- **Published**: 2015-06-24 02:15:17+00:00
- **Updated**: 2015-06-24 02:15:17+00:00
- **Authors**: Jian Guo, Stephen Gould
- **Comment**: None
- **Journal**: None
- **Summary**: We report on the methods used in our recent DeepEnsembleCoco submission to the PASCAL VOC 2012 challenge, which achieves state-of-the-art performance on the object detection task. Our method is a variant of the R-CNN model proposed Girshick:CVPR14 with two key improvements to training and evaluation. First, our method constructs an ensemble of deep CNN models with different architectures that are complementary to each other. Second, we augment the PASCAL VOC training set with images from the Microsoft COCO dataset to significantly enlarge the amount training data. Importantly, we select a subset of the Microsoft COCO images to be consistent with the PASCAL VOC task. Results on the PASCAL VOC evaluation server show that our proposed method outperform all previous methods on the PASCAL VOC 2012 detection task at time of submission.



### Incremental RANSAC for Online Relocation in Large Dynamic Environments
- **Arxiv ID**: http://arxiv.org/abs/1506.07236v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1506.07236v2)
- **Published**: 2015-06-24 04:07:28+00:00
- **Updated**: 2015-06-25 03:24:34+00:00
- **Authors**: Kanji Tanaka, Eiji Kondo
- **Comment**: Offprint of ICRA2006 paper
- **Journal**: None
- **Summary**: Vehicle relocation is the problem in which a mobile robot has to estimate the self-position with respect to an a priori map of landmarks using the perception and the motion measurements without using any knowledge of the initial self-position. Recently, RANdom SAmple Consensus (RANSAC), a robust multi-hypothesis estimator, has been successfully applied to offline relocation in static environments. On the other hand, online relocation in dynamic environments is still a difficult problem, for available computation time is always limited, and for measurement include many outliers. To realize real time algorithm for such an online process, we have developed an incremental version of RANSAC algorithm by extending an efficient preemption RANSAC scheme. This novel scheme named incremental RANSAC is able to find inlier hypotheses of self-positions out of large number of outlier hypotheses contaminated by outlier measurements.



### A Novel Feature Extraction Method for Scene Recognition Based on Centered Convolutional Restricted Boltzmann Machines
- **Arxiv ID**: http://arxiv.org/abs/1506.07257v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07257v1)
- **Published**: 2015-06-24 06:42:42+00:00
- **Updated**: 2015-06-24 06:42:42+00:00
- **Authors**: Jingyu Gao, Jinfu Yang, Guanghui Wang, Mingai Li
- **Comment**: 22 pages, 11 figures
- **Journal**: None
- **Summary**: Scene recognition is an important research topic in computer vision, while feature extraction is a key step of object recognition. Although classical Restricted Boltzmann machines (RBM) can efficiently represent complicated data, it is hard to handle large images due to its complexity in computation. In this paper, a novel feature extraction method, named Centered Convolutional Restricted Boltzmann Machines (CCRBM), is proposed for scene recognition. The proposed model is an improved Convolutional Restricted Boltzmann Machines (CRBM) by introducing centered factors in its learning strategy to reduce the source of instabilities. First, the visible units of the network are redefined using centered factors. Then, the hidden units are learned with a modified energy function by utilizing a distribution function, and the visible units are reconstructed using the learned hidden units. In order to achieve better generative ability, the Centered Convolutional Deep Belief Networks (CCDBN) is trained in a greedy layer-wise way. Finally, a softmax regression is incorporated for scene recognition. Extensive experimental evaluations using natural scenes, MIT-indoor scenes, and Caltech 101 datasets show that the proposed approach performs better than other counterparts in terms of stability, generalization, and discrimination. The CCDBN model is more suitable for natural scene image recognition by virtue of convolutional property.



### Natural Scene Recognition Based on Superpixels and Deep Boltzmann Machines
- **Arxiv ID**: http://arxiv.org/abs/1506.07271v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07271v1)
- **Published**: 2015-06-24 07:53:54+00:00
- **Updated**: 2015-06-24 07:53:54+00:00
- **Authors**: Jinfu Yang, Jingyu Gao, Guanghui Wang, Shanshan Zhang
- **Comment**: 29 pages, 8 figures
- **Journal**: None
- **Summary**: The Deep Boltzmann Machines (DBM) is a state-of-the-art unsupervised learning model, which has been successfully applied to handwritten digit recognition and, as well as object recognition. However, the DBM is limited in scene recognition due to the fact that natural scene images are usually very large. In this paper, an efficient scene recognition approach is proposed based on superpixels and the DBMs. First, a simple linear iterative clustering (SLIC) algorithm is employed to generate superpixels of input images, where each superpixel is regarded as an input of a learning model. Then, a two-layer DBM model is constructed by stacking two restricted Boltzmann machines (RBMs), and a greedy layer-wise algorithm is applied to train the DBM model. Finally, a softmax regression is utilized to categorize scene images. The proposed technique can effectively reduce the computational complexity and enhance the performance for large natural image recognition. The approach is verified and evaluated by extensive experiments, including the fifteen-scene categories dataset the UIUC eight-sports dataset, and the SIFT flow dataset, are used to evaluate the proposed method. The experimental results show that the proposed approach outperforms other state-of-the-art methods in terms of recognition rate.



### Targeting Ultimate Accuracy: Face Recognition via Deep Embedding
- **Arxiv ID**: http://arxiv.org/abs/1506.07310v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07310v4)
- **Published**: 2015-06-24 10:36:26+00:00
- **Updated**: 2015-07-23 02:34:29+00:00
- **Authors**: Jingtuo Liu, Yafeng Deng, Tao Bai, Zhengping Wei, Chang Huang
- **Comment**: None
- **Journal**: None
- **Summary**: Face Recognition has been studied for many decades. As opposed to traditional hand-crafted features such as LBP and HOG, much more sophisticated features can be learned automatically by deep learning methods in a data-driven way. In this paper, we propose a two-stage approach that combines a multi-patch deep CNN and deep metric learning, which extracts low dimensional but very discriminative features for face verification and recognition. Experiments show that this method outperforms other state-of-the-art methods on LFW dataset, achieving 99.77% pair-wise verification accuracy and significantly better accuracy under other two more practical protocols. This paper also discusses the importance of data size and the number of patches, showing a clear path to practical high-performance face recognition systems in real world.



### Salient Object Detection via Objectness Measure
- **Arxiv ID**: http://arxiv.org/abs/1506.07363v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07363v1)
- **Published**: 2015-06-24 13:44:21+00:00
- **Updated**: 2015-06-24 13:44:21+00:00
- **Authors**: Sai Srivatsa R, R. Venkatesh Babu
- **Comment**: In IEEE International Conference on Image Processing (ICIP), 2015
- **Journal**: None
- **Summary**: Salient object detection has become an important task in many image processing applications. The existing approaches exploit background prior and contrast prior to attain state of the art results. In this paper, instead of using background cues, we estimate the foreground regions in an image using objectness proposals and utilize it to obtain smooth and accurate saliency maps. We propose a novel saliency measure called `foreground connectivity' which determines how tightly a pixel or a region is connected to the estimated foreground. We use the values assigned by this measure as foreground weights and integrate these in an optimization framework to obtain the final saliency maps. We extensively evaluate the proposed approach on two benchmark databases and demonstrate that the results obtained are better than the existing state of the art approaches.



### Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images
- **Arxiv ID**: http://arxiv.org/abs/1506.07365v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1506.07365v3)
- **Published**: 2015-06-24 13:48:51+00:00
- **Updated**: 2015-11-20 14:49:18+00:00
- **Authors**: Manuel Watter, Jost Tobias Springenberg, Joschka Boedecker, Martin Riedmiller
- **Comment**: Final NIPS version
- **Journal**: None
- **Summary**: We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems.



### Kernel Cuts: MRF meets Kernel & Spectral Clustering
- **Arxiv ID**: http://arxiv.org/abs/1506.07439v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07439v6)
- **Published**: 2015-06-24 16:00:43+00:00
- **Updated**: 2016-09-21 03:41:06+00:00
- **Authors**: Meng Tang, Dmitrii Marin, Ismail Ben Ayed, Yuri Boykov
- **Comment**: The main ideas of this work are published in our conference papers:
  "Normalized cut meets MRF" [70] (ECCV 2016) and "Secrets of Grabcut and
  kernel K-means" [41] (ICCV 2015)
- **Journal**: None
- **Summary**: We propose a new segmentation model combining common regularization energies, e.g. Markov Random Field (MRF) potentials, and standard pairwise clustering criteria like Normalized Cut (NC), average association (AA), etc. These clustering and regularization models are widely used in machine learning and computer vision, but they were not combined before due to significant differences in the corresponding optimization, e.g. spectral relaxation and combinatorial max-flow techniques. On the one hand, we show that many common applications using MRF segmentation energies can benefit from a high-order NC term, e.g. enforcing balanced clustering of arbitrary high-dimensional image features combining color, texture, location, depth, motion, etc. On the other hand, standard clustering applications can benefit from an inclusion of common pairwise or higher-order MRF constraints, e.g. edge alignment, bin-consistency, label cost, etc. To address joint energies like NC+MRF, we propose efficient Kernel Cut algorithms based on bound optimization. While focusing on graph cut and move-making techniques, our new unary (linear) kernel and spectral bound formulations for common pairwise clustering criteria allow to integrate them with any regularization functionals with existing discrete or continuous solvers.



### Unshredding of Shredded Documents: Computational Framework and Implementation
- **Arxiv ID**: http://arxiv.org/abs/1506.07440v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1506.07440v1)
- **Published**: 2015-06-24 16:01:24+00:00
- **Updated**: 2015-06-24 16:01:24+00:00
- **Authors**: Lei Kristoffer R. Lactuan, Jaderick P. Pabico
- **Comment**: 7 pages, 3 figures
- **Journal**: Asia Pacific Journal of Multidisciplinary Research 3(3):20-25,
  2015
- **Summary**: A shredded document $D$ is a document whose pages have been cut into strips for the purpose of destroying private, confidential, or sensitive information $I$ contained in $D$. Shredding has become a standard means of government organizations, businesses, and private individuals to destroy archival records that have been officially classified for disposal. It can also be used to destroy documentary evidence of wrongdoings by entities who are trying to hide $I$.   In this paper, we present an optimal $O((n\times m)^2)$ algorithm $A$ that reconstructs an $n$-page $D$, where each page $p$ is shredded into $m$ strips. We also present the efficacy of $A$ in reconstructing three document types: hand-written, machine typed-set, and images.



### Parallel Multi-Dimensional LSTM, With Application to Fast Biomedical Volumetric Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1506.07452v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1506.07452v1)
- **Published**: 2015-06-24 16:26:51+00:00
- **Updated**: 2015-06-24 16:26:51+00:00
- **Authors**: Marijn F. Stollenga, Wonmin Byeon, Marcus Liwicki, Juergen Schmidhuber
- **Comment**: Marijn F. Stollenga and Wonmin Byeon are the shared first authors,
  both authors contributed equally to this work
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNNs) can be shifted across 2D images or 3D videos to segment them. They have a fixed input size and typically perceive only small local contexts of the pixels to be classified as foreground or background. In contrast, Multi-Dimensional Recurrent NNs (MD-RNNs) can perceive the entire spatio-temporal context of each pixel in a few sweeps through all pixels, especially when the RNN is a Long Short-Term Memory (LSTM). Despite these theoretical advantages, however, unlike CNNs, previous MD-LSTM variants were hard to parallelize on GPUs. Here we re-arrange the traditional cuboid order of computations in MD-LSTM in pyramidal fashion. The resulting PyraMiD-LSTM is easy to parallelize, especially for 3D data such as stacks of brain slice images. PyraMiD-LSTM achieved best known pixel-wise brain image segmentation results on MRBrainS13 (and competitive results on EM-ISBI12).



### Nonnegative Matrix Factorization applied to reordered pixels of single images based on patches to achieve structured nonnegative dictionaries
- **Arxiv ID**: http://arxiv.org/abs/1506.08110v1
- **DOI**: None
- **Categories**: **cs.CV**, math.NA, 65K02
- **Links**: [PDF](http://arxiv.org/pdf/1506.08110v1)
- **Published**: 2015-06-24 17:27:11+00:00
- **Updated**: 2015-06-24 17:27:11+00:00
- **Authors**: Richard M. Charles, Kye M. Taylor, James H. Curry
- **Comment**: 34 pages, 15 figures, 2 tables
- **Journal**: None
- **Summary**: Recent improvements in computing allow for the processing and analysis of very large datasets in a variety of fields. Often the analysis requires the creation of low-rank approximations to the datasets leading to efficient storage. This article presents and analyzes a novel approach for creating nonnegative, structured dictionaries using NMF applied to reordered pixels of single, natural images. We reorder the pixels based on patches and present our approach in general. We investigate our approach when using the Singular Value Decomposition (SVD) and Nonnegative Matrix Factorizations (NMF) as low-rank approximations. Peak Signal-to-Noise Ratio (PSNR) and Mean Structural Similarity Index (MSSIM) are used to evaluate the algorithm. We report that while the SVD provides the best reconstructions, its dictionary of vectors lose both the sign structure of the original image and details of localized image content. In contrast, the dictionaries produced using NMF preserves the sign structure of the original image matrix and offer a nonnegative, parts-based dictionary.



### Multiresolution Approach to Acceleration of Iterative Image Reconstruction for X-Ray Imaging for Security Applications
- **Arxiv ID**: http://arxiv.org/abs/1508.04458v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.04458v1)
- **Published**: 2015-06-24 22:03:28+00:00
- **Updated**: 2015-06-24 22:03:28+00:00
- **Authors**: S. Degirmenci, Joseph A. O'Sullivan, David G. Politte
- **Comment**: None
- **Journal**: None
- **Summary**: Three-dimensional x-ray CT image reconstruction in baggage scanning in security applications is an important research field. The variety of materials to be reconstructed is broader than medical x-ray imaging. Presence of high attenuating materials such as metal may cause artifacts if analytical reconstruction methods are used. Statistical modeling and the resultant iterative algorithms are known to reduce these artifacts and present good quantitative accuracy in estimates of linear attenuation coefficients. However, iterative algorithms may require computations in order to achieve quantitatively accurate results. For the case of baggage scanning, in order to provide fast accurate inspection throughput, they must be accelerated drastically. There are many approaches proposed in the literature to increase speed of convergence. This paper presents a new method that estimates the wavelet coefficients of the images in the discrete wavelet transform domain instead of the image space itself. Initially, surrogate functions are created around approximation coefficients only. As the iterations proceed, the wavelet tree on which the updates are made is expanded based on a criterion and detail coefficients at each level are updated and the tree is expanded this way. For example, in the smooth regions of the image the detail coefficients are not updated while the coefficients that represent the high-frequency component around edges are being updated, thus saving time by focusing computations where they are needed. This approach is implemented on real data from a SureScan (TM) x1000 Explosive Detection System and compared to straightforward implementation of the unregularized alternating minimization of O'Sullivan and Benac [1].



