# Arxiv Papers in cs.CV on 2015-12-16
### Effects of GIMP Retinex Filtering Evaluated by the Image Entropy
- **Arxiv ID**: http://arxiv.org/abs/1512.05653v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.05653v1)
- **Published**: 2015-12-16 10:45:17+00:00
- **Updated**: 2015-12-16 10:45:17+00:00
- **Authors**: A. C. Sparavigna, R. Marazzato
- **Comment**: Keywords: Image Processing, Foggy Images, Retinex, Shannon Entropy,
  Generalized Entropies, Kaniadakis Entropy
- **Journal**: None
- **Summary**: A GIMP Retinex filtering can be used for enhancing images, with good results on foggy images, as recently discussed. Since this filter has some parameters that can be adjusted to optimize the output image, several approaches can be decided according to desired results. Here, as a criterion for optimizing the filtering parameters, we consider the maximization of the image entropy. We use, besides the Shannon entropy, also a generalized entropy.



### Fine-grained Categorization and Dataset Bootstrapping using Deep Metric Learning with Humans in the Loop
- **Arxiv ID**: http://arxiv.org/abs/1512.05227v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.05227v2)
- **Published**: 2015-12-16 16:14:22+00:00
- **Updated**: 2016-04-11 04:34:13+00:00
- **Authors**: Yin Cui, Feng Zhou, Yuanqing Lin, Serge Belongie
- **Comment**: 10 pages, 9 figures, CVPR 2016
- **Journal**: None
- **Summary**: Existing fine-grained visual categorization methods often suffer from three challenges: lack of training data, large number of fine-grained categories, and high intraclass vs. low inter-class variance. In this work we propose a generic iterative framework for fine-grained categorization and dataset bootstrapping that handles these three challenges. Using deep metric learning with humans in the loop, we learn a low dimensional feature embedding with anchor points on manifolds for each category. These anchor points capture intra-class variances and remain discriminative between classes. In each round, images with high confidence scores from our model are sent to humans for labeling. By comparing with exemplar images, labelers mark each candidate image as either a "true positive" or a "false positive". True positives are added into our current dataset and false positives are regarded as "hard negatives" for our metric learning model. Then the model is retrained with an expanded dataset and hard negatives for the next round. To demonstrate the effectiveness of the proposed framework, we bootstrap a fine-grained flower dataset with 620 categories from Instagram images. The proposed deep metric learning scheme is evaluated on both our dataset and the CUB-200-2001 Birds dataset. Experimental evaluations show significant performance gain using dataset bootstrapping and demonstrate state-of-the-art results achieved by the proposed deep metric learning methods.



### Blockout: Dynamic Model Selection for Hierarchical Deep Networks
- **Arxiv ID**: http://arxiv.org/abs/1512.05246v1
- **DOI**: 10.1109/CVPR.2016.283
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1512.05246v1)
- **Published**: 2015-12-16 16:58:36+00:00
- **Updated**: 2015-12-16 16:58:36+00:00
- **Authors**: Calvin Murdock, Zhen Li, Howard Zhou, Tom Duerig
- **Comment**: None
- **Journal**: None
- **Summary**: Most deep architectures for image classification--even those that are trained to classify a large number of diverse categories--learn shared image representations with a single model. Intuitively, however, categories that are more similar should share more information than those that are very different. While hierarchical deep networks address this problem by learning separate features for subsets of related categories, current implementations require simplified models using fixed architectures specified via heuristic clustering methods. Instead, we propose Blockout, a method for regularization and model selection that simultaneously learns both the model architecture and parameters. A generalization of Dropout, our approach gives a novel parametrization of hierarchical architectures that allows for structure learning via back-propagation. To demonstrate its utility, we evaluate Blockout on the CIFAR and ImageNet datasets, demonstrating improved classification accuracy, better regularization performance, faster training, and the clear emergence of hierarchical network structures.



### Shape and Spatially-Varying Reflectance Estimation From Virtual Exemplars
- **Arxiv ID**: http://arxiv.org/abs/1512.05278v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.05278v3)
- **Published**: 2015-12-16 18:48:38+00:00
- **Updated**: 2016-09-21 00:10:38+00:00
- **Authors**: Zhuo Hui, Aswin C Sankaranarayanan
- **Comment**: PAMI minor revision. arXiv admin note: substantial text overlap with
  arXiv:1503.04265
- **Journal**: None
- **Summary**: This paper addresses the problem of estimating the shape of objects that exhibit spatially-varying reflectance. We assume that multiple images of the object are obtained under a fixed view-point and varying illumination, i.e., the setting of photometric stereo. At the core of our techniques is the assumption that the BRDF at each pixel lies in the non-negative span of a known BRDF dictionary.This assumption enables a per-pixel surface normal and BRDF estimation framework that is computationally tractable and requires no initialization in spite of the underlying problem being non-convex. Our estimation framework first solves for the surface normal at each pixel using a variant of example-based photometric stereo. We design an efficient multi-scale search strategy for estimating the surface normal and subsequently, refine this estimate using a gradient descent procedure. Given the surface normal estimate, we solve for the spatially-varying BRDF by constraining the BRDF at each pixel to be in the span of the BRDF dictionary, here, we use additional priors to further regularize the solution. A hallmark of our approach is that it does not require iterative optimization techniques nor the need for careful initialization, both of which are endemic to most state-of-the-art techniques. We showcase the performance of our technique on a wide range of simulated and real scenes where we outperform competing methods.



### Multiregion Bilinear Convolutional Neural Networks for Person Re-Identification
- **Arxiv ID**: http://arxiv.org/abs/1512.05300v5
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.05300v5)
- **Published**: 2015-12-16 19:45:37+00:00
- **Updated**: 2017-09-06 14:38:55+00:00
- **Authors**: Evgeniya Ustinova, Yaroslav Ganin, Victor Lempitsky
- **Comment**: in AVSS 2017
- **Journal**: None
- **Summary**: In this work we propose a new architecture for person re-identification. As the task of re-identification is inherently associated with embedding learning and non-rigid appearance description, our architecture is based on the deep bilinear convolutional network (Bilinear-CNN) that has been proposed recently for fine-grained classification of highly non-rigid objects. While the last stages of the original Bilinear-CNN architecture completely removes the geometric information from consideration by performing orderless pooling, we observe that a better embedding can be learned by performing bilinear pooling in a more local way, where each pooling is confined to a predefined region. Our architecture thus represents a compromise between traditional convolutional networks and bilinear CNNs and strikes a balance between rigid matching and completely ignoring spatial information.   We perform the experimental validation of the new architecture on the three popular benchmark datasets (Market-1501, CUHK01, CUHK03), comparing it to baselines that include Bilinear-CNN as well as prior art. The new architecture outperforms the baseline on all three datasets, while performing better than state-of-the-art on two out of three. The code and the pretrained models of the approach can be found at https://github.com/madkn/MultiregionBilinearCNN-ReId.



