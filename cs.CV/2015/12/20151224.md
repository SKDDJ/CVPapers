# Arxiv Papers in cs.CV on 2015-12-24
### Adaptive Object Detection Using Adjacency and Zoom Prediction
- **Arxiv ID**: http://arxiv.org/abs/1512.07711v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.07711v2)
- **Published**: 2015-12-24 04:20:16+00:00
- **Updated**: 2016-04-11 05:51:12+00:00
- **Authors**: Yongxi Lu, Tara Javidi, Svetlana Lazebnik
- **Comment**: Accepted to CVPR 2016
- **Journal**: None
- **Summary**: State-of-the-art object detection systems rely on an accurate set of region proposals. Several recent methods use a neural network architecture to hypothesize promising object locations. While these approaches are computationally efficient, they rely on fixed image regions as anchors for predictions. In this paper we propose to use a search strategy that adaptively directs computational resources to sub-regions likely to contain objects. Compared to methods based on fixed anchor locations, our approach naturally adapts to cases where object instances are sparse and small. Our approach is comparable in terms of accuracy to the state-of-the-art Faster R-CNN approach while using two orders of magnitude fewer anchors on average. Code is publicly available.



### Fast Acquisition for Quantitative MRI Maps: Sparse Recovery from Non-linear Measurements
- **Arxiv ID**: http://arxiv.org/abs/1512.07712v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.07712v1)
- **Published**: 2015-12-24 04:24:27+00:00
- **Updated**: 2015-12-24 04:24:27+00:00
- **Authors**: Anupriya Gogna, Angshul Majumdar
- **Comment**: None
- **Journal**: None
- **Summary**: This work addresses the problem of estimating proton density and T1 maps from two partially sampled K-space scans such that the total acquisition time remains approximately the same as a single scan. Existing multi parametric non linear curve fitting techniques require a large number (8 or more) of echoes to estimate the maps resulting in prolonged (clinically infeasible) acquisition times. Our simulation results show that our method yields very accurate and robust results from only two partially sampled scans (total scan time being the same as a single echo MRI). We model PD and T1 maps to be sparse in some transform domain. The PD map is recovered via standard Compressed Sensing based recovery technique. Estimating the T1 map requires solving an analysis prior sparse recovery problem from non linear measurements, since the relationship between T1 values and intensity values or K space samples is not linear. For the first time in this work, we propose an algorithm for analysis prior sparse recovery for non linear measurements. We have compared our approach with the only existing technique based on matrix factorization from non linear measurements; our method yields considerably superior results.



### G-CNN: an Iterative Grid Based Object Detector
- **Arxiv ID**: http://arxiv.org/abs/1512.07729v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.07729v2)
- **Published**: 2015-12-24 07:02:37+00:00
- **Updated**: 2016-04-25 20:40:11+00:00
- **Authors**: Mahyar Najibi, Mohammad Rastegari, Larry S. Davis
- **Comment**: To appear in Proceedings of IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR), 2016. (Spotlight)
- **Journal**: None
- **Summary**: We introduce G-CNN, an object detection technique based on CNNs which works without proposal algorithms. G-CNN starts with a multi-scale grid of fixed bounding boxes. We train a regressor to move and scale elements of the grid towards objects iteratively. G-CNN models the problem of object detection as finding a path from a fixed grid to boxes tightly surrounding the objects. G-CNN with around 180 boxes in a multi-scale grid performs comparably to Fast R-CNN which uses around 2K bounding boxes generated with a proposal technique. This strategy makes detection faster by removing the object proposal stage as well as reducing the number of boxes to be processed.



### Truncated Max-of-Convex Models
- **Arxiv ID**: http://arxiv.org/abs/1512.07815v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.07815v2)
- **Published**: 2015-12-24 13:52:44+00:00
- **Updated**: 2016-12-03 15:56:12+00:00
- **Authors**: Pankaj Pansari, M. Pawan Kumar
- **Comment**: Under review at CVPR 2017
- **Journal**: None
- **Summary**: Truncated convex models (TCM) are a special case of pairwise random fields that have been widely used in computer vision. However, by restricting the order of the potentials to be at most two, they fail to capture useful image statistics. We propose a natural generalization of TCM to high-order random fields, which we call truncated max-of-convex models (TMCM). The energy function of TMCM consistsof two types of potentials: (i) unary potential, which has no restriction on its form; and (ii) clique potential, which is the sum of the m largest truncated convex distances over all label pairs in a clique. The use of a convex distance function encourages smoothness, while truncation allows for discontinuities in the labeling. By using m > 1, TMCM provides robustness towards errors in the definition of the cliques. In order to minimize the energy function of a TMCM over all possible labelings, we design an efficient st-MINCUT based range expansion algorithm. We prove the accuracy of our algorithm by establishing strong multiplicative bounds for several special cases of interest. Using synthetic and standard real data sets, we demonstrate the benefit of our high-order TMCM over pairwise TCM, as well as the benefit of our range expansion algorithm over other st-MINCUT based approaches.



### Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network
- **Arxiv ID**: http://arxiv.org/abs/1512.07928v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.07928v1)
- **Published**: 2015-12-24 22:33:27+00:00
- **Updated**: 2015-12-24 22:33:27+00:00
- **Authors**: Seunghoon Hong, Junhyuk Oh, Bohyung Han, Honglak Lee
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel weakly-supervised semantic segmentation algorithm based on Deep Convolutional Neural Network (DCNN). Contrary to existing weakly-supervised approaches, our algorithm exploits auxiliary segmentation annotations available for different categories to guide segmentations on images with only image-level class labels. To make the segmentation knowledge transferrable across categories, we design a decoupled encoder-decoder architecture with attention model. In this architecture, the model generates spatial highlights of each category presented in an image using an attention model, and subsequently generates foreground segmentation for each highlighted region using decoder. Combining attention model, we show that the decoder trained with segmentation annotations in different categories can boost the performance of weakly-supervised semantic segmentation. The proposed algorithm demonstrates substantially improved performance compared to the state-of-the-art weakly-supervised techniques in challenging PASCAL VOC 2012 dataset when our model is trained with the annotations in 60 exclusive categories in Microsoft COCO dataset.



