# Arxiv Papers in cs.CV on 2015-12-01
### Dynamic Parallel and Distributed Graph Cuts
- **Arxiv ID**: http://arxiv.org/abs/1512.00101v2
- **DOI**: 10.1109/TIP.2016.2609819
- **Categories**: **cs.DS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1512.00101v2)
- **Published**: 2015-12-01 00:19:50+00:00
- **Updated**: 2016-09-12 00:31:20+00:00
- **Authors**: Miao Yu, Shuhan Shen, Zhanyi Hu
- **Comment**: None
- **Journal**: None
- **Summary**: Graph-cuts are widely used in computer vision. In order to speed up the optimization process and improve the scalability for large graphs, Strandmark and Kahl introduced a splitting method to split a graph into multiple subgraphs for parallel computation in both shared and distributed memory models. However, this parallel algorithm (parallel BK-algorithm) does not have a polynomial bound on the number of iterations and is found non-convergent in some cases due to the possible multiple optimal solutions of its sub-problems.   To remedy this non-convergence problem, in this work we first introduce a merging method capable of merging any number of those adjacent sub-graphs which could hardly reach an agreement on their overlapped region in the parallel BK algorithm. Based on the pseudo-boolean representations of graph cuts,our merging method is shown able to effectively reuse all the computed flows in these sub-graphs. Through both the splitting and merging, we further propose a dynamic parallel and distributed graph-cuts algorithm with guaranteed convergence to the globally optimal solutions within a predefined number of iterations. In essence, this work provides a general framework to allow more sophisticated splitting and merging strategies to be employed to further boost performance. Our dynamic parallel algorithm is validated with extensive experimental results.



### Implicit Sparse Code Hashing
- **Arxiv ID**: http://arxiv.org/abs/1512.00130v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00130v1)
- **Published**: 2015-12-01 03:12:09+00:00
- **Updated**: 2015-12-01 03:12:09+00:00
- **Authors**: Tsung-Yu Lin, Tsung-Wei Ke, Tyng-Luh Liu
- **Comment**: 9 pages, 1 figure
- **Journal**: None
- **Summary**: We address the problem of converting large-scale high-dimensional image data into binary codes so that approximate nearest-neighbor search over them can be efficiently performed. Different from most of the existing unsupervised approaches for yielding binary codes, our method is based on a dimensionality-reduction criterion that its resulting mapping is designed to preserve the image relationships entailed by the inner products of sparse codes, rather than those implied by the Euclidean distances in the ambient space. While the proposed formulation does not require computing any sparse codes, the underlying computation model still inevitably involves solving an unmanageable eigenproblem when extremely high-dimensional descriptors are used. To overcome the difficulty, we consider the column-sampling technique and presume a special form of rotation matrix to facilitate subproblem decomposition. We test our method on several challenging image datasets and demonstrate its effectiveness by comparing with state-of-the-art binary coding techniques.



### Analyzing Classifiers: Fisher Vectors and Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1512.00172v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00172v1)
- **Published**: 2015-12-01 08:14:11+00:00
- **Updated**: 2015-12-01 08:14:11+00:00
- **Authors**: Sebastian Bach, Alexander Binder, Grégoire Montavon, Klaus-Robert Müller, Wojciech Samek
- **Comment**: 17 pages (10 main document + references , 7 appendix) 1 Table 7
  Figures 1 Algorithm submitted to CVPR on 06/11/2025
- **Journal**: None
- **Summary**: Fisher Vector classifiers and Deep Neural Networks (DNNs) are popular and successful algorithms for solving image classification problems. However, both are generally considered `black box' predictors as the non-linear transformations involved have so far prevented transparent and interpretable reasoning. Recently, a principled technique, Layer-wise Relevance Propagation (LRP), has been developed in order to better comprehend the inherent structured reasoning of complex nonlinear classification models such as Bag of Feature models or DNNs. In this paper we (1) extend the LRP framework also for Fisher Vector classifiers and then use it as analysis tool to (2) quantify the importance of context for classification, (3) qualitatively compare DNNs against FV classifiers in terms of important image regions and (4) detect potential flaws and biases in data. All experiments are performed on the PASCAL VOC 2007 data set.



### Fast and High Quality Highlight Removal from A Single Image
- **Arxiv ID**: http://arxiv.org/abs/1512.00237v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00237v1)
- **Published**: 2015-12-01 12:21:49+00:00
- **Updated**: 2015-12-01 12:21:49+00:00
- **Authors**: Dongsheng An, Jinli Suo, Xiangyang Ji, Haoqian Wang, Qionghai Dai
- **Comment**: 11 pages, 10 figures, submitted to IEEE TIP
- **Journal**: None
- **Summary**: Specular reflection exists widely in photography and causes the recorded color deviating from its true value, so fast and high quality highlight removal from a single nature image is of great importance. In spite of the progress in the past decades in highlight removal, achieving wide applicability to the large diversity of nature scenes is quite challenging. To handle this problem, we propose an analytic solution to highlight removal based on an L2 chromaticity definition and corresponding dichromatic model. Specifically, this paper derives a normalized dichromatic model for the pixels with identical diffuse color: a unit circle equation of projection coefficients in two subspaces that are orthogonal to and parallel with the illumination, respectively. In the former illumination orthogonal subspace, which is specular-free, we can conduct robust clustering with an explicit criterion to determine the cluster number adaptively. In the latter illumination parallel subspace, a property called pure diffuse pixels distribution rule (PDDR) helps map each specular-influenced pixel to its diffuse component. In terms of efficiency, the proposed approach involves few complex calculation, and thus can remove highlight from high resolution images fast. Experiments show that this method is of superior performance in various challenging cases.



### Towards Dropout Training for Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1512.00242v1
- **DOI**: 10.1016/j.neunet.2015.07.007
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1512.00242v1)
- **Published**: 2015-12-01 12:46:11+00:00
- **Updated**: 2015-12-01 12:46:11+00:00
- **Authors**: Haibing Wu, Xiaodong Gu
- **Comment**: This paper has been published in Neural Networks,
  http://www.sciencedirect.com/science/article/pii/S0893608015001446
- **Journal**: Neural Networks 71: 1-10 (2015)
- **Summary**: Recently, dropout has seen increasing use in deep learning. For deep convolutional neural networks, dropout is known to work well in fully-connected layers. However, its effect in convolutional and pooling layers is still not clear. This paper demonstrates that max-pooling dropout is equivalent to randomly picking activation based on a multinomial distribution at training time. In light of this insight, we advocate employing our proposed probabilistic weighted pooling, instead of commonly used max-pooling, to act as model averaging at test time. Empirical evidence validates the superiority of probabilistic weighted pooling. We also empirically show that the effect of convolutional dropout is not trivial, despite the dramatically reduced possibility of over-fitting due to the convolutional architecture. Elaborately designing dropout training simultaneously in max-pooling and fully-connected layers, we achieve state-of-the-art performance on MNIST, and very competitive results on CIFAR-10 and CIFAR-100, relative to other approaches without data augmentation. Finally, we compare max-pooling dropout and stochastic pooling, both of which introduce stochasticity based on multinomial distributions at pooling stage.



### On Optical Flow Models for Variational Motion Estimation
- **Arxiv ID**: http://arxiv.org/abs/1512.00298v1
- **DOI**: None
- **Categories**: **math.NA**, cs.CV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1512.00298v1)
- **Published**: 2015-12-01 15:37:19+00:00
- **Updated**: 2015-12-01 15:37:19+00:00
- **Authors**: Martin Burger, Hendrik Dirks, Lena Frerking
- **Comment**: 27 pages, 3 figures, 2 tables
- **Journal**: None
- **Summary**: The aim of this paper is to discuss and evaluate total variation based regularization methods for motion estimation, with particular focus on optical flow models. In addition to standard $L^2$ and $L^1$ data fidelities we give an overview of different variants of total variation regularization obtained from combination with higher order models and a unified computational optimization approach based on primal-dual methods. Moreover, we extend the models by Bregman iterations and provide an inverse problems perspective to the analysis of variational optical flow models. A particular focus of the paper is the quantitative evaluation of motion estimation, which is a difficult and often underestimated task. We discuss several approaches for quality measures of motion estimation and apply them to compare the previously discussed regularization approaches.



### Accelerated graph-based nonlinear denoising filters
- **Arxiv ID**: http://arxiv.org/abs/1512.00389v2
- **DOI**: 10.1016/j.procs.2016.05.348
- **Categories**: **cs.CV**, math.NA, 65F30, I.4.3; G.1.3
- **Links**: [PDF](http://arxiv.org/pdf/1512.00389v2)
- **Published**: 2015-12-01 18:54:19+00:00
- **Updated**: 2016-04-13 20:00:49+00:00
- **Authors**: Andrew Knyazev, Alexander Malyshev
- **Comment**: 10 pages, 6 figures, to appear in Procedia Computer Science, vol.80,
  2016, International Conference on Computational Science, San Diego, CA, USA,
  June 6-8, 2016
- **Journal**: Procedia Computer Science Volume 80, 2016, Pages 607-616,
  International Conference on Computational Science 2016, ICCS 2016, 6-8 June
  2016, San Diego, California, USA
- **Summary**: Denoising filters, such as bilateral, guided, and total variation filters, applied to images on general graphs may require repeated application if noise is not small enough. We formulate two acceleration techniques of the resulted iterations: conjugate gradient method and Nesterov's acceleration. We numerically show efficiency of the accelerated nonlinear filters for image denoising and demonstrate 2-12 times speed-up, i.e., the acceleration techniques reduce the number of iterations required to reach a given peak signal-to-noise ratio (PSNR) by the above indicated factor of 2-12.



### Loss Functions for Top-k Error: Analysis and Insights
- **Arxiv ID**: http://arxiv.org/abs/1512.00486v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1512.00486v2)
- **Published**: 2015-12-01 21:22:35+00:00
- **Updated**: 2016-04-13 15:12:01+00:00
- **Authors**: Maksim Lapin, Matthias Hein, Bernt Schiele
- **Comment**: In Computer Vision and Pattern Recognition (CVPR), 2016
- **Journal**: None
- **Summary**: In order to push the performance on realistic computer vision tasks, the number of classes in modern benchmark datasets has significantly increased in recent years. This increase in the number of classes comes along with increased ambiguity between the class labels, raising the question if top-1 error is the right performance measure. In this paper, we provide an extensive comparison and evaluation of established multiclass methods comparing their top-k performance both from a practical as well as from a theoretical perspective. Moreover, we introduce novel top-k loss functions as modifications of the softmax and the multiclass SVM losses and provide efficient optimization schemes for them. In the experiments, we compare on various datasets all of the proposed and established methods for top-k error optimization. An interesting insight of this paper is that the softmax loss yields competitive top-k performance for all k simultaneously. For a specific top-k error, our new top-k losses lead typically to further improvements while being faster to train than the softmax.



### Efficient Edge Detection on Low-Cost FPGAs
- **Arxiv ID**: http://arxiv.org/abs/1512.00504v1
- **DOI**: None
- **Categories**: **cs.AR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1512.00504v1)
- **Published**: 2015-12-01 22:32:21+00:00
- **Updated**: 2015-12-01 22:32:21+00:00
- **Authors**: Jamie Schiel, Andrew Bainbridge-Smith
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: Improving the efficiency of edge detection in embedded applications, such as UAV control, is critical for reducing system cost and power dissipation. Field programmable gate arrays (FPGA) are a good platform for making improvements because of their specialised internal structure. However, current FPGA edge detectors do not exploit this structure well. A new edge detection architecture is proposed that is better optimised for FPGAs. The basis of the architecture is the Sobel edge kernels that are shown to be the most suitable because of their separability and absence of multiplications. Edge intensities are calculated with a new 4:2 compressor that consists of two custom-designed 3:2 compressors. Addition speed is increased by breaking carry propagation chains with look-ahead logic. Testing of the design showed it gives a 28% increase in speed and 4.4% reduction in area over previous equivalent designs, which demonstrated that it will lower the cost of edge detection systems, dissipate less power and still maintain high-speed control.



### Labeling the Features Not the Samples: Efficient Video Classification with Minimal Supervision
- **Arxiv ID**: http://arxiv.org/abs/1512.00517v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00517v1)
- **Published**: 2015-12-01 23:24:12+00:00
- **Updated**: 2015-12-01 23:24:12+00:00
- **Authors**: Marius Leordeanu, Alexandra Radu, Shumeet Baluja, Rahul Sukthankar
- **Comment**: arXiv admin note: text overlap with arXiv:1411.7714
- **Journal**: None
- **Summary**: Feature selection is essential for effective visual recognition. We propose an efficient joint classifier learning and feature selection method that discovers sparse, compact representations of input features from a vast sea of candidates, with an almost unsupervised formulation. Our method requires only the following knowledge, which we call the \emph{feature sign}---whether or not a particular feature has on average stronger values over positive samples than over negatives. We show how this can be estimated using as few as a single labeled training sample per class. Then, using these feature signs, we extend an initial supervised learning problem into an (almost) unsupervised clustering formulation that can incorporate new data without requiring ground truth labels. Our method works both as a feature selection mechanism and as a fully competitive classifier. It has important properties, low computational cost and excellent accuracy, especially in difficult cases of very limited training data. We experiment on large-scale recognition in video and show superior speed and performance to established feature selection approaches such as AdaBoost, Lasso, greedy forward-backward selection, and powerful classifiers such as SVM.



