# Arxiv Papers in cs.CV on 2015-12-30
### Actor-Action Semantic Segmentation with Grouping Process Models
- **Arxiv ID**: http://arxiv.org/abs/1512.09041v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.09041v1)
- **Published**: 2015-12-30 18:07:45+00:00
- **Updated**: 2015-12-30 18:07:45+00:00
- **Authors**: Chenliang Xu, Jason J. Corso
- **Comment**: Technical report
- **Journal**: None
- **Summary**: Actor-action semantic segmentation made an important step toward advanced video understanding problems: what action is happening; who is performing the action; and where is the action in space-time. Current models for this problem are local, based on layered CRFs, and are unable to capture long-ranging interaction of video parts. We propose a new model that combines these local labeling CRFs with a hierarchical supervoxel decomposition. The supervoxels provide cues for possible groupings of nodes, at various scales, in the CRFs to encourage adaptive, high-order groups for more effective labeling. Our model is dynamic and continuously exchanges information during inference: the local CRFs influence what supervoxels in the hierarchy are active, and these active nodes influence the connectivity in the CRF; we hence call it a grouping process model. The experimental results on a recent large-scale video dataset show a large margin of 60% relative improvement over the state of the art, which demonstrates the effectiveness of the dynamic, bidirectional flow between labeling and grouping.



### LIBSVX: A Supervoxel Library and Benchmark for Early Video Processing
- **Arxiv ID**: http://arxiv.org/abs/1512.09049v1
- **DOI**: 10.1007/s11263-016-0906-5
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.09049v1)
- **Published**: 2015-12-30 18:25:19+00:00
- **Updated**: 2015-12-30 18:25:19+00:00
- **Authors**: Chenliang Xu, Jason J. Corso
- **Comment**: In Review at International Journal of Computer Vision
- **Journal**: Int J Comput Vis (2016) 119: 272
- **Summary**: Supervoxel segmentation has strong potential to be incorporated into early video analysis as superpixel segmentation has in image analysis. However, there are many plausible supervoxel methods and little understanding as to when and where each is most appropriate. Indeed, we are not aware of a single comparative study on supervoxel segmentation. To that end, we study seven supervoxel algorithms, including both off-line and streaming methods, in the context of what we consider to be a good supervoxel: namely, spatiotemporal uniformity, object/region boundary detection, region compression and parsimony. For the evaluation we propose a comprehensive suite of seven quality metrics to measure these desirable supervoxel characteristics. In addition, we evaluate the methods in a supervoxel classification task as a proxy for subsequent high-level uses of the supervoxels in video analysis. We use six existing benchmark video datasets with a variety of content-types and dense human annotations. Our findings have led us to conclusive evidence that the hierarchical graph-based (GBH), segmentation by weighted aggregation (SWA) and temporal superpixels (TSP) methods are the top-performers among the seven methods. They all perform well in terms of segmentation accuracy, but vary in regard to the other desiderata: GBH captures object boundaries best; SWA has the best potential for region compression; and TSP achieves the best undersegmentation error.



