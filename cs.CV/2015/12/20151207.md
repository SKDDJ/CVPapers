# Arxiv Papers in cs.CV on 2015-12-07
### Recognition from Hand Cameras
- **Arxiv ID**: http://arxiv.org/abs/1512.01881v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01881v3)
- **Published**: 2015-12-07 02:06:29+00:00
- **Updated**: 2016-03-22 09:12:04+00:00
- **Authors**: Cheng-Sheng Chan, Shou-Zhong Chen, Pei-Xuan Xie, Chiung-Chih Chang, Min Sun
- **Comment**: None
- **Journal**: None
- **Summary**: We revisit the study of a wrist-mounted camera system (referred to as HandCam) for recognizing activities of hands. HandCam has two unique properties as compared to egocentric systems (referred to as HeadCam): (1) it avoids the need to detect hands; (2) it more consistently observes the activities of hands. By taking advantage of these properties, we propose a deep-learning-based method to recognize hand states (free v.s. active hands, hand gestures, object categories), and discover object categories. Moreover, we propose a novel two-streams deep network to further take advantage of both HandCam and HeadCam. We have collected a new synchronized HandCam and HeadCam dataset with 20 videos captured in three scenes for hand states recognition. Experiments show that our HandCam system consistently outperforms a deep-learning-based HeadCam method (with estimated manipulation regions) and a dense-trajectory-based HeadCam method in all tasks. We also show that HandCam videos captured by different users can be easily aligned to improve free v.s. active recognition accuracy (3.3% improvement) in across-scenes use case. Moreover, we observe that finetuning Convolutional Neural Network consistently improves accuracy. Finally, our novel two-streams deep network combining HandCam and HeadCam features achieves the best performance in four out of five tasks. With more data, we believe a joint HandCam and HeadCam system can robustly log hand states in daily life.



### Sparsifying Neural Network Connections for Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1512.01891v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01891v1)
- **Published**: 2015-12-07 02:56:27+00:00
- **Updated**: 2015-12-07 02:56:27+00:00
- **Authors**: Yi Sun, Xiaogang Wang, Xiaoou Tang
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes to learn high-performance deep ConvNets with sparse neural connections, referred to as sparse ConvNets, for face recognition. The sparse ConvNets are learned in an iterative way, each time one additional layer is sparsified and the entire model is re-trained given the initial weights learned in previous iterations. One important finding is that directly training the sparse ConvNet from scratch failed to find good solutions for face recognition, while using a previously learned denser model to properly initialize a sparser model is critical to continue learning effective features for face recognition. This paper also proposes a new neural correlation-based weight selection criterion and empirically verifies its effectiveness in selecting informative connections from previously learned models in each iteration. When taking a moderately sparse structure (26%-76% of weights in the dense model), the proposed sparse ConvNet model significantly improves the face recognition performance of the previous state-of-the-art DeepID2+ models given the same training data, while it keeps the performance of the baseline model with only 12% of the original parameters.



### Fast Optimization Algorithm on Riemannian Manifolds and Its Application in Low-Rank Representation
- **Arxiv ID**: http://arxiv.org/abs/1512.01927v1
- **DOI**: None
- **Categories**: **cs.NA**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1512.01927v1)
- **Published**: 2015-12-07 06:44:23+00:00
- **Updated**: 2015-12-07 06:44:23+00:00
- **Authors**: Haoran Chen, Yanfeng Sun, Junbin Gao, Yongli Hu
- **Comment**: None
- **Journal**: None
- **Summary**: The paper addresses the problem of optimizing a class of composite functions on Riemannian manifolds and a new first order optimization algorithm (FOA) with a fast convergence rate is proposed. Through the theoretical analysis for FOA, it has been proved that the algorithm has quadratic convergence. The experiments in the matrix completion task show that FOA has better performance than other first order optimization methods on Riemannian manifolds. A fast subspace pursuit method based on FOA is proposed to solve the low-rank representation model based on augmented Lagrange method on the low rank matrix variety. Experimental results on synthetic and real data sets are presented to demonstrate that both FOA and SP-RPRG(ALM) can achieve superior performance in terms of faster convergence and higher accuracy.



### Hyperspectral Chemical Plume Detection Algorithms Based On Multidimensional Iterative Filtering Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1512.01979v1
- **DOI**: 10.1098/rsta.2015.0196
- **Categories**: **math.NA**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1512.01979v1)
- **Published**: 2015-12-07 11:06:10+00:00
- **Updated**: 2015-12-07 11:06:10+00:00
- **Authors**: Antonio Cicone, Jingfang Liu, Haomin Zhou
- **Comment**: None
- **Journal**: None
- **Summary**: Chemicals released in the air can be extremely dangerous for human beings and the environment. Hyperspectral images can be used to identify chemical plumes, however the task can be extremely challenging. Assuming we know a priori that some chemical plume, with a known frequency spectrum, has been photographed using a hyperspectral sensor, we can use standard techniques like the so called matched filter or adaptive cosine estimator, plus a properly chosen threshold value, to identify the position of the chemical plume. However, due to noise and sensors fault, the accurate identification of chemical pixels is not easy even in this apparently simple situation. In this paper we present a post-processing tool that, in a completely adaptive and data driven fashion, allows to improve the performance of any classification methods in identifying the boundaries of a plume. This is done using the Multidimensional Iterative Filtering (MIF) algorithm (arXiv:1411.6051, arXiv:1507.07173), which is a non-stationary signal decomposition method like the pioneering Empirical Mode Decomposition (EMD) method. Moreover, based on the MIF technique, we propose also a pre-processing method that allows to decorrelate and mean-center a hyperspectral dataset. The Cosine Similarity measure, which often fails in practice, appears to become a successful and outperforming classifier when equipped with such pre-processing method. We show some examples of the proposed methods when applied to real life problems.



### Scalable domain adaptation of convolutional neural networks
- **Arxiv ID**: http://arxiv.org/abs/1512.02013v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.02013v1)
- **Published**: 2015-12-07 12:31:32+00:00
- **Updated**: 2015-12-07 12:31:32+00:00
- **Authors**: Adrian Popescu, Etienne Gadeski, Herv√© Le Borgne
- **Comment**: technical report, 6 pages
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) tend to become a standard approach to solve a wide array of computer vision problems. Besides important theoretical and practical advances in their design, their success is built on the existence of manually labeled visual resources, such as ImageNet. The creation of such datasets is cumbersome and here we focus on alternatives to manual labeling. We hypothesize that new resources are of uttermost importance in domains which are not or weakly covered by ImageNet, such as tourism photographs. We first collect noisy Flickr images for tourist points of interest and apply automatic or weakly-supervised reranking techniques to reduce noise. Then, we learn domain adapted models with a standard CNN architecture and compare them to a generic model obtained from ImageNet. Experimental validation is conducted with publicly available datasets, including Oxford5k, INRIA Holidays and Div150Cred. Results show that low-cost domain adaptation improves results compared to the use of generic models but also compared to strong non-CNN baselines such as triangulation embedding.



### Visualizing Deep Convolutional Neural Networks Using Natural Pre-Images
- **Arxiv ID**: http://arxiv.org/abs/1512.02017v3
- **DOI**: 10.1007/s11263-016-0911-8
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1512.02017v3)
- **Published**: 2015-12-07 12:38:13+00:00
- **Updated**: 2016-04-14 15:05:28+00:00
- **Authors**: Aravindh Mahendran, Andrea Vedaldi
- **Comment**: A substantially extended version of
  http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/mahendran15understanding.pdf.
  arXiv admin note: text overlap with arXiv:1412.0035
- **Journal**: None
- **Summary**: Image representations, from SIFT and bag of visual words to Convolutional Neural Networks (CNNs) are a crucial component of almost all computer vision systems. However, our understanding of them remains limited. In this paper we study several landmark representations, both shallow and deep, by a number of complementary visualization techniques. These visualizations are based on the concept of "natural pre-image", namely a natural-looking image whose representation has some notable property. We study in particular three such visualizations: inversion, in which the aim is to reconstruct an image from its representation, activation maximization, in which we search for patterns that maximally stimulate a representation component, and caricaturization, in which the visual patterns that a representation detects in an image are exaggerated. We pose these as a regularized energy-minimization framework and demonstrate its generality and effectiveness. In particular, we show that this method can invert representations such as HOG more accurately than recent alternatives while being applicable to CNNs too. Among our findings, we show that several layers in CNNs retain photographically accurate information about the image, with different degrees of geometric and photometric invariance.



### On The Continuous Steering of the Scale of Tight Wavelet Frames
- **Arxiv ID**: http://arxiv.org/abs/1512.02072v1
- **DOI**: 10.1137/15M1033885
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.02072v1)
- **Published**: 2015-12-07 14:50:43+00:00
- **Updated**: 2015-12-07 14:50:43+00:00
- **Authors**: Zsuzsanna P√ºsp√∂ki, John Paul Ward, Daniel Sage, Michael Unser
- **Comment**: None
- **Journal**: None
- **Summary**: In analogy with steerable wavelets, we present a general construction of adaptable tight wavelet frames, with an emphasis on scaling operations. In particular, the derived wavelets can be "dilated" by a procedure comparable to the operation of steering steerable wavelets. The fundamental aspects of the construction are the same: an admissible collection of Fourier multipliers is used to extend a tight wavelet frame, and the "scale" of the wavelets is adapted by scaling the multipliers. As an application, the proposed wavelets can be used to improve the frequency localization. Importantly, the localized frequency bands specified by this construction can be scaled efficiently using matrix multiplication.



### Clustering by Deep Nearest Neighbor Descent (D-NND): A Density-based Parameter-Insensitive Clustering Method
- **Arxiv ID**: http://arxiv.org/abs/1512.02097v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, stat.CO, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/1512.02097v1)
- **Published**: 2015-12-07 15:47:49+00:00
- **Updated**: 2015-12-07 15:47:49+00:00
- **Authors**: Teng Qiu, Yongjie Li
- **Comment**: 28 pages, 14 figures
- **Journal**: None
- **Summary**: Most density-based clustering methods largely rely on how well the underlying density is estimated. However, density estimation itself is also a challenging problem, especially the determination of the kernel bandwidth. A large bandwidth could lead to the over-smoothed density estimation in which the number of density peaks could be less than the true clusters, while a small bandwidth could lead to the under-smoothed density estimation in which spurious density peaks, or called the "ripple noise", would be generated in the estimated density. In this paper, we propose a density-based hierarchical clustering method, called the Deep Nearest Neighbor Descent (D-NND), which could learn the underlying density structure layer by layer and capture the cluster structure at the same time. The over-smoothed density estimation could be largely avoided and the negative effect of the under-estimated cases could be also largely reduced. Overall, D-NND presents not only the strong capability of discovering the underlying cluster structure but also the remarkable reliability due to its insensitivity to parameters.



### In-situ multi-scattering tomography
- **Arxiv ID**: http://arxiv.org/abs/1512.02110v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.02110v1)
- **Published**: 2015-12-07 16:24:48+00:00
- **Updated**: 2015-12-07 16:24:48+00:00
- **Authors**: Vadim Holodovsky, Yoav Y. Schechner, Anat Levin, Aviad Levis, Amit Aides
- **Comment**: None
- **Journal**: None
- **Summary**: To recover the three dimensional (3D) volumetric distribution of matter in an object, images of the object are captured from multiple directions and locations. Using these images tomographic computations extract the distribution. In highly scattering media and constrained, natural irradiance, tomography must explicitly account for off-axis scattering. Furthermore, the tomographic model and recovery must function when imaging is done in-situ, as occurs in medical imaging and ground-based atmospheric sensing. We formulate tomography that handles arbitrary orders of scattering, using a monte-carlo model. Moreover, the model is highly parallelizable in our formulation. This enables large scale rendering and recovery of volumetric scenes having a large number of variables. We solve stability and conditioning problems that stem from radiative transfer (RT) modeling in-situ.



### A Large Dataset to Train Convolutional Networks for Disparity, Optical Flow, and Scene Flow Estimation
- **Arxiv ID**: http://arxiv.org/abs/1512.02134v1
- **DOI**: 10.1109/CVPR.2016.438
- **Categories**: **cs.CV**, cs.LG, stat.ML, I.2.6; I.2.10; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1512.02134v1)
- **Published**: 2015-12-07 17:35:00+00:00
- **Updated**: 2015-12-07 17:35:00+00:00
- **Authors**: Nikolaus Mayer, Eddy Ilg, Philip H√§usser, Philipp Fischer, Daniel Cremers, Alexey Dosovitskiy, Thomas Brox
- **Comment**: Includes supplementary material
- **Journal**: None
- **Summary**: Recent work has shown that optical flow estimation can be formulated as a supervised learning task and can be successfully solved with convolutional networks. Training of the so-called FlowNet was enabled by a large synthetically generated dataset. The present paper extends the concept of optical flow estimation via convolutional networks to disparity and scene flow estimation. To this end, we propose three synthetic stereo video datasets with sufficient realism, variation, and size to successfully train large networks. Our datasets are the first large-scale datasets to enable training and evaluating scene flow methods. Besides the datasets, we present a convolutional network for real-time disparity estimation that provides state-of-the-art results. By combining a flow and disparity estimation network and training it jointly, we demonstrate the first scene flow estimation with a convolutional network.



### Simple Baseline for Visual Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1512.02167v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1512.02167v2)
- **Published**: 2015-12-07 19:00:54+00:00
- **Updated**: 2015-12-15 05:17:49+00:00
- **Authors**: Bolei Zhou, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, Rob Fergus
- **Comment**: One comparison method's scores are put into the correct column, and a
  new experiment of generating attention map is added
- **Journal**: None
- **Summary**: We describe a very simple bag-of-words baseline for visual question answering. This baseline concatenates the word features from the question and CNN features from the image to predict the answer. When evaluated on the challenging VQA dataset [2], it shows comparable performance to many recent approaches using recurrent neural networks. To explore the strength and weakness of the trained model, we also provide an interactive web demo and open-source code. .



### Pseudo-Bayesian Robust PCA: Algorithms and Analyses
- **Arxiv ID**: http://arxiv.org/abs/1512.02188v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1512.02188v2)
- **Published**: 2015-12-07 19:43:54+00:00
- **Updated**: 2016-10-07 16:08:25+00:00
- **Authors**: Tae-Hyun Oh, Yasuyuki Matsushita, In So Kweon, David Wipf
- **Comment**: Journal version of NIPS 2016. Submitted to TPAMI
- **Journal**: None
- **Summary**: Commonly used in computer vision and other applications, robust PCA represents an algorithmic attempt to reduce the sensitivity of classical PCA to outliers. The basic idea is to learn a decomposition of some data matrix of interest into low rank and sparse components, the latter representing unwanted outliers. Although the resulting optimization problem is typically NP-hard, convex relaxations provide a computationally-expedient alternative with theoretical support. However, in practical regimes performance guarantees break down and a variety of non-convex alternatives, including Bayesian-inspired models, have been proposed to boost estimation quality. Unfortunately though, without additional a priori knowledge none of these methods can significantly expand the critical operational range such that exact principal subspace recovery is possible. Into this mix we propose a novel pseudo-Bayesian algorithm that explicitly compensates for design weaknesses in many existing non-convex approaches leading to state-of-the-art performance with a sound analytical foundation. Surprisingly, our algorithm can even outperform convex matrix completion despite the fact that the latter is provided with perfect knowledge of which entries are not corrupted.



