# Arxiv Papers in cs.CV on 2015-12-03
### The Indian Spontaneous Expression Database for Emotion Recognition
- **Arxiv ID**: http://arxiv.org/abs/1512.00932v2
- **DOI**: 10.1109/TAFFC.2015.2498174
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00932v2)
- **Published**: 2015-12-03 02:51:08+00:00
- **Updated**: 2016-06-16 02:01:16+00:00
- **Authors**: S L Happy, Priyadarshi Patnaik, Aurobinda Routray, Rajlakshmi Guha
- **Comment**: in IEEE Transactions on Affective Computing, 2016
- **Journal**: None
- **Summary**: Automatic recognition of spontaneous facial expressions is a major challenge in the field of affective computing. Head rotation, face pose, illumination variation, occlusion etc. are the attributes that increase the complexity of recognition of spontaneous expressions in practical applications. Effective recognition of expressions depends significantly on the quality of the database used. Most well-known facial expression databases consist of posed expressions. However, currently there is a huge demand for spontaneous expression databases for the pragmatic implementation of the facial expression recognition algorithms. In this paper, we propose and establish a new facial expression database containing spontaneous expressions of both male and female participants of Indian origin. The database consists of 428 segmented video clips of the spontaneous facial expressions of 50 participants. In our experiment, emotions were induced among the participants by using emotional videos and simultaneously their self-ratings were collected for each experienced emotion. Facial expression clips were annotated carefully by four trained decoders, which were further validated by the nature of stimuli used and self-report of emotions. An extensive analysis was carried out on the database using several machine learning algorithms and the results are provided for future reference. Such a spontaneous database will help in the development and validation of algorithms for recognition of spontaneous expressions.



### A Literature Survey of various Fingerprint De-noising Techniques to justify the need of a new De-noising model based upon Pixel Component Analysis
- **Arxiv ID**: http://arxiv.org/abs/1512.00939v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.00939v1)
- **Published**: 2015-12-03 04:13:38+00:00
- **Updated**: 2015-12-03 04:13:38+00:00
- **Authors**: Siddharth Choubey, Deepika Banchhor
- **Comment**: None
- **Journal**: None
- **Summary**: Image Preprocessing is a vital step in the field of image processing for biometric pattern recognition. This paper studies and reviews various classical and modern fingerprint image de-noising models. The various model used for de-noising ranges widely from transform matrix using frequency, histogram model de-noising, de-noising by introducing Gabor filter and its types to enhance fingerprint images.   The output efficiency of various de-noising model proposed earlier is calculated on the basis of SNR (signal to noise ratio) and MSE (mean square error rate). Our simulated experimental results indicates that incorporating the de-noising model based on Gabor filter inside domain of wavelet ranges with composite method only betters MSE (Mean Square Error). Improved MSE without significant improvement in SNR improves the fingerprint images only by a little margin which is non-optimal in nature. Thus the objective of this research paper is to build an optimal de-noising model for fingerprint images so that its usage in biometric authentication can be more robust in nature.



### Weighted Schatten $p$-Norm Minimization for Image Denoising and Background Subtraction
- **Arxiv ID**: http://arxiv.org/abs/1512.01003v1
- **DOI**: 10.1109/TIP.2016.2599290
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01003v1)
- **Published**: 2015-12-03 09:24:20+00:00
- **Updated**: 2015-12-03 09:24:20+00:00
- **Authors**: Yuan Xie, Shuhang Gu, Yan Liu, Wangmeng Zuo, Wensheng Zhang, Lei Zhang
- **Comment**: 13 pages, 11 figures
- **Journal**: None
- **Summary**: Low rank matrix approximation (LRMA), which aims to recover the underlying low rank matrix from its degraded observation, has a wide range of applications in computer vision. The latest LRMA methods resort to using the nuclear norm minimization (NNM) as a convex relaxation of the nonconvex rank minimization. However, NNM tends to over-shrink the rank components and treats the different rank components equally, limiting its flexibility in practical applications. We propose a more flexible model, namely the Weighted Schatten $p$-Norm Minimization (WSNM), to generalize the NNM to the Schatten $p$-norm minimization with weights assigned to different singular values. The proposed WSNM not only gives better approximation to the original low-rank assumption, but also considers the importance of different rank components. We analyze the solution of WSNM and prove that, under certain weights permutation, WSNM can be equivalently transformed into independent non-convex $l_p$-norm subproblems, whose global optimum can be efficiently solved by generalized iterated shrinkage algorithm. We apply WSNM to typical low-level vision problems, e.g., image denoising and background subtraction. Extensive experimental results show, both qualitatively and quantitatively, that the proposed WSNM can more effectively remove noise, and model complex and dynamic scenes compared with state-of-the-art methods.



### Simulations for Validation of Vision Systems
- **Arxiv ID**: http://arxiv.org/abs/1512.01030v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01030v1)
- **Published**: 2015-12-03 10:53:32+00:00
- **Updated**: 2015-12-03 10:53:32+00:00
- **Authors**: V S R Veeravasarapu, Rudra Narayan Hota, Constantin Rothkopf, Ramesh Visvanathan
- **Comment**: None
- **Journal**: None
- **Summary**: As the computer vision matures into a systems science and engineering discipline, there is a trend in leveraging latest advances in computer graphics simulations for performance evaluation, learning, and inference. However, there is an open question on the utility of graphics simulations for vision with apparently contradicting views in the literature. In this paper, we place the results from the recent literature in the context of performance characterization methodology outlined in the 90's and note that insights derived from simulations can be qualitative or quantitative depending on the degree of fidelity of models used in simulation and the nature of the question posed by the experimenter. We describe a simulation platform that incorporates latest graphics advances and use it for systematic performance characterization and trade-off analysis for vision system design. We verify the utility of the platform in a case study of validating a generative model inspired vision hypothesis, Rank-Order consistency model, in the contexts of global and local illumination changes, and bad weather, and high-frequency noise. Our approach establishes the link between alternative viewpoints, involving models with physics based semantics and signal and perturbation semantics and confirms insights in literature on robust change detection.



### Occlusion-Aware Human Pose Estimation with Mixtures of Sub-Trees
- **Arxiv ID**: http://arxiv.org/abs/1512.01055v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01055v1)
- **Published**: 2015-12-03 12:25:33+00:00
- **Updated**: 2015-12-03 12:25:33+00:00
- **Authors**: Ibrahim Radwan, Abhinav Dhall, Roland Goecke
- **Comment**: 12 pages, 5 figures and 3 Tables
- **Journal**: None
- **Summary**: In this paper, we study the problem of learning a model for human pose estimation as mixtures of compositional sub-trees in two layers of prediction. This involves estimating the pose of a sub-tree followed by identifying the relationships between sub-trees that are used to handle occlusions between different parts. The mixtures of the sub-trees are learnt utilising both geometric and appearance distances. The Chow-Liu (CL) algorithm is recursively applied to determine the inter-relations between the nodes and to build the structure of the sub-trees. These structures are used to learn the latent parameters of the sub-trees and the inference is done using a standard belief propagation technique. The proposed method handles occlusions during the inference process by identifying overlapping regions between different sub-trees and introducing a penalty term for overlapping parts. Experiments are performed on three different datasets: the Leeds Sports, Image Parse and UIUC People datasets. The results show the robustness of the proposed method to occlusions over the state-of-the-art approaches.



### Prototypical Priors: From Improving Classification to Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1512.01192v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.01192v2)
- **Published**: 2015-12-03 19:06:16+00:00
- **Updated**: 2018-04-25 13:40:35+00:00
- **Authors**: Saumya Jetley, Bernardino Romera-Paredes, Sadeep Jayasumana, Philip Torr
- **Comment**: 12 Pages, 6 Figures, 2 Tables, in British Machine Vision Conference
  (BMVC), 2015
- **Journal**: None
- **Summary**: Recent works on zero-shot learning make use of side information such as visual attributes or natural language semantics to define the relations between output visual classes and then use these relationships to draw inference on new unseen classes at test time. In a novel extension to this idea, we propose the use of visual prototypical concepts as side information. For most real-world visual object categories, it may be difficult to establish a unique prototype. However, in cases such as traffic signs, brand logos, flags, and even natural language characters, these prototypical templates are available and can be leveraged for an improved recognition performance. The present work proposes a way to incorporate this prototypical information in a deep learning framework. Using prototypes as prior information, the deepnet pipeline learns the input image projections into the prototypical embedding space subject to minimization of the final classification loss. Based on our experiments with two different datasets of traffic signs and brand logos, prototypical embeddings incorporated in a conventional convolutional neural network improve the recognition performance. Recognition accuracy on the Belga logo dataset is especially noteworthy and establishes a new state-of-the-art. In zero-shot learning scenarios, the same system can be directly deployed to draw inference on unseen classes by simply adding the prototypical information for these new classes at test time. Thus, unlike earlier approaches, testing on seen and unseen classes is handled using the same pipeline, and the system can be tuned for a trade-off of seen and unseen class performance as per task requirement. Comparison with one of the latest works in the zero-shot learning domain yields top results on the two datasets mentioned above.



