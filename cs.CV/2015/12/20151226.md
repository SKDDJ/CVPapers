# Arxiv Papers in cs.CV on 2015-12-26
### Part-Stacked CNN for Fine-Grained Visual Categorization
- **Arxiv ID**: http://arxiv.org/abs/1512.08086v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.08086v1)
- **Published**: 2015-12-26 08:08:40+00:00
- **Updated**: 2015-12-26 08:08:40+00:00
- **Authors**: Shaoli Huang, Zhe Xu, Dacheng Tao, Ya Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: In the context of fine-grained visual categorization, the ability to interpret models as human-understandable visual manuals is sometimes as important as achieving high classification accuracy. In this paper, we propose a novel Part-Stacked CNN architecture that explicitly explains the fine-grained recognition process by modeling subtle differences from object parts. Based on manually-labeled strong part annotations, the proposed architecture consists of a fully convolutional network to locate multiple object parts and a two-stream classification network that en- codes object-level and part-level cues simultaneously. By adopting a set of sharing strategies between the computation of multiple object parts, the proposed architecture is very efficient running at 20 frames/sec during inference. Experimental results on the CUB-200-2011 dataset reveal the effectiveness of the proposed architecture, from both the perspective of classification accuracy and model interpretability.



### Data Driven Robust Image Guided Depth Map Restoration
- **Arxiv ID**: http://arxiv.org/abs/1512.08103v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.08103v1)
- **Published**: 2015-12-26 12:04:54+00:00
- **Updated**: 2015-12-26 12:04:54+00:00
- **Authors**: Wei Liu, Yun Gu, Chunhua Shen, Xiaogang Chen, Qiang Wu, Jie Yang
- **Comment**: 9 pages, 9 figures, conference paper
- **Journal**: None
- **Summary**: Depth maps captured by modern depth cameras such as Kinect and Time-of-Flight (ToF) are usually contaminated by missing data, noises and suffer from being of low resolution. In this paper, we present a robust method for high-quality restoration of a degraded depth map with the guidance of the corresponding color image. We solve the problem in an energy optimization framework that consists of a novel robust data term and smoothness term. To accommodate not only the noise but also the inconsistency between depth discontinuities and the color edges, we model both the data term and smoothness term with a robust exponential error norm function. We propose to use Iteratively Re-weighted Least Squares (IRLS) methods for efficiently solving the resulting highly non-convex optimization problem. More importantly, we further develop a data-driven adaptive parameter selection scheme to properly determine the parameter in the model. We show that the proposed approach can preserve fine details and sharp depth discontinuities even for a large upsampling factor ($8\times$ for example). Experimental results on both simulated and real datasets demonstrate that the proposed method outperforms recent state-of-the-art methods in coping with the heavy noise, preserving sharp depth discontinuities and suppressing the texture copy artifacts.



