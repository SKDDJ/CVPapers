# Arxiv Papers in cs.CV on 2015-12-28
### Outlier Detection In Large-scale Traffic Data By Na√Øve Bayes Method and Gaussian Mixture Model Method
- **Arxiv ID**: http://arxiv.org/abs/1512.08413v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.08413v1)
- **Published**: 2015-12-28 13:59:16+00:00
- **Updated**: 2015-12-28 13:59:16+00:00
- **Authors**: Philip Lam, Lili Wang, Henry Y. T. Ngan, Nelson H. C. Yung, Anthony G. O. Yeh
- **Comment**: 6 pages, 5 figures
- **Journal**: None
- **Summary**: It is meaningful to detect outliers in traffic data for traffic management. However, this is a massive task for people from large-scale database to distinguish outliers. In this paper, we present two methods: Kernel Smoothing Na\"ive Bayes (NB) method and Gaussian Mixture Model (GMM) method to automatically detect any hardware errors as well as abnormal traffic events in traffic data collected at a four-arm junction in Hong Kong. Traffic data was recorded in a video format, and converted to spatial-temporal (ST) traffic signals by statistics. The ST signals are then projected to a two-dimensional (2D) (x,y)-coordinate plane by Principal Component Analysis (PCA) for dimension reduction. We assume that inlier data are normal distributed. As such, the NB and GMM methods are successfully applied in outlier detection (OD) for traffic data. The kernel smooth NB method assumes the existence of kernel distributions in traffic data and uses Bayes' Theorem to perform OD. In contrast, the GMM method believes the traffic data is formed by the mixture of Gaussian distributions and exploits confidence region for OD. This paper would address the modeling of each method and evaluate their respective performances. Experimental results show that the NB algorithm with Triangle kernel and GMM method achieve up to 93.78% and 94.50% accuracies, respectively.



### Graph entropies in texture segmentation of images
- **Arxiv ID**: http://arxiv.org/abs/1512.08424v1
- **DOI**: 10.1002/9783527693245.ch7
- **Categories**: **cs.CV**, I.4.7; I.4.6; G.2.2; I.2.10; G.1.2
- **Links**: [PDF](http://arxiv.org/pdf/1512.08424v1)
- **Published**: 2015-12-28 14:44:05+00:00
- **Updated**: 2015-12-28 14:44:05+00:00
- **Authors**: Martin Welk
- **Comment**: 28 pages, 6 figures
- **Journal**: None
- **Summary**: We study the applicability of a set of texture descriptors introduced in recent work by the author to texture-based segmentation of images. The texture descriptors under investigation result from applying graph indices from quantitative graph theory to graphs encoding the local structure of images. The underlying graphs arise from the computation of morphological amoebas as structuring elements for adaptive morphology, either as weighted or unweighted Dijkstra search trees or as edge-weighted pixel graphs within structuring elements. In the present paper we focus on texture descriptors in which the graph indices are entropy-based, and use them in a geodesic active contour framework for image segmentation. Experiments on several synthetic and one real-world image are shown to demonstrate texture segmentation by this approach. Forthermore, we undertake an attempt to analyse selected entropy-based texture descriptors with regard to what information about texture they actually encode. Whereas this analysis uses some heuristic assumptions, it indicates that the graph-based texture descriptors are related to fractal dimension measures that have been proven useful in texture analysis.



### MRF-Based Multispectral Image Fusion Using an Adaptive Approach Based on Edge-Guided Interpolation
- **Arxiv ID**: http://arxiv.org/abs/1512.08475v6
- **DOI**: 10.4236/jgis.2017.92008
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1512.08475v6)
- **Published**: 2015-12-28 18:18:43+00:00
- **Updated**: 2019-04-24 09:53:32+00:00
- **Authors**: Mohammad Reza Khosravi, Mohammad Sharif-Yazd, Mohammad Kazem Moghimi, Ahmad Keshavarz, Habib Rostami, Suleiman Mansouri
- **Comment**: 12 pages
- **Journal**: Journal of Geographic Information System, vol. 9, no. 2, pp.
  114-125 (2017)
- **Summary**: In interpretation of remote sensing images, it is possible that some images which are supplied by different sensors become incomprehensible. For better visual perception of these images, it is essential to operate series of pre-processing and elementary corrections and then operate a series of main processing steps for more precise analysis on the images. There are several approaches for processing which are depended on the type of remote sensing images. The discussed approach in this article, i.e. image fusion, is the use of natural colors of an optical image for adding color to a grayscale satellite image which gives us the ability for better observation of the HR image of OLI sensor of Landsat-8. This process with emphasis on details of fusion technique has previously been performed; however, we are going to apply the concept of the interpolation process. In fact, we see many important software tools such as ENVI and ERDAS as the most famous remote sensing image processing tools have only classical interpolation techniques (such as bi-linear (BL) and bi-cubic/cubic convolution (CC)). Therefore, ENVI- and ERDAS-based researches in image fusion area and even other fusion researches often dont use new and better interpolators and are mainly concentrated on the fusion algorithms details for achieving a better quality, so we only focus on the interpolation impact on fusion quality in Landsat-8 multispectral images. The important feature of this approach is to use a statistical, adaptive, and edge-guided interpolation method for improving the color quality in the images in practice. Numerical simulations show selecting the suitable interpolation techniques in MRF-based images creates better quality than the classical interpolators.



### Visually Indicated Sounds
- **Arxiv ID**: http://arxiv.org/abs/1512.08512v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.SD
- **Links**: [PDF](http://arxiv.org/pdf/1512.08512v2)
- **Published**: 2015-12-28 20:56:50+00:00
- **Updated**: 2016-04-30 03:03:04+00:00
- **Authors**: Andrew Owens, Phillip Isola, Josh McDermott, Antonio Torralba, Edward H. Adelson, William T. Freeman
- **Comment**: None
- **Journal**: None
- **Summary**: Objects make distinctive sounds when they are hit or scratched. These sounds reveal aspects of an object's material properties, as well as the actions that produced them. In this paper, we propose the task of predicting what sound an object makes when struck as a way of studying physical interactions within a visual scene. We present an algorithm that synthesizes sound from silent videos of people hitting and scratching objects with a drumstick. This algorithm uses a recurrent neural network to predict sound features from videos and then produces a waveform from these features with an example-based synthesis procedure. We show that the sounds predicted by our model are realistic enough to fool participants in a "real or fake" psychophysical experiment, and that they convey significant information about material properties and physical interactions.



