# Arxiv Papers in cs.CV on 2015-11-05
### Coherent Motion Segmentation in Moving Camera Videos using Optical Flow Orientations
- **Arxiv ID**: http://arxiv.org/abs/1511.01619v1
- **DOI**: 10.1109/ICCV.2013.199
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01619v1)
- **Published**: 2015-11-05 06:10:13+00:00
- **Updated**: 2015-11-05 06:10:13+00:00
- **Authors**: Manjunath Narayana, Allen Hanson, Erik Learned-Miller
- **Comment**: 8 pages, 5 figures, in 2013 IEEE International Conference on Computer
  Vision (ICCV)
- **Journal**: None
- **Summary**: In moving camera videos, motion segmentation is commonly performed using the image plane motion of pixels, or optical flow. However, objects that are at different depths from the camera can exhibit different optical flows even if they share the same real-world motion. This can cause a depth-dependent segmentation of the scene. Our goal is to develop a segmentation algorithm that clusters pixels that have similar real-world motion irrespective of their depth in the scene. Our solution uses optical flow orientations instead of the complete vectors and exploits the well-known property that under camera translation, optical flow orientations are independent of object depth. We introduce a probabilistic model that automatically estimates the number of observed independent motions and results in a labeling that is consistent with real-world motion in the scene. The result of our system is that static objects are correctly identified as one segment, even if they are at different depths. Color features and information from previous frames in the video sequence are used to correct occasional errors due to the orientation-based segmentation. We present results on more than thirty videos from different benchmarks. The system is particularly robust on complex background scenes containing objects at significantly different depths



### Background subtraction - separating the modeling and the inference
- **Arxiv ID**: http://arxiv.org/abs/1511.01627v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01627v1)
- **Published**: 2015-11-05 06:57:38+00:00
- **Updated**: 2015-11-05 06:57:38+00:00
- **Authors**: Manjunath Narayana, Allen Hanson, Erik Learned-Miller
- **Comment**: 19 pages, 6 figures, Machine Vision and Applications journal
- **Journal**: Machine Vision and Applications July 2014, Volume 25, Issue 5, pp
  1163-1174
- **Summary**: In its early implementations, background modeling was a process of building a model for the background of a video with a stationary camera, and identifying pixels that did not conform well to this model. The pixels that were not well-described by the background model were assumed to be moving objects. Many systems today maintain models for the foreground as well as the background, and these models compete to explain the pixels in a video. In this paper, we argue that the logical endpoint of this evolution is to simply use Bayes' rule to classify pixels. In particular, it is essential to have a background likelihood, a foreground likelihood, and a prior at each pixel. A simple application of Bayes' rule then gives a posterior probability over the label. The only remaining question is the quality of the component models: the background likelihood, the foreground likelihood, and the prior. We describe a model for the likelihoods that is built by using not only the past observations at a given pixel location, but by also including observations in a spatial neighborhood around the location. This enables us to model the influence between neighboring pixels and is an improvement over earlier pixelwise models that do not allow for such influence. Although similar in spirit to the joint domain-range model, we show that our model overcomes certain deficiencies in that model. We use a spatially dependent prior for the background and foreground. The background and foreground labels from the previous frame, after spatial smoothing to account for movement of objects,are used to build the prior for the current frame.



### Background Modeling Using Adaptive Pixelwise Kernel Variances in a Hybrid Feature Space
- **Arxiv ID**: http://arxiv.org/abs/1511.01631v1
- **DOI**: 10.1109/CVPR.2012.6247916
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01631v1)
- **Published**: 2015-11-05 07:18:05+00:00
- **Updated**: 2015-11-05 07:18:05+00:00
- **Authors**: Manjunath Narayana, Allen Hanson, Erik Learned-Miller
- **Comment**: 8 pages, 4 figures, CVPR 2012 conference paper in CVPR '12
  Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR)
- **Journal**: None
- **Summary**: Recent work on background subtraction has shown developments on two major fronts. In one, there has been increasing sophistication of probabilistic models, from mixtures of Gaussians at each pixel [7], to kernel density estimates at each pixel [1], and more recently to joint domainrange density estimates that incorporate spatial information [6]. Another line of work has shown the benefits of increasingly complex feature representations, including the use of texture information, local binary patterns, and recently scale-invariant local ternary patterns [4]. In this work, we use joint domain-range based estimates for background and foreground scores and show that dynamically choosing kernel variances in our kernel estimates at each individual pixel can significantly improve results. We give a heuristic method for selectively applying the adaptive kernel calculations which is nearly as accurate as the full procedure but runs much faster. We combine these modeling improvements with recently developed complex features [4] and show significant improvements on a standard backgrounding benchmark.



### Image classification based on support vector machine and the fusion of complementary features
- **Arxiv ID**: http://arxiv.org/abs/1511.01706v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01706v1)
- **Published**: 2015-11-05 11:57:28+00:00
- **Updated**: 2015-11-05 11:57:28+00:00
- **Authors**: Huilin Gao, Wenjie Chen, Lihua Dou
- **Comment**: 22 pages,4 figures
- **Journal**: None
- **Summary**: Image Classification based on BOW (Bag-of-words) has broad application prospect in pattern recognition field but the shortcomings are existed because of single feature and low classification accuracy. To this end we combine three ingredients: (i) Three features with functions of mutual complementation are adopted to describe the images, including PHOW (Pyramid Histogram of Words), PHOC (Pyramid Histogram of Color) and PHOG (Pyramid Histogram of Orientated Gradients). (ii) The improvement of traditional BOW model is presented by using dense sample and an improved K-means clustering method for constructing the visual dictionary. (iii) An adaptive feature-weight adjusted image categorization algorithm based on the SVM and the fusion of multiple features is adopted. Experiments carried out on Caltech 101 database confirm the validity of the proposed approach. From the experimental results can be seen that the classification accuracy rate of the proposed method is improved by 7%-17% higher than that of the traditional BOW methods. This algorithm makes full use of global, local and spatial information and has significant improvements to the classification accuracy.



### Multi-Target Tracking and Occlusion Handling with Learned Variational Bayesian Clusters and a Social Force Model
- **Arxiv ID**: http://arxiv.org/abs/1511.01726v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01726v1)
- **Published**: 2015-11-05 13:01:35+00:00
- **Updated**: 2015-11-05 13:01:35+00:00
- **Authors**: Ata-ur-Rehman, Syed Mohsen Naqvi, Lyudmila Mihaylova, Jonathon Chambers
- **Comment**: 19 pages, 14 figures
- **Journal**: None
- **Summary**: This paper considers the problem of multiple human target tracking in a sequence of video data. A solution is proposed which is able to deal with the challenges of a varying number of targets, interactions and when every target gives rise to multiple measurements. The developed novel algorithm comprises variational Bayesian clustering combined with a social force model, integrated within a particle filter with an enhanced prediction step. It performs measurement-to-target association by automatically detecting the measurement relevance. The performance of the developed algorithm is evaluated over several sequences from publicly available data sets: AV16.3, CAVIAR and PETS2006, which demonstrates that the proposed algorithm successfully initializes and tracks a variable number of targets in the presence of complex occlusions. A comparison with state-of-the-art techniques due to Khan et al., Laet et al. and Czyz et al. shows improved tracking performance.



### Symmetry-invariant optimization in deep networks
- **Arxiv ID**: http://arxiv.org/abs/1511.01754v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1511.01754v2)
- **Published**: 2015-11-05 14:17:40+00:00
- **Updated**: 2015-11-07 19:01:03+00:00
- **Authors**: Vijay Badrinarayanan, Bamdev Mishra, Roberto Cipolla
- **Comment**: Submitted to ICLR 2016. arXiv admin note: text overlap with
  arXiv:1511.01029
- **Journal**: None
- **Summary**: Recent works have highlighted scale invariance or symmetry that is present in the weight space of a typical deep network and the adverse effect that it has on the Euclidean gradient based stochastic gradient descent optimization. In this work, we show that these and other commonly used deep networks, such as those which use a max-pooling and sub-sampling layer, possess more complex forms of symmetry arising from scaling based reparameterization of the network weights. We then propose two symmetry-invariant gradient based weight updates for stochastic gradient descent based learning. Our empirical evidence based on the MNIST dataset shows that these updates improve the test performance without sacrificing the computational efficiency of the weight updates. We also show the results of training with one of the proposed weight updates on an image segmentation problem.



### Wood Species Recognition Based on SIFT Keypoint Histogram
- **Arxiv ID**: http://arxiv.org/abs/1511.01804v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01804v4)
- **Published**: 2015-11-05 16:33:54+00:00
- **Updated**: 2015-12-16 03:49:07+00:00
- **Authors**: Shuaiqi Hu, Ke Li, Xudong Bao
- **Comment**: CISP 2015
- **Journal**: None
- **Summary**: Traditionally, only experts who are equipped with professional knowledge and rich experience are able to recognize different species of wood. Applying image processing techniques for wood species recognition can not only reduce the expense to train qualified identifiers, but also increase the recognition accuracy. In this paper, a wood species recognition technique base on Scale Invariant Feature Transformation (SIFT) keypoint histogram is proposed. We use first the SIFT algorithm to extract keypoints from wood cross section images, and then k-means and k-means++ algorithms are used for clustering. Using the clustering results, an SIFT keypoints histogram is calculated for each wood image. Furthermore, several classification models, including Artificial Neural Networks (ANN), Support Vector Machine (SVM) and K-Nearest Neighbor (KNN) are used to verify the performance of the method. Finally, through comparing with other prevalent wood recognition methods such as GLCM and LBP, results show that our scheme achieves higher accuracy.



### Convolutional Neural Network for Stereotypical Motor Movement Detection in Autism
- **Arxiv ID**: http://arxiv.org/abs/1511.01865v3
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1511.01865v3)
- **Published**: 2015-11-05 19:36:33+00:00
- **Updated**: 2016-06-07 19:11:34+00:00
- **Authors**: Nastaran Mohammadian Rad, Andrea Bizzego, Seyed Mostafa Kia, Giuseppe Jurman, Paola Venuti, Cesare Furlanello
- **Comment**: Presented at 5th NIPS Workshop on Machine Learning and Interpretation
  in Neuroimaging (MLINI), 2015, (http://arxiv.org/html/1605.04435), Report-no:
  MLINI/2015/13
- **Journal**: None
- **Summary**: Autism Spectrum Disorders (ASDs) are often associated with specific atypical postural or motor behaviors, of which Stereotypical Motor Movements (SMMs) have a specific visibility. While the identification and the quantification of SMM patterns remain complex, its automation would provide support to accurate tuning of the intervention in the therapy of autism. Therefore, it is essential to develop automatic SMM detection systems in a real world setting, taking care of strong inter-subject and intra-subject variability. Wireless accelerometer sensing technology can provide a valid infrastructure for real-time SMM detection, however such variability remains a problem also for machine learning methods, in particular whenever handcrafted features extracted from accelerometer signal are considered. Here, we propose to employ the deep learning paradigm in order to learn discriminating features from multi-sensor accelerometer signals. Our results provide preliminary evidence that feature learning and transfer learning embedded in the deep architecture achieve higher accurate SMM detectors in longitudinal scenarios.



### Radon-Nikodym approximation in application to image analysis
- **Arxiv ID**: http://arxiv.org/abs/1511.01887v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01887v2)
- **Published**: 2015-11-05 20:43:01+00:00
- **Updated**: 2015-12-15 19:20:17+00:00
- **Authors**: Vladislav Gennadievich Malyshkin
- **Comment**: Images interpolated with d_x=d_y=100 are added to show the
  practicality of high order moments calculation
- **Journal**: None
- **Summary**: For an image pixel information can be converted to the moments of some basis $Q_k$, e.g. Fourier-Mellin, Zernike, monomials, etc. Given sufficient number of moments pixel information can be completely recovered, for insufficient number of moments only partial information can be recovered and the image reconstruction is, at best, of interpolatory type. Standard approach is to present interpolated value as a linear combination of basis functions, what is equivalent to least squares expansion. However, recent progress in numerical stability of moments estimation allows image information to be recovered from moments in a completely different manner, applying Radon-Nikodym type of expansion, what gives the result as a ratio of two quadratic forms of basis functions. In contrast with least squares the Radon-Nikodym approach has oscillation near the boundaries very much suppressed and does not diverge outside of basis support. While least squares theory operate with vectors $<fQ_k>$, Radon-Nikodym theory operates with matrices $<fQ_jQ_k>$, what make the approach much more suitable to image transforms and statistical property estimation.



### Recovering hard-to-find object instances by sampling context-based object proposals
- **Arxiv ID**: http://arxiv.org/abs/1511.01954v3
- **DOI**: 10.1016/j.cviu.2016.08.007
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.01954v3)
- **Published**: 2015-11-05 23:39:19+00:00
- **Updated**: 2016-10-04 08:30:40+00:00
- **Authors**: Jose Oramas M., Tinne Tuytelaars
- **Comment**: Computer Vision and Image Understanding (CVIU)
- **Journal**: None
- **Summary**: In this paper we focus on improving object detection performance in terms of recall. We propose a post-detection stage during which we explore the image with the objective of recovering missed detections. This exploration is performed by sampling object proposals in the image. We analyze four different strategies to perform this sampling, giving special attention to strategies that exploit spatial relations between objects. In addition, we propose a novel method to discover higher-order relations between groups of objects. Experiments on the challenging KITTI dataset show that our proposed relations-based proposal generation strategies can help improving recall at the cost of a relatively low amount of object proposals.



