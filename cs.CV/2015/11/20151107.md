# Arxiv Papers in cs.CV on 2015-11-07
### Stacked Attention Networks for Image Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1511.02274v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1511.02274v2)
- **Published**: 2015-11-07 00:43:32+00:00
- **Updated**: 2016-01-26 20:37:49+00:00
- **Authors**: Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Smola
- **Comment**: test-dev/standard results added
- **Journal**: None
- **Summary**: This paper presents stacked attention networks (SANs) that learn to answer natural language questions from images. SANs use semantic representation of a question as query to search for the regions in an image that are related to the answer. We argue that image question answering (QA) often requires multiple steps of reasoning. Thus, we develop a multiple-layer SAN in which we query an image multiple times to infer the answer progressively. Experiments conducted on four image QA data sets demonstrate that the proposed SANs significantly outperform previous state-of-the-art approaches. The visualization of the attention layers illustrates the progress that the SAN locates the relevant visual clues that lead to the answer of the question layer-by-layer.



### Fingertip in the Eye: A cascaded CNN pipeline for the real-time fingertip detection in egocentric videos
- **Arxiv ID**: http://arxiv.org/abs/1511.02282v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.02282v1)
- **Published**: 2015-11-07 02:06:11+00:00
- **Updated**: 2015-11-07 02:06:11+00:00
- **Authors**: Xiaorui Liu, Yichao Huang, Xin Zhang, Lianwen Jin
- **Comment**: 5 pages, 8 figures
- **Journal**: None
- **Summary**: We introduce a new pipeline for hand localization and fingertip detection. For RGB images captured from an egocentric vision mobile camera, hand and fingertip detection remains a challenging problem due to factors like background complexity and hand shape variety. To address these issues accurately and robustly, we build a large scale dataset named Ego-Fingertip and propose a bi-level cascaded pipeline of convolutional neural networks, namely, Attention-based Hand Detector as well as Multi-point Fingertip Detector. The proposed method significantly tackles challenges and achieves satisfactorily accurate prediction and real-time performance compared to previous hand and fingertip detection methods.



### Generation and Comprehension of Unambiguous Object Descriptions
- **Arxiv ID**: http://arxiv.org/abs/1511.02283v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.LG, cs.RO, I.2.6; I.2.7; I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1511.02283v3)
- **Published**: 2015-11-07 02:17:36+00:00
- **Updated**: 2016-04-11 01:11:56+00:00
- **Authors**: Junhua Mao, Jonathan Huang, Alexander Toshev, Oana Camburu, Alan Yuille, Kevin Murphy
- **Comment**: We have released the Google Refexp dataset together with a toolbox
  for visualization and evaluation, see
  https://github.com/mjhucla/Google_Refexp_toolbox. Camera ready version for
  CVPR 2016
- **Journal**: None
- **Summary**: We propose a method that can generate an unambiguous description (known as a referring expression) of a specific object or region in an image, and which can also comprehend or interpret such an expression to infer which object is being described. We show that our method outperforms previous methods that generate descriptions of objects without taking into account other potentially ambiguous objects in the scene. Our model is inspired by recent successes of deep learning methods for image captioning, but while image captioning is difficult to evaluate, our task allows for easy objective evaluation. We also present a new large-scale dataset for referring expressions, based on MS-COCO. We have released the dataset and a toolbox for visualization and evaluation, see https://github.com/mjhucla/Google_Refexp_toolbox



### Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images
- **Arxiv ID**: http://arxiv.org/abs/1511.02300v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.02300v2)
- **Published**: 2015-11-07 04:34:18+00:00
- **Updated**: 2016-03-09 19:21:23+00:00
- **Authors**: Shuran Song, Jianxiong Xiao
- **Comment**: None
- **Journal**: None
- **Summary**: We focus on the task of amodal 3D object detection in RGB-D images, which aims to produce a 3D bounding box of an object in metric form at its full extent. We introduce Deep Sliding Shapes, a 3D ConvNet formulation that takes a 3D volumetric scene from a RGB-D image as input and outputs 3D object bounding boxes. In our approach, we propose the first 3D Region Proposal Network (RPN) to learn objectness from geometric shapes and the first joint Object Recognition Network (ORN) to extract geometric features in 3D and color features in 2D. In particular, we handle objects of various sizes by training an amodal RPN at two different scales and an ORN to regress 3D bounding boxes. Experiments show that our algorithm outperforms the state-of-the-art by 13.8 in mAP and is 200x faster than the original Sliding Shapes. All source code and pre-trained models will be available at GitHub.



### Review of Person Re-identification Techniques
- **Arxiv ID**: http://arxiv.org/abs/1511.02319v1
- **DOI**: 10.1049/iet-cvi.2013.0180
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.02319v1)
- **Published**: 2015-11-07 08:26:19+00:00
- **Updated**: 2015-11-07 08:26:19+00:00
- **Authors**: Mohammad Ali Saghafi, Aini Hussain, Halimah Badioze Zaman, Mohamad Hanif Md Saad
- **Comment**: Published 2014
- **Journal**: IET Computer Vision, 2014, 8, (6), p. 455-474
- **Summary**: Person re-identification across different surveillance cameras with disjoint fields of view has become one of the most interesting and challenging subjects in the area of intelligent video surveillance. Although several methods have been developed and proposed, certain limitations and unresolved issues remain. In all of the existing re-identification approaches, feature vectors are extracted from segmented still images or video frames. Different similarity or dissimilarity measures have been applied to these vectors. Some methods have used simple constant metrics, whereas others have utilised models to obtain optimised metrics. Some have created models based on local colour or texture information, and others have built models based on the gait of people. In general, the main objective of all these approaches is to achieve a higher-accuracy rate and lowercomputational costs. This study summarises several developments in recent literature and discusses the various available methods used in person re-identification. Specifically, their advantages and disadvantages are mentioned and compared.



### A Survey of the Trends in Facial and Expression Recognition Databases and Methods
- **Arxiv ID**: http://arxiv.org/abs/1511.02407v2
- **DOI**: 10.5121/ijcses.2015.6501
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.02407v2)
- **Published**: 2015-11-07 22:05:12+00:00
- **Updated**: 2015-12-05 14:01:38+00:00
- **Authors**: Sohini Roychowdhury, Michelle Emmons
- **Comment**: 16 pages, 4 figures, 3 tables, International Journal of Computer
  Science and Engineering Survey, October, 2015
- **Journal**: International Journal of Computer Science & Engineering Survey,
  2015, 6, 1-19
- **Summary**: Automated facial identification and facial expression recognition have been topics of active research over the past few decades. Facial and expression recognition find applications in human-computer interfaces, subject tracking, real-time security surveillance systems and social networking. Several holistic and geometric methods have been developed to identify faces and expressions using public and local facial image databases. In this work we present the evolution in facial image data sets and the methodologies for facial identification and recognition of expressions such as anger, sadness, happiness, disgust, fear and surprise. We observe that most of the earlier methods for facial and expression recognition aimed at improving the recognition rates for facial feature-based methods using static images. However, the recent methodologies have shifted focus towards robust implementation of facial/expression recognition from large image databases that vary with space (gathered from the internet) and time (video recordings). The evolution trends in databases and methodologies for facial and expression recognition can be useful for assessing the next-generation topics that may have applications in security systems or personal identification systems that involve "Quantitative face" assessments.



