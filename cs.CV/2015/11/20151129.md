# Arxiv Papers in cs.CV on 2015-11-29
### MidRank: Learning to rank based on subsequences
- **Arxiv ID**: http://arxiv.org/abs/1511.08951v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1511.08951v1)
- **Published**: 2015-11-29 00:47:19+00:00
- **Updated**: 2015-11-29 00:47:19+00:00
- **Authors**: Basura Fernando, Efstratios Gavves, Damien Muselet, Tinne Tuytelaars
- **Comment**: To appear in ICCV 2015
- **Journal**: None
- **Summary**: We present a supervised learning to rank algorithm that effectively orders images by exploiting the structure in image sequences. Most often in the supervised learning to rank literature, ranking is approached either by analyzing pairs of images or by optimizing a list-wise surrogate loss function on full sequences. In this work we propose MidRank, which learns from moderately sized sub-sequences instead. These sub-sequences contain useful structural ranking information that leads to better learnability during training and better generalization during testing. By exploiting sub-sequences, the proposed MidRank improves ranking accuracy considerably on an extensive array of image ranking applications and datasets.



### Sparseness helps: Sparsity Augmented Collaborative Representation for Classification
- **Arxiv ID**: http://arxiv.org/abs/1511.08956v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.08956v1)
- **Published**: 2015-11-29 01:59:34+00:00
- **Updated**: 2015-11-29 01:59:34+00:00
- **Authors**: Naveed Akhtar, Faisal Shafait, Ajmal Mian
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Many classification approaches first represent a test sample using the training samples of all the classes. This collaborative representation is then used to label the test sample. It was a common belief that sparseness of the representation is the key to success for this classification scheme. However, more recently, it has been claimed that it is the collaboration and not the sparseness that makes the scheme effective. This claim is attractive as it allows to relinquish the computationally expensive sparsity constraint over the representation. In this paper, we first extend the analysis supporting this claim and then show that sparseness explicitly contributes to improved classification, hence it should not be completely ignored for computational gains. Inspired by this result, we augment a dense collaborative representation with a sparse representation and propose an efficient classification method that capitalizes on the resulting representation. The augmented representation and the classification method work together meticulously to achieve higher accuracy and lower computational time compared to state-of-the-art collaborative representation based classification approaches. Experiments on benchmark face, object and action databases show the efficacy of our approach.



### On-line Recognition of Handwritten Mathematical Symbols
- **Arxiv ID**: http://arxiv.org/abs/1511.09030v1
- **DOI**: 10.5445/IR/1000048047
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.09030v1)
- **Published**: 2015-11-29 15:52:00+00:00
- **Updated**: 2015-11-29 15:52:00+00:00
- **Authors**: Martin Thoma
- **Comment**: None
- **Journal**: None
- **Summary**: Finding the name of an unknown symbol is often hard, but writing the symbol is easy. This bachelor's thesis presents multiple systems that use the pen trajectory to classify handwritten symbols. Five preprocessing steps, one data augmentation algorithm, five features and five variants for multilayer Perceptron training were evaluated using 166898 recordings which were collected with two crowdsourcing projects. The evaluation results of these 21 experiments were used to create an optimized recognizer which has a TOP1 error of less than 17.5% and a TOP3 error of 4.0%. This is an improvement of 18.5% for the TOP1 error and 29.7% for the TOP3 error.



### The Multiverse Loss for Robust Transfer Learning
- **Arxiv ID**: http://arxiv.org/abs/1511.09033v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.09033v2)
- **Published**: 2015-11-29 16:10:47+00:00
- **Updated**: 2015-12-22 14:00:59+00:00
- **Authors**: Etai Littwin, Lior Wolf
- **Comment**: In the second version, whitening was applied in the CIFAR-100
  experiments in order to improve results. Figure 2 in [v1] had a duplicate
  subfigure which is now fixed
- **Journal**: None
- **Summary**: Deep learning techniques are renowned for supporting effective transfer learning. However, as we demonstrate, the transferred representations support only a few modes of separation and much of its dimensionality is unutilized. In this work, we suggest to learn, in the source domain, multiple orthogonal classifiers. We prove that this leads to a reduced rank representation, which, however, supports more discriminative directions. Interestingly, the softmax probabilities produced by the multiple classifiers are likely to be identical. Experimental results, on CIFAR-100 and LFW, further demonstrate the effectiveness of our method.



### Sparse Coral Classification Using Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1511.09067v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.09067v1)
- **Published**: 2015-11-29 19:18:36+00:00
- **Updated**: 2015-11-29 19:18:36+00:00
- **Authors**: Mohamed Elawady
- **Comment**: Thesis Submitted for the Degree of MSc Erasmus Mundus in Vision and
  Robotics (VIBOT 2014)
- **Journal**: None
- **Summary**: Autonomous repair of deep-sea coral reefs is a recent proposed idea to support the oceans ecosystem in which is vital for commercial fishing, tourism and other species. This idea can be operated through using many small autonomous underwater vehicles (AUVs) and swarm intelligence techniques to locate and replace chunks of coral which have been broken off, thus enabling re-growth and maintaining the habitat. The aim of this project is developing machine vision algorithms to enable an underwater robot to locate a coral reef and a chunk of coral on the seabed and prompt the robot to pick it up. Although there is no literature on this particular problem, related work on fish counting may give some insight into the problem. The technical challenges are principally due to the potential lack of clarity of the water and platform stabilization as well as spurious artifacts (rocks, fish, and crabs). We present an efficient sparse classification for coral species using supervised deep learning method called Convolutional Neural Networks (CNNs). We compute Weber Local Descriptor (WLD), Phase Congruency (PC), and Zero Component Analysis (ZCA) Whitening to extract shape and texture feature descriptors, which are employed to be supplementary channels (feature-based maps) besides basic spatial color channels (spatial-based maps) of coral input image, we also experiment state-of-art preprocessing underwater algorithms for image enhancement and color normalization and color conversion adjustment. Our proposed coral classification method is developed under MATLAB platform, and evaluated by two different coral datasets (University of California San Diego's Moorea Labeled Corals, and Heriot-Watt University's Atlantic Deep Sea).



