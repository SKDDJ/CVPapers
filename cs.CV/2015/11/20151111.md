# Arxiv Papers in cs.CV on 2015-11-11
### Principal Autoparallel Analysis: Data Analysis in Weitzenb√∂ck Space
- **Arxiv ID**: http://arxiv.org/abs/1511.03355v1
- **DOI**: None
- **Categories**: **stat.ME**, cs.CV, math.DG
- **Links**: [PDF](http://arxiv.org/pdf/1511.03355v1)
- **Published**: 2015-11-11 01:52:24+00:00
- **Updated**: 2015-11-11 01:52:24+00:00
- **Authors**: Stephen Marsland, Carole J Twining
- **Comment**: 9 pages, conference submission
- **Journal**: None
- **Summary**: The statistical analysis of data lying on a differentiable, locally Euclidean, manifold introduces a variety of challenges because the analogous measures to standard Euclidean statistics are local, that is only defined within a neighbourhood of each datapoint. This is because the curvature of the space means that the connection of Riemannian geometry is path dependent. In this paper we transfer the problem to Weitzenb\"{o}ck space, which has torsion, but not curvature, meaning that parallel transport is path independent, and rather than considering geodesics, it is natural to consider autoparallels, which are `straight' in the sense that they follow the local basis vectors. We demonstrate how to generate these autoparallels in a data-driven fashion, and show that the resulting representation of the data is a useful space in which to perform further analysis.



### Discovery Radiomics via StochasticNet Sequencers for Cancer Detection
- **Arxiv ID**: http://arxiv.org/abs/1511.03361v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1511.03361v1)
- **Published**: 2015-11-11 02:27:23+00:00
- **Updated**: 2015-11-11 02:27:23+00:00
- **Authors**: Mohammad Javad Shafiee, Audrey G. Chung, Devinder Kumar, Farzad Khalvati, Masoom Haider, Alexander Wong
- **Comment**: 3 pages
- **Journal**: None
- **Summary**: Radiomics has proven to be a powerful prognostic tool for cancer detection, and has previously been applied in lung, breast, prostate, and head-and-neck cancer studies with great success. However, these radiomics-driven methods rely on pre-defined, hand-crafted radiomic feature sets that can limit their ability to characterize unique cancer traits. In this study, we introduce a novel discovery radiomics framework where we directly discover custom radiomic features from the wealth of available medical imaging data. In particular, we leverage novel StochasticNet radiomic sequencers for extracting custom radiomic features tailored for characterizing unique cancer tissue phenotype. Using StochasticNet radiomic sequencers discovered using a wealth of lung CT data, we perform binary classification on 42,340 lung lesions obtained from the CT scans of 93 patients in the LIDC-IDRI dataset. Preliminary results show significant improvement over previous state-of-the-art methods, indicating the potential of the proposed discovery radiomics framework for improving cancer screening and diagnosis.



### Facial Expression Detection using Patch-based Eigen-face Isomap Networks
- **Arxiv ID**: http://arxiv.org/abs/1511.03363v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03363v1)
- **Published**: 2015-11-11 02:39:26+00:00
- **Updated**: 2015-11-11 02:39:26+00:00
- **Authors**: Sohini Roychowdhury
- **Comment**: 6 pages,7 figures, IJCAI-HINA 2015
- **Journal**: None
- **Summary**: Automated facial expression detection problem pose two primary challenges that include variations in expression and facial occlusions (glasses, beard, mustache or face covers). In this paper we introduce a novel automated patch creation technique that masks a particular region of interest in the face, followed by Eigen-value decomposition of the patched faces and generation of Isomaps to detect underlying clustering patterns among faces. The proposed masked Eigen-face based Isomap clustering technique achieves 75% sensitivity and 66-73% accuracy in classification of faces with occlusions and smiling faces in around 1 second per image. Also, betweenness centrality, Eigen centrality and maximum information flow can be used as network-based measures to identify the most significant training faces for expression classification tasks. The proposed method can be used in combination with feature-based expression classification methods in large data sets for improving expression classification accuracies.



### Multimodal MRI Neuroimaging with Motion Compensation Based on Particle Filtering
- **Arxiv ID**: http://arxiv.org/abs/1511.03369v1
- **DOI**: None
- **Categories**: **cs.CV**, physics.data-an, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1511.03369v1)
- **Published**: 2015-11-11 02:52:10+00:00
- **Updated**: 2015-11-11 02:52:10+00:00
- **Authors**: Yu-Hui Chen, Roni Mittelman, Boklye Kim, Charles Meyer, Alfred Hero
- **Comment**: This paper has been submitted to Transaction on Medical Imaging
- **Journal**: None
- **Summary**: Head movement during scanning impedes activation detection in fMRI studies. Head motion in fMRI acquired using slice-based Echo Planar Imaging (EPI) can be estimated and compensated by aligning the images onto a reference volume through image registration. However, registering EPI images volume to volume fails to consider head motion between slices, which may lead to severely biased head motion estimates. Slice-to-volume registration can be used to estimate motion parameters for each slice by more accurately representing the image acquisition sequence. However, accurate slice to volume mapping is dependent on the information content of the slices: middle slices are information rich, while edge slides are information poor and more prone to distortion. In this work, we propose a Gaussian particle filter based head motion tracking algorithm to reduce the image misregistration errors. The algorithm uses a dynamic state space model of head motion with an observation equation that models continuous slice acquisition of the scanner. Under this model the particle filter provides more accurate motion estimates and voxel position estimates. We demonstrate significant performance improvement of the proposed approach as compared to registration-only methods of head motion estimation and brain activation detection.



### A GMM-Based Stair Quality Model for Human Perceived JPEG Images
- **Arxiv ID**: http://arxiv.org/abs/1511.03398v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1511.03398v1)
- **Published**: 2015-11-11 06:44:31+00:00
- **Updated**: 2015-11-11 06:44:31+00:00
- **Authors**: Sudeng Hu, Haiqiang Wang, C. -C. Jay Kuo
- **Comment**: None
- **Journal**: None
- **Summary**: Based on the notion of just noticeable differences (JND), a stair quality function (SQF) was recently proposed to model human perception on JPEG images. Furthermore, a k-means clustering algorithm was adopted to aggregate JND data collected from multiple subjects to generate a single SQF. In this work, we propose a new method to derive the SQF using the Gaussian Mixture Model (GMM). The newly derived SQF can be interpreted as a way to characterize the mean viewer experience. Furthermore, it has a lower information criterion (BIC) value than the previous one, indicating that it offers a better model. A specific example is given to demonstrate the advantages of the new approach.



### Visual7W: Grounded Question Answering in Images
- **Arxiv ID**: http://arxiv.org/abs/1511.03416v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1511.03416v4)
- **Published**: 2015-11-11 08:29:14+00:00
- **Updated**: 2016-04-09 07:18:10+00:00
- **Authors**: Yuke Zhu, Oliver Groth, Michael Bernstein, Li Fei-Fei
- **Comment**: CVPR 2016
- **Journal**: None
- **Summary**: We have seen great progress in basic perceptual tasks such as object recognition and detection. However, AI models still fail to match humans in high-level vision tasks due to the lack of capacities for deeper reasoning. Recently the new task of visual question answering (QA) has been proposed to evaluate a model's capacity for deep image understanding. Previous works have established a loose, global association between QA sentences and images. However, many questions and answers, in practice, relate to local regions in the images. We establish a semantic link between textual descriptions and image regions by object-level grounding. It enables a new type of QA with visual answers, in addition to textual answers used in previous work. We study the visual QA tasks in a grounded setting with a large collection of 7W multiple-choice QA pairs. Furthermore, we evaluate human performance and several baseline models on the QA tasks. Finally, we propose a novel LSTM model with spatial attention to tackle the 7W QA tasks.



### A Directional Diffusion Algorithm for Inpainting
- **Arxiv ID**: http://arxiv.org/abs/1511.03464v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03464v1)
- **Published**: 2015-11-11 11:38:22+00:00
- **Updated**: 2015-11-11 11:38:22+00:00
- **Authors**: Jan Deriu, Rolf Jagerman, Kai-En Tsay
- **Comment**: None
- **Journal**: None
- **Summary**: The problem of inpainting involves reconstructing the missing areas of an image. Inpainting has many applications, such as reconstructing old damaged photographs or removing obfuscations from images. In this paper we present the directional diffusion algorithm for inpainting. Typical diffusion algorithms are bad at propagating edges from the image into the unknown masked regions. The directional diffusion algorithm improves on the regular diffusion algorithm by reconstructing edges more accurately. It scores better than regular diffusion when reconstructing images that are obfuscated by a text mask.



### God(s) Know(s): Developmental and Cross-Cultural Patterns in Children Drawings
- **Arxiv ID**: http://arxiv.org/abs/1511.03466v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03466v2)
- **Published**: 2015-11-11 11:47:58+00:00
- **Updated**: 2016-02-08 15:28:49+00:00
- **Authors**: Ksenia Konyushkova, Nikolaos Arvanitopoulos, Zhargalma Dandarova Robert, Pierre-Yves Brandt, Sabine S√ºsstrunk
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a novel approach to data analysis designed for the needs of specialists in psychology of religion. We detect developmental and cross-cultural patterns in children's drawings of God(s) and other supernatural agents. We develop methods to objectively evaluate our empirical observations of the drawings with respect to: (1) the gravity center, (2) the average intensities of the colors \emph{green} and \emph{yellow}, (3) the use of different colors (palette) and (4) the visual complexity of the drawings. We find statistically significant differences across ages and countries in the gravity centers and in the average intensities of colors. These findings support the hypotheses of the experts and raise new questions for further investigation.



### Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning
- **Arxiv ID**: http://arxiv.org/abs/1511.03476v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03476v1)
- **Published**: 2015-11-11 12:38:14+00:00
- **Updated**: 2015-11-11 12:38:14+00:00
- **Authors**: Pingbo Pan, Zhongwen Xu, Yi Yang, Fei Wu, Yueting Zhuang
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, deep learning approach, especially deep Convolutional Neural Networks (ConvNets), have achieved overwhelming accuracy with fast processing speed for image classification. Incorporating temporal structure with deep ConvNets for video representation becomes a fundamental problem for video content analysis. In this paper, we propose a new approach, namely Hierarchical Recurrent Neural Encoder (HRNE), to exploit temporal information of videos. Compared to recent video representation inference approaches, this paper makes the following three contributions. First, our HRNE is able to efficiently exploit video temporal structure in a longer range by reducing the length of input information flow, and compositing multiple consecutive inputs at a higher level. Second, computation operations are significantly lessened while attaining more non-linearity. Third, HRNE is able to uncover temporal transitions between frame chunks with different granularities, i.e., it can model the temporal transitions between frames as well as the transitions between segments. We apply the new method to video captioning where temporal information plays a crucial role. Experiments demonstrate that our method outperforms the state-of-the-art on video captioning benchmarks. Notably, even using a single network with only RGB stream as input, HRNE beats all the recent systems which combine multiple inputs, such as RGB ConvNet plus 3D ConvNet.



### Complete Dictionary Recovery over the Sphere I: Overview and the Geometric Picture
- **Arxiv ID**: http://arxiv.org/abs/1511.03607v3
- **DOI**: 10.1109/TIT.2016.2632162
- **Categories**: **cs.IT**, cs.CV, math.IT, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1511.03607v3)
- **Published**: 2015-11-11 19:09:22+00:00
- **Updated**: 2016-09-01 17:19:08+00:00
- **Authors**: Ju Sun, Qing Qu, John Wright
- **Comment**: Accepted by IEEE Transaction on Information Theory; revised according
  to the reviewers' comments
- **Journal**: IEEE Trans. Information Theory, 63(2): 853 - 884 (2017)
- **Summary**: We consider the problem of recovering a complete (i.e., square and invertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb{R}^{n \times p}$ with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ is sufficiently sparse. This recovery problem is central to theoretical understanding of dictionary learning, which seeks a sparse representation for a collection of input signals and finds numerous applications in modern signal processing and machine learning. We give the first efficient algorithm that provably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros per column, under suitable probability model for $\mathbf X_0$. In contrast, prior results based on efficient algorithms either only guarantee recovery when $\mathbf X_0$ has $O(\sqrt{n})$ zeros per column, or require multiple rounds of SDP relaxation to work when $\mathbf X_0$ has $O(n^{1-\delta})$ nonzeros per column (for any constant $\delta \in (0, 1)$). }   Our algorithmic pipeline centers around solving a certain nonconvex optimization problem with a spherical constraint. In this paper, we provide a geometric characterization of the objective landscape. In particular, we show that the problem is highly structured: with high probability, (1) there are no "spurious" local minimizers; and (2) around all saddle points the objective has a negative directional curvature. This distinctive structure makes the problem amenable to efficient optimization algorithms. In a companion paper (arXiv:1511.04777), we design a second-order trust-region algorithm over the sphere that provably converges to a local minimizer from arbitrary initializations, despite the presence of saddle points.



### A Continuous Max-Flow Approach to Cyclic Field Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1511.03629v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03629v1)
- **Published**: 2015-11-11 19:55:05+00:00
- **Updated**: 2015-11-11 19:55:05+00:00
- **Authors**: John S. H. Baxter, Jonathan McLeod, Terry M. Peters
- **Comment**: 8 pages, 1 figure
- **Journal**: None
- **Summary**: Reconstruction of an image from noisy data using Markov Random Field theory has been explored by both the graph-cuts and continuous max-flow community in the form of the Potts and Ishikawa models. However, neither model takes into account the particular cyclic topology of specific intensity types such as the hue in natural colour images, or the phase in complex valued MRI. This paper presents \textit{cyclic continuous max-flow} image reconstruction which models the intensity being reconstructed as having a fundamentally cyclic topology. This model complements the Ishikawa model in that it is designed with image reconstruction in mind, having the topology of the intensity space inherent in the model while being readily extendable to an arbitrary intensity resolution.



### Piecewise Linear Activation Functions For More Efficient Deep Networks
- **Arxiv ID**: http://arxiv.org/abs/1511.03650v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1511.03650v3)
- **Published**: 2015-11-11 20:54:28+00:00
- **Updated**: 2015-12-07 14:20:01+00:00
- **Authors**: Cheng-Yang Fu, Alexander C. Berg
- **Comment**: Withdrawn by arXiv admins
- **Journal**: None
- **Summary**: This submission has been withdrawn by arXiv administrators because it is intentionally incomplete, which is in violation of our policies.



### Deep Multimodal Semantic Embeddings for Speech and Images
- **Arxiv ID**: http://arxiv.org/abs/1511.03690v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/1511.03690v1)
- **Published**: 2015-11-11 21:30:10+00:00
- **Updated**: 2015-11-11 21:30:10+00:00
- **Authors**: David Harwath, James Glass
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a model which takes as input a corpus of images with relevant spoken captions and finds a correspondence between the two modalities. We employ a pair of convolutional neural networks to model visual objects and speech signals at the word level, and tie the networks together with an embedding and alignment model which learns a joint semantic space over both modalities. We evaluate our model using image search and annotation tasks on the Flickr8k dataset, which we augmented by collecting a corpus of 40,000 spoken captions using Amazon Mechanical Turk.



