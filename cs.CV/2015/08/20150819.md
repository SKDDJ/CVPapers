# Arxiv Papers in cs.CV on 2015-08-19
### Bit-Scalable Deep Hashing with Regularized Similarity Learning for Image Retrieval and Person Re-identification
- **Arxiv ID**: http://arxiv.org/abs/1508.04535v2
- **DOI**: 10.1109/TIP.2015.2467315
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.04535v2)
- **Published**: 2015-08-19 06:26:34+00:00
- **Updated**: 2015-08-21 06:02:54+00:00
- **Authors**: Ruimao Zhang, Liang Lin, Rui Zhang, Wangmeng Zuo, Lei Zhang
- **Comment**: 14 pages, 5 figures. IEEE Transactions on Image Processing 2015
- **Journal**: None
- **Summary**: Extracting informative image features and learning effective approximate hashing functions are two crucial steps in image retrieval . Conventional methods often study these two steps separately, e.g., learning hash functions from a predefined hand-crafted feature space. Meanwhile, the bit lengths of output hashing codes are preset in most previous methods, neglecting the significance level of different bits and restricting their practical flexibility. To address these issues, we propose a supervised learning framework to generate compact and bit-scalable hashing codes directly from raw images. We pose hashing learning as a problem of regularized similarity learning. Specifically, we organize the training images into a batch of triplet samples, each sample containing two images with the same label and one with a different label. With these triplet samples, we maximize the margin between matched pairs and mismatched pairs in the Hamming space. In addition, a regularization term is introduced to enforce the adjacency consistency, i.e., images of similar appearances should have similar codes. The deep convolutional neural network is utilized to train the model in an end-to-end fashion, where discriminative image features and hash functions are simultaneously optimized. Furthermore, each bit of our hashing codes is unequally weighted so that we can manipulate the code lengths by truncating the insignificant bits. Our framework outperforms state-of-the-arts on public benchmarks of similar image search and also achieves promising results in the application of person re-identification in surveillance. It is also shown that the generated bit-scalable hashing codes well preserve the discriminative powers with shorter code lengths.



### Learning Analysis-by-Synthesis for 6D Pose Estimation in RGB-D Images
- **Arxiv ID**: http://arxiv.org/abs/1508.04546v1
- **DOI**: None
- **Categories**: **cs.CV**, 65-XX
- **Links**: [PDF](http://arxiv.org/pdf/1508.04546v1)
- **Published**: 2015-08-19 07:24:14+00:00
- **Updated**: 2015-08-19 07:24:14+00:00
- **Authors**: Alexander Krull, Eric Brachmann, Frank Michel, Michael Ying Yang, Stefan Gumhold, Carsten Rother
- **Comment**: 16 pages, 8 figures
- **Journal**: None
- **Summary**: Analysis-by-synthesis has been a successful approach for many tasks in computer vision, such as 6D pose estimation of an object in an RGB-D image which is the topic of this work. The idea is to compare the observation with the output of a forward process, such as a rendered image of the object of interest in a particular pose. Due to occlusion or complicated sensor noise, it can be difficult to perform this comparison in a meaningful way. We propose an approach that "learns to compare", while taking these difficulties into account. This is done by describing the posterior density of a particular object pose with a convolutional neural network (CNN) that compares an observed and rendered image. The network is trained with the maximum likelihood paradigm. We observe empirically that the CNN does not specialize to the geometry or appearance of specific objects, and it can be used with objects of vastly different shapes and appearances, and in different backgrounds. Compared to state-of-the-art, we demonstrate a significant improvement on two different datasets which include a total of eleven objects, cluttered background, and heavy occlusion.



### Mining Brain Networks using Multiple Side Views for Neurological Disorder Identification
- **Arxiv ID**: http://arxiv.org/abs/1508.04554v1
- **DOI**: 10.1109/ICDM.2015.50
- **Categories**: **cs.LG**, cs.CV, cs.CY, stat.AP, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1508.04554v1)
- **Published**: 2015-08-19 07:51:14+00:00
- **Updated**: 2015-08-19 07:51:14+00:00
- **Authors**: Bokai Cao, Xiangnan Kong, Jingyuan Zhang, Philip S. Yu, Ann B. Ragin
- **Comment**: in Proceedings of IEEE International Conference on Data Mining (ICDM)
  2015
- **Journal**: None
- **Summary**: Mining discriminative subgraph patterns from graph data has attracted great interest in recent years. It has a wide variety of applications in disease diagnosis, neuroimaging, etc. Most research on subgraph mining focuses on the graph representation alone. However, in many real-world applications, the side information is available along with the graph data. For example, for neurological disorder identification, in addition to the brain networks derived from neuroimaging data, hundreds of clinical, immunologic, serologic and cognitive measures may also be documented for each subject. These measures compose multiple side views encoding a tremendous amount of supplemental information for diagnostic purposes, yet are often ignored. In this paper, we study the problem of discriminative subgraph selection using multiple side views and propose a novel solution to find an optimal set of subgraph features for graph classification by exploring a plurality of side views. We derive a feature evaluation criterion, named gSide, to estimate the usefulness of subgraph patterns based upon side views. Then we develop a branch-and-bound algorithm, called gMSV, to efficiently search for optimal subgraph features by integrating the subgraph mining process and the procedure of discriminative feature selection. Empirical studies on graph classification tasks for neurological disorders using brain networks demonstrate that subgraph patterns selected by the multi-side-view guided subgraph selection approach can effectively boost graph classification performances and are relevant to disease diagnosis.



### Saliency maps on image hierarchies
- **Arxiv ID**: http://arxiv.org/abs/1508.04586v1
- **DOI**: 10.1016/j.image.2015.07.012
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.04586v1)
- **Published**: 2015-08-19 10:07:07+00:00
- **Updated**: 2015-08-19 10:07:07+00:00
- **Authors**: Ver√≥nica Vilaplana
- **Comment**: Accepted for publication in Signal Processing: Image Communications,
  2015
- **Journal**: None
- **Summary**: In this paper we propose two saliency models for salient object segmentation based on a hierarchical image segmentation, a tree-like structure that represents regions at different scales from the details to the whole image (e.g. gPb-UCM, BPT). The first model is based on a hierarchy of image partitions. The saliency at each level is computed on a region basis, taking into account the contrast between regions. The maps obtained for the different partitions are then integrated into a final saliency map. The second model directly works on the structure created by the segmentation algorithm, computing saliency at each node and integrating these cues in a straightforward manner into a single saliency map. We show that the proposed models produce high quality saliency maps. Objective evaluation demonstrates that the two methods achieve state-of-the-art performance in several benchmark datasets.



### Who are the Devils Wearing Prada in New York City?
- **Arxiv ID**: http://arxiv.org/abs/1508.04785v1
- **DOI**: 10.1145/2733373.2809930
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1508.04785v1)
- **Published**: 2015-08-19 20:28:31+00:00
- **Updated**: 2015-08-19 20:28:31+00:00
- **Authors**: KuanTing Chen, Kezhen Chen, Peizhong Cong, Winston H. Hsu, Jiebo Luo
- **Comment**: None
- **Journal**: None
- **Summary**: Fashion is a perpetual topic in human social life, and the mass has the penchant to emulate what large city residents and celebrities wear. Undeniably, New York City is such a bellwether large city with all kinds of fashion leadership. Consequently, to study what the fashion trends are during this year, it is very helpful to learn the fashion trends of New York City. Discovering fashion trends in New York City could boost many applications such as clothing recommendation and advertising. Does the fashion trend in the New York Fashion Show actually influence the clothing styles on the public? To answer this question, we design a novel system that consists of three major components: (1) constructing a large dataset from the New York Fashion Shows and New York street chic in order to understand the likely clothing fashion trends in New York, (2) utilizing a learning-based approach to discover fashion attributes as the representative characteristics of fashion trends, and (3) comparing the analysis results from the New York Fashion Shows and street-chic images to verify whether the fashion shows have actual influence on the people in New York City. Through the preliminary experiments over a large clothing dataset, we demonstrate the effectiveness of our proposed system, and obtain useful insights on fashion trends and fashion influence.



