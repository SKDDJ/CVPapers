# Arxiv Papers in cs.CV on 2015-08-02
### Indexing of CNN Features for Large Scale Image Search
- **Arxiv ID**: http://arxiv.org/abs/1508.00217v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00217v4)
- **Published**: 2015-08-02 10:43:25+00:00
- **Updated**: 2018-02-01 09:39:54+00:00
- **Authors**: Ruoyu Liu, Yao Zhao, Shikui Wei, Yi Yang
- **Comment**: 21 pages, 9 figures, submitted to Multimedia Tools and Applications
- **Journal**: None
- **Summary**: The convolutional neural network (CNN) features can give a good description of image content, which usually represent images with unique global vectors. Although they are compact compared to local descriptors, they still cannot efficiently deal with large-scale image retrieval due to the cost of the linear incremental computation and storage. To address this issue, we build a simple but effective indexing framework based on inverted table, which significantly decreases both the search time and memory usage. In addition, several strategies are fully investigated under an indexing framework to adapt it to CNN features and compensate for quantization errors. First, we use multiple assignment for the query and database images to increase the probability of relevant images' co-existing in the same Voronoi cells obtained via the clustering algorithm. Then, we introduce embedding codes to further improve precision by removing false matches during a search. We demonstrate that by using hashing schemes to calculate the embedding codes and by changing the ranking rule, indexing framework speeds can be greatly improved. Extensive experiments conducted on several unsupervised and supervised benchmarks support these results and the superiority of the proposed indexing framework. We also provide a fair comparison between the popular CNN features.



### Partial matching face recognition method for rehabilitation nursing robots beds
- **Arxiv ID**: http://arxiv.org/abs/1508.00239v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00239v1)
- **Published**: 2015-08-02 14:09:02+00:00
- **Updated**: 2015-08-02 14:09:02+00:00
- **Authors**: Dongmei Liang, Wushan Cheng
- **Comment**: None
- **Journal**: None
- **Summary**: In order to establish face recognition system in rehabilitation nursing robots beds and achieve real-time monitor the patient on the bed. We propose a face recognition method based on partial matching Hu moments which apply for rehabilitation nursing robots beds. Firstly we using Haar classifier to detect human faces automatically in dynamic video frames. Secondly we using Otsu threshold method to extract facial features (eyebrows, eyes, mouth) in the face image and its Hu moments. Finally, we using Hu moment feature set to achieve the automatic face recognition. Experimental results show that this method can efficiently identify face in a dynamic video and it has high practical value (the accuracy rate is 91% and the average recognition time is 4.3s).



### Recurrent Network Models for Human Dynamics
- **Arxiv ID**: http://arxiv.org/abs/1508.00271v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00271v2)
- **Published**: 2015-08-02 18:59:52+00:00
- **Updated**: 2015-09-29 01:28:23+00:00
- **Authors**: Katerina Fragkiadaki, Sergey Levine, Panna Felsen, Jitendra Malik
- **Comment**: International Conference on Computer Vision 2015
- **Journal**: None
- **Summary**: We propose the Encoder-Recurrent-Decoder (ERD) model for recognition and prediction of human body pose in videos and motion capture. The ERD model is a recurrent neural network that incorporates nonlinear encoder and decoder networks before and after recurrent layers. We test instantiations of ERD architectures in the tasks of motion capture (mocap) generation, body pose labeling and body pose forecasting in videos. Our model handles mocap training data across multiple subjects and activity domains, and synthesizes novel motions while avoid drifting for long periods of time. For human pose labeling, ERD outperforms a per frame body part detector by resolving left-right body part confusions. For video pose forecasting, ERD predicts body joint displacements across a temporal horizon of 400ms and outperforms a first order motion model based on optical flow. ERDs extend previous Long Short Term Memory (LSTM) models in the literature to jointly learn representations and their dynamics. Our experiments show such representation learning is crucial for both labeling and prediction in space-time. We find this is a distinguishing feature between the spatio-temporal visual domain in comparison to 1D text, speech or handwriting, where straightforward hard coded representations have shown excellent results when directly combined with recurrent units.



### Dictionary and Image Recovery from Incomplete and Random Measurements
- **Arxiv ID**: http://arxiv.org/abs/1508.00278v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00278v1)
- **Published**: 2015-08-02 19:55:27+00:00
- **Updated**: 2015-08-02 19:55:27+00:00
- **Authors**: Mohammad Aghagolzadeh, Hayder Radha
- **Comment**: None
- **Journal**: None
- **Summary**: This paper tackles algorithmic and theoretical aspects of dictionary learning from incomplete and random block-wise image measurements and the performance of the adaptive dictionary for sparse image recovery. This problem is related to blind compressed sensing in which the sparsifying dictionary or basis is viewed as an unknown variable and subject to estimation during sparse recovery. However, unlike existing guarantees for a successful blind compressed sensing, our results do not rely on additional structural constraints on the learned dictionary or the measured signal. In particular, we rely on the spatial diversity of compressive measurements to guarantee that the solution is unique with a high probability. Moreover, our distinguishing goal is to measure and reduce the estimation error with respect to the ideal dictionary that is based on the complete image. Using recent results from random matrix theory, we show that applying a slightly modified dictionary learning algorithm over compressive measurements results in accurate estimation of the ideal dictionary for large-scale images. Empirically, we experiment with both space-invariant and space-varying sensing matrices and demonstrate the critical role of spatial diversity in measurements. Simulation results confirm that the presented algorithm outperforms the typical non-adaptive sparse recovery based on offline-learned universal dictionaries.



### On Hyperspectral Classification in the Compressed Domain
- **Arxiv ID**: http://arxiv.org/abs/1508.00282v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00282v1)
- **Published**: 2015-08-02 20:40:21+00:00
- **Updated**: 2015-08-02 20:40:21+00:00
- **Authors**: Mohammad Aghagolzadeh, Hayder Radha
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we study the problem of hyperspectral pixel classification based on the recently proposed architectures for compressive whisk-broom hyperspectral imagers without the need to reconstruct the complete data cube. A clear advantage of classification in the compressed domain is its suitability for real-time on-site processing of the sensed data. Moreover, it is assumed that the training process also takes place in the compressed domain, thus, isolating the classification unit from the recovery unit at the receiver's side. We show that, perhaps surprisingly, using distinct measurement matrices for different pixels results in more accuracy of the learned classifier and consistent classification performance, supporting the role of information diversity in learning.



