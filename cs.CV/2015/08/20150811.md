# Arxiv Papers in cs.CV on 2015-08-11
### A Practical Guide to CNNs and Fisher Vectors for Image Instance Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1508.02496v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1508.02496v3)
- **Published**: 2015-08-11 07:15:07+00:00
- **Updated**: 2015-08-25 11:30:22+00:00
- **Authors**: Vijay Chandrasekhar, Jie Lin, Olivier Mor√®re, Hanlin Goh, Antoine Veillard
- **Comment**: Deep Convolutional Neural Networks for instance retrieval, Fisher
  Vectors, instance retrieval
- **Journal**: None
- **Summary**: With deep learning becoming the dominant approach in computer vision, the use of representations extracted from Convolutional Neural Nets (CNNs) is quickly gaining ground on Fisher Vectors (FVs) as favoured state-of-the-art global image descriptors for image instance retrieval. While the good performance of CNNs for image classification are unambiguously recognised, which of the two has the upper hand in the image retrieval context is not entirely clear yet. In this work, we propose a comprehensive study that systematically evaluates FVs and CNNs for image retrieval. The first part compares the performances of FVs and CNNs on multiple publicly available data sets. We investigate a number of details specific to each method. For FVs, we compare sparse descriptors based on interest point detectors with dense single-scale and multi-scale variants. For CNNs, we focus on understanding the impact of depth, architecture and training data on retrieval results. Our study shows that no descriptor is systematically better than the other and that performance gains can usually be obtained by using both types together. The second part of the study focuses on the impact of geometrical transformations such as rotations and scale changes. FVs based on interest point detectors are intrinsically resilient to such transformations while CNNs do not have a built-in mechanism to ensure such invariance. We show that performance of CNNs can quickly degrade in presence of rotations while they are far less affected by changes in scale. We then propose a number of ways to incorporate the required invariances in the CNN pipeline. Overall, our work is intended as a reference guide offering practically useful and simply implementable guidelines to anyone looking for state-of-the-art global descriptors best suited to their specific image instance retrieval problem.



### InAR:Inverse Augmented Reality
- **Arxiv ID**: http://arxiv.org/abs/1508.02606v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.02606v1)
- **Published**: 2015-08-11 14:17:28+00:00
- **Updated**: 2015-08-11 14:17:28+00:00
- **Authors**: Hao Hu, Hainan Cui
- **Comment**: 2 pages
- **Journal**: None
- **Summary**: Augmented reality is the art to seamlessly fuse virtual objects into real ones. In this short note, we address the opposite problem, the inverse augmented reality, that is, given a perfectly augmented reality scene where human is unable to distinguish real objects from virtual ones, how the machine could help do the job. We show by structure from motion (SFM), a simple 3D reconstruction technique from images in computer vision, the real and virtual objects can be easily separated in the reconstructed 3D scene.



