# Arxiv Papers in cs.CV on 2015-08-08
### Simulation of optical flow and fuzzy based obstacle avoidance system for mobile robots
- **Arxiv ID**: http://arxiv.org/abs/1508.01859v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1508.01859v1)
- **Published**: 2015-08-08 06:40:55+00:00
- **Updated**: 2015-08-08 06:40:55+00:00
- **Authors**: G. D. Illeperuma, D. U. J. Sonnadara
- **Comment**: 4 pages, Published in 30 April 2015
- **Journal**: International Journal of Artificial Intelligence and Neural
  Networks, 5-1 (2015) 53-56
- **Summary**: Honey bees use optical flow to avoid obstacles effectively. In this research work similar methodology was tested on a simulated mobile robot. Simulation framework was based on VRML and Simulink in a 3D world. Optical flow vectors were calculated from a video scene captured by a virtual camera which was used as inputs to a fuzzy logic controller. Fuzzy logic controller decided the locomotion of the robot. Different fuzzy logic rules were evaluated. The robot was able to navigate through complex static and dynamic environments effectively, avoiding obstacles on its path.



### A straightforward method to assess motion blur for different types of displays
- **Arxiv ID**: http://arxiv.org/abs/1602.07573v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.07573v1)
- **Published**: 2015-08-08 11:08:11+00:00
- **Updated**: 2015-08-08 11:08:11+00:00
- **Authors**: Fuhao Chen, Jun Chen, Feng Huang
- **Comment**: 22 pages, 9 figures
- **Journal**: None
- **Summary**: A simulation method based on the liquid crystal response and the human visual system is suitable to characterize motion blur for LCDs but not other display types. We propose a more straightforward and widely applicable method to quantify motion blur based on the width of the moving object. We thus compare various types of displays objectively. A perceptual experiment was conducted to validate the proposed method. We test varying motion velocities for nine commercial displays. We compare the three motion blur evaluation methods (simulation, human perception, and our method) using z-scores. Our comparisons indicate that our method accurately characterizes motion blur for various display types.



### Deep Boosting: Joint Feature Selection and Analysis Dictionary Learning in Hierarchy
- **Arxiv ID**: http://arxiv.org/abs/1508.01887v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1508.01887v2)
- **Published**: 2015-08-08 11:42:21+00:00
- **Updated**: 2015-08-11 09:45:07+00:00
- **Authors**: Zhanglin Peng, Ya Li, Zhaoquan Cai, Liang Lin
- **Comment**: None
- **Journal**: None
- **Summary**: This work investigates how the traditional image classification pipelines can be extended into a deep architecture, inspired by recent successes of deep neural networks. We propose a deep boosting framework based on layer-by-layer joint feature boosting and dictionary learning. In each layer, we construct a dictionary of filters by combining the filters from the lower layer, and iteratively optimize the image representation with a joint discriminative-generative formulation, i.e. minimization of empirical classification error plus regularization of analysis image generation over training images. For optimization, we perform two iterating steps: i) to minimize the classification error, select the most discriminative features using the gentle adaboost algorithm; ii) according to the feature selection, update the filters to minimize the regularization on analysis image representation using the gradient descent method. Once the optimization is converged, we learn the higher layer representation in the same way. Our model delivers several distinct advantages. First, our layer-wise optimization provides the potential to build very deep architectures. Second, the generated image representation is compact and meaningful. In several visual recognition tasks, our framework outperforms existing state-of-the-art approaches.



