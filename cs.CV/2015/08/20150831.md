# Arxiv Papers in cs.CV on 2015-08-31
### Action Recognition by Hierarchical Mid-level Action Elements
- **Arxiv ID**: http://arxiv.org/abs/1508.07654v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.07654v1)
- **Published**: 2015-08-31 00:56:20+00:00
- **Updated**: 2015-08-31 00:56:20+00:00
- **Authors**: Tian Lan, Yuke Zhu, Amir Roshan Zamir, Silvio Savarese
- **Comment**: None
- **Journal**: None
- **Summary**: Realistic videos of human actions exhibit rich spatiotemporal structures at multiple levels of granularity: an action can always be decomposed into multiple finer-grained elements in both space and time. To capture this intuition, we propose to represent videos by a hierarchy of mid-level action elements (MAEs), where each MAE corresponds to an action-related spatiotemporal segment in the video. We introduce an unsupervised method to generate this representation from videos. Our method is capable of distinguishing action-related segments from background segments and representing actions at multiple spatiotemporal resolutions. Given a set of spatiotemporal segments generated from the training data, we introduce a discriminative clustering algorithm that automatically discovers MAEs at multiple levels of granularity. We develop structured models that capture a rich set of spatial, temporal and hierarchical relations among the segments, where the action label and multiple levels of MAE labels are jointly inferred. The proposed model achieves state-of-the-art performance in multiple action recognition benchmarks. Moreover, we demonstrate the effectiveness of our model in real-world applications such as action recognition in large-scale untrimmed videos and action parsing.



### Domain Generalization for Object Recognition with Multi-task Autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1508.07680v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1508.07680v1)
- **Published**: 2015-08-31 04:15:31+00:00
- **Updated**: 2015-08-31 04:15:31+00:00
- **Authors**: Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, David Balduzzi
- **Comment**: accepted in ICCV 2015
- **Journal**: None
- **Summary**: The problem of domain generalization is to take knowledge acquired from a number of related domains where training data is available, and to then successfully apply it to previously unseen domains. We propose a new feature learning algorithm, Multi-Task Autoencoder (MTAE), that provides good generalization performance for cross-domain object recognition.   Our algorithm extends the standard denoising autoencoder framework by substituting artificially induced corruption with naturally occurring inter-domain variability in the appearance of objects. Instead of reconstructing images from noisy versions, MTAE learns to transform the original image into analogs in multiple related domains. It thereby learns features that are robust to variations across domains. The learnt features are then used as inputs to a classifier.   We evaluated the performance of the algorithm on benchmark image recognition datasets, where the task is to learn features from multiple datasets and to then predict the image label from unseen datasets. We found that (denoising) MTAE outperforms alternative autoencoder-based models as well as the current state-of-the-art algorithms for domain generalization.



### Multi-Projector Color Structured-Light Vision
- **Arxiv ID**: http://arxiv.org/abs/1508.07859v1
- **DOI**: 10.1016/j.image.2013.05.005
- **Categories**: **cs.CV**, cs.GR, physics.optics, I.2.10; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1508.07859v1)
- **Published**: 2015-08-31 14:55:59+00:00
- **Updated**: 2015-08-31 14:55:59+00:00
- **Authors**: Changsoo Je, Kwang Hee Lee, Sang Wook Lee
- **Comment**: 25 pages, 13 figures
- **Journal**: Signal Processing: Image Communication, Volume 28, Issue 9, pp.
  1046-1058, October, 2013
- **Summary**: Research interest in rapid structured-light imaging has grown increasingly for the modeling of moving objects, and a number of methods have been suggested for the range capture in a single video frame. The imaging area of a 3D object using a single projector is restricted since the structured light is projected only onto a limited area of the object surface. Employing additional projectors to broaden the imaging area is a challenging problem since simultaneous projection of multiple patterns results in their superposition in the light-intersected areas and the recognition of original patterns is by no means trivial. This paper presents a novel method of multi-projector color structured-light vision based on projector-camera triangulation. By analyzing the behavior of superposed-light colors in a chromaticity domain, we show that the original light colors cannot be properly extracted by the conventional direct estimation. We disambiguate multiple projectors by multiplexing the orientations of projector patterns so that the superposed patterns can be separated by explicit derivative computations. Experimental studies are carried out to demonstrate the validity of the presented method. The proposed method increases the efficiency of range acquisition compared to conventional active stereo using multiple projectors.



### Maximum Persistency via Iterative Relaxed Inference with Graphical Models
- **Arxiv ID**: http://arxiv.org/abs/1508.07902v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.DS
- **Links**: [PDF](http://arxiv.org/pdf/1508.07902v3)
- **Published**: 2015-08-31 16:28:55+00:00
- **Updated**: 2017-02-03 13:21:01+00:00
- **Authors**: Alexander Shekhovtsov, Paul Swoboda, Bogdan Savchynskyy
- **Comment**: Reworked version, submitted to PAMI
- **Journal**: None
- **Summary**: We consider the NP-hard problem of MAP-inference for undirected discrete graphical models. We propose a polynomial time and practically efficient algorithm for finding a part of its optimal solution. Specifically, our algorithm marks some labels of the considered graphical model either as (i) optimal, meaning that they belong to all optimal solutions of the inference problem; (ii) non-optimal if they provably do not belong to any solution. With access to an exact solver of a linear programming relaxation to the MAP-inference problem, our algorithm marks the maximal possible (in a specified sense) number of labels. We also present a version of the algorithm, which has access to a suboptimal dual solver only and still can ensure the (non-)optimality for the marked labels, although the overall number of the marked labels may decrease. We propose an efficient implementation, which runs in time comparable to a single run of a suboptimal dual solver. Our method is well-scalable and shows state-of-the-art results on computational benchmarks from machine learning and computer vision.



### Approximate Nearest Neighbor Fields in Video
- **Arxiv ID**: http://arxiv.org/abs/1508.07953v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.07953v1)
- **Published**: 2015-08-31 18:43:31+00:00
- **Updated**: 2015-08-31 18:43:31+00:00
- **Authors**: Nir Ben-Zrihem, Lihi Zelnik-Manor
- **Comment**: A CVPR 2015 oral paper
- **Journal**: None
- **Summary**: We introduce RIANN (Ring Intersection Approximate Nearest Neighbor search), an algorithm for matching patches of a video to a set of reference patches in real-time. For each query, RIANN finds potential matches by intersecting rings around key points in appearance space. Its search complexity is reversely correlated to the amount of temporal change, making it a good fit for videos, where typically most patches change slowly with time. Experiments show that RIANN is up to two orders of magnitude faster than previous ANN methods, and is the only solution that operates in real-time. We further demonstrate how RIANN can be used for real-time video processing and provide examples for a range of real-time video applications, including colorization, denoising, and several artistic effects.



### Metastatic liver tumour segmentation from discriminant Grassmannian manifolds
- **Arxiv ID**: http://arxiv.org/abs/1509.00083v1
- **DOI**: 10.1088/0031-9155/60/16/6459
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1509.00083v1)
- **Published**: 2015-08-31 21:45:40+00:00
- **Updated**: 2015-08-31 21:45:40+00:00
- **Authors**: Samuel Kadoury, Eugene Vorontsov, An Tang
- **Comment**: None
- **Journal**: Physics in Medicine and Biology 60 (2015)
- **Summary**: The early detection, diagnosis and monitoring of liver cancer progression can be achieved with the precise delineation of metastatic tumours. However, accurate automated segmentation remains challenging due to the presence of noise, inhomogeneity and the high appearance variability of malignant tissue. In this paper, we propose an unsupervised metastatic liver tumour segmentation framework using a machine learning approach based on discriminant Grassmannian manifolds which learns the appearance of tumours with respect to normal tissue. First, the framework learns within-class and between-class similarity distributions from a training set of images to discover the optimal manifold discrimination between normal and pathological tissue in the liver. Second, a conditional optimisation scheme computes nonlocal pairwise as well as pattern-based clique potentials from the manifold subspace to recognise regions with similar labelings and to incorporate global consistency in the segmentation process. The proposed framework was validated on a clinical database of 43 CT images from patients with metastatic liver cancer. Compared to state-of-the-art methods, our method achieves a better performance on two separate datasets of metastatic liver tumours from different clinical sites, yielding an overall mean Dice similarity coefficient of 90.7 +/- 2.4 in over 50 tumours with an average volume of 27.3 mm3.



