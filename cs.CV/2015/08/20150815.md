# Arxiv Papers in cs.CV on 2015-08-15
### A Novel Approach For Finger Vein Verification Based on Self-Taught Learning
- **Arxiv ID**: http://arxiv.org/abs/1508.03710v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.03710v1)
- **Published**: 2015-08-15 09:03:19+00:00
- **Updated**: 2015-08-15 09:03:19+00:00
- **Authors**: Mohsen Fayyaz, Masoud PourReza, Mohammad Hajizadeh Saffar, Mohammad Sabokrou, Mahmood Fathy
- **Comment**: 4 pages, 4 figures, Submitted Iranian Conference on Machine Vision
  and Image Processing
- **Journal**: None
- **Summary**: In this paper, we propose a method for user Finger Vein Authentication (FVA) as a biometric system. Using the discriminative features for classifying theses finger veins is one of the main tips that make difference in related works, Thus we propose to learn a set of representative features, based on autoencoders. We model the user finger vein using a Gaussian distribution. Experimental results show that our algorithm perform like a state-of-the-art on SDUMLA-HMT benchmark.



### Beat-Event Detection in Action Movie Franchises
- **Arxiv ID**: http://arxiv.org/abs/1508.03755v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.03755v1)
- **Published**: 2015-08-15 17:04:50+00:00
- **Updated**: 2015-08-15 17:04:50+00:00
- **Authors**: Danila Potapov, Matthijs Douze, Jerome Revaud, Zaid Harchaoui, Cordelia Schmid
- **Comment**: None
- **Journal**: None
- **Summary**: While important advances were recently made towards temporally localizing and recognizing specific human actions or activities in videos, efficient detection and classification of long video chunks belonging to semantically defined categories such as "pursuit" or "romance" remains challenging.We introduce a new dataset, Action Movie Franchises, consisting of a collection of Hollywood action movie franchises. We define 11 non-exclusive semantic categories - called beat-categories - that are broad enough to cover most of the movie footage. The corresponding beat-events are annotated as groups of video shots, possibly overlapping.We propose an approach for localizing beat-events based on classifying shots into beat-categories and learning the temporal constraints between shots. We show that temporal constraints significantly improve the classification performance. We set up an evaluation protocol for beat-event localization as well as for shot classification, depending on whether movies from the same franchise are present or not in the training data.



