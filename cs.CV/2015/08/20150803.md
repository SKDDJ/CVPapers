# Arxiv Papers in cs.CV on 2015-08-03
### Local Color Contrastive Descriptor for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1508.00307v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00307v1)
- **Published**: 2015-08-03 03:29:50+00:00
- **Updated**: 2015-08-03 03:29:50+00:00
- **Authors**: Sheng Guo, Weilin Huang, Yu Qiao
- **Comment**: None
- **Journal**: None
- **Summary**: Image representation and classification are two fundamental tasks towards multimedia content retrieval and understanding. The idea that shape and texture information (e.g. edge or orientation) are the key features for visual representation is ingrained and dominated in current multimedia and computer vision communities. A number of low-level features have been proposed by computing local gradients (e.g. SIFT, LBP and HOG), and have achieved great successes on numerous multimedia applications. In this paper, we present a simple yet efficient local descriptor for image classification, referred as Local Color Contrastive Descriptor (LCCD), by leveraging the neural mechanisms of color contrast. The idea originates from the observation in neural science that color and shape information are linked inextricably in visual cortical processing. The color contrast yields key information for visual color perception and provides strong linkage between color and shape. We propose a novel contrastive mechanism to compute the color contrast in both spatial location and multiple channels. The color contrast is computed by measuring \emph{f}-divergence between the color distributions of two regions. Our descriptor enriches local image representation with both color and contrast information. We verified experimentally that it can compensate strongly for the shape based descriptor (e.g. SIFT), while keeping computationally simple. Extensive experimental results on image classification show that our descriptor improves the performance of SIFT substantially by combinations, and achieves the state-of-the-art performance on three challenging benchmark datasets. It improves recent Deep Learning model (DeCAF) [1] largely from the accuracy of 40.94% to 49.68% in the large scale SUN397 database. Codes for the LCCD will be available.



### On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units
- **Arxiv ID**: http://arxiv.org/abs/1508.00330v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1508.00330v2)
- **Published**: 2015-08-03 07:24:07+00:00
- **Updated**: 2015-11-01 06:44:10+00:00
- **Authors**: Zhibin Liao, Gustavo Carneiro
- **Comment**: None
- **Journal**: None
- **Summary**: Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets. The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit regularization scheme based on the fact that they must share their parameters with other subnetworks. Using this framework, we have made an empirical observation that can improve even more the performance of such models. We notice that these models assume a balanced initial distribution of data points with respect to the domain of the piecewise linear activation function. If that assumption is violated, then the piecewise linear activation units can degenerate into purely linear activation units, which can result in a significant reduction of their capacity to learn complex functions. Furthermore, as the number of model layers increases, this unbalanced initial distribution makes the model ill-conditioned. Therefore, we propose the introduction of batch normalisation units into deep feedforward neural networks with piecewise linear activations, which drives a more balanced use of these activation units, where each region of the activation function is trained with a relatively large proportion of training samples. Also, this batch normalisation promotes the pre-conditioning of very deep learning models. We show that by introducing maxout and batch normalisation units to the network in network model results in a model that produces classification results that are better than or comparable to the current state of the art in CIFAR-10, CIFAR-100, MNIST, and SVHN datasets.



### Identifying Emotion from Natural Walking
- **Arxiv ID**: http://arxiv.org/abs/1508.00413v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1508.00413v2)
- **Published**: 2015-08-03 13:48:46+00:00
- **Updated**: 2015-09-10 06:38:36+00:00
- **Authors**: Liqing Cui, Shun Li, Wan Zhang, Zhan Zhang, Tingshao Zhu
- **Comment**: None
- **Journal**: None
- **Summary**: Emotion identification from gait aims to automatically determine persons affective state, it has attracted a great deal of interests and offered immense potential value in action tendency, health care, psychological detection and human-computer(robot) interaction.In this paper, we propose a new method of identifying emotion from natural walking, and analyze the relevance between the traits of walking and affective states. After obtaining the pure acceleration data of wrist and ankle, we set a moving average filter window with different sizes w, then extract 114 features including time-domain, frequency-domain, power and distribution features from each data slice, and run principal component analysis (PCA) to reduce dimension. In experiments, we train SVM, Decision Tree, multilayerperception, Random Tree and Random Forest classification models, and compare the classification accuracy on data of wrist and ankle with respect to different w. The performance of emotion identification on acceleration data of ankle is better than wrist.Comparing different classification models' results, SVM has best accuracy of identifying anger and happy could achieve 90:31% and 89:76% respectively, and identification ratio of anger-happy is 87:10%.The anger-neutral-happy classification reaches 85%-78%-78%.The results show that it is capable of identifying personal emotional states through the gait of walking.



### Kernelized Multiview Projection
- **Arxiv ID**: http://arxiv.org/abs/1508.00430v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00430v2)
- **Published**: 2015-08-03 14:33:03+00:00
- **Updated**: 2015-08-04 09:42:14+00:00
- **Authors**: Mengyang Yu, Li Liu, Ling Shao
- **Comment**: None
- **Journal**: None
- **Summary**: Conventional vision algorithms adopt a single type of feature or a simple concatenation of multiple features, which is always represented in a high-dimensional space. In this paper, we propose a novel unsupervised spectral embedding algorithm called Kernelized Multiview Projection (KMP) to better fuse and embed different feature representations. Computing the kernel matrices from different features/views, KMP can encode them with the corresponding weights to achieve a low-dimensional and semantically meaningful subspace where the distribution of each view is sufficiently smooth and discriminative. More crucially, KMP is linear for the reproducing kernel Hilbert space (RKHS) and solves the out-of-sample problem, which allows it to be competent for various practical applications. Extensive experiments on three popular image datasets demonstrate the effectiveness of our multiview embedding algorithm.



### Integrated Inference and Learning of Neural Factors in Structural Support Vector Machines
- **Arxiv ID**: http://arxiv.org/abs/1508.00451v4
- **DOI**: 10.1016/j.patcog.2016.03.014
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1508.00451v4)
- **Published**: 2015-08-03 15:29:57+00:00
- **Updated**: 2016-03-03 22:46:17+00:00
- **Authors**: Rein Houthooft, Filip De Turck
- **Comment**: None
- **Journal**: None
- **Summary**: Tackling pattern recognition problems in areas such as computer vision, bioinformatics, speech or text recognition is often done best by taking into account task-specific statistical relations between output variables. In structured prediction, this internal structure is used to predict multiple outputs simultaneously, leading to more accurate and coherent predictions. Structural support vector machines (SSVMs) are nonprobabilistic models that optimize a joint input-output function through margin-based learning. Because SSVMs generally disregard the interplay between unary and interaction factors during the training phase, final parameters are suboptimal. Moreover, its factors are often restricted to linear combinations of input features, limiting its generalization power. To improve prediction accuracy, this paper proposes: (i) Joint inference and learning by integration of back-propagation and loss-augmented inference in SSVM subgradient descent; (ii) Extending SSVM factors to neural networks that form highly nonlinear functions of input features. Image segmentation benchmark results demonstrate improvements over conventional SSVM training methods in terms of accuracy, highlighting the feasibility of end-to-end SSVM training with neural factors.



### Evaluating software-based fingerprint liveness detection using Convolutional Networks and Local Binary Patterns
- **Arxiv ID**: http://arxiv.org/abs/1508.00537v1
- **DOI**: 10.1109/BIOMS.2014.6951531
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00537v1)
- **Published**: 2015-08-03 19:21:03+00:00
- **Updated**: 2015-08-03 19:21:03+00:00
- **Authors**: Rodrigo Frassetto Nogueira, Roberto de Alencar Lotufo, Rubens Campos Machado
- **Comment**: arXiv admin note: text overlap with arXiv:1301.3557 by other authors
- **Journal**: Biometric Measurements and Systems for Security and Medical
  Applications (BIOMS) Proceedings, 2014 IEEE Workshop on
- **Summary**: With the growing use of biometric authentication systems in the past years, spoof fingerprint detection has become increasingly important. In this work, we implement and evaluate two different feature extraction techniques for software-based fingerprint liveness detection: Convolutional Networks with random weights and Local Binary Patterns. Both techniques were used in conjunction with a Support Vector Machine (SVM) classifier. Dataset Augmentation was used to increase classifier's performance and a variety of preprocessing operations were tested, such as frequency filtering, contrast equalization, and region of interest filtering. The experiments were made on the datasets used in The Liveness Detection Competition of years 2009, 2011 and 2013, which comprise almost 50,000 real and fake fingerprints' images. Our best method achieves an overall rate of 95.2% of correctly classified samples - an improvement of 35% in test error when compared with the best previously published results.



