# Arxiv Papers in cs.CV on 2015-08-05
### 3D Automatic Segmentation Method for Retinal Optical Coherence Tomography Volume Data Using Boundary Surface Enhancement
- **Arxiv ID**: http://arxiv.org/abs/1508.00966v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00966v1)
- **Published**: 2015-08-05 03:42:54+00:00
- **Updated**: 2015-08-05 03:42:54+00:00
- **Authors**: Yankui Sun, Tian Zhang, Yue Zhao, Yufan He
- **Comment**: 27 pages, 19 figures
- **Journal**: None
- **Summary**: With the introduction of spectral-domain optical coherence tomography (SDOCT), much larger image datasets are routinely acquired compared to what was possible using the previous generation of time-domain OCT. Thus, there is a critical need for the development of 3D segmentation methods for processing these data. We present here a novel 3D automatic segmentation method for retinal OCT volume data. Briefly, to segment a boundary surface, two OCT volume datasets are obtained by using a 3D smoothing filter and a 3D differential filter. Their linear combination is then calculated to generate new volume data with an enhanced boundary surface, where pixel intensity, boundary position information, and intensity changes on both sides of the boundary surface are used simultaneously. Next, preliminary discrete boundary points are detected from the A-Scans of the volume data. Finally, surface smoothness constraints and a dynamic threshold are applied to obtain a smoothed boundary surface by correcting a small number of error points. Our method can extract retinal layer boundary surfaces sequentially with a decreasing search region of volume data. We performed automatic segmentation on eight human OCT volume datasets acquired from a commercial Spectralis OCT system, where each volume of data consisted of 97 OCT images with a resolution of 496 512; experimental results show that this method can accurately segment seven layer boundary surfaces in normal as well as some abnormal eyes.



### Single and Multiple Illuminant Estimation Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1508.00998v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.00998v2)
- **Published**: 2015-08-05 08:25:27+00:00
- **Updated**: 2015-12-11 14:35:20+00:00
- **Authors**: Simone Bianco, Claudio Cusano, Raimondo Schettini
- **Comment**: Submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence
- **Journal**: None
- **Summary**: In this paper we present a method for the estimation of the color of the illuminant in RAW images. The method includes a Convolutional Neural Network that has been specially designed to produce multiple local estimates. A multiple illuminant detector determines whether or not the local outputs of the network must be aggregated into a single estimate. We evaluated our method on standard datasets with single and multiple illuminants, obtaining lower estimation errors with respect to those obtained by other general purpose methods in the state of the art.



### Estimating snow cover from publicly available images
- **Arxiv ID**: http://arxiv.org/abs/1508.01055v1
- **DOI**: 10.1109/TMM.2016.2535356
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1508.01055v1)
- **Published**: 2015-08-05 12:46:26+00:00
- **Updated**: 2015-08-05 12:46:26+00:00
- **Authors**: Roman Fedorov, Alessandro Camerada, Piero Fraternali, Marco Tagliasacchi
- **Comment**: submitted to IEEE Transactions on Multimedia
- **Journal**: None
- **Summary**: In this paper we study the problem of estimating snow cover in mountainous regions, that is, the spatial extent of the earth surface covered by snow. We argue that publicly available visual content, in the form of user generated photographs and image feeds from outdoor webcams, can both be leveraged as additional measurement sources, complementing existing ground, satellite and airborne sensor data. To this end, we describe two content acquisition and processing pipelines that are tailored to such sources, addressing the specific challenges posed by each of them, e.g., identifying the mountain peaks, filtering out images taken in bad weather conditions, handling varying illumination conditions. The final outcome is summarized in a snow cover index, which indicates for a specific mountain and day of the year, the fraction of visible area covered by snow, possibly at different elevations. We created a manually labelled dataset to assess the accuracy of the image snow covered area estimation, achieving 90.0% precision at 91.1% recall. In addition, we show that seasonal trends related to air temperature are captured by the snow cover index.



### On the convergence of the sparse possibilistic c-means algorithm
- **Arxiv ID**: http://arxiv.org/abs/1508.01057v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01057v2)
- **Published**: 2015-08-05 13:02:48+00:00
- **Updated**: 2017-04-19 08:19:29+00:00
- **Authors**: Spyridoula D. Xenaki, Konstantinos D. Koutroumbas, Athanasios A. Rontogiannis
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, a convergence proof for the recently proposed sparse possibilistic c-means (SPCM) algorithm is provided, utilizing the celebrated Zangwill convergence theorem. It is shown that the iterative sequence generated by SPCM converges to a stationary point or there exists a subsequence of it that converges to a stationary point of the cost function of the algorithm.



### Detection of Critical Number of People in Interlocked Doors for Security Access Control by Exploiting a Microwave Transceiver-Array
- **Arxiv ID**: http://arxiv.org/abs/1508.01081v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01081v1)
- **Published**: 2015-08-05 14:09:23+00:00
- **Updated**: 2015-08-05 14:09:23+00:00
- **Authors**: Paolo Nesi, Gianni Pantaleo
- **Comment**: None
- **Journal**: None
- **Summary**: Counting the number of people is something many security application focus on, when dealing with controlling accesses in restricted areas, as it occurs with banks, airports, railway stations and governmental offices. This paper presents an automated solution for detecting the presence of more than one person into interlocked doors adopted in many accesses. In most cases, interlocked doors are small areas where other pieces of information and sensors are placed in order to detect the presence of guns, explosive, etc. The general goals and the required environmental condition, allowed us to implement a detection system at lower costs and complexity, with respect to other existing techniques. The system consists of a fixed array of microwave transceiver modules, whose received signals are processed to collect information related to a sort of volume occupied in the interlocked door cabin. The proposed solution has been statistically validated by using statistical analysis. The whole solution has been also implemented to be used in a real time environment and thus validated against real experimental measures.



### Evaluating color texture descriptors under large variations of controlled lighting conditions
- **Arxiv ID**: http://arxiv.org/abs/1508.01108v1
- **DOI**: 10.1364/JOSAA.33.000017
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01108v1)
- **Published**: 2015-08-05 15:40:21+00:00
- **Updated**: 2015-08-05 15:40:21+00:00
- **Authors**: Claudio Cusano, Paolo Napoletano, Raimondo Schettini
- **Comment**: Submitted to the Journal of the Optical Society of America A
- **Journal**: None
- **Summary**: The recognition of color texture under varying lighting conditions is still an open issue. Several features have been proposed for this purpose, ranging from traditional statistical descriptors to features extracted with neural networks. Still, it is not completely clear under what circumstances a feature performs better than the others. In this paper we report an extensive comparison of old and new texture features, with and without a color normalization step, with a particular focus on how they are affected by small and large variation in the lighting conditions. The evaluation is performed on a new texture database including 68 samples of raw food acquired under 46 conditions that present single and combined variations of light color, direction and intensity. The database allows to systematically investigate the robustness of texture descriptors across a large range of variations of imaging conditions.



### Partitioned Shape Modeling with On-the-Fly Sparse Appearance Learning for Anterior Visual Pathway Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1508.01128v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01128v1)
- **Published**: 2015-08-05 17:00:24+00:00
- **Updated**: 2015-08-05 17:00:24+00:00
- **Authors**: Awais Mansoor, Juan J. Cerrolaza, Robert A. Avery, Marius G. Linguraru
- **Comment**: 8 pages; 4 figures
- **Journal**: None
- **Summary**: MRI quantification of cranial nerves such as anterior visual pathway (AVP) in MRI is challenging due to their thin small size, structural variation along its path, and adjacent anatomic structures. Segmentation of pathologically abnormal optic nerve (e.g. optic nerve glioma) poses additional challenges due to changes in its shape at unpredictable locations. In this work, we propose a partitioned joint statistical shape model approach with sparse appearance learning for the segmentation of healthy and pathological AVP. Our main contributions are: (1) optimally partitioned statistical shape models for the AVP based on regional shape variations for greater local flexibility of statistical shape model; (2) refinement model to accommodate pathological regions as well as areas of subtle variation by training the model on-the-fly using the initial segmentation obtained in (1); (3) hierarchical deformable framework to incorporate scale information in partitioned shape and appearance models. Our method, entitled PAScAL (PArtitioned Shape and Appearance Learning), was evaluated on 21 MRI scans (15 healthy + 6 glioma cases) from pediatric patients (ages 2-17). The experimental results show that the proposed localized shape and sparse appearance-based learning approach significantly outperforms segmentation approaches in the analysis of pathological data.



### Socially Constrained Structural Learning for Groups Detection in Crowd
- **Arxiv ID**: http://arxiv.org/abs/1508.01158v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01158v2)
- **Published**: 2015-08-05 18:31:42+00:00
- **Updated**: 2015-08-06 17:08:31+00:00
- **Authors**: Francesco Solera, Simone Calderara, Rita Cucchiara
- **Comment**: None
- **Journal**: None
- **Summary**: Modern crowd theories agree that collective behavior is the result of the underlying interactions among small groups of individuals. In this work, we propose a novel algorithm for detecting social groups in crowds by means of a Correlation Clustering procedure on people trajectories. The affinity between crowd members is learned through an online formulation of the Structural SVM framework and a set of specifically designed features characterizing both their physical and social identity, inspired by Proxemic theory, Granger causality, DTW and Heat-maps. To adhere to sociological observations, we introduce a loss function (G-MITRE) able to deal with the complexity of evaluating group detection performances. We show our algorithm achieves state-of-the-art results when relying on both ground truth trajectories and tracklets previously extracted by available detector/tracker systems.



### HFirst: A Temporal Approach to Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1508.01176v1
- **DOI**: 10.1109/TPAMI.2015.2392947
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01176v1)
- **Published**: 2015-08-05 19:03:32+00:00
- **Updated**: 2015-08-05 19:03:32+00:00
- **Authors**: Garrick Orchard, Cedric Meyer, Ralph Etienne-Cummings, Christoph Posch, Nitish Thakor, Ryad Benosman
- **Comment**: 13 pages, 10 figures
- **Journal**: Pattern Analysis and Machine Intelligence, IEEE Transactions on,
  vol.37, no.10, pp.2028-2040, Oct 2015
- **Summary**: This paper introduces a spiking hierarchical model for object recognition which utilizes the precise timing information inherently present in the output of biologically inspired asynchronous Address Event Representation (AER) vision sensors. The asynchronous nature of these systems frees computation and communication from the rigid predetermined timing enforced by system clocks in conventional systems. Freedom from rigid timing constraints opens the possibility of using true timing to our advantage in computation. We show not only how timing can be used in object recognition, but also how it can in fact simplify computation. Specifically, we rely on a simple temporal-winner-take-all rather than more computationally intensive synchronous operations typically used in biologically inspired neural networks for object recognition. This approach to visual computation represents a major paradigm shift from conventional clocked systems and can find application in other sensory modalities and computational tasks. We showcase effectiveness of the approach by achieving the highest reported accuracy to date (97.5\%$\pm$3.5\%) for a previously published four class card pip recognition task and an accuracy of 84.9\%$\pm$1.9\% for a new more difficult 36 class character recognition task.



### TabletGaze: Unconstrained Appearance-based Gaze Estimation in Mobile Tablets
- **Arxiv ID**: http://arxiv.org/abs/1508.01244v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1508.01244v3)
- **Published**: 2015-08-05 22:38:53+00:00
- **Updated**: 2016-07-16 09:06:23+00:00
- **Authors**: Qiong Huang, Ashok Veeraraghavan, Ashutosh Sabharwal
- **Comment**: 18 pages, 17 figures, submitted to journal, website hosting the
  dataset: http://sh.rice.edu/tablet_gaze.html
- **Journal**: None
- **Summary**: We study gaze estimation on tablets, our key design goal is uncalibrated gaze estimation using the front-facing camera during natural use of tablets, where the posture and method of holding the tablet is not constrained. We collected the first large unconstrained gaze dataset of tablet users, labeled Rice TabletGaze dataset. The dataset consists of 51 subjects, each with 4 different postures and 35 gaze locations. Subjects vary in race, gender and in their need for prescription glasses, all of which might impact gaze estimation accuracy. Driven by our observations on the collected data, we present a TabletGaze algorithm for automatic gaze estimation using multi-level HoG feature and Random Forests regressor. The TabletGaze algorithm achieves a mean error of 3.17 cm. We perform extensive evaluation on the impact of various factors such as dataset size, race, wearing glasses and user posture on the gaze estimation accuracy and make important observations about the impact of these factors.



