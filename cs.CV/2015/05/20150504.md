# Arxiv Papers in cs.CV on 2015-05-04
### Modeling Representation of Videos for Anomaly Detection using Deep Learning: A Review
- **Arxiv ID**: http://arxiv.org/abs/1505.00523v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00523v1)
- **Published**: 2015-05-04 05:16:08+00:00
- **Updated**: 2015-05-04 05:16:08+00:00
- **Authors**: Yong Shean Chong, Yong Haur Tay
- **Comment**: arXiv admin note: text overlap with arXiv:1411.4423 by other authors
- **Journal**: None
- **Summary**: This review article surveys the current progresses made toward video-based anomaly detection. We address the most fundamental aspect for video anomaly detection, that is, video feature representation. Much research works have been done in finding the right representation to perform anomaly detection in video streams accurately with an acceptable false alarm rate. However, this is very challenging due to large variations in environment and human movement, and high space-time complexity due to huge dimensionality of video data. The weakly supervised nature of deep learning algorithms can help in learning representations from the video data itself instead of manually designing the right feature for specific scenes. In this paper, we would like to review the existing methods of modeling video representations using deep learning techniques for the task of anomaly detection and action recognition.



### Learning Document Image Binarization from Data
- **Arxiv ID**: http://arxiv.org/abs/1505.00529v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00529v1)
- **Published**: 2015-05-04 05:57:17+00:00
- **Updated**: 2015-05-04 05:57:17+00:00
- **Authors**: Yue Wu, Stephen Rawls, Wael AbdAlmageed, Premkumar Natarajan
- **Comment**: 13 pages, 8 figures
- **Journal**: None
- **Summary**: In this paper we present a fully trainable binarization solution for degraded document images. Unlike previous attempts that often used simple features with a series of pre- and post-processing, our solution encodes all heuristics about whether or not a pixel is foreground text into a high-dimensional feature vector and learns a more complicated decision function. In particular, we prepare features of three types: 1) existing features for binarization such as intensity [1], contrast [2], [3], and Laplacian [4], [5]; 2) reformulated features from existing binarization decision functions such those in [6] and [7]; and 3) our newly developed features, namely the Logarithm Intensity Percentile (LIP) and the Relative Darkness Index (RDI). Our initial experimental results show that using only selected samples (about 1.5% of all available training data), we can achieve a binarization performance comparable to those fine-tuned (typically by hand), state-of-the-art methods. Additionally, the trained document binarization classifier shows good generalization capabilities on out-of-domain data.



### Higher Order Maximum Persistency and Comparison Theorems
- **Arxiv ID**: http://arxiv.org/abs/1505.00571v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DM, math.CO
- **Links**: [PDF](http://arxiv.org/pdf/1505.00571v1)
- **Published**: 2015-05-04 09:50:25+00:00
- **Updated**: 2015-05-04 09:50:25+00:00
- **Authors**: Alexander Shekhovtsov
- **Comment**: Submitted to CVIU Special Issuie on Inference in Graphical Models
- **Journal**: None
- **Summary**: We address combinatorial problems that can be formulated as minimization of a partially separable function of discrete variables (energy minimization in graphical models, weighted constraint satisfaction, pseudo-Boolean optimization, 0-1 polynomial programming). For polyhedral relaxations of such problems it is generally not true that variables integer in the relaxed solution will retain the same values in the optimal discrete solution. Those which do are called persistent. Such persistent variables define a part of a globally optimal solution. Once identified, they can be excluded from the problem, reducing its size.   To any polyhedral relaxation we associate a sufficient condition proving persistency of a subset of variables. We set up a specially constructed linear program which determines the set of persistent variables maximal with respect to the relaxation. The condition improves as the relaxation is tightened and possesses all its invariances. The proposed framework explains a variety of existing methods originating from different areas of research and based on different principles. A theoretical comparison is established that relates these methods to the standard linear relaxation and proves that the proposed technique identifies same or larger set of persistent variables.



### Activity recognition from videos with parallel hypergraph matching on GPUs
- **Arxiv ID**: http://arxiv.org/abs/1505.00581v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00581v1)
- **Published**: 2015-05-04 10:30:47+00:00
- **Updated**: 2015-05-04 10:30:47+00:00
- **Authors**: Eric Lombardi, Christian Wolf, Oya Celiktutan, BÃ¼lent Sankur
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a method for activity recognition from videos based on sparse local features and hypergraph matching. We benefit from special properties of the temporal domain in the data to derive a sequential and fast graph matching algorithm for GPUs.   Traditionally, graphs and hypergraphs are frequently used to recognize complex and often non-rigid patterns in computer vision, either through graph matching or point-set matching with graphs. Most formulations resort to the minimization of a difficult discrete energy function mixing geometric or structural terms with data attached terms involving appearance features. Traditional methods solve this minimization problem approximately, for instance with spectral techniques.   In this work, instead of solving the problem approximatively, the exact solution for the optimal assignment is calculated in parallel on GPUs. The graphical structure is simplified and regularized, which allows to derive an efficient recursive minimization algorithm. The algorithm distributes subproblems over the calculation units of a GPU, which solves them in parallel, allowing the system to run faster than real-time on medium-end GPUs.



### Light-field Microscopy with a Consumer Light-field Camera
- **Arxiv ID**: http://arxiv.org/abs/1508.03590v2
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1508.03590v2)
- **Published**: 2015-05-04 12:17:09+00:00
- **Updated**: 2015-12-07 09:12:02+00:00
- **Authors**: Lois Mignard-Debise, Ivo Ihrke
- **Comment**: None
- **Journal**: None
- **Summary**: We explore the use of inexpensive consumer light- field camera technology for the purpose of light-field mi- croscopy. Our experiments are based on the Lytro (first gen- eration) camera. Unfortunately, the optical systems of the Lytro and those of microscopes are not compatible, lead- ing to a loss of light-field information due to angular and spatial vignetting when directly recording microscopic pic- tures. We therefore consider an adaptation of the Lytro op- tical system. We demonstrate that using the Lytro directly as an oc- ular replacement, leads to unacceptable spatial vignetting. However, we also found a setting that allows the use of the Lytro camera in a virtual imaging mode which prevents the information loss to a large extent. We analyze the new vir- tual imaging mode and use it in two different setups for im- plementing light-field microscopy using a Lytro camera. As a practical result, we show that the camera can be used for low magnification work, as e.g. common in quality control, surface characterization, etc. We achieve a maximum spa- tial resolution of about 6.25{\mu}m, albeit at a limited SNR for the side views.



### See the Difference: Direct Pre-Image Reconstruction and Pose Estimation by Differentiating HOG
- **Arxiv ID**: http://arxiv.org/abs/1505.00663v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00663v4)
- **Published**: 2015-05-04 14:50:29+00:00
- **Updated**: 2015-10-02 10:00:18+00:00
- **Authors**: Wei-Chen Chiu, Mario Fritz
- **Comment**: None
- **Journal**: None
- **Summary**: The Histogram of Oriented Gradient (HOG) descriptor has led to many advances in computer vision over the last decade and is still part of many state of the art approaches. We realize that the associated feature computation is piecewise differentiable and therefore many pipelines which build on HOG can be made differentiable. This lends to advanced introspection as well as opportunities for end-to-end optimization. We present our implementation of $\nabla$HOG based on the auto-differentiation toolbox Chumpy and show applications to pre-image visualization and pose estimation which extends the existing differentiable renderer OpenDR pipeline. Both applications improve on the respective state-of-the-art HOG approaches.



### Interleaved Text/Image Deep Mining on a Large-Scale Radiology Database for Automated Image Interpretation
- **Arxiv ID**: http://arxiv.org/abs/1505.00670v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1505.00670v1)
- **Published**: 2015-05-04 15:05:59+00:00
- **Updated**: 2015-05-04 15:05:59+00:00
- **Authors**: Hoo-Chang Shin, Le Lu, Lauren Kim, Ari Seff, Jianhua Yao, Ronald M. Summers
- **Comment**: None
- **Journal**: None
- **Summary**: Despite tremendous progress in computer vision, there has not been an attempt for machine learning on very large-scale medical image databases. We present an interleaved text/image deep learning system to extract and mine the semantic interactions of radiology images and reports from a national research hospital's Picture Archiving and Communication System. With natural language processing, we mine a collection of representative ~216K two-dimensional key images selected by clinicians for diagnostic reference, and match the images with their descriptions in an automated manner. Our system interleaves between unsupervised learning and supervised learning on document- and sentence-level text collections, to generate semantic labels and to predict them given an image. Given an image of a patient scan, semantic topics in radiology levels are predicted, and associated key-words are generated. Also, a number of frequent disease types are detected as present or absent, to provide more specific interpretation of a patient scan. This shows the potential of large-scale learning and prediction in electronic patient records available in most modern clinical institutions.



### Unsupervised Learning of Visual Representations using Videos
- **Arxiv ID**: http://arxiv.org/abs/1505.00687v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00687v2)
- **Published**: 2015-05-04 15:50:53+00:00
- **Updated**: 2015-10-06 17:05:49+00:00
- **Authors**: Xiaolong Wang, Abhinav Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: Is strong supervision necessary for learning a good visual representation? Do we really need millions of semantically-labeled images to train a Convolutional Neural Network (CNN)? In this paper, we present a simple yet surprisingly powerful approach for unsupervised learning of CNN. Specifically, we use hundreds of thousands of unlabeled videos from the web to learn visual representations. Our key idea is that visual tracking provides the supervision. That is, two patches connected by a track should have similar visual representation in deep feature space since they probably belong to the same object or object part. We design a Siamese-triplet network with a ranking loss function to train this CNN representation. Without using a single image from ImageNet, just using 100K unlabeled videos and the VOC 2012 dataset, we train an ensemble of unsupervised networks that achieves 52% mAP (no bounding box regression). This performance comes tantalizingly close to its ImageNet-supervised counterpart, an ensemble which achieves a mAP of 54.4%. We also show that our unsupervised network can perform competitively in other tasks such as surface-normal estimation.



### A Gaussian Scale Space Approach For Exudates Detection, Classification And Severity Prediction
- **Arxiv ID**: http://arxiv.org/abs/1505.00737v1
- **DOI**: None
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1505.00737v1)
- **Published**: 2015-05-04 18:05:52+00:00
- **Updated**: 2015-05-04 18:05:52+00:00
- **Authors**: Mrinal Haloi, Samarendra Dandapat, Rohit Sinha
- **Comment**: Accepted in ICIP 2015, Quebec city, Canada
- **Journal**: None
- **Summary**: In the context of Computer Aided Diagnosis system for diabetic retinopathy, we present a novel method for detection of exudates and their classification for disease severity prediction. The method is based on Gaussian scale space based interest map and mathematical morphology. It makes use of support vector machine for classification and location information of the optic disc and the macula region for severity prediction. It can efficiently handle luminance variation and it is suitable for varied sized exudates. The method has been probed in publicly available DIARETDB1V2 and e-ophthaEX databases. For exudate detection the proposed method achieved a sensitivity of 96.54% and prediction of 98.35% in DIARETDB1V2 database.



### Self-Expressive Decompositions for Matrix Approximation and Clustering
- **Arxiv ID**: http://arxiv.org/abs/1505.00824v1
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, cs.LG, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1505.00824v1)
- **Published**: 2015-05-04 21:56:54+00:00
- **Updated**: 2015-05-04 21:56:54+00:00
- **Authors**: Eva L. Dyer, Tom A. Goldstein, Raajen Patel, Konrad P. Kording, Richard G. Baraniuk
- **Comment**: 11 pages, 7 figures
- **Journal**: None
- **Summary**: Data-aware methods for dimensionality reduction and matrix decomposition aim to find low-dimensional structure in a collection of data. Classical approaches discover such structure by learning a basis that can efficiently express the collection. Recently, "self expression", the idea of using a small subset of data vectors to represent the full collection, has been developed as an alternative to learning. Here, we introduce a scalable method for computing sparse SElf-Expressive Decompositions (SEED). SEED is a greedy method that constructs a basis by sequentially selecting incoherent vectors from the dataset. After forming a basis from a subset of vectors in the dataset, SEED then computes a sparse representation of the dataset with respect to this basis. We develop sufficient conditions under which SEED exactly represents low rank matrices and vectors sampled from a unions of independent subspaces. We show how SEED can be used in applications ranging from matrix approximation and denoising to clustering, and apply it to numerous real-world datasets. Our results demonstrate that SEED is an attractive low-complexity alternative to other sparse matrix factorization approaches such as sparse PCA and self-expressive methods for clustering.



