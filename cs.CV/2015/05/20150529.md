# Arxiv Papers in cs.CV on 2015-05-29
### Cross-domain Image Retrieval with a Dual Attribute-aware Ranking Network
- **Arxiv ID**: http://arxiv.org/abs/1505.07922v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.07922v1)
- **Published**: 2015-05-29 04:46:37+00:00
- **Updated**: 2015-05-29 04:46:37+00:00
- **Authors**: Junshi Huang, Rogerio S. Feris, Qiang Chen, Shuicheng Yan
- **Comment**: None
- **Journal**: None
- **Summary**: We address the problem of cross-domain image retrieval, considering the following practical application: given a user photo depicting a clothing image, our goal is to retrieve the same or attribute-similar clothing items from online shopping stores. This is a challenging problem due to the large discrepancy between online shopping images, usually taken in ideal lighting/pose/background conditions, and user photos captured in uncontrolled conditions. To address this problem, we propose a Dual Attribute-aware Ranking Network (DARN) for retrieval feature learning. More specifically, DARN consists of two sub-networks, one for each domain, whose retrieval feature representations are driven by semantic attribute learning. We show that this attribute-guided learning is a key factor for retrieval accuracy improvement. In addition, to further align with the nature of the retrieval problem, we impose a triplet visual similarity constraint for learning to rank across the two sub-networks. Another contribution of our work is a large-scale dataset which makes the network learning feasible. We exploit customer review websites to crawl a large set of online shopping images and corresponding offline user photos with fine-grained clothing attributes, i.e., around 450,000 online shopping images and about 90,000 exact offline counterpart images of those online ones. All these images are collected from real-world consumer websites reflecting the diversity of the data modality, which makes this dataset unique and rare in the academic community. We extensively evaluate the retrieval performance of networks in different configurations. The top-20 retrieval accuracy is doubled when using the proposed DARN other than the current popular solution using pre-trained CNN features only (0.570 vs. 0.268).



### Fast Computation of PERCLOS and Saccadic Ratio
- **Arxiv ID**: http://arxiv.org/abs/1505.07923v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.07923v1)
- **Published**: 2015-05-29 05:04:30+00:00
- **Updated**: 2015-05-29 05:04:30+00:00
- **Authors**: Anirban Dasgupta, Aurobinda Routray
- **Comment**: MS Thesis
- **Journal**: None
- **Summary**: This thesis describes the development of fast algorithms for the computation of PERcentage CLOSure of eyes (PERCLOS) and Saccadic Ratio (SR). PERCLOS and SR are two ocular parameters reported to be measures of alertness levels in human beings. PERCLOS is the percentage of time in which at least 80% of the eyelid remains closed over the pupil. Saccades are fast and simultaneous movement of both the eyes in the same direction. SR is the ratio of peak saccadic velocity to the saccadic duration. This thesis addresses the issues of image based estimation of PERCLOS and SR, prevailing in the literature such as illumination variation, poor illumination conditions, head rotations etc. In this work, algorithms for real-time PERCLOS computation has been developed and implemented on an embedded platform. The platform has been used as a case study for assessment of loss of attention in automotive drivers. The SR estimation has been carried out offline as real-time implementation requires high frame rates of processing which is difficult to achieve due to hardware limitations. The accuracy in estimation of the loss of attention using PERCLOS and SR has been validated using brain signals, which are reported to be an authentic cue for estimating the state of alertness in human beings. The major contributions of this thesis include database creation, design and implementation of fast algorithms for estimating PERCLOS and SR on embedded computing platforms.



### Salient Object Detection via Augmented Hypotheses
- **Arxiv ID**: http://arxiv.org/abs/1505.07930v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.07930v1)
- **Published**: 2015-05-29 06:03:57+00:00
- **Updated**: 2015-05-29 06:03:57+00:00
- **Authors**: Tam V. Nguyen, Jose Sepulveda
- **Comment**: IJCAI 2015 paper
- **Journal**: None
- **Summary**: In this paper, we propose using \textit{augmented hypotheses} which consider objectness, foreground and compactness for salient object detection. Our algorithm consists of four basic steps. First, our method generates the objectness map via objectness hypotheses. Based on the objectness map, we estimate the foreground margin and compute the corresponding foreground map which prefers the foreground objects. From the objectness map and the foreground map, the compactness map is formed to favor the compact objects. We then derive a saliency measure that produces a pixel-accurate saliency map which uniformly covers the objects of interest and consistently separates fore- and background. We finally evaluate the proposed framework on two challenging datasets, MSRA-1000 and iCoSeg. Our extensive experimental results show that our method outperforms state-of-the-art approaches.



### Symbolic Segmentation Using Algorithm Selection
- **Arxiv ID**: http://arxiv.org/abs/1505.07934v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.07934v1)
- **Published**: 2015-05-29 06:18:31+00:00
- **Updated**: 2015-05-29 06:18:31+00:00
- **Authors**: Martin Lukac, Kamila Abdiyeva, Michitaka Kameyama
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present an alternative approach to symbolic segmentation; instead of implementing a new method we approach symbolic segmentation as an algorithm selection problem. That is, let there be $n$ available algorithms for symbolic segmentation, a selection mechanism forms a set of input features and image attributes and selects on a case by case basis the best algorithm. The selection mechanism is demonstrated from within an algorithm framework where the selection is done in a set of various algorithm networks. Two sets of experiments are performed and in both cases we demonstrate that the algorithm selection allows to increase the result of the symbolic segmentation by a considerable amount.



### Research on the fast Fourier transform of image based on GPU
- **Arxiv ID**: http://arxiv.org/abs/1505.08019v1
- **DOI**: None
- **Categories**: **cs.MS**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.08019v1)
- **Published**: 2015-05-29 12:33:52+00:00
- **Updated**: 2015-05-29 12:33:52+00:00
- **Authors**: Feifei Shen, Zhenjian Song, Congrui Wu, Jiaqi Geng, Qingyun Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Study of general purpose computation by GPU (Graphics Processing Unit) can improve the image processing capability of micro-computer system. This paper studies the parallelism of the different stages of decimation in time radix 2 FFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT on GPU. The experiment result demonstrates the validity and advantage over general CPU, especially in the condition of large input size. The approach can also be generalized to other transforms alike.



### General Deformations of Point Configurations Viewed By a Pinhole Model Camera
- **Arxiv ID**: http://arxiv.org/abs/1505.08070v2
- **DOI**: None
- **Categories**: **cs.CV**, math.AG, 53Z99, 53A07, 68T45, 14P05
- **Links**: [PDF](http://arxiv.org/pdf/1505.08070v2)
- **Published**: 2015-05-29 14:51:18+00:00
- **Updated**: 2022-01-09 19:51:44+00:00
- **Authors**: Yirmeyahu Kaminski, Michael Werman
- **Comment**: None
- **Journal**: None
- **Summary**: This paper is a theoretical study of the following Non-Rigid Structure from Motion problem. What can be computed from a monocular view of a parametrically deforming set of points? We treat various variations of this problem for affine and polynomial deformations with calibrated and uncalibrated cameras. We show that in general at least three images with quasi-identical two deformations are needed in order to have a finite set of solutions of the points' structure and calculate some simple examples.



### Geometry of Graph Edit Distance Spaces
- **Arxiv ID**: http://arxiv.org/abs/1505.08071v1
- **DOI**: None
- **Categories**: **cs.CV**, math.MG
- **Links**: [PDF](http://arxiv.org/pdf/1505.08071v1)
- **Published**: 2015-05-29 14:51:23+00:00
- **Updated**: 2015-05-29 14:51:23+00:00
- **Authors**: Brijnesh J. Jain
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we study the geometry of graph spaces endowed with a special class of graph edit distances. The focus is on geometrical results useful for statistical pattern recognition. The main result is the Graph Representation Theorem. It states that a graph is a point in some geometrical space, called orbit space. Orbit spaces are well investigated and easier to explore than the original graph space. We derive a number of geometrical results from the orbit space representation, translate them to the graph space, and indicate their significance and usefulness in statistical pattern recognition.



### Learning to count with deep object features
- **Arxiv ID**: http://arxiv.org/abs/1505.08082v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.08082v1)
- **Published**: 2015-05-29 15:06:15+00:00
- **Updated**: 2015-05-29 15:06:15+00:00
- **Authors**: Santi Seguí, Oriol Pujol, Jordi Vitrià
- **Comment**: This paper has been accepted at Deep Vision Workshop at CVPR 2015
- **Journal**: None
- **Summary**: Learning to count is a learning strategy that has been recently proposed in the literature for dealing with problems where estimating the number of object instances in a scene is the final objective. In this framework, the task of learning to detect and localize individual object instances is seen as a harder task that can be evaded by casting the problem as that of computing a regression value from hand-crafted image features. In this paper we explore the features that are learned when training a counting convolutional neural network in order to understand their underlying representation. To this end we define a counting problem for MNIST data and show that the internal representation of the network is able to classify digits in spite of the fact that no direct supervision was provided for them during training. We also present preliminary results about a deep network that is able to count the number of pedestrians in a scene.



### CURL: Co-trained Unsupervised Representation Learning for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1505.08098v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, stat.ML, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/1505.08098v2)
- **Published**: 2015-05-29 15:57:40+00:00
- **Updated**: 2015-09-11 12:21:20+00:00
- **Authors**: Simone Bianco, Gianluigi Ciocca, Claudio Cusano
- **Comment**: Submitted
- **Journal**: None
- **Summary**: In this paper we propose a strategy for semi-supervised image classification that leverages unsupervised representation learning and co-training. The strategy, that is called CURL from Co-trained Unsupervised Representation Learning, iteratively builds two classifiers on two different views of the data. The two views correspond to different representations learned from both labeled and unlabeled data and differ in the fusion scheme used to combine the image features. To assess the performance of our proposal, we conducted several experiments on widely used data sets for scene and object recognition. We considered three scenarios (inductive, transductive and self-taught learning) that differ in the strategy followed to exploit the unlabeled data. As image features we considered a combination of GIST, PHOG, and LBP as well as features extracted from a Convolutional Neural Network. Moreover, two embodiments of CURL are investigated: one using Ensemble Projection as unsupervised representation learning coupled with Logistic Regression, and one based on LapSVM. The results show that CURL clearly outperforms other supervised and semi-supervised learning methods in the state of the art.



### Feature Representation for Online Signature Verification
- **Arxiv ID**: http://arxiv.org/abs/1505.08153v1
- **DOI**: 10.1109/AISP.2015.7123528
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1505.08153v1)
- **Published**: 2015-05-29 19:09:02+00:00
- **Updated**: 2015-05-29 19:09:02+00:00
- **Authors**: Mohsen Fayyaz, Mohammad Hajizadeh_Saffar, Mohammad Sabokrou, Mahmood Fathy
- **Comment**: 10 pages, 10 figures, Submitted to IEEE Transactions on Information
  Forensics and Security
- **Journal**: None
- **Summary**: Biometrics systems have been used in a wide range of applications and have improved people authentication. Signature verification is one of the most common biometric methods with techniques that employ various specifications of a signature. Recently, deep learning has achieved great success in many fields, such as image, sounds and text processing. In this paper, deep learning method has been used for feature extraction and feature selection.



