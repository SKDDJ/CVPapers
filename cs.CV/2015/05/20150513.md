# Arxiv Papers in cs.CV on 2015-05-13
### Leveraging Image based Prior for Visual Place Recognition
- **Arxiv ID**: http://arxiv.org/abs/1505.03205v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03205v2)
- **Published**: 2015-05-13 00:36:38+00:00
- **Updated**: 2015-05-14 04:12:09+00:00
- **Authors**: Tsukamoto Taisho, Tanaka Kanji
- **Comment**: 8 pages, 6 figures, preprint. Accepted for publication in MVA2015
  (oral presentation)
- **Journal**: None
- **Summary**: In this study, we propose a novel scene descriptor for visual place recognition. Unlike popular bag-of-words scene descriptors which rely on a library of vector quantized visual features, our proposed descriptor is based on a library of raw image data, such as publicly available photo collections from Google StreetView and Flickr. The library images need not to be associated with spatial information regarding the viewpoint and orientation of the scene. As a result, these images are cheaper than the database images; in addition, they are readily available. Our proposed descriptor directly mines the image library to discover landmarks (i.e., image patches) that suitably match an input query/database image. The discovered landmarks are then compactly described by their pose and shape (i.e., library image ID, bounding boxes) and used as a compact discriminative scene descriptor for the input image. We evaluate the effectiveness of our scene description framework by comparing its performance to that of previous approaches.



### PISA: Pixelwise Image Saliency by Aggregating Complementary Appearance Contrast Measures with Edge-Preserving Coherence
- **Arxiv ID**: http://arxiv.org/abs/1505.03227v1
- **DOI**: 10.1109/TIP.2015.2432712
- **Categories**: **cs.CV**, 68U10
- **Links**: [PDF](http://arxiv.org/pdf/1505.03227v1)
- **Published**: 2015-05-13 03:05:46+00:00
- **Updated**: 2015-05-13 03:05:46+00:00
- **Authors**: Keze Wang, Liang Lin, Jiangbo Lu, Chenglong Li, Keyang Shi
- **Comment**: 14 pages, 14 figures, 1 table, to appear in IEEE Transactions on
  Image Processing
- **Journal**: IEEE Transactions on Image Processing (TIP), volume. 24, Issue.
  10, page. 3019 - 3033, Oct. 2015
- **Summary**: Driven by recent vision and graphics applications such as image segmentation and object recognition, computing pixel-accurate saliency values to uniformly highlight foreground objects becomes increasingly important. In this paper, we propose a unified framework called PISA, which stands for Pixelwise Image Saliency Aggregating various bottom-up cues and priors. It generates spatially coherent yet detail-preserving, pixel-accurate and fine-grained saliency, and overcomes the limitations of previous methods which use homogeneous superpixel-based and color only treatment. PISA aggregates multiple saliency cues in a global context such as complementary color and structure contrast measures with their spatial priors in the image domain. The saliency confidence is further jointly modeled with a neighborhood consistence constraint into an energy minimization formulation, in which each pixel will be evaluated with multiple hypothetical saliency levels. Instead of using global discrete optimization methods, we employ the cost-volume filtering technique to solve our formulation, assigning the saliency levels smoothly while preserving the edge-aware structure details. In addition, a faster version of PISA is developed using a gradient-driven image sub-sampling strategy to greatly improve the runtime efficiency while keeping comparable detection accuracy. Extensive experiments on a number of public datasets suggest that PISA convincingly outperforms other state-of-the-art approaches. In addition, with this work we also create a new dataset containing $800$ commodity images for evaluating saliency detection. The dataset and source code of PISA can be downloaded at http://vision.sysu.edu.cn/project/PISA/



### APAC: Augmented PAttern Classification with Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1505.03229v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03229v1)
- **Published**: 2015-05-13 03:33:29+00:00
- **Updated**: 2015-05-13 03:33:29+00:00
- **Authors**: Ikuro Sato, Hiroki Nishimura, Kensuke Yokoi
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have been exhibiting splendid accuracies in many of visual pattern classification problems. Many of the state-of-the-art methods employ a technique known as data augmentation at the training stage. This paper addresses an issue of decision rule for classifiers trained with augmented data. Our method is named as APAC: the Augmented PAttern Classification, which is a way of classification using the optimal decision rule for augmented data learning. Discussion of methods of data augmentation is not our primary focus. We show clear evidences that APAC gives far better generalization performance than the traditional way of class prediction in several experiments. Our convolutional neural network model with APAC achieved a state-of-the-art accuracy on the MNIST dataset among non-ensemble classifiers. Even our multilayer perceptron model beats some of the convolutional models with recently invented stochastic regularization techniques on the CIFAR-10 dataset.



### A Framework for Fast Face and Eye Detection
- **Arxiv ID**: http://arxiv.org/abs/1505.03344v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03344v1)
- **Published**: 2015-05-13 11:56:01+00:00
- **Updated**: 2015-05-13 11:56:01+00:00
- **Authors**: Anjith George, Anirban Dasgupta, Aurobinda Routray
- **Comment**: 5 pages , 10 figures,
- **Journal**: None
- **Summary**: Face detection is an essential step in many computer vision applications like surveillance, tracking, medical analysis, facial expression analysis etc. Several approaches have been made in the direction of face detection. Among them, Haar-like features based method is a robust method. In spite of the robustness, Haar - like features work with some limitations. However, with some simple modifications in the algorithm, its performance can be made faster and more robust. The present work refers to the increase in speed of operation of the original algorithm by down sampling the frames and its analysis with different scale factors. It also discusses the detection of tilted faces using an affine transformation of the input image.



### A Vision Based System for Monitoring the Loss of Attention in Automotive Drivers
- **Arxiv ID**: http://arxiv.org/abs/1505.03352v1
- **DOI**: 10.1109/TITS.2013.2271052
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03352v1)
- **Published**: 2015-05-13 12:21:26+00:00
- **Updated**: 2015-05-13 12:21:26+00:00
- **Authors**: Anirban Dasgupta, Anjith George, S. L. Happy, Aurobinda Routray
- **Comment**: 14 pages, 24 figures Journal article
- **Journal**: Intelligent Transportation Systems, IEEE Transactions on 14, no. 4
  (2013): 1825-1838
- **Summary**: On board monitoring of the alertness level of an automotive driver has been a challenging research in transportation safety and management. In this paper, we propose a robust real time embedded platform to monitor the loss of attention of the driver during day as well as night driving conditions. The PERcentage of eye CLOSure (PERCLOS) has been used as the indicator of the alertness level. In this approach, the face is detected using Haar like features and tracked using a Kalman Filter. The Eyes are detected using Principal Component Analysis (PCA) during day time and the block Local Binary Pattern (LBP) features during night. Finally the eye state is classified as open or closed using Support Vector Machines(SVM). In plane and off plane rotations of the drivers face have been compensated using Affine and Perspective Transformation respectively. Compensation in illumination variation is carried out using Bi Histogram Equalization (BHE). The algorithm has been cross validated using brain signals and finally been implemented on a Single Board Computer (SBC) having Intel Atom processor, 1 GB RAM, 1.66 GHz clock, x86 architecture, Windows Embedded XP operating system. The system is found to be robust under actual driving conditions.



### An Image is Worth More than a Thousand Favorites: Surfacing the Hidden Beauty of Flickr Pictures
- **Arxiv ID**: http://arxiv.org/abs/1505.03358v2
- **DOI**: None
- **Categories**: **cs.SI**, cs.CV, cs.CY, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1505.03358v2)
- **Published**: 2015-05-13 12:40:24+00:00
- **Updated**: 2015-05-15 10:05:34+00:00
- **Authors**: Rossano Schifanella, Miriam Redi, Luca Aiello
- **Comment**: ICWSM 2015
- **Journal**: None
- **Summary**: The dynamics of attention in social media tend to obey power laws. Attention concentrates on a relatively small number of popular items and neglecting the vast majority of content produced by the crowd. Although popularity can be an indication of the perceived value of an item within its community, previous research has hinted to the fact that popularity is distinct from intrinsic quality. As a result, content with low visibility but high quality lurks in the tail of the popularity distribution. This phenomenon can be particularly evident in the case of photo-sharing communities, where valuable photographers who are not highly engaged in online social interactions contribute with high-quality pictures that remain unseen. We propose to use a computer vision method to surface beautiful pictures from the immense pool of near-zero-popularity items, and we test it on a large dataset of creative-commons photos on Flickr. By gathering a large crowdsourced ground truth of aesthetics scores for Flickr images, we show that our method retrieves photos whose median perceived beauty score is equal to the most popular ones, and whose average is lower by only 1.5%.



### MRF Optimization by Graph Approximation
- **Arxiv ID**: http://arxiv.org/abs/1505.03365v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03365v1)
- **Published**: 2015-05-13 13:05:05+00:00
- **Updated**: 2015-05-13 13:05:05+00:00
- **Authors**: Wonsik Kim, Kyoung Mu Lee
- **Comment**: CVPR2015
- **Journal**: None
- **Summary**: Graph cuts-based algorithms have achieved great success in energy minimization for many computer vision applications. These algorithms provide approximated solutions for multi-label energy functions via move-making approach. This approach fuses the current solution with a proposal to generate a lower-energy solution. Thus, generating the appropriate proposals is necessary for the success of the move-making approach. However, not much research efforts has been done on the generation of "good" proposals, especially for non-metric energy functions. In this paper, we propose an application-independent and energy-based approach to generate "good" proposals. With these proposals, we present a graph cuts-based move-making algorithm called GA-fusion (fusion with graph approximation-based proposals). Extensive experiments support that our proposal generation is effective across different classes of energy functions. The proposed algorithm outperforms others both on real and synthetic problems.



### A Review Paper: Noise Models in Digital Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1505.03489v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03489v1)
- **Published**: 2015-05-13 18:37:01+00:00
- **Updated**: 2015-05-13 18:37:01+00:00
- **Authors**: Ajay Kumar Boyat, Brijendra Kumar Joshi
- **Comment**: None
- **Journal**: Signal & Image Processing : An International Journal (SIPIJ)
  Vol.6, No.2, April 2015
- **Summary**: Noise is always presents in digital images during image acquisition, coding, transmission, and processing steps. Noise is very difficult to remove it from the digital images without the prior knowledge of noise model. That is why, review of noise models are essential in the study of image denoising techniques. In this paper, we express a brief overview of various noise models. These noise models can be selected by analysis of their origin. In this way, we present a complete and quantitative analysis of noise models available in digital images.



### Modified Hausdorff Fractal Dimension (MHFD)
- **Arxiv ID**: http://arxiv.org/abs/1505.03493v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03493v2)
- **Published**: 2015-05-13 18:45:07+00:00
- **Updated**: 2015-05-14 13:08:15+00:00
- **Authors**: Reza Farrahi Moghaddam, Mohamed Cheriet
- **Comment**: 15 pages, 4 figures, 2 algorithms. Working Paper WP-RFM-15-02,
  (version: 150507)
- **Journal**: None
- **Summary**: The Hausdorff fractal dimension has been a fast-to-calculate method to estimate complexity of fractal shapes. In this work, a modified version of this fractal dimension is presented in order to make it more robust when applied in estimating complexity of non-fractal images. The modified Hausdorff fractal dimension stands on two features that weaken the requirement of presence of a shape and also reduce the impact of the noise possibly presented in the input image. The new algorithm has been evaluated on a set of images of different character with promising performance.



### Loop-corrected belief propagation for lattice spin models
- **Arxiv ID**: http://arxiv.org/abs/1505.03504v3
- **DOI**: 10.1140/epjb/e2015-60485-6
- **Categories**: **cond-mat.stat-mech**, cond-mat.dis-nn, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.03504v3)
- **Published**: 2015-05-13 19:36:35+00:00
- **Updated**: 2016-02-16 07:55:59+00:00
- **Authors**: Hai-Jun Zhou, Wei-Mou Zheng
- **Comment**: 11 pages, minor changes with new references added. Final version as
  published in EPJB
- **Journal**: European Physical Journal B 88: 336 (2015)
- **Summary**: Belief propagation (BP) is a message-passing method for solving probabilistic graphical models. It is very successful in treating disordered models (such as spin glasses) on random graphs. On the other hand, finite-dimensional lattice models have an abundant number of short loops, and the BP method is still far from being satisfactory in treating the complicated loop-induced correlations in these systems. Here we propose a loop-corrected BP method to take into account the effect of short loops in lattice spin models. We demonstrate, through an application to the square-lattice Ising model, that loop-corrected BP improves over the naive BP method significantly. We also implement loop-corrected BP at the coarse-grained region graph level to further boost its performance.



### On a spatial-temporal decomposition of the optical flow
- **Arxiv ID**: http://arxiv.org/abs/1505.03505v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.03505v3)
- **Published**: 2015-05-13 19:38:57+00:00
- **Updated**: 2017-01-28 20:57:56+00:00
- **Authors**: Aniello Raffale Patrone, Otmar Scherzer
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we present a decomposition algorithm for computation of the spatial-temporal optical flow of a dynamic image sequence. We consider several applications, such as the extraction of temporal motion features and motion detection in dynamic sequences under varying illumination conditions, such as they appear for instance in psychological flickering experiments. For the numerical implementation we are solving an integro-differential equation by a fixed point iteration. For comparison purposes we use a standard time dependent optical flow algorithm, which in contrast to our method, constitutes in solving a spatial-temporal differential equation.



### Brain Tumor Segmentation with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1505.03540v3
- **DOI**: 10.1016/j.media.2016.05.004
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1505.03540v3)
- **Published**: 2015-05-13 20:06:21+00:00
- **Updated**: 2016-05-20 06:30:23+00:00
- **Authors**: Mohammad Havaei, Axel Davy, David Warde-Farley, Antoine Biard, Aaron Courville, Yoshua Bengio, Chris Pal, Pierre-Marc Jodoin, Hugo Larochelle
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data.   We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test dataset reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster.



### COROLA: A Sequential Solution to Moving Object Detection Using Low-rank Approximation
- **Arxiv ID**: http://arxiv.org/abs/1505.03566v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1505.03566v2)
- **Published**: 2015-05-13 22:13:20+00:00
- **Updated**: 2016-01-28 21:10:35+00:00
- **Authors**: Moein Shakeri, Hong Zhang
- **Comment**: 37 pages, 10 figures
- **Journal**: None
- **Summary**: Extracting moving objects from a video sequence and estimating the background of each individual image are fundamental issues in many practical applications such as visual surveillance, intelligent vehicle navigation, and traffic monitoring. Recently, some methods have been proposed to detect moving objects in a video via low-rank approximation and sparse outliers where the background is modeled with the computed low-rank component of the video and the foreground objects are detected as the sparse outliers in the low-rank approximation. All of these existing methods work in a batch manner, preventing them from being applied in real time and long duration tasks. In this paper, we present an online sequential framework, namely contiguous outliers representation via online low-rank approximation (COROLA), to detect moving objects and learn the background model at the same time. We also show that our model can detect moving objects with a moving camera. Our experimental evaluation uses simulated data and real public datasets and demonstrates the superior performance of COROLA in terms of both accuracy and execution time.



