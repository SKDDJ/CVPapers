# Arxiv Papers in cs.CV on 2015-05-01
### Pose Induction for Novel Object Categories
- **Arxiv ID**: http://arxiv.org/abs/1505.00066v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00066v2)
- **Published**: 2015-05-01 01:45:52+00:00
- **Updated**: 2015-09-28 18:17:20+00:00
- **Authors**: Shubham Tulsiani, João Carreira, Jitendra Malik
- **Comment**: None
- **Journal**: None
- **Summary**: We address the task of predicting pose for objects of unannotated object categories from a small seed set of annotated object classes. We present a generalized classifier that can reliably induce pose given a single instance of a novel category. In case of availability of a large collection of novel instances, our approach then jointly reasons over all instances to improve the initial estimates. We empirically validate the various components of our algorithm and quantitatively show that our method produces reliable pose estimates. We also show qualitative results on a diverse set of classes and further demonstrate the applicability of our system for learning shape models of novel object classes.



### Image Denoising using Optimally Weighted Bilateral Filters: A Sure and Fast Approach
- **Arxiv ID**: http://arxiv.org/abs/1505.00074v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00074v2)
- **Published**: 2015-05-01 02:49:55+00:00
- **Updated**: 2015-05-25 09:42:04+00:00
- **Authors**: Kunal N. Chaudhury, Kollipara Rithwik
- **Comment**: To appear in the IEEE International Conference on Image Processing
  (ICIP 2015). Link to the Matlab code added in the revision
- **Journal**: None
- **Summary**: The bilateral filter is known to be quite effective in denoising images corrupted with small dosages of additive Gaussian noise. The denoising performance of the filter, however, is known to degrade quickly with the increase in noise level. Several adaptations of the filter have been proposed in the literature to address this shortcoming, but often at a substantial computational overhead. In this paper, we report a simple pre-processing step that can substantially improve the denoising performance of the bilateral filter, at almost no additional cost. The modified filter is designed to be robust at large noise levels, and often tends to perform poorly below a certain noise threshold. To get the best of the original and the modified filter, we propose to combine them in a weighted fashion, where the weights are chosen to minimize (a surrogate of) the oracle mean-squared-error (MSE). The optimally-weighted filter is thus guaranteed to perform better than either of the component filters in terms of the MSE, at all noise levels. We also provide a fast algorithm for the weighted filtering. Visual and quantitative denoising results on standard test images are reported which demonstrate that the improvement over the original filter is significant both visually and in terms of PSNR. Moreover, the denoising performance of the optimally-weighted bilateral filter is competitive with the computation-intensive non-local means filter.



### Fast and Accurate Bilateral Filtering using Gauss-Polynomial Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1505.00077v2
- **DOI**: 10.1109/ICIP.2015.7351152
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00077v2)
- **Published**: 2015-05-01 03:01:09+00:00
- **Updated**: 2015-05-25 09:50:02+00:00
- **Authors**: Kunal N. Chaudhury
- **Comment**: To appear in the IEEE International Conference on Image Processing
  (ICIP 2015)
- **Journal**: None
- **Summary**: The bilateral filter is a versatile non-linear filter that has found diverse applications in image processing, computer vision, computer graphics, and computational photography. A widely-used form of the filter is the Gaussian bilateral filter in which both the spatial and range kernels are Gaussian. A direct implementation of this filter requires $O(\sigma^2)$ operations per pixel, where $\sigma$ is the standard deviation of the spatial Gaussian. In this paper, we propose an accurate approximation algorithm that can cut down the computational complexity to $O(1)$ per pixel for any arbitrary $\sigma$ (constant-time implementation). This is based on the observation that the range kernel operates via the translations of a fixed Gaussian over the range space, and that these translated Gaussians can be accurately approximated using the so-called Gauss-polynomials. The overall algorithm emerging from this approximation involves a series of spatial Gaussian filtering, which can be implemented in constant-time using separability and recursion. We present some preliminary results to demonstrate that the proposed algorithm compares favorably with some of the existing fast algorithms in terms of speed and accuracy.



### The Cross-Depiction Problem: Computer Vision Algorithms for Recognising Objects in Artwork and in Photographs
- **Arxiv ID**: http://arxiv.org/abs/1505.00110v1
- **DOI**: None
- **Categories**: **cs.CV**, 68745, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1505.00110v1)
- **Published**: 2015-05-01 07:38:52+00:00
- **Updated**: 2015-05-01 07:38:52+00:00
- **Authors**: Hongping Cai, Qi Wu, Tadeo Corradi, Peter Hall
- **Comment**: 12 pages, 6 figures
- **Journal**: None
- **Summary**: The cross-depiction problem is that of recognising visual objects regardless of whether they are photographed, painted, drawn, etc. It is a potentially significant yet under-researched problem. Emulating the remarkable human ability to recognise objects in an astonishingly wide variety of depictive forms is likely to advance both the foundations and the applications of Computer Vision.   In this paper we benchmark classification, domain adaptation, and deep learning methods; demonstrating that none perform consistently well in the cross-depiction problem. Given the current interest in deep learning, the fact such methods exhibit the same behaviour as all but one other method: they show a significant fall in performance over inhomogeneous databases compared to their peak performance, which is always over data comprising photographs only. Rather, we find the methods that have strong models of spatial relations between parts tend to be more robust and therefore conclude that such information is important in modelling object classes regardless of appearance details.



### Quality Control in Crowdsourced Object Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1505.00145v1
- **DOI**: 10.1109/ICIP.2015.7351606
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1505.00145v1)
- **Published**: 2015-05-01 10:33:49+00:00
- **Updated**: 2015-05-01 10:33:49+00:00
- **Authors**: Ferran Cabezas, Axel Carlier, Amaia Salvador, Xavier Giró-i-Nieto, Vincent Charvillat
- **Comment**: Paper accepted at the IEEE International Conference on Image
  Processing (ICIP) 2015. Quebec City, 27-30 September 2015
- **Journal**: None
- **Summary**: This paper explores processing techniques to deal with noisy data in crowdsourced object segmentation tasks. We use the data collected with "Click'n'Cut", an online interactive segmentation tool, and we perform several experiments towards improving the segmentation results. First, we introduce different superpixel-based techniques to filter users' traces, and assess their impact on the segmentation result. Second, we present different criteria to detect and discard the traces from potential bad users, resulting in a remarkable increase in performance. Finally, we show a novel superpixel-based segmentation algorithm which does not require any prior filtering and is based on weighting each user's contribution according to his/her level of expertise.



### SynthCam3D: Semantic Understanding With Synthetic Indoor Scenes
- **Arxiv ID**: http://arxiv.org/abs/1505.00171v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00171v1)
- **Published**: 2015-05-01 12:55:32+00:00
- **Updated**: 2015-05-01 12:55:32+00:00
- **Authors**: Ankur Handa, Viorica Patraucean, Vijay Badrinarayanan, Simon Stent, Roberto Cipolla
- **Comment**: None
- **Journal**: None
- **Summary**: We are interested in automatic scene understanding from geometric cues. To this end, we aim to bring semantic segmentation in the loop of real-time reconstruction. Our semantic segmentation is built on a deep autoencoder stack trained exclusively on synthetic depth data generated from our novel 3D scene library, SynthCam3D. Importantly, our network is able to segment real world scenes without any noise modelling. We present encouraging preliminary results.



### Segmentation and Restoration of Images on Surfaces by Parametric Active Contours with Topology Changes
- **Arxiv ID**: http://arxiv.org/abs/1505.00193v1
- **DOI**: None
- **Categories**: **cs.CV**, math.AP, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1505.00193v1)
- **Published**: 2015-05-01 14:41:23+00:00
- **Updated**: 2015-05-01 14:41:23+00:00
- **Authors**: Heike Benninghoff, Harald Garcke
- **Comment**: None
- **Journal**: None
- **Summary**: In this article, a new method for segmentation and restoration of images on two-dimensional surfaces is given. Active contour models for image segmentation are extended to images on surfaces. The evolving curves on the surfaces are mathematically described using a parametric approach. For image restoration, a diffusion equation with Neumann boundary conditions is solved in a postprocessing step in the individual regions. Numerical schemes are presented which allow to efficiently compute segmentations and denoised versions of images on surfaces. Also topology changes of the evolving curves are detected and performed using a fast sub-routine. Finally, several experiments are presented where the developed methods are applied on different artificial and real images defined on different surfaces.



### Volumetric Bias in Segmentation and Reconstruction: Secrets and Solutions
- **Arxiv ID**: http://arxiv.org/abs/1505.00218v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00218v1)
- **Published**: 2015-05-01 17:01:37+00:00
- **Updated**: 2015-05-01 17:01:37+00:00
- **Authors**: Yuri Boykov, Hossam Isack, Carl Olsson, Ismail Ben Ayed
- **Comment**: 9 pages, 9 figures, 1 table
- **Journal**: None
- **Summary**: Many standard optimization methods for segmentation and reconstruction compute ML model estimates for appearance or geometry of segments, e.g. Zhu-Yuille 1996, Torr 1998, Chan-Vese 2001, GrabCut 2004, Delong et al. 2012. We observe that the standard likelihood term in these formulations corresponds to a generalized probabilistic K-means energy. In learning it is well known that this energy has a strong bias to clusters of equal size, which can be expressed as a penalty for KL divergence from a uniform distribution of cardinalities. However, this volumetric bias has been mostly ignored in computer vision. We demonstrate significant artifacts in standard segmentation and reconstruction methods due to this bias. Moreover, we propose binary and multi-label optimization techniques that either (a) remove this bias or (b) replace it by a KL divergence term for any given target volume distribution. Our general ideas apply to many continuous or discrete energy formulations in segmentation, stereo, and other reconstruction problems.



### Image Segmentation by Size-Dependent Single Linkage Clustering of a Watershed Basin Graph
- **Arxiv ID**: http://arxiv.org/abs/1505.00249v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00249v1)
- **Published**: 2015-05-01 19:14:39+00:00
- **Updated**: 2015-05-01 19:14:39+00:00
- **Authors**: Aleksandar Zlateski, H. Sebastian Seung
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: We present a method for hierarchical image segmentation that defines a disaffinity graph on the image, over-segments it into watershed basins, defines a new graph on the basins, and then merges basins with a modified, size-dependent version of single linkage clustering. The quasilinear runtime of the method makes it suitable for segmenting large images. We illustrate the method on the challenging problem of segmenting 3D electron microscopic brain images.



### DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/1505.00256v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00256v3)
- **Published**: 2015-05-01 19:31:13+00:00
- **Updated**: 2015-09-26 05:17:59+00:00
- **Authors**: Chenyi Chen, Ari Seff, Alain Kornhauser, Jianxiong Xiao
- **Comment**: None
- **Journal**: None
- **Summary**: Today, there are two major paradigms for vision-based autonomous driving systems: mediated perception approaches that parse an entire scene to make a driving decision, and behavior reflex approaches that directly map an input image to a driving action by a regressor. In this paper, we propose a third paradigm: a direct perception approach to estimate the affordance for driving. We propose to map an input image to a small number of key perception indicators that directly relate to the affordance of a road/traffic state for driving. Our representation provides a set of compact yet complete descriptions of the scene to enable a simple controller to drive autonomously. Falling in between the two extremes of mediated perception and behavior reflex, we argue that our direct perception representation provides the right level of abstraction. To demonstrate this, we train a deep Convolutional Neural Network using recording from 12 hours of human driving in a video game and show that our model can work well to drive a car in a very diverse set of virtual environments. We also train a model for car distance estimation on the KITTI dataset. Results show that our direct perception approach can generalize well to real driving images. Source code and data are available on our project website.



### Joint Object and Part Segmentation using Deep Learned Potentials
- **Arxiv ID**: http://arxiv.org/abs/1505.00276v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.00276v1)
- **Published**: 2015-05-01 20:35:24+00:00
- **Updated**: 2015-05-01 20:35:24+00:00
- **Authors**: Peng Wang, Xiaohui Shen, Zhe Lin, Scott Cohen, Brian Price, Alan Yuille
- **Comment**: None
- **Journal**: None
- **Summary**: Segmenting semantic objects from images and parsing them into their respective semantic parts are fundamental steps towards detailed object understanding in computer vision. In this paper, we propose a joint solution that tackles semantic object and part segmentation simultaneously, in which higher object-level context is provided to guide part segmentation, and more detailed part-level localization is utilized to refine object segmentation. Specifically, we first introduce the concept of semantic compositional parts (SCP) in which similar semantic parts are grouped and shared among different objects. A two-channel fully convolutional network (FCN) is then trained to provide the SCP and object potentials at each pixel. At the same time, a compact set of segments can also be obtained from the SCP predictions of the network. Given the potentials and the generated segments, in order to explore long-range context, we finally construct an efficient fully connected conditional random field (FCRF) to jointly predict the final object and part labels. Extensive evaluation on three different datasets shows that our approach can mutually enhance the performance of object and part segmentation, and outperforms the current state-of-the-art on both tasks.



