# Arxiv Papers in cs.CV on 2015-05-08
### Noise in Structured-Light Stereo Depth Cameras: Modeling and its Applications
- **Arxiv ID**: http://arxiv.org/abs/1505.01936v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.01936v1)
- **Published**: 2015-05-08 06:15:42+00:00
- **Updated**: 2015-05-08 06:15:42+00:00
- **Authors**: Avishek Chatterjee, Venu Madhav Govindu
- **Comment**: None
- **Journal**: None
- **Summary**: Depth maps obtained from commercially available structured-light stereo based depth cameras, such as the Kinect, are easy to use but are affected by significant amounts of noise. This paper is devoted to a study of the intrinsic noise characteristics of such depth maps, i.e. the standard deviation of noise in estimated depth varies quadratically with the distance of the object from the depth camera. We validate this theoretical model against empirical observations and demonstrate the utility of this noise model in three popular applications: depth map denoising, volumetric scan merging for 3D modeling, and identification of 3D planes in depth maps.



### The structure of optimal parameters for image restoration problems
- **Arxiv ID**: http://arxiv.org/abs/1505.01953v1
- **DOI**: 10.1016/j.jmaa.2015.09.023
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.01953v1)
- **Published**: 2015-05-08 08:26:24+00:00
- **Updated**: 2015-05-08 08:26:24+00:00
- **Authors**: Juan Carlos De Los Reyes, Carola-Bibiane Schönlieb, Tuomo Valkonen
- **Comment**: None
- **Journal**: None
- **Summary**: We study the qualitative properties of optimal regularisation parameters in variational models for image restoration. The parameters are solutions of bilevel optimisation problems with the image restoration problem as constraint. A general type of regulariser is considered, which encompasses total variation (TV), total generalized variation (TGV) and infimal-convolution total variation (ICTV). We prove that under certain conditions on the given data optimal parameters derived by bilevel optimisation problems exist. A crucial point in the existence proof turns out to be the boundedness of the optimal parameters away from $0$ which we prove in this paper. The analysis is done on the original -- in image restoration typically non-smooth variational problem -- as well as on a smoothed approximation set in Hilbert space which is the one considered in numerical computations. For the smoothed bilevel problem we also prove that it $\Gamma$ converges to the original problem as the smoothing vanishes. All analysis is done in function spaces rather than on the discretised learning problem.



### Deep Learning for Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1505.02000v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.02000v1)
- **Published**: 2015-05-08 11:35:53+00:00
- **Updated**: 2015-05-08 11:35:53+00:00
- **Authors**: Matthew Lai
- **Comment**: None
- **Journal**: None
- **Summary**: This report provides an overview of the current state of the art deep learning architectures and optimisation techniques, and uses the ADNI hippocampus MRI dataset as an example to compare the effectiveness and efficiency of different convolutional architectures on the task of patch-based 3-dimensional hippocampal segmentation, which is important in the diagnosis of Alzheimer's Disease. We found that a slightly unconventional "stacked 2D" approach provides much better classification performance than simple 2D patches without requiring significantly more computational power. We also examined the popular "tri-planar" approach used in some recently published studies, and found that it provides much better results than the 2D approaches, but also with a moderate increase in computational power requirement. Finally, we evaluated a full 3D convolutional architecture, and found that it provides marginally better results than the tri-planar approach, but at the cost of a very significant increase in computational power requirement.



### Exploring Models and Data for Image Question Answering
- **Arxiv ID**: http://arxiv.org/abs/1505.02074v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CL, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.02074v4)
- **Published**: 2015-05-08 15:59:44+00:00
- **Updated**: 2015-11-29 22:45:12+00:00
- **Authors**: Mengye Ren, Ryan Kiros, Richard Zemel
- **Comment**: 12 pages. Conference paper at NIPS 2015
- **Journal**: None
- **Summary**: This work aims to address the problem of image-based question-answering (QA) with new models and datasets. In our work, we propose to use neural networks and visual semantic embeddings, without intermediate stages such as object detection and image segmentation, to predict answers to simple questions about images. Our model performs 1.8 times better than the only published results on an existing image QA dataset. We also present a question generation algorithm that converts image descriptions, which are widely available, into QA form. We used this algorithm to produce an order-of-magnitude larger dataset, with more evenly distributed answers. A suite of baseline results on this new dataset are also presented.



### MegaFace: A Million Faces for Recognition at Scale
- **Arxiv ID**: http://arxiv.org/abs/1505.02108v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.02108v2)
- **Published**: 2015-05-08 17:39:23+00:00
- **Updated**: 2015-09-07 19:45:47+00:00
- **Authors**: D. Miller, E. Brossard, S. Seitz, I. Kemelmacher-Shlizerman
- **Comment**: Please see http://megaface.cs.washington.edu/ for code and data
- **Journal**: None
- **Summary**: Recent face recognition experiments on the LFW benchmark show that face recognition is performing stunningly well, surpassing human recognition rates. In this paper, we study face recognition at scale. Specifically, we have collected from Flickr a \textbf{Million} faces and evaluated state of the art face recognition algorithms on this dataset. We found that the performance of algorithms varies--while all perform great on LFW, once evaluated at scale recognition rates drop drastically for most algorithms. Interestingly, deep learning based approach by \cite{schroff2015facenet} performs much better, but still gets less robust at scale. We consider both verification and identification problems, and evaluate how pose affects recognition at scale. Moreover, we ran an extensive human study on Mechanical Turk to evaluate human recognition at scale, and report results. All the photos are creative commons photos and is released at \small{\url{http://megaface.cs.washington.edu/}} for research and further experiments.



### Bilevel approaches for learning of variational imaging models
- **Arxiv ID**: http://arxiv.org/abs/1505.02120v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.02120v1)
- **Published**: 2015-05-08 18:27:34+00:00
- **Updated**: 2015-05-08 18:27:34+00:00
- **Authors**: Luca Calatroni, Cao Chung, Juan Carlos De Los Reyes, Carola-Bibiane Schönlieb, Tuomo Valkonen
- **Comment**: None
- **Journal**: None
- **Summary**: We review some recent learning approaches in variational imaging, based on bilevel optimisation, and emphasize the importance of their treatment in function space. The paper covers both analytical and numerical techniques. Analytically, we include results on the existence and structure of minimisers, as well as optimality conditions for their characterisation. Based on this information, Newton type methods are studied for the solution of the problems at hand, combining them with sampling techniques in case of large databases. The computational verification of the developed techniques is extensively documented, covering instances with different type of regularisers, several noise models, spatially dependent weights and large image databases.



### DeepBox: Learning Objectness with Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1505.02146v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.02146v2)
- **Published**: 2015-05-08 19:24:17+00:00
- **Updated**: 2015-09-26 21:38:49+00:00
- **Authors**: Weicheng Kuo, Bharath Hariharan, Jitendra Malik
- **Comment**: ICCV 2015 Camera-ready version
- **Journal**: None
- **Summary**: Existing object proposal approaches use primarily bottom-up cues to rank proposals, while we believe that objectness is in fact a high level construct. We argue for a data-driven, semantic approach for ranking object proposals. Our framework, which we call DeepBox, uses convolutional neural networks (CNNs) to rerank proposals from a bottom-up method. We use a novel four-layer CNN architecture that is as good as much larger networks on the task of evaluating objectness while being much faster. We show that DeepBox significantly improves over the bottom-up ranking, achieving the same recall with 500 proposals as achieved by bottom-up methods with 2000. This improvement generalizes to categories the CNN has never seen before and leads to a 4.5-point gain in detection mAP. Our implementation achieves this performance while running at 260 ms per image.



### Learning image representations tied to ego-motion
- **Arxiv ID**: http://arxiv.org/abs/1505.02206v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1505.02206v2)
- **Published**: 2015-05-08 23:15:00+00:00
- **Updated**: 2016-03-29 19:30:18+00:00
- **Authors**: Dinesh Jayaraman, Kristen Grauman
- **Comment**: Supplementary material appended at end. In ICCV 2015
- **Journal**: None
- **Summary**: Understanding how images of objects and scenes behave in response to specific ego-motions is a crucial aspect of proper visual development, yet existing visual learning methods are conspicuously disconnected from the physical source of their images. We propose to exploit proprioceptive motor signals to provide unsupervised regularization in convolutional neural networks to learn visual representations from egocentric video. Specifically, we enforce that our learned features exhibit equivariance i.e. they respond predictably to transformations associated with distinct ego-motions. With three datasets, we show that our unsupervised feature learning approach significantly outperforms previous approaches on visual recognition and next-best-view prediction tasks. In the most challenging test, we show that features learned from video captured on an autonomous driving platform improve large-scale scene recognition in static images from a disjoint domain.



