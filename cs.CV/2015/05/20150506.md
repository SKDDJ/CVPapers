# Arxiv Papers in cs.CV on 2015-05-06
### A Deeper Look at Dataset Bias
- **Arxiv ID**: http://arxiv.org/abs/1505.01257v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.01257v1)
- **Published**: 2015-05-06 06:19:23+00:00
- **Updated**: 2015-05-06 06:19:23+00:00
- **Authors**: Tatiana Tommasi, Novi Patricia, Barbara Caputo, Tinne Tuytelaars
- **Comment**: None
- **Journal**: None
- **Summary**: The presence of a bias in each image data collection has recently attracted a lot of attention in the computer vision community showing the limits in generalization of any learning method trained on a specific dataset. At the same time, with the rapid development of deep learning architectures, the activation values of Convolutional Neural Networks (CNN) are emerging as reliable and robust image descriptors. In this paper we propose to verify the potential of the DeCAF features when facing the dataset bias problem. We conduct a series of analyses looking at how existing datasets differ among each other and verifying the performance of existing debiasing methods under different representations. We learn important lessons on which part of the dataset bias problem can be considered solved and which open questions still need to be tackled.



### Comparing persistence diagrams through complex vectors
- **Arxiv ID**: http://arxiv.org/abs/1505.01335v2
- **DOI**: None
- **Categories**: **math.AT**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1505.01335v2)
- **Published**: 2015-05-06 12:13:26+00:00
- **Updated**: 2015-07-07 23:02:36+00:00
- **Authors**: Barbara Di Fabio, Massimo Ferri
- **Comment**: 11 pages, 4 figures, 2 tables
- **Journal**: None
- **Summary**: The natural pseudo-distance of spaces endowed with filtering functions is precious for shape classification and retrieval; its optimal estimate coming from persistence diagrams is the bottleneck distance, which unfortunately suffers from combinatorial explosion. A possible algebraic representation of persistence diagrams is offered by complex polynomials; since far polynomials represent far persistence diagrams, a fast comparison of the coefficient vectors can reduce the size of the database to be classified by the bottleneck distance. This article explores experimentally three transformations from diagrams to polynomials and three distances between the complex vectors of coefficients.



### Classification of Occluded Objects using Fast Recurrent Processing
- **Arxiv ID**: http://arxiv.org/abs/1505.01350v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.01350v1)
- **Published**: 2015-05-06 12:58:58+00:00
- **Updated**: 2015-05-06 12:58:58+00:00
- **Authors**: Ozgur Yilmaz
- **Comment**: arXiv admin note: text overlap with arXiv:1409.8576 by other authors
- **Journal**: None
- **Summary**: Recurrent neural networks are powerful tools for handling incomplete data problems in computer vision, thanks to their significant generative capabilities. However, the computational demand for these algorithms is too high to work in real time, without specialized hardware or software solutions. In this paper, we propose a framework for augmenting recurrent processing capabilities into a feedforward network without sacrificing much from computational efficiency. We assume a mixture model and generate samples of the last hidden layer according to the class decisions of the output layer, modify the hidden layer activity using the samples, and propagate to lower layers. For visual occlusion problem, the iterative procedure emulates feedforward-feedback loop, filling-in the missing hidden layer activity with meaningful representations. The proposed algorithm is tested on a widely used dataset, and shown to achieve 2$\times$ improvement in classification accuracy for occluded objects. When compared to Restricted Boltzmann Machines, our algorithm shows superior performance for occluded object classification.



### Geometry-Aware Neighborhood Search for Learning Local Models for Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1505.01429v3
- **DOI**: 10.1109/TIP.2016.2522303
- **Categories**: **cs.CV**, cs.IT, math.IT, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1505.01429v3)
- **Published**: 2015-05-06 16:46:55+00:00
- **Updated**: 2016-01-05 13:37:40+00:00
- **Authors**: Julio Cesar Ferreira, Elif Vural, Christine Guillemot
- **Comment**: 15 pages, 10 figures and 5 tables
- **Journal**: None
- **Summary**: Local learning of sparse image models has proven to be very effective to solve inverse problems in many computer vision applications. To learn such models, the data samples are often clustered using the K-means algorithm with the Euclidean distance as a dissimilarity metric. However, the Euclidean distance may not always be a good dissimilarity measure for comparing data samples lying on a manifold. In this paper, we propose two algorithms for determining a local subset of training samples from which a good local model can be computed for reconstructing a given input test sample, where we take into account the underlying geometry of the data. The first algorithm, called Adaptive Geometry-driven Nearest Neighbor search (AGNN), is an adaptive scheme which can be seen as an out-of-sample extension of the replicator graph clustering method for local model learning. The second method, called Geometry-driven Overlapping Clusters (GOC), is a less complex nonadaptive alternative for training subset selection. The proposed AGNN and GOC methods are evaluated in image super-resolution, deblurring and denoising applications and shown to outperform spectral clustering, soft clustering, and geodesic distance based subset selection in most settings.



