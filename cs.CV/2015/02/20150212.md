# Arxiv Papers in cs.CV on 2015-02-12
### An equalised global graphical model-based approach for multi-camera object tracking
- **Arxiv ID**: http://arxiv.org/abs/1502.03532v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03532v2)
- **Published**: 2015-02-12 04:10:56+00:00
- **Updated**: 2016-07-19 01:45:53+00:00
- **Authors**: Weihua Chen, Lijun Cao, Xiaotang Chen, Kaiqi Huang
- **Comment**: 13 pages, 17 figures
- **Journal**: None
- **Summary**: Non-overlapping multi-camera visual object tracking typically consists of two steps: single camera object tracking and inter-camera object tracking. Most of tracking methods focus on single camera object tracking, which happens in the same scene, while for real surveillance scenes, inter-camera object tracking is needed and single camera tracking methods can not work effectively. In this paper, we try to improve the overall multi-camera object tracking performance by a global graph model with an improved similarity metric. Our method treats the similarities of single camera tracking and inter-camera tracking differently and obtains the optimization in a global graph model. The results show that our method can work better even in the condition of poor single camera object tracking.



### Convergence of gradient based pre-training in Denoising autoencoders
- **Arxiv ID**: http://arxiv.org/abs/1502.03537v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1502.03537v1)
- **Published**: 2015-02-12 04:31:36+00:00
- **Updated**: 2015-02-12 04:31:36+00:00
- **Authors**: Vamsi K Ithapu, Sathya Ravi, Vikas Singh
- **Comment**: 20 pages
- **Journal**: None
- **Summary**: The success of deep architectures is at least in part attributed to the layer-by-layer unsupervised pre-training that initializes the network. Various papers have reported extensive empirical analysis focusing on the design and implementation of good pre-training procedures. However, an understanding pertaining to the consistency of parameter estimates, the convergence of learning procedures and the sample size estimates is still unavailable in the literature. In this work, we study pre-training in classical and distributed denoising autoencoders with these goals in mind. We show that the gradient converges at the rate of $\frac{1}{\sqrt{N}}$ and has a sub-linear dependence on the size of the autoencoder network. In a distributed setting where disjoint sections of the whole network are pre-trained synchronously, we show that the convergence improves by at least $\tau^{3/4}$, where $\tau$ corresponds to the size of the sections. We provide a broad set of experiments to empirically evaluate the suggested behavior.



### Towards zero-configuration condition monitoring based on dictionary learning
- **Arxiv ID**: http://arxiv.org/abs/1502.03596v1
- **DOI**: 10.1109/EUSIPCO.2015.7362595
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03596v1)
- **Published**: 2015-02-12 10:49:12+00:00
- **Updated**: 2015-02-12 10:49:12+00:00
- **Authors**: Sergio Martin-del-Campo, Fredrik Sandin
- **Comment**: 5 pages, 3 figures
- **Journal**: 2015 23rd European Signal Processing Conference (EUSIPCO)
- **Summary**: Condition-based predictive maintenance can significantly improve overall equipment effectiveness provided that appropriate monitoring methods are used. Online condition monitoring systems are customized to each type of machine and need to be reconfigured when conditions change, which is costly and requires expert knowledge. Basic feature extraction methods limited to signal distribution functions and spectra are commonly used, making it difficult to automatically analyze and compare machine conditions. In this paper, we investigate the possibility to automate the condition monitoring process by continuously learning a dictionary of optimized shift-invariant feature vectors using a well-known sparse approximation method. We study how the feature vectors learned from a vibration signal evolve over time when a fault develops within a ball bearing of a rotating machine. We quantify the adaptation rate of learned features and find that this quantity changes significantly in the transitions between normal and faulty states of operation of the ball bearing.



### Simulation of Color Blindness and a Proposal for Using Google Glass as Color-correcting Tool
- **Arxiv ID**: http://arxiv.org/abs/1502.03723v1
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1502.03723v1)
- **Published**: 2015-02-12 16:36:55+00:00
- **Updated**: 2015-02-12 16:36:55+00:00
- **Authors**: H. M. de Oliveira, J. Ranhel, R. B. A. Alves
- **Comment**: 4 pages, 6 figures, XXIV Congresso Brasileiro de Engenharia
  Biomedica, Uberlandia, MG, Brazil, 2014
- **Journal**: None
- **Summary**: The human visual color response is driven by specialized cells called cones, which exist in three types, viz. R, G, and B. Software is developed to simulate how color images are displayed for different types of color blindness. Specified the default color deficiency associated with a user, it generates a preview of the rainbow (in the visible range, from red to violet) and shows up, side by side with a colorful image provided as input, the display correspondent colorblind. The idea is to provide an image processing after image acquisition to enable a better perception ofcolors by the color blind. Examples of pseudo-correction are shown for the case of Protanopia (red blindness). The system is adapted into a screen of an i-pad or a cellphone in which the colorblind observe the camera, the image processed with color detail previously imperceptible by his naked eye. As prospecting, wearable computer glasses could be manufactured to provide a corrected image playback. The approach can also provide augmented reality for human vision by adding the UV or IR responses as a new feature of Google Glass.



### Discovering Human Interactions in Videos with Limited Data Labeling
- **Arxiv ID**: http://arxiv.org/abs/1502.03851v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03851v1)
- **Published**: 2015-02-12 22:38:28+00:00
- **Updated**: 2015-02-12 22:38:28+00:00
- **Authors**: Mehran Khodabandeh, Arash Vahdat, Guang-Tong Zhou, Hossein Hajimirsadeghi, Mehrsan Javan Roshtkhari, Greg Mori, Stephen Se
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel approach for discovering human interactions in videos. Activity understanding techniques usually require a large number of labeled examples, which are not available in many practical cases. Here, we focus on recovering semantically meaningful clusters of human-human and human-object interaction in an unsupervised fashion. A new iterative solution is introduced based on Maximum Margin Clustering (MMC), which also accepts user feedback to refine clusters. This is achieved by formulating the whole process as a unified constrained latent max-margin clustering problem. Extensive experiments have been carried out over three challenging datasets, Collective Activity, VIRAT, and UT-interaction. Empirical results demonstrate that the proposed algorithm can efficiently discover perfect semantic clusters of human interactions with only a small amount of labeling effort.



