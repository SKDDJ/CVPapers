# Arxiv Papers in cs.CV on 2015-02-13
### Semi-supervised Data Representation via Affinity Graph Learning
- **Arxiv ID**: http://arxiv.org/abs/1502.03879v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, 68T10, I.4.2; I.4.7
- **Links**: [PDF](http://arxiv.org/pdf/1502.03879v1)
- **Published**: 2015-02-13 03:35:15+00:00
- **Updated**: 2015-02-13 03:35:15+00:00
- **Authors**: Weiya Ren
- **Comment**: 10 pages,2 Tables. Written in Aug,2013
- **Journal**: None
- **Summary**: We consider the general problem of utilizing both labeled and unlabeled data to improve data representation performance. A new semi-supervised learning framework is proposed by combing manifold regularization and data representation methods such as Non negative matrix factorization and sparse coding. We adopt unsupervised data representation methods as the learning machines because they do not depend on the labeled data, which can improve machine's generation ability as much as possible. The proposed framework forms the Laplacian regularizer through learning the affinity graph. We incorporate the new Laplacian regularizer into the unsupervised data representation to smooth the low dimensional representation of data and make use of label information. Experimental results on several real benchmark datasets indicate that our semi-supervised learning framework achieves encouraging results compared with state-of-art methods.



### Skeleton Matching based approach for Text Localization in Scene Images
- **Arxiv ID**: http://arxiv.org/abs/1502.03913v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03913v1)
- **Published**: 2015-02-13 08:42:00+00:00
- **Updated**: 2015-02-13 08:42:00+00:00
- **Authors**: B. H. Shekar, Smitha M. L
- **Comment**: 10 pages, 8 figures, Eighth International Conference on Image and
  Signal Processing,Elsevier Publications,pp: 145-153, held at UVCE, Bangalore
  in July 2014. ISBN: 9789351072522
- **Journal**: None
- **Summary**: In this paper, we propose a skeleton matching based approach which aids in text localization in scene images. The input image is preprocessed and segmented into blocks using connected component analysis. We obtain the skeleton of the segmented block using morphology based approach. The skeletonized images are compared with the trained templates in the database to categorize into text and non-text blocks. Further, the newly designed geometrical rules and morphological operations are employed on the detected text blocks for scene text localization. The experimental results obtained on publicly available standard datasets illustrate that the proposed method can detect and localize the texts of various sizes, fonts and colors.



### Gradient Difference based approach for Text Localization in Compressed domain
- **Arxiv ID**: http://arxiv.org/abs/1502.03918v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03918v1)
- **Published**: 2015-02-13 09:08:35+00:00
- **Updated**: 2015-02-13 09:08:35+00:00
- **Authors**: B. H. Shekar, Smitha M. L
- **Comment**: 11 pages, Second International Conference on Emerging Research in
  Computing, Information, Communications and Applications, Elsevier
  Publications, ISBN: 9789351072638, vol. III, pp: 299-308, held at NMIT,
  Bangalore August 2014
- **Journal**: None
- **Summary**: In this paper, we propose a gradient difference based approach to text localization in videos and scene images. The input video frame/ image is first compressed using multilevel 2-D wavelet transform. The edge information of the reconstructed image is found which is further used for finding the maximum gradient difference between the pixels and then the boundaries of the detected text blocks are computed using zero crossing technique. We perform logical AND operation of the text blocks obtained by gradient difference and the zero crossing technique followed by connected component analysis to eliminate the false positives. Finally, the morphological dilation operation is employed on the detected text blocks for scene text localization. The experimental results obtained on publicly available standard datasets illustrate that the proposed method can detect and localize the texts of various sizes, fonts and colors.



### Modeling Brain Circuitry over a Wide Range of Scales
- **Arxiv ID**: http://arxiv.org/abs/1502.04110v2
- **DOI**: 10.3389/fnana.2015.00042
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.04110v2)
- **Published**: 2015-02-13 20:41:07+00:00
- **Updated**: 2015-04-08 07:23:47+00:00
- **Authors**: Pascal Fua, Graham Knott
- **Comment**: None
- **Journal**: None
- **Summary**: If we are ever to unravel the mysteries of brain function at its most fundamental level, we will need a precise understanding of how its component neurons connect to each other. Electron Microscopes (EM) can now provide the nanometer resolution that is needed to image synapses, and therefore connections, while Light Microscopes (LM) see at the micrometer resolution required to model the 3D structure of the dendritic network. Since both the topology and the connection strength are integral parts of the brain's wiring diagram, being able to combine these two modalities is critically important.   In fact, these microscopes now routinely produce high-resolution imagery in such large quantities that the bottleneck becomes automated processing and interpretation, which is needed for such data to be exploited to its full potential. In this paper, we briefly review the Computer Vision techniques we have developed at EPFL to address this need. They include delineating dendritic arbors from LM imagery, segmenting organelles from EM, and combining the two into a consistent representation.



### Long-short Term Motion Feature for Action Classification and Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1502.04132v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.04132v1)
- **Published**: 2015-02-13 21:15:57+00:00
- **Updated**: 2015-02-13 21:15:57+00:00
- **Authors**: Zhenzhong Lan, Xuanchong Li, Ming Lin, Alexander G. Hauptmann
- **Comment**: arXiv admin note: text overlap with arXiv:1411.6660
- **Journal**: None
- **Summary**: We propose a method for representing motion information for video classification and retrieval. We improve upon local descriptor based methods that have been among the most popular and successful models for representing videos. The desired local descriptors need to satisfy two requirements: 1) to be representative, 2) to be discriminative. Therefore, they need to occur frequently enough in the videos and to be be able to tell the difference among different types of motions. To generate such local descriptors, the video blocks they are based on must contain just the right amount of motion information. However, current state-of-the-art local descriptor methods use video blocks with a single fixed size, which is insufficient for covering actions with varying speeds. In this paper, we introduce a long-short term motion feature that generates descriptors from video blocks with multiple lengths, thus covering motions with large speed variance. Experimental results show that, albeit simple, our model achieves state-of-the-arts results on several benchmark datasets.



