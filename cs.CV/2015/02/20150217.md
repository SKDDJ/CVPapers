# Arxiv Papers in cs.CV on 2015-02-17
### 3D Pose from Detections
- **Arxiv ID**: http://arxiv.org/abs/1502.04754v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.04754v3)
- **Published**: 2015-02-17 00:11:41+00:00
- **Updated**: 2015-07-20 18:27:38+00:00
- **Authors**: Cosimo Rubino, Marco Crocco, Alessandro Perina, Vittorio Murino, Alessio Del Bue
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel method to infer, in closed-form, a general 3D spatial occupancy and orientation of a collection of rigid objects given 2D image detections from a sequence of images. In particular, starting from 2D ellipses fitted to bounding boxes, this novel multi-view problem can be reformulated as the estimation of a quadric (ellipsoid) in 3D. We show that an efficient solution exists in the dual-space using a minimum of three views while a solution with two views is possible through the use of regularization. However, this algebraic solution can be negatively affected in the presence of gross inaccuracies in the bounding boxes estimation. To this end, we also propose a robust ellipse fitting algorithm able to improve performance in the presence of errors in the detected objects. Results on synthetic tests and on different real datasets, involving real challenging scenarios, demonstrate the applicability and potential of our method.



### Randomized LU decomposition: An Algorithm for Dictionaries Construction
- **Arxiv ID**: http://arxiv.org/abs/1502.04824v2
- **DOI**: None
- **Categories**: **cs.CV**, I.5
- **Links**: [PDF](http://arxiv.org/pdf/1502.04824v2)
- **Published**: 2015-02-17 08:18:00+00:00
- **Updated**: 2018-01-27 05:59:28+00:00
- **Authors**: Aviv Rotbart, Gil Shabat, Yaniv Shmueli, Amir Averbuch
- **Comment**: Errors in several parts of the paper. No replacement is currently
  available or being written
- **Journal**: None
- **Summary**: In recent years, distinctive-dictionary construction has gained importance due to his usefulness in data processing. Usually, one or more dictionaries are constructed from a training data and then they are used to classify signals that did not participate in the training process. A new dictionary construction algorithm is introduced. It is based on a low-rank matrix factorization being achieved by the application of the randomized LU decomposition to a training data. This method is fast, scalable, parallelizable, consumes low memory, outperforms SVD in these categories and works also extremely well on large sparse matrices. In contrast to existing methods, the randomized LU decomposition constructs an under-complete dictionary, which simplifies both the construction and the classification processes of newly arrived signals. The dictionary construction is generic and general that fits different applications. We demonstrate the capabilities of this algorithm for file type identification, which is a fundamental task in digital security arena, performed nowadays for example by sandboxing mechanism, deep packet inspection, firewalls and anti-virus systems. We propose a content-based method that detects file types that neither depend on file extension nor on metadata. Such approach is harder to deceive and we show that only a few file fragments from a whole file are needed for a successful classification. Based on the constructed dictionaries, we show that the proposed method can effectively identify execution code fragments in PDF files.   $\textbf{Keywords.}$ Dictionary construction, classification, LU decomposition, randomized LU decomposition, content-based file detection, computer security.



### Nonparametric Nearest Neighbor Descent Clustering based on Delaunay Triangulation
- **Arxiv ID**: http://arxiv.org/abs/1502.04837v2
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1502.04837v2)
- **Published**: 2015-02-17 09:27:03+00:00
- **Updated**: 2015-03-18 12:17:46+00:00
- **Authors**: Teng Qiu, Yongjie Li
- **Comment**: 7 pages; 6 figures
- **Journal**: None
- **Summary**: In our physically inspired in-tree (IT) based clustering algorithm and the series after it, there is only one free parameter involved in computing the potential value of each point. In this work, based on the Delaunay Triangulation or its dual Voronoi tessellation, we propose a nonparametric process to compute potential values by the local information. This computation, though nonparametric, is relatively very rough, and consequently, many local extreme points will be generated. However, unlike those gradient-based methods, our IT-based methods are generally insensitive to those local extremes. This positively demonstrates the superiority of these parametric (previous) and nonparametric (in this work) IT-based methods.



### SA-CNN: Dynamic Scene Classification using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1502.05243v2
- **DOI**: None
- **Categories**: **cs.CV**, I.5.4; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1502.05243v2)
- **Published**: 2015-02-17 12:25:27+00:00
- **Updated**: 2015-08-29 06:01:02+00:00
- **Authors**: Aalok Gangopadhyay, Shivam Mani Tripathi, Ishan Jindal, Shanmuganathan Raman
- **Comment**: None
- **Journal**: None
- **Summary**: The task of classifying videos of natural dynamic scenes into appropriate classes has gained lot of attention in recent years. The problem especially becomes challenging when the camera used to capture the video is dynamic. In this paper, we analyse the performance of statistical aggregation (SA) techniques on various pre-trained convolutional neural network(CNN) models to address this problem. The proposed approach works by extracting CNN activation features for a number of frames in a video and then uses an aggregation scheme in order to obtain a robust feature descriptor for the video. We show through results that the proposed approach performs better than the-state-of-the arts for the Maryland and YUPenn dataset. The final descriptor obtained is powerful enough to distinguish among dynamic scenes and is even capable of addressing the scenario where the camera motion is dominant and the scene dynamics are complex. Further, this paper shows an extensive study on the performance of various aggregation methods and their combinations. We compare the proposed approach with other dynamic scene classification algorithms on two publicly available datasets - Maryland and YUPenn to demonstrate the superior performance of the proposed approach.



### Semi-supervised Segmentation Fusion of Multi-spectral and Aerial Images
- **Arxiv ID**: http://arxiv.org/abs/1502.04981v2
- **DOI**: 10.1109/ICPR.2014.659
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.04981v2)
- **Published**: 2015-02-17 18:01:13+00:00
- **Updated**: 2015-02-26 00:11:44+00:00
- **Authors**: Mete Ozay
- **Comment**: A version of the manuscript was published in ICPR 2014
- **Journal**: Proc. 22nd International Conference on Pattern Recognition, pp.
  3839-3844, Stockholm, 2014
- **Summary**: A Semi-supervised Segmentation Fusion algorithm is proposed using consensus and distributed learning. The aim of Unsupervised Segmentation Fusion (USF) is to achieve a consensus among different segmentation outputs obtained from different segmentation algorithms by computing an approximate solution to the NP problem with less computational complexity. Semi-supervision is incorporated in USF using a new algorithm called Semi-supervised Segmentation Fusion (SSSF). In SSSF, side information about the co-occurrence of pixels in the same or different segments is formulated as the constraints of a convex optimization problem. The results of the experiments employed on artificial and real-world benchmark multi-spectral and aerial images show that the proposed algorithms perform better than the individual state-of-the art segmentation algorithms.



### Context Tricks for Cheap Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1502.04983v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.04983v1)
- **Published**: 2015-02-17 18:08:53+00:00
- **Updated**: 2015-02-17 18:08:53+00:00
- **Authors**: Thanapong Intharah, Gabriel J. Brostow
- **Comment**: Supplementary material can be found at
  http://www0.cs.ucl.ac.uk/staff/T.Intharah/research.html
- **Journal**: None
- **Summary**: Accurate semantic labeling of image pixels is difficult because intra-class variability is often greater than inter-class variability. In turn, fast semantic segmentation is hard because accurate models are usually too complicated to also run quickly at test-time. Our experience with building and running semantic segmentation systems has also shown a reasonably obvious bottleneck on model complexity, imposed by small training datasets. We therefore propose two simple complementary strategies that leverage context to give better semantic segmentation, while scaling up or down to train on different-sized datasets.   As easy modifications for existing semantic segmentation algorithms, we introduce Decorrelated Semantic Texton Forests, and the Context Sensitive Image Level Prior. The proposed modifications are tested using a Semantic Texton Forest (STF) system, and the modifications are validated on two standard benchmark datasets, MSRC-21 and PascalVOC-2010. In Python based comparisons, our system is insignificantly slower than STF at test-time, yet produces superior semantic segmentations overall, with just push-button training.



### What makes for effective detection proposals?
- **Arxiv ID**: http://arxiv.org/abs/1502.05082v3
- **DOI**: 10.1109/TPAMI.2015.2465908
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.05082v3)
- **Published**: 2015-02-17 22:45:14+00:00
- **Updated**: 2015-08-01 16:33:25+00:00
- **Authors**: Jan Hosang, Rodrigo Benenson, Piotr Doll√°r, Bernt Schiele
- **Comment**: TPAMI final version, duplicate proposals removed in experiments
- **Journal**: None
- **Summary**: Current top performing object detectors employ detection proposals to guide the search for objects, thereby avoiding exhaustive sliding window search across images. Despite the popularity and widespread use of detection proposals, it is unclear which trade-offs are made when using them during object detection. We provide an in-depth analysis of twelve proposal methods along with four baselines regarding proposal repeatability, ground truth annotation recall on PASCAL, ImageNet, and MS COCO, and their impact on DPM, R-CNN, and Fast R-CNN detection performance. Our analysis shows that for object detection improving proposal localisation accuracy is as important as improving recall. We introduce a novel metric, the average recall (AR), which rewards both high recall and good localisation and correlates surprisingly well with detection performance. Our findings show common strengths and weaknesses of existing methods, and provide insights and metrics for selecting and tuning proposal methods.



