# Arxiv Papers in cs.CV on 2015-02-11
### A Hybrid Approach for Improved Content-based Image Retrieval using Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1502.03215v1
- **DOI**: None
- **Categories**: **cs.IR**, cs.CV, stat.ME
- **Links**: [PDF](http://arxiv.org/pdf/1502.03215v1)
- **Published**: 2015-02-11 08:23:05+00:00
- **Updated**: 2015-02-11 08:23:05+00:00
- **Authors**: Smarajit Bose, Amita Pal, Jhimli Mallick, Sunil Kumar, Pratyaydipta Rudra
- **Comment**: None
- **Journal**: None
- **Summary**: The objective of Content-Based Image Retrieval (CBIR) methods is essentially to extract, from large (image) databases, a specified number of images similar in visual and semantic content to a so-called query image. To bridge the semantic gap that exists between the representation of an image by low-level features (namely, colour, shape, texture) and its high-level semantic content as perceived by humans, CBIR systems typically make use of the relevance feedback (RF) mechanism. RF iteratively incorporates user-given inputs regarding the relevance of retrieved images, to improve retrieval efficiency. One approach is to vary the weights of the features dynamically via feature reweighting. In this work, an attempt has been made to improve retrieval accuracy by enhancing a CBIR system based on color features alone, through implicit incorporation of shape information obtained through prior segmentation of the images. Novel schemes for feature reweighting as well as for initialization of the relevant set for improved relevance feedback, have also been proposed for boosting performance of RF- based CBIR. At the same time, new measures for evaluation of retrieval accuracy have been suggested, to overcome the limitations of existing measures in the RF context. Results of extensive experiments have been presented to illustrate the effectiveness of the proposed approaches.



### Conditional Random Fields as Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1502.03240v3
- **DOI**: 10.1109/ICCV.2015.179
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03240v3)
- **Published**: 2015-02-11 10:02:50+00:00
- **Updated**: 2016-04-13 23:26:45+00:00
- **Authors**: Shuai Zheng, Sadeep Jayasumana, Bernardino Romera-Paredes, Vibhav Vineet, Zhizhong Su, Dalong Du, Chang Huang, Philip H. S. Torr
- **Comment**: This paper is published in IEEE ICCV 2015
- **Journal**: None
- **Summary**: Pixel-level labelling tasks, such as semantic segmentation, play a central role in image understanding. Recent approaches have attempted to harness the capabilities of deep learning techniques for image recognition to tackle pixel-level labelling tasks. One central issue in this methodology is the limited capacity of deep learning techniques to delineate visual objects. To solve this problem, we introduce a new form of convolutional neural network that combines the strengths of Convolutional Neural Networks (CNNs) and Conditional Random Fields (CRFs)-based probabilistic graphical modelling. To this end, we formulate mean-field approximate inference for the Conditional Random Fields with Gaussian pairwise potentials as Recurrent Neural Networks. This network, called CRF-RNN, is then plugged in as a part of a CNN to obtain a deep network that has desirable properties of both CNNs and CRFs. Importantly, our system fully integrates CRF modelling with CNNs, making it possible to train the whole deep network end-to-end with the usual back-propagation algorithm, avoiding offline post-processing methods for object delineation. We apply the proposed method to the problem of semantic image segmentation, obtaining top results on the challenging Pascal VOC 2012 segmentation benchmark.



### Image denoising based on improved data-driven sparse representation
- **Arxiv ID**: http://arxiv.org/abs/1502.03273v2
- **DOI**: None
- **Categories**: **cs.CV**, 68U10, 90C90, 65T60
- **Links**: [PDF](http://arxiv.org/pdf/1502.03273v2)
- **Published**: 2015-02-11 11:57:53+00:00
- **Updated**: 2016-03-01 13:09:36+00:00
- **Authors**: Dai-Qiang Chen
- **Comment**: 19 pages, 5 figures
- **Journal**: None
- **Summary**: Sparse representation of images under certain transform domain has been playing a fundamental role in image restoration tasks. One such representative method is the widely used wavelet tight frame systems. Instead of adopting fixed filters for constructing a tight frame to sparsely model any input image, a data-driven tight frame was proposed for the sparse representation of images, and shown to be very efficient for image denoising very recently. However, in this method the number of framelet filters used for constructing a tight frame is the same as the length of filters. In fact, through further investigation it is found that part of these filters are unnecessary and even harmful to the recovery effect due to the influence of noise. Therefore, an improved data-driven sparse representation systems constructed with much less number of filters are proposed. Numerical results on denoising experiments demonstrate that the proposed algorithm overall outperforms the original data-driven tight frame construction scheme on both the recovery quality and computational time.



### Large-Scale Deep Learning on the YFCC100M Dataset
- **Arxiv ID**: http://arxiv.org/abs/1502.03409v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1502.03409v1)
- **Published**: 2015-02-11 19:24:36+00:00
- **Updated**: 2015-02-11 19:24:36+00:00
- **Authors**: Karl Ni, Roger Pearce, Kofi Boakye, Brian Van Essen, Damian Borth, Barry Chen, Eric Wang
- **Comment**: None
- **Journal**: None
- **Summary**: We present a work-in-progress snapshot of learning with a 15 billion parameter deep learning network on HPC architectures applied to the largest publicly available natural image and video dataset released to-date. Recent advancements in unsupervised deep neural networks suggest that scaling up such networks in both model and training dataset size can yield significant improvements in the learning of concepts at the highest layers. We train our three-layer deep neural network on the Yahoo! Flickr Creative Commons 100M dataset. The dataset comprises approximately 99.2 million images and 800,000 user-created videos from Yahoo's Flickr image and video sharing platform. Training of our network takes eight days on 98 GPU nodes at the High Performance Computing Center at Lawrence Livermore National Laboratory. Encouraging preliminary results and future research directions are presented and discussed.



### An exploration of parameter redundancy in deep networks with circulant projections
- **Arxiv ID**: http://arxiv.org/abs/1502.03436v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.03436v2)
- **Published**: 2015-02-11 20:56:02+00:00
- **Updated**: 2015-10-27 06:45:51+00:00
- **Authors**: Yu Cheng, Felix X. Yu, Rogerio S. Feris, Sanjiv Kumar, Alok Choudhary, Shih-Fu Chang
- **Comment**: International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: We explore the redundancy of parameters in deep neural networks by replacing the conventional linear projection in fully-connected layers with the circulant projection. The circulant structure substantially reduces memory footprint and enables the use of the Fast Fourier Transform to speed up the computation. Considering a fully-connected neural network layer with d input nodes, and d output nodes, this method improves the time complexity from O(d^2) to O(dlogd) and space complexity from O(d^2) to O(d). The space savings are particularly important for modern deep convolutional neural network architectures, where fully-connected layers typically contain more than 90% of the network parameters. We further show that the gradient computation and optimization of the circulant projections can be performed very efficiently. Our experiments on three standard datasets show that the proposed approach achieves this significant gain in storage and efficiency with minimal increase in error rate compared to neural networks with unstructured projections.



