# Arxiv Papers in cs.CV on 2015-02-26
### Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields
- **Arxiv ID**: http://arxiv.org/abs/1502.07411v6
- **DOI**: 10.1109/TPAMI.2015.2505283
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07411v6)
- **Published**: 2015-02-26 01:26:22+00:00
- **Updated**: 2015-11-25 00:03:31+00:00
- **Authors**: Fayao Liu, Chunhua Shen, Guosheng Lin, Ian Reid
- **Comment**: Appearing in IEEE T. Pattern Analysis and Machine Intelligence.
  Journal version of arXiv:1411.6387 . Test code is available at
  https://bitbucket.org/fayao/dcnf-fcsp
- **Journal**: None
- **Summary**: In this article, we tackle the problem of depth estimation from single monocular images. Compared with depth estimation using multiple images such as stereo depth perception, depth from monocular images is much more challenging. Prior work typically focuses on exploiting geometric priors or additional sources of information, most using hand-crafted features. Recently, there is mounting evidence that features from deep convolutional neural networks (CNN) set new records for various vision applications. On the other hand, considering the continuous characteristic of the depth values, depth estimations can be naturally formulated as a continuous conditional random field (CRF) learning problem. Therefore, here we present a deep convolutional neural field model for estimating depths from single monocular images, aiming to jointly explore the capacity of deep CNN and continuous CRF. In particular, we propose a deep structured learning scheme which learns the unary and pairwise potentials of continuous CRF in a unified deep CNN framework. We then further propose an equally effective model based on fully convolutional networks and a novel superpixel pooling method, which is $\sim 10$ times faster, to speedup the patch-wise convolutions in the deep model. With this more efficient model, we are able to design deeper networks to pursue better performance. Experiments on both indoor and outdoor scene datasets demonstrate that the proposed method outperforms state-of-the-art depth estimation approaches.



### Connections Between Nuclear Norm and Frobenius Norm Based Representations
- **Arxiv ID**: http://arxiv.org/abs/1502.07423v2
- **DOI**: 10.1109/TNNLS.2016.2608834
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07423v2)
- **Published**: 2015-02-26 03:59:36+00:00
- **Updated**: 2016-10-17 03:17:01+00:00
- **Authors**: Xi Peng, Canyi Lu, Zhang Yi, Huajin Tang
- **Comment**: IEEE Trans. on Neural Networks and Learning Systems, 2016
- **Journal**: IEEE Trans. on Neural Networks and Learning Systems, 2016
- **Summary**: A lot of works have shown that frobenius-norm based representation (FNR) is competitive to sparse representation and nuclear-norm based representation (NNR) in numerous tasks such as subspace clustering. Despite the success of FNR in experimental studies, less theoretical analysis is provided to understand its working mechanism. In this paper, we fill this gap by building the theoretical connections between FNR and NNR. More specially, we prove that: 1) when the dictionary can provide enough representative capacity, FNR is exactly NNR even though the data set contains the Gaussian noise, Laplacian noise, or sample-specified corruption, 2) otherwise, FNR and NNR are two solutions on the column space of the dictionary.



### Coercive Region-level Registration for Multi-modal Images
- **Arxiv ID**: http://arxiv.org/abs/1502.07432v3
- **DOI**: None
- **Categories**: **cs.CV**, physics.data-an
- **Links**: [PDF](http://arxiv.org/pdf/1502.07432v3)
- **Published**: 2015-02-26 04:57:52+00:00
- **Updated**: 2015-11-18 03:24:57+00:00
- **Authors**: Yu-Hui Chen, Dennis Wei, Gregory Newstadt, Jeffrey Simmons, Alfred Hero
- **Comment**: This work has been accepted to International Conference on Image
  Processing (ICIP) 2015
- **Journal**: None
- **Summary**: We propose a coercive approach to simultaneously register and segment multi-modal images which share similar spatial structure. Registration is done at the region level to facilitate data fusion while avoiding the need for interpolation. The algorithm performs alternating minimization of an objective function informed by statistical models for pixel values in different modalities. Hypothesis tests are developed to determine whether to refine segmentations by splitting regions. We demonstrate that our approach has significantly better performance than the state-of-the-art registration and segmentation methods on microscopy images.



### A Dictionary Approach to EBSD Indexing
- **Arxiv ID**: http://arxiv.org/abs/1502.07436v2
- **DOI**: None
- **Categories**: **cs.CV**, physics.data-an, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/1502.07436v2)
- **Published**: 2015-02-26 05:03:49+00:00
- **Updated**: 2015-02-27 20:29:28+00:00
- **Authors**: Yu-Hui Chen, Se Un Park, Dennis Wei, Gregory Newstadt, Michael Jackson, Jeff P. Simmons, Marc De Graef, Alfred O. Hero
- **Comment**: This paper is in press in the Journal of Microscopy and
  Microanalysis, Cambridge University Press, Feb. 2015
- **Journal**: None
- **Summary**: We propose a framework for indexing of grain and sub-grain structures in electron backscatter diffraction (EBSD) images of polycrystalline materials. The framework is based on a previously introduced physics-based forward model by Callahan and De Graef (2013) relating measured patterns to grain orientations (Euler angle). The forward model is tuned to the microscope and the sample symmetry group. We discretize the domain of the forward model onto a dense grid of Euler angles and for each measured pattern we identify the most similar patterns in the dictionary. These patterns are used to identify boundaries, detect anomalies, and index crystal orientations. The statistical distribution of these closest matches is used in an unsupervised binary decision tree (DT) classifier to identify grain boundaries and anomalous regions. The DT classifies a pattern as an anomaly if it has an abnormally low similarity to any pattern in the dictionary. It classifies a pixel as being near a grain boundary if the highly ranked patterns in the dictionary differ significantly over the pixels 3x3 neighborhood. Indexing is accomplished by computing the mean orientation of the closest dictionary matches to each pattern. The mean orientation is estimated using a maximum likelihood approach that models the orientation distribution as a mixture of Von Mises-Fisher distributions over the quaternionic 3-sphere. The proposed dictionary matching approach permits segmentation, anomaly detection, and indexing to be performed in a unified manner with the additional benefit of uncertainty quantification. We demonstrate the proposed dictionary-based approach on a Ni-base IN100 alloy.



### Estimating the Potential Speedup of Computer Vision Applications on Embedded Multiprocessors
- **Arxiv ID**: http://arxiv.org/abs/1502.07446v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DC, cs.PF
- **Links**: [PDF](http://arxiv.org/pdf/1502.07446v1)
- **Published**: 2015-02-26 06:13:47+00:00
- **Updated**: 2015-02-26 06:13:47+00:00
- **Authors**: Vítor Schwambach, Sébastien Cleyet-Merle, Alain Issard, Stéphane Mancini
- **Comment**: Presented at DATE Friday Workshop on Heterogeneous Architectures and
  Design Methods for Embedded Image Systems (HIS 2015) (arXiv:1502.07241)
- **Journal**: None
- **Summary**: Computer vision applications constitute one of the key drivers for embedded multicore architectures. Although the number of available cores is increasing in new architectures, designing an application to maximize the utilization of the platform is still a challenge. In this sense, parallel performance prediction tools can aid developers in understanding the characteristics of an application and finding the most adequate parallelization strategy. In this work, we present a method for early parallel performance estimation on embedded multiprocessors from sequential application traces. We describe its implementation in Parana, a fast trace-driven simulator targeting OpenMP applications on the STMicroelectronics' STxP70 Application-Specific Multiprocessor (ASMP). Results for the FAST key point detector application show an error margin of less than 10% compared to the reference cycle-approximate simulator, with lower modeling effort and up to 20x faster execution time.



### Automatic Optimization of Hardware Accelerators for Image Processing
- **Arxiv ID**: http://arxiv.org/abs/1502.07448v1
- **DOI**: None
- **Categories**: **cs.PL**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1502.07448v1)
- **Published**: 2015-02-26 06:16:51+00:00
- **Updated**: 2015-02-26 06:16:51+00:00
- **Authors**: Oliver Reiche, Konrad Häublein, Marc Reichenbach, Frank Hannig, Jürgen Teich, Dietmar Fey
- **Comment**: Presented at DATE Friday Workshop on Heterogeneous Architectures and
  Design Methods for Embedded Image Systems (HIS 2015) (arXiv:1502.07241)
- **Journal**: None
- **Summary**: In the domain of image processing, often real-time constraints are required. In particular, in safety-critical applications, such as X-ray computed tomography in medical imaging or advanced driver assistance systems in the automotive domain, timing is of utmost importance. A common approach to maintain real-time capabilities of compute-intensive applications is to offload those computations to dedicated accelerator hardware, such as Field Programmable Gate Arrays (FPGAs). Programming such architectures is a challenging task, with respect to the typical FPGA-specific design criteria: Achievable overall algorithm latency and resource usage of FPGA primitives (BRAM, FF, LUT, and DSP). High-Level Synthesis (HLS) dramatically simplifies this task by enabling the description of algorithms in well-known higher languages (C/C++) and its automatic synthesis that can be accomplished by HLS tools. However, algorithm developers still need expert knowledge about the target architecture, in order to achieve satisfying results. Therefore, in previous work, we have shown that elevating the description of image algorithms to an even higher abstraction level, by using a Domain-Specific Language (DSL), can significantly cut down the complexity for designing such algorithms for FPGAs. To give the developer even more control over the common trade-off, latency vs. resource usage, we will present an automatic optimization process where these criteria are analyzed and fed back to the DSL compiler, in order to generate code that is closer to the desired design specifications. Finally, we generate code for stereo block matching algorithms and compare it with handwritten implementations to quantify the quality of our results.



### Concept for a CMOS Image Sensor Suited for Analog Image Pre-Processing
- **Arxiv ID**: http://arxiv.org/abs/1502.07449v1
- **DOI**: None
- **Categories**: **cs.ET**, cs.AR, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1502.07449v1)
- **Published**: 2015-02-26 06:18:04+00:00
- **Updated**: 2015-02-26 06:18:04+00:00
- **Authors**: Lan Shi, Christopher Soell, Andreas Baenisch, Robert Weigel, Jürgen Seiler, Thomas Ussmueller
- **Comment**: Presented at DATE Friday Workshop on Heterogeneous Architectures and
  Design Methods for Embedded Image Systems (HIS 2015) (arXiv:1502.07241)
- **Journal**: None
- **Summary**: A concept for a novel CMOS image sensor suited for analog image pre-processing is presented in this paper. As an example, an image restoration algorithm for reducing image noise is applied as image pre-processing in the analog domain. To supply low-latency data input for analog image preprocessing, the proposed concept for a CMOS image sensor offers a new sensor signal acquisition method in 2D. In comparison to image pre-processing in the digital domain, the proposed analog image pre-processing promises an improved image quality. Furthermore, the image noise at the stage of analog sensor signal acquisition can be used to select the most effective restoration algorithm applied to the analog circuit due to image processing prior to the A/D converter.



### A Holistic Approach for Modeling and Synthesis of Image Processing Applications for Heterogeneous Computing Architectures
- **Arxiv ID**: http://arxiv.org/abs/1502.07453v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07453v1)
- **Published**: 2015-02-26 06:20:44+00:00
- **Updated**: 2015-02-26 06:20:44+00:00
- **Authors**: Christian Hartmann, Anna Yupatova, Marc Reichenbach, Dietmar Fey, Reinhard German
- **Comment**: Presented at DATE Friday Workshop on Heterogeneous Architectures and
  Design Methods for Embedded Image Systems (HIS 2015) (arXiv:1502.07241)
- **Journal**: None
- **Summary**: Image processing applications are common in every field of our daily life. However, most of them are very complex and contain several tasks with different complexities which result in varying requirements for computing architectures. Nevertheless, a general processing scheme in every image processing application has a similar structure, called image processing pipeline: (1) capturing an image, (2) pre-processing using local operators, (3) processing with global operators and (4) post-processing using complex operations. Therefore, application-specialized hardware solutions based on heterogeneous architectures are used for image processing. Unfortunately the development of applications for heterogeneous hardware architectures is challenging due to the distribution of computational tasks among processors and programmable logic units. Nowadays, image processing systems are started from scratch which is time-consuming, error-prone and inflexible. A new methodology for modeling and implementing is needed in order to reduce the development time of heterogenous image processing systems. This paper introduces a new holistic top down approach for image processing systems. Two challenges have to be investigated. First, designers ought to be able to model their complete image processing pipeline on an abstract layer using UML. Second, we want to close the gap between the abstract system and the system architecture.



### A hypothesize-and-verify framework for Text Recognition using Deep Recurrent Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1502.07540v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07540v1)
- **Published**: 2015-02-26 13:18:09+00:00
- **Updated**: 2015-02-26 13:18:09+00:00
- **Authors**: Anupama Ray, Sai Rajeswar, Santanu Chaudhury
- **Comment**: None
- **Journal**: None
- **Summary**: Deep LSTM is an ideal candidate for text recognition. However text recognition involves some initial image processing steps like segmentation of lines and words which can induce error to the recognition system. Without segmentation, learning very long range context is difficult and becomes computationally intractable. Therefore, alternative soft decisions are needed at the pre-processing level. This paper proposes a hybrid text recognizer using a deep recurrent neural network with multiple layers of abstraction and long range context along with a language model to verify the performance of the deep neural network. In this paper we construct a multi-hypotheses tree architecture with candidate segments of line sequences from different segmentation algorithms at its different branches. The deep neural network is trained on perfectly segmented data and tests each of the candidate segments, generating unicode sequences. In the verification step, these unicode sequences are validated using a sub-string match with the language model and best first search is used to find the best possible combination of alternative hypothesis from the tree structure. Thus the verification framework using language models eliminates wrong segmentation outputs and filters recognition errors.



### Coding local and global binary visual features extracted from video sequences
- **Arxiv ID**: http://arxiv.org/abs/1502.07939v1
- **DOI**: 10.1109/TIP.2015.2445294
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1502.07939v1)
- **Published**: 2015-02-26 14:23:39+00:00
- **Updated**: 2015-02-26 14:23:39+00:00
- **Authors**: Luca Baroffio, Antonio Canclini, Matteo Cesana, Alessandro Redondi, Marco Tagliasacchi, Stefano Tubaro
- **Comment**: submitted to IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: Binary local features represent an effective alternative to real-valued descriptors, leading to comparable results for many visual analysis tasks, while being characterized by significantly lower computational complexity and memory requirements. When dealing with large collections, a more compact representation based on global features is often preferred, which can be obtained from local features by means of, e.g., the Bag-of-Visual-Word (BoVW) model. Several applications, including for example visual sensor networks and mobile augmented reality, require visual features to be transmitted over a bandwidth-limited network, thus calling for coding techniques that aim at reducing the required bit budget, while attaining a target level of efficiency. In this paper we investigate a coding scheme tailored to both local and global binary features, which aims at exploiting both spatial and temporal redundancy by means of intra- and inter-frame coding. In this respect, the proposed coding scheme can be conveniently adopted to support the Analyze-Then-Compress (ATC) paradigm. That is, visual features are extracted from the acquired content, encoded at remote nodes, and finally transmitted to a central controller that performs visual analysis. This is in contrast with the traditional approach, in which visual content is acquired at a node, compressed and then sent to a central unit for further processing, according to the Compress-Then-Analyze (CTA) paradigm. In this paper we experimentally compare ATC and CTA by means of rate-efficiency curves in the context of two different visual analysis tasks: homography estimation and content-based retrieval. Our results show that the novel ATC paradigm based on the proposed coding primitives can be competitive with CTA, especially in bandwidth limited scenarios.



### Dynamic Belief Fusion for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1502.07643v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07643v3)
- **Published**: 2015-02-26 17:31:15+00:00
- **Updated**: 2015-11-12 04:19:40+00:00
- **Authors**: Ryan Robinson
- **Comment**: The paper has been withdrawn and an updated paper has been uploaded
  by a co-author: http://arxiv.org/pdf/1511.03183.pdf
- **Journal**: None
- **Summary**: A novel approach for the fusion of detection scores from disparate object detection methods is proposed. In order to effectively integrate the outputs of multiple detectors, the level of ambiguity in each individual detection score (called "uncertainty") is estimated using the precision/recall relationship of the corresponding detector. The proposed fusion method, called Dynamic Belief Fusion (DBF), dynamically assigns basic probabilities to propositions (target, non-target, uncertain) based on confidence levels in the detection results of individual approaches. A joint basic probability assignment, containing information from all detectors, is determined using Dempster's combination rule, and is easily reduced to a single fused detection score. Experiments on ARL and PASCAL VOC 07 datasets demonstrate that the detection accuracy of DBF is considerably greater than conventional fusion approaches as well as state-of-the-art individual detectors.



### Total variation on a tree
- **Arxiv ID**: http://arxiv.org/abs/1502.07770v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07770v3)
- **Published**: 2015-02-26 21:36:07+00:00
- **Updated**: 2016-04-25 19:41:23+00:00
- **Authors**: Vladimir Kolmogorov, Thomas Pock, Michal Rolinek
- **Comment**: accepted to SIAM Journal on Imaging Sciences (SIIMS)
- **Journal**: None
- **Summary**: We consider the problem of minimizing the continuous valued total variation subject to different unary terms on trees and propose fast direct algorithms based on dynamic programming to solve these problems. We treat both the convex and the non-convex case and derive worst case complexities that are equal or better than existing methods. We show applications to total variation based 2D image processing and computer vision problems based on a Lagrangian decomposition approach. The resulting algorithms are very efficient, offer a high degree of parallelism and come along with memory requirements which are only in the order of the number of image pixels.



### The conjugated null space method of blind PSF estimation and deconvolution optimization
- **Arxiv ID**: http://arxiv.org/abs/1502.07781v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.07781v1)
- **Published**: 2015-02-26 22:37:01+00:00
- **Updated**: 2015-02-26 22:37:01+00:00
- **Authors**: Yuriy A. Bunyak, Roman N. Kvetnyy, Olga Yu. Sofina
- **Comment**: arXiv admin note: text overlap with arXiv:1206.3594
- **Journal**: None
- **Summary**: We have shown that the vector of the point spread function (PSF) lexicographical presentation belongs to the left side conjugated null space (NS) of the autoregression (AR) matrix operator on condition the AR parameters are common for original and blurred images. The method of the PSF and inverse PSF (IPSF) evaluation in the basis of the NS eigenfunctions is offered. The optimization of the PSF and IPSF shape with the aim of fluctuation elimination is considered in NS spectral domain and image space domain. The function of surface area was used as the regularization functional. Two methods of original image estimate optimization were designed basing on maximum entropy generalization of sought and blurred images conditional probability density and regularization. The first method uses balanced variations of convolutions with the PSF and IPSF to obtaining iterative schema of image optimization. The variations balance is providing by dynamic regularization basing on condition of the iteration process convergence. The regularization has dynamic character because depends on current and previous image estimate variations. The second method implements the regularization of the deconvolution optimization in curved space with metric defined on image estimate surface. The given iterative schemas have fast convergence and therefore can be used for reconstruction of high resolution images series in real time. The NS can be used for design of denoising bilateral linear filter which does not introduce image smoothing.



