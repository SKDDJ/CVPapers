# Arxiv Papers in cs.CV on 2015-02-21
### Study on Sparse Representation based Classification for Biometric Verification
- **Arxiv ID**: http://arxiv.org/abs/1502.06073v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.06073v2)
- **Published**: 2015-02-21 07:00:01+00:00
- **Updated**: 2015-02-27 11:50:33+00:00
- **Authors**: Zengxi Huang, Yiguang Liu, Xiaoming Wang, Jinrong Hu
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a multimodal verification system integrating face and ear based on sparse representation based classification (SRC). The face and ear query samples are first encoded separately to derive sparsity-based match scores, and which are then combined with sum-rule fusion for verification. Apart from validating the encouraging performance of SRC-based multimodal verification, this paper also dedicates to provide a clear understanding about the characteristics of SRC-based biometric verification. To this end, two sparsity-based metrics, i.e. spare coding error (SCE) and sparse contribution rate (SCR), are involved, together with face and ear unimodal SRC-based verification. As for the issue that SRC-based biometric verification may suffer from heavy computational burden and verification accuracy degradation with increase of enrolled subjects, we argue that it could be properly resolved by exploiting small random dictionary for sparsity-based score computation, which consists of training samples from a limited number of randomly selected subjects. Experimental results demonstrate the superiority of SRC-based multimodal verification compared to the state-of-the-art multimodal methods like likelihood ratio (LLR), support vector machine (SVM), and the sum-rule fusion methods using cosine similarity, meanwhile the idea of using small random dictionary is feasible in both effectiveness and efficiency.



### A new network-based algorithm for human activity recognition in video
- **Arxiv ID**: http://arxiv.org/abs/1502.06075v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.06075v1)
- **Published**: 2015-02-21 07:10:02+00:00
- **Updated**: 2015-02-21 07:10:02+00:00
- **Authors**: Weiyao Lin, Yuanzhe Chen, Jianxin Wu, Hanli Wang, Bin Sheng, Hongxiang Li
- **Comment**: This manuscript is the accepted version for TCSVT (IEEE Transactions
  on Circuits and Systems for Video Technology)
- **Journal**: IEEE Trans. Circuits and Systems for Video Technology, vol. 24,
  no. 5, pp. 826-841, 2014
- **Summary**: In this paper, a new network-transmission-based (NTB) algorithm is proposed for human activity recognition in videos. The proposed NTB algorithm models the entire scene as an error-free network. In this network, each node corresponds to a patch of the scene and each edge represents the activity correlation between the corresponding patches. Based on this network, we further model people in the scene as packages while human activities can be modeled as the process of package transmission in the network. By analyzing these specific "package transmission" processes, various activities can be effectively detected. The implementation of our NTB algorithm into abnormal activity detection and group activity recognition are described in detail in the paper. Experimental results demonstrate the effectiveness of our proposed algorithm.



### A Heat-Map-based Algorithm for Recognizing Group Activities in Videos
- **Arxiv ID**: http://arxiv.org/abs/1502.06076v1
- **DOI**: 10.1109/TCSVT.2013.2269780
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.06076v1)
- **Published**: 2015-02-21 07:22:07+00:00
- **Updated**: 2015-02-21 07:22:07+00:00
- **Authors**: Weiyao Lin, Hang Chu, Jianxin Wu, Bin Sheng, Zhenzhong Chen
- **Comment**: This manuscript is the accepted version for TCSVT(IEEE Transactions
  on Circuits and Systems for Video Technology)
- **Journal**: IEEE Trans. Circuits and Systems for Video Technology, vol. 23,
  no. 11, pp. 1980-1992, 2013
- **Summary**: In this paper, a new heat-map-based (HMB) algorithm is proposed for group activity recognition. The proposed algorithm first models human trajectories as series of "heat sources" and then applies a thermal diffusion process to create a heat map (HM) for representing the group activities. Based on this heat map, a new key-point based (KPB) method is used for handling the alignments among heat maps with different scales and rotations. And a surface-fitting (SF) method is also proposed for recognizing group activities. Our proposed HM feature can efficiently embed the temporal motion information of the group activities while the proposed KPB and SF methods can effectively utilize the characteristics of the heat map for activity recognition. Experimental results demonstrate the effectiveness of our proposed algorithms.



### Intra-and-Inter-Constraint-based Video Enhancement based on Piecewise Tone Mapping
- **Arxiv ID**: http://arxiv.org/abs/1502.06080v1
- **DOI**: 10.1109/TCSVT.2012.2203198
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1502.06080v1)
- **Published**: 2015-02-21 07:36:26+00:00
- **Updated**: 2015-02-21 07:36:26+00:00
- **Authors**: Yuanzhe Chen, Weiyao Lin, Chongyang Zhang, Zhenzhong Chen, Ning Xu, Jun Xie
- **Comment**: This manuscript is the accepted version for TCSVT (IEEE Transactions
  on Circuits and Systems for Video Technology)
- **Journal**: IEEE Trans. Circuits and Systems for Video Technology, vol. 23,
  no. 1, pp. 74-82, 2013
- **Summary**: Video enhancement plays an important role in various video applications. In this paper, we propose a new intra-and-inter-constraint-based video enhancement approach aiming to 1) achieve high intra-frame quality of the entire picture where multiple region-of-interests (ROIs) can be adaptively and simultaneously enhanced, and 2) guarantee the inter-frame quality consistencies among video frames. We first analyze features from different ROIs and create a piecewise tone mapping curve for the entire frame such that the intra-frame quality of a frame can be enhanced. We further introduce new inter-frame constraints to improve the temporal quality consistency. Experimental results show that the proposed algorithm obviously outperforms the state-of-the-art algorithms.



### Study of a Robust Algorithm Applied in the Optimal Position Tuning for the Camera Lens in Automated Visual Inspection Systems
- **Arxiv ID**: http://arxiv.org/abs/1502.06081v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.06081v1)
- **Published**: 2015-02-21 07:40:18+00:00
- **Updated**: 2015-02-21 07:40:18+00:00
- **Authors**: Radu Arsinte
- **Comment**: 5 pages, 2 figures
- **Journal**: Proceedings of Fifth International Conference on Pattern
  Recognition and Information Processing - PRIP'99 - May 18-20, 1999 Minsk,
  Belarus - pag.237-242 - ISBN 83-87362-16-6
- **Summary**: This paper present the mathematical fundaments and experimental study of an algorithm used to find the optimal position for the camera lens to obtain a maximum of details. This information can be further applied to a appropriate system to automatically correct this position. The algorithm is based on the evaluation of a so called resolution function who calculates the maximum of gradient in a certain zone of the image. The paper also presents alternative forms of the function, results of measurements and set up a set of practical rules for the right application of the algorithm.



### Regularization and Kernelization of the Maximin Correlation Approach
- **Arxiv ID**: http://arxiv.org/abs/1502.06105v2
- **DOI**: 10.1109/ACCESS.2016.2551727
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1502.06105v2)
- **Published**: 2015-02-21 14:37:44+00:00
- **Updated**: 2016-03-29 04:42:12+00:00
- **Authors**: Taehoon Lee, Taesup Moon, Seung Jean Kim, Sungroh Yoon
- **Comment**: Submitted to IEEE Access
- **Journal**: None
- **Summary**: Robust classification becomes challenging when each class consists of multiple subclasses. Examples include multi-font optical character recognition and automated protein function prediction. In correlation-based nearest-neighbor classification, the maximin correlation approach (MCA) provides the worst-case optimal solution by minimizing the maximum misclassification risk through an iterative procedure. Despite the optimality, the original MCA has drawbacks that have limited its wide applicability in practice. That is, the MCA tends to be sensitive to outliers, cannot effectively handle nonlinearities in datasets, and suffers from having high computational complexity. To address these limitations, we propose an improved solution, named regularized maximin correlation approach (R-MCA). We first reformulate MCA as a quadratically constrained linear programming (QCLP) problem, incorporate regularization by introducing slack variables in the primal problem of the QCLP, and derive the corresponding Lagrangian dual. The dual formulation enables us to apply the kernel trick to R-MCA so that it can better handle nonlinearities. Our experimental results demonstrate that the regularization and kernelization make the proposed R-MCA more robust and accurate for various classification tasks than the original MCA. Furthermore, when the data size or dimensionality grows, R-MCA runs substantially faster by solving either the primal or dual (whichever has a smaller variable dimension) of the QCLP.



### Don't Just Listen, Use Your Imagination: Leveraging Visual Common Sense for Non-Visual Tasks
- **Arxiv ID**: http://arxiv.org/abs/1502.06108v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.06108v3)
- **Published**: 2015-02-21 15:25:40+00:00
- **Updated**: 2015-07-29 03:04:19+00:00
- **Authors**: Xiao Lin, Devi Parikh
- **Comment**: None
- **Journal**: None
- **Summary**: Artificial agents today can answer factual questions. But they fall short on questions that require common sense reasoning. Perhaps this is because most existing common sense databases rely on text to learn and represent knowledge. But much of common sense knowledge is unwritten - partly because it tends not to be interesting enough to talk about, and partly because some common sense is unnatural to articulate in text. While unwritten, it is not unseen. In this paper we leverage semantic common sense knowledge learned from images - i.e. visual common sense - in two textual tasks: fill-in-the-blank and visual paraphrasing. We propose to "imagine" the scene behind the text, and leverage visual cues from the "imagined" scenes in addition to textual cues while answering these questions. We imagine the scenes as a visual abstraction. Our approach outperforms a strong text-only baseline on these tasks. Our proposed tasks can serve as benchmarks to quantitatively evaluate progress in solving tasks that go "beyond recognition". Our code and datasets are publicly available.



