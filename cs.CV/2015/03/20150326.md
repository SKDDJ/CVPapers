# Arxiv Papers in cs.CV on 2015-03-26
### Robust Eye Centers Localization with Zero--Crossing Encoded Image Projections
- **Arxiv ID**: http://arxiv.org/abs/1503.07697v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.07697v1)
- **Published**: 2015-03-26 11:51:14+00:00
- **Updated**: 2015-03-26 11:51:14+00:00
- **Authors**: Laura Florea, Corneliu Florea, Constantin Vertan
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a new framework for the eye centers localization by the joint use of encoding of normalized image projections and a Multi Layer Perceptron (MLP) classifier. The encoding is novel and it consists in identifying the zero-crossings and extracting the relevant parameters from the resulting modes. The compressed normalized projections produce feature descriptors that are inputs to a properly-trained MLP, for discriminating among various categories of image regions. The proposed framework forms a fast and reliable system for the eye centers localization, especially in the context of face expression analysis in unconstrained environments. We successfully test the proposed method on a wide variety of databases including BioID, Cohn-Kanade, Extended Yale B and Labelled Faces in the Wild (LFW) databases.



### Pain Intensity Estimation by a Self--Taught Selection of Histograms of Topographical Features
- **Arxiv ID**: http://arxiv.org/abs/1503.07706v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.07706v1)
- **Published**: 2015-03-26 12:32:20+00:00
- **Updated**: 2015-03-26 12:32:20+00:00
- **Authors**: Corneliu Florea, Laura Florea, Raluca Boia, Alessandra Bandrabur, Constantin Vertan
- **Comment**: None
- **Journal**: None
- **Summary**: Pain assessment through observational pain scales is necessary for special categories of patients such as neonates, patients with dementia, critically ill patients, etc. The recently introduced Prkachin-Solomon score allows pain assessment directly from facial images opening the path for multiple assistive applications. In this paper, we introduce the Histograms of Topographical (HoT) features, which are a generalization of the topographical primal sketch, for the description of the face parts contributing to the mentioned score. We propose a semi-supervised, clustering oriented self--taught learning procedure developed on the emotion oriented Cohn-Kanade database. We use this procedure to improve the discrimination between different pain intensity levels and the generalization with respect to the monitored persons, while testing on the UNBC McMaster Shoulder Pain database.



### Towards Learning free Naive Bayes Nearest Neighbor-based Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1503.07783v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.07783v1)
- **Published**: 2015-03-26 16:55:19+00:00
- **Updated**: 2015-03-26 16:55:19+00:00
- **Authors**: Faraz Saeedan, Barbara Caputo
- **Comment**: None
- **Journal**: None
- **Summary**: As of today, object categorization algorithms are not able to achieve the level of robustness and generality necessary to work reliably in the real world. Even the most powerful convolutional neural network we can train fails to perform satisfactorily when trained and tested on data from different databases. This issue, known as domain adaptation and/or dataset bias in the literature, is due to a distribution mismatch between data collections. Methods addressing it go from max-margin classifiers to learning how to modify the features and obtain a more robust representation. Recent work showed that by casting the problem into the image-to-class recognition framework, the domain adaptation problem is significantly alleviated \cite{danbnn}. Here we follow this approach, and show how a very simple, learning free Naive Bayes Nearest Neighbor (NBNN)-based domain adaptation algorithm can significantly alleviate the distribution mismatch among source and target data, especially when the number of classes and the number of sources grow. Experiments on standard benchmarks used in the literature show that our approach (a) is competitive with the current state of the art on small scale problems, and (b) achieves the current state of the art as the number of classes and sources grows, with minimal computational requirements.



### Transductive Multi-label Zero-shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1503.07790v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1503.07790v1)
- **Published**: 2015-03-26 17:12:34+00:00
- **Updated**: 2015-03-26 17:12:34+00:00
- **Authors**: Yanwei Fu, Yongxin Yang, Tim Hospedales, Tao Xiang, Shaogang Gong
- **Comment**: 12 pages, 6 figures, Accepted to BMVC 2014 (oral)
- **Journal**: None
- **Summary**: Zero-shot learning has received increasing interest as a means to alleviate the often prohibitive expense of annotating training data for large scale recognition problems. These methods have achieved great success via learning intermediate semantic representations in the form of attributes and more recently, semantic word vectors. However, they have thus far been constrained to the single-label case, in contrast to the growing popularity and importance of more realistic multi-label data. In this paper, for the first time, we investigate and formalise a general framework for multi-label zero-shot learning, addressing the unique challenge therein: how to exploit multi-label correlation at test time with no training data for those classes? In particular, we propose (1) a multi-output deep regression model to project an image into a semantic word space, which explicitly exploits the correlations in the intermediate semantic layer of word vectors; (2) a novel zero-shot learning algorithm for multi-label data that exploits the unique compositionality property of semantic word vector representations; and (3) a transductive learning strategy to enable the regression model learned from seen classes to generalise well to unseen classes. Our zero-shot learning experiments on a number of standard multi-label datasets demonstrate that our method outperforms a variety of baselines.



### Transductive Multi-class and Multi-label Zero-shot Learning
- **Arxiv ID**: http://arxiv.org/abs/1503.07884v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1503.07884v1)
- **Published**: 2015-03-26 20:07:37+00:00
- **Updated**: 2015-03-26 20:07:37+00:00
- **Authors**: Yanwei Fu, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Shaogang Gong
- **Comment**: 4 pages, 4 figures, ECCV 2014 Workshop on Parts and Attributes
- **Journal**: None
- **Summary**: Recently, zero-shot learning (ZSL) has received increasing interest. The key idea underpinning existing ZSL approaches is to exploit knowledge transfer via an intermediate-level semantic representation which is assumed to be shared between the auxiliary and target datasets, and is used to bridge between these domains for knowledge transfer. The semantic representation used in existing approaches varies from visual attributes to semantic word vectors and semantic relatedness. However, the overall pipeline is similar: a projection mapping low-level features to the semantic representation is learned from the auxiliary dataset by either classification or regression models and applied directly to map each instance into the same semantic representation space where a zero-shot classifier is used to recognise the unseen target class instances with a single known 'prototype' of each target class. In this paper we discuss two related lines of work improving the conventional approach: exploiting transductive learning ZSL, and generalising ZSL to the multi-label case.



