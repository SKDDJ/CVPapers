# Arxiv Papers in cs.CV on 2015-03-11
### Learning Classifiers from Synthetic Data Using a Multichannel Autoencoder
- **Arxiv ID**: http://arxiv.org/abs/1503.03163v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1503.03163v1)
- **Published**: 2015-03-11 03:31:53+00:00
- **Updated**: 2015-03-11 03:31:53+00:00
- **Authors**: Xi Zhang, Yanwei Fu, Andi Zang, Leonid Sigal, Gady Agam
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: We propose a method for using synthetic data to help learning classifiers. Synthetic data, even is generated based on real data, normally results in a shift from the distribution of real data in feature space. To bridge the gap between the real and synthetic data, and jointly learn from synthetic and real data, this paper proposes a Multichannel Autoencoder(MCAE). We show that by suing MCAE, it is possible to learn a better feature representation for classification. To evaluate the proposed approach, we conduct experiments on two types of datasets. Experimental results on two datasets validate the efficiency of our MCAE model and our methodology of generating synthetic data.



### Deep Convolutional Inverse Graphics Network
- **Arxiv ID**: http://arxiv.org/abs/1503.03167v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1503.03167v4)
- **Published**: 2015-03-11 04:08:42+00:00
- **Updated**: 2015-06-22 02:10:00+00:00
- **Authors**: Tejas D. Kulkarni, Will Whitney, Pushmeet Kohli, Joshua B. Tenenbaum
- **Comment**: First two authors contributed equally
- **Journal**: None
- **Summary**: This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a model that learns an interpretable representation of images. This representation is disentangled with respect to transformations such as out-of-plane rotations and lighting variations. The DC-IGN model is composed of multiple layers of convolution and de-convolution operators and is trained using the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a training procedure to encourage neurons in the graphics code layer to represent a specific transformation (e.g. pose or light). Given a single input image, our model can generate new images of the same object with variations in pose and lighting. We present qualitative and quantitative results of the model's efficacy at learning a 3D rendering engine.



### Simple, Accurate, and Robust Nonparametric Blind Super-Resolution
- **Arxiv ID**: http://arxiv.org/abs/1503.03187v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.03187v2)
- **Published**: 2015-03-11 06:21:39+00:00
- **Updated**: 2015-03-16 10:12:07+00:00
- **Authors**: Wen-Ze Shao, Michael Elad
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a simple, accurate, and robust approach to single image nonparametric blind Super-Resolution (SR). This task is formulated as a functional to be minimized with respect to both an intermediate super-resolved image and a nonparametric blur-kernel. The proposed approach includes a convolution consistency constraint which uses a non-blind learning-based SR result to better guide the estimation process. Another key component is the unnatural bi-l0-l2-norm regularization imposed on the super-resolved, sharp image and the blur-kernel, which is shown to be quite beneficial for estimating the blur-kernel accurately. The numerical optimization is implemented by coupling the splitting augmented Lagrangian and the conjugate gradient (CG). Using the pre-estimated blur-kernel, we finally reconstruct the SR image by a very simple non-blind SR method that uses a natural image prior. The proposed approach is demonstrated to achieve better performance than the recent method by Michaeli and Irani [2] in both terms of the kernel estimation accuracy and image SR quality.



### A model-based approach to recovering the structure of a plant from images
- **Arxiv ID**: http://arxiv.org/abs/1503.03191v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.03191v2)
- **Published**: 2015-03-11 06:37:40+00:00
- **Updated**: 2015-03-12 00:28:52+00:00
- **Authors**: Ben Ward, John Bastian, Anton van den Hengel, Daniel Pooley, Rajendra Bari, Bettina Berger, Mark Tester
- **Comment**: None
- **Journal**: None
- **Summary**: We present a method for recovering the structure of a plant directly from a small set of widely-spaced images. Structure recovery is more complex than shape estimation, but the resulting structure estimate is more closely related to phenotype than is a 3D geometric model. The method we propose is applicable to a wide variety of plants, but is demonstrated on wheat. Wheat is made up of thin elements with few identifiable features, making it difficult to analyse using standard feature matching techniques. Our method instead analyses the structure of plants using only their silhouettes. We employ a generate-and-test method, using a database of manually modelled leaves and a model for their composition to synthesise plausible plant structures which are evaluated against the images. The method is capable of efficiently recovering accurate estimates of plant structure in a wide variety of imaging scenarios, with no manual intervention.



### Adaptive-Rate Sparse Signal Reconstruction With Application in Compressive Background Subtraction
- **Arxiv ID**: http://arxiv.org/abs/1503.03231v1
- **DOI**: None
- **Categories**: **math.OC**, cs.CV, cs.IT, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1503.03231v1)
- **Published**: 2015-03-11 09:16:39+00:00
- **Updated**: 2015-03-11 09:16:39+00:00
- **Authors**: Joao F. C. Mota, Nikos Deligiannis, Aswin C. Sankaranarayanan, Volkan Cevher, Miguel R. D. Rodrigues
- **Comment**: submitted to IEEE Trans. Signal Processing
- **Journal**: None
- **Summary**: We propose and analyze an online algorithm for reconstructing a sequence of signals from a limited number of linear measurements. The signals are assumed sparse, with unknown support, and evolve over time according to a generic nonlinear dynamical model. Our algorithm, based on recent theoretical results for $\ell_1$-$\ell_1$ minimization, is recursive and computes the number of measurements to be taken at each time on-the-fly. As an example, we apply the algorithm to compressive video background subtraction, a problem that can be stated as follows: given a set of measurements of a sequence of images with a static background, simultaneously reconstruct each image while separating its foreground from the background. The performance of our method is illustrated on sequences of real images: we observe that it allows a dramatic reduction in the number of measurements with respect to state-of-the-art compressive background subtraction schemes.



### A Novel Hybrid CNN-AIS Visual Pattern Recognition Engine
- **Arxiv ID**: http://arxiv.org/abs/1503.03270v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.03270v1)
- **Published**: 2015-03-11 10:58:25+00:00
- **Updated**: 2015-03-11 10:58:25+00:00
- **Authors**: Vandna Bhalla, Santanu Chaudhury, Arihant Jain
- **Comment**: None
- **Journal**: None
- **Summary**: Machine learning methods are used today for most recognition problems. Convolutional Neural Networks (CNN) have time and again proved successful for many image processing tasks primarily for their architecture. In this paper we propose to apply CNN to small data sets like for example, personal albums or other similar environs where the size of training dataset is a limitation, within the framework of a proposed hybrid CNN-AIS model. We use Artificial Immune System Principles to enhance small size of training data set. A layer of Clonal Selection is added to the local filtering and max pooling of CNN Architecture. The proposed Architecture is evaluated using the standard MNIST dataset by limiting the data size and also with a small personal data sample belonging to two different classes. Experimental results show that the proposed hybrid CNN-AIS based recognition engine works well when the size of training data is limited in size



### Stochastic Texture Difference for Scale-Dependent Data Analysis
- **Arxiv ID**: http://arxiv.org/abs/1503.03278v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.03278v3)
- **Published**: 2015-03-11 11:30:04+00:00
- **Updated**: 2015-10-05 08:26:28+00:00
- **Authors**: Nicolas Brodu, Hussein Yahia
- **Comment**: None
- **Journal**: None
- **Summary**: This article introduces the Stochastic Texture Difference method for analyzing data at prescribed spatial and value scales. This method relies on constrained random walks around each pixel, describing how nearby image values typically evolve on each side of this pixel. Textures are represented as probability distributions of such random walks, so a texture difference operator is statistically defined as a distance between these distributions in a suitable reproducing kernel Hilbert space. The method is thus not limited to scalar pixel values: any data type for which a kernel is available may be considered, from color triplets and multispectral vector data to strings, graphs, and more. By adjusting the size of the neighborhoods that are compared, the method is implicitly scale-dependent. It is also able to focus on either small changes or large gradients. We demonstrate how it can be used to infer spatial and data value characteristic scales in measured signals and natural images.



### Dense image registration and deformable surface reconstruction in presence of occlusions and minimal texture
- **Arxiv ID**: http://arxiv.org/abs/1503.03429v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.03429v3)
- **Published**: 2015-03-11 17:37:22+00:00
- **Updated**: 2015-09-25 09:07:09+00:00
- **Authors**: Dat Tien Ngo, Sanghuyk Park, Anne Jorstad, Alberto Crivellaro, Chang Yoo, Pascal Fua
- **Comment**: In Proceedings of International Conference on Computer Vision, 2015
- **Journal**: None
- **Summary**: Deformable surface tracking from monocular images is well-known to be under-constrained. Occlusions often make the task even more challenging, and can result in failure if the surface is not sufficiently textured. In this work, we explicitly address the problem of 3D reconstruction of poorly textured, occluded surfaces, proposing a framework based on a template-matching approach that scales dense robust features by a relevancy score. Our approach is extensively compared to current methods employing both local feature matching and dense template alignment. We test on standard datasets as well as on a new dataset (that will be made publicly available) of a sparsely textured, occluded surface. Our framework achieves state-of-the-art results for both well and poorly textured, occluded surfaces.



### Properties of simple sets in digital spaces. Contractions of simple sets preserving the homotopy type of a digital space
- **Arxiv ID**: http://arxiv.org/abs/1503.03491v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.DM, math.AT
- **Links**: [PDF](http://arxiv.org/pdf/1503.03491v1)
- **Published**: 2015-03-11 20:17:58+00:00
- **Updated**: 2015-03-11 20:17:58+00:00
- **Authors**: Alexander V. Evako
- **Comment**: 7 pages, 5 figures. arXiv admin note: text overlap with
  arXiv:1412.0218
- **Journal**: None
- **Summary**: A point of a digital space is called simple if it can be deleted from the space without altering topology. This paper introduces the notion simple set of points of a digital space. The definition is based on contractible spaces and contractible transformations. A set of points in a digital space is called simple if it can be contracted to a point without changing topology of the space. It is shown that contracting a simple set of points does not change the homotopy type of a digital space, and the number of points in a digital space without simple points can be reduces by contracting simple sets. Using the process of contracting, we can substantially compress a digital space while preserving the topology. The paper proposes a method for thinning a digital space which shows that this approach can contribute to computer science such as medical imaging, computer graphics and pattern analysis.



### Diverse Landmark Sampling from Determinantal Point Processes for Scalable Manifold Learning
- **Arxiv ID**: http://arxiv.org/abs/1503.03506v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1503.03506v1)
- **Published**: 2015-03-11 21:09:28+00:00
- **Updated**: 2015-03-11 21:09:28+00:00
- **Authors**: Christian Wachinger, Polina Golland
- **Comment**: None
- **Journal**: None
- **Summary**: High computational costs of manifold learning prohibit its application for large point sets. A common strategy to overcome this problem is to perform dimensionality reduction on selected landmarks and to successively embed the entire dataset with the Nystr\"om method. The two main challenges that arise are: (i) the landmarks selected in non-Euclidean geometries must result in a low reconstruction error, (ii) the graph constructed from sparsely sampled landmarks must approximate the manifold well. We propose the sampling of landmarks from determinantal distributions on non-Euclidean spaces. Since current determinantal sampling algorithms have the same complexity as those for manifold learning, we present an efficient approximation running in linear time. Further, we recover the local geometry after the sparsification by assigning each landmark a local covariance matrix, estimated from the original point set. The resulting neighborhood selection based on the Bhattacharyya distance improves the embedding of sparsely sampled manifolds. Our experiments show a significant performance improvement compared to state-of-the-art landmark selection techniques.



### Appearance-based indoor localization: A comparison of patch descriptor performance
- **Arxiv ID**: http://arxiv.org/abs/1503.03514v1
- **DOI**: 10.1016/j.patrec.2015.03.003
- **Categories**: **cs.CV**, cs.RO, 68T45, 68T40
- **Links**: [PDF](http://arxiv.org/pdf/1503.03514v1)
- **Published**: 2015-03-11 21:43:46+00:00
- **Updated**: 2015-03-11 21:43:46+00:00
- **Authors**: Jose Rivera-Rubio, Ioannis Alexiou, Anil A. Bharath
- **Comment**: Accepted for publication on Pattern Recognition Letters
- **Journal**: None
- **Summary**: Vision is one of the most important of the senses, and humans use it extensively during navigation. We evaluated different types of image and video frame descriptors that could be used to determine distinctive visual landmarks for localizing a person based on what is seen by a camera that they carry. To do this, we created a database containing over 3 km of video-sequences with ground-truth in the form of distance travelled along different corridors. Using this database, the accuracy of localization - both in terms of knowing which route a user is on - and in terms of position along a certain route, can be evaluated. For each type of descriptor, we also tested different techniques to encode visual structure and to search between journeys to estimate a user's position. The techniques include single-frame descriptors, those using sequences of frames, and both colour and achromatic descriptors. We found that single-frame indexing worked better within this particular dataset. This might be because the motion of the person holding the camera makes the video too dependent on individual steps and motions of one particular journey. Our results suggest that appearance-based information could be an additional source of navigational data indoors, augmenting that provided by, say, radio signal strength indicators (RSSIs). Such visual information could be collected by crowdsourcing low-resolution video feeds, allowing journeys made by different users to be associated with each other, and location to be inferred without requiring explicit mapping. This offers a complementary approach to methods based on simultaneous localization and mapping (SLAM) algorithms.



