# Arxiv Papers in cs.CV on 2015-03-31
### Beyond Short Snippets: Deep Networks for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1503.08909v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.08909v2)
- **Published**: 2015-03-31 04:34:12+00:00
- **Updated**: 2015-04-13 19:44:25+00:00
- **Authors**: Joe Yue-Hei Ng, Matthew Hausknecht, Sudheendra Vijayanarasimhan, Oriol Vinyals, Rajat Monga, George Toderici
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have been extensively applied for image recognition problems giving state-of-the-art results on recognition, detection, segmentation and retrieval. In this work we propose and evaluate several deep neural network architectures to combine image information across a video over longer time periods than previously attempted. We propose two methods capable of handling full length videos. The first method explores various convolutional temporal feature pooling architectures, examining the various design choices which need to be made when adapting a CNN for this task. The second proposed method explicitly models the video as an ordered sequence of frames. For this purpose we employ a recurrent neural network that uses Long Short-Term Memory (LSTM) cells which are connected to the output of the underlying CNN. Our best networks exhibit significant performance improvements over previously published results on the Sports 1 million dataset (73.1% vs. 60.9%) and the UCF-101 datasets with (88.6% vs. 88.0%) and without additional optical flow information (82.6% vs. 72.8%).



### Real-World Font Recognition Using Deep Network and Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/1504.00028v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1504.00028v1)
- **Published**: 2015-03-31 20:30:00+00:00
- **Updated**: 2015-03-31 20:30:00+00:00
- **Authors**: Zhangyang Wang, Jianchao Yang, Hailin Jin, Eli Shechtman, Aseem Agarwala, Jonathan Brandt, Thomas S. Huang
- **Comment**: None
- **Journal**: None
- **Summary**: We address a challenging fine-grain classification problem: recognizing a font style from an image of text. In this task, it is very easy to generate lots of rendered font examples but very hard to obtain real-world labeled images. This real-to-synthetic domain gap caused poor generalization to new real data in previous methods (Chen et al. (2014)). In this paper, we refer to Convolutional Neural Networks, and use an adaptation technique based on a Stacked Convolutional Auto-Encoder that exploits unlabeled real-world images combined with synthetic data. The proposed method achieves an accuracy of higher than 80% (top-5) on a real-world dataset.



### Weakly Supervised Learning of Objects, Attributes and their Associations
- **Arxiv ID**: http://arxiv.org/abs/1504.00045v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.00045v1)
- **Published**: 2015-03-31 21:18:18+00:00
- **Updated**: 2015-03-31 21:18:18+00:00
- **Authors**: Zhiyuan Shi, Yongxin Yang, Timothy M. Hospedales, Tao Xiang
- **Comment**: 14 pages, Accepted to ECCV 2014
- **Journal**: None
- **Summary**: When humans describe images they tend to use combinations of nouns and adjectives, corresponding to objects and their associated attributes respectively. To generate such a description automatically, one needs to model objects, attributes and their associations. Conventional methods require strong annotation of object and attribute locations, making them less scalable. In this paper, we model object-attribute associations from weakly labelled images, such as those widely available on media sharing sites (e.g. Flickr), where only image-level labels (either object or attributes) are given, without their locations and associations. This is achieved by introducing a novel weakly supervised non-parametric Bayesian model. Once learned, given a new image, our model can describe the image, including objects, attributes and their associations, as well as their locations and segmentation. Extensive experiments on benchmark datasets demonstrate that our weakly supervised model performs at par with strongly supervised models on tasks such as image description and retrieval based on object-attribute associations.



