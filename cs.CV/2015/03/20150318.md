# Arxiv Papers in cs.CV on 2015-03-18
### What Properties are Desirable from an Electron Microscopy Segmentation Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1503.05430v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05430v3)
- **Published**: 2015-03-18 14:38:00+00:00
- **Updated**: 2015-09-28 14:05:32+00:00
- **Authors**: Toufiq Parag
- **Comment**: Extended version of the ICCV 2015 paper: Efficient Classifier
  Training to Minimize False Merges in Electron Microscopy Segmentation
- **Journal**: None
- **Summary**: The prospect of neural reconstruction from Electron Microscopy (EM) images has been elucidated by the automatic segmentation algorithms. Although segmentation algorithms eliminate the necessity of tracing the neurons by hand, significant manual effort is still essential for correcting the mistakes they make. A considerable amount of human labor is also required for annotating groundtruth volumes for training the classifiers of a segmentation framework. It is critically important to diminish the dependence on human interaction in the overall reconstruction system. This study proposes a novel classifier training algorithm for EM segmentation aimed to reduce the amount of manual effort demanded by the groundtruth annotation and error refinement tasks. Instead of using an exhaustive pixel level groundtruth, an active learning algorithm is proposed for sparse labeling of pixel and boundaries of superpixels. Because over-segmentation errors are in general more tolerable and easier to correct than the under-segmentation errors, our algorithm is designed to prioritize minimization of false-merges over false-split mistakes. Our experiments on both 2D and 3D data suggest that the proposed method yields segmentation outputs that are more amenable to neural reconstruction than those of existing methods.



### Nonparametric Detection of Nonlinearly Mixed Pixels and Endmember Estimation in Hyperspectral Images
- **Arxiv ID**: http://arxiv.org/abs/1503.05521v1
- **DOI**: 10.1109/TIP.2015.2509258
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05521v1)
- **Published**: 2015-03-18 18:20:24+00:00
- **Updated**: 2015-03-18 18:20:24+00:00
- **Authors**: Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard, Jean-Yves Tourneret
- **Comment**: None
- **Journal**: None
- **Summary**: Mixing phenomena in hyperspectral images depend on a variety of factors such as the resolution of observation devices, the properties of materials, and how these materials interact with incident light in the scene. Different parametric and nonparametric models have been considered to address hyperspectral unmixing problems. The simplest one is the linear mixing model. Nevertheless, it has been recognized that mixing phenomena can also be nonlinear. The corresponding nonlinear analysis techniques are necessarily more challenging and complex than those employed for linear unmixing. Within this context, it makes sense to detect the nonlinearly mixed pixels in an image prior to its analysis, and then employ the simplest possible unmixing technique to analyze each pixel. In this paper, we propose a technique for detecting nonlinearly mixed pixels. The detection approach is based on the comparison of the reconstruction errors using both a Gaussian process regression model and a linear regression model. The two errors are combined into a detection statistics for which a probability density function can be reasonably approximated. We also propose an iterative endmember extraction algorithm to be employed in combination with the detection algorithm. The proposed Detect-then-Unmix strategy, which consists of extracting endmembers, detecting nonlinearly mixed pixels and unmixing, is tested with synthetic and real images.



### Video Inpainting of Complex Scenes
- **Arxiv ID**: http://arxiv.org/abs/1503.05528v2
- **DOI**: 10.1137/140954933
- **Categories**: **cs.CV**, cs.MM, eess.IV, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1503.05528v2)
- **Published**: 2015-03-18 18:35:40+00:00
- **Updated**: 2015-06-08 06:43:01+00:00
- **Authors**: Alasdair Newson, Andrés Almansa, Matthieu Fradet, Yann Gousseau, Patrick Pérez
- **Comment**: None
- **Journal**: SIAM Journal on Imaging Sciences, Society for Industrial and
  Applied Mathematics, 2014, 7 (4), pp.1993-2019
- **Summary**: We propose an automatic video inpainting algorithm which relies on the optimisation of a global, patch-based functional. Our algorithm is able to deal with a variety of challenging situations which naturally arise in video inpainting, such as the correct reconstruction of dynamic textures, multiple moving objects and moving background. Furthermore, we achieve this in an order of magnitude less execution time with respect to the state-of-the-art. We are also able to achieve good quality results on high definition videos. Finally, we provide specific algorithmic details to make implementation of our algorithm as easy as possible. The resulting algorithm requires no segmentation or manual input other than the definition of the inpainting mask, and can deal with a wider variety of situations than is handled by previous work. 1. Introduction. Advanced image and video editing techniques are increasingly common in the image processing and computer vision world, and are also starting to be used in media entertainment. One common and difficult task closely linked to the world of video editing is image and video " inpainting ". Generally speaking, this is the task of replacing the content of an image or video with some other content which is visually pleasing. This subject has been extensively studied in the case of images, to such an extent that commercial image inpainting products destined for the general public are available, such as Photoshop's " Content Aware fill " [1]. However, while some impressive results have been obtained in the case of videos, the subject has been studied far less extensively than image inpainting. This relative lack of research can largely be attributed to high time complexity due to the added temporal dimension. Indeed, it has only very recently become possible to produce good quality inpainting results on high definition videos, and this only in a semi-automatic manner. Nevertheless, high-quality video inpainting has many important and useful applications such as film restoration, professional post-production in cinema and video editing for personal use. For this reason, we believe that an automatic, generic video inpainting algorithm would be extremely useful for both academic and professional communities.



