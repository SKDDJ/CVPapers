# Arxiv Papers in cs.CV on 2015-03-28
### Socializing the Semantic Gap: A Comparative Survey on Image Tag Assignment, Refinement and Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1503.08248v3
- **DOI**: 10.1145/2906152
- **Categories**: **cs.IR**, cs.CV, cs.MM, cs.SI, H.3.1; H.3.3
- **Links**: [PDF](http://arxiv.org/pdf/1503.08248v3)
- **Published**: 2015-03-28 00:10:16+00:00
- **Updated**: 2016-03-23 05:45:31+00:00
- **Authors**: Xirong Li, Tiberio Uricchio, Lamberto Ballan, Marco Bertini, Cees G. M. Snoek, Alberto Del Bimbo
- **Comment**: to appear in ACM Computing Surveys
- **Journal**: ACM Computing Surveys, Volume 49 Issue 1, 14:1-14:39, June 2016
- **Summary**: Where previous reviews on content-based image retrieval emphasize on what can be seen in an image to bridge the semantic gap, this survey considers what people tag about an image. A comprehensive treatise of three closely linked problems, i.e., image tag assignment, refinement, and tag-based image retrieval is presented. While existing works vary in terms of their targeted tasks and methodology, they rely on the key functionality of tag relevance, i.e. estimating the relevance of a specific tag with respect to the visual content of a given image and its social context. By analyzing what information a specific method exploits to construct its tag relevance function and how such information is exploited, this paper introduces a taxonomy to structure the growing literature, understand the ingredients of the main works, clarify their connections and difference, and recognize their merits and limitations. For a head-to-head comparison between the state-of-the-art, a new experimental protocol is presented, with training sets containing 10k, 100k and 1m images and an evaluation on three test sets, contributed by various research groups. Eleven representative works are implemented and evaluated. Putting all this together, the survey aims to provide an overview of the past and foster progress for the near future.



### CRF Learning with CNN Features for Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1503.08263v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.08263v1)
- **Published**: 2015-03-28 04:05:09+00:00
- **Updated**: 2015-03-28 04:05:09+00:00
- **Authors**: Fayao Liu, Guosheng Lin, Chunhua Shen
- **Comment**: None
- **Journal**: None
- **Summary**: Conditional Random Rields (CRF) have been widely applied in image segmentations. While most studies rely on hand-crafted features, we here propose to exploit a pre-trained large convolutional neural network (CNN) to generate deep features for CRF learning. The deep CNN is trained on the ImageNet dataset and transferred to image segmentations here for constructing potentials of superpixels. Then the CRF parameters are learnt using a structured support vector machine (SSVM). To fully exploit context information in inference, we construct spatially related co-occurrence pairwise potentials and incorporate them into the energy function. This prefers labelling of object pairs that frequently co-occur in a certain spatial layout and at the same time avoids implausible labellings during the inference. Extensive experiments on binary and multi-class segmentation benchmarks demonstrate the promise of the proposed method. We thus provide new baselines for the segmentation performance on the Weizmann horse, Graz-02, MSRC-21, Stanford Background and PASCAL VOC 2011 datasets.



