# Arxiv Papers in cs.CV on 2015-03-19
### Edge Detection: A Collection of Pixel based Approach for Colored Images
- **Arxiv ID**: http://arxiv.org/abs/1503.05689v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05689v1)
- **Published**: 2015-03-19 10:08:37+00:00
- **Updated**: 2015-03-19 10:08:37+00:00
- **Authors**: B. O Sadiq, S. M Sani, S Garba
- **Comment**: 5 Pages
- **Journal**: None
- **Summary**: The existing traditional edge detection algorithms process a single pixel on an image at a time, thereby calculating a value which shows the edge magnitude of the pixel and the edge orientation. Most of these existing algorithms convert the coloured images into gray scale before detection of edges. However, this process leads to inaccurate precision of recognized edges, thus producing false and broken edges in the image. This paper presents a profile modelling scheme for collection of pixels based on the step and ramp edges, with a view to reducing the false and broken edges present in the image. The collection of pixel scheme generated is used with the Vector Order Statistics to reduce the imprecision of recognized edges when converting from coloured to gray scale images. The Pratt Figure of Merit (PFOM) is used as a quantitative comparison between the existing traditional edge detection algorithm and the developed algorithm as a means of validation. The PFOM value obtained for the developed algorithm is 0.8480, which showed an improvement over the existing traditional edge detection algorithms.



### An approach to improving edge detection for facial and remotely sensed images using vector order statistics
- **Arxiv ID**: http://arxiv.org/abs/1503.05692v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05692v1)
- **Published**: 2015-03-19 10:18:05+00:00
- **Updated**: 2015-03-19 10:18:05+00:00
- **Authors**: B O. Sadiq, S. M. Sani, S. Garba
- **Comment**: 9 pages, 11 figures
- **Journal**: None
- **Summary**: This paper presents an improved edge detection algorithm for facial and remotely sensed images using vector order statistics. The developed algorithm processes colored images directly without been converted to gray scale. A number of the existing algorithms converts the colored images into gray scale before detection of edges. But this process leads to inaccurate precision of recognized edges, thus producing false and broken edges in the output edge map. Facial and remotely sensed images consist of curved edge lines which have to be detected continuously to prevent broken edges. In order to deal with this, a collection of pixel approach is introduced with a view to minimizing the false and broken edges that exists in the generated output edge map of facial and remotely sensed images.



### Automatic Pollen Grain and Exine Segmentation from Microscope Images
- **Arxiv ID**: http://arxiv.org/abs/1503.05767v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05767v1)
- **Published**: 2015-03-19 13:58:15+00:00
- **Updated**: 2015-03-19 13:58:15+00:00
- **Authors**: François Chung, Tomás Rodríguez
- **Comment**: None
- **Journal**: None
- **Summary**: In this article, we propose an automatic method for the segmentation of pollen grains from microscope images, followed by the automatic segmentation of their exine. The objective of exine segmentation is to separate the pollen grain in two regions of interest: exine and inner part. A coarse-to-fine approach ensures a smooth and accurate segmentation of both structures. As a rough stage, grain segmentation is performed by a procedure involving clustering and morphological operations, while the exine is approximated by an iterative procedure consisting in consecutive cropping steps of the pollen grain. A snake-based segmentation is performed to refine the segmentation of both structures. Results have shown that our segmentation method is able to deal with different pollen types, as well as with different types of exine and inner part appearance. The proposed segmentation method aims to be generic and has been designed as one of the core steps of an automatic pollen classification framework.



### On learning optimized reaction diffusion processes for effective image restoration
- **Arxiv ID**: http://arxiv.org/abs/1503.05768v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05768v2)
- **Published**: 2015-03-19 14:01:42+00:00
- **Updated**: 2015-03-25 19:59:44+00:00
- **Authors**: Yunjin Chen, Wei Yu, Thomas Pock
- **Comment**: 9 pages, 3 figures, 3 tables. CVPR2015 oral presentation together
  with the supplemental material of 13 pages, 8 pages (Notes on diffusion
  networks)
- **Journal**: None
- **Summary**: For several decades, image restoration remains an active research topic in low-level computer vision and hence new approaches are constantly emerging. However, many recently proposed algorithms achieve state-of-the-art performance only at the expense of very high computation time, which clearly limits their practical relevance. In this work, we propose a simple but effective approach with both high computational efficiency and high restoration quality. We extend conventional nonlinear reaction diffusion models by several parametrized linear filters as well as several parametrized influence functions. We propose to train the parameters of the filters and the influence functions through a loss based approach. Experiments show that our trained nonlinear reaction diffusion models largely benefit from the training of the parameters and finally lead to the best reported performance on common test datasets for image restoration. Due to their structural simplicity, our trained models are highly efficient and are also well-suited for parallel computation on GPUs.



### Learning Hypergraph-regularized Attribute Predictors
- **Arxiv ID**: http://arxiv.org/abs/1503.05782v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1503.05782v1)
- **Published**: 2015-03-19 14:31:56+00:00
- **Updated**: 2015-03-19 14:31:56+00:00
- **Authors**: Sheng Huang, Mohamed Elhoseiny, Ahmed Elgammal, Dan Yang
- **Comment**: This is an attribute learning paper accepted by CVPR 2015
- **Journal**: None
- **Summary**: We present a novel attribute learning framework named Hypergraph-based Attribute Predictor (HAP). In HAP, a hypergraph is leveraged to depict the attribute relations in the data. Then the attribute prediction problem is casted as a regularized hypergraph cut problem in which HAP jointly learns a collection of attribute projections from the feature space to a hypergraph embedding space aligned with the attribute space. The learned projections directly act as attribute classifiers (linear and kernelized). This formulation leads to a very efficient approach. By considering our model as a multi-graph cut task, our framework can flexibly incorporate other available information, in particular class label. We apply our approach to attribute prediction, Zero-shot and $N$-shot learning tasks. The results on AWA, USAA and CUB databases demonstrate the value of our methods in comparison with the state-of-the-art approaches.



### A General Framework for Multi-focal Image Classification and Authentication: Application to Microscope Pollen Images
- **Arxiv ID**: http://arxiv.org/abs/1503.05786v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05786v1)
- **Published**: 2015-03-19 14:44:29+00:00
- **Updated**: 2015-03-19 14:44:29+00:00
- **Authors**: François Chung, Tomás Rodríguez
- **Comment**: None
- **Journal**: None
- **Summary**: In this article, we propose a general framework for multi-focal image classification and authentication, the methodology being demonstrated on microscope pollen images. The framework is meant to be generic and based on a brute force-like approach aimed to be efficient not only on any kind, and any number, of pollen images (regardless of the pollen type), but also on any kind of multi-focal images. All stages of the framework's pipeline are designed to be used in an automatic fashion. First, the optimal focus is selected using the absolute gradient method. Then, pollen grains are extracted using a coarse-to-fine approach involving both clustering and morphological techniques (coarse stage), and a snake-based segmentation (fine stage). Finally, features are extracted and selected using a generalized approach, and their classification is tested with four classifiers: Weighted Neighbor Distance, Neural Network, Decision Tree and Random Forest. The latter method, which has shown the best and more robust classification accuracy results (above 97\% for any number of pollen types), is finally used for the authentication stage.



### Sign Language Fingerspelling Classification from Depth and Color Images using a Deep Belief Network
- **Arxiv ID**: http://arxiv.org/abs/1503.05830v1
- **DOI**: 10.1109/CRV.2014.20
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05830v1)
- **Published**: 2015-03-19 16:30:10+00:00
- **Updated**: 2015-03-19 16:30:10+00:00
- **Authors**: Lucas Rioux-Maldague, Philippe Giguère
- **Comment**: Published in 2014 Canadian Conference on Computer and Robot Vision
- **Journal**: None
- **Summary**: Automatic sign language recognition is an open problem that has received a lot of attention recently, not only because of its usefulness to signers, but also due to the numerous applications a sign classifier can have. In this article, we present a new feature extraction technique for hand pose recognition using depth and intensity images captured from a Microsoft Kinect sensor. We applied our technique to American Sign Language fingerspelling classification using a Deep Belief Network, for which our feature extraction technique is tailored. We evaluated our results on a multi-user data set with two scenarios: one with all known users and one with an unseen user. We achieved 99% recall and precision on the first, and 77% recall and 79% precision on the second. Our method is also capable of real-time sign classification and is adaptive to any environment or lightning intensity.



### Building Statistical Shape Spaces for 3D Human Modeling
- **Arxiv ID**: http://arxiv.org/abs/1503.05860v2
- **DOI**: 10.1016/j.patcog.2017.02.018
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.05860v2)
- **Published**: 2015-03-19 17:59:57+00:00
- **Updated**: 2017-03-03 20:44:19+00:00
- **Authors**: Leonid Pishchulin, Stefanie Wuhrer, Thomas Helten, Christian Theobalt, Bernt Schiele
- **Comment**: Published in Pattern Recognition 2017
- **Journal**: None
- **Summary**: Statistical models of 3D human shape and pose learned from scan databases have developed into valuable tools to solve a variety of vision and graphics problems. Unfortunately, most publicly available models are of limited expressiveness as they were learned on very small databases that hardly reflect the true variety in human body shapes. In this paper, we contribute by rebuilding a widely used statistical body representation from the largest commercially available scan database, and making the resulting model available to the community (visit http://humanshape.mpi-inf.mpg.de). As preprocessing several thousand scans for learning the model is a challenge in itself, we contribute by developing robust best practice solutions for scan alignment that quantitatively lead to the best learned models. We make implementations of these preprocessing steps also publicly available. We extensively evaluate the improved accuracy and generality of our new model, and show its improved performance for human body reconstruction from sparse input data.



### Reduced Basis Decomposition: a Certified and Fast Lossy Data Compression Algorithm
- **Arxiv ID**: http://arxiv.org/abs/1503.05947v1
- **DOI**: None
- **Categories**: **math.NA**, cs.AI, cs.CV, cs.NA
- **Links**: [PDF](http://arxiv.org/pdf/1503.05947v1)
- **Published**: 2015-03-19 21:10:57+00:00
- **Updated**: 2015-03-19 21:10:57+00:00
- **Authors**: Yanlai Chen
- **Comment**: None
- **Journal**: None
- **Summary**: Dimension reduction is often needed in the area of data mining. The goal of these methods is to map the given high-dimensional data into a low-dimensional space preserving certain properties of the initial data. There are two kinds of techniques for this purpose. The first, projective methods, builds an explicit linear projection from the high-dimensional space to the low-dimensional one. On the other hand, the nonlinear methods utilizes nonlinear and implicit mapping between the two spaces. In both cases, the methods considered in literature have usually relied on computationally very intensive matrix factorizations, frequently the Singular Value Decomposition (SVD). The computational burden of SVD quickly renders these dimension reduction methods infeasible thanks to the ever-increasing sizes of the practical datasets.   In this paper, we present a new decomposition strategy, Reduced Basis Decomposition (RBD), which is inspired by the Reduced Basis Method (RBM). Given $X$ the high-dimensional data, the method approximates it by $Y \, T (\approx X)$ with $Y$ being the low-dimensional surrogate and $T$ the transformation matrix. $Y$ is obtained through a greedy algorithm thus extremely efficient. In fact, it is significantly faster than SVD with comparable accuracy. $T$ can be computed on the fly. Moreover, unlike many compression algorithms, it easily finds the mapping for an arbitrary ``out-of-sample'' vector and it comes with an ``error indicator'' certifying the accuracy of the compression. Numerical results are shown validating these claims.



