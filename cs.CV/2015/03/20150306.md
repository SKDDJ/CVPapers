# Arxiv Papers in cs.CV on 2015-03-06
### Latent Hierarchical Model for Activity Recognition
- **Arxiv ID**: http://arxiv.org/abs/1503.01820v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1503.01820v1)
- **Published**: 2015-03-06 00:05:12+00:00
- **Updated**: 2015-03-06 00:05:12+00:00
- **Authors**: Ninghang Hu, Gwenn Englebienne, Zhongyu Lou, Ben Kr√∂se
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel hierarchical model for human activity recognition. In contrast to approaches that successively recognize actions and activities, our approach jointly models actions and activities in a unified framework, and their labels are simultaneously predicted. The model is embedded with a latent layer that is able to capture a richer class of contextual information in both state-state and observation-state pairs. Although loops are present in the model, the model has an overall linear-chain structure, where the exact inference is tractable. Therefore, the model is very efficient in both inference and learning. The parameters of the graphical model are learned with a Structured Support Vector Machine (Structured-SVM). A data-driven approach is used to initialize the latent variables; therefore, no manual labeling for the latent states is required. The experimental results from using two benchmark datasets show that our model outperforms the state-of-the-art approach, and our model is computationally more efficient.



### Linear Global Translation Estimation with Feature Tracks
- **Arxiv ID**: http://arxiv.org/abs/1503.01832v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.01832v2)
- **Published**: 2015-03-06 02:14:14+00:00
- **Updated**: 2015-09-04 01:36:59+00:00
- **Authors**: Zhaopeng Cui, Nianjuan Jiang, Chengzhou Tang, Ping Tan
- **Comment**: Changes: 1. Adopt BMVC2015 style; 2. Combine sections 3 and 5; 3.
  Move "Evaluation on synthetic data" out to supplementary file; 4. Divide
  subsection "Evaluation on general data" to subsections "Experiment on
  sequential data" and "Experiment on unordered Internet data"; 5. Change Fig.
  1 and Fig.8; 6. Move Fig. 6 and Fig. 7 to supplementary file; 7 Change some
  symbols; 8. Correct some typos
- **Journal**: None
- **Summary**: This paper derives a novel linear position constraint for cameras seeing a common scene point, which leads to a direct linear method for global camera translation estimation. Unlike previous solutions, this method deals with collinear camera motion and weak image association at the same time. The final linear formulation does not involve the coordinates of scene points, which makes it efficient even for large scale data. We solve the linear equation based on $L_1$ norm, which makes our system more robust to outliers in essential matrices and feature correspondences. We experiment this method on both sequentially captured images and unordered Internet images. The experiments demonstrate its strength in robustness, accuracy, and efficiency.



### Total Variation Regularized Tensor RPCA for Background Subtraction from Compressive Measurements
- **Arxiv ID**: http://arxiv.org/abs/1503.01868v4
- **DOI**: 10.1109/TIP.2016.2579262
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.01868v4)
- **Published**: 2015-03-06 08:00:43+00:00
- **Updated**: 2016-06-05 17:46:14+00:00
- **Authors**: Wenfei Cao, Yao Wang, Jian Sun, Deyu Meng, Can Yang, Andrzej Cichocki, Zongben Xu
- **Comment**: To appear in IEEE TIP
- **Journal**: None
- **Summary**: Background subtraction has been a fundamental and widely studied task in video analysis, with a wide range of applications in video surveillance, teleconferencing and 3D modeling. Recently, motivated by compressive imaging, background subtraction from compressive measurements (BSCM) is becoming an active research task in video surveillance. In this paper, we propose a novel tensor-based robust PCA (TenRPCA) approach for BSCM by decomposing video frames into backgrounds with spatial-temporal correlations and foregrounds with spatio-temporal continuity in a tensor framework. In this approach, we use 3D total variation (TV) to enhance the spatio-temporal continuity of foregrounds, and Tucker decomposition to model the spatio-temporal correlations of video background. Based on this idea, we design a basic tensor RPCA model over the video frames, dubbed as the holistic TenRPCA model (H-TenRPCA). To characterize the correlations among the groups of similar 3D patches of video background, we further design a patch-group-based tensor RPCA model (PG-TenRPCA) by joint tensor Tucker decompositions of 3D patch groups for modeling the video background. Efficient algorithms using alternating direction method of multipliers (ADMM) are developed to solve the proposed models. Extensive experiments on simulated and real-world videos demonstrate the superiority of the proposed approaches over the existing state-of-the-art approaches.



### Partial light field tomographic reconstruction from a fixed-camera focal stack
- **Arxiv ID**: http://arxiv.org/abs/1503.01903v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1503.01903v1)
- **Published**: 2015-03-06 10:50:40+00:00
- **Updated**: 2015-03-06 10:50:40+00:00
- **Authors**: A. Mousnier, E. Vural, C. Guillemot
- **Comment**: None
- **Journal**: None
- **Summary**: This paper describes a novel approach to partially reconstruct high-resolution 4D light fields from a stack of differently focused photographs taken with a fixed camera. First, a focus map is calculated from this stack using a simple approach combining gradient detection and region expansion with graph-cut. Then, this focus map is converted into a depth map thanks to the calibration of the camera. We proceed after this with the tomographic reconstruction of the epipolar images by back-projecting the focused regions of the scene only. We call it masked back-projection. The angles of back-projection are calculated from the depth map. Thanks to the high angular resolution we achieve by suitably exploiting the image content captured over a large interval of focus distances, we are able to render puzzling perspective shifts although the original photographs were taken from a single fixed camera at a fixed position.



### Fast image-based obstacle detection from unmanned surface vehicles
- **Arxiv ID**: http://arxiv.org/abs/1503.01918v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.01918v1)
- **Published**: 2015-03-06 11:21:07+00:00
- **Updated**: 2015-03-06 11:21:07+00:00
- **Authors**: Matej Kristan, Vildana Sulic, Stanislav Kovacic, Janez Pers
- **Comment**: This is an extended version of the ACCV2014 paper [Kristan et al.,
  2014] submitted to a journal. [Kristan et al., 2014] M. Kristan, J. Pers, V.
  Sulic, S. Kovacic, A graphical model for rapid obstacle image-map estimation
  from unmanned surface vehicles, in Proc. Asian Conf. Computer Vision, 2014
- **Journal**: None
- **Summary**: Obstacle detection plays an important role in unmanned surface vehicles (USV). The USVs operate in highly diverse environments in which an obstacle may be a floating piece of wood, a scuba diver, a pier, or a part of a shoreline, which presents a significant challenge to continuous detection from images taken onboard. This paper addresses the problem of online detection by constrained unsupervised segmentation. To this end, a new graphical model is proposed that affords a fast and continuous obstacle image-map estimation from a single video stream captured onboard a USV. The model accounts for the semantic structure of marine environment as observed from USV by imposing weak structural constraints. A Markov random field framework is adopted and a highly efficient algorithm for simultaneous optimization of model parameters and segmentation mask estimation is derived. Our approach does not require computationally intensive extraction of texture features and comfortably runs in real-time. The algorithm is tested on a new, challenging, dataset for segmentation and obstacle detection in marine environments, which is the largest annotated dataset of its kind. Results on this dataset show that our model outperforms the related approaches, while requiring a fraction of computational effort.



### Convex Color Image Segmentation with Optimal Transport Distances
- **Arxiv ID**: http://arxiv.org/abs/1503.01986v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.01986v2)
- **Published**: 2015-03-06 15:19:19+00:00
- **Updated**: 2015-03-16 09:23:19+00:00
- **Authors**: Julien Rabin, Nicolas Papadakis
- **Comment**: A short version of this report has been submitted to the Fifth
  International Conference on Scale Space and Variational Methods in Computer
  Vision (SSVM) 2015
- **Journal**: None
- **Summary**: This work is about the use of regularized optimal-transport distances for convex, histogram-based image segmentation. In the considered framework, fixed exemplar histograms define a prior on the statistical features of the two regions in competition. In this paper, we investigate the use of various transport-based cost functions as discrepancy measures and rely on a primal-dual algorithm to solve the obtained convex optimization problem.



### Tomographic Image Reconstruction using Training images
- **Arxiv ID**: http://arxiv.org/abs/1503.01993v2
- **DOI**: None
- **Categories**: **cs.CV**, math.NA, 65F22, 65K10
- **Links**: [PDF](http://arxiv.org/pdf/1503.01993v2)
- **Published**: 2015-03-06 15:47:45+00:00
- **Updated**: 2015-08-17 09:34:37+00:00
- **Authors**: Sara Soltani, Martin S. Andersen, Per Christian Hansen
- **Comment**: 25 pages, 12 figures
- **Journal**: None
- **Summary**: We describe and examine an algorithm for tomographic image reconstruction where prior knowledge about the solution is available in the form of training images. We first construct a nonnegative dictionary based on prototype elements from the training images; this problem is formulated as a regularized non-negative matrix factorization. Incorporating the dictionary as a prior in a convex reconstruction problem, we then find an approximate solution with a sparse representation in the dictionary. The dictionary is applied to non-overlapping patches of the image, which reduces the computational complexity compared to other algorithms. Computational experiments clarify the choice and interplay of the model parameters and the regularization parameters, and we show that in few-projection low-dose settings our algorithm is competitive with total variation regularization and tends to include more texture and more correct edges.



### On the Invariance of Dictionary Learning and Sparse Representation to Projecting Data to a Discriminative Space
- **Arxiv ID**: http://arxiv.org/abs/1503.02041v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.02041v2)
- **Published**: 2015-03-06 19:41:09+00:00
- **Updated**: 2015-06-11 15:25:49+00:00
- **Authors**: Mehrdad J. Gangeh, Ali Ghodsi
- **Comment**: We would like to withdraw this paper as it seems that the proof
  provided in the paper is not including all the cases mentioned
- **Journal**: None
- **Summary**: In this paper, it is proved that dictionary learning and sparse representation is invariant to a linear transformation. It subsumes the special case of transforming/projecting the data into a discriminative space. This is important because recently, supervised dictionary learning algorithms have been proposed, which suggest to include the category information into the learning of dictionary to improve its discriminative power. Among them, there are some approaches that propose to learn the dictionary in a discriminative projected space. To this end, two approaches have been proposed: first, assigning the discriminative basis as the dictionary and second, perform dictionary learning in the projected space. Based on the invariance of dictionary learning to any transformation in general, and to a discriminative space in particular, we advocate the first approach.



### Band selection in RKHS for fast nonlinear unmixing of hyperspectral images
- **Arxiv ID**: http://arxiv.org/abs/1503.02090v1
- **DOI**: 10.1109/EUSIPCO.2015.7362664
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.02090v1)
- **Published**: 2015-03-06 21:20:15+00:00
- **Updated**: 2015-03-06 21:20:15+00:00
- **Authors**: T. Imbiriba, J. C. M. Bermudez, C. Richard, J. -Y. Tourneret
- **Comment**: None
- **Journal**: None
- **Summary**: The profusion of spectral bands generated by the acquisition process of hyperspectral images generally leads to high computational costs. Such difficulties arise in particular with nonlinear unmixing methods, which are naturally more complex than linear ones. This complexity, associated with the high redundancy of information within the complete set of bands, make the search of band selection algorithms relevant. With this work, we propose a band selection strategy in reproducing kernel Hilbert spaces that allows to drastically reduce the processing time required by nonlinear unmixing techniques. Simulation results show a complexity reduction of two orders of magnitude without compromising unmixing performance.



