# Arxiv Papers in cs.CV on 2015-03-14
### Novel Super-Resolution Method Based on High Order Nonlocal-Means
- **Arxiv ID**: http://arxiv.org/abs/1503.04253v3
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1503.04253v3)
- **Published**: 2015-03-14 00:16:06+00:00
- **Updated**: 2015-06-17 08:24:52+00:00
- **Authors**: Kang Yong-Rim, Kim Yong-Jin
- **Comment**: 1 table
- **Journal**: None
- **Summary**: Super-resolution without explicit sub-pixel motion estimation is a very active subject of image reconstruction containing general motion. The Non-Local Means (NLM) method is a simple image reconstruction method without explicit motion estimation. In this paper we generalize NLM method to higher orders using kernel regression can apply to super-resolution reconstruction. The performance of the generalized method is compared with other methods.



### A Dictionary-based Approach for Estimating Shape and Spatially-Varying Reflectance
- **Arxiv ID**: http://arxiv.org/abs/1503.04265v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.04265v1)
- **Published**: 2015-03-14 04:24:23+00:00
- **Updated**: 2015-03-14 04:24:23+00:00
- **Authors**: Zhuo Hui, Aswin C. Sankaranarayanan
- **Comment**: IEEE Intl. Conf. Computational Photography, 2015
- **Journal**: None
- **Summary**: We present a technique for estimating the shape and reflectance of an object in terms of its surface normals and spatially-varying BRDF. We assume that multiple images of the object are obtained under fixed view-point and varying illumination, i.e, the setting of photometric stereo. Assuming that the BRDF at each pixel lies in the non-negative span of a known BRDF dictionary, we derive a per-pixel surface normal and BRDF estimation framework that requires neither iterative optimization techniques nor careful initialization, both of which are endemic to most state-of-the-art techniques. We showcase the performance of our technique on a wide range of simulated and real scenes where we outperform competing methods.



### LiSens --- A Scalable Architecture for Video Compressive Sensing
- **Arxiv ID**: http://arxiv.org/abs/1503.04267v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.04267v1)
- **Published**: 2015-03-14 04:36:07+00:00
- **Updated**: 2015-03-14 04:36:07+00:00
- **Authors**: Jian Wang, Mohit Gupta, Aswin C. Sankaranarayanan
- **Comment**: IEEE Intl. Conf. Computational Photography, 2015
- **Journal**: None
- **Summary**: The measurement rate of cameras that take spatially multiplexed measurements by using spatial light modulators (SLM) is often limited by the switching speed of the SLMs. This is especially true for single-pixel cameras where the photodetector operates at a rate that is many orders-of-magnitude greater than the SLM. We study the factors that determine the measurement rate for such spatial multiplexing cameras (SMC) and show that increasing the number of pixels in the device improves the measurement rate, but there is an optimum number of pixels (typically, few thousands) beyond which the measurement rate does not increase. This motivates the design of LiSens, a novel imaging architecture, that replaces the photodetector in the single-pixel camera with a 1D linear array or a line-sensor. We illustrate the optical architecture underlying LiSens, build a prototype, and demonstrate results of a range of indoor and outdoor scenes. LiSens delivers on the promise of SMCs: imaging at a megapixel resolution, at video rate, using an inexpensive low-resolution sensor.



### Metric Localization using Google Street View
- **Arxiv ID**: http://arxiv.org/abs/1503.04287v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1503.04287v2)
- **Published**: 2015-03-14 10:22:39+00:00
- **Updated**: 2015-04-16 16:15:55+00:00
- **Authors**: Pratik Agarwal, Wolfram Burgard, Luciano Spinello
- **Comment**: 8 pages, 11 figures. 2 tables
- **Journal**: None
- **Summary**: Accurate metrical localization is one of the central challenges in mobile robotics. Many existing methods aim at localizing after building a map with the robot. In this paper, we present a novel approach that instead uses geotagged panoramas from the Google Street View as a source of global positioning. We model the problem of localization as a non-linear least squares estimation in two phases. The first estimates the 3D position of tracked feature points from short monocular camera sequences. The second computes the rigid body transformation between the Street View panoramas and the estimated points. The only input of this approach is a stream of monocular camera images and odometry estimates. We quantified the accuracy of the method by running the approach on a robotic platform in a parking lot by using visual fiducials as ground truth. Additionally, we applied the approach in the context of personal localization in a real urban scenario by using data from a Google Tango tablet.



### Content-Based Bird Retrieval using Shape context, Color moments and Bag of Features
- **Arxiv ID**: http://arxiv.org/abs/1503.07816v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1503.07816v1)
- **Published**: 2015-03-14 11:02:14+00:00
- **Updated**: 2015-03-14 11:02:14+00:00
- **Authors**: Bahri Abdelkhalak, Hamid Zouaki
- **Comment**: 5 pages, 2 figures, IJCSI
- **Journal**: None
- **Summary**: In this paper we propose a new descriptor for birds search. First, our work was carried on the choice of a descriptor. This choice is usually driven by the application requirements such as robustness to noise, stability with respect to bias, the invariance to geometrical transformations or tolerance to occlusions. In this context, we introduce a descriptor which combines the shape and color descriptors to have an effectiveness description of birds. The proposed descriptor is an adaptation of a descriptor based on the contours defined in article Belongie et al. [5] combined with color moments [19]. Specifically, points of interest are extracted from each image and information's in the region in the vicinity of these points are represented by descriptors of shape context concatenated with color moments. Thus, the approach bag of visual words is applied to the latter. The experimental results show the effectiveness of our descriptor for the bird search by content.



### Towards radio astronomical imaging using an arbitrary basis
- **Arxiv ID**: http://arxiv.org/abs/1503.04338v2
- **DOI**: None
- **Categories**: **astro-ph.IM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1503.04338v2)
- **Published**: 2015-03-14 19:56:00+00:00
- **Updated**: 2015-04-11 14:03:46+00:00
- **Authors**: Matthias Petschow
- **Comment**: None
- **Journal**: None
- **Summary**: The new generation of radio telescopes, such as the Square Kilometer Array (SKA), requires dramatic advances in computer hardware and software, in order to process the large amounts of produced data efficiently. In this document, we explore a new approach to wide-field imaging. By generalizing the image reconstruction, which is performed by an inverse Fourier transform, to arbitrary transformations, we gain enormous new possibilities. In particular, we outline an approach that might allow to obtain a sky image of size P times Q in (optimal) O(PQ) time. This could be a step in the direction of real-time, wide-field sky imaging for future telescopes.



