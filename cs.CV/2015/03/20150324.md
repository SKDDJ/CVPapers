# Arxiv Papers in cs.CV on 2015-03-24
### Unsupervised Video Analysis Based on a Spatiotemporal Saliency Detector
- **Arxiv ID**: http://arxiv.org/abs/1503.06917v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.06917v1)
- **Published**: 2015-03-24 05:25:45+00:00
- **Updated**: 2015-03-24 05:25:45+00:00
- **Authors**: Qiang Zhang, Yilin Wang, Baoxin Li
- **Comment**: 21 pages
- **Journal**: None
- **Summary**: Visual saliency, which predicts regions in the field of view that draw the most visual attention, has attracted a lot of interest from researchers. It has already been used in several vision tasks, e.g., image classification, object detection, foreground segmentation. Recently, the spectrum analysis based visual saliency approach has attracted a lot of interest due to its simplicity and good performance, where the phase information of the image is used to construct the saliency map. In this paper, we propose a new approach for detecting spatiotemporal visual saliency based on the phase spectrum of the videos, which is easy to implement and computationally efficient. With the proposed algorithm, we also study how the spatiotemporal saliency can be used in two important vision task, abnormality detection and spatiotemporal interest point detection. The proposed algorithm is evaluated on several commonly used datasets with comparison to the state-of-art methods from the literature. The experiments demonstrate the effectiveness of the proposed approach to spatiotemporal visual saliency detection and its application to the above vision tasks



### Fast keypoint detection in video sequences
- **Arxiv ID**: http://arxiv.org/abs/1503.06959v1
- **DOI**: 10.1109/ICASSP.2016.7471895
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1503.06959v1)
- **Published**: 2015-03-24 09:28:28+00:00
- **Updated**: 2015-03-24 09:28:28+00:00
- **Authors**: Luca Baroffio, Matteo Cesana, Alessandro Redondi, Marco Tagliasacchi
- **Comment**: submitted to IEEE International Conference on Image Processing 2015
- **Journal**: None
- **Summary**: A number of computer vision tasks exploit a succinct representation of the visual content in the form of sets of local features. Given an input image, feature extraction algorithms identify a set of keypoints and assign to each of them a description vector, based on the characteristics of the visual content surrounding the interest point. Several tasks might require local features to be extracted from a video sequence, on a frame-by-frame basis. Although temporal downsampling has been proven to be an effective solution for mobile augmented reality and visual search, high temporal resolution is a key requirement for time-critical applications such as object tracking, event recognition, pedestrian detection, surveillance. In recent years, more and more computationally efficient visual feature detectors and decriptors have been proposed. Nonetheless, such approaches are tailored to still images. In this paper we propose a fast keypoint detection algorithm for video sequences, that exploits the temporal coherence of the sequence of keypoints. According to the proposed method, each frame is preprocessed so as to identify the parts of the input frame for which keypoint detection and description need to be performed. Our experiments show that it is possible to achieve a reduction in computational time of up to 40%, without significantly affecting the task accuracy.



### Rotation-invariant convolutional neural networks for galaxy morphology prediction
- **Arxiv ID**: http://arxiv.org/abs/1503.07077v1
- **DOI**: 10.1093/mnras/stv632
- **Categories**: **astro-ph.IM**, astro-ph.GA, cs.CV, cs.LG, cs.NE, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1503.07077v1)
- **Published**: 2015-03-24 15:34:06+00:00
- **Updated**: 2015-03-24 15:34:06+00:00
- **Authors**: Sander Dieleman, Kyle W. Willett, Joni Dambre
- **Comment**: Accepted for publication in MNRAS. 20 pages, 14 figures
- **Journal**: None
- **Summary**: Measuring the morphological parameters of galaxies is a key requirement for studying their formation and evolution. Surveys such as the Sloan Digital Sky Survey (SDSS) have resulted in the availability of very large collections of images, which have permitted population-wide analyses of galaxy morphology. Morphological analysis has traditionally been carried out mostly via visual inspection by trained experts, which is time-consuming and does not scale to large ($\gtrsim10^4$) numbers of images.   Although attempts have been made to build automated classification systems, these have not been able to achieve the desired level of accuracy. The Galaxy Zoo project successfully applied a crowdsourcing strategy, inviting online users to classify images by answering a series of questions. Unfortunately, even this approach does not scale well enough to keep up with the increasing availability of galaxy images.   We present a deep neural network model for galaxy morphology classification which exploits translational and rotational symmetry. It was developed in the context of the Galaxy Challenge, an international competition to build the best model for morphology classification based on annotated images from the Galaxy Zoo project.   For images with high agreement among the Galaxy Zoo participants, our model is able to reproduce their consensus with near-perfect accuracy ($> 99\%$) for most questions. Confident model predictions are highly accurate, which makes the model suitable for filtering large collections of images and forwarding challenging images to experts for manual annotation. This approach greatly reduces the experts' workload without affecting accuracy. The application of these algorithms to larger sets of training data will be critical for analysing results from future surveys such as the LSST.



