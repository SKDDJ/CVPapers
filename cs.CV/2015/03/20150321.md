# Arxiv Papers in cs.CV on 2015-03-21
### Skin Detection of Animation Characters
- **Arxiv ID**: http://arxiv.org/abs/1503.06275v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.06275v1)
- **Published**: 2015-03-21 07:36:47+00:00
- **Updated**: 2015-03-21 07:36:47+00:00
- **Authors**: Kazi Tanvir Ahmed Siddiqui, Abu Wasif
- **Comment**: None
- **Journal**: None
- **Summary**: The increasing popularity of animes makes it vulnerable to unwanted usages like copyright violations and pornography. That is why, we need to develop a method to detect and recognize animation characters. Skin detection is one of the most important steps in this way. Though there are some methods to detect human skin color, but those methods do not work properly for anime characters. Anime skin varies greatly from human skin in color, texture, tone and in different kinds of lighting. They also vary greatly among themselves. Moreover, many other things (for example leather, shirt, hair etc.), which are not skin, can have color similar to skin. In this paper, we have proposed three methods that can identify an anime character skin more successfully as compared with Kovac, Swift, Saleh and Osman methods, which are primarily designed for human skin detection. Our methods are based on RGB values and their comparative relations.



### Wavelet based approach for tissue fractal parameter measurement: Pre cancer detection
- **Arxiv ID**: http://arxiv.org/abs/1503.06323v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.06323v1)
- **Published**: 2015-03-21 17:09:40+00:00
- **Updated**: 2015-03-21 17:09:40+00:00
- **Authors**: Sabyasachi Mukhopadhyay, Nandan K. Das, Soham Mandal, Sawon Pratiher, Asish Mitra, Asima Pradhan, Nirmalya Ghosh, Prasanta K. Panigrahi
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we have carried out the detail studies of pre-cancer by wavelet coherency and multifractal based detrended fluctuation analysis (MFDFA) on differential interference contrast (DIC) images of stromal region among different grades of pre-cancer tissues. Discrete wavelet transform (DWT) through Daubechies basis has been performed for identifying fluctuations over polynomial trends for clear characterization and differentiation of tissues. Wavelet coherence plots are performed for identifying the level of correlation in time scale plane between normal and various grades of DIC samples. Applying MFDFA on refractive index variations of cervical tissues, we have observed that the values of Hurst exponent (correlation) decreases from healthy (normal) to pre-cancer tissues. The width of singularity spectrum has a sudden degradation at grade-I in comparison of healthy (normal) tissue but later on it increases as cancer progresses from grade-II to grade-III.



### Boosting Convolutional Features for Robust Object Proposals
- **Arxiv ID**: http://arxiv.org/abs/1503.06350v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1503.06350v1)
- **Published**: 2015-03-21 20:54:39+00:00
- **Updated**: 2015-03-21 20:54:39+00:00
- **Authors**: Nikolaos Karianakis, Thomas J. Fuchs, Stefano Soatto
- **Comment**: 9 pages, 4 figures, 2 tables, 42 references
- **Journal**: None
- **Summary**: Deep Convolutional Neural Networks (CNNs) have demonstrated excellent performance in image classification, but still show room for improvement in object-detection tasks with many categories, in particular for cluttered scenes and occlusion. Modern detection algorithms like Regions with CNNs (Girshick et al., 2014) rely on Selective Search (Uijlings et al., 2013) to propose regions which with high probability represent objects, where in turn CNNs are deployed for classification. Selective Search represents a family of sophisticated algorithms that are engineered with multiple segmentation, appearance and saliency cues, typically coming with a significant run-time overhead. Furthermore, (Hosang et al., 2014) have shown that most methods suffer from low reproducibility due to unstable superpixels, even for slight image perturbations. Although CNNs are subsequently used for classification in top-performing object-detection pipelines, current proposal methods are agnostic to how these models parse objects and their rich learned representations. As a result they may propose regions which may not resemble high-level objects or totally miss some of them. To overcome these drawbacks we propose a boosting approach which directly takes advantage of hierarchical CNN features for detecting regions of interest fast. We demonstrate its performance on ImageNet 2013 detection benchmark and compare it with state-of-the-art methods.



