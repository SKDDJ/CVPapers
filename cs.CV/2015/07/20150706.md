# Arxiv Papers in cs.CV on 2015-07-06
### Visual Data Deblocking using Structural Layer Priors
- **Arxiv ID**: http://arxiv.org/abs/1507.01330v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.01330v1)
- **Published**: 2015-07-06 05:34:41+00:00
- **Updated**: 2015-07-06 05:34:41+00:00
- **Authors**: Xiaojie Guo
- **Comment**: None
- **Journal**: None
- **Summary**: The blocking artifact frequently appears in compressed real-world images or video sequences, especially coded at low bit rates, which is visually annoying and likely hurts the performance of many computer vision algorithms. A compressed frame can be viewed as the superimposition of an intrinsic layer and an artifact one. Recovering the two layers from such frames seems to be a severely ill-posed problem since the number of unknowns to recover is twice as many as the given measurements. In this paper, we propose a simple and robust method to separate these two layers, which exploits structural layer priors including the gradient sparsity of the intrinsic layer, and the independence of the gradient fields of the two layers. A novel Augmented Lagrangian Multiplier based algorithm is designed to efficiently and effectively solve the recovery problem. Extensive experimental results demonstrate the superior performance of our method over the state of the arts, in terms of visual quality and simplicity.



### End-to-end Convolutional Network for Saliency Prediction
- **Arxiv ID**: http://arxiv.org/abs/1507.01422v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1507.01422v1)
- **Published**: 2015-07-06 12:43:26+00:00
- **Updated**: 2015-07-06 12:43:26+00:00
- **Authors**: Junting Pan, Xavier Gir√≥-i-Nieto
- **Comment**: Winner of the saliency prediction challenge in the Large-scale Scene
  Understanding (LSUN) Challenge in the associated workshop of the IEEE
  Conference on Computer Vision and Pattern Recognition (CVPR) 2015
- **Journal**: None
- **Summary**: The prediction of saliency areas in images has been traditionally addressed with hand crafted features based on neuroscience principles. This paper however addresses the problem with a completely data-driven approach by training a convolutional network. The learning process is formulated as a minimization of a loss function that measures the Euclidean distance of the predicted saliency map with the provided ground truth. The recent publication of large datasets of saliency prediction has provided enough data to train a not very deep architecture which is both fast and accurate. The convolutional network in this paper, named JuntingNet, won the LSUN 2015 challenge on saliency prediction with a superior performance in all considered metrics.



### Learning Better Encoding for Approximate Nearest Neighbor Search with Dictionary Annealing
- **Arxiv ID**: http://arxiv.org/abs/1507.01442v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.01442v1)
- **Published**: 2015-07-06 13:25:35+00:00
- **Updated**: 2015-07-06 13:25:35+00:00
- **Authors**: Shicong Liu, Hongtao Lu
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: We introduce a novel dictionary optimization method for high-dimensional vector quantization employed in approximate nearest neighbor (ANN) search. Vector quantization methods first seek a series of dictionaries, then approximate each vector by a sum of elements selected from these dictionaries. An optimal series of dictionaries should be mutually independent, and each dictionary should generate a balanced encoding for the target dataset. Existing methods did not explicitly consider this. To achieve these goals along with minimizing the quantization error (residue), we propose a novel dictionary optimization method called \emph{Dictionary Annealing} that alternatively "heats up" a single dictionary by generating an intermediate dataset with residual vectors, "cools down" the dictionary by fitting the intermediate dataset, then extracts the new residual vectors for the next iteration. Better codes can be learned by DA for the ANN search tasks. DA is easily implemented on GPU to utilize the latest computing technology, and can easily extended to an online dictionary learning scheme. We show by experiments that our optimized dictionaries substantially reduce the overall quantization error. Jointly used with residual vector quantization, our optimized dictionaries lead to a better approximate nearest neighbor search performance compared to the state-of-the-art methods.



### Joint Calibration for Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/1507.01581v4
- **DOI**: None
- **Categories**: **cs.CV**, 68T45
- **Links**: [PDF](http://arxiv.org/pdf/1507.01581v4)
- **Published**: 2015-07-06 19:55:18+00:00
- **Updated**: 2015-08-12 14:20:08+00:00
- **Authors**: Holger Caesar, Jasper Uijlings, Vittorio Ferrari
- **Comment**: Includes improved results based on VGG16 CNN
- **Journal**: BMVC 2015
- **Summary**: Semantic segmentation is the task of assigning a class-label to each pixel in an image. We propose a region-based semantic segmentation framework which handles both full and weak supervision, and addresses three common problems: (1) Objects occur at multiple scales and therefore we should use regions at multiple scales. However, these regions are overlapping which creates conflicting class predictions at the pixel-level. (2) Class frequencies are highly imbalanced in realistic datasets. (3) Each pixel can only be assigned to a single class, which creates competition between classes. We address all three problems with a joint calibration method which optimizes a multi-class loss defined over the final pixel-level output labeling, as opposed to simply region classification. Our method outperforms the state-of-the-art on the popular SIFT Flow [18] dataset in both the fully and weakly supervised setting by a considerably margin (+6% and +10%, respectively).



