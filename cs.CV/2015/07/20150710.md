# Arxiv Papers in cs.CV on 2015-07-10
### Riemannian Dictionary Learning and Sparse Coding for Positive Definite Matrices
- **Arxiv ID**: http://arxiv.org/abs/1507.02772v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.02772v2)
- **Published**: 2015-07-10 03:18:50+00:00
- **Updated**: 2015-12-17 03:33:50+00:00
- **Authors**: Anoop Cherian, Suvrit Sra
- **Comment**: None
- **Journal**: None
- **Summary**: Data encoded as symmetric positive definite (SPD) matrices frequently arise in many areas of computer vision and machine learning. While these matrices form an open subset of the Euclidean space of symmetric matrices, viewing them through the lens of non-Euclidean Riemannian geometry often turns out to be better suited in capturing several desirable data properties. However, formulating classical machine learning algorithms within such a geometry is often non-trivial and computationally expensive. Inspired by the great success of dictionary learning and sparse coding for vector-valued data, our goal in this paper is to represent data in the form of SPD matrices as sparse conic combinations of SPD atoms from a learned dictionary via a Riemannian geometric approach. To that end, we formulate a novel Riemannian optimization objective for dictionary learning and sparse coding in which the representation loss is characterized via the affine invariant Riemannian metric. We also present a computationally simple algorithm for optimizing our model. Experiments on several computer vision datasets demonstrate superior classification and retrieval performance using our approach when compared to sparse coding via alternative non-Riemannian formulations.



### Robust Performance-driven 3D Face Tracking in Long Range Depth Scenes
- **Arxiv ID**: http://arxiv.org/abs/1507.02779v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.02779v1)
- **Published**: 2015-07-10 04:52:36+00:00
- **Updated**: 2015-07-10 04:52:36+00:00
- **Authors**: Hai X. Pham, Chongyu Chen, Luc N. Dao, Vladimir Pavlovic, Jianfei Cai, Tat-jen Cham
- **Comment**: 10 pages, 8 figures, 4 tables
- **Journal**: None
- **Summary**: We introduce a novel robust hybrid 3D face tracking framework from RGBD video streams, which is capable of tracking head pose and facial actions without pre-calibration or intervention from a user. In particular, we emphasize on improving the tracking performance in instances where the tracked subject is at a large distance from the cameras, and the quality of point cloud deteriorates severely. This is accomplished by the combination of a flexible 3D shape regressor and the joint 2D+3D optimization on shape parameters. Our approach fits facial blendshapes to the point cloud of the human head, while being driven by an efficient and rapid 3D shape regressor trained on generic RGB datasets. As an on-line tracking system, the identity of the unknown user is adapted on-the-fly resulting in improved 3D model reconstruction and consequently better tracking performance. The result is a robust RGBD face tracker, capable of handling a wide range of target scene depths, beyond those that can be afforded by traditional depth or RGB face trackers. Lastly, since the blendshape is not able to accurately recover the real facial shape, we use the tracked 3D face model as a prior in a novel filtering process to further refine the depth map for use in other tasks, such as 3D reconstruction.



### Deep Perceptual Mapping for Thermal to Visible Face Recognition
- **Arxiv ID**: http://arxiv.org/abs/1507.02879v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.02879v1)
- **Published**: 2015-07-10 12:55:34+00:00
- **Updated**: 2015-07-10 12:55:34+00:00
- **Authors**: M. Saquib Sarfraz, Rainer Stiefelhagen
- **Comment**: BMVC 2015 (oral)
- **Journal**: None
- **Summary**: Cross modal face matching between the thermal and visible spectrum is a much de- sired capability for night-time surveillance and security applications. Due to a very large modality gap, thermal-to-visible face recognition is one of the most challenging face matching problem. In this paper, we present an approach to bridge this modality gap by a significant margin. Our approach captures the highly non-linear relationship be- tween the two modalities by using a deep neural network. Our model attempts to learn a non-linear mapping from visible to thermal spectrum while preserving the identity in- formation. We show substantive performance improvement on a difficult thermal-visible face dataset. The presented approach improves the state-of-the-art by more than 10% in terms of Rank-1 identification and bridge the drop in performance due to the modality gap by more than 40%.



