# Arxiv Papers in cs.CV on 2015-07-02
### Convolutional Color Constancy
- **Arxiv ID**: http://arxiv.org/abs/1507.00410v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.00410v2)
- **Published**: 2015-07-02 02:16:42+00:00
- **Updated**: 2015-09-18 18:01:47+00:00
- **Authors**: Jonathan T. Barron
- **Comment**: None
- **Journal**: None
- **Summary**: Color constancy is the problem of inferring the color of the light that illuminated a scene, usually so that the illumination color can be removed. Because this problem is underconstrained, it is often solved by modeling the statistical regularities of the colors of natural objects and illumination. In contrast, in this paper we reformulate the problem of color constancy as a 2D spatial localization task in a log-chrominance space, thereby allowing us to apply techniques from object detection and structured prediction to the color constancy problem. By directly learning how to discriminate between correctly white-balanced images and poorly white-balanced images, our model is able to improve performance on standard benchmarks by nearly 40%.



### Cross Modal Distillation for Supervision Transfer
- **Arxiv ID**: http://arxiv.org/abs/1507.00448v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.00448v2)
- **Published**: 2015-07-02 07:21:04+00:00
- **Updated**: 2015-11-25 08:46:56+00:00
- **Authors**: Saurabh Gupta, Judy Hoffman, Jitendra Malik
- **Comment**: Updated version (v2) contains additional experiments and results
- **Journal**: None
- **Summary**: In this work we propose a technique that transfers supervision between images from different modalities. We use learned representations from a large labeled modality as a supervisory signal for training representations for a new unlabeled paired modality. Our method enables learning of rich representations for unlabeled modalities and can be used as a pre-training procedure for new modalities with limited labeled data. We show experimental results where we transfer supervision from labeled RGB images to unlabeled depth and optical flow images and demonstrate large improvements for both these cross modal supervision transfers. Code, data and pre-trained models are available at https://github.com/s-gupta/fast-rcnn/tree/distillation



### Distributed image reconstruction for very large arrays in radio astronomy
- **Arxiv ID**: http://arxiv.org/abs/1507.00501v1
- **DOI**: 10.1109/SAM.2014.6882424
- **Categories**: **astro-ph.IM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1507.00501v1)
- **Published**: 2015-07-02 10:07:04+00:00
- **Updated**: 2015-07-02 10:07:04+00:00
- **Authors**: André Ferrari, David Mary, Rémi Flamary, Cédric Richard
- **Comment**: Sensor Array and Multichannel Signal Processing Workshop (SAM), 2014
  IEEE 8th, Jun 2014, Coruna, Spain. 2014
- **Journal**: None
- **Summary**: Current and future radio interferometric arrays such as LOFAR and SKA are characterized by a paradox. Their large number of receptors (up to millions) allow theoretically unprecedented high imaging resolution. In the same time, the ultra massive amounts of samples makes the data transfer and computational loads (correlation and calibration) order of magnitudes too high to allow any currently existing image reconstruction algorithm to achieve, or even approach, the theoretical resolution. We investigate here decentralized and distributed image reconstruction strategies which select, transfer and process only a fraction of the total data. The loss in MSE incurred by the proposed approach is evaluated theoretically and numerically on simple test cases.



