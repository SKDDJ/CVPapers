# Arxiv Papers in cs.CV on 2015-07-23
### Multi-Target Tracking with Time-Varying Clutter Rate and Detection Profile: Application to Time-lapse Cell Microscopy Sequences
- **Arxiv ID**: http://arxiv.org/abs/1507.06397v1
- **DOI**: 10.1109/TMI.2015.2390647
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.06397v1)
- **Published**: 2015-07-23 07:13:24+00:00
- **Updated**: 2015-07-23 07:13:24+00:00
- **Authors**: Seyed Hamid Rezatofighi, Stephen Gould, Ba Tuong Vo, Ba-Ngu Vo, Katarina Mele, Richard Hartley
- **Comment**: None
- **Journal**: None
- **Summary**: Quantitative analysis of the dynamics of tiny cellular and sub-cellular structures, known as particles, in time-lapse cell microscopy sequences requires the development of a reliable multi-target tracking method capable of tracking numerous similar targets in the presence of high levels of noise, high target density, complex motion patterns and intricate interactions. In this paper, we propose a framework for tracking these structures based on the random finite set Bayesian filtering framework. We focus on challenging biological applications where image characteristics such as noise and background intensity change during the acquisition process. Under these conditions, detection methods usually fail to detect all particles and are often followed by missed detections and many spurious measurements with unknown and time-varying rates. To deal with this, we propose a bootstrap filter composed of an estimator and a tracker. The estimator adaptively estimates the required meta parameters for the tracker such as clutter rate and the detection probability of the targets, while the tracker estimates the state of the targets. Our results show that the proposed approach can outperform state-of-the-art particle trackers on both synthetic and real data in this regime.



### Deep Fishing: Gradient Features from Deep Nets
- **Arxiv ID**: http://arxiv.org/abs/1507.06429v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.06429v1)
- **Published**: 2015-07-23 10:01:45+00:00
- **Updated**: 2015-07-23 10:01:45+00:00
- **Authors**: Albert Gordo, Adrien Gaidon, Florent Perronnin
- **Comment**: To appear at BMVC 2015
- **Journal**: None
- **Summary**: Convolutional Networks (ConvNets) have recently improved image recognition performance thanks to end-to-end learning of deep feed-forward models from raw pixels. Deep learning is a marked departure from the previous state of the art, the Fisher Vector (FV), which relied on gradient-based encoding of local hand-crafted features. In this paper, we discuss a novel connection between these two approaches. First, we show that one can derive gradient representations from ConvNets in a similar fashion to the FV. Second, we show that this gradient representation actually corresponds to a structured matrix that allows for efficient similarity computation. We experimentally study the benefits of transferring this representation over the outputs of ConvNet layers, and find consistent improvements on the Pascal VOC 2007 and 2012 datasets.



### Active skeleton for bacteria modeling
- **Arxiv ID**: http://arxiv.org/abs/1507.06504v4
- **DOI**: 10.1080/21681163.2015.1100099
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.06504v4)
- **Published**: 2015-07-23 14:08:49+00:00
- **Updated**: 2016-12-22 13:13:06+00:00
- **Authors**: Jean-Pascal Jacob, Mariella Dimiccoli, Lionel Moisan
- **Comment**: Published in Computer Methods in Biomechanics and Biomedical
  Engineering: Imaging and Visualizationto appear in
- **Journal**: Computer Methods in Biomechanics and Biomedical Engineering:
  Imaging and Visualization, pp. 1-13, 2016
- **Summary**: The investigation of spatio-temporal dynamics of bacterial cells and their molecular components requires automated image analysis tools to track cell shape properties and molecular component locations inside the cells. In the study of bacteria aging, the molecular components of interest are protein aggregates accumulated near bacteria boundaries. This particular location makes very ambiguous the correspondence between aggregates and cells, since computing accurately bacteria boundaries in phase-contrast time-lapse imaging is a challenging task. This paper proposes an active skeleton formulation for bacteria modeling which provides several advantages: an easy computation of shape properties (perimeter, length, thickness, orientation), an improved boundary accuracy in noisy images, and a natural bacteria-centered coordinate system that permits the intrinsic location of molecular components inside the cell. Starting from an initial skeleton estimate, the medial axis of the bacterium is obtained by minimizing an energy function which incorporates bacteria shape constraints. Experimental results on biological images and comparative evaluation of the performances validate the proposed approach for modeling cigar-shaped bacteria like Escherichia coli. The Image-J plugin of the proposed method can be found online at http://fluobactracker.inrialpes.fr.



### Manitest: Are classifiers really invariant?
- **Arxiv ID**: http://arxiv.org/abs/1507.06535v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1507.06535v1)
- **Published**: 2015-07-23 15:36:50+00:00
- **Updated**: 2015-07-23 15:36:50+00:00
- **Authors**: Alhussein Fawzi, Pascal Frossard
- **Comment**: BMVC 2015
- **Journal**: None
- **Summary**: Invariance to geometric transformations is a highly desirable property of automatic classifiers in many image recognition tasks. Nevertheless, it is unclear to which extent state-of-the-art classifiers are invariant to basic transformations such as rotations and translations. This is mainly due to the lack of general methods that properly measure such an invariance. In this paper, we propose a rigorous and systematic approach for quantifying the invariance to geometric transformations of any classifier. Our key idea is to cast the problem of assessing a classifier's invariance as the computation of geodesics along the manifold of transformed images. We propose the Manitest method, built on the efficient Fast Marching algorithm to compute the invariance of classifiers. Our new method quantifies in particular the importance of data augmentation for learning invariance from data, and the increased invariance of convolutional neural networks with depth. We foresee that the proposed generic tool for measuring invariance to a large class of geometric transformations and arbitrary classifiers will have many applications for evaluating and comparing classifiers based on their invariance, and help improving the invariance of existing classifiers.



### Human Pose Estimation with Iterative Error Feedback
- **Arxiv ID**: http://arxiv.org/abs/1507.06550v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1507.06550v3)
- **Published**: 2015-07-23 16:20:57+00:00
- **Updated**: 2016-06-12 19:10:55+00:00
- **Authors**: Joao Carreira, Pulkit Agrawal, Katerina Fragkiadaki, Jitendra Malik
- **Comment**: None
- **Journal**: None
- **Summary**: Hierarchical feature extractors such as Convolutional Networks (ConvNets) have achieved impressive performance on a variety of classification tasks using purely feedforward processing. Feedforward architectures can learn rich representations of the input space but do not explicitly model dependencies in the output spaces, that are quite structured for tasks such as articulated human pose estimation or object segmentation. Here we propose a framework that expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback. Instead of directly predicting the outputs in one go, we use a self-correcting model that progressively changes an initial solution by feeding back error predictions, in a process we call Iterative Error Feedback (IEF). IEF shows excellent performance on the task of articulated pose estimation in the challenging MPII and LSP benchmarks, matching the state-of-the-art without requiring ground truth scale annotation.



### Fourier descriptors based on the structure of the human primary visual cortex with applications to object recognition
- **Arxiv ID**: http://arxiv.org/abs/1507.06617v4
- **DOI**: 10.1007/s10851-016-0669-1
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.06617v4)
- **Published**: 2015-07-23 19:09:27+00:00
- **Updated**: 2016-06-28 09:07:33+00:00
- **Authors**: Amine Bohi, Dario Prandi, Vincente Guis, Frédéric Bouchara, Jean-Paul Gauthier
- **Comment**: 16 pages, 5 figures -- Added acknowledgements
- **Journal**: None
- **Summary**: In this paper we propose a supervised object recognition method using new global features and inspired by the model of the human primary visual cortex V1 as the semidiscrete roto-translation group $SE(2,N) = \mathbb Z_N\rtimes \mathbb R^2$. The proposed technique is based on generalized Fourier descriptors on the latter group, which are invariant to natural geometric transformations (rotations, translations). These descriptors are then used to feed an SVM classifier. We have tested our method against the COIL-100 image database and the ORL face database, and compared it with other techniques based on traditional descriptors, global and local. The obtained results have shown that our approach looks extremely efficient and stable to noise, in presence of which it outperforms the other techniques analyzed in the paper.



