# Arxiv Papers in cs.CV on 2015-07-28
### Learning 3D Deformation of Animals from 2D Images
- **Arxiv ID**: http://arxiv.org/abs/1507.07646v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.07646v3)
- **Published**: 2015-07-28 05:28:34+00:00
- **Updated**: 2016-05-24 18:32:58+00:00
- **Authors**: Angjoo Kanazawa, Shahar Kovalsky, Ronen Basri, David W. Jacobs
- **Comment**: 10 pages, Eurographics 2016 (Best paper award)
- **Journal**: None
- **Summary**: Understanding how an animal can deform and articulate is essential for a realistic modification of its 3D model. In this paper, we show that such information can be learned from user-clicked 2D images and a template 3D model of the target animal. We present a volumetric deformation framework that produces a set of new 3D models by deforming a template 3D model according to a set of user-clicked images. Our framework is based on a novel locally-bounded deformation energy, where every local region has its own stiffness value that bounds how much distortion is allowed at that location. We jointly learn the local stiffness bounds as we deform the template 3D mesh to match each user-clicked image. We show that this seemingly complex task can be solved as a sequence of convex optimization problems. We demonstrate the effectiveness of our approach on cats and horses, which are highly deformable and articulated animals. Our framework produces new 3D models of animals that are significantly more plausible than methods without learned stiffness.



### A Hyperelastic Two-Scale Optimization Model for Shape Matching
- **Arxiv ID**: http://arxiv.org/abs/1507.07760v1
- **DOI**: None
- **Categories**: **cs.CG**, cs.CV, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/1507.07760v1)
- **Published**: 2015-07-28 13:27:51+00:00
- **Updated**: 2015-07-28 13:27:51+00:00
- **Authors**: Konrad Simon, Sameer Sheorey, David Jacobs, Ronen Basri
- **Comment**: None
- **Journal**: None
- **Summary**: We suggest a novel shape matching algorithm for three-dimensional surface meshes of disk or sphere topology. The method is based on the physical theory of nonlinear elasticity and can hence handle large rotations and deformations. Deformation boundary conditions that supplement the underlying equations are usually unknown. Given an initial guess, these are optimized such that the mechanical boundary forces that are responsible for the deformation are of a simple nature. We show a heuristic way to approximate the nonlinear optimization problem by a sequence of convex problems using finite elements. The deformation cost, i.e, the forces, is measured on a coarse scale while ICP-like matching is done on the fine scale. We demonstrate the plausibility of our algorithm on examples taken from different datasets.



### SynapCountJ --- a Tool for Analyzing Synaptic Densities in Neurons
- **Arxiv ID**: http://arxiv.org/abs/1507.07800v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1507.07800v1)
- **Published**: 2015-07-28 15:12:42+00:00
- **Updated**: 2015-07-28 15:12:42+00:00
- **Authors**: Gadea Mata, JÃ³nathan Heras, Miguel Morales, Ana Romero, Julio Rubio
- **Comment**: None
- **Journal**: None
- **Summary**: The quantification of synapses is instrumental to measure the evolution of synaptic densities of neurons under the effect of some physiological conditions, neuronal diseases or even drug treatments. However, the manual quantification of synapses is a tedious, error-prone, time-consuming and subjective task; therefore, tools that might automate this process are desirable. In this paper, we present SynapCountJ, an ImageJ plugin, that can measure synaptic density of individual neurons obtained by immunofluorescence techniques, and also can be applied for batch processing of neurons that have been obtained in the same experiment or using the same setting. The procedure to quantify synapses implemented in SynapCountJ is based on the colocalization of three images of the same neuron (the neuron marked with two antibody markers and the structure of the neuron) and is inspired by methods coming from Computational Algebraic Topology. SynapCountJ provides a procedure to semi-automatically quantify the number of synapses of neuron cultures; as a result, the time required for such an analysis is greatly reduced.



### A Multi-Camera Image Processing and Visualization System for Train Safety Assessment
- **Arxiv ID**: http://arxiv.org/abs/1507.07815v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.07815v1)
- **Published**: 2015-07-28 15:36:24+00:00
- **Updated**: 2015-07-28 15:36:24+00:00
- **Authors**: Giuseppe Lisanti, Svebor Karaman, Daniele Pezzatini, Alberto Del Bimbo
- **Comment**: 11 pages
- **Journal**: None
- **Summary**: In this paper we present a machine vision system to efficiently monitor, analyze and present visual data acquired with a railway overhead gantry equipped with multiple cameras. This solution aims to improve the safety of daily life railway transportation in a two- fold manner: (1) by providing automatic algorithms that can process large imagery of trains (2) by helping train operators to keep attention on any possible malfunction. The system is designed with the latest cutting edge, high-rate visible and thermal cameras that ob- serve a train passing under an railway overhead gantry. The machine vision system is composed of three principal modules: (1) an automatic wagon identification system, recognizing the wagon ID according to the UIC classification of railway coaches; (2) a temperature monitoring system; (3) a system for the detection, localization and visualization of the pantograph of the train. These three machine vision modules process batch trains sequences and their resulting analysis are presented to an operator using a multitouch user interface. We detail all technical aspects of our multi-camera portal: the hardware requirements, the software developed to deal with the high-frame rate cameras and ensure reliable acquisition, the algorithms proposed to solve each computer vision task, and the multitouch interaction and visualization interface. We evaluate each component of our system on a dataset recorded in an ad-hoc railway test-bed, showing the potential of our proposed portal for train safety assessment.



### Zero-Shot Domain Adaptation via Kernel Regression on the Grassmannian
- **Arxiv ID**: http://arxiv.org/abs/1507.07830v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1507.07830v2)
- **Published**: 2015-07-28 16:13:48+00:00
- **Updated**: 2015-07-29 17:53:59+00:00
- **Authors**: Yongxin Yang, Timothy Hospedales
- **Comment**: Accepted to BMVC 2015 Workshop on Differential Geometry in Computer
  Vision (DIFF-CV)
- **Journal**: None
- **Summary**: Most visual recognition methods implicitly assume the data distribution remains unchanged from training to testing. However, in practice domain shift often exists, where real-world factors such as lighting and sensor type change between train and test, and classifiers do not generalise from source to target domains. It is impractical to train separate models for all possible situations because collecting and labelling the data is expensive. Domain adaptation algorithms aim to ameliorate domain shift, allowing a model trained on a source to perform well on a different target domain. However, even for the setting of unsupervised domain adaptation, where the target domain is unlabelled, collecting data for every possible target domain is still costly. In this paper, we propose a new domain adaptation method that has no need to access either data or labels of the target domain when it can be described by a parametrised vector and there exits several related source domains within the same parametric space. It greatly reduces the burden of data collection and annotation, and our experiments show some promising results.



### Offline Handwritten Signature Verification - Literature Review
- **Arxiv ID**: http://arxiv.org/abs/1507.07909v4
- **DOI**: 10.1109/IPTA.2017.8310112
- **Categories**: **cs.CV**, stat.ML, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1507.07909v4)
- **Published**: 2015-07-28 19:31:44+00:00
- **Updated**: 2017-10-16 12:56:24+00:00
- **Authors**: Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira
- **Comment**: Accepted to the International Conference on Image Processing Theory,
  Tools and Applications (IPTA 2017)
- **Journal**: None
- **Summary**: The area of Handwritten Signature Verification has been broadly researched in the last decades, but remains an open research problem. The objective of signature verification systems is to discriminate if a given signature is genuine (produced by the claimed individual), or a forgery (produced by an impostor). This has demonstrated to be a challenging task, in particular in the offline (static) scenario, that uses images of scanned signatures, where the dynamic information about the signing process is not available. Many advancements have been proposed in the literature in the last 5-10 years, most notably the application of Deep Learning methods to learn feature representations from signature images. In this paper, we present how the problem has been handled in the past few decades, analyze the recent advancements in the field, and the potential directions for future research.



