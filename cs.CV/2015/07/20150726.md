# Arxiv Papers in cs.CV on 2015-07-26
### Capturing the Dynamics of Pedestrian Traffic Using a Machine Vision System
- **Arxiv ID**: http://arxiv.org/abs/1507.07203v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.07203v1)
- **Published**: 2015-07-26 14:29:55+00:00
- **Updated**: 2015-07-26 14:29:55+00:00
- **Authors**: Louie Vincent A. Ngoho, Jaderick P. Pabico
- **Comment**: 11 pages, 10 figures, appeared in Proceedings (CDROM) of the 7th
  National Conference on IT Education (NCITE 2009), Capitol University, Cagayan
  De Oro City, Philippines, 21-23 October 2009
- **Journal**: Philippine Information Technology Journal, 2(2):1-11, 2009
- **Summary**: We developed a machine vision system to automatically capture the dynamics of pedestrians under four different traffic scenarios. By considering the overhead view of each pedestrian as a digital object, the system processes the image sequences to track the pedestrians. Considering the perspective effect of the camera lens and the projected area of the hallway at the top-view scene, the distance of each tracked object from its original position to its current position is approximated every video frame. Using the approximated distance and the video frame rate (30 frames per second), the respective velocity and acceleration of each tracked object are later derived. The quantified motion characteristics of the pedestrians are displayed by the system through 2-dimensional graphs of the kinematics of motion. The system also outputs video images of the pedestrians with superimposed markers for tracking. These visual markers were used to visually describe and quantify the behavior of the pedestrians under different traffic scenarios.



### Face Search at Scale: 80 Million Gallery
- **Arxiv ID**: http://arxiv.org/abs/1507.07242v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1507.07242v2)
- **Published**: 2015-07-26 20:06:43+00:00
- **Updated**: 2015-07-28 22:09:17+00:00
- **Authors**: Dayong Wang, Charles Otto, Anil K. Jain
- **Comment**: 14 pages, 16 figures
- **Journal**: None
- **Summary**: Due to the prevalence of social media websites, one challenge facing computer vision researchers is to devise methods to process and search for persons of interest among the billions of shared photos on these websites. Facebook revealed in a 2013 white paper that its users have uploaded more than 250 billion photos, and are uploading 350 million new photos each day. Due to this humongous amount of data, large-scale face search for mining web images is both important and challenging. Despite significant progress in face recognition, searching a large collection of unconstrained face images has not been adequately addressed. To address this challenge, we propose a face search system which combines a fast search procedure, coupled with a state-of-the-art commercial off the shelf (COTS) matcher, in a cascaded framework. Given a probe face, we first filter the large gallery of photos to find the top-k most similar faces using deep features generated from a convolutional neural network. The k candidates are re-ranked by combining similarities from deep features and the COTS matcher. We evaluate the proposed face search system on a gallery containing 80 million web-downloaded face images. Experimental results demonstrate that the deep features are competitive with state-of-the-art methods on unconstrained face recognition benchmarks (LFW and IJB-A). Further, the proposed face search system offers an excellent trade-off between accuracy and scalability on datasets consisting of millions of images. Additionally, in an experiment involving searching for face images of the Tsarnaev brothers, convicted of the Boston Marathon bombing, the proposed face search system could find the younger brother's (Dzhokhar Tsarnaev) photo at rank 1 in 1 second on a 5M gallery and at rank 8 in 7 seconds on an 80M gallery.



