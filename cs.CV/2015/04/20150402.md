# Arxiv Papers in cs.CV on 2015-04-02
### Direct l_(2,p)-Norm Learning for Feature Selection
- **Arxiv ID**: http://arxiv.org/abs/1504.00430v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.00430v1)
- **Published**: 2015-04-02 02:16:39+00:00
- **Updated**: 2015-04-02 02:16:39+00:00
- **Authors**: Hanyang Peng, Yong Fan
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we propose a novel sparse learning based feature selection method that directly optimizes a large margin linear classification model sparsity with l_(2,p)-norm (0 < p < 1)subject to data-fitting constraints, rather than using the sparsity as a regularization term. To solve the direct sparsity optimization problem that is non-smooth and non-convex when 0<p<1, we provide an efficient iterative algorithm with proved convergence by converting it to a convex and smooth optimization problem at every iteration step. The proposed algorithm has been evaluated based on publicly available datasets, and extensive comparison experiments have demonstrated that our algorithm could achieve feature selection performance competitive to state-of-the-art algorithms.



### Quantum image classification using principal component analysis
- **Arxiv ID**: http://arxiv.org/abs/1504.00580v1
- **DOI**: 10.20904/271001
- **Categories**: **quant-ph**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1504.00580v1)
- **Published**: 2015-04-02 14:53:51+00:00
- **Updated**: 2015-04-02 14:53:51+00:00
- **Authors**: Mateusz Ostaszewski, PrzemysÅ‚aw Sadowski, Piotr Gawron
- **Comment**: 9 pages
- **Journal**: Theoretical and Applied Informatics, Vol. 27, No. 1, pp. 1-12
  (2015)
- **Summary**: We present a novel quantum algorithm for classification of images. The algorithm is constructed using principal component analysis and von Neuman quantum measurements. In order to apply the algorithm we present a new quantum representation of grayscale images.



### The Approximation of the Dissimilarity Projection
- **Arxiv ID**: http://arxiv.org/abs/1504.00593v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.00593v1)
- **Published**: 2015-04-02 15:47:46+00:00
- **Updated**: 2015-04-02 15:47:46+00:00
- **Authors**: Emanuele Olivetti, Thien Bao Nguyen, Paolo Avesani
- **Comment**: None
- **Journal**: None
- **Summary**: Diffusion magnetic resonance imaging (dMRI) data allow to reconstruct the 3D pathways of axons within the white matter of the brain as a tractography. The analysis of tractographies has drawn attention from the machine learning and pattern recognition communities providing novel challenges such as finding an appropriate representation space for the data. Many of the current learning algorithms require the input to be from a vectorial space. This requirement contrasts with the intrinsic nature of the tractography because its basic elements, called streamlines or tracks, have different lengths and different number of points and for this reason they cannot be directly represented in a common vectorial space. In this work we propose the adoption of the dissimilarity representation which is an Euclidean embedding technique defined by selecting a set of streamlines called prototypes and then mapping any new streamline to the vector of distances from prototypes. We investigate the degree of approximation of this projection under different prototype selection policies and prototype set sizes in order to characterise its use on tractography data. Additionally we propose the use of a scalable approximation of the most effective prototype selection policy that provides fast and accurate dissimilarity approximations of complete tractographies.



### A Probabilistic Theory of Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1504.00641v1
- **DOI**: None
- **Categories**: **stat.ML**, cs.CV, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1504.00641v1)
- **Published**: 2015-04-02 18:38:38+00:00
- **Updated**: 2015-04-02 18:38:38+00:00
- **Authors**: Ankit B. Patel, Tan Nguyen, Richard G. Baraniuk
- **Comment**: 56 pages, 6 figures, 2 tables
- **Journal**: None
- **Summary**: A grand challenge in machine learning is the development of computational algorithms that match or outperform humans in perceptual inference tasks that are complicated by nuisance variation. For instance, visual object recognition involves the unknown object position, orientation, and scale in object recognition while speech recognition involves the unknown voice pronunciation, pitch, and speed. Recently, a new breed of deep learning algorithms have emerged for high-nuisance inference tasks that routinely yield pattern recognition systems with near- or super-human capabilities. But a fundamental question remains: Why do they work? Intuitions abound, but a coherent framework for understanding, analyzing, and synthesizing deep learning architectures has remained elusive. We answer this question by developing a new probabilistic framework for deep learning based on the Deep Rendering Model: a generative probabilistic model that explicitly captures latent nuisance variation. By relaxing the generative model to a discriminative one, we can recover two of the current leading deep learning systems, deep convolutional neural networks and random decision forests, providing insights into their successes and shortcomings, as well as a principled route to their improvement.



### End-to-End Training of Deep Visuomotor Policies
- **Arxiv ID**: http://arxiv.org/abs/1504.00702v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1504.00702v5)
- **Published**: 2015-04-02 22:23:51+00:00
- **Updated**: 2016-04-19 01:33:13+00:00
- **Authors**: Sergey Levine, Chelsea Finn, Trevor Darrell, Pieter Abbeel
- **Comment**: updating with revisions for JMLR final version
- **Journal**: None
- **Summary**: Policy search methods can allow robots to learn control policies for a wide range of tasks, but practical applications of policy search often require hand-engineered components for perception, state estimation, and low-level control. In this paper, we aim to answer the following question: does training the perception and control systems jointly end-to-end provide better performance than training each component separately? To this end, we develop a method that can be used to learn policies that map raw image observations directly to torques at the robot's motors. The policies are represented by deep convolutional neural networks (CNNs) with 92,000 parameters, and are trained using a partially observed guided policy search method, which transforms policy search into supervised learning, with supervision provided by a simple trajectory-centric reinforcement learning method. We evaluate our method on a range of real-world manipulation tasks that require close coordination between vision and control, such as screwing a cap onto a bottle, and present simulated comparisons to a range of prior policy search methods.



