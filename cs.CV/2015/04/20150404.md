# Arxiv Papers in cs.CV on 2015-04-04
### Convex Denoising using Non-Convex Tight Frame Regularization
- **Arxiv ID**: http://arxiv.org/abs/1504.00976v2
- **DOI**: 10.1109/LSP.2015.2432095
- **Categories**: **cs.CV**, math.OC
- **Links**: [PDF](http://arxiv.org/pdf/1504.00976v2)
- **Published**: 2015-04-04 03:28:01+00:00
- **Updated**: 2015-06-03 15:55:05+00:00
- **Authors**: Ankit Parekh, Ivan W. Selesnick
- **Comment**: 5 pages, 6 figures
- **Journal**: IEEE Signal Processing Letters, 22(10):1786-1790, Oct. 2015
- **Summary**: This paper considers the problem of signal denoising using a sparse tight-frame analysis prior. The L1 norm has been extensively used as a regularizer to promote sparsity; however, it tends to under-estimate non-zero values of the underlying signal. To more accurately estimate non-zero values, we propose the use of a non-convex regularizer, chosen so as to ensure convexity of the objective function. The convexity of the objective function is ensured by constraining the parameter of the non-convex penalty. We use ADMM to obtain a solution and show how to guarantee that ADMM converges to the global optimum of the objective function. We illustrate the proposed method for 1D and 2D signal denoising.



### Temporal Localization of Fine-Grained Actions in Videos by Domain Transfer from Web Images
- **Arxiv ID**: http://arxiv.org/abs/1504.00983v2
- **DOI**: 10.1145/2733373.2806226
- **Categories**: **cs.CV**, cs.MM, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1504.00983v2)
- **Published**: 2015-04-04 05:40:55+00:00
- **Updated**: 2015-08-04 07:04:34+00:00
- **Authors**: Chen Sun, Sanketh Shetty, Rahul Sukthankar, Ram Nevatia
- **Comment**: Camera ready version for ACM Multimedia 2015
- **Journal**: None
- **Summary**: We address the problem of fine-grained action localization from temporally untrimmed web videos. We assume that only weak video-level annotations are available for training. The goal is to use these weak labels to identify temporal segments corresponding to the actions, and learn models that generalize to unconstrained web videos. We find that web images queried by action names serve as well-localized highlights for many actions, but are noisily labeled. To solve this problem, we propose a simple yet effective method that takes weak video labels and noisy image labels as input, and generates localized action frames as output. This is achieved by cross-domain transfer between video frames and web images, using pre-trained deep convolutional neural networks. We then use the localized action frames to train action recognition models with long short-term memory networks. We collect a fine-grained sports action data set FGA-240 of more than 130,000 YouTube videos. It has 240 fine-grained actions under 85 sports activities. Convincing results are shown on the FGA-240 data set, as well as the THUMOS 2014 localization data set with untrimmed training videos.



### Efficient piecewise training of deep structured models for semantic segmentation
- **Arxiv ID**: http://arxiv.org/abs/1504.01013v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01013v4)
- **Published**: 2015-04-04 14:26:23+00:00
- **Updated**: 2016-06-06 00:26:44+00:00
- **Authors**: Guosheng Lin, Chunhua Shen, Anton van dan Hengel, Ian Reid
- **Comment**: Appearing in IEEE Conf. Computer Vision and Pattern Recognition
  (CVPR) 2016
- **Journal**: None
- **Summary**: Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information; specifically, we explore `patch-patch' context between image regions, and `patch-background' context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the proposed deep structured model is then applied to avoid repeated expensive CRF inference for back propagation. For capturing the patch-background context, we show that a network design with traditional multi-scale image input and sliding pyramid pooling is effective for improving performance. Our experimental results set new state-of-the-art performance on a number of popular semantic segmentation datasets, including NYUDv2, PASCAL VOC 2012, PASCAL-Context, and SIFT-flow. In particular, we achieve an intersection-over-union score of 78.0 on the challenging PASCAL VOC 2012 dataset.



### Preprint Extending Touch-less Interaction on Vision Based Wearable Device
- **Arxiv ID**: http://arxiv.org/abs/1504.01025v2
- **DOI**: None
- **Categories**: **cs.HC**, cs.CV, cs.GR, H.1.2; H.5.1
- **Links**: [PDF](http://arxiv.org/pdf/1504.01025v2)
- **Published**: 2015-04-04 17:12:19+00:00
- **Updated**: 2015-07-29 09:14:35+00:00
- **Authors**: Zhihan Lv, Liangbing Feng, Shengzhong Feng, Haibo Li
- **Comment**: This is the preprint version of our paper on IEEE Virtual Reality
  Conference 2015
- **Journal**: None
- **Summary**: This is the preprint version of our paper on IEEE Virtual Reality Conference 2015. A touch-less interaction technology on vision based wearable device is designed and evaluated. Users interact with the application with dynamic hands/feet gestures in front of the camera. Several proof-of-concept prototypes with eleven dynamic gestures are developed based on the touch-less interaction. At last, a comparing user study evaluation is proposed to demonstrate the usability of the touch-less approach, as well as the impact on user's emotion, running on a wearable framework or Google Glass.



### Fast algorithms for morphological operations using run-length encoded binary images
- **Arxiv ID**: http://arxiv.org/abs/1504.01052v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.IT, math.IT, 94A08 (Primary) 65D18, 65D19, 68U10, 94A12 (Secondary), I.4.3; I.5; I.4.10
- **Links**: [PDF](http://arxiv.org/pdf/1504.01052v1)
- **Published**: 2015-04-04 20:51:43+00:00
- **Updated**: 2015-04-04 20:51:43+00:00
- **Authors**: Gregor Ehrensperger, Alexander Ostermann, Felix Schwitzer
- **Comment**: 17 pages, 2 figures. Submitted to Elsevier (Pattern Recognition). For
  the associated source code, see
  https://numerical-analysis.uibk.ac.at/g.ehrensperger
- **Journal**: None
- **Summary**: This paper presents innovative algorithms to efficiently compute erosions and dilations of run-length encoded (RLE) binary images with arbitrary shaped structuring elements. An RLE image is given by a set of runs, where a run is a horizontal concatenation of foreground pixels. The proposed algorithms extract the skeleton of the structuring element and build distance tables of the input image, which are storing the distance to the next background pixel on the left and right hand sides. This information is then used to speed up the calculations of the erosion and dilation operator by enabling the use of techniques which allow to skip the analysis of certain pixels whenever a hit or miss occurs. Additionally the input image gets trimmed during the preprocessing steps on the base of two primitive criteria. Experimental results show the advantages over other algorithms. The source code of our algorithms is available in C++.



