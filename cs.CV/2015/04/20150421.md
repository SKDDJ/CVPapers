# Arxiv Papers in cs.CV on 2015-04-21
### Deep Spatial Pyramid: The Devil is Once Again in the Details
- **Arxiv ID**: http://arxiv.org/abs/1504.05277v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05277v2)
- **Published**: 2015-04-21 02:13:44+00:00
- **Updated**: 2015-04-23 02:20:26+00:00
- **Authors**: Bin-Bin Gao, Xiu-Shen Wei, Jianxin Wu, Weiyao Lin
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we show that by carefully making good choices for various detailed but important factors in a visual recognition framework using deep learning features, one can achieve a simple, efficient, yet highly accurate image classification system. We first list 5 important factors, based on both existing researches and ideas proposed in this paper. These important detailed factors include: 1) $\ell_2$ matrix normalization is more effective than unnormalized or $\ell_2$ vector normalization, 2) the proposed natural deep spatial pyramid is very effective, and 3) a very small $K$ in Fisher Vectors surprisingly achieves higher accuracy than normally used large $K$ values. Along with other choices (convolutional activations and multiple scales), the proposed DSP framework is not only intuitive and efficient, but also achieves excellent classification accuracy on many benchmark datasets. For example, DSP's accuracy on SUN397 is 59.78%, significantly higher than previous state-of-the-art (53.86%).



### Viewpoint distortion compensation in practical surveillance systems
- **Arxiv ID**: http://arxiv.org/abs/1504.05298v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05298v1)
- **Published**: 2015-04-21 04:08:39+00:00
- **Updated**: 2015-04-21 04:08:39+00:00
- **Authors**: Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh
- **Comment**: International Conference on Multimedia & Expo, 2015
- **Journal**: None
- **Summary**: Our aim is to estimate the perspective-effected geometric distortion of a scene from a video feed. In contrast to all previous work we wish to achieve this using from low-level, spatio-temporally local motion features used in commercial semi-automatic surveillance systems. We: (i) describe a dense algorithm which uses motion features to estimate the perspective distortion at each image locus and then polls all such local estimates to arrive at the globally best estimate, (ii) present an alternative coarse algorithm which subdivides the image frame into blocks, and uses motion features to derive block-specific motion characteristics and constrain the relationships between these characteristics, with the perspective estimate emerging as a result of a global optimization scheme, and (iii) report the results of an evaluation using nine large sets acquired using existing close-circuit television (CCTV) cameras. Our findings demonstrate that both of the proposed methods are successful, their accuracy matching that of human labelling using complete visual data.



### Groupwise registration of aerial images
- **Arxiv ID**: http://arxiv.org/abs/1504.05299v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05299v1)
- **Published**: 2015-04-21 04:14:02+00:00
- **Updated**: 2015-04-21 04:14:02+00:00
- **Authors**: Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh
- **Comment**: International Joint Conference on Artificial Intelligence, 2015
- **Journal**: None
- **Summary**: This paper addresses the task of time separated aerial image registration. The ability to solve this problem accurately and reliably is important for a variety of subsequent image understanding applications. The principal challenge lies in the extent and nature of transient appearance variation that a land area can undergo, such as that caused by the change in illumination conditions, seasonal variations, or the occlusion by non-persistent objects (people, cars). Our work introduces several novelties: (i) unlike all previous work on aerial image registration, we approach the problem using a set-based paradigm; (ii) we show how local, pair-wise constraints can be used to enforce a globally good registration using a constraints graph structure; (iii) we show how a simple holistic representation derived from raw aerial images can be used as a basic building block of the constraints graph in a manner which achieves both high registration accuracy and speed. We demonstrate: (i) that the proposed method outperforms the state-of-the-art for pair-wise registration already, achieving greater accuracy and reliability, while at the same time reducing the computational cost of the task; and (ii) that the increase in the number of available images in a set consistently reduces the average registration error.



### The adaptable buffer algorithm for high quantile estimation in non-stationary data streams
- **Arxiv ID**: http://arxiv.org/abs/1504.05302v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05302v1)
- **Published**: 2015-04-21 04:42:58+00:00
- **Updated**: 2015-04-21 04:42:58+00:00
- **Authors**: Ognjen Arandjelovic, Duc-Son Pham, Svetha Venkatesh
- **Comment**: International Joint Conference on Neural Networks, 2015
- **Journal**: None
- **Summary**: The need to estimate a particular quantile of a distribution is an important problem which frequently arises in many computer vision and signal processing applications. For example, our work was motivated by the requirements of many semi-automatic surveillance analytics systems which detect abnormalities in close-circuit television (CCTV) footage using statistical models of low-level motion features. In this paper we specifically address the problem of estimating the running quantile of a data stream with non-stationary stochasticity when the memory for storing observations is limited. We make several major contributions: (i) we derive an important theoretical result which shows that the change in the quantile of a stream is constrained regardless of the stochastic properties of data, (ii) we describe a set of high-level design goals for an effective estimation algorithm that emerge as a consequence of our theoretical findings, (iii) we introduce a novel algorithm which implements the aforementioned design goals by retaining a sample of data values in a manner adaptive to changes in the distribution of data and progressively narrowing down its focus in the periods of quasi-stationary stochasticity, and (iv) we present a comprehensive evaluation of the proposed algorithm and compare it with the existing methods in the literature on both synthetic data sets and three large `real-world' streams acquired in the course of operation of an existing commercial surveillance system. Our findings convincingly demonstrate that the proposed method is highly successful and vastly outperforms the existing alternatives, especially when the target quantile is high valued and the available buffer capacity severely limited.



### Automatic Face Recognition from Video
- **Arxiv ID**: http://arxiv.org/abs/1504.05308v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05308v1)
- **Published**: 2015-04-21 05:10:41+00:00
- **Updated**: 2015-04-21 05:10:41+00:00
- **Authors**: Ognjen Arandjelovic
- **Comment**: Doctor of Philosophy (PhD) dissertation, University of Cambridge,
  2007
- **Journal**: None
- **Summary**: The objective of this work is to automatically recognize faces from video sequences in a realistic, unconstrained setup in which illumination conditions are extreme and greatly changing, viewpoint and user motion pattern have a wide variability, and video input is of low quality. At the centre of focus are face appearance manifolds: this thesis presents a significant advance of their understanding and application in the sphere of face recognition. The two main contributions are the Generic Shape-Illumination Manifold recognition algorithm and the Anisotropic Manifold Space clustering. The Generic Shape-Illumination Manifold is evaluated on a large data corpus acquired in real-world conditions and its performance is shown to greatly exceed that of state-of-the-art methods in the literature and the best performing commercial software. Empirical evaluation of the Anisotropic Manifold Space clustering on a popular situation comedy is also described with excellent preliminary results.



### Key-Pose Prediction in Cyclic Human Motion
- **Arxiv ID**: http://arxiv.org/abs/1504.05369v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05369v1)
- **Published**: 2015-04-21 10:09:43+00:00
- **Updated**: 2015-04-21 10:09:43+00:00
- **Authors**: Dan Zecha, Rainer Lienhart
- **Comment**: Accepted at WACV 2015, 8 pages, 3 figures
- **Journal**: None
- **Summary**: In this paper we study the problem of estimating innercyclic time intervals within repetitive motion sequences of top-class swimmers in a swimming channel. Interval limits are given by temporal occurrences of key-poses, i.e. distinctive postures of the body. A key-pose is defined by means of only one or two specific features of the complete posture. It is often difficult to detect such subtle features directly. We therefore propose the following method: Given that we observe the swimmer from the side, we build a pictorial structure of poselets to robustly identify random support poses within the regular motion of a swimmer. We formulate a maximum likelihood model which predicts a key-pose given the occurrences of multiple support poses within one stroke. The maximum likelihood can be extended with prior knowledge about the temporal location of a key-pose in order to improve the prediction recall. We experimentally show that our models reliably and robustly detect key-poses with a high precision and that their performance can be improved by extending the framework with additional camera views.



### Adaptive Compressive Tracking via Online Vector Boosting Feature Selection
- **Arxiv ID**: http://arxiv.org/abs/1504.05451v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05451v2)
- **Published**: 2015-04-21 14:55:07+00:00
- **Updated**: 2015-04-22 01:27:08+00:00
- **Authors**: Qingshan Liu, Jing Yang, Kaihua Zhang, Yi Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, the compressive tracking (CT) method has attracted much attention due to its high efficiency, but it cannot well deal with the large scale target appearance variations due to its data-independent random projection matrix that results in less discriminative features. To address this issue, in this paper we propose an adaptive CT approach, which selects the most discriminative features to design an effective appearance model. Our method significantly improves CT in three aspects: Firstly, the most discriminative features are selected via an online vector boosting method. Secondly, the object representation is updated in an effective online manner, which preserves the stable features while filtering out the noisy ones. Finally, a simple and effective trajectory rectification approach is adopted that can make the estimated location more accurate. Extensive experiments on the CVPR2013 tracking benchmark demonstrate the superior performance of our algorithm compared over state-of-the-art tracking algorithms.



### A robust and efficient video representation for action recognition
- **Arxiv ID**: http://arxiv.org/abs/1504.05524v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.05524v1)
- **Published**: 2015-04-21 17:44:07+00:00
- **Updated**: 2015-04-21 17:44:07+00:00
- **Authors**: Heng Wang, Dan Oneata, Jakob Verbeek, Cordelia Schmid
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a state-of-the-art video representation and applies it to efficient action recognition and detection. We first propose to improve the popular dense trajectory features by explicit camera motion estimation. More specifically, we extract feature point matches between frames using SURF descriptors and dense optical flow. The matches are used to estimate a homography with RANSAC. To improve the robustness of homography estimation, a human detector is employed to remove outlier matches from the human body as human motion is not constrained by the camera. Trajectories consistent with the homography are considered as due to camera motion, and thus removed. We also use the homography to cancel out camera motion from the optical flow. This results in significant improvement on motion-based HOF and MBH descriptors. We further explore the recent Fisher vector as an alternative feature encoding approach to the standard bag-of-words histogram, and consider different ways to include spatial layout information in these encodings. We present a large and varied set of evaluations, considering (i) classification of short basic actions on six datasets, (ii) localization of such actions in feature-length movies, and (iii) large-scale recognition of complex events. We find that our improved trajectory features significantly outperform previous dense trajectories, and that Fisher vectors are superior to bag-of-words encodings for video recognition tasks. In all three tasks, we show substantial improvements over the state-of-the-art results.



