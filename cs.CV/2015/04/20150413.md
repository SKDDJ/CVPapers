# Arxiv Papers in cs.CV on 2015-04-13
### Joint Learning of Distributed Representations for Images and Texts
- **Arxiv ID**: http://arxiv.org/abs/1504.03083v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03083v2)
- **Published**: 2015-04-13 07:36:08+00:00
- **Updated**: 2015-04-28 17:24:00+00:00
- **Authors**: Xiaodong He, Rupesh Srivastava, Jianfeng Gao, Li Deng
- **Comment**: This is a previous tech report of a part of the work of
  arXiv:1411.4952. In order to avoid confusion, we'd like to withdraw this
  report from arXiv
- **Journal**: None
- **Summary**: This technical report provides extra details of the deep multimodal similarity model (DMSM) which was proposed in (Fang et al. 2015, arXiv:1411.4952). The model is trained via maximizing global semantic similarity between images and their captions in natural language using the public Microsoft COCO database, which consists of a large set of images and their corresponding captions. The learned representations attempt to capture the combination of various visual concepts and cues.



### Learning Multiple Visual Tasks while Discovering their Structure
- **Arxiv ID**: http://arxiv.org/abs/1504.03106v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.03106v1)
- **Published**: 2015-04-13 09:27:23+00:00
- **Updated**: 2015-04-13 09:27:23+00:00
- **Authors**: Carlo Ciliberto, Lorenzo Rosasco, Silvia Villa
- **Comment**: 19 pages, 3 figures, 3 tables
- **Journal**: None
- **Summary**: Multi-task learning is a natural approach for computer vision applications that require the simultaneous solution of several distinct but related problems, e.g. object detection, classification, tracking of multiple agents, or denoising, to name a few. The key idea is that exploring task relatedness (structure) can lead to improved performances.   In this paper, we propose and study a novel sparse, non-parametric approach exploiting the theory of Reproducing Kernel Hilbert Spaces for vector-valued functions. We develop a suitable regularization framework which can be formulated as a convex optimization problem, and is provably solvable using an alternating minimization approach. Empirical tests show that the proposed method compares favorably to state of the art techniques and further allows to recover interpretable structures, a problem of interest in its own right.



### Real-world Object Recognition with Off-the-shelf Deep Conv Nets: How Many Objects can iCub Learn?
- **Arxiv ID**: http://arxiv.org/abs/1504.03154v2
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1504.03154v2)
- **Published**: 2015-04-13 12:45:09+00:00
- **Updated**: 2015-04-14 05:56:01+00:00
- **Authors**: Giulia Pasquale, Carlo Ciliberto, Francesca Odone, Lorenzo Rosasco, Lorenzo Natale
- **Comment**: 18 pages, 9 figures, 3 tables
- **Journal**: None
- **Summary**: The ability to visually recognize objects is a fundamental skill for robotics systems. Indeed, a large variety of tasks involving manipulation, navigation or interaction with other agents, deeply depends on the accurate understanding of the visual scene. Yet, at the time being, robots are lacking good visual perceptual systems, which often become the main bottleneck preventing the use of autonomous agents for real-world applications.   Lately in computer vision, systems that learn suitable visual representations and based on multi-layer deep convolutional networks are showing remarkable performance in tasks such as large-scale visual recognition and image retrieval. To this regard, it is natural to ask whether such remarkable performance would generalize also to the robotic setting.   In this paper we investigate such possibility, while taking further steps in developing a computational vision system to be embedded on a robotic platform, the iCub humanoid robot. In particular, we release a new dataset ({\sc iCubWorld28}) that we use as a benchmark to address the question: {\it how many objects can iCub recognize?} Our study is developed in a learning framework which reflects the typical visual experience of a humanoid robot like the iCub. Experiments shed interesting insights on the strength and weaknesses of current computer vision approaches applied in real robotic settings.



### Multiple Measurements and Joint Dimensionality Reduction for Large Scale Image Search with Short Vectors - Extended Version
- **Arxiv ID**: http://arxiv.org/abs/1504.03285v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03285v1)
- **Published**: 2015-04-13 18:17:12+00:00
- **Updated**: 2015-04-13 18:17:12+00:00
- **Authors**: Filip Radenovic, Herve Jegou, Ondrej Chum
- **Comment**: Extended version of the ICMR 2015 paper
- **Journal**: None
- **Summary**: This paper addresses the construction of a short-vector (128D) image representation for large-scale image and particular object retrieval. In particular, the method of joint dimensionality reduction of multiple vocabularies is considered. We study a variety of vocabulary generation techniques: different k-means initializations, different descriptor transformations, different measurement regions for descriptor extraction. Our extensive evaluation shows that different combinations of vocabularies, each partitioning the descriptor space in a different yet complementary manner, results in a significant performance improvement, which exceeds the state-of-the-art.



### Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction
- **Arxiv ID**: http://arxiv.org/abs/1504.03293v3
- **DOI**: 10.1109/CVPR.2015.7298621
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03293v3)
- **Published**: 2015-04-13 18:50:51+00:00
- **Updated**: 2016-01-14 04:11:45+00:00
- **Authors**: Yuting Zhang, Kihyuk Sohn, Ruben Villegas, Gang Pan, Honglak Lee
- **Comment**: CVPR 2015
- **Journal**: None
- **Summary**: Object detection systems based on the deep convolutional neural network (CNN) have recently made ground- breaking advances on several object detection benchmarks. While the features learned by these high-capacity neural networks are discriminative for categorization, inaccurate localization is still a major source of error for detection. Building upon high-capacity CNN architectures, we address the localization problem by 1) using a search algorithm based on Bayesian optimization that sequentially proposes candidate regions for an object bounding box, and 2) training the CNN with a structured loss that explicitly penalizes the localization inaccuracy. In experiments, we demonstrated that each of the proposed methods improves the detection performance over the baseline method on PASCAL VOC 2007 and 2012 datasets. Furthermore, two methods are complementary and significantly outperform the previous state-of-the-art when combined.



