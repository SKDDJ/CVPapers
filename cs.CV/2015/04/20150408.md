# Arxiv Papers in cs.CV on 2015-04-08
### A Multicomponent Approach to Nonrigid Registration of Diffusion Tensor Images
- **Arxiv ID**: http://arxiv.org/abs/1504.01800v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01800v2)
- **Published**: 2015-04-08 02:02:55+00:00
- **Updated**: 2015-04-14 12:27:57+00:00
- **Authors**: Mohammed Khader, A. Ben Hamza
- **Comment**: 19 pages, 9 figures
- **Journal**: None
- **Summary**: We propose a nonrigid registration approach for diffusion tensor images using a multicomponent information-theoretic measure. Explicit orientation optimization is enabled by incorporating tensor reorientation, which is necessary for wrapping diffusion tensor images. Experimental results on diffusion tensor images indicate the feasibility of the proposed approach and a much better performance compared to the affine registration method based on mutual information in terms of registration accuracy in the presence of geometric distortion.



### Kernelized Low Rank Representation on Grassmann Manifolds
- **Arxiv ID**: http://arxiv.org/abs/1504.01806v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01806v1)
- **Published**: 2015-04-08 02:37:49+00:00
- **Updated**: 2015-04-08 02:37:49+00:00
- **Authors**: Boyue Wang, Yongli Hu, Junbin Gao, Yanfeng Sun, Baocai Yin
- **Comment**: 13 pages
- **Journal**: None
- **Summary**: Low rank representation (LRR) has recently attracted great interest due to its pleasing efficacy in exploring low-dimensional subspace structures embedded in data. One of its successful applications is subspace clustering which means data are clustered according to the subspaces they belong to. In this paper, at a higher level, we intend to cluster subspaces into classes of subspaces. This is naturally described as a clustering problem on Grassmann manifold. The novelty of this paper is to generalize LRR on Euclidean space onto an LRR model on Grassmann manifold in a uniform kernelized framework. The new methods have many applications in computer vision tasks. Several clustering experiments are conducted on handwritten digit images, dynamic textures, human face clips and traffic scene sequences. The experimental results show that the proposed methods outperform a number of state-of-the-art subspace clustering methods.



### Low Rank Representation on Grassmann Manifolds: An Extrinsic Perspective
- **Arxiv ID**: http://arxiv.org/abs/1504.01807v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01807v1)
- **Published**: 2015-04-08 02:38:04+00:00
- **Updated**: 2015-04-08 02:38:04+00:00
- **Authors**: Boyue Wang, Yongli Hu, Junbin Gao, Yanfeng Sun, Baocai Yin
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: Many computer vision algorithms employ subspace models to represent data. The Low-rank representation (LRR) has been successfully applied in subspace clustering for which data are clustered according to their subspace structures. The possibility of extending LRR on Grassmann manifold is explored in this paper. Rather than directly embedding Grassmann manifold into a symmetric matrix space, an extrinsic view is taken by building the self-representation of LRR over the tangent space of each Grassmannian point. A new algorithm for solving the proposed Grassmannian LRR model is designed and implemented. Several clustering experiments are conducted on handwritten digits dataset, dynamic texture video clips and YouTube celebrity face video data. The experimental results show our method outperforms a number of existing methods.



### Robust real time face recognition and tracking on gpu using fusion of rgb and depth image
- **Arxiv ID**: http://arxiv.org/abs/1504.01883v1
- **DOI**: 10.5121/csit.2015.50601
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01883v1)
- **Published**: 2015-04-08 09:34:30+00:00
- **Updated**: 2015-04-08 09:34:30+00:00
- **Authors**: Narmada Naik, G. N Rathna
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a real-time face recognition system using kinect sensor. The algorithm is implemented on GPU using opencl and significant speed improvements are observed. We use kinect depth image to increase the robustness and reduce computational cost of conventional LBP based face recognition. The main objective of this paper was to perform robust, high speed fusion based face recognition and tracking. The algorithm is mainly composed of three steps. First step is to detect all faces in the video using viola jones algorithm. The second step is online database generation using a tracking window on the face. A modified LBP feature vector is calculated using fusion information from depth and greyscale image on GPU. This feature vector is used to train a svm classifier. Third step involves recognition of multiple faces based on our modified feature vector.



### Evaluating Two-Stream CNN for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1504.01920v1
- **DOI**: 10.1145/2671188.2749406
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01920v1)
- **Published**: 2015-04-08 11:29:21+00:00
- **Updated**: 2015-04-08 11:29:21+00:00
- **Authors**: Hao Ye, Zuxuan Wu, Rui-Wei Zhao, Xi Wang, Yu-Gang Jiang, Xiangyang Xue
- **Comment**: ACM ICMR'15
- **Journal**: None
- **Summary**: Videos contain very rich semantic information. Traditional hand-crafted features are known to be inadequate in analyzing complex video semantics. Inspired by the huge success of the deep learning methods in analyzing image, audio and text data, significant efforts are recently being devoted to the design of deep nets for video analytics. Among the many practical needs, classifying videos (or video clips) based on their major semantic categories (e.g., "skiing") is useful in many applications. In this paper, we conduct an in-depth study to investigate important implementation options that may affect the performance of deep nets on video classification. Our evaluations are conducted on top of a recent two-stream convolutional neural network (CNN) pipeline, which uses both static frames and motion optical flows, and has demonstrated competitive performance against the state-of-the-art methods. In order to gain insights and to arrive at a practical guideline, many important options are studied, including network architectures, model fusion, learning parameters and the final prediction methods. Based on the evaluations, very competitive results are attained on two popular video classification benchmarks. We hope that the discussions and conclusions from this work can help researchers in related fields to quickly set up a good basis for further investigations along this very promising direction.



### MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
- **Arxiv ID**: http://arxiv.org/abs/1504.01942v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01942v1)
- **Published**: 2015-04-08 12:56:38+00:00
- **Updated**: 2015-04-08 12:56:38+00:00
- **Authors**: Laura Leal-Taix√©, Anton Milan, Ian Reid, Stefan Roth, Konrad Schindler
- **Comment**: None
- **Journal**: None
- **Summary**: In the recent past, the computer vision community has developed centralized benchmarks for the performance evaluation of a variety of tasks, including generic object and pedestrian detection, 3D reconstruction, optical flow, single-object short-term tracking, and stereo estimation. Despite potential pitfalls of such benchmarks, they have proved to be extremely helpful to advance the state of the art in the respective area. Interestingly, there has been rather limited work on the standardization of quantitative benchmarks for multiple target tracking. One of the few exceptions is the well-known PETS dataset, targeted primarily at surveillance applications. Despite being widely used, it is often applied inconsistently, for example involving using different subsets of the available data, different ways of training the models, or differing evaluation scripts. This paper describes our work toward a novel multiple object tracking benchmark aimed to address such issues. We discuss the challenges of creating such a framework, collecting existing and new data, gathering state-of-the-art methods to be tested on the datasets, and finally creating a unified evaluation system. With MOTChallenge we aim to pave the way toward a unified evaluation framework for a more meaningful quantification of multi-target tracking.



### Image Subset Selection Using Gabor Filters and Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1504.01954v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01954v1)
- **Published**: 2015-04-08 13:22:13+00:00
- **Updated**: 2015-04-08 13:22:13+00:00
- **Authors**: Heider K. Ali, Anthony Whitehead
- **Comment**: 14 pages
- **Journal**: None
- **Summary**: An automatic method for the selection of subsets of images, both modern and historic, out of a set of landmark large images collected from the Internet is presented in this paper. This selection depends on the extraction of dominant features using Gabor filtering. Features are selected carefully from a preliminary image set and fed into a neural network as a training data. The method collects a large set of raw landmark images containing modern and historic landmark images and non-landmark images. The method then processes these images to classify them as landmark and non-landmark images. The classification performance highly depends on the number of candidate features of the landmark.



### Pixel-wise Deep Learning for Contour Detection
- **Arxiv ID**: http://arxiv.org/abs/1504.01989v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1504.01989v1)
- **Published**: 2015-04-08 14:44:20+00:00
- **Updated**: 2015-04-08 14:44:20+00:00
- **Authors**: Jyh-Jing Hwang, Tyng-Luh Liu
- **Comment**: 2 pages. arXiv admin note: substantial text overlap with
  arXiv:1412.6857
- **Journal**: None
- **Summary**: We address the problem of contour detection via per-pixel classifications of edge point. To facilitate the process, the proposed approach leverages with DenseNet, an efficient implementation of multiscale convolutional neural networks (CNNs), to extract an informative feature vector for each pixel and uses an SVM classifier to accomplish contour detection. In the experiment of contour detection, we look into the effectiveness of combining per-pixel features from different CNN layers and verify their performance on BSDS500.



