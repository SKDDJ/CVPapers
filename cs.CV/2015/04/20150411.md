# Arxiv Papers in cs.CV on 2015-04-11
### siftservice.com - Turning a Computer Vision algorithm into a World Wide Web Service
- **Arxiv ID**: http://arxiv.org/abs/1504.02840v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.02840v1)
- **Published**: 2015-04-11 05:47:09+00:00
- **Updated**: 2015-04-11 05:47:09+00:00
- **Authors**: Ahmad Pahlavan Tafti, Hamid Hassannia, Zeyun Yu
- **Comment**: 8 pages, 7 figures
- **Journal**: None
- **Summary**: Image features detection and description is a longstanding topic in computer vision and pattern recognition areas. The Scale Invariant Feature Transform (SIFT) is probably the most popular and widely demanded feature descriptor which facilitates a variety of computer vision applications such as image registration, object tracking, image forgery detection, and 3D surface reconstruction. This work introduces a Software as a Service (SaaS) based implementation of the SIFT algorithm which is freely available at http://siftservice.com for any academic, educational and research purposes. The service provides application-to-application interaction and aims Rapid Application Development (RAD) and also fast prototyping for computer vision students and researchers all around the world. An Internet connection is all they need!



### High Density Noise Removal by Cascading Algorithms
- **Arxiv ID**: http://arxiv.org/abs/1504.02856v1
- **DOI**: 10.1109/ACCT.2015.100
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.02856v1)
- **Published**: 2015-04-11 10:21:56+00:00
- **Updated**: 2015-04-11 10:21:56+00:00
- **Authors**: Arabinda Dash, Sujaya Kumar Sathua
- **Comment**: 6 pages, 6 figures
- **Journal**: None
- **Summary**: An advanced non-linear cascading filter algorithm for the removal of high density salt and pepper noise from the digital images is proposed. The proposed method consists of two stages. The first stage Decision base Median Filter (DMF) acts as the preliminary noise removal algorithm. The second stage is either Modified Decision Base Partial Trimmed Global Mean Filter (MDBPTGMF) or Modified Decision Based Unsymmetric Trimmed Median Filter (MDBUTMF) which is used to remove the remaining noise and enhance the image quality. The DMF algorithm performs well at low noise density but it fails to remove the noise at medium and high level. The MDBPTGMF and MDUTMF have excellent performance at low, medium and high noise density but these reduce the image quality and blur the image at high noise level. So the basic idea behind this paper is to combine the advantages of the filters used in both the stages to remove the Salt and Pepper noise and enhance the image quality at all the noise density level. The proposed method is tested against different gray scale images and it gives better Mean Absolute Error (MAE), Peak Signal to Noise Ratio (PSNR) and Image Enhancement Factor (IEF) than the Adaptive Median Filter (AMF), Decision Base Unsymmetric Trimmed Median Filter (DBUTMF), Modified Decision Base Unsymmetric Trimmed Median Filter (MDBUTMF) and Decision Base Partial Trimmed Global Mean Filter (DBPTGMF).



### Appearance-Based Gaze Estimation in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1504.02863v1
- **DOI**: 10.1109/CVPR.2015.7299081
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.02863v1)
- **Published**: 2015-04-11 11:52:33+00:00
- **Updated**: 2015-04-11 11:52:33+00:00
- **Authors**: Xucong Zhang, Yusuke Sugano, Mario Fritz, Andreas Bulling
- **Comment**: None
- **Journal**: None
- **Summary**: Appearance-based gaze estimation is believed to work well in real-world settings, but existing datasets have been collected under controlled laboratory conditions and methods have been not evaluated across multiple datasets. In this work we study appearance-based gaze estimation in the wild. We present the MPIIGaze dataset that contains 213,659 images we collected from 15 participants during natural everyday laptop use over more than three months. Our dataset is significantly more variable than existing ones with respect to appearance and illumination. We also present a method for in-the-wild appearance-based gaze estimation using multimodal convolutional neural networks that significantly outperforms state-of-the art methods in the most challenging cross-dataset evaluation. We present an extensive evaluation of several state-of-the-art image-based gaze estimation algorithms on three current datasets, including our own. This evaluation provides clear insights and allows us to identify key research challenges of gaze estimation in the wild.



