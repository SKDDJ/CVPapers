# Arxiv Papers in cs.CV on 2015-04-26
### Computational Cost Reduction in Learned Transform Classifications
- **Arxiv ID**: http://arxiv.org/abs/1504.06779v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1504.06779v2)
- **Published**: 2015-04-26 01:16:44+00:00
- **Updated**: 2016-04-30 15:03:29+00:00
- **Authors**: Emerson Lopes Machado, Cristiano Jacques Miosso, Ricardo von Borries, Murilo Coutinho, Pedro de Azevedo Berger, Thiago Marques, Ricardo Pezzuol Jacobi
- **Comment**: None
- **Journal**: None
- **Summary**: We present a theoretical analysis and empirical evaluations of a novel set of techniques for computational cost reduction of classifiers that are based on learned transform and soft-threshold. By modifying optimization procedures for dictionary and classifier training, as well as the resulting dictionary entries, our techniques allow to reduce the bit precision and to replace each floating-point multiplication by a single integer bit shift. We also show how the optimization algorithms in some dictionary training methods can be modified to penalize higher-energy dictionaries. We applied our techniques with the classifier Learning Algorithm for Soft-Thresholding, testing on the datasets used in its original paper. Our results indicate it is feasible to use solely sums and bit shifts of integers to classify at test time with a limited reduction of the classification accuracy. These low power operations are a valuable trade off in FPGA implementations as they increase the classification throughput while decrease both energy consumption and manufacturing cost.



### Complete Dictionary Recovery over the Sphere
- **Arxiv ID**: http://arxiv.org/abs/1504.06785v3
- **DOI**: None
- **Categories**: **cs.IT**, cs.CV, cs.LG, math.IT, math.OC, stat.ML, 68P30, 58C05, 94A12, 94A08, 68T05, 90C26, 90C48, 90C55
- **Links**: [PDF](http://arxiv.org/pdf/1504.06785v3)
- **Published**: 2015-04-26 04:57:19+00:00
- **Updated**: 2015-11-17 21:56:30+00:00
- **Authors**: Ju Sun, Qing Qu, John Wright
- **Comment**: 104 pages, 5 figures. Due to length constraint of publication, this
  long paper are subsequently divided into two papers (arXiv:1511.03607 and
  arXiv:1511.04777). Further updates will be made only to the two papers
- **Journal**: None
- **Summary**: We consider the problem of recovering a complete (i.e., square and invertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb R^{n \times p}$ with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ is sufficiently sparse. This recovery problem is central to the theoretical understanding of dictionary learning, which seeks a sparse representation for a collection of input signals, and finds numerous applications in modern signal processing and machine learning. We give the first efficient algorithm that provably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros per column, under suitable probability model for $\mathbf X_0$. In contrast, prior results based on efficient algorithms provide recovery guarantees when $\mathbf X_0$ has only $O(n^{1-\delta})$ nonzeros per column for any constant $\delta \in (0, 1)$.   Our algorithmic pipeline centers around solving a certain nonconvex optimization problem with a spherical constraint, and hence is naturally phrased in the language of manifold optimization. To show this apparently hard problem is tractable, we first provide a geometric characterization of the high-dimensional objective landscape, which shows that with high probability there are no "spurious" local minima. This particular geometric structure allows us to design a Riemannian trust region algorithm over the sphere that provably converges to one local minimizer with an arbitrary initialization, despite the presence of saddle points. The geometric approach we develop here may also shed light on other problems arising from nonconvex recovery of structured signals.



### Deviation Based Pooling Strategies For Full Reference Image Quality Assessment
- **Arxiv ID**: http://arxiv.org/abs/1504.06786v2
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.06786v2)
- **Published**: 2015-04-26 05:06:33+00:00
- **Updated**: 2015-05-06 19:37:36+00:00
- **Authors**: Hossein Ziaei Nafchi, Rachid Hedjam, Atena Shahkolaei, Mohamed Cheriet
- **Comment**: None
- **Journal**: None
- **Summary**: The state-of-the-art pooling strategies for perceptual image quality assessment (IQA) are based on the mean and the weighted mean. They are robust pooling strategies which usually provide a moderate to high performance for different IQAs. Recently, standard deviation (SD) pooling was also proposed. Although, this deviation pooling provides a very high performance for a few IQAs, its performance is lower than mean poolings for many other IQAs. In this paper, we propose to use the mean absolute deviation (MAD) and show that it is a more robust and accurate pooling strategy for a wider range of IQAs. In fact, MAD pooling has the advantages of both mean pooling and SD pooling. The joint computation and use of the MAD and SD pooling strategies is also considered in this paper. Experimental results provide useful information on the choice of the proper deviation pooling strategy for different IQA models.



### Max-margin Deep Generative Models
- **Arxiv ID**: http://arxiv.org/abs/1504.06787v4
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.06787v4)
- **Published**: 2015-04-26 06:01:19+00:00
- **Updated**: 2015-12-15 03:01:06+00:00
- **Authors**: Chongxuan Li, Jun Zhu, Tianlin Shi, Bo Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Deep generative models (DGMs) are effective on learning multilayered representations of complex data and performing inference of input data by exploring the generative ability. However, little work has been done on examining or empowering the discriminative ability of DGMs on making accurate predictions. This paper presents max-margin deep generative models (mmDGMs), which explore the strongly discriminative principle of max-margin learning to improve the discriminative power of DGMs, while retaining the generative capability. We develop an efficient doubly stochastic subgradient algorithm for the piecewise linear objective. Empirical results on MNIST and SVHN datasets demonstrate that (1) max-margin learning can significantly improve the prediction performance of DGMs and meanwhile retain the generative ability; and (2) mmDGMs are competitive to the state-of-the-art fully discriminative networks by employing deep convolutional neural networks (CNNs) as both recognition and generative models.



### FlowNet: Learning Optical Flow with Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/1504.06852v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, I.2.6; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1504.06852v2)
- **Published**: 2015-04-26 17:30:32+00:00
- **Updated**: 2015-05-04 08:50:57+00:00
- **Authors**: Philipp Fischer, Alexey Dosovitskiy, Eddy Ilg, Philip Häusser, Caner Hazırbaş, Vladimir Golkov, Patrick van der Smagt, Daniel Cremers, Thomas Brox
- **Comment**: Added supplementary material
- **Journal**: None
- **Summary**: Convolutional neural networks (CNNs) have recently been very successful in a variety of computer vision tasks, especially on those linked to recognition. Optical flow estimation has not been among the tasks where CNNs were successful. In this paper we construct appropriate CNNs which are capable of solving the optical flow estimation problem as a supervised learning task. We propose and compare two architectures: a generic architecture and another one including a layer that correlates feature vectors at different image locations.   Since existing ground truth data sets are not sufficiently large to train a CNN, we generate a synthetic Flying Chairs dataset. We show that networks trained on this unrealistic data still generalize very well to existing datasets such as Sintel and KITTI, achieving competitive accuracy at frame rates of 5 to 10 fps.



### Fast Dictionary Matching for Content-based Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1504.06864v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.06864v1)
- **Published**: 2015-04-26 18:41:51+00:00
- **Updated**: 2015-04-26 18:41:51+00:00
- **Authors**: Patryk Najgebauer, Janusz Rygal, Tomasz Nowak, Jakub Romanowski, Leszek Rutkowski, Sviatoslav Voloshynovskiy, Rafal Scherer
- **Comment**: Accepted for the 14th International Conference on Artificial
  Intelligence and Soft Computing, ICAISC, June 14-18, 2015, Zakopane, Poland,
  http://www.icaisc.eu/
- **Journal**: None
- **Summary**: This paper describes a method for searching for common sets of descriptors between collections of images. The presented method operates on local interest keypoints, which are generated using the SURF algorithm. The use of a dictionary of descriptors allowed achieving good performance of the content-based image retrieval. The method can be used to initially determine a set of similar pairs of keypoints between images. For this purpose, we use a certain level of tolerance between values of descriptors, as values of feature descriptors are almost never equal but similar between different images. After that, the method compares the structure of rotation and location of interest points in one image with the point structure in other images. Thus, we were able to find similar areas in images and determine the level of similarity between them, even when images contain different scenes.



