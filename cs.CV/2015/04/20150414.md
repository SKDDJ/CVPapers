# Arxiv Papers in cs.CV on 2015-04-14
### Clustering Assisted Fundamental Matrix Estimation
- **Arxiv ID**: http://arxiv.org/abs/1504.03409v1
- **DOI**: 10.5121/csit.2015.50604
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03409v1)
- **Published**: 2015-04-14 03:13:40+00:00
- **Updated**: 2015-04-14 03:13:40+00:00
- **Authors**: Hao Wu, Yi Wan
- **Comment**: 12 pages, 8 figures, 3 tables, Second International Conference on
  Computer Science and Information Technology (COSIT 2015) March 21~22, 2015,
  Geneva, Switzerland
- **Journal**: None
- **Summary**: In computer vision, the estimation of the fundamental matrix is a basic problem that has been extensively studied. The accuracy of the estimation imposes a significant influence on subsequent tasks such as the camera trajectory determination and 3D reconstruction. In this paper we propose a new method for fundamental matrix estimation that makes use of clustering a group of 4D vectors. The key insight is the observation that among the 4D vectors constructed from matching pairs of points obtained from the SIFT algorithm, well-defined cluster points tend to be reliable inliers suitable for fundamental matrix estimation. Based on this, we utilizes a recently proposed efficient clustering method through density peaks seeking and propose a new clustering assisted method. Experimental results show that the proposed algorithm is faster and more accurate than currently commonly used methods.



### Simultaneous Feature Learning and Hash Coding with Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1504.03410v1
- **DOI**: 10.1109/CVPR.2015.7298947
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03410v1)
- **Published**: 2015-04-14 03:14:24+00:00
- **Updated**: 2015-04-14 03:14:24+00:00
- **Authors**: Hanjiang Lai, Yan Pan, Ye Liu, Shuicheng Yan
- **Comment**: This paper has been accepted to IEEE International Conference on
  Pattern Recognition and Computer Vision (CVPR), 2015
- **Journal**: None
- **Summary**: Similarity-preserving hashing is a widely-used method for nearest neighbour search in large-scale image retrieval tasks. For most existing hashing methods, an image is first encoded as a vector of hand-engineering visual features, followed by another separate projection or quantization step that generates binary codes. However, such visual feature vectors may not be optimally compatible with the coding process, thus producing sub-optimal hashing codes. In this paper, we propose a deep architecture for supervised hashing, in which images are mapped into binary codes via carefully designed deep neural networks. The pipeline of the proposed deep architecture consists of three building blocks: 1) a sub-network with a stack of convolution layers to produce the effective intermediate image features; 2) a divide-and-encode module to divide the intermediate image features into multiple branches, each encoded into one hash bit; and 3) a triplet ranking loss designed to characterize that one image is more similar to the second image than to the third one. Extensive evaluations on several benchmark image datasets show that the proposed simultaneous feature learning and hash coding pipeline brings substantial improvements over other state-of-the-art supervised or unsupervised hashing methods.



### Image Denoising Using Low Rank Minimization With Modified Noise Estimation
- **Arxiv ID**: http://arxiv.org/abs/1504.03439v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03439v2)
- **Published**: 2015-04-14 07:18:48+00:00
- **Updated**: 2015-04-24 11:30:32+00:00
- **Authors**: Zahid Hussain Shamsi, Hyun Sook Oh, Dai-Gyoung Kim
- **Comment**: 4 pages, 8 figures
- **Journal**: None
- **Summary**: Recently, the application of low rank minimization to image denoising has shown remarkable denoising results which are equivalent or better than those of the existing state-of-the-art algorithms. However, due to iterative nature of low rank optimization, estimation of residual noise is an essential requirement after each iteration. Currently, this noise is estimated by using the filtered noise in the previous iteration without considering the geometric structure of the given image. This estimate may be affected in the presence of moderate and severe levels of noise. To obtain a more reliable estimate of residual noise, we propose a modified algorithm (GWNNM) which includes the contribution of the geometric structure of an image to the existing noise estimation. Furthermore, the proposed algorithm exploits the difference of large and small singular values to enhance the edges and textures during the denoising process. Consequently, the proposed modifications achieve significant improvements in the denoising results of the existing low rank optimization algorithms.



### Sketch-based 3D Shape Retrieval using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1504.03504v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03504v1)
- **Published**: 2015-04-14 11:55:45+00:00
- **Updated**: 2015-04-14 11:55:45+00:00
- **Authors**: Fang Wang, Le Kang, Yi Li
- **Comment**: CVPR 2015
- **Journal**: None
- **Summary**: Retrieving 3D models from 2D human sketches has received considerable attention in the areas of graphics, image retrieval, and computer vision. Almost always in state of the art approaches a large amount of "best views" are computed for 3D models, with the hope that the query sketch matches one of these 2D projections of 3D models using predefined features.   We argue that this two stage approach (view selection -- matching) is pragmatic but also problematic because the "best views" are subjective and ambiguous, which makes the matching inputs obscure. This imprecise nature of matching further makes it challenging to choose features manually. Instead of relying on the elusive concept of "best views" and the hand-crafted features, we propose to define our views using a minimalism approach and learn features for both sketches and views. Specifically, we drastically reduce the number of views to only two predefined directions for the whole dataset. Then, we learn two Siamese Convolutional Neural Networks (CNNs), one for the views and one for the sketches. The loss function is defined on the within-domain as well as the cross-domain similarities. Our experiments on three benchmark datasets demonstrate that our method is significantly better than state of the art approaches, and outperforms them in all conventional metrics.



### Efficient Scene Text Localization and Recognition with Local Character Refinement
- **Arxiv ID**: http://arxiv.org/abs/1504.03522v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03522v1)
- **Published**: 2015-04-14 12:42:56+00:00
- **Updated**: 2015-04-14 12:42:56+00:00
- **Authors**: Lukáš Neumann, Jiří Matas
- **Comment**: None
- **Journal**: None
- **Summary**: An unconstrained end-to-end text localization and recognition method is presented. The method detects initial text hypothesis in a single pass by an efficient region-based method and subsequently refines the text hypothesis using a more robust local text model, which deviates from the common assumption of region-based methods that all characters are detected as connected components.   Additionally, a novel feature based on character stroke area estimation is introduced. The feature is efficiently computed from a region distance map, it is invariant to scaling and rotations and allows to efficiently detect text regions regardless of what portion of text they capture.   The method runs in real time and achieves state-of-the-art text localization and recognition results on the ICDAR 2013 Robust Reading dataset.



### Building Proteins in a Day: Efficient 3D Molecular Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1504.03573v1
- **DOI**: 10.1109/CVPR.2015.7298929
- **Categories**: **cs.CV**, q-bio.QM
- **Links**: [PDF](http://arxiv.org/pdf/1504.03573v1)
- **Published**: 2015-04-14 14:56:17+00:00
- **Updated**: 2015-04-14 14:56:17+00:00
- **Authors**: Marcus A. Brubaker, Ali Punjani, David J. Fleet
- **Comment**: To be presented at IEEE Conference on Computer Vision and Pattern
  Recognition (CVPR) 2015
- **Journal**: None
- **Summary**: Discovering the 3D atomic structure of molecules such as proteins and viruses is a fundamental research problem in biology and medicine. Electron Cryomicroscopy (Cryo-EM) is a promising vision-based technique for structure estimation which attempts to reconstruct 3D structures from 2D images. This paper addresses the challenging problem of 3D reconstruction from 2D Cryo-EM images. A new framework for estimation is introduced which relies on modern stochastic optimization techniques to scale to large datasets. We also introduce a novel technique which reduces the cost of evaluating the objective function during optimization by over five orders or magnitude. The net result is an approach capable of estimating 3D molecular structure from large scale datasets in about a day on a single workstation.



### Learning to Compare Image Patches via Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1504.03641v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1504.03641v1)
- **Published**: 2015-04-14 17:53:51+00:00
- **Updated**: 2015-04-14 17:53:51+00:00
- **Authors**: Sergey Zagoruyko, Nikos Komodakis
- **Comment**: CVPR 2015
- **Journal**: None
- **Summary**: In this paper we show how to learn directly from image data (i.e., without resorting to manually-designed features) a general similarity function for comparing image patches, which is a task of fundamental importance for many computer vision problems. To encode such a function, we opt for a CNN-based model that is trained to account for a wide variety of changes in image appearance. To that end, we explore and study multiple neural network architectures, which are specifically adapted to this task. We show that such an approach can significantly outperform the state-of-the-art on several problems and benchmark datasets.



### Background Subtraction via Generalized Fused Lasso Foreground Modeling
- **Arxiv ID**: http://arxiv.org/abs/1504.03707v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03707v1)
- **Published**: 2015-04-14 20:25:27+00:00
- **Updated**: 2015-04-14 20:25:27+00:00
- **Authors**: Bo Xin, Yuan Tian, Yizhou Wang, Wen Gao
- **Comment**: None
- **Journal**: None
- **Summary**: Background Subtraction (BS) is one of the key steps in video analysis. Many background models have been proposed and achieved promising performance on public data sets. However, due to challenges such as illumination change, dynamic background etc. the resulted foreground segmentation often consists of holes as well as background noise. In this regard, we consider generalized fused lasso regularization to quest for intact structured foregrounds. Together with certain assumptions about the background, such as the low-rank assumption or the sparse-composition assumption (depending on whether pure background frames are provided), we formulate BS as a matrix decomposition problem using regularization terms for both the foreground and background matrices. Moreover, under the proposed formulation, the two generally distinctive background assumptions can be solved in a unified manner. The optimization was carried out via applying the augmented Lagrange multiplier (ALM) method in such a way that a fast parametric-flow algorithm is used for updating the foreground matrix. Experimental results on several popular BS data sets demonstrate the advantage of the proposed model compared to state-of-the-arts.



