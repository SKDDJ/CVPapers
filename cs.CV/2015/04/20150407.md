# Arxiv Papers in cs.CV on 2015-04-07
### Locally Non-rigid Registration for Mobile HDR Photography
- **Arxiv ID**: http://arxiv.org/abs/1504.01441v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01441v3)
- **Published**: 2015-04-07 00:29:54+00:00
- **Updated**: 2015-05-05 00:15:00+00:00
- **Authors**: Orazio Gallo, Alejandro Troccoli, Jun Hu, Kari Pulli, Jan Kautz
- **Comment**: None
- **Journal**: None
- **Summary**: Image registration for stack-based HDR photography is challenging. If not properly accounted for, camera motion and scene changes result in artifacts in the composite image. Unfortunately, existing methods to address this problem are either accurate, but too slow for mobile devices, or fast, but prone to failing. We propose a method that fills this void: our approach is extremely fast---under 700ms on a commercial tablet for a pair of 5MP images---and prevents the artifacts that arise from insufficient registration quality.



### A comparative study between proposed Hyper Kurtosis based Modified Duo-Histogram Equalization (HKMDHE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) for Contrast Enhancement Purpose of Low Contrast Human Brain CT scan images
- **Arxiv ID**: http://arxiv.org/abs/1505.06219v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1505.06219v1)
- **Published**: 2015-04-07 01:26:06+00:00
- **Updated**: 2015-04-07 01:26:06+00:00
- **Authors**: Sabyasachi Mukhopadhyay, Soham Mandal, Sawon Pratiher, Satyasaran Changdar, Ritwik Burman, Nirmalya Ghosh, Prasanta K. Panigrahi
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, a comparative study between proposed hyper kurtosis based modified duo-histogram equalization (HKMDHE) algorithm and contrast limited adaptive histogram enhancement (CLAHE) has been presented for the implementation of contrast enhancement and brightness preservation of low contrast human brain CT scan images. In HKMDHE algorithm, contrast enhancement is done on the hyper-kurtosis based application. The results are very promising of proposed HKMDHE technique with improved PSNR values and lesser AMMBE values than CLAHE technique.



### Mobile Phone Based Vehicle License Plate Recognition for Road Policing
- **Arxiv ID**: http://arxiv.org/abs/1504.01476v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01476v1)
- **Published**: 2015-04-07 05:25:42+00:00
- **Updated**: 2015-04-07 05:25:42+00:00
- **Authors**: Lajish V. L., Sunil Kumar Kopparapu
- **Comment**: 7 pages; PReMI Experiential Workshop, Delhi
- **Journal**: None
- **Summary**: Identity of a vehicle is done through the vehicle license plate by traffic police in general. Au- tomatic vehicle license plate recognition has several applications in intelligent traffic management systems. The security situation across the globe and particularly in India demands a need to equip the traffic police with a system that enables them to get instant details of a vehicle. The system should be easy to use, should be mobile, and work 24 x 7. In this paper, we describe a mobile phone based, client-server architected, license plate recognition system. While we use the state of the art image processing and pattern recognition algorithms tuned for Indian conditions to automatically recognize non-uniform license plates, the main contribution is in creating an end to end usable solution. The client application runs on a mobile device and a server application, with access to vehicle information database, is hosted centrally. The solution enables capture of license plate image captured by the phone camera and passes to the server; on the server the license plate number is recognized; the data associated with the number plate is then sent back to the mobile device, instantaneously. We describe the end to end system architecture in detail. A working prototype of the proposed system has been implemented in the lab environment.



### On-line Handwritten Devanagari Character Recognition using Fuzzy Directional Features
- **Arxiv ID**: http://arxiv.org/abs/1504.01488v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01488v1)
- **Published**: 2015-04-07 06:31:58+00:00
- **Updated**: 2015-04-07 06:31:58+00:00
- **Authors**: Sunil Kumar Kopparapu, Lajish VL
- **Comment**: 6 pages; 2009
- **Journal**: None
- **Summary**: This paper describes a new feature set for use in the recognition of on-line handwritten Devanagari script based on Fuzzy Directional Features. Experiments are conducted for the automatic recognition of isolated handwritten character primitives (sub-character units). Initially we describe the proposed feature set, called the Fuzzy Directional Features (FDF) and then show how these features can be effectively utilized for writer independent character recognition. Experimental results show that FDF set perform well for writer independent data set at stroke level recognition. The main contribution of this paper is the introduction of a novel feature set and establish experimentally its ability in recognition of handwritten Devanagari script.



### Efficient SDP Inference for Fully-connected CRFs Based on Low-rank Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1504.01492v1
- **DOI**: 10.1109/CVPR.2015.7298942
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1504.01492v1)
- **Published**: 2015-04-07 06:43:50+00:00
- **Updated**: 2015-04-07 06:43:50+00:00
- **Authors**: Peng Wang, Chunhua Shen, Anton van den Hengel
- **Comment**: 15 pages. A conference version of this work appears in Proc. IEEE
  Conference on Computer Vision and Pattern Recognition, 2015
- **Journal**: None
- **Summary**: Conditional Random Fields (CRF) have been widely used in a variety of computer vision tasks. Conventional CRFs typically define edges on neighboring image pixels, resulting in a sparse graph such that efficient inference can be performed. However, these CRFs fail to model long-range contextual relationships. Fully-connected CRFs have thus been proposed. While there are efficient approximate inference methods for such CRFs, usually they are sensitive to initialization and make strong assumptions. In this work, we develop an efficient, yet general algorithm for inference on fully-connected CRFs. The algorithm is based on a scalable SDP algorithm and the low- rank approximation of the similarity/kernel matrix. The core of the proposed algorithm is a tailored quasi-Newton method that takes advantage of the low-rank matrix approximation when solving the specialized SDP dual problem. Experiments demonstrate that our method can be applied on fully-connected CRFs that cannot be solved previously, such as pixel-level image co-segmentation.



### Separable time-causal and time-recursive spatio-temporal receptive fields
- **Arxiv ID**: http://arxiv.org/abs/1504.01502v1
- **DOI**: 10.1007/978-3-319-18461-6_8
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1504.01502v1)
- **Published**: 2015-04-07 07:29:54+00:00
- **Updated**: 2015-04-07 07:29:54+00:00
- **Authors**: Tony Lindeberg
- **Comment**: 12 pages, 2 figures, 2 tables. arXiv admin note: substantial text
  overlap with arXiv:1404.2037
- **Journal**: Proc SSVM 2015: Scale-Space and Variational Methods for Computer
  Vision, Springer LNCS vol 9087, pages 90-102, 2015
- **Summary**: We present an improved model and theory for time-causal and time-recursive spatio-temporal receptive fields, obtained by a combination of Gaussian receptive fields over the spatial domain and first-order integrators or equivalently truncated exponential filters coupled in cascade over the temporal domain. Compared to previous spatio-temporal scale-space formulations in terms of non-enhancement of local extrema or scale invariance, these receptive fields are based on different scale-space axiomatics over time by ensuring non-creation of new local extrema or zero-crossings with increasing temporal scale. Specifically, extensions are presented about parameterizing the intermediate temporal scale levels, analysing the resulting temporal dynamics and transferring the theory to a discrete implementation in terms of recursive filters over time.



### Simultaneously sparse and low-rank abundance matrix estimation for hyperspectral image unmixing
- **Arxiv ID**: http://arxiv.org/abs/1504.01515v2
- **DOI**: 10.1109/TGRS.2016.2551327
- **Categories**: **cs.CV**, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1504.01515v2)
- **Published**: 2015-04-07 08:23:45+00:00
- **Updated**: 2015-10-14 16:53:41+00:00
- **Authors**: Paris Giampouras, Konstantinos Themelis, Athanasios Rontogiannis, Konstantinos Koutroumbas
- **Comment**: 30 pages, 9 figures
- **Journal**: None
- **Summary**: In a plethora of applications dealing with inverse problems, e.g. in image processing, social networks, compressive sensing, biological data processing etc., the signal of interest is known to be structured in several ways at the same time. This premise has recently guided the research to the innovative and meaningful idea of imposing multiple constraints on the parameters involved in the problem under study. For instance, when dealing with problems whose parameters form sparse and low-rank matrices, the adoption of suitably combined constraints imposing sparsity and low-rankness, is expected to yield substantially enhanced estimation results. In this paper, we address the spectral unmixing problem in hyperspectral images. Specifically, two novel unmixing algorithms are introduced, in an attempt to exploit both spatial correlation and sparse representation of pixels lying in homogeneous regions of hyperspectral images. To this end, a novel convex mixed penalty term is first defined consisting of the sum of the weighted $\ell_1$ and the weighted nuclear norm of the abundance matrix corresponding to a small area of the image determined by a sliding square window. This penalty term is then used to regularize a conventional quadratic cost function and impose simultaneously sparsity and row-rankness on the abundance matrix. The resulting regularized cost function is minimized by a) an incremental proximal sparse and low-rank unmixing algorithm and b) an algorithm based on the alternating minimization method of multipliers (ADMM). The effectiveness of the proposed algorithms is illustrated in experiments conducted both on simulated and real data.



### Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for Video Classification
- **Arxiv ID**: http://arxiv.org/abs/1504.01561v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1504.01561v1)
- **Published**: 2015-04-07 11:53:46+00:00
- **Updated**: 2015-04-07 11:53:46+00:00
- **Authors**: Zuxuan Wu, Xi Wang, Yu-Gang Jiang, Hao Ye, Xiangyang Xue
- **Comment**: None
- **Journal**: None
- **Summary**: Classifying videos according to content semantics is an important problem with a wide range of applications. In this paper, we propose a hybrid deep learning framework for video classification, which is able to model static spatial information, short-term motion, as well as long-term temporal clues in the videos. Specifically, the spatial and the short-term motion features are extracted separately by two Convolutional Neural Networks (CNN). These two types of CNN-based features are then combined in a regularized feature fusion network for classification, which is able to learn and utilize feature relationships for improved performance. In addition, Long Short Term Memory (LSTM) networks are applied on top of the two features to further model longer-term temporal clues. The main contribution of this work is the hybrid learning framework that can model several important aspects of the video data. We also show that (1) combining the spatial and the short-term motion features in the regularized fusion network is better than direct classification and fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is highly complementary to the traditional classification strategy without considering the temporal frame orders. Extensive experiments are conducted on two popular and challenging benchmarks, the UCF-101 Human Actions and the Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves to-date the best reported performance: $91.3\%$ on the UCF-101 and $83.5\%$ on the CCV.



### Ego-Object Discovery
- **Arxiv ID**: http://arxiv.org/abs/1504.01639v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/1504.01639v2)
- **Published**: 2015-04-07 15:23:22+00:00
- **Updated**: 2015-07-08 09:19:48+00:00
- **Authors**: Marc Bolaños, Petia Radeva
- **Comment**: 9 pages, 13 figures, Submitted to: Image and Vision Computing
- **Journal**: None
- **Summary**: Lifelogging devices are spreading faster everyday. This growth can represent great benefits to develop methods for extraction of meaningful information about the user wearing the device and his/her environment. In this paper, we propose a semi-supervised strategy for easily discovering objects relevant to the person wearing a first-person camera. Given an egocentric video/images sequence acquired by the camera, our algorithm uses both the appearance extracted by means of a convolutional neural network and an object refill methodology that allows to discover objects even in case of small amount of object appearance in the collection of images. An SVM filtering strategy is applied to deal with the great part of the False Positive object candidates found by most of the state of the art object detectors. We validate our method on a new egocentric dataset of 4912 daily images acquired by 4 persons as well as on both PASCAL 2012 and MSRC datasets. We obtain for all of them results that largely outperform the state of the art approach. We make public both the EDUB dataset and the algorithm code.



### An Empirical Evaluation of Deep Learning on Highway Driving
- **Arxiv ID**: http://arxiv.org/abs/1504.01716v3
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1504.01716v3)
- **Published**: 2015-04-07 19:41:59+00:00
- **Updated**: 2015-04-17 01:27:14+00:00
- **Authors**: Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Cheng-Yue, Fernando Mujica, Adam Coates, Andrew Y. Ng
- **Comment**: Added a video for lane detection
- **Journal**: None
- **Summary**: Numerous groups have applied a variety of deep learning techniques to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent deep learning advances. Computer vision, combined with deep learning, has the potential to bring about a relatively inexpensive, robust solution to autonomous driving. To prepare deep learning for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply deep learning and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that deep learning holds promise for autonomous driving.



### Design and Implementation of a 3D Undersea Camera System
- **Arxiv ID**: http://arxiv.org/abs/1504.01753v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01753v1)
- **Published**: 2015-04-07 21:05:48+00:00
- **Updated**: 2015-04-07 21:05:48+00:00
- **Authors**: Xida Chen, Steve Sutphen, Paul Macoun, Yee-Hong Yang
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we present the design and development of an undersea camera system. The goal of our system is to provide a 3D model of the undersea habitat in a long-term continuous manner. The most important feature of our system is the use of multiple cameras and multiple projectors, which is able to provide accurate 3D models with an accuracy of a millimeter. By introducing projectors in our system, we can use many different structured light methods for different tasks. There are two main advantages comparing our system with using ROVs or AUVs. First, our system can provide continuous monitoring of the undersea habitat. Second, our system has a low hardware cost. Comparing to existing deployed camera systems, the advantage of our system is that it can provide accurate 3D models and provides opportunities for future development of innovative algorithms for undersea research.



### Heterogeneous Tensor Decomposition for Clustering via Manifold Optimization
- **Arxiv ID**: http://arxiv.org/abs/1504.01777v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.01777v2)
- **Published**: 2015-04-07 23:18:34+00:00
- **Updated**: 2015-04-29 02:53:10+00:00
- **Authors**: Yanfeng Sun, Junbin Gao, Xia Hong, Bamdev Mishra, Baocai Yin
- **Comment**: 12 pages, 2 figures
- **Journal**: None
- **Summary**: Tensors or multiarray data are generalizations of matrices. Tensor clustering has become a very important research topic due to the intrinsically rich structures in real-world multiarray datasets. Subspace clustering based on vectorizing multiarray data has been extensively researched. However, vectorization of tensorial data does not exploit complete structure information. In this paper, we propose a subspace clustering algorithm without adopting any vectorization process. Our approach is based on a novel heterogeneous Tucker decomposition model. In contrast to existing techniques, we propose a new clustering algorithm that alternates between different modes of the proposed heterogeneous tensor model. All but the last mode have closed-form updates. Updating the last mode reduces to optimizing over the so-called multinomial manifold, for which we investigate second order Riemannian geometry and propose a trust-region algorithm. Numerical experiments show that our proposed algorithm compete effectively with state-of-the-art clustering algorithms that are based on tensor factorization.



