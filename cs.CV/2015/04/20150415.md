# Arxiv Papers in cs.CV on 2015-04-15
### Text Localization in Video Using Multiscale Weber's Local Descriptor
- **Arxiv ID**: http://arxiv.org/abs/1504.03810v1
- **DOI**: 10.1109/SPICES.2015.7091559
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03810v1)
- **Published**: 2015-04-15 07:56:05+00:00
- **Updated**: 2015-04-15 07:56:05+00:00
- **Authors**: B. H. Shekar, Smitha M. L.
- **Comment**: IEEE SPICES, 2015
- **Journal**: None
- **Summary**: In this paper, we propose a novel approach for detecting the text present in videos and scene images based on the Multiscale Weber's Local Descriptor (MWLD). Given an input video, the shots are identified and the key frames are extracted based on their spatio-temporal relationship. From each key frame, we detect the local region information using WLD with different radius and neighborhood relationship of pixel values and hence obtained intensity enhanced key frames at multiple scales. These multiscale WLD key frames are merged together and then the horizontal gradients are computed using morphological operations. The obtained results are then binarized and the false positives are eliminated based on geometrical properties. Finally, we employ connected component analysis and morphological dilation operation to determine the text regions that aids in text localization. The experimental results obtained on publicly available standard Hua, Horizontal-1 and Horizontal-2 video dataset illustrate that the proposed method can accurately detect and localize texts of various sizes, fonts and colors in videos.



### Tracking Live Fish from Low-Contrast and Low-Frame-Rate Stereo Videos
- **Arxiv ID**: http://arxiv.org/abs/1504.03811v1
- **DOI**: 10.1109/TCSVT.2014.2357093
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03811v1)
- **Published**: 2015-04-15 08:05:14+00:00
- **Updated**: 2015-04-15 08:05:14+00:00
- **Authors**: Meng-Che Chuang, Jenq-Neng Hwang, Kresimir Williams, Richard Towler
- **Comment**: 14 pages, 14 figures, 6 tables
- **Journal**: IEEE Trans. on Circuits and Systems for Video Technology, vol. 25,
  no. 1, pp.167-179, Jan. 2015
- **Summary**: Non-extractive fish abundance estimation with the aid of visual analysis has drawn increasing attention. Unstable illumination, ubiquitous noise and low frame rate video capturing in the underwater environment, however, make conventional tracking methods unreliable. In this paper, we present a multiple fish tracking system for low-contrast and low-frame-rate stereo videos with the use of a trawl-based underwater camera system. An automatic fish segmentation algorithm overcomes the low-contrast issues by adopting a histogram backprojection approach on double local-thresholded images to ensure an accurate segmentation on the fish shape boundaries. Built upon a reliable feature-based object matching method, a multiple-target tracking algorithm via a modified Viterbi data association is proposed to overcome the poor motion continuity and frequent entrance/exit of fish targets under low-frame-rate scenarios. In addition, a computationally efficient block-matching approach performs successful stereo matching, which enables an automatic fish-body tail compensation to greatly reduce segmentation error and allows for an accurate fish length measurement. Experimental results show that an effective and reliable tracking performance for multiple live fish with underwater stereo cameras is achieved.



### Comparisons of wavelet functions in QRS signal to noise ratio enhancement and detection accuracy
- **Arxiv ID**: http://arxiv.org/abs/1504.03834v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CE
- **Links**: [PDF](http://arxiv.org/pdf/1504.03834v2)
- **Published**: 2015-04-15 09:22:31+00:00
- **Updated**: 2015-04-16 04:35:37+00:00
- **Authors**: Pornchai Phukpattaranont
- **Comment**: 16 pages, 8 figures, Article submitted to Journal of the Korean
  Physical Society for considering of publication
- **Journal**: None
- **Summary**: We compare the capability of wavelet functions used for noise removal in preprocessing step of a QRS detection algorithm in the electrocardiogram (ECG) signal. The QRS signal to noise ratio enhancement and the detection accuracy of each wavelet function are evaluated using three measures: (1) the ratio of the maximum beat amplitude to the minimum beat amplitude (RMM), (2) the mean of absolute of time error (MATE), and (3) the figure of merit (FOM). Three wavelet functions from previous well-known publications are explored, i.e., Bior1.3, Db10, and Mexican hat wavelet functions. Results evaluated with the ECG signal from MIT-BIH arrhythmia database show that the Mexican hat wavelet function is better than the others. While the scale 8 of Mexican hat wavelet function can provide the best enhancement in QRS signal to noise ratio, the scale 4 of Mexican hat wavelet function can provide the best detection accuracy. These results may be combined and may enable the use of a single fixed threshold for all ECG records leading to the reduction in computational complexity of the QRS detection algorithm.



### Bio-inspired Unsupervised Learning of Visual Features Leads to Robust Invariant Object Recognition
- **Arxiv ID**: http://arxiv.org/abs/1504.03871v3
- **DOI**: 10.1016/j.neucom.2016.04.029
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1504.03871v3)
- **Published**: 2015-04-15 11:47:21+00:00
- **Updated**: 2016-06-28 10:54:22+00:00
- **Authors**: Saeed Reza Kheradpisheh, Mohammad Ganjtabesh, Timoth√©e Masquelier
- **Comment**: None
- **Journal**: Neurocomputing 205 (2016) 382-392
- **Summary**: Retinal image of surrounding objects varies tremendously due to the changes in position, size, pose, illumination condition, background context, occlusion, noise, and nonrigid deformations. But despite these huge variations, our visual system is able to invariantly recognize any object in just a fraction of a second. To date, various computational models have been proposed to mimic the hierarchical processing of the ventral visual pathway, with limited success. Here, we show that the association of both biologically inspired network architecture and learning rule significantly improves the models' performance when facing challenging invariant object recognition problems. Our model is an asynchronous feedforward spiking neural network. When the network is presented with natural images, the neurons in the entry layers detect edges, and the most activated ones fire first, while neurons in higher layers are equipped with spike timing-dependent plasticity. These neurons progressively become selective to intermediate complexity visual features appropriate for object categorization. The model is evaluated on 3D-Object and ETH-80 datasets which are two benchmarks for invariant object recognition, and is shown to outperform state-of-the-art models, including DeepConvNet and HMAX. This demonstrates its ability to accurately recognize different instances of multiple object classes even under various appearance conditions (different views, scales, tilts, and backgrounds). Several statistical analysis techniques are used to show that our model extracts class specific and highly informative features.



### Application of Enhanced-2D-CWT in Topographic Images for Mapping Landslide Risk Areas
- **Arxiv ID**: http://arxiv.org/abs/1504.05137v1
- **DOI**: 10.1007/978-3-642-39094-4_43
- **Categories**: **cs.CV**, physics.geo-ph
- **Links**: [PDF](http://arxiv.org/pdf/1504.05137v1)
- **Published**: 2015-04-15 14:02:22+00:00
- **Updated**: 2015-04-15 14:02:22+00:00
- **Authors**: V. V. Vermehren Valenzuela, R. D. Lins, H. M. de Oliveira
- **Comment**: 8 pages, 8 figures; Lecture Notes in Computer Science LNCS 7950,
  pp.380-388, 2013 Springer-Verlag, Heidelberg ISBN: 978-3-642-39093-7
- **Journal**: None
- **Summary**: There has been lately a number of catastrophic events of landslides and mudslides in the mountainous region of Rio de Janeiro, Brazil. Those were caused by intense rain in localities where there was unplanned occupation of slopes of hills and mountains. Thus, it became imperative creating an inventory of landslide risk areas in densely populated cities. This work presents a way of demarcating risk areas by using the bidimensional Continuous Wavelet Transform (2D-CWT) applied to high resolution topographic images of the mountainous region of Rio de Janeiro.



### Deep convolutional networks for pancreas segmentation in CT imaging
- **Arxiv ID**: http://arxiv.org/abs/1504.03967v1
- **DOI**: 10.1117/12.2081420
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.03967v1)
- **Published**: 2015-04-15 16:55:46+00:00
- **Updated**: 2015-04-15 16:55:46+00:00
- **Authors**: Holger R. Roth, Amal Farag, Le Lu, Evrim B. Turkbey, Ronald M. Summers
- **Comment**: SPIE Medical Imaging conference, Orlando, FL, USA: SPIE Proceedings |
  Volume 9413 | Classification
- **Journal**: Proc. SPIE 9413, Medical Imaging 2015: Image Processing, 94131G
  (20 March 2015)
- **Summary**: Automatic organ segmentation is an important prerequisite for many computer-aided diagnosis systems. The high anatomical variability of organs in the abdomen, such as the pancreas, prevents many segmentation methods from achieving high accuracies when compared to other segmentation of organs like the liver, heart or kidneys. Recently, the availability of large annotated training sets and the accessibility of affordable parallel computing resources via GPUs have made it feasible for "deep learning" methods such as convolutional networks (ConvNets) to succeed in image classification tasks. These methods have the advantage that used classification features are trained directly from the imaging data. We present a fully-automated bottom-up method for pancreas segmentation in computed tomography (CT) images of the abdomen. The method is based on hierarchical coarse-to-fine classification of local image regions (superpixels). Superpixels are extracted from the abdominal region using Simple Linear Iterative Clustering (SLIC). An initial probability response map is generated, using patch-level confidences and a two-level cascade of random forest classifiers, from which superpixel regions with probabilities larger 0.5 are retained. These retained superpixels serve as a highly sensitive initial input of the pancreas and its surroundings to a ConvNet that samples a bounding box around each superpixel at different scales (and random non-rigid deformations at training time) in order to assign a more distinct probability of each superpixel region being pancreas or not. We evaluate our method on CT images of 82 patients (60 for training, 2 for validation, and 20 for testing). Using ConvNets we achieve average Dice scores of 68%+-10% (range, 43-80%) in testing. This shows promise for accurate pancreas segmentation, using a deep learning approach and compares favorably to state-of-the-art methods.



### Anatomy-specific classification of medical images using deep convolutional nets
- **Arxiv ID**: http://arxiv.org/abs/1504.04003v1
- **DOI**: 10.1109/ISBI.2015.7163826
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.04003v1)
- **Published**: 2015-04-15 19:55:27+00:00
- **Updated**: 2015-04-15 19:55:27+00:00
- **Authors**: Holger R. Roth, Christopher T. Lee, Hoo-Chang Shin, Ari Seff, Lauren Kim, Jianhua Yao, Le Lu, Ronald M. Summers
- **Comment**: Presented at: 2015 IEEE International Symposium on Biomedical
  Imaging, April 16-19, 2015, New York Marriott at Brooklyn Bridge, NY, USA
- **Journal**: Biomedical Imaging (ISBI), 2015 IEEE 12th International Symposium
  on Year: 2015 Pages: 101 - 104
- **Summary**: Automated classification of human anatomy is an important prerequisite for many computer-aided diagnosis systems. The spatial complexity and variability of anatomy throughout the human body makes classification difficult. "Deep learning" methods such as convolutional networks (ConvNets) outperform other state-of-the-art methods in image classification tasks. In this work, we present a method for organ- or body-part-specific anatomical classification of medical images acquired using computed tomography (CT) with ConvNets. We train a ConvNet, using 4,298 separate axial 2D key-images to learn 5 anatomical classes. Key-images were mined from a hospital PACS archive, using a set of 1,675 patients. We show that a data augmentation approach can help to enrich the data set and improve classification performance. Using ConvNets and data augmentation, we achieve anatomy-specific classification error of 5.9 % and area-under-the-curve (AUC) values of an average of 0.998 in testing. We demonstrate that deep learning can be used to train very reliable and accurate classifiers that could initialize further computer-aided diagnosis.



