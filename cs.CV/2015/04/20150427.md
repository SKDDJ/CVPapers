# Arxiv Papers in cs.CV on 2015-04-27
### Linear Spatial Pyramid Matching Using Non-convex and non-negative Sparse Coding for Image Classification
- **Arxiv ID**: http://arxiv.org/abs/1504.06897v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, 68T45, I.5.2
- **Links**: [PDF](http://arxiv.org/pdf/1504.06897v1)
- **Published**: 2015-04-27 00:46:54+00:00
- **Updated**: 2015-04-27 00:46:54+00:00
- **Authors**: Chengqiang Bao, Liangtian He, Yilun Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Recently sparse coding have been highly successful in image classification mainly due to its capability of incorporating the sparsity of image representation. In this paper, we propose an improved sparse coding model based on linear spatial pyramid matching(SPM) and Scale Invariant Feature Transform (SIFT ) descriptors. The novelty is the simultaneous non-convex and non-negative characters added to the sparse coding model. Our numerical experiments show that the improved approach using non-convex and non-negative sparse coding is superior than the original ScSPM[1] on several typical databases.



### Detection and Recognition of Malaysian Special License Plate Based On SIFT Features
- **Arxiv ID**: http://arxiv.org/abs/1504.06921v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.06921v1)
- **Published**: 2015-04-27 03:49:33+00:00
- **Updated**: 2015-04-27 03:49:33+00:00
- **Authors**: Hooi Sin Ng, Yong Haur Tay, Kim Meng Liang, Hamam Mokayed, Hock Woon Hon
- **Comment**: seven pages, 7 figures
- **Journal**: None
- **Summary**: Automated car license plate recognition systems are developed and applied for purpose of facilitating the surveillance, law enforcement, access control and intelligent transportation monitoring with least human intervention. In this paper, an algorithm based on SIFT feature points clustering and matching is proposed to address the issue of recognizing Malaysian special plates. These special plates do not follow the format of standard car plates as they may contain italic, cursive, connected and small letters. The algorithm is tested with 150 Malaysian special plate images under different environment and the promising experimental results demonstrate that the proposed algorithm is relatively robust.



### Compression Artifacts Reduction by a Deep Convolutional Network
- **Arxiv ID**: http://arxiv.org/abs/1504.06993v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.5; I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/1504.06993v1)
- **Published**: 2015-04-27 09:30:30+00:00
- **Updated**: 2015-04-27 09:30:30+00:00
- **Authors**: Chao Dong, Yubin Deng, Chen Change Loy, Xiaoou Tang
- **Comment**: 9 pages, 12 figures, conference
- **Journal**: None
- **Summary**: Lossy compression introduces complex compression artifacts, particularly the blocking artifacts, ringing effects and blurring. Existing algorithms either focus on removing blocking artifacts and produce blurred output, or restores sharpened images that are accompanied with ringing effects. Inspired by the deep convolutional networks (DCN) on super-resolution, we formulate a compact and efficient network for seamless attenuation of different compression artifacts. We also demonstrate that a deeper model can be effectively trained with the features learned in a shallow network. Following a similar "easy to hard" idea, we systematically investigate several practical transfer settings and show the effectiveness of transfer learning in low-level vision problems. Our method shows superior performance than the state-of-the-arts both on the benchmark datasets and the real-world use case (i.e. Twitter). In addition, we show that our method can be applied as pre-processing to facilitate other low-level vision routines when they take compressed images as input.



### On-Board Vision Processing For Small UAVs: Time to Rethink Strategy
- **Arxiv ID**: http://arxiv.org/abs/1504.07021v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1504.07021v1)
- **Published**: 2015-04-27 10:52:27+00:00
- **Updated**: 2015-04-27 10:52:27+00:00
- **Authors**: Shoaib Ehsan, Klaus D. McDonald-Maier
- **Comment**: 2009 NASA/ESA Conference on Adaptive Hardware and Systems
- **Journal**: None
- **Summary**: The ultimate research goal for unmanned aerial vehicles (UAVs) is to facilitate autonomy of operation. Research in the last decade has highlighted the potential of vision sensing in this regard. Although vital for accomplishment of missions assigned to any type of unmanned aerial vehicles, vision sensing is more critical for small aerial vehicles due to lack of high precision inertial sensors. In addition, uncertainty of GPS signal in indoor and urban environments calls for more reliance on vision sensing for such small vehicles. With off-line processing does not offer an attractive option in terms of autonomy, these vehicles have been challenging platforms to implement vision processing onboard due to their strict payload capacity and power budget. The strict constraints drive the need for new vision processing architectures for small unmanned aerial vehicles. Recent research has shown encouraging results with FPGA based hardware architectures. This paper reviews the bottle necks involved in implementing vision processing on-board, advocates the potential of hardware based solutions to tackle strict constraints of small unmanned aerial vehicles and finally analyzes feasibility of ASICs, Structured ASICs and FPGAs for use on future systems.



### SegSALSA-STR: A convex formulation to supervised hyperspectral image segmentation using hidden fields and structure tensor regularization
- **Arxiv ID**: http://arxiv.org/abs/1504.07028v1
- **DOI**: None
- **Categories**: **cs.CV**, 68
- **Links**: [PDF](http://arxiv.org/pdf/1504.07028v1)
- **Published**: 2015-04-27 11:08:53+00:00
- **Updated**: 2015-04-27 11:08:53+00:00
- **Authors**: Filipe Condessa, Jose Bioucas-Dias, Jelena Kovacevic
- **Comment**: This paper was submitted to IEEE WHISPERS 2015: 7th Workshop on
  Hyperspectral Image and Signal Processing: Evolution on Remote Sensing. 5
  pages, 1 figure
- **Journal**: None
- **Summary**: We present a supervised hyperspectral image segmentation algorithm based on a convex formulation of a marginal maximum a posteriori segmentation with hidden fields and structure tensor regularization: Segmentation via the Constraint Split Augmented Lagrangian Shrinkage by Structure Tensor Regularization (SegSALSA-STR). This formulation avoids the generally discrete nature of segmentation problems and the inherent NP-hardness of the integer optimization associated.   We extend the Segmentation via the Constraint Split Augmented Lagrangian Shrinkage (SegSALSA) algorithm by generalizing the vectorial total variation prior using a structure tensor prior constructed from a patch-based Jacobian. The resulting algorithm is convex, time-efficient and highly parallelizable. This shows the potential of combining hidden fields with convex optimization through the inclusion of different regularizers. The SegSALSA-STR algorithm is validated in the segmentation of real hyperspectral images.



### Cascaded Sparse Spatial Bins for Efficient and Effective Generic Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1504.07029v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.07029v2)
- **Published**: 2015-04-27 11:14:27+00:00
- **Updated**: 2015-10-13 10:30:22+00:00
- **Authors**: David Novotny, Jiri Matas
- **Comment**: Accepted to ICCV15
- **Journal**: None
- **Summary**: A novel efficient method for extraction of object proposals is introduced. Its "objectness" function exploits deep spatial pyramid features, a novel fast-to-compute HoG-based edge statistic and the EdgeBoxes score. The efficiency is achieved by the use of spatial bins in a novel combination with sparsity-inducing group normalized SVM. State-of-the-art recall performance is achieved on Pascal VOC07, significantly outperforming methods with comparable speed. Interestingly, when only 100 proposals per image are considered the method attains 78% recall on VOC07. The method improves mAP of the RCNN state-of-the-art class-specific detector, increasing it by 10 points when only 50 proposals are used in each image. The system trained on twenty classes performs well on the two hundred class ILSVRC2013 set confirming generalization capability.



### Shape Representation and Classification through Pattern Spectrum and Local Binary Pattern - A Decision Level Fusion Approach
- **Arxiv ID**: http://arxiv.org/abs/1504.07082v1
- **DOI**: 10.1109/ICSIP.2014.41
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.07082v1)
- **Published**: 2015-04-27 13:38:20+00:00
- **Updated**: 2015-04-27 13:38:20+00:00
- **Authors**: B. H. Shekar, Bharathi Pilar
- **Comment**: Fifth International Conference on Signals and Image Processing
  (ICSIP) 2014
- **Journal**: None
- **Summary**: In this paper, we present a decision level fused local Morphological Pattern Spectrum(PS) and Local Binary Pattern (LBP) approach for an efficient shape representation and classification. This method makes use of Earth Movers Distance(EMD) as the measure in feature matching and shape retrieval process. The proposed approach has three major phases : Feature Extraction, Construction of hybrid spectrum knowledge base and Classification. In the first phase, feature extraction of the shape is done using pattern spectrum and local binary pattern method. In the second phase, the histograms of both pattern spectrum and local binary pattern are fused and stored in the knowledge base. In the third phase, the comparison and matching of the features, which are represented in the form of histograms, is done using Earth Movers Distance(EMD) as metric. The top-n shapes are retrieved for each query shape. The accuracy is tested by means of standard Bulls eye score method. The experiments are conducted on publicly available shape datasets like Kimia-99, Kimia-216 and MPEG-7. The comparative study is also provided with the well known approaches to exhibit the retrieval accuracy of the proposed approach.



### Meta learning of bounds on the Bayes classifier error
- **Arxiv ID**: http://arxiv.org/abs/1504.07116v2
- **DOI**: 10.1109/DSP-SPE.2015.7369520
- **Categories**: **cs.LG**, astro-ph.SR, cs.CV, cs.IT, math.IT
- **Links**: [PDF](http://arxiv.org/pdf/1504.07116v2)
- **Published**: 2015-04-27 14:49:24+00:00
- **Updated**: 2015-07-03 17:34:13+00:00
- **Authors**: Kevin R. Moon, Veronique Delouille, Alfred O. Hero III
- **Comment**: 6 pages, 3 figures, to appear in proceedings of 2015 IEEE Signal
  Processing and SP Education Workshop
- **Journal**: IEEE Signal Processing and SP Education Workshop, pp. 13-18, Aug.
  2015
- **Summary**: Meta learning uses information from base learners (e.g. classifiers or estimators) as well as information about the learning problem to improve upon the performance of a single base learner. For example, the Bayes error rate of a given feature space, if known, can be used to aid in choosing a classifier, as well as in feature selection and model selection for the base classifiers and the meta classifier. Recent work in the field of f-divergence functional estimation has led to the development of simple and rapidly converging estimators that can be used to estimate various bounds on the Bayes error. We estimate multiple bounds on the Bayes error using an estimator that applies meta learning to slowly converging plug-in estimators to obtain the parametric convergence rate. We compare the estimated bounds empirically on simulated data and then estimate the tighter bounds on features extracted from an image patch analysis of sunspot continuum and magnetogram images.



### Combining Local Appearance and Holistic View: Dual-Source Deep Neural Networks for Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/1504.07159v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.07159v1)
- **Published**: 2015-04-27 17:00:30+00:00
- **Updated**: 2015-04-27 17:00:30+00:00
- **Authors**: Xiaochuan Fan, Kang Zheng, Yuewei Lin, Song Wang
- **Comment**: CVPR 2015
- **Journal**: None
- **Summary**: We propose a new learning-based method for estimating 2D human pose from a single image, using Dual-Source Deep Convolutional Neural Networks (DS-CNN). Recently, many methods have been developed to estimate human pose by using pose priors that are estimated from physiologically inspired graphical models or learned from a holistic perspective. In this paper, we propose to integrate both the local (body) part appearance and the holistic view of each local part for more accurate human pose estimation. Specifically, the proposed DS-CNN takes a set of image patches (category-independent object proposals for training and multi-scale sliding windows for testing) as the input and then learns the appearance of each local part by considering their holistic views in the full body. Using DS-CNN, we achieve both joint detection, which determines whether an image patch contains a body joint, and joint localization, which finds the exact location of the joint in the image patch. Finally, we develop an algorithm to combine these joint detection/localization results from all the image patches for estimating the human pose. The experimental results show the effectiveness of the proposed method by comparing to the state-of-the-art human-pose estimation methods based on pose priors that are estimated from physiologically inspired graphical models or learned from a holistic perspective.



### Image Segmentation and Restoration Using Parametric Contours With Free Endpoints
- **Arxiv ID**: http://arxiv.org/abs/1504.07259v1
- **DOI**: 10.1109/TIP.2016.2529180
- **Categories**: **cs.CV**, math.AP, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1504.07259v1)
- **Published**: 2015-04-27 20:08:37+00:00
- **Updated**: 2015-04-27 20:08:37+00:00
- **Authors**: Heike Benninghoff, Harald Garcke
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper, we introduce a novel approach for active contours with free endpoints. A scheme is presented for image segmentation and restoration based on a discrete version of the Mumford-Shah functional where the contours can be both closed and open curves. Additional to a flow of the curves in normal direction, evolution laws for the tangential flow of the endpoints are derived. Using a parametric approach to describe the evolving contours together with an edge-preserving denoising, we obtain a fast method for image segmentation and restoration. The analytical and numerical schemes are presented followed by numerical experiments with artificial test images and with a real medical image.



### Dynamic Body VSLAM with Semantic Constraints
- **Arxiv ID**: http://arxiv.org/abs/1504.07269v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.07269v1)
- **Published**: 2015-04-27 20:30:04+00:00
- **Updated**: 2015-04-27 20:30:04+00:00
- **Authors**: N. Dinesh Reddy, Prateek Singhal, Visesh Chari, K. Madhava Krishna
- **Comment**: None
- **Journal**: None
- **Summary**: Image based reconstruction of urban environments is a challenging problem that deals with optimization of large number of variables, and has several sources of errors like the presence of dynamic objects. Since most large scale approaches make the assumption of observing static scenes, dynamic objects are relegated to the noise modeling section of such systems. This is an approach of convenience since the RANSAC based framework used to compute most multiview geometric quantities for static scenes naturally confine dynamic objects to the class of outlier measurements. However, reconstructing dynamic objects along with the static environment helps us get a complete picture of an urban environment. Such understanding can then be used for important robotic tasks like path planning for autonomous navigation, obstacle tracking and avoidance, and other areas. In this paper, we propose a system for robust SLAM that works in both static and dynamic environments. To overcome the challenge of dynamic objects in the scene, we propose a new model to incorporate semantic constraints into the reconstruction algorithm. While some of these constraints are based on multi-layered dense CRFs trained over appearance as well as motion cues, other proposed constraints can be expressed as additional terms in the bundle adjustment optimization process that does iterative refinement of 3D structure and camera / object motion trajectories. We show results on the challenging KITTI urban dataset for accuracy of motion segmentation and reconstruction of the trajectory and shape of moving objects relative to ground truth. We are able to show average relative error reduction by a significant amount for moving object trajectory reconstruction relative to state-of-the-art methods like VISO 2, as well as standard bundle adjustment algorithms.



### Mid-level Elements for Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1504.07284v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1504.07284v1)
- **Published**: 2015-04-27 21:41:01+00:00
- **Updated**: 2015-04-27 21:41:01+00:00
- **Authors**: Aayush Bansal, Abhinav Shrivastava, Carl Doersch, Abhinav Gupta
- **Comment**: None
- **Journal**: None
- **Summary**: Building on the success of recent discriminative mid-level elements, we propose a surprisingly simple approach for object detection which performs comparable to the current state-of-the-art approaches on PASCAL VOC comp-3 detection challenge (no external data). Through extensive experiments and ablation analysis, we show how our approach effectively improves upon the HOG-based pipelines by adding an intermediate mid-level representation for the task of object detection. This representation is easily interpretable and allows us to visualize what our object detector "sees". We also discuss the insights our approach shares with CNN-based methods, such as sharing representation between categories helps.



