# Arxiv Papers in cs.CV on 2015-01-10
### Efficient Rotation-Scaling-Translation Parameters Estimation Based on Fractal Image Model
- **Arxiv ID**: http://arxiv.org/abs/1501.02372v2
- **DOI**: 10.1109/TGRS.2015.2453126
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.02372v2)
- **Published**: 2015-01-10 17:31:11+00:00
- **Updated**: 2015-07-04 08:59:30+00:00
- **Authors**: M. Uss, B. Vozel, V. Lukin, K. Chehdi
- **Comment**: 42 pages, 8 figures, 7 tables. Journal paper
- **Journal**: None
- **Summary**: This paper deals with area-based subpixel image registration under rotation-isometric scaling-translation transformation hypothesis. Our approach is based on a parametrical modeling of geometrically transformed textural image fragments and maximum likelihood estimation of transformation vector between them. Due to the parametrical approach based on the fractional Brownian motion modeling of the local fragments texture, the proposed estimator MLfBm (ML stands for "Maximum Likelihood" and fBm for "Fractal Brownian motion") has the ability to better adapt to real image texture content compared to other methods relying on universal similarity measures like mutual information or normalized correlation. The main benefits are observed when assumptions underlying the fBm model are fully satisfied, e.g. for isotropic normally distributed textures with stationary increments. Experiments on both simulated and real images and for high and weak correlation between registered images show that the MLfBm estimator offers significant improvement compared to other state-of-the-art methods. It reduces translation vector, rotation angle and scaling factor estimation errors by a factor of about 1.75...2 and it decreases probability of false match by up to 5 times. Besides, an accurate confidence interval for MLfBm estimates can be obtained from the Cramer-Rao lower bound on rotation-scaling-translation parameters estimation error. This bound depends on texture roughness, noise level in reference and template images, correlation between these images and geometrical transformation parameters.



### On the Distribution of Salient Objects in Web Images and its Influence on Salient Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1501.03383v1
- **DOI**: 10.1371/journal.pone.0130316
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.03383v1)
- **Published**: 2015-01-10 17:36:24+00:00
- **Updated**: 2015-01-10 17:36:24+00:00
- **Authors**: Boris Schauerte, Rainer Stiefelhagen
- **Comment**: None
- **Journal**: PLoS ONE 10 (2015)
- **Summary**: It has become apparent that a Gaussian center bias can serve as an important prior for visual saliency detection, which has been demonstrated for predicting human eye fixations and salient object detection. Tseng et al. have shown that the photographer's tendency to place interesting objects in the center is a likely cause for the center bias of eye fixations. We investigate the influence of the photographer's center bias on salient object detection, extending our previous work. We show that the centroid locations of salient objects in photographs of Achanta and Liu's data set in fact correlate strongly with a Gaussian model. This is an important insight, because it provides an empirical motivation and justification for the integration of such a center bias in salient object detection algorithms and helps to understand why Gaussian models are so effective. To assess the influence of the center bias on salient object detection, we integrate an explicit Gaussian center bias model into two state-of-the-art salient object detection algorithms. This way, first, we quantify the influence of the Gaussian center bias on pixel- and segment-based salient object detection. Second, we improve the performance in terms of F1 score, Fb score, area under the recall-precision curve, area under the receiver operating characteristic curve, and hit-rate on the well-known data set by Achanta and Liu. Third, by debiasing Cheng et al.'s region contrast model, we exemplarily demonstrate that implicit center biases are partially responsible for the outstanding performance of state-of-the-art algorithms. Last but not least, as a result of debiasing Cheng et al.'s algorithm, we introduce a non-biased salient object detection method, which is of interest for applications in which the image data is not likely to have a photographer's center bias (e.g., image data of surveillance cameras or autonomous robots).



### Simplified vision based automatic navigation for wheat harvesting in low income economies
- **Arxiv ID**: http://arxiv.org/abs/1501.02376v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1501.02376v1)
- **Published**: 2015-01-10 17:55:08+00:00
- **Updated**: 2015-01-10 17:55:08+00:00
- **Authors**: Muhammad Zubair Ahmad, Ayyaz Akhtar, Abdul Qadeer Khan, Amir A. Khan
- **Comment**: None
- **Journal**: None
- **Summary**: Recent developments in the domain of agricultural robotics have resulted in development of complex and efficient systems. Most of the land owners in the South Asian region are low income farmers. The agricultural experience for them is still a completely manual process. However, the extreme weather conditions, heat and flooding, often combine to put a lot of stress on these small land owners and the associated labor. In this paper, we propose a prototype for an automated power reaper for the wheat crop. This automated vehicle is navigated using a simple vision based approach employing the low-cost camera and assisted GPS. The mechanical platform is driven by three motors controlled through an interface between the proposed vision algorithm and the electrical drive. The proposed methodology is applied on some real field scenarios to demonstrate the efficiency of the vision based algorithm.



### Low Cost Semi-Autonomous Agricultural Robots In Pakistan-Vision Based Navigation Scalable methodology for wheat harvesting
- **Arxiv ID**: http://arxiv.org/abs/1501.02378v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1501.02378v1)
- **Published**: 2015-01-10 18:14:10+00:00
- **Updated**: 2015-01-10 18:14:10+00:00
- **Authors**: Muhammad Zubair Ahmad, Ayyaz Akhtar, Abdul Qadeer Khan, Amir Ali Khan, Muhammad Murtaza Khan
- **Comment**: None
- **Journal**: None
- **Summary**: Robots have revolutionized our way of life in recent years.One of the domains that has not yet completely benefited from the robotic automation is the agricultural sector. Agricultural Robotics should complement humans in the arduous tasks during different sub-domains of this sector. Extensive research in Agricultural Robotics has been carried out in Japan, USA, Australia and Germany focusing mainly on the heavy agricultural machinery. Pakistan is an agricultural rich country and its economy and food security are closely tied with agriculture in general and wheat in particular. However, agricultural research in Pakistan is still carried out using the conventional methodologies. This paper is an attempt to trigger the research in this modern domain so that we can benefit from cost effective and resource efficient autonomous agricultural methodologies. This paper focuses on a scalable low cost semi-autonomous technique for wheat harvest which primarily focuses on the farmers with small land holdings. The main focus will be on the vision part of the navigation system deployed by the proposed robot.



### Autonomous Farm Vehicles: Prototype of Power Reaper
- **Arxiv ID**: http://arxiv.org/abs/1501.02379v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1501.02379v1)
- **Published**: 2015-01-10 18:21:48+00:00
- **Updated**: 2015-01-10 18:21:48+00:00
- **Authors**: Abdul Qadeer Khan, Ayyaz Akhtar, Muhammad Zubair Ahmad
- **Comment**: None
- **Journal**: None
- **Summary**: Chapter 2 will begin with introduction of Agricultural Robotics. There will be a literature review of the mechanical structure, vision and control algorithms. In chapter 3 we will discuss the methodology in detail using block diagrams and flowcharts. The results of the tested and the proposed algorithms will also be displayed. In chapter 4 we will discuss the results in detail and how they are of significance in our work. In chapter 5 we will conclude our work and discuss some future perspectives. In appendices we will provide some background information necessary regarding this project.



### Riemannian Metric Learning for Symmetric Positive Definite Matrices
- **Arxiv ID**: http://arxiv.org/abs/1501.02393v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1501.02393v1)
- **Published**: 2015-01-10 21:12:09+00:00
- **Updated**: 2015-01-10 21:12:09+00:00
- **Authors**: Raviteja Vemulapalli, David W. Jacobs
- **Comment**: None
- **Journal**: None
- **Summary**: Over the past few years, symmetric positive definite (SPD) matrices have been receiving considerable attention from computer vision community. Though various distance measures have been proposed in the past for comparing SPD matrices, the two most widely-used measures are affine-invariant distance and log-Euclidean distance. This is because these two measures are true geodesic distances induced by Riemannian geometry. In this work, we focus on the log-Euclidean Riemannian geometry and propose a data-driven approach for learning Riemannian metrics/geodesic distances for SPD matrices. We show that the geodesic distance learned using the proposed approach performs better than various existing distance measures when evaluated on face matching and clustering tasks.



