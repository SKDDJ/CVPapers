# Arxiv Papers in cs.CV on 2015-01-25
### Accurate automatic segmentation of retina layers with emphasis on first layer
- **Arxiv ID**: http://arxiv.org/abs/1501.06114v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.06114v2)
- **Published**: 2015-01-25 04:54:42+00:00
- **Updated**: 2015-02-15 07:23:35+00:00
- **Authors**: Mahdi Salarian
- **Comment**: None
- **Journal**: None
- **Summary**: Quantification of intra-retinal boundaries in optical coherence tomography (OCT) is a crucial task for studying and diagnosing neurological and ocular diseases. Since manual segmentation of layers is usually a time consuming task and relay on user, a lot of attempts done to do it automatically and without interference of user. Although for extracting all layers usually same procedure is applied but finding the first layer is usually more difficult due to vanishing it in some region specially close to Fobia. To have a general software, beside using common methods like applying shortest path algorithm on global gradient of image, some extra steps are used here to confine search area for Dijstra algorithm especially for the second layer. Results demonstrates high accuracy in segmenting all present layers, especially the first one that is important for diagnosing issue.



### Constrained Extreme Learning Machines: A Study on Classification Cases
- **Arxiv ID**: http://arxiv.org/abs/1501.06115v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1501.06115v2)
- **Published**: 2015-01-25 05:11:34+00:00
- **Updated**: 2015-02-04 11:42:01+00:00
- **Authors**: Wentao Zhu, Jun Miao, Laiyun Qing
- **Comment**: 14 pages, 6 figure, journel
- **Journal**: None
- **Summary**: Extreme learning machine (ELM) is an extremely fast learning method and has a powerful performance for pattern recognition tasks proven by enormous researches and engineers. However, its good generalization ability is built on large numbers of hidden neurons, which is not beneficial to real time response in the test process. In this paper, we proposed new ways, named "constrained extreme learning machines" (CELMs), to randomly select hidden neurons based on sample distribution. Compared to completely random selection of hidden nodes in ELM, the CELMs randomly select hidden nodes from the constrained vector space containing some basic combinations of original sample vectors. The experimental results show that the CELMs have better generalization ability than traditional ELM, SVM and some other related methods. Additionally, the CELMs have a similar fast learning speed as ELM.



### An Occlusion Reasoning Scheme for Monocular Pedestrian Tracking in Dynamic Scenes
- **Arxiv ID**: http://arxiv.org/abs/1501.06129v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.06129v1)
- **Published**: 2015-01-25 08:38:48+00:00
- **Updated**: 2015-01-25 08:38:48+00:00
- **Authors**: Sourav Garg, Swagat Kumar, Rajesh Ratnakaram, Prithwijit Guha
- **Comment**: 8 pages
- **Journal**: None
- **Summary**: This paper looks into the problem of pedestrian tracking using a monocular, potentially moving, uncalibrated camera. The pedestrians are located in each frame using a standard human detector, which are then tracked in subsequent frames. This is a challenging problem as one has to deal with complex situations like changing background, partial or full occlusion and camera motion. In order to carry out successful tracking, it is necessary to resolve associations between the detected windows in the current frame with those obtained from the previous frame. Compared to methods that use temporal windows incorporating past as well as future information, we attempt to make decision on a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve the association problem between a pair of consecutive frames by using an affinity matrix that defines the closeness between a pair of windows and then, uses a binary integer programming to obtain unique association between them. A second stage of verification based on SURF matching is used to deal with those cases where the above optimization scheme might yield wrong associations. The efficacy of the approach is demonstrated through experiments on several standard pedestrian datasets.



### Unsupervised Object Discovery and Localization in the Wild: Part-based Matching with Bottom-up Region Proposals
- **Arxiv ID**: http://arxiv.org/abs/1501.06170v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.06170v3)
- **Published**: 2015-01-25 15:09:23+00:00
- **Updated**: 2015-05-04 16:18:58+00:00
- **Authors**: Minsu Cho, Suha Kwak, Cordelia Schmid, Jean Ponce
- **Comment**: CVPR 2015
- **Journal**: None
- **Summary**: This paper addresses unsupervised discovery and localization of dominant objects from a noisy image collection with multiple object classes. The setting of this problem is fully unsupervised, without even image-level annotations or any assumption of a single dominant class. This is far more general than typical colocalization, cosegmentation, or weakly-supervised localization tasks. We tackle the discovery and localization problem using a part-based region matching approach: We use off-the-shelf region proposals to form a set of candidate bounding boxes for objects and object parts. These regions are efficiently matched across images using a probabilistic Hough transform that evaluates the confidence for each candidate correspondence considering both appearance and spatial consistency. Dominant objects are discovered and localized by comparing the scores of candidate regions and selecting those that stand out over other regions containing them. Extensive experimental evaluations on standard benchmarks demonstrate that the proposed approach significantly outperforms the current state of the art in colocalization, and achieves robust object discovery in challenging mixed-class datasets.



### Exploring Human Vision Driven Features for Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1501.06180v1
- **DOI**: 10.1109/TCSVT.2015.2397199
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.06180v1)
- **Published**: 2015-01-25 16:52:41+00:00
- **Updated**: 2015-01-25 16:52:41+00:00
- **Authors**: Shanshan Zhang, Christian Bauckhage, Dominik A. Klein, Armin B. Cremers
- **Comment**: Accepted for publication in IEEE Transactions on Circuits and Systems
  for Video Technology (TCSVT)
- **Journal**: None
- **Summary**: Motivated by the center-surround mechanism in the human visual attention system, we propose to use average contrast maps for the challenge of pedestrian detection in street scenes due to the observation that pedestrians indeed exhibit discriminative contrast texture. Our main contributions are first to design a local, statistical multi-channel descriptorin order to incorporate both color and gradient information. Second, we introduce a multi-direction and multi-scale contrast scheme based on grid-cells in order to integrate expressive local variations. Contributing to the issue of selecting most discriminative features for assessing and classification, we perform extensive comparisons w.r.t. statistical descriptors, contrast measurements, and scale structures. This way, we obtain reasonable results under various configurations. Empirical findings from applying our optimized detector on the INRIA and Caltech pedestrian datasets show that our features yield state-of-the-art performance in pedestrian detection.



### Robust Subjective Visual Property Prediction from Crowdsourced Pairwise Labels
- **Arxiv ID**: http://arxiv.org/abs/1501.06202v4
- **DOI**: 10.1109/TPAMI.2015.2456887
- **Categories**: **cs.CV**, cs.LG, cs.MM, cs.SI, math.ST, stat.TH
- **Links**: [PDF](http://arxiv.org/pdf/1501.06202v4)
- **Published**: 2015-01-25 20:02:45+00:00
- **Updated**: 2015-07-27 14:42:17+00:00
- **Authors**: Yanwei Fu, Timothy M. Hospedales, Tao Xiang, Jiechao Xiong, Shaogang Gong, Yizhou Wang, Yuan Yao
- **Comment**: 14 pages, accepted by IEEE TPAMI
- **Journal**: None
- **Summary**: The problem of estimating subjective visual properties from image and video has attracted increasing interest. A subjective visual property is useful either on its own (e.g. image and video interestingness) or as an intermediate representation for visual recognition (e.g. a relative attribute). Due to its ambiguous nature, annotating the value of a subjective visual property for learning a prediction model is challenging. To make the annotation more reliable, recent studies employ crowdsourcing tools to collect pairwise comparison labels because human annotators are much better at ranking two images/videos (e.g. which one is more interesting) than giving an absolute value to each of them separately. However, using crowdsourced data also introduces outliers. Existing methods rely on majority voting to prune the annotation outliers/errors. They thus require large amount of pairwise labels to be collected. More importantly as a local outlier detection method, majority voting is ineffective in identifying outliers that can cause global ranking inconsistencies. In this paper, we propose a more principled way to identify annotation outliers by formulating the subjective visual property prediction task as a unified robust learning to rank problem, tackling both the outlier detection and learning to rank jointly. Differing from existing methods, the proposed method integrates local pairwise comparison labels together to minimise a cost that corresponds to global inconsistency of ranking order. This not only leads to better detection of annotation outliers but also enables learning with extremely sparse annotations. Extensive experiments on various benchmark datasets demonstrate that our new approach significantly outperforms state-of-the-arts alternatives.



### Parallel Magnetic Resonance Imaging
- **Arxiv ID**: http://arxiv.org/abs/1501.06209v2
- **DOI**: None
- **Categories**: **cs.NA**, cs.CV, math.NA, math.OC, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/1501.06209v2)
- **Published**: 2015-01-25 21:01:41+00:00
- **Updated**: 2015-07-17 06:20:43+00:00
- **Authors**: Martin Uecker
- **Comment**: 22 pages, 9 Figures, 76 References. Copyright: Martin Uecker. Draft
  for a book chapter. To appear in: A Majumdar and RK Ward (eds.), MRI:
  Physics, Image Reconstruction, and Analysis, CRC Press 2015
- **Journal**: In: MRI: Physics, Image Reconstruction, and Analysis, CRC Press
  2015, pp. 73-92, ISBN 9781482298871
- **Summary**: The main disadvantage of Magnetic Resonance Imaging (MRI) are its long scan times and, in consequence, its sensitivity to motion. Exploiting the complementary information from multiple receive coils, parallel imaging is able to recover images from under-sampled k-space data and to accelerate the measurement. Because parallel magnetic resonance imaging can be used to accelerate basically any imaging sequence it has many important applications. Parallel imaging brought a fundamental shift in image reconstruction: Image reconstruction changed from a simple direct Fourier transform to the solution of an ill-conditioned inverse problem. This work gives an overview of image reconstruction from the perspective of inverse problems. After introducing basic concepts such as regularization, discretization, and iterative reconstruction, advanced topics are discussed including algorithms for auto-calibration, the connection to approximation theory, and the combination with compressed sensing.



