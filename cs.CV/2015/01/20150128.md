# Arxiv Papers in cs.CV on 2015-01-28
### Feature Sampling Strategies for Action Recognition
- **Arxiv ID**: http://arxiv.org/abs/1501.06993v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.06993v1)
- **Published**: 2015-01-28 05:41:07+00:00
- **Updated**: 2015-01-28 05:41:07+00:00
- **Authors**: Youjie Zhou, Hongkai Yu, Song Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Although dense local spatial-temporal features with bag-of-features representation achieve state-of-the-art performance for action recognition, the huge feature number and feature size prevent current methods from scaling up to real size problems. In this work, we investigate different types of feature sampling strategies for action recognition, namely dense sampling, uniformly random sampling and selective sampling. We propose two effective selective sampling methods using object proposal techniques. Experiments conducted on a large video dataset show that we are able to achieve better average recognition accuracy using 25% less features, through one of proposed selective sampling methods, and even remain comparable accuracy while discarding 70% features.



### A Discrete Tchebichef Transform Approximation for Image and Video Coding
- **Arxiv ID**: http://arxiv.org/abs/1502.00555v1
- **DOI**: 10.1109/LSP.2015.2389899
- **Categories**: **stat.ME**, cs.CV, cs.MM, cs.NA, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/1502.00555v1)
- **Published**: 2015-01-28 14:07:44+00:00
- **Updated**: 2015-01-28 14:07:44+00:00
- **Authors**: P. A. M. Oliveira, R. J. Cintra, F. M. Bayer, S. Kulasekera, A. Madanayake
- **Comment**: 13 pages, 5 figures, 2 tables
- **Journal**: IEEE Signal Processing Letters, vol. 22, issue 8, pp. 1137-1141,
  2015
- **Summary**: In this paper, we introduce a low-complexity approximation for the discrete Tchebichef transform (DTT). The proposed forward and inverse transforms are multiplication-free and require a reduced number of additions and bit-shifting operations. Numerical compression simulations demonstrate the efficiency of the proposed transform for image and video coding. Furthermore, Xilinx Virtex-6 FPGA based hardware realization shows 44.9% reduction in dynamic power consumption and 64.7% lower area when compared to the literature.



### End-to-End Photo-Sketch Generation via Fully Convolutional Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/1501.07180v2
- **DOI**: 10.1145/2671188.2749321
- **Categories**: **cs.CV**, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1501.07180v2)
- **Published**: 2015-01-28 16:32:53+00:00
- **Updated**: 2015-04-11 14:28:21+00:00
- **Authors**: Liliang Zhang, Liang Lin, Xian Wu, Shengyong Ding, Lei Zhang
- **Comment**: 8 pages, 6 figures. Proceeding in ACM International Conference on
  Multimedia Retrieval (ICMR), 2015
- **Journal**: None
- **Summary**: Sketch-based face recognition is an interesting task in vision and multimedia research, yet it is quite challenging due to the great difference between face photos and sketches. In this paper, we propose a novel approach for photo-sketch generation, aiming to automatically transform face photos into detail-preserving personal sketches. Unlike the traditional models synthesizing sketches based on a dictionary of exemplars, we develop a fully convolutional network to learn the end-to-end photo-sketch mapping. Our approach takes whole face photos as inputs and directly generates the corresponding sketch images with efficient inference and learning, in which the architecture are stacked by only convolutional kernels of very small sizes. To well capture the person identity during the photo-sketch transformation, we define our optimization objective in the form of joint generative-discriminative minimization. In particular, a discriminative regularization term is incorporated into the photo-sketch generation, enhancing the discriminability of the generated person sketches against other individuals. Extensive experiments on several standard benchmarks suggest that our approach outperforms other state-of-the-art methods in both photo-sketch generation and face sketch verification.



### The Beauty of Capturing Faces: Rating the Quality of Digital Portraits
- **Arxiv ID**: http://arxiv.org/abs/1501.07304v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1501.07304v1)
- **Published**: 2015-01-28 22:51:23+00:00
- **Updated**: 2015-01-28 22:51:23+00:00
- **Authors**: Miriam Redi, Nikhil Rasiwasia, Gaurav Aggarwal, Alejandro Jaimes
- **Comment**: FG 2015, 8 pages
- **Journal**: None
- **Summary**: Digital portrait photographs are everywhere, and while the number of face pictures keeps growing, not much work has been done to on automatic portrait beauty assessment. In this paper, we design a specific framework to automatically evaluate the beauty of digital portraits. To this end, we procure a large dataset of face images annotated not only with aesthetic scores but also with information about the traits of the subject portrayed. We design a set of visual features based on portrait photography literature, and extensively analyze their relation with portrait beauty, exposing interesting findings about what makes a portrait beautiful. We find that the beauty of a portrait is linked to its artistic value, and independent from age, race and gender of the subject. We also show that a classifier trained with our features to separate beautiful portraits from non-beautiful portraits outperforms generic aesthetic classifiers.



