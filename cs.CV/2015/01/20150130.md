# Arxiv Papers in cs.CV on 2015-01-30
### Hyper-parameter optimization of Deep Convolutional Networks for object recognition
- **Arxiv ID**: http://arxiv.org/abs/1501.07645v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1501.07645v2)
- **Published**: 2015-01-30 02:08:51+00:00
- **Updated**: 2015-05-17 03:32:22+00:00
- **Authors**: Sachin S. Talathi
- **Comment**: 4 pages, 1 figure, 3 tables, Submitted to ICIP 2015
- **Journal**: None
- **Summary**: Recently sequential model based optimization (SMBO) has emerged as a promising hyper-parameter optimization strategy in machine learning. In this work, we investigate SMBO to identify architecture hyper-parameters of deep convolution networks (DCNs) object recognition. We propose a simple SMBO strategy that starts from a set of random initial DCN architectures to generate new architectures, which on training perform well on a given dataset. Using the proposed SMBO strategy we are able to identify a number of DCN architectures that produce results that are comparable to state-of-the-art results on object recognition benchmarks.



### Disaggregation of Remotely Sensed Soil Moisture in Heterogeneous Landscapes using Holistic Structure based Models
- **Arxiv ID**: http://arxiv.org/abs/1501.07680v2
- **DOI**: 10.1109/TGRS.2016.2547389
- **Categories**: **cs.CV**, 68
- **Links**: [PDF](http://arxiv.org/pdf/1501.07680v2)
- **Published**: 2015-01-30 07:09:09+00:00
- **Updated**: 2016-01-20 20:33:08+00:00
- **Authors**: Subit Chakrabarti, Jasmeet Judge, Anand Rangarajan, Sanjay Ranka
- **Comment**: 28 pages, 14 figures, submitted to IEEE Transactions on Geoscience
  and Remote Sensing
- **Journal**: IEEE Trans. Geosci. Remote Sens. 54 (2008) 4629-4641
- **Summary**: In this study, a novel machine learning algorithm is presented for disaggregation of satellite soil moisture (SM) based on self-regularized regressive models (SRRM) using high-resolution correlated information from auxiliary sources. It includes regularized clustering that assigns soft memberships to each pixel at fine-scale followed by a kernel regression that computes the value of the desired variable at all pixels. Coarse-scale remotely sensed SM were disaggregated from 10km to 1km using land cover, precipitation, land surface temperature, leaf area index, and in-situ observations of SM. This algorithm was evaluated using multi-scale synthetic observations in NC Florida for heterogeneous agricultural land covers. It was found that the root mean square error (RMSE) for 96% of the pixels was less than 0.02 $m^3/m^3$. The clusters generated represented the data well and reduced the RMSE by upto 40% during periods of high heterogeneity in land-cover and meteorological conditions. The Kullback Leibler divergence (KLD) between the true SM and the disaggregated estimates is close to 0, for both vegetated and baresoil landcovers. The disaggregated estimates were compared to those generated by the Principle of Relevant Information (PRI) method. The RMSE for the PRI disaggregated estimates is higher than the RMSE for the SRRM on each day of the season. The KLD of the disaggregated estimates generated by the SRRM is at least four orders of magnitude lower than those for the PRI disaggregated estimates, while the computational time needed was reduced by three times. The results indicate that the SRRM can be used for disaggregating SM with complex non-linear correlations on a grid with high accuracy.



### Vector Quantization by Minimizing Kullback-Leibler Divergence
- **Arxiv ID**: http://arxiv.org/abs/1501.07681v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07681v1)
- **Published**: 2015-01-30 07:16:50+00:00
- **Updated**: 2015-01-30 07:16:50+00:00
- **Authors**: Lan Yang, Jingbin Wang, Yujin Tu, Prarthana Mahapatra, Nelson Cardoso
- **Comment**: None
- **Journal**: None
- **Summary**: This paper proposes a new method for vector quantization by minimizing the Kullback-Leibler Divergence between the class label distributions over the quantization inputs, which are original vectors, and the output, which is the quantization subsets of the vector set. In this way, the vector quantization output can keep as much information of the class label as possible. An objective function is constructed and we also developed an iterative algorithm to minimize it. The new method is evaluated on bag-of-features based image classification problem.



### Downscaling Microwave Brightness Temperatures Using Self Regularized Regressive Models
- **Arxiv ID**: http://arxiv.org/abs/1501.07683v1
- **DOI**: None
- **Categories**: **cs.CV**, 68
- **Links**: [PDF](http://arxiv.org/pdf/1501.07683v1)
- **Published**: 2015-01-30 07:24:44+00:00
- **Updated**: 2015-01-30 07:24:44+00:00
- **Authors**: Subit Chakrabarti, Jasmeet Judge, Anand Rangarajan, Sanjay Ranka
- **Comment**: 7 pages, 4 figures, submitted to be presented at the International
  Geoscience and Remote Sensing Conference 2015
- **Journal**: None
- **Summary**: A novel algorithm is proposed to downscale microwave brightness temperatures ($\mathrm{T_B}$), at scales of 10-40 km such as those from the Soil Moisture Active Passive mission to a resolution meaningful for hydrological and agricultural applications. This algorithm, called Self-Regularized Regressive Models (SRRM), uses auxiliary variables correlated to $\mathrm{T_B}$ along-with a limited set of \textit{in-situ} SM observations, which are converted to high resolution $\mathrm{T_B}$ observations using biophysical models. It includes an information-theoretic clustering step based on all auxiliary variables to identify areas of similarity, followed by a kernel regression step that produces downscaled $\mathrm{T_B}$. This was implemented on a multi-scale synthetic data-set over NC-Florida for one year. An RMSE of 5.76~K with standard deviation of 2.8~k was achieved during the vegetated season and an RMSE of 1.2~K with a standard deviation of 0.9~K during periods of no vegetation.



### Blob indentation identification via curvature measurement
- **Arxiv ID**: http://arxiv.org/abs/1501.07692v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07692v1)
- **Published**: 2015-01-30 08:12:48+00:00
- **Updated**: 2015-01-30 08:12:48+00:00
- **Authors**: Matthew Sottile
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents a novel method for identifying indentations on the boundary of solid 2D shape. It uses the signed curvature at a set of points along the boundary to identify indentations and provides one parameter for tuning the selection mechanism for discriminating indentations from other boundary irregularities. An efficient implementation is described based on the Fourier transform for calculating curvature from a sequence of points obtained from the boundary of a binary blob.



### Montblanc: GPU accelerated Radio Interferometer Measurement Equations in support of Bayesian Inference for Radio Observations
- **Arxiv ID**: http://arxiv.org/abs/1501.07719v3
- **DOI**: None
- **Categories**: **cs.DC**, astro-ph.IM, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1501.07719v3)
- **Published**: 2015-01-30 10:04:27+00:00
- **Updated**: 2015-06-19 11:52:12+00:00
- **Authors**: Simon Perkins, Patrick Marais, Jonathan Zwart, Iniyan Natarajan, Cyril Tasse, Oleg Smirnov
- **Comment**: Submitted to Astronomy and Computing
  (http://www.journals.elsevier.com/astronomy-and-computing). The code is
  available online at https://github.com/ska-sa/montblanc. 29 pages long, with
  10 figures, 6 tables and 3 algorithms
- **Journal**: None
- **Summary**: We present Montblanc, a GPU implementation of the Radio interferometer measurement equation (RIME) in support of the Bayesian inference for radio observations (BIRO) technique. BIRO uses Bayesian inference to select sky models that best match the visibilities observed by a radio interferometer. To accomplish this, BIRO evaluates the RIME multiple times, varying sky model parameters to produce multiple model visibilities. Chi-squared values computed from the model and observed visibilities are used as likelihood values to drive the Bayesian sampling process and select the best sky model.   As most of the elements of the RIME and chi-squared calculation are independent of one another, they are highly amenable to parallel computation. Additionally, Montblanc caters for iterative RIME evaluation to produce multiple chi-squared values. Modified model parameters are transferred to the GPU between each iteration.   We implemented Montblanc as a Python package based upon NVIDIA's CUDA architecture. As such, it is easy to extend and implement different pipelines. At present, Montblanc supports point and Gaussian morphologies, but is designed for easy addition of new source profiles.   Montblanc's RIME implementation is performant: On an NVIDIA K40, it is approximately 250 times faster than MeqTrees on a dual hexacore Intel E5-2620v2 CPU. Compared to the OSKAR simulator's GPU-implemented RIME components it is 7.7 and 12 times faster on the same K40 for single and double-precision floating point respectively. However, OSKAR's RIME implementation is more general than Montblanc's BIRO-tailored RIME.   Theoretical analysis of Montblanc's dominant CUDA kernel suggests that it is memory bound. In practice, profiling shows that is balanced between compute and memory, as much of the data required by the problem is retained in L1 and L2 cache.



### Co-Regularized Deep Representations for Video Summarization
- **Arxiv ID**: http://arxiv.org/abs/1501.07738v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07738v1)
- **Published**: 2015-01-30 11:48:20+00:00
- **Updated**: 2015-01-30 11:48:20+00:00
- **Authors**: Olivier Mor√®re, Hanlin Goh, Antoine Veillard, Vijay Chandrasekhar, Jie Lin
- **Comment**: Video summarization, deep convolutional neural networks,
  co-regularized restricted Boltzmann machines
- **Journal**: None
- **Summary**: Compact keyframe-based video summaries are a popular way of generating viewership on video sharing platforms. Yet, creating relevant and compelling summaries for arbitrarily long videos with a small number of keyframes is a challenging task. We propose a comprehensive keyframe-based summarization framework combining deep convolutional neural networks and restricted Boltzmann machines. An original co-regularization scheme is used to discover meaningful subject-scene associations. The resulting multimodal representations are then used to select highly-relevant keyframes. A comprehensive user study is conducted comparing our proposed method to a variety of schemes, including the summarization currently in use by one of the most popular video sharing websites. The results show that our method consistently outperforms the baseline schemes for any given amount of keyframes both in terms of attractiveness and informativeness. The lead is even more significant for smaller summaries.



### Gibbs-Ringing Artifact Removal Based on Local Subvoxel-shifts
- **Arxiv ID**: http://arxiv.org/abs/1501.07758v1
- **DOI**: None
- **Categories**: **physics.med-ph**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1501.07758v1)
- **Published**: 2015-01-30 12:52:30+00:00
- **Updated**: 2015-01-30 12:52:30+00:00
- **Authors**: Elias Kellner, Bibek Dhital, Marco Reisert
- **Comment**: 8 pages, 7 figures
- **Journal**: None
- **Summary**: Gibbs-ringing is a well known artifact which manifests itself as spurious oscillations in the vicinity of sharp image transients, e.g. at tissue boundaries. The origin can be seen in the truncation of k-space during MRI data-acquisition. Consequently, correction techniques like Gegenbauer reconstruction or extrapolation methods aim at recovering these missing data. Here, we present a simple and robust method which exploits a different view on the Gibbs-phenomena. The truncation in k-space can be interpreted as a convolution with a sinc-function in image space. Hence, the severity of the artifacts depends on how the sinc-function is sampled. We propose to re-interpolate the image based on local, subvoxel shifts to sample the ringing pattern at the zero-crossings of the oscillating sinc-function. With this, the artifact can effectively and robustly be removed with a minimal amount of smoothing.



### RANSAC based three points algorithm for ellipse fitting of spherical object's projection
- **Arxiv ID**: http://arxiv.org/abs/1503.07460v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1503.07460v1)
- **Published**: 2015-01-30 15:05:12+00:00
- **Updated**: 2015-01-30 15:05:12+00:00
- **Authors**: Shenghui Xu
- **Comment**: None
- **Journal**: None
- **Summary**: As the spherical object can be seen everywhere, we should extract the ellipse image accurately and fit it by implicit algebraic curve in order to finish the 3D reconstruction. In this paper, we propose a new ellipse fitting algorithm which only needs three points to fit the projection of spherical object and is different from the traditional algorithms that need at least five point. The fitting procedure is just similar as the estimation of Fundamental Matrix estimation by seven points, and the RANSAC algorithm has also been used to exclude the interference of noise and scattered points.



### A Proximal Bregman Projection Approach to Continuous Max-Flow Problems Using Entropic Distances
- **Arxiv ID**: http://arxiv.org/abs/1501.07844v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07844v1)
- **Published**: 2015-01-30 17:03:22+00:00
- **Updated**: 2015-01-30 17:03:22+00:00
- **Authors**: John S. H. Baxter, Martin Rajchl, Jing Yuan, Terry M. Peters
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: One issue limiting the adaption of large-scale multi-region segmentation is the sometimes prohibitive memory requirements. This is especially troubling considering advances in massively parallel computing and commercial graphics processing units because of their already limited memory compared to the current random access memory used in more traditional computation. To address this issue in the field of continuous max-flow segmentation, we have developed a \textit{pseudo-flow} framework using the theory of Bregman proximal projections and entropic distances which implicitly represents flow variables between labels and designated source and sink nodes. This reduces the memory requirements for max-flow segmentation by approximately 20\% for Potts models and approximately 30\% for hierarchical max-flow (HMF) and directed acyclic graph max-flow (DAGMF) models. This represents a great improvement in the state-of-the-art in max-flow segmentation, allowing for much larger problems to be addressed and accelerated using commercially available graphics processing hardware.



### An Analytical Study of different Document Image Binarization Methods
- **Arxiv ID**: http://arxiv.org/abs/1501.07862v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07862v1)
- **Published**: 2015-01-30 17:50:41+00:00
- **Updated**: 2015-01-30 17:50:41+00:00
- **Authors**: Mahua Nandy, Satadal Saha
- **Comment**: National Conference on Computing and Communication Systems
  (COCOSYS-09), UIT, Burdwan, January 02-04, 2009, pp. 71-76
- **Journal**: None
- **Summary**: Document image has been the area of research for a couple of decades because of its potential application in the area of text recognition, line recognition or any other shape recognition from the image. For most of these purposes binarization of image becomes mandatory as far as recognition is concerned. Throughout couple decades standard algorithms have already been developed for this purpose. Some of these algorithms are applicable to degraded image also. Our objective behind this work is to study the existing techniques, compare them in view of advantages and disadvantages and modify some of these algorithms to optimize time or performance.



### Multi-task Image Classification via Collaborative, Hierarchical Spike-and-Slab Priors
- **Arxiv ID**: http://arxiv.org/abs/1501.07867v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.07867v1)
- **Published**: 2015-01-30 18:05:01+00:00
- **Updated**: 2015-01-30 18:05:01+00:00
- **Authors**: Hojjat Seyed Mousavi, Umamahesh Srinivas, Vishal Monga, Yuanming Suo, Minh Dao, Trac. D. Tran
- **Comment**: Accepted to International Conference in Image Processing (ICIP) 2014
- **Journal**: None
- **Summary**: Promising results have been achieved in image classification problems by exploiting the discriminative power of sparse representations for classification (SRC). Recently, it has been shown that the use of \emph{class-specific} spike-and-slab priors in conjunction with the class-specific dictionaries from SRC is particularly effective in low training scenarios. As a logical extension, we build on this framework for multitask scenarios, wherein multiple representations of the same physical phenomena are available. We experimentally demonstrate the benefits of mining joint information from different camera views for multi-view face recognition.



### Sketch-a-Net that Beats Humans
- **Arxiv ID**: http://arxiv.org/abs/1501.07873v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1501.07873v3)
- **Published**: 2015-01-30 18:35:59+00:00
- **Updated**: 2015-07-21 15:59:05+00:00
- **Authors**: Qian Yu, Yongxin Yang, Yi-Zhe Song, Tao Xiang, Timothy Hospedales
- **Comment**: Accepted to BMVC 2015 (oral)
- **Journal**: None
- **Summary**: We propose a multi-scale multi-channel deep neural network framework that, for the first time, yields sketch recognition performance surpassing that of humans. Our superior performance is a result of explicitly embedding the unique characteristics of sketches in our model: (i) a network architecture designed for sketch rather than natural photo statistics, (ii) a multi-channel generalisation that encodes sequential ordering in the sketching process, and (iii) a multi-scale network ensemble with joint Bayesian fusion that accounts for the different levels of abstraction exhibited in free-hand sketches. We show that state-of-the-art deep networks specifically engineered for photos of natural objects fail to perform well on sketch recognition, regardless whether they are trained using photo or sketch. Our network on the other hand not only delivers the best performance on the largest human sketch dataset to date, but also is small in size making efficient training possible using just CPUs.



### SHOE: Supervised Hashing with Output Embeddings
- **Arxiv ID**: http://arxiv.org/abs/1502.00030v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1502.00030v1)
- **Published**: 2015-01-30 22:04:12+00:00
- **Updated**: 2015-01-30 22:04:12+00:00
- **Authors**: Sravanthi Bondugula, Varun Manjunatha, Larry S. Davis, David Doermann
- **Comment**: None
- **Journal**: None
- **Summary**: We present a supervised binary encoding scheme for image retrieval that learns projections by taking into account similarity between classes obtained from output embeddings. Our motivation is that binary hash codes learned in this way improve both the visual quality of retrieval results and existing supervised hashing schemes. We employ a sequential greedy optimization that learns relationship aware projections by minimizing the difference between inner products of binary codes and output embedding vectors. We develop a joint optimization framework to learn projections which improve the accuracy of supervised hashing over the current state of the art with respect to standard and sibling evaluation metrics. We further boost performance by applying the supervised dimensionality reduction technique on kernelized input CNN features. Experiments are performed on three datasets: CUB-2011, SUN-Attribute and ImageNet ILSVRC 2010. As a by-product of our method, we show that using a simple k-nn pooling classifier with our discriminative codes improves over the complex classification models on fine grained datasets like CUB and offer an impressive compression ratio of 1024 on CNN features.



