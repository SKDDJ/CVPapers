# Arxiv Papers in cs.CV on 2015-01-23
### Beyond Frontal Faces: Improving Person Recognition Using Multiple Cues
- **Arxiv ID**: http://arxiv.org/abs/1501.05703v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05703v2)
- **Published**: 2015-01-23 02:35:01+00:00
- **Updated**: 2015-01-30 18:48:27+00:00
- **Authors**: Ning Zhang, Manohar Paluri, Yaniv Taigman, Rob Fergus, Lubomir Bourdev
- **Comment**: None
- **Journal**: None
- **Summary**: We explore the task of recognizing peoples' identities in photo albums in an unconstrained setting. To facilitate this, we introduce the new People In Photo Albums (PIPA) dataset, consisting of over 60000 instances of 2000 individuals collected from public Flickr photo albums. With only about half of the person images containing a frontal face, the recognition task is very challenging due to the large variations in pose, clothing, camera viewpoint, image resolution and illumination. We propose the Pose Invariant PErson Recognition (PIPER) method, which accumulates the cues of poselet-level person recognizers trained by deep convolutional networks to discount for the pose variations, combined with a face recognizer and a global recognizer. Experiments on three different settings confirm that in our unconstrained setup PIPER significantly improves on the performance of DeepFace, which is one of the best face recognizers as measured on the LFW dataset.



### Filtered Channel Features for Pedestrian Detection
- **Arxiv ID**: http://arxiv.org/abs/1501.05759v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05759v1)
- **Published**: 2015-01-23 10:19:33+00:00
- **Updated**: 2015-01-23 10:19:33+00:00
- **Authors**: Shanshan Zhang, Rodrigo Benenson, Bernt Schiele
- **Comment**: None
- **Journal**: None
- **Summary**: This paper starts from the observation that multiple top performing pedestrian detectors can be modelled by using an intermediate layer filtering low-level features in combination with a boosted decision forest. Based on this observation we propose a unifying framework and experimentally explore different filter families. We report extensive results enabling a systematic analysis.   Using filtered channel features we obtain top performance on the challenging Caltech and KITTI datasets, while using only HOG+LUV as low-level features. When adding optical flow features we further improve detection quality and report the best known results on the Caltech dataset, reaching 93% recall at 1 FPPI.



### Taking a Deeper Look at Pedestrians
- **Arxiv ID**: http://arxiv.org/abs/1501.05790v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05790v1)
- **Published**: 2015-01-23 13:07:56+00:00
- **Updated**: 2015-01-23 13:07:56+00:00
- **Authors**: Jan Hosang, Mohamed Omran, Rodrigo Benenson, Bernt Schiele
- **Comment**: None
- **Journal**: None
- **Summary**: In this paper we study the use of convolutional neural networks (convnets) for the task of pedestrian detection. Despite their recent diverse successes, convnets historically underperform compared to other pedestrian detectors. We deliberately omit explicitly modelling the problem into the network (e.g. parts or occlusion modelling) and show that we can reach competitive performance without bells and whistles. In a wide range of experiments we analyse small and big convnets, their architectural choices, parameters, and the influence of different training data, including pre-training on surrogate tasks.   We present the best convnet detectors on the Caltech and KITTI dataset. On Caltech our convnets reach top performance both for the Caltech1x and Caltech10x training setup. Using additional data at training time our strongest convnet model is competitive even to detectors that use additional data (optical flow) at test time.



### Unsupervised Segmentation of Multispectral Images with Cellular Automata
- **Arxiv ID**: http://arxiv.org/abs/1501.05854v1
- **DOI**: 10.13140/2.1.2250.7849
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05854v1)
- **Published**: 2015-01-23 16:11:23+00:00
- **Updated**: 2015-01-23 16:11:23+00:00
- **Authors**: Wuilian Torres, Antonio Rueda-Toicen
- **Comment**: 6 pages, 6 figures, conference: CIMENICS XII, 2014
- **Journal**: None
- **Summary**: Multispectral images acquired by satellites are used to study phenomena on the Earth's surface. Unsupervised classification techniques analyze multispectral image content without considering prior knowledge of the observed terrain; this is done using techniques which group pixels that have similar statistics of digital level distribution in the various image channels. In this paper, we propose a methodology for unsupervised classification based on a deterministic cellular automaton. The automaton is initialized in an unsupervised manner by setting seed cells, selected according to two criteria: to be representative of the spatial distribution of the dominant elements in the image, and to take into account the diversity of spectral signatures in the image. The automaton's evolution is based on an attack rule that is applied simultaneously to all its cells. Among the noteworthy advantages of deterministic cellular automata for multispectral processing of satellite imagery is the consideration of topological information in the image via seed positioning, and the ability to modify the scale of the study.



### Advances in Human Action Recognition: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1501.05964v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05964v1)
- **Published**: 2015-01-23 21:36:55+00:00
- **Updated**: 2015-01-23 21:36:55+00:00
- **Authors**: Guangchun Cheng, Yiwen Wan, Abdullah N. Saudagar, Kamesh Namuduri, Bill P. Buckles
- **Comment**: None
- **Journal**: None
- **Summary**: Human action recognition has been an important topic in computer vision due to its many applications such as video surveillance, human machine interaction and video retrieval. One core problem behind these applications is automatically recognizing low-level actions and high-level activities of interest. The former is usually the basis for the latter. This survey gives an overview of the most recent advances in human action recognition during the past several years, following a well-formed taxonomy proposed by a previous survey. From this state-of-the-art survey, researchers can view a panorama of progress in this area for future research.



### Automatic Objects Removal for Scene Completion
- **Arxiv ID**: http://arxiv.org/abs/1501.05970v1
- **DOI**: 10.1109/INFCOMW.2014.6849291
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.05970v1)
- **Published**: 2015-01-23 21:46:41+00:00
- **Updated**: 2015-01-23 21:46:41+00:00
- **Authors**: Jianjun Yang, Yin Wang, Honggang Wang, Kun Hua, Wei Wang, Ju Shen
- **Comment**: 6 pages, IEEE International Conference on Computer Communications
  (INFOCOM 14), Workshop on Security and Privacy in Big Data, Toronto, Canada,
  2014
- **Journal**: None
- **Summary**: With the explosive growth of web-based cameras and mobile devices, billions of photographs are uploaded to the internet. We can trivially collect a huge number of photo streams for various goals, such as 3D scene reconstruction and other big data applications. However, this is not an easy task due to the fact the retrieved photos are neither aligned nor calibrated. Furthermore, with the occlusion of unexpected foreground objects like people, vehicles, it is even more challenging to find feature correspondences and reconstruct realistic scenes. In this paper, we propose a structure based image completion algorithm for object removal that produces visually plausible content with consistent structure and scene texture. We use an edge matching technique to infer the potential structure of the unknown region. Driven by the estimated structure, texture synthesis is performed automatically along the estimated curves. We evaluate the proposed method on different types of images: from highly structured indoor environment to the natural scenes. Our experimental results demonstrate satisfactory performance that can be potentially used for subsequent big data processing: 3D scene reconstruction and location recognition.



