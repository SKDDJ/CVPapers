# Arxiv Papers in cs.CV on 2015-01-20
### Deep Convolutional Neural Networks for Action Recognition Using Depth Map Sequences
- **Arxiv ID**: http://arxiv.org/abs/1501.04686v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04686v1)
- **Published**: 2015-01-20 00:46:10+00:00
- **Updated**: 2015-01-20 00:46:10+00:00
- **Authors**: Pichao Wang, Wanqing Li, Zhimin Gao, Jing Zhang, Chang Tang, Philip Ogunbona
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, deep learning approach has achieved promising results in various fields of computer vision. In this paper, a new framework called Hierarchical Depth Motion Maps (HDMM) + 3 Channel Deep Convolutional Neural Networks (3ConvNets) is proposed for human action recognition using depth map sequences. Firstly, we rotate the original depth data in 3D pointclouds to mimic the rotation of cameras, so that our algorithms can handle view variant cases. Secondly, in order to effectively extract the body shape and motion information, we generate weighted depth motion maps (DMM) at several temporal scales, referred to as Hierarchical Depth Motion Maps (HDMM). Then, three channels of ConvNets are trained on the HDMMs from three projected orthogonal planes separately. The proposed algorithms are evaluated on MSRAction3D, MSRAction3DExt, UTKinect-Action and MSRDailyActivity3D datasets respectively. We also combine the last three datasets into a larger one (called Combined Dataset) and test the proposed method on it. The results show that our approach can achieve state-of-the-art results on the individual datasets and without dramatical performance degradation on the Combined Dataset.



### Naive-Deep Face Recognition: Touching the Limit of LFW Benchmark or Not?
- **Arxiv ID**: http://arxiv.org/abs/1501.04690v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04690v1)
- **Published**: 2015-01-20 01:15:02+00:00
- **Updated**: 2015-01-20 01:15:02+00:00
- **Authors**: Erjin Zhou, Zhimin Cao, Qi Yin
- **Comment**: None
- **Journal**: None
- **Summary**: Face recognition performance improves rapidly with the recent deep learning technique developing and underlying large training dataset accumulating. In this paper, we report our observations on how big data impacts the recognition performance. According to these observations, we build our Megvii Face Recognition System, which achieves 99.50% accuracy on the LFW benchmark, outperforming the previous state-of-the-art. Furthermore, we report the performance in a real-world security certification scenario. There still exists a clear gap between machine recognition and human performance. We summarize our experiments and present three challenges lying ahead in recent face recognition. And we indicate several possible solutions towards these challenges. We hope our work will stimulate the community's discussion of the difference between research benchmark and real-world applications.



### Tracing the boundaries of materials in transparent vessels using computer vision
- **Arxiv ID**: http://arxiv.org/abs/1501.04691v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04691v3)
- **Published**: 2015-01-20 01:19:33+00:00
- **Updated**: 2015-01-31 20:59:29+00:00
- **Authors**: Sagi Eppel
- **Comment**: Code and documentation for the method described is freely available
  at:
  http://www.mathworks.com/matlabcentral/fileexchange/49076-find-the-boundaries-of-materials-in-transparent-vessels-using-computer-vision
- **Journal**: None
- **Summary**: Visual recognition of material boundaries in transparent vessels is valuable for numerous applications. Such recognition is essential for estimation of fill-level, volume and phase-boundaries as well as for tracking of such chemical processes as precipitation, crystallization, condensation, evaporation and phase-separation. The problem of material boundary recognition in images is particularly complex for materials with non-flat surfaces, i.e., solids, powders and viscous fluids, in which the material interfaces have unpredictable shapes. This work demonstrates a general method for finding the boundaries of materials inside transparent containers in images. The method uses an image of the transparent vessel containing the material and the boundary of the vessel in this image. The recognition is based on the assumption that the material boundary appears in the image in the form of a curve (with various constraints) whose endpoints are both positioned on the vessel contour. The probability that a curve matches the material boundary in the image is evaluated using a cost function based on some image properties along this curve. Several image properties were examined as indicators for the material boundary. The optimal boundary curve was found using Dijkstra's algorithm. The method was successfully examined for recognition of various types of phase-boundaries, including liquid-air, solid-air and solid-liquid interfaces, as well as for various types of glassware containers from everyday life and the chemistry laboratory (i.e., bottles, beakers, flasks, jars, columns, vials and separation-funnels). In addition, the method can be easily extended to materials carried on top of carrier vessels (i.e., plates, spoons, spatulas).



### DeepHash: Getting Regularization, Depth and Fine-Tuning Right
- **Arxiv ID**: http://arxiv.org/abs/1501.04711v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.IR
- **Links**: [PDF](http://arxiv.org/pdf/1501.04711v1)
- **Published**: 2015-01-20 04:36:12+00:00
- **Updated**: 2015-01-20 04:36:12+00:00
- **Authors**: Jie Lin, Olivier Morere, Vijay Chandrasekhar, Antoine Veillard, Hanlin Goh
- **Comment**: None
- **Journal**: None
- **Summary**: This work focuses on representing very high-dimensional global image descriptors using very compact 64-1024 bit binary hashes for instance retrieval. We propose DeepHash: a hashing scheme based on deep networks. Key to making DeepHash work at extremely low bitrates are three important considerations -- regularization, depth and fine-tuning -- each requiring solutions specific to the hashing problem. In-depth evaluation shows that our scheme consistently outperforms state-of-the-art methods across all data sets for both Fisher Vectors and Deep Convolutional Neural Network features, by up to 20 percent over other schemes. The retrieval performance with 256-bit hashes is close to that of the uncompressed floating point features -- a remarkable 512 times compression.



### Robust Face Recognition by Constrained Part-based Alignment
- **Arxiv ID**: http://arxiv.org/abs/1501.04717v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1501.04717v1)
- **Published**: 2015-01-20 06:05:01+00:00
- **Updated**: 2015-01-20 06:05:01+00:00
- **Authors**: Yuting Zhang, Kui Jia, Yueming Wang, Gang Pan, Tsung-Han Chan, Yi Ma
- **Comment**: None
- **Journal**: None
- **Summary**: Developing a reliable and practical face recognition system is a long-standing goal in computer vision research. Existing literature suggests that pixel-wise face alignment is the key to achieve high-accuracy face recognition. By assuming a human face as piece-wise planar surfaces, where each surface corresponds to a facial part, we develop in this paper a Constrained Part-based Alignment (CPA) algorithm for face recognition across pose and/or expression. Our proposed algorithm is based on a trainable CPA model, which learns appearance evidence of individual parts and a tree-structured shape configuration among different parts. Given a probe face, CPA simultaneously aligns all its parts by fitting them to the appearance evidence with consideration of the constraint from the tree-structured shape configuration. This objective is formulated as a norm minimization problem regularized by graph likelihoods. CPA can be easily integrated with many existing classifiers to perform part-based face recognition. Extensive experiments on benchmark face datasets show that CPA outperforms or is on par with existing methods for robust face recognition across pose, expression, and/or illumination changes.



### Distributed Data Association in Smart Camera Networks via Dual Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1501.04754v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04754v1)
- **Published**: 2015-01-20 10:24:31+00:00
- **Updated**: 2015-01-20 10:24:31+00:00
- **Authors**: Jiuqing Wan, Yuting Nie, Li Liu
- **Comment**: 30 pages, 11 figures
- **Journal**: None
- **Summary**: One of the fundamental requirements for visual surveillance using smart camera networks is the correct association of each persons observations generated on different cameras. Recently, distributed data association that involves only local information processing on each camera node and mutual information exchanging between neighboring cameras has attracted many research interests due to its superiority in large scale applications. In this paper, we formulate the problem of data association in smart camera networks as an Integer Programming problem by introducing a set of linking variables, and propose two distributed algorithms, namely L-DD and Q-DD, to solve the Integer Programming problem using dual decomposition technique. In our algorithms, the original IP problem is decomposed into several sub-problems, which can be solved locally and efficiently on each smart camera, and then different sub-problems reach consensus on their solutions in a rigorous way by adjusting their parameters based on projected sub-gradient optimization. The proposed methods are simple and flexible, in that (i) we can incorporate any feature extraction and matching technique into our framework to measure the similarity between two observations, which is used to define the cost of each link, and (ii) we can decompose the original problem in any way as long as the resulting sub-problem can be solved independently on individual camera. We show the competitiveness of our methods in both accuracy and speed by theoretical analysis and experimental comparison with state of the art algorithms on two real data sets collected by camera networks in our campus garden and office building.



### Constructing Binary Descriptors with a Stochastic Hill Climbing Search
- **Arxiv ID**: http://arxiv.org/abs/1501.04782v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04782v2)
- **Published**: 2015-01-20 12:38:08+00:00
- **Updated**: 2015-07-16 14:57:47+00:00
- **Authors**: Nenad Markuš, Igor S. Pandžić, Jörgen Ahlberg
- **Comment**: None
- **Journal**: None
- **Summary**: Binary descriptors of image patches provide processing speed advantages and require less storage than methods that encode the patch appearance with a vector of real numbers. We provide evidence that, despite its simplicity, a stochastic hill climbing bit selection procedure for descriptor construction defeats recently proposed alternatives on a standard discriminative power benchmark. The method is easy to implement and understand, has no free parameters that need fine tuning, and runs fast.



### Scalable Multi-Output Label Prediction: From Classifier Chains to Classifier Trellises
- **Arxiv ID**: http://arxiv.org/abs/1501.04870v1
- **DOI**: 10.1016/j.patcog.2015.01.004
- **Categories**: **stat.ML**, cs.CV, cs.DS, cs.LG, stat.CO
- **Links**: [PDF](http://arxiv.org/pdf/1501.04870v1)
- **Published**: 2015-01-20 16:33:40+00:00
- **Updated**: 2015-01-20 16:33:40+00:00
- **Authors**: J. Read, L. Martino, P. Olmos, D. Luengo
- **Comment**: (accepted in Pattern Recognition)
- **Journal**: Pattern Recognition, Volume 48, Issue 6, 2015, Pages 2096-2109
- **Summary**: Multi-output inference tasks, such as multi-label classification, have become increasingly important in recent years. A popular method for multi-label classification is classifier chains, in which the predictions of individual classifiers are cascaded along a chain, thus taking into account inter-label dependencies and improving the overall performance. Several varieties of classifier chain methods have been introduced, and many of them perform very competitively across a wide range of benchmark datasets. However, scalability limitations become apparent on larger datasets when modeling a fully-cascaded chain. In particular, the methods' strategies for discovering and modeling a good chain structure constitutes a mayor computational bottleneck. In this paper, we present the classifier trellis (CT) method for scalable multi-label classification. We compare CT with several recently proposed classifier chain methods to show that it occupies an important niche: it is highly competitive on standard multi-label problems, yet it can also scale up to thousands or even tens of thousands of labels.



### A Light Transport Model for Mitigating Multipath Interference in TOF Sensors
- **Arxiv ID**: http://arxiv.org/abs/1501.04878v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.04878v2)
- **Published**: 2015-01-20 16:56:49+00:00
- **Updated**: 2015-01-30 21:11:48+00:00
- **Authors**: Nikhil Naik, Achuta Kadambi, Christoph Rhemann, Shahram Izadi, Ramesh Raskar, Sing Bing Kang
- **Comment**: This paper has been withdrawn by the submitter as the submission was
  made due to a miscommunication
- **Journal**: None
- **Summary**: Continuous-wave Time-of-flight (TOF) range imaging has become a commercially viable technology with many applications in computer vision and graphics. However, the depth images obtained from TOF cameras contain scene dependent errors due to multipath interference (MPI). Specifically, MPI occurs when multiple optical reflections return to a single spatial location on the imaging sensor. Many prior approaches to rectifying MPI rely on sparsity in optical reflections, which is an extreme simplification. In this paper, we correct MPI by combining the standard measurements from a TOF camera with information from direct and global light transport. We report results on both simulated experiments and physical experiments (using the Kinect sensor). Our results, evaluated against ground truth, demonstrate a quantitative improvement in depth accuracy.



