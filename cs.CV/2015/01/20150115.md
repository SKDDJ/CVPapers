# Arxiv Papers in cs.CV on 2015-01-15
### LATCH: Learned Arrangements of Three Patch Codes
- **Arxiv ID**: http://arxiv.org/abs/1501.03719v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.03719v1)
- **Published**: 2015-01-15 15:38:57+00:00
- **Updated**: 2015-01-15 15:38:57+00:00
- **Authors**: Gil Levi, Tal Hassner
- **Comment**: None
- **Journal**: None
- **Summary**: We present a novel means of describing local image appearances using binary strings. Binary descriptors have drawn increasing interest in recent years due to their speed and low memory footprint. A known shortcoming of these representations is their inferior performance compared to larger, histogram based descriptors such as the SIFT. Our goal is to close this performance gap while maintaining the benefits attributed to binary representations. To this end we propose the Learned Arrangements of Three Patch Codes descriptors, or LATCH. Our key observation is that existing binary descriptors are at an increased risk from noise and local appearance variations. This, as they compare the values of pixel pairs; changes to either of the pixels can easily lead to changes in descriptor values, hence damaging its performance. In order to provide more robustness, we instead propose a novel means of comparing pixel patches. This ostensibly small change, requires a substantial redesign of the descriptors themselves and how they are produced. Our resulting LATCH representation is rigorously compared to state-of-the-art binary descriptors and shown to provide far better performance for similar computation and space requirements.



### Visual Analytics of Image-Centric Cohort Studies in Epidemiology
- **Arxiv ID**: http://arxiv.org/abs/1501.04009v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1501.04009v1)
- **Published**: 2015-01-15 16:51:20+00:00
- **Updated**: 2015-01-15 16:51:20+00:00
- **Authors**: Bernhard Preim, Paul Klemm, Helwig Hauser, Katrin Hegenscheid, Steffen Oeltze, Klaus Toennies, Henry VÃ¶lzke
- **Comment**: None
- **Journal**: None
- **Summary**: Epidemiology characterizes the influence of causes to disease and health conditions of defined populations. Cohort studies are population-based studies involving usually large numbers of randomly selected individuals and comprising numerous attributes, ranging from self-reported interview data to results from various medical examinations, e.g., blood and urine samples. Since recently, medical imaging has been used as an additional instrument to assess risk factors and potential prognostic information. In this chapter, we discuss such studies and how the evaluation may benefit from visual analytics. Cluster analysis to define groups, reliable image analysis of organs in medical imaging data and shape space exploration to characterize anatomical shapes are among the visual analytics tools that may enable epidemiologists to fully exploit the potential of their huge and complex data. To gain acceptance, visual analytics tools need to complement more classical epidemiologic tools, primarily hypothesis-driven statistical analysis.



### Screen Content Image Segmentation Using Least Absolute Deviation Fitting
- **Arxiv ID**: http://arxiv.org/abs/1501.03755v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.03755v2)
- **Published**: 2015-01-15 17:40:20+00:00
- **Updated**: 2015-02-19 07:07:06+00:00
- **Authors**: Shervin Minaee, Yao Wang
- **Comment**: 5 pages
- **Journal**: None
- **Summary**: We propose an algorithm for separating the foreground (mainly text and line graphics) from the smoothly varying background in screen content images. The proposed method is designed based on the assumption that the background part of the image is smoothly varying and can be represented by a linear combination of a few smoothly varying basis functions, while the foreground text and graphics create sharp discontinuity and cannot be modeled by this smooth representation. The algorithm separates the background and foreground using a least absolute deviation method to fit the smooth model to the image pixels. This algorithm has been tested on several images from HEVC standard test sequences for screen content coding, and is shown to have superior performance over other popular methods, such as k-means clustering based segmentation in DjVu and shape primitive extraction and coding (SPEC) algorithm. Such background/foreground segmentation are important pre-processing steps for text extraction and separate coding of background and foreground for compression of screen content images.



### Submodular relaxation for inference in Markov random fields
- **Arxiv ID**: http://arxiv.org/abs/1501.03771v1
- **DOI**: 10.1109/TPAMI.2014.2369046
- **Categories**: **cs.CV**, math.OC, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1501.03771v1)
- **Published**: 2015-01-15 18:34:27+00:00
- **Updated**: 2015-01-15 18:34:27+00:00
- **Authors**: Anton Osokin, Dmitry Vetrov
- **Comment**: This paper is accepted for publication in IEEE Transactions on
  Pattern Analysis and Machine Intelligence
- **Journal**: None
- **Summary**: In this paper we address the problem of finding the most probable state of a discrete Markov random field (MRF), also known as the MRF energy minimization problem. The task is known to be NP-hard in general and its practical importance motivates numerous approximate algorithms. We propose a submodular relaxation approach (SMR) based on a Lagrangian relaxation of the initial problem. Unlike the dual decomposition approach of Komodakis et al., 2011 SMR does not decompose the graph structure of the initial problem but constructs a submodular energy that is minimized within the Lagrangian relaxation. Our approach is applicable to both pairwise and high-order MRFs and allows to take into account global potentials of certain types. We study theoretical properties of the proposed approach and evaluate it experimentally.



### Computer-assisted polyp matching between optical colonoscopy and CT colonography: a phantom study
- **Arxiv ID**: http://arxiv.org/abs/1501.03779v1
- **DOI**: 10.1117/12.2042860
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1501.03779v1)
- **Published**: 2015-01-15 19:11:26+00:00
- **Updated**: 2015-01-15 19:11:26+00:00
- **Authors**: Holger R. Roth, Thomas E. Hampshire, Emma Helbren, Mingxing Hu, Roser Vega, Steve Halligan, David J. Hawkes
- **Comment**: This paper was presented at the SPIE Medical Imaging 2014 conference
- **Journal**: Proc. SPIE 9036, Medical Imaging 2014: Image-Guided Procedures,
  Robotic Interventions, and Modeling, 903609 (March 12, 2014)
- **Summary**: Potentially precancerous polyps detected with CT colonography (CTC) need to be removed subsequently, using an optical colonoscope (OC). Due to large colonic deformations induced by the colonoscope, even very experienced colonoscopists find it difficult to pinpoint the exact location of the colonoscope tip in relation to polyps reported on CTC. This can cause unduly prolonged OC examinations that are stressful for the patient, colonoscopist and supporting staff.   We developed a method, based on monocular 3D reconstruction from OC images, that automatically matches polyps observed in OC with polyps reported on prior CTC. A matching cost is computed, using rigid point-based registration between surface point clouds extracted from both modalities. A 3D printed and painted phantom of a 25 cm long transverse colon segment was used to validate the method on two medium sized polyps. Results indicate that the matching cost is smaller at the correct corresponding polyp between OC and CTC: the value is 3.9 times higher at the incorrect polyp, comparing the correct match between polyps to the incorrect match. Furthermore, we evaluate the matching of the reconstructed polyp from OC with other colonic endoluminal surface structures such as haustral folds and show that there is a minimum at the correct polyp from CTC.   Automated matching between polyps observed at OC and prior CTC would facilitate the biopsy or removal of true-positive pathology or exclusion of false-positive CTC findings, and would reduce colonoscopy false-negative (missed) polyps. Ultimately, such a method might reduce healthcare costs, patient inconvenience and discomfort.



