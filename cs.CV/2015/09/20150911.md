# Arxiv Papers in cs.CV on 2015-09-11
### Efficient Convolutional Neural Networks for Pixelwise Classification on Heterogeneous Hardware Systems
- **Arxiv ID**: http://arxiv.org/abs/1509.03371v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, I.2.6; I.5.1
- **Links**: [PDF](http://arxiv.org/pdf/1509.03371v1)
- **Published**: 2015-09-11 01:20:46+00:00
- **Updated**: 2015-09-11 01:20:46+00:00
- **Authors**: Fabian Tschopp
- **Comment**: 92 pages, project source code available at
  https://github.com/naibaf7/, technical report written at ETH Z\"urich, in
  collaboration with AMD, UZH INI and HHMI Janelia
- **Journal**: None
- **Summary**: This work presents and analyzes three convolutional neural network (CNN) models for efficient pixelwise classification of images. When using convolutional neural networks to classify single pixels in patches of a whole image, a lot of redundant computations are carried out when using sliding window networks. This set of new architectures solve this issue by either removing redundant computations or using fully convolutional architectures that inherently predict many pixels at once.   The implementations of the three models are accessible through a new utility on top of the Caffe library. The utility provides support for a wide range of image input and output formats, pre-processing parameters and methods to equalize the label histogram during training. The Caffe library has been extended by new layers and a new backend for availability on a wider range of hardware such as CPUs and GPUs through OpenCL.   On AMD GPUs, speedups of $54\times$ (SK-Net), $437\times$ (U-Net) and $320\times$ (USK-Net) have been observed, taking the SK equivalent SW (sliding window) network as the baseline. The label throughput is up to one megapixel per second.   The analyzed neural networks have distinctive characteristics that apply during training or processing, and not every data set is suitable to every architecture. The quality of the predictions is assessed on two neural tissue data sets, of which one is the ISBI 2012 challenge data set. Two different loss functions, Malis loss and Softmax loss, were used during training.   The whole pipeline, consisting of models, interface and modified Caffe library, is available as Open Source software under the working title Project Greentea.



### Learning Sparse Feature Representations using Probabilistic Quadtrees and Deep Belief Nets
- **Arxiv ID**: http://arxiv.org/abs/1509.03413v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03413v1)
- **Published**: 2015-09-11 08:13:35+00:00
- **Updated**: 2015-09-11 08:13:35+00:00
- **Authors**: Saikat Basu, Manohar Karki, Sangram Ganguly, Robert DiBiano, Supratik Mukhopadhyay, Ramakrishna Nemani
- **Comment**: Published in the European Symposium on Artificial Neural Networks,
  ESANN 2015
- **Journal**: None
- **Summary**: Learning sparse feature representations is a useful instrument for solving an unsupervised learning problem. In this paper, we present three labeled handwritten digit datasets, collectively called n-MNIST. Then, we propose a novel framework for the classification of handwritten digits that learns sparse representations using probabilistic quadtrees and Deep Belief Nets. On the MNIST and n-MNIST datasets, our framework shows promising results and significantly outperforms traditional Deep Belief Networks.



### A reliable order-statistics-based approximate nearest neighbor search algorithm
- **Arxiv ID**: http://arxiv.org/abs/1509.03453v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03453v2)
- **Published**: 2015-09-11 10:33:34+00:00
- **Updated**: 2016-10-29 10:16:09+00:00
- **Authors**: Luisa Verdoliva, Davide Cozzolino, Giovanni Poggi
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a new algorithm for fast approximate nearest neighbor search based on the properties of ordered vectors. Data vectors are classified based on the index and sign of their largest components, thereby partitioning the space in a number of cones centered in the origin. The query is itself classified, and the search starts from the selected cone and proceeds to neighboring ones. Overall, the proposed algorithm corresponds to locality sensitive hashing in the space of directions, with hashing based on the order of components. Thanks to the statistical features emerging through ordering, it deals very well with the challenging case of unstructured data, and is a valuable building block for more complex techniques dealing with structured data. Experiments on both simulated and real-world data prove the proposed algorithm to provide a state-of-the-art performance.



### OCR accuracy improvement on document images through a novel pre-processing approach
- **Arxiv ID**: http://arxiv.org/abs/1509.03456v1
- **DOI**: 10.5121/sipij.2015.6401
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03456v1)
- **Published**: 2015-09-11 10:52:52+00:00
- **Updated**: 2015-09-11 10:52:52+00:00
- **Authors**: Abdeslam El Harraj, Naoufal Raissouni
- **Comment**: None
- **Journal**: Signal & Image Processing : An International Journal (SIPIJ)
  Vol.6, No.4, August 2015
- **Summary**: Digital camera and mobile document image acquisition are new trends arising in the world of Optical Character Recognition and text detection. In some cases, such process integrates many distortions and produces poorly scanned text or text-photo images and natural images, leading to an unreliable OCR digitization. In this paper, we present a novel nonparametric and unsupervised method to compensate for undesirable document image distortions aiming to optimally improve OCR accuracy. Our approach relies on a very efficient stack of document image enhancing techniques to recover deformation of the entire document image. First, we propose a local brightness and contrast adjustment method to effectively handle lighting variations and the irregular distribution of image illumination. Second, we use an optimized greyscale conversion algorithm to transform our document image to greyscale level. Third, we sharpen the useful information in the resulting greyscale image using Un-sharp Masking method. Finally, an optimal global binarization approach is used to prepare the final document image to OCR recognition. The proposed approach can significantly improve text detection rate and optical character recognition accuracy. To demonstrate the efficiency of our approach, an exhaustive experimentation on a standard dataset is presented.



### Person Recognition in Personal Photo Collections
- **Arxiv ID**: http://arxiv.org/abs/1509.03502v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03502v2)
- **Published**: 2015-09-11 13:34:45+00:00
- **Updated**: 2015-09-25 19:58:34+00:00
- **Authors**: Seong Joon Oh, Rodrigo Benenson, Mario Fritz, Bernt Schiele
- **Comment**: Accepted to ICCV 2015, revised
- **Journal**: None
- **Summary**: Recognising persons in everyday photos presents major challenges (occluded faces, different clothing, locations, etc.) for machine vision. We propose a convnet based person recognition system on which we provide an in-depth analysis of informativeness of different body cues, impact of training data, and the common failure modes of the system. In addition, we discuss the limitations of existing benchmarks and propose more challenging ones. Our method is simple and is built on open source and open data, yet it improves the state of the art results on a large dataset of social media photos (PIPA).



### Fingerprint Recognition Using Translation Invariant Scattering Network
- **Arxiv ID**: http://arxiv.org/abs/1509.03542v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03542v3)
- **Published**: 2015-09-11 15:04:35+00:00
- **Updated**: 2015-11-26 01:48:13+00:00
- **Authors**: Shervin Minaee, Yao Wang
- **Comment**: IEEE Signal Processing in Medicine and Biology Symposium, 2015
- **Journal**: None
- **Summary**: Fingerprint recognition has drawn a lot of attention during last decades. Different features and algorithms have been used for fingerprint recognition in the past. In this paper, a powerful image representation called scattering transform/network, is used for recognition. Scattering network is a convolutional network where its architecture and filters are predefined wavelet transforms. The first layer of scattering representation is similar to sift descriptors and the higher layers capture higher frequency content of the signal. After extraction of scattering features, their dimensionality is reduced by applying principal component analysis (PCA). At the end, multi-class SVM is used to perform template matching for the recognition task. The proposed scheme is tested on a well-known fingerprint database and has shown promising results with the best accuracy rate of 98\%.



### DeepSat - A Learning framework for Satellite Imagery
- **Arxiv ID**: http://arxiv.org/abs/1509.03602v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03602v1)
- **Published**: 2015-09-11 18:32:51+00:00
- **Updated**: 2015-09-11 18:32:51+00:00
- **Authors**: Saikat Basu, Sangram Ganguly, Supratik Mukhopadhyay, Robert DiBiano, Manohar Karki, Ramakrishna Nemani
- **Comment**: Paper was accepted at ACM SIGSPATIAL 2015
- **Journal**: None
- **Summary**: Satellite image classification is a challenging problem that lies at the crossroads of remote sensing, computer vision, and machine learning. Due to the high variability inherent in satellite data, most of the current object classification approaches are not suitable for handling satellite datasets. The progress of satellite image analytics has also been inhibited by the lack of a single labeled high-resolution dataset with multiple class labels. The contributions of this paper are twofold - (1) first, we present two new satellite datasets called SAT-4 and SAT-6, and (2) then, we propose a classification framework that extracts features from an input image, normalizes them and feeds the normalized feature vectors to a Deep Belief Network for classification. On the SAT-4 dataset, our best network produces a classification accuracy of 97.95% and outperforms three state-of-the-art object recognition algorithms, namely - Deep Belief Networks, Convolutional Neural Networks and Stacked Denoising Autoencoders by ~11%. On SAT-6, it produces a classification accuracy of 93.9% and outperforms the other algorithms by ~15%. Comparative studies with a Random Forest classifier show the advantage of an unsupervised learning approach over traditional supervised learning techniques. A statistical analysis based on Distribution Separability Criterion and Intrinsic Dimensionality Estimation substantiates the effectiveness of our approach in learning better representations for satellite imagery.



