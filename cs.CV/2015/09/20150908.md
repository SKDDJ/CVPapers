# Arxiv Papers in cs.CV on 2015-09-08
### Object Proposals for Text Extraction in the Wild
- **Arxiv ID**: http://arxiv.org/abs/1509.02317v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.02317v1)
- **Published**: 2015-09-08 10:44:09+00:00
- **Updated**: 2015-09-08 10:44:09+00:00
- **Authors**: Lluis Gomez, Dimosthenis Karatzas
- **Comment**: 13th International Conference on Document Analysis and Recognition
  (ICDAR 2015)
- **Journal**: None
- **Summary**: Object Proposals is a recent computer vision technique receiving increasing interest from the research community. Its main objective is to generate a relatively small set of bounding box proposals that are most likely to contain objects of interest. The use of Object Proposals techniques in the scene text understanding field is innovative. Motivated by the success of powerful while expensive techniques to recognize words in a holistic way, Object Proposals techniques emerge as an alternative to the traditional text detectors.   In this paper we study to what extent the existing generic Object Proposals methods may be useful for scene text understanding. Also, we propose a new Object Proposals algorithm that is specifically designed for text and compare it with other generic methods in the state of the art. Experiments show that our proposal is superior in its ability of producing good quality word proposals in an efficient way. The source code of our method is made publicly available.



### HEp-2 Cell Classification: The Role of Gaussian Scale Space Theory as A Pre-processing Approach
- **Arxiv ID**: http://arxiv.org/abs/1509.02320v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.02320v1)
- **Published**: 2015-09-08 10:59:21+00:00
- **Updated**: 2015-09-08 10:59:21+00:00
- **Authors**: Xianbiao Qi, Guoying Zhao, Jie Chen, Matti Pietik√§inen
- **Comment**: 9 pages, 6 figures
- **Journal**: None
- **Summary**: \textit{Indirect Immunofluorescence Imaging of Human Epithelial Type 2} (HEp-2) cells is an effective way to identify the presence of Anti-Nuclear Antibody (ANA). Most existing works on HEp-2 cell classification mainly focus on feature extraction, feature encoding and classifier design. Very few efforts have been devoted to study the importance of the pre-processing techniques. In this paper, we analyze the importance of the pre-processing, and investigate the role of Gaussian Scale Space (GSS) theory as a pre-processing approach for the HEp-2 cell classification task. We validate the GSS pre-processing under the Local Binary Pattern (LBP) and the Bag-of-Words (BoW) frameworks. Under the BoW framework, the introduced pre-processing approach, using only one Local Orientation Adaptive Descriptor (LOAD), achieved superior performance on the Executable Thematic on Pattern Recognition Techniques for Indirect Immunofluorescence (ET-PRT-IIF) image analysis. Our system, using only one feature, outperformed the winner of the ICPR 2014 contest that combined four types of features. Meanwhile, the proposed pre-processing method is not restricted to this work; it can be generalized to many existing works.



### Accelerated graph-based spectral polynomial filters
- **Arxiv ID**: http://arxiv.org/abs/1509.02468v1
- **DOI**: 10.1109/MLSP.2015.7324315
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.02468v1)
- **Published**: 2015-09-08 17:52:03+00:00
- **Updated**: 2015-09-08 17:52:03+00:00
- **Authors**: Andrew Knyazev, Alexander Malyshev
- **Comment**: 6 pages, 6 figures. Accepted to the 2015 IEEE International Workshop
  on Machine Learning for Signal Processing
- **Journal**: Machine Learning for Signal Processing (MLSP), 2015 IEEE 25th
  International Workshop on , pp.1-6, 17-20 Sept. 2015
- **Summary**: Graph-based spectral denoising is a low-pass filtering using the eigendecomposition of the graph Laplacian matrix of a noisy signal. Polynomial filtering avoids costly computation of the eigendecomposition by projections onto suitable Krylov subspaces. Polynomial filters can be based, e.g., on the bilateral and guided filters. We propose constructing accelerated polynomial filters by running flexible Krylov subspace based linear and eigenvalue solvers such as the Block Locally Optimal Preconditioned Conjugate Gradient (LOBPCG) method.



### Deep Attributes from Context-Aware Regional Neural Codes
- **Arxiv ID**: http://arxiv.org/abs/1509.02470v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1509.02470v1)
- **Published**: 2015-09-08 17:53:54+00:00
- **Updated**: 2015-09-08 17:53:54+00:00
- **Authors**: Jianwei Luo, Jianguo Li, Jun Wang, Zhiguo Jiang, Yurong Chen
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: Recently, many researches employ middle-layer output of convolutional neural network models (CNN) as features for different visual recognition tasks. Although promising results have been achieved in some empirical studies, such type of representations still suffer from the well-known issue of semantic gap. This paper proposes so-called deep attribute framework to alleviate this issue from three aspects. First, we introduce object region proposals as intermedia to represent target images, and extract features from region proposals. Second, we study aggregating features from different CNN layers for all region proposals. The aggregation yields a holistic yet compact representation of input images. Results show that cross-region max-pooling of soft-max layer output outperform all other layers. As soft-max layer directly corresponds to semantic concepts, this representation is named "deep attributes". Third, we observe that only a small portion of generated regions by object proposals algorithm are correlated to classification target. Therefore, we introduce context-aware region refining algorithm to pick out contextual regions and build context-aware classifiers.   We apply the proposed deep attributes framework for various vision tasks. Extensive experiments are conducted on standard benchmarks for three visual recognition tasks, i.e., image classification, fine-grained recognition and visual instance retrieval. Results show that deep attribute approaches achieve state-of-the-art results, and outperforms existing peer methods with a significant margin, even though some benchmarks have little overlap of concepts with the pre-trained CNN models.



### Edge-enhancing Filters with Negative Weights
- **Arxiv ID**: http://arxiv.org/abs/1509.02491v1
- **DOI**: 10.1109/GlobalSIP.2015.7418197
- **Categories**: **cs.CV**, cs.IT, math.CO, math.IT, 68U10, 05C85, I.4.3; I.4.6; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1509.02491v1)
- **Published**: 2015-09-08 18:36:53+00:00
- **Updated**: 2015-09-08 18:36:53+00:00
- **Authors**: Andrew Knyazev
- **Comment**: 5 pages; 6 figures. Accepted to IEEE GlobalSIP 2015 conference
- **Journal**: 2015 IEEE Global Conference on Signal and Information Processing
  (GlobalSIP), Orlando, FL, 14-16 Dec.2015, pp. 260 - 264
- **Summary**: In [DOI:10.1109/ICMEW.2014.6890711], a graph-based denoising is performed by projecting the noisy image to a lower dimensional Krylov subspace of the graph Laplacian, constructed using nonnegative weights determined by distances between image data corresponding to image pixels. We~extend the construction of the graph Laplacian to the case, where some graph weights can be negative. Removing the positivity constraint provides a more accurate inference of a graph model behind the data, and thus can improve quality of filters for graph-based signal processing, e.g., denoising, compared to the standard construction, without affecting the costs.



