# Arxiv Papers in cs.CV on 2015-09-14
### Learning Social Relation Traits from Face Images
- **Arxiv ID**: http://arxiv.org/abs/1509.03936v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/1509.03936v1)
- **Published**: 2015-09-14 03:02:36+00:00
- **Updated**: 2015-09-14 03:02:36+00:00
- **Authors**: Zhanpeng Zhang, Ping Luo, Chen Change Loy, Xiaoou Tang
- **Comment**: To appear in International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: Social relation defines the association, e.g, warm, friendliness, and dominance, between two or more people. Motivated by psychological studies, we investigate if such fine-grained and high-level relation traits can be characterised and quantified from face images in the wild. To address this challenging problem we propose a deep model that learns a rich face representation to capture gender, expression, head pose, and age-related attributes, and then performs pairwise-face reasoning for relation prediction. To learn from heterogeneous attribute sources, we formulate a new network architecture with a bridging layer to leverage the inherent correspondences among these datasets. It can also cope with missing target attribute labels. Extensive experiments show that our approach is effective for fine-grained social relation learning in images and videos.



### Geometry and dimensionality reduction of feature spaces in primary visual cortex
- **Arxiv ID**: http://arxiv.org/abs/1509.03942v1
- **DOI**: 10.1117/12.2187026
- **Categories**: **q-bio.NC**, cs.CV, math.GR
- **Links**: [PDF](http://arxiv.org/pdf/1509.03942v1)
- **Published**: 2015-09-14 03:21:54+00:00
- **Updated**: 2015-09-14 03:21:54+00:00
- **Authors**: Davide Barbieri
- **Comment**: None
- **Journal**: None
- **Summary**: Some geometric properties of the wavelet analysis performed by visual neurons are discussed and compared with experimental data. In particular, several relationships between the cortical morphologies and the parametric dependencies of extracted features are formalized and considered from a harmonic analysis point of view.



### Learning to Divide and Conquer for Online Multi-Target Tracking
- **Arxiv ID**: http://arxiv.org/abs/1509.03956v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.03956v1)
- **Published**: 2015-09-14 05:25:52+00:00
- **Updated**: 2015-09-14 05:25:52+00:00
- **Authors**: Francesco Solera, Simone Calderara, Rita Cucchiara
- **Comment**: None
- **Journal**: None
- **Summary**: Online Multiple Target Tracking (MTT) is often addressed within the tracking-by-detection paradigm. Detections are previously extracted independently in each frame and then objects trajectories are built by maximizing specifically designed coherence functions. Nevertheless, ambiguities arise in presence of occlusions or detection errors. In this paper we claim that the ambiguities in tracking could be solved by a selective use of the features, by working with more reliable features if possible and exploiting a deeper representation of the target only if necessary. To this end, we propose an online divide and conquer tracker for static camera scenes, which partitions the assignment problem in local subproblems and solves them by selectively choosing and combining the best features. The complete framework is cast as a structural learning task that unifies these phases and learns tracker parameters from examples. Experiments on two different datasets highlights a significant improvement of tracking performances (MOTA +10%) over the state of the art.



### Natural scene statistics mediate the perception of image complexity
- **Arxiv ID**: http://arxiv.org/abs/1509.03970v1
- **DOI**: 10.1080/13506285.2014.950365
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1509.03970v1)
- **Published**: 2015-09-14 07:34:46+00:00
- **Updated**: 2015-09-14 07:34:46+00:00
- **Authors**: Nicolas Gauvrit, Fernando Soler-Toscano, Hector Zenil
- **Comment**: None
- **Journal**: Visual Cognition 22 (8), 2014, pages 1084-1091
- **Summary**: Humans are sensitive to complexity and regularity in patterns. The subjective perception of pattern complexity is correlated to algorithmic (Kolmogorov-Chaitin) complexity as defined in computer science, but also to the frequency of naturally occurring patterns. However, the possible mediational role of natural frequencies in the perception of algorithmic complexity remains unclear. Here we reanalyze Hsu et al. (2010) through a mediational analysis, and complement their results in a new experiment. We conclude that human perception of complexity seems partly shaped by natural scenes statistics, thereby establishing a link between the perception of complexity and the effect of natural scene statistics.



### Color-Phase Analysis for Sinusoidal Structured Light in Rapid Range Imaging
- **Arxiv ID**: http://arxiv.org/abs/1509.04115v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, physics.optics, I.2.10; I.4.8
- **Links**: [PDF](http://arxiv.org/pdf/1509.04115v1)
- **Published**: 2015-09-14 14:35:20+00:00
- **Updated**: 2015-09-14 14:35:20+00:00
- **Authors**: Changsoo Je, Sang Wook Lee, Rae-Hong Park
- **Comment**: 6 pages, 12 figures. 6th Asian Conference on Computer Vision (ACCV
  2004)
- **Journal**: Proc. 6th Asian Conference on Computer Vision (ACCV 2004), vol. 1,
  pp. 270-275, Jeju Island, Korea, January 27, 2004
- **Summary**: Active range sensing using structured-light is the most accurate and reliable method for obtaining 3D information. However, most of the work has been limited to range sensing of static objects, and range sensing of dynamic (moving or deforming) objects has been investigated recently only by a few researchers. Sinusoidal structured-light is one of the well-known optical methods for 3D measurement. In this paper, we present a novel method for rapid high-resolution range imaging using color sinusoidal pattern. We consider the real-world problem of nonlinearity and color-band crosstalk in the color light projector and color camera, and present methods for accurate recovery of color-phase. For high-resolution ranging, we use high-frequency patterns and describe new unwrapping algorithms for reliable range recovery. The experimental results demonstrate the effectiveness of our methods.



### Expanded Parts Model for Semantic Description of Humans in Still Images
- **Arxiv ID**: http://arxiv.org/abs/1509.04186v2
- **DOI**: 10.1109/TPAMI.2016.2537325
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04186v2)
- **Published**: 2015-09-14 16:33:04+00:00
- **Updated**: 2016-02-25 12:14:05+00:00
- **Authors**: Gaurav Sharma, Frederic Jurie, Cordelia Schmid
- **Comment**: Accepted for publication in IEEE Transactions on Pattern Analysis and
  Machine Intelligence (TPAMI)
- **Journal**: None
- **Summary**: We introduce an Expanded Parts Model (EPM) for recognizing human attributes (e.g. young, short hair, wearing suit) and actions (e.g. running, jumping) in still images. An EPM is a collection of part templates which are learnt discriminatively to explain specific scale-space regions in the images (in human centric coordinates). This is in contrast to current models which consist of a relatively few (i.e. a mixture of) 'average' templates. EPM uses only a subset of the parts to score an image and scores the image sparsely in space, i.e. it ignores redundant and random background in an image. To learn our model, we propose an algorithm which automatically mines parts and learns corresponding discriminative templates together with their respective locations from a large number of candidate parts. We validate our method on three recent challenging datasets of human attributes and actions. We obtain convincing qualitative and state-of-the-art quantitative results on the three datasets.



### Deep Learning Applied to Image and Text Matching
- **Arxiv ID**: http://arxiv.org/abs/1601.03478v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1601.03478v1)
- **Published**: 2015-09-14 17:19:33+00:00
- **Updated**: 2015-09-14 17:19:33+00:00
- **Authors**: Afroze Ibrahim Baqapuri
- **Comment**: None
- **Journal**: None
- **Summary**: The ability to describe images with natural language sentences is the hallmark for image and language understanding. Such a system has wide ranging applications such as annotating images and using natural sentences to search for images.In this project we focus on the task of bidirectional image retrieval: such asystem is capable of retrieving an image based on a sentence (image search) andretrieve sentence based on an image query (image annotation). We present asystem based on a global ranking objective function which uses a combinationof convolutional neural networks (CNN) and multi layer perceptrons (MLP).It takes a pair of image and sentence and processes them in different channels,finally embedding it into a common multimodal vector space. These embeddingsencode abstract semantic information about the two inputs and can be comparedusing traditional information retrieval approaches. For each such pair, the modelreturns a score which is interpretted as a similarity metric. If this score is high,the image and sentence are likely to convey similar meaning, and if the score is low then they are likely not to.   The visual input is modeled via deep convolutional neural network. On theother hand we explore three models for the textual module. The first one isbag of words with an MLP. The second one uses n-grams (bigram, trigrams,and a combination of trigram & skip-grams) with an MLP. The third is morespecialized deep network specific for modeling variable length sequences (SSE).We report comparable performance to recent work in the field, even though ouroverall model is simpler. We also show that the training time choice of how wecan generate our negative samples has a significant impact on performance, and can be used to specialize the bi-directional system in one particular task.



### gSLICr: SLIC superpixels at over 250Hz
- **Arxiv ID**: http://arxiv.org/abs/1509.04232v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04232v1)
- **Published**: 2015-09-14 18:30:05+00:00
- **Updated**: 2015-09-14 18:30:05+00:00
- **Authors**: Carl Yuheng Ren, Victor Adrian Prisacariu, Ian D Reid
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce a parallel GPU implementation of the Simple Linear Iterative Clustering (SLIC) superpixel segmentation. Using a single graphic card, our implementation achieves speedups of up to $83\times$ from the standard sequential implementation. Our implementation is fully compatible with the standard sequential implementation and the software is now available online and is open source.



### Sparse Representation for 3D Shape Estimation: A Convex Relaxation Approach
- **Arxiv ID**: http://arxiv.org/abs/1509.04309v3
- **DOI**: 10.1109/TPAMI.2016.2605097
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04309v3)
- **Published**: 2015-09-14 20:35:11+00:00
- **Updated**: 2017-01-10 19:16:44+00:00
- **Authors**: Xiaowei Zhou, Menglong Zhu, Spyridon Leonardos, Kostas Daniilidis
- **Comment**: Extended version of the paper: 3D Shape Estimation from 2D Landmarks:
  A Convex Relaxation Approach. X. Zhou et al., CVPR, 2015. arXiv admin note:
  substantial text overlap with arXiv:1411.2942
- **Journal**: IEEE Transactions on Pattern Analysis and Machine Intelligence,
  2017
- **Summary**: We investigate the problem of estimating the 3D shape of an object defined by a set of 3D landmarks, given their 2D correspondences in a single image. A successful approach to alleviating the reconstruction ambiguity is the 3D deformable shape model and a sparse representation is often used to capture complex shape variability. But the model inference is still a challenge due to the nonconvexity in optimization resulted from joint estimation of shape and viewpoint. In contrast to prior work that relies on a alternating scheme with solutions depending on initialization, we propose a convex approach to addressing this challenge and develop an efficient algorithm to solve the proposed convex program. Moreover, we propose a robust model to handle gross errors in the 2D correspondences. We demonstrate the exact recovery property of the proposed method, the advantage compared to the nonconvex baseline methods and the applicability to recover 3D human poses and car models from single images.



