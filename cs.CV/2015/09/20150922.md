# Arxiv Papers in cs.CV on 2015-09-22
### From Facial Parts Responses to Face Detection: A Deep Learning Approach
- **Arxiv ID**: http://arxiv.org/abs/1509.06451v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06451v1)
- **Published**: 2015-09-22 02:59:31+00:00
- **Updated**: 2015-09-22 02:59:31+00:00
- **Authors**: Shuo Yang, Ping Luo, Chen Change Loy, Xiaoou Tang
- **Comment**: To appear in ICCV 2015
- **Journal**: None
- **Summary**: In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically, our method achieves a high recall rate of 90.99% on the challenging FDDB benchmark, outperforming the state-of-the-art method by a large margin of 2.91%. Importantly, we consider finding faces from a new perspective through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect faces under severe occlusion and unconstrained pose variation, which are the main difficulty and bottleneck of most existing face detection approaches. We show that despite the use of DCN, our network can achieve practical runtime speed.



### Understand Scene Categories by Objects: A Semantic Regularized Scene Classifier Using Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/1509.06470v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06470v1)
- **Published**: 2015-09-22 05:43:27+00:00
- **Updated**: 2015-09-22 05:43:27+00:00
- **Authors**: Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Scene classification is a fundamental perception task for environmental understanding in today's robotics. In this paper, we have attempted to exploit the use of popular machine learning technique of deep learning to enhance scene understanding, particularly in robotics applications. As scene images have larger diversity than the iconic object images, it is more challenging for deep learning methods to automatically learn features from scene images with less samples. Inspired by human scene understanding based on object knowledge, we address the problem of scene classification by encouraging deep neural networks to incorporate object-level information. This is implemented with a regularization of semantic segmentation. With only 5 thousand training images, as opposed to 2.5 million images, we show the proposed deep architecture achieves superior scene classification results to the state-of-the-art on a publicly available SUN RGB-D dataset. In addition, performance of semantic segmentation, the regularizer, also reaches a new record with refinement derived from predicted scene labels. Finally, we apply our SUN RGB-D dataset trained model to a mobile robot captured images to classify scenes in our university demonstrating the generalization ability of the proposed algorithm.



### Local Multi-Grouped Binary Descriptor with Ring-based Pooling Configuration and Optimization
- **Arxiv ID**: http://arxiv.org/abs/1509.06557v1
- **DOI**: 10.1109/TIP.2015.2469093
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06557v1)
- **Published**: 2015-09-22 11:56:21+00:00
- **Updated**: 2015-09-22 11:56:21+00:00
- **Authors**: Yongqiang Gao, Weilin Huang, Yu Qiao
- **Comment**: To appear in IEEE Trans. on Image Processing, 2015
- **Journal**: None
- **Summary**: Local binary descriptors are attracting increasingly attention due to their great advantages in computational speed, which are able to achieve real-time performance in numerous image/vision applications. Various methods have been proposed to learn data-dependent binary descriptors. However, most existing binary descriptors aim overly at computational simplicity at the expense of significant information loss which causes ambiguity in similarity measure using Hamming distance. In this paper, by considering multiple features might share complementary information, we present a novel local binary descriptor, referred as Ring-based Multi-Grouped Descriptor (RMGD), to successfully bridge the performance gap between current binary and floated-point descriptors. Our contributions are two-fold. Firstly, we introduce a new pooling configuration based on spatial ring-region sampling, allowing for involving binary tests on the full set of pairwise regions with different shapes, scales and distances. This leads to a more meaningful description than existing methods which normally apply a limited set of pooling configurations. Then, an extended Adaboost is proposed for efficient bit selection by emphasizing high variance and low correlation, achieving a highly compact representation. Secondly, the RMGD is computed from multiple image properties where binary strings are extracted. We cast multi-grouped features integration as rankSVM or sparse SVM learning problem, so that different features can compensate strongly for each other, which is the key to discriminativeness and robustness. The performance of RMGD was evaluated on a number of publicly available benchmarks, where the RMGD outperforms the state-of-the-art binary descriptors significantly.



### Homotopy relations for digital images
- **Arxiv ID**: http://arxiv.org/abs/1509.06576v2
- **DOI**: None
- **Categories**: **math.GN**, cs.CV, 55P10, 55Q05, I.4.m
- **Links**: [PDF](http://arxiv.org/pdf/1509.06576v2)
- **Published**: 2015-09-22 12:49:31+00:00
- **Updated**: 2016-08-02 23:13:11+00:00
- **Authors**: Laurence Boxer, P. Christopher Staecker
- **Comment**: 30 pages, some revisions & corrections
- **Journal**: None
- **Summary**: We introduce three generalizations of homotopy equivalence in digital images, to allow us to express whether a finite and an infinite digital image are similar with respect to homotopy.   We show that these three generalizations are not equivalent to ordinary homotopy equivalence, and give several examples. We show that, like homotopy equivalence, our three generalizations imply isomorphism of fundamental groups, and are preserved under wedges and Cartesian products.



### Attribute-Graph: A Graph based approach to Image Ranking
- **Arxiv ID**: http://arxiv.org/abs/1509.06658v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06658v2)
- **Published**: 2015-09-22 16:01:02+00:00
- **Updated**: 2015-10-08 04:38:36+00:00
- **Authors**: Nikita Prabhu, R. Venkatesh Babu
- **Comment**: In IEEE International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: We propose a novel image representation, termed Attribute-Graph, to rank images by their semantic similarity to a given query image. An Attribute-Graph is an undirected fully connected graph, incorporating both local and global image characteristics. The graph nodes characterise objects as well as the overall scene context using mid-level semantic attributes, while the edges capture the object topology. We demonstrate the effectiveness of Attribute-Graphs by applying them to the problem of image ranking. We benchmark the performance of our algorithm on the 'rPascal' and 'rImageNet' datasets, which we have created in order to evaluate the ranking performance on complex queries containing multiple objects. Our experimental evaluation shows that modelling images as Attribute-Graphs results in improved ranking performance over existing techniques.



### Invariants of objects and their images under surjective maps
- **Arxiv ID**: http://arxiv.org/abs/1509.06690v1
- **DOI**: 10.1134/S1995080215030063
- **Categories**: **math.DG**, cs.CV, 53A55, 14L24, 14H50, 68T45, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1509.06690v1)
- **Published**: 2015-09-22 17:19:52+00:00
- **Updated**: 2015-09-22 17:19:52+00:00
- **Authors**: Irina A. Kogan, Peter J. Olver
- **Comment**: This paper includes corrections and additions to the published
  version
- **Journal**: Lobachevskii J. Math. 36 (2015), 260--285
- **Summary**: We examine the relationships between the differential invariants of objects and of their images under a surjective map. We analyze both the case when the underlying transformation group is projectable and hence induces an action on the image, and the case when only a proper subgroup of the entire group acts projectably. In the former case, we establish a constructible isomorphism between the algebra of differential invariants of the images and the algebra of fiber-wise constant (gauge) differential invariants of the objects. In the latter case, we describe residual effects of the full transformation group on the image invariants. Our motivation comes from the problem of reconstruction of an object from multiple-view images, with central and parallel projections of curves from three-dimensional space to the two-dimensional plane serving as our main examples.



### A Dual-Source Approach for 3D Pose Estimation from a Single Image
- **Arxiv ID**: http://arxiv.org/abs/1509.06720v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06720v2)
- **Published**: 2015-09-22 18:38:16+00:00
- **Updated**: 2016-03-27 11:43:06+00:00
- **Authors**: Hashim Yasin, Umar Iqbal, Björn Krüger, Andreas Weber, Juergen Gall
- **Comment**: Accepted to CVPR 2016. The source code and models are publicly
  available. Title changed from the previous version
- **Journal**: None
- **Summary**: One major challenge for 3D pose estimation from a single RGB image is the acquisition of sufficient training data. In particular, collecting large amounts of training data that contain unconstrained images and are annotated with accurate 3D poses is infeasible. We therefore propose to use two independent training sources. The first source consists of images with annotated 2D poses and the second source consists of accurate 3D motion capture data. To integrate both sources, we propose a dual-source approach that combines 2D pose estimation with efficient and robust 3D pose retrieval. In our experiments, we show that our approach achieves state-of-the-art results and is even competitive when the skeleton structure of the two sources differ substantially.



### Algebraic Clustering of Affine Subspaces
- **Arxiv ID**: http://arxiv.org/abs/1509.06729v3
- **DOI**: 10.1109/TPAMI.2017.2678477
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.06729v3)
- **Published**: 2015-09-22 19:04:00+00:00
- **Updated**: 2017-03-08 18:04:32+00:00
- **Authors**: Manolis C. Tsakiris, Rene Vidal
- **Comment**: None
- **Journal**: IEEE Transactions on Pattern Analysis and Machine Intelligence (
  Volume: 40 , Issue: 2 , Feb. 1 2018 )
- **Summary**: Subspace clustering is an important problem in machine learning with many applications in computer vision and pattern recognition. Prior work has studied this problem using algebraic, iterative, statistical, low-rank and sparse representation techniques. While these methods have been applied to both linear and affine subspaces, theoretical results have only been established in the case of linear subspaces. For example, algebraic subspace clustering (ASC) is guaranteed to provide the correct clustering when the data points are in general position and the union of subspaces is transversal. In this paper we study in a rigorous fashion the properties of ASC in the case of affine subspaces. Using notions from algebraic geometry, we prove that the homogenization trick, which embeds points in a union of affine subspaces into points in a union of linear subspaces, preserves the general position of the points and the transversality of the union of subspaces in the embedded space, thus establishing the correctness of ASC for affine subpaces.



