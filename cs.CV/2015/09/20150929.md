# Arxiv Papers in cs.CV on 2015-09-29
### Long-Range Trajectories from Global and Local Motion Representations
- **Arxiv ID**: http://arxiv.org/abs/1509.08647v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08647v1)
- **Published**: 2015-09-29 09:02:57+00:00
- **Updated**: 2015-09-29 09:02:57+00:00
- **Authors**: Eduardo M. Pereira, Jaime S. Cardoso, Ricardo Morla
- **Comment**: None
- **Journal**: None
- **Summary**: Motion is a fundamental cue for scene analysis and human activity understan- ding in videos. It can be encoded in trajectories for tracking objects and for action recognition, or in form of flow to address behaviour analysis in crowded scenes. Each approach can only be applied on limited scenarios. We propose a motion-based system that represents the spatial and temporal features of the flow in terms of long-range trajectories. The novelty resides on the system formulation, its generic approach to handle scene variability and motion variations, motion integration from local and global representations, and the resulting long-range trajectories that overcome trajectory-based approach problems. We report the results and conclusions that state its pertinence on different scenarios, comparing and correlating the extracted trajectories of individual pedestrians, manually annotated. We also propose an evaluation framework and stress the diverse system characteristics that can be used for human activity tasks, namely on motion segmentation.



### Retinex filtering of foggy images: generation of a bulk set with selection and ranking
- **Arxiv ID**: http://arxiv.org/abs/1509.08715v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08715v1)
- **Published**: 2015-09-29 12:26:08+00:00
- **Updated**: 2015-09-29 12:26:08+00:00
- **Authors**: Roberto Marazzato, Amelia Carolina Sparavigna
- **Comment**: Keywords: GIMP Retinex, GIMP, Image processing, Bulk generation of
  images, Bulk manipulation of images
- **Journal**: None
- **Summary**: In this paper we are proposing the use of GIMP Retinex, a filter of the GNU Image Manipulation Program, for enhancing foggy images. This filter involves adjusting four different parameters to find the output image which has to be preferred according to some specific purposes. Aiming to obtain a processing, which is able of choosing automatically the best image from a given set, we are proposing a method for the generation a bulk set of GIMP Retinex filtered images and a preliminary approach for selecting and ranking them.



### Compression of Deep Neural Networks on the Fly
- **Arxiv ID**: http://arxiv.org/abs/1509.08745v5
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/1509.08745v5)
- **Published**: 2015-09-29 13:32:30+00:00
- **Updated**: 2016-03-18 09:33:01+00:00
- **Authors**: Guillaume Soulié, Vincent Gripon, Maëlys Robert
- **Comment**: None
- **Journal**: None
- **Summary**: Thanks to their state-of-the-art performance, deep neural networks are increasingly used for object recognition. To achieve these results, they use millions of parameters to be trained. However, when targeting embedded applications the size of these models becomes problematic. As a consequence, their usage on smartphones or other resource limited devices is prohibited. In this paper we introduce a novel compression method for deep neural networks that is performed during the learning phase. It consists in adding an extra regularization term to the cost function of fully-connected layers. We combine this method with Product Quantization (PQ) of the trained weights for higher savings in storage consumption. We evaluate our method on two data sets (MNIST and CIFAR10), on which we achieve significantly larger compression rates than state-of-the-art methods.



### Scalable Nonlinear Embeddings for Semantic Category-based Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/1509.08902v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08902v1)
- **Published**: 2015-09-29 19:41:33+00:00
- **Updated**: 2015-09-29 19:41:33+00:00
- **Authors**: Gaurav Sharma, Bernt Schiele
- **Comment**: ICCV 2015 preprint
- **Journal**: None
- **Summary**: We propose a novel algorithm for the task of supervised discriminative distance learning by nonlinearly embedding vectors into a low dimensional Euclidean space. We work in the challenging setting where supervision is with constraints on similar and dissimilar pairs while training. The proposed method is derived by an approximate kernelization of a linear Mahalanobis-like distance metric learning algorithm and can also be seen as a kernel neural network. The number of model parameters and test time evaluation complexity of the proposed method are O(dD) where D is the dimensionality of the input features and d is the dimension of the projection space - this is in contrast to the usual kernelization methods as, unlike them, the complexity does not scale linearly with the number of training examples. We propose a stochastic gradient based learning algorithm which makes the method scalable (w.r.t. the number of training examples), while being nonlinear. We train the method with up to half a million training pairs of 4096 dimensional CNN features. We give empirical comparisons with relevant baselines on seven challenging datasets for the task of low dimensional semantic category based image retrieval.



### Light Field Reconstruction Using Shearlet Transform
- **Arxiv ID**: http://arxiv.org/abs/1509.08969v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08969v1)
- **Published**: 2015-09-29 22:37:21+00:00
- **Updated**: 2015-09-29 22:37:21+00:00
- **Authors**: Suren Vagharshakyan, Robert Bregovic, Atanas Gotchev
- **Comment**: 12 pages, 11 figures
- **Journal**: None
- **Summary**: In this article we develop an image based rendering technique based on light field reconstruction from a limited set of perspective views acquired by cameras. Our approach utilizes sparse representation of epipolar-plane images in a directionally sensitive transform domain, obtained by an adapted discrete shearlet transform. The used iterative thresholding algorithm provides high-quality reconstruction results for relatively big disparities between neighboring views. The generated densely sampled light field of a given 3D scene is thus suitable for all applications which requires light field reconstruction. The proposed algorithm is compared favorably against state of the art depth image based rendering techniques.



### Energy-Efficient Object Detection using Semantic Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1509.08970v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08970v3)
- **Published**: 2015-09-29 22:56:33+00:00
- **Updated**: 2016-09-20 14:38:32+00:00
- **Authors**: Priyadarshini Panda, Swagath Venkataramani, Abhronil Sengupta, Anand Raghunathan, Kaushik Roy
- **Comment**: 10 pages, 13 figures, 3 algorithms, Submitted to IEEE TVLSI(Under
  Review)
- **Journal**: None
- **Summary**: Machine-learning algorithms offer immense possibilities in the development of several cognitive applications. In fact, large scale machine-learning classifiers now represent the state-of-the-art in a wide range of object detection/classification problems. However, the network complexities of large-scale classifiers present them as one of the most challenging and energy intensive workloads across the computing spectrum. In this paper, we present a new approach to optimize energy efficiency of object detection tasks using semantic decomposition to build a hierarchical classification framework. We observe that certain semantic information like color/texture are common across various images in real-world datasets for object detection applications. We exploit these common semantic features to distinguish the objects of interest from the remaining inputs (non-objects of interest) in a dataset at a lower computational effort. We propose a 2-stage hierarchical classification framework, with increasing levels of complexity, wherein the first stage is trained to recognize the broad representative semantic features relevant to the object of interest. The first stage rejects the input instances that do not have the representative features and passes only the relevant instances to the second stage. Our methodology thus allows us to reject certain information at lower complexity and utilize the full computational effort of a network only on a smaller fraction of inputs to perform detection. We use color and texture as distinctive traits to carry out several experiments for object detection. Our experiments on the Caltech101/CIFAR10 dataset show that the proposed method yields 1.93x/1.46x improvement in average energy, respectively, over the traditional single classifier model.



### Conditional Deep Learning for Energy-Efficient and Enhanced Pattern Recognition
- **Arxiv ID**: http://arxiv.org/abs/1509.08971v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.08971v6)
- **Published**: 2015-09-29 23:08:09+00:00
- **Updated**: 2016-01-28 18:34:42+00:00
- **Authors**: Priyadarshini Panda, Abhronil Sengupta, Kaushik Roy
- **Comment**: 6 pages, 10 figures, 2 algorithms < Accepted for Design and
  Automation Test in Europe (DATE) conference, 2016>
- **Journal**: None
- **Summary**: Deep learning neural networks have emerged as one of the most powerful classification tools for vision related applications. However, the computational and energy requirements associated with such deep nets can be quite high, and hence their energy-efficient implementation is of great interest. Although traditionally the entire network is utilized for the recognition of all inputs, we observe that the classification difficulty varies widely across inputs in real-world datasets; only a small fraction of inputs require the full computational effort of a network, while a large majority can be classified correctly with very low effort. In this paper, we propose Conditional Deep Learning (CDL) where the convolutional layer features are used to identify the variability in the difficulty of input instances and conditionally activate the deeper layers of the network. We achieve this by cascading a linear network of output neurons for each convolutional layer and monitoring the output of the linear network to decide whether classification can be terminated at the current stage or not. The proposed methodology thus enables the network to dynamically adjust the computational effort depending upon the difficulty of the input data while maintaining competitive classification accuracy. We evaluate our approach on the MNIST dataset. Our experiments demonstrate that our proposed CDL yields 1.91x reduction in average number of operations per input, which translates to 1.84x improvement in energy. In addition, our results show an improvement in classification accuracy from 97.5% to 98.9% as compared to the original network.



### Symbol Emergence in Robotics: A Survey
- **Arxiv ID**: http://arxiv.org/abs/1509.08973v1
- **DOI**: 10.1080/01691864.2016.1164622
- **Categories**: **cs.AI**, cs.CL, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1509.08973v1)
- **Published**: 2015-09-29 23:16:48+00:00
- **Updated**: 2015-09-29 23:16:48+00:00
- **Authors**: Tadahiro Taniguchi, Takayuki Nagai, Tomoaki Nakamura, Naoto Iwahashi, Tetsuya Ogata, Hideki Asoh
- **Comment**: submitted to Advanced Robotics
- **Journal**: Advanced Robotics, 30:11-12, 706-728, 2016
- **Summary**: Humans can learn the use of language through physical interaction with their environment and semiotic communication with other people. It is very important to obtain a computational understanding of how humans can form a symbol system and obtain semiotic skills through their autonomous mental development. Recently, many studies have been conducted on the construction of robotic systems and machine-learning methods that can learn the use of language through embodied multimodal interaction with their environment and other systems. Understanding human social interactions and developing a robot that can smoothly communicate with human users in the long term, requires an understanding of the dynamics of symbol systems and is crucially important. The embodied cognition and social interaction of participants gradually change a symbol system in a constructive manner. In this paper, we introduce a field of research called symbol emergence in robotics (SER). SER is a constructive approach towards an emergent symbol system. The emergent symbol system is socially self-organized through both semiotic communications and physical interactions with autonomous cognitive developmental agents, i.e., humans and developmental robots. Specifically, we describe some state-of-art research topics concerning SER, e.g., multimodal categorization, word discovery, and a double articulation analysis, that enable a robot to obtain words and their embodied meanings from raw sensory--motor information, including visual information, haptic information, auditory information, and acoustic speech signals, in a totally unsupervised manner. Finally, we suggest future directions of research in SER.



