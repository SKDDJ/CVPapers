# Arxiv Papers in cs.CV on 2015-09-19
### Similar Handwritten Chinese Character Discrimination by Weakly Supervised Learning
- **Arxiv ID**: http://arxiv.org/abs/1509.05844v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.05844v1)
- **Published**: 2015-09-19 03:08:42+00:00
- **Updated**: 2015-09-19 03:08:42+00:00
- **Authors**: Zhibo Yang, Huanle Xu, Keda Fu, Yong Xia
- **Comment**: 5 figures, 8 pages
- **Journal**: None
- **Summary**: Traditional approaches for handwritten Chinese character recognition suffer in classifying similar characters. In this paper, we propose to discriminate similar handwritten Chinese characters by using weakly supervised learning. Our approach learns a discriminative SVM for each similar pair which simultaneously localizes the discriminative region of similar character and makes the classification. For the first time, similar handwritten Chinese character recognition (SHCCR) is formulated as an optimization problem extended from SVM. We also propose a novel feature descriptor, Gradient Context, and apply bag-of-words model to represent regions with different scales. In our method, we do not need to select a sized-fixed sub-window to differentiate similar characters. The unconstrained property makes our method well adapted to high variance in the size and position of discriminative regions in similar handwritten Chinese characters. We evaluate our proposed approach over the CASIA Chinese character data set and the results show that our method outperforms the state of the art.



### Face Photo Sketch Synthesis via Larger Patch and Multiresolution Spline
- **Arxiv ID**: http://arxiv.org/abs/1509.05897v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.05897v1)
- **Published**: 2015-09-19 14:20:50+00:00
- **Updated**: 2015-09-19 14:20:50+00:00
- **Authors**: Xu Yang
- **Comment**: None
- **Journal**: None
- **Summary**: Face photo sketch synthesis has got some researchers' attention in recent years because of its potential applications in digital entertainment and law enforcement. Some patches based methods have been proposed to solve this problem. These methods usually focus more on how to get a sketch patch for a given photo patch than how to blend these generated patches. However, without appropriately blending method, some jagged parts and mottled points will appear in the entire face sketch. In order to get a smoother sketch, we propose a new method to reduce such jagged parts and mottled points. In our system, we resort to an existed method, which is Markov Random Fields (MRF), to train a crude face sketch firstly. Then this crude sketch face sketch will be divided into some larger patches again and retrained by Non-Negative Matrix Factorization (NMF). At last, we use Multiresolution Spline and a blend trick named full-coverage trick to blend these retrained patches. The experiment results show that compared with some previous method, we can get a smoother face sketch.



### Modelling Uncertainty in Deep Learning for Camera Relocalization
- **Arxiv ID**: http://arxiv.org/abs/1509.05909v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1509.05909v2)
- **Published**: 2015-09-19 16:01:05+00:00
- **Updated**: 2016-02-18 13:30:25+00:00
- **Authors**: Alex Kendall, Roberto Cipolla
- **Comment**: ICRA 2016; Fixed numerical error with rotation results
- **Journal**: None
- **Summary**: We present a robust and real-time monocular six degree of freedom visual relocalization system. We use a Bayesian convolutional neural network to regress the 6-DOF camera pose from a single RGB image. It is trained in an end-to-end manner with no need of additional engineering or graph optimisation. The algorithm can operate indoors and outdoors in real time, taking under 6ms to compute. It obtains approximately 2m and 6 degrees accuracy for very large scale outdoor scenes and 0.5m and 10 degrees accuracy indoors. Using a Bayesian convolutional neural network implementation we obtain an estimate of the model's relocalization uncertainty and improve state of the art localization accuracy on a large scale outdoor dataset. We leverage the uncertainty measure to estimate metric relocalization error and to detect the presence or absence of the scene in the input image. We show that the model's uncertainty is caused by images being dissimilar to the training dataset in either pose or appearance.



