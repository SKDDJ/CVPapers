# Arxiv Papers in cs.CV on 2015-09-15
### Analyzing structural characteristics of object category representations from their semantic-part distributions
- **Arxiv ID**: http://arxiv.org/abs/1509.04399v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04399v1)
- **Published**: 2015-09-15 04:58:03+00:00
- **Updated**: 2015-09-15 04:58:03+00:00
- **Authors**: Ravi Kiran Sarvadevabhatla, Venkatesh Babu R
- **Comment**: None
- **Journal**: None
- **Summary**: Studies from neuroscience show that part-mapping computations are employed by human visual system in the process of object recognition. In this work, we present an approach for analyzing semantic-part characteristics of object category representations. For our experiments, we use category-epitome, a recently proposed sketch-based spatial representation for objects. To enable part-importance analysis, we first obtain semantic-part annotations of hand-drawn sketches originally used to construct the corresponding epitomes. We then examine the extent to which the semantic-parts are present in the epitomes of a category and visualize the relative importance of parts as a word cloud. Finally, we show how such word cloud visualizations provide an intuitive understanding of category-level structural trends that exist in the category-epitome object representations.



### Neuron detection in stack images: a persistent homology interpretation
- **Arxiv ID**: http://arxiv.org/abs/1509.04420v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/1509.04420v1)
- **Published**: 2015-09-15 07:06:32+00:00
- **Updated**: 2015-09-15 07:06:32+00:00
- **Authors**: Jónathan Heras, Gadea Mata, Germán Cuesto, Julio Rubio, Miguel Morales
- **Comment**: None
- **Journal**: None
- **Summary**: Automation and reliability are the two main requirements when computers are applied in Life Sciences. In this paper we report on an application to neuron recognition, an important step in our long-term project of providing software systems to the study of neural morphology and functionality from biomedical images. Our algorithms have been implemented in an ImageJ plugin called NeuronPersistentJ, which has been validated experimentally. The soundness and reliability of our approach are based on the interpretation of our processing methods with respect to persistent homology, a well-known tool in computational mathematics.



### A Low Complexity VLSI Architecture for Multi-Focus Image Fusion in DCT Domain
- **Arxiv ID**: http://arxiv.org/abs/1602.07620v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1602.07620v1)
- **Published**: 2015-09-15 13:25:30+00:00
- **Updated**: 2015-09-15 13:25:30+00:00
- **Authors**: Ashutosh Mishra, Sudipta Mahapatra, Swapna Banerjee
- **Comment**: Submitting to journal
- **Journal**: None
- **Summary**: Due to the confined focal length of optical sensors, focusing all objects in a scene with a single sensor is a difficult task. To handle such a situation, image fusion methods are used in multi-focus environment. Discrete Cosine Transform (DCT) is a widely used image compression transform, image fusion in DCT domain is an efficient method. This paper presents a low complexity approach for multi-focus image fusion and its VLSI implementation using DCT. The proposed method is evaluated using reference/non-reference fusion measure criteria and the obtained results asserts it's effectiveness. The maximum synthesized frequency on FPGA is found to be 221 MHz and consumes 42% of FPGA resources. The proposed method consumes very less power and can process 4K resolution images at the rate of 60 frames per second which makes the hardware suitable for handheld portable devices such as camera module and wireless image sensors.



### Kernelized Deep Convolutional Neural Network for Describing Complex Images
- **Arxiv ID**: http://arxiv.org/abs/1509.04581v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.IR, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1509.04581v1)
- **Published**: 2015-09-15 14:35:11+00:00
- **Updated**: 2015-09-15 14:35:11+00:00
- **Authors**: Zhen Liu
- **Comment**: 9 pages
- **Journal**: None
- **Summary**: With the impressive capability to capture visual content, deep convolutional neural networks (CNN) have demon- strated promising performance in various vision-based ap- plications, such as classification, recognition, and objec- t detection. However, due to the intrinsic structure design of CNN, for images with complex content, it achieves lim- ited capability on invariance to translation, rotation, and re-sizing changes, which is strongly emphasized in the s- cenario of content-based image retrieval. In this paper, to address this problem, we proposed a new kernelized deep convolutional neural network. We first discuss our motiva- tion by an experimental study to demonstrate the sensitivi- ty of the global CNN feature to the basic geometric trans- formations. Then, we propose to represent visual content with approximate invariance to the above geometric trans- formations from a kernelized perspective. We extract CNN features on the detected object-like patches and aggregate these patch-level CNN features to form a vectorial repre- sentation with the Fisher vector model. The effectiveness of our proposed algorithm is demonstrated on image search application with three benchmark datasets.



### Adapting Resilient Propagation for Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/1509.04612v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1509.04612v2)
- **Published**: 2015-09-15 15:55:29+00:00
- **Updated**: 2015-09-16 11:45:48+00:00
- **Authors**: Alan Mosca, George D. Magoulas
- **Comment**: Published in the proceedings of the UK workshop on Computational
  Intelligence 2015 (UKCI)
- **Journal**: None
- **Summary**: The Resilient Propagation (Rprop) algorithm has been very popular for backpropagation training of multilayer feed-forward neural networks in various applications. The standard Rprop however encounters difficulties in the context of deep neural networks as typically happens with gradient-based learning algorithms. In this paper, we propose a modification of the Rprop that combines standard Rprop steps with a special drop out technique. We apply the method for training Deep Neural Networks as standalone components and in ensemble formulations. Results on the MNIST dataset show that the proposed modification alleviates standard Rprop's problems demonstrating improved learning speed and accuracy.



### Medical Image Classification via SVM using LBP Features from Saliency-Based Folded Data
- **Arxiv ID**: http://arxiv.org/abs/1509.04619v1
- **DOI**: 10.1109/ICMLA.2015.131
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04619v1)
- **Published**: 2015-09-15 16:08:08+00:00
- **Updated**: 2015-09-15 16:08:08+00:00
- **Authors**: Zehra Camlica, H. R. Tizhoosh, Farzad Khalvati
- **Comment**: To appear in proceedings of The 14th International Conference on
  Machine Learning and Applications (IEEE ICMLA 2015), Miami, Florida, USA,
  2015
- **Journal**: None
- **Summary**: Good results on image classification and retrieval using support vector machines (SVM) with local binary patterns (LBPs) as features have been extensively reported in the literature where an entire image is retrieved or classified. In contrast, in medical imaging, not all parts of the image may be equally significant or relevant to the image retrieval application at hand. For instance, in lung x-ray image, the lung region may contain a tumour, hence being highly significant whereas the surrounding area does not contain significant information from medical diagnosis perspective. In this paper, we propose to detect salient regions of images during training and fold the data to reduce the effect of irrelevant regions. As a result, smaller image areas will be used for LBP features calculation and consequently classification by SVM. We use IRMA 2009 dataset with 14,410 x-ray images to verify the performance of the proposed approach. The results demonstrate the benefits of saliency-based folding approach that delivers comparable classification accuracies with state-of-the-art but exhibits lower computational cost and storage requirements, factors highly important for big data analytics.



### Comparative Design Space Exploration of Dense and Semi-Dense SLAM
- **Arxiv ID**: http://arxiv.org/abs/1509.04648v3
- **DOI**: 10.1109/ICRA.2016.7487261
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1509.04648v3)
- **Published**: 2015-09-15 17:12:13+00:00
- **Updated**: 2016-03-03 18:19:22+00:00
- **Authors**: M. Zeeshan Zia, Luigi Nardi, Andrew Jack, Emanuele Vespa, Bruno Bodin, Paul H. J. Kelly, Andrew J. Davison
- **Comment**: IEEE International Conference on Robotics and Automation 2016
- **Journal**: None
- **Summary**: SLAM has matured significantly over the past few years, and is beginning to appear in serious commercial products. While new SLAM systems are being proposed at every conference, evaluation is often restricted to qualitative visualizations or accuracy estimation against a ground truth. This is due to the lack of benchmarking methodologies which can holistically and quantitatively evaluate these systems. Further investigation at the level of individual kernels and parameter spaces of SLAM pipelines is non-existent, which is absolutely essential for systems research and integration. We extend the recently introduced SLAMBench framework to allow comparing two state-of-the-art SLAM pipelines, namely KinectFusion and LSD-SLAM, along the metrics of accuracy, energy consumption, and processing frame rate on two different hardware platforms, namely a desktop and an embedded device. We also analyze the pipelines at the level of individual kernels and explore their algorithmic and hardware design spaces for the first time, yielding valuable insights.



### Self-Configuring and Evolving Fuzzy Image Thresholding
- **Arxiv ID**: http://arxiv.org/abs/1509.04664v1
- **DOI**: 10.1109/ICMLA.2015.130
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.04664v1)
- **Published**: 2015-09-15 18:19:02+00:00
- **Updated**: 2015-09-15 18:19:02+00:00
- **Authors**: A. Othman, H. R. Tizhoosh, F. Khalvati
- **Comment**: To appear in proceedings of The 14th International Conference on
  Machine Learning and Applications (IEEE ICMLA 2015), Miami, Florida, USA,
  2015
- **Journal**: None
- **Summary**: Every segmentation algorithm has parameters that need to be adjusted in order to achieve good results. Evolving fuzzy systems for adjustment of segmentation parameters have been proposed recently (Evolving fuzzy image segmentation -- EFIS [1]. However, similar to any other algorithm, EFIS too suffers from a few limitations when used in practice. As a major drawback, EFIS depends on detection of the object of interest for feature calculation, a task that is highly application-dependent. In this paper, a new version of EFIS is proposed to overcome these limitations. The new EFIS, called self-configuring EFIS (SC-EFIS), uses available training data to auto-configure the parameters that are fixed in EFIS. As well, the proposed SC-EFIS relies on a feature selection process that does not require the detection of a region of interest (ROI).



### Direct high-order edge-preserving regularization for tomographic image reconstruction
- **Arxiv ID**: http://arxiv.org/abs/1509.04706v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MS, cs.NA, math.NA
- **Links**: [PDF](http://arxiv.org/pdf/1509.04706v1)
- **Published**: 2015-09-15 18:23:56+00:00
- **Updated**: 2015-09-15 18:23:56+00:00
- **Authors**: Daniil Kazantsev, Evgueni Ovtchinnikov, William R. B. Lionheart, Philip J. Withers, Peter D. Lee
- **Comment**: 16 pages, 11 figures
- **Journal**: None
- **Summary**: In this paper we present a new two-level iterative algorithm for tomographic image reconstruction. The algorithm uses a regularization technique, which we call edge-preserving Laplacian, that preserves sharp edges between objects while damping spurious oscillations in the areas where the reconstructed image is smooth. Our numerical simulations demonstrate that the proposed method outperforms total variation (TV) regularization and it is competitive with the combined TV-L2 penalty. Obtained reconstructed images show increased signal-to-noise ratio and visually appealing structural features. Computer implementation and parameter control of the proposed technique is straightforward, which increases the feasibility of it across many tomographic applications. In this paper, we applied our method to the under-sampled computed tomography (CT) projection data and also considered a case of reconstruction in emission tomography The MATLAB code is provided to support obtained results.



### Free-body Gesture Tracking and Augmented Reality Improvisation for Floor and Aerial Dance
- **Arxiv ID**: http://arxiv.org/abs/1509.04751v1
- **DOI**: None
- **Categories**: **cs.MM**, cs.CV, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1509.04751v1)
- **Published**: 2015-09-15 21:54:21+00:00
- **Updated**: 2015-09-15 21:54:21+00:00
- **Authors**: Tammuz Dubnov, Cheng-i Wang
- **Comment**: 8 pages. Technical paper
- **Journal**: None
- **Summary**: This paper describes an updated interactive performance system for floor and Aerial Dance that controls visual and sonic aspects of the presentation via a depth sensing camera (MS Kinect). In order to detect, measure and track free movement in space, 3 degree of freedom (3-DOF) tracking in space (on the ground and in the air) is performed using IR markers with a method for multi target tracking capabilities added and described in detail. An improved gesture tracking and recognition system, called Action Graph (AG), is described in the paper. Action Graph uses an efficient incremental construction from a single long sequence of movement features and automatically captures repeated sub-segments in the movement from start to finish with no manual interaction needed with other advanced capabilities discussed as well. By using the new model for the gesture we can unify an entire choreography piece by dynamically tracking and recognizing gestures and sub-portions of the piece. This gives the performer the freedom to improvise based on a set of recorded gestures/portions of the choreography and have the system dynamically respond in relation to the performer within a set of related rehearsed actions, an ability that has not been seen in any other system to date.



### Zero-Shot Learning via Semantic Similarity Embedding
- **Arxiv ID**: http://arxiv.org/abs/1509.04767v2
- **DOI**: None
- **Categories**: **cs.CV**, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1509.04767v2)
- **Published**: 2015-09-15 23:18:52+00:00
- **Updated**: 2015-09-25 20:26:08+00:00
- **Authors**: Ziming Zhang, Venkatesh Saligrama
- **Comment**: accepted for ICCV 2015
- **Journal**: None
- **Summary**: In this paper we consider a version of the zero-shot learning problem where seen class source and target domain data are provided. The goal during test-time is to accurately predict the class label of an unseen target domain instance based on revealed source domain side information (\eg attributes) for unseen classes. Our method is based on viewing each source or target data as a mixture of seen class proportions and we postulate that the mixture patterns have to be similar if the two instances belong to the same unseen class. This perspective leads us to learning source/target embedding functions that map an arbitrary source/target domain data into a same semantic space where similarity can be readily measured. We develop a max-margin framework to learn these similarity functions and jointly optimize parameters by means of cross validation. Our test results are compelling, leading to significant improvement in terms of accuracy on most benchmark datasets for zero-shot recognition.



