# Arxiv Papers in cs.CV on 2015-09-30
### Stats-Calculus Pose Descriptor Feeding A Discrete HMM Low-latency Detection and Recognition System For 3D Skeletal Actions
- **Arxiv ID**: http://arxiv.org/abs/1509.09014v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.09014v4)
- **Published**: 2015-09-30 05:02:52+00:00
- **Updated**: 2015-10-16 19:53:00+00:00
- **Authors**: Rofael Emil Fayez Behnam
- **Comment**: None
- **Journal**: None
- **Summary**: Recognition of human actions, under low observational latency, is a growing interest topic, nowadays. Many approaches have been represented based on a provided set of 3D Cartesian coordinates system originated at a certain specific point located on a root joint. In this paper, We will present a statistical detection and recognition system using Hidden Markov Model using 7 types of pose descriptors. * Cartesian Calculus Pose descriptor. * Angular Calculus Pose descriptor. * Mixed-mode Stats-Calculus Pose descriptor. * Centro-Stats-Calculus Pose descriptor. * Rela-Centro-Stats-Calculus Pose descriptor. * Rela-Centro-Stats-Calculus DCT Pose descriptor. * Rela-Centro-Stats-Calculus DCT-AMDF Pose descriptor. Stats-Calculus is a feature extracting technique, that is developed on Moving Pose descriptor , but using a combination of Statistics measures and Calculus measures.



### Moving Object Detection in Video Using Saliency Map and Subspace Learning
- **Arxiv ID**: http://arxiv.org/abs/1509.09089v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.09089v1)
- **Published**: 2015-09-30 09:13:20+00:00
- **Updated**: 2015-09-30 09:13:20+00:00
- **Authors**: Yanwei Pang, Li Ye, Xuelong Li, Jing Pan
- **Comment**: None
- **Journal**: None
- **Summary**: Moving object detection is a key to intelligent video analysis. On the one hand, what moves is not only interesting objects but also noise and cluttered background. On the other hand, moving objects without rich texture are prone not to be detected. So there are undesirable false alarms and missed alarms in many algorithms of moving object detection. To reduce the false alarms and missed alarms, in this paper, we propose to incorporate a saliency map into an incremental subspace analysis framework where the saliency map makes estimated background has less chance than foreground (i.e., moving objects) to contain salient objects. The proposed objective function systematically takes account into the properties of sparsity, low-rank, connectivity, and saliency. An alternative minimization algorithm is proposed to seek the optimal solutions. Experimental results on the Perception Test Images Sequences demonstrate that the proposed method is effective in reducing false alarms and missed alarms.



### Online Object Tracking with Proposal Selection
- **Arxiv ID**: http://arxiv.org/abs/1509.09114v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.09114v1)
- **Published**: 2015-09-30 10:38:27+00:00
- **Updated**: 2015-09-30 10:38:27+00:00
- **Authors**: Yang Hua, Karteek Alahari, Cordelia Schmid
- **Comment**: ICCV 2015
- **Journal**: None
- **Summary**: Tracking-by-detection approaches are some of the most successful object trackers in recent years. Their success is largely determined by the detector model they learn initially and then update over time. However, under challenging conditions where an object can undergo transformations, e.g., severe rotation, these methods are found to be lacking. In this paper, we address this problem by formulating it as a proposal selection task and making two contributions. The first one is introducing novel proposals estimated from the geometric transformations undergone by the object, and building a rich candidate set for predicting the object location. The second one is devising a novel selection strategy using multiple cues, i.e., detection score and edgeness score computed from state-of-the-art object edges and motion boundaries. We extensively evaluate our approach on the visual object tracking 2014 challenge and online tracking benchmark datasets, and show the best performance.



### A spatial compositional model (SCM) for linear unmixing and endmember uncertainty estimation
- **Arxiv ID**: http://arxiv.org/abs/1509.09243v1
- **DOI**: 10.1109/TIP.2016.2618002
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.09243v1)
- **Published**: 2015-09-30 16:24:45+00:00
- **Updated**: 2015-09-30 16:24:45+00:00
- **Authors**: Yuan Zhou, Anand Rangarajan, Paul Gader
- **Comment**: None
- **Journal**: None
- **Summary**: The normal compositional model (NCM) has been extensively used in hyperspectral unmixing. However, most of the previous research has focused on estimation of endmembers and/or their variability. Also, little work has employed spatial information in NCM. In this paper, we show that NCM can be used for calculating the uncertainty of the estimated endmembers with spatial priors incorporated for better unmixing. This results in a spatial compositional model (SCM) which features (i) spatial priors that force neighboring abundances to be similar based on their pixel similarity and (ii) a posterior that is obtained from a likelihood model which does not assume pixel independence. The resulting algorithm turns out to be easy to implement and efficient to run. We compared SCM with current state-of-the-art algorithms on synthetic and real images. The results show that SCM can in the main provide more accurate endmembers and abundances. Moreover, the estimated uncertainty can serve as a prediction of endmember error under certain conditions.



### General Dynamic Scene Reconstruction from Multiple View Video
- **Arxiv ID**: http://arxiv.org/abs/1509.09294v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1509.09294v1)
- **Published**: 2015-09-30 18:37:24+00:00
- **Updated**: 2015-09-30 18:37:24+00:00
- **Authors**: Armin Mustafa, Hansung Kim, Jean-Yves Guillemaut, Adrian Hilton
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces a general approach to dynamic scene reconstruction from multiple moving cameras without prior knowledge or limiting constraints on the scene structure, appearance, or illumination. Existing techniques for dynamic scene reconstruction from multiple wide-baseline camera views primarily focus on accurate reconstruction in controlled environments, where the cameras are fixed and calibrated and background is known. These approaches are not robust for general dynamic scenes captured with sparse moving cameras. Previous approaches for outdoor dynamic scene reconstruction assume prior knowledge of the static background appearance and structure. The primary contributions of this paper are twofold: an automatic method for initial coarse dynamic scene segmentation and reconstruction without prior knowledge of background appearance or structure; and a general robust approach for joint segmentation refinement and dense reconstruction of dynamic scenes from multiple wide-baseline static or moving cameras. Evaluation is performed on a variety of indoor and outdoor scenes with cluttered backgrounds and multiple dynamic non-rigid objects such as people. Comparison with state-of-the-art approaches demonstrates improved accuracy in both multiple view segmentation and dense reconstruction. The proposed approach also eliminates the requirement for prior knowledge of scene structure and appearance.



