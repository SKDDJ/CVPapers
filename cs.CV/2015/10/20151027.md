# Arxiv Papers in cs.CV on 2015-10-27
### The Wilson Machine for Image Modeling
- **Arxiv ID**: http://arxiv.org/abs/1510.07740v2
- **DOI**: None
- **Categories**: **stat.ML**, cond-mat.stat-mech, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1510.07740v2)
- **Published**: 2015-10-27 01:04:05+00:00
- **Updated**: 2015-11-11 22:28:55+00:00
- **Authors**: Saeed Saremi, Terrence J. Sejnowski
- **Comment**: None
- **Journal**: None
- **Summary**: Learning the distribution of natural images is one of the hardest and most important problems in machine learning. The problem remains open, because the enormous complexity of the structures in natural images spans all length scales. We break down the complexity of the problem and show that the hierarchy of structures in natural images fuels a new class of learning algorithms based on the theory of critical phenomena and stochastic processes. We approach this problem from the perspective of the theory of critical phenomena, which was developed in condensed matter physics to address problems with infinite length-scale fluctuations, and build a framework to integrate the criticality of natural images into a learning algorithm. The problem is broken down by mapping images into a hierarchy of binary images, called bitplanes. In this representation, the top bitplane is critical, having fluctuations in structures over a vast range of scales. The bitplanes below go through a gradual stochastic heating process to disorder. We turn this representation into a directed probabilistic graphical model, transforming the learning problem into the unsupervised learning of the distribution of the critical bitplane and the supervised learning of the conditional distributions for the remaining bitplanes. We learnt the conditional distributions by logistic regression in a convolutional architecture. Conditioned on the critical binary image, this simple architecture can generate large, natural-looking images, with many shades of gray, without the use of hidden units, unprecedented in the studies of natural images. The framework presented here is a major step in bringing criticality and stochastic processes to machine learning and in studying natural image statistics.



### Computational models: Bottom-up and top-down aspects
- **Arxiv ID**: http://arxiv.org/abs/1510.07748v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.07748v1)
- **Published**: 2015-10-27 01:47:26+00:00
- **Updated**: 2015-10-27 01:47:26+00:00
- **Authors**: Laurent Itti, Ali Borji
- **Comment**: None
- **Journal**: The Oxford Handbook of Attention, (A. C. Nobre, S. Kastner Ed.),
  pp. 1-20, 2013
- **Summary**: Computational models of visual attention have become popular over the past decade, we believe primarily for two reasons: First, models make testable predictions that can be explored by experimentalists as well as theoreticians, second, models have practical and technological applications of interest to the applied science and engineering communities. In this chapter, we take a critical look at recent attention modeling efforts. We focus on {\em computational models of attention} as defined by Tsotsos \& Rothenstein \shortcite{Tsotsos_Rothenstein11}: Models which can process any visual stimulus (typically, an image or video clip), which can possibly also be given some task definition, and which make predictions that can be compared to human or animal behavioral or physiological responses elicited by the same stimulus and task. Thus, we here place less emphasis on abstract models, phenomenological models, purely data-driven fitting or extrapolation models, or models specifically designed for a single task or for a restricted class of stimuli. For theoretical models, we refer the reader to a number of previous reviews that address attention theories and models more generally \cite{Itti_Koch01nrn,Paletta_etal05,Frintrop_etal10,Rothenstein_Tsotsos08,Gottlieb_Balan10,Toet11,Borji_Itti12pami}.



### Some like it hot - visual guidance for preference prediction
- **Arxiv ID**: http://arxiv.org/abs/1510.07867v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.07867v2)
- **Published**: 2015-10-27 11:17:46+00:00
- **Updated**: 2016-03-10 15:02:19+00:00
- **Authors**: Rasmus Rothe, Radu Timofte, Luc Van Gool
- **Comment**: accepted for publication at CVPR 2016
- **Journal**: None
- **Summary**: For people first impressions of someone are of determining importance. They are hard to alter through further information. This begs the question if a computer can reach the same judgement. Earlier research has already pointed out that age, gender, and average attractiveness can be estimated with reasonable precision. We improve the state-of-the-art, but also predict - based on someone's known preferences - how much that particular person is attracted to a novel face. Our computational pipeline comprises a face detector, convolutional neural networks for the extraction of deep features, standard support vector regression for gender, age and facial beauty, and - as the main novelties - visual regularized collaborative filtering to infer inter-person preferences as well as a novel regression technique for handling visual queries without rating history. We validate the method using a very large dataset from a dating site as well as images from celebrities. Our experiments yield convincing results, i.e. we predict 76% of the ratings correctly solely based on an image, and reveal some sociologically relevant conclusions. We also validate our collaborative filtering solution on the standard MovieLens rating dataset, augmented with movie posters, to predict an individual's movie rating. We demonstrate our algorithms on howhot.io which went viral around the Internet with more than 50 million pictures evaluated in the first month.



### Learning Multi-Domain Convolutional Neural Networks for Visual Tracking
- **Arxiv ID**: http://arxiv.org/abs/1510.07945v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.07945v2)
- **Published**: 2015-10-27 15:53:00+00:00
- **Updated**: 2016-01-06 06:14:53+00:00
- **Authors**: Hyeonseob Nam, Bohyung Han
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a novel visual tracking algorithm based on the representations from a discriminatively trained Convolutional Neural Network (CNN). Our algorithm pretrains a CNN using a large set of videos with tracking ground-truths to obtain a generic target representation. Our network is composed of shared layers and multiple branches of domain-specific layers, where domains correspond to individual training sequences and each branch is responsible for binary classification to identify the target in each domain. We train the network with respect to each domain iteratively to obtain generic target representations in the shared layers. When tracking a target in a new sequence, we construct a new network by combining the shared layers in the pretrained CNN with a new binary classification layer, which is updated online. Online tracking is performed by evaluating the candidate windows randomly sampled around the previous target state. The proposed algorithm illustrates outstanding performance compared with state-of-the-art methods in existing tracking benchmarks.



### ENFT: Efficient Non-Consecutive Feature Tracking for Robust Structure-from-Motion
- **Arxiv ID**: http://arxiv.org/abs/1510.08012v2
- **DOI**: 10.1109/TIP.2016.2607425
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.08012v2)
- **Published**: 2015-10-27 18:00:42+00:00
- **Updated**: 2016-10-12 11:29:33+00:00
- **Authors**: Guofeng Zhang, Haomin Liu, Zilong Dong, Jiaya Jia, Tien-Tsin Wong, Hujun Bao
- **Comment**: 15 pages, 12 figures
- **Journal**: None
- **Summary**: Structure-from-motion (SfM) largely relies on feature tracking. In image sequences, if disjointed tracks caused by objects moving in and out of the field of view, occasional occlusion, or image noise, are not handled well, corresponding SfM could be affected. This problem becomes severer for large-scale scenes, which typically requires to capture multiple sequences to cover the whole scene. In this paper, we propose an efficient non-consecutive feature tracking (ENFT) framework to match interrupted tracks distributed in different subsequences or even in different videos. Our framework consists of steps of solving the feature `dropout' problem when indistinctive structures, noise or large image distortion exists, and of rapidly recognizing and joining common features located in different subsequences. In addition, we contribute an effective segment-based coarse-to-fine SfM algorithm for robustly handling large datasets. Experimental results on challenging video data demonstrate the effectiveness of the proposed system.



### Hybrid One-Shot 3D Hand Pose Estimation by Exploiting Uncertainties
- **Arxiv ID**: http://arxiv.org/abs/1510.08039v1
- **DOI**: 10.5244/C.29.182
- **Categories**: **cs.CV**, I.2.10; I.4.8; I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1510.08039v1)
- **Published**: 2015-10-27 19:44:44+00:00
- **Updated**: 2015-10-27 19:44:44+00:00
- **Authors**: Georg Poier, Konstantinos Roditakis, Samuel Schulter, Damien Michel, Horst Bischof, Antonis A. Argyros
- **Comment**: BMVC 2015 (oral); see also
  http://lrs.icg.tugraz.at/research/hybridhape/
- **Journal**: None
- **Summary**: Model-based approaches to 3D hand tracking have been shown to perform well in a wide range of scenarios. However, they require initialisation and cannot recover easily from tracking failures that occur due to fast hand motions. Data-driven approaches, on the other hand, can quickly deliver a solution, but the results often suffer from lower accuracy or missing anatomical validity compared to those obtained from model-based approaches. In this work we propose a hybrid approach for hand pose estimation from a single depth image. First, a learned regressor is employed to deliver multiple initial hypotheses for the 3D position of each hand joint. Subsequently, the kinematic parameters of a 3D hand model are found by deliberately exploiting the inherent uncertainty of the inferred joint proposals. This way, the method provides anatomically valid and accurate solutions without requiring manual initialisation or suffering from track losses. Quantitative results on several standard datasets demonstrate that the proposed method outperforms state-of-the-art representatives of the model-based, data-driven and hybrid paradigms.



