# Arxiv Papers in cs.CV on 2015-10-13
### Deep convolutional neural networks for pedestrian detection
- **Arxiv ID**: http://arxiv.org/abs/1510.03608v5
- **DOI**: 10.1016/j.image.2016.05.007
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.03608v5)
- **Published**: 2015-10-13 09:57:46+00:00
- **Updated**: 2016-03-07 09:42:33+00:00
- **Authors**: Denis Tomè, Federico Monti, Luca Baroffio, Luca Bondi, Marco Tagliasacchi, Stefano Tubaro
- **Comment**: submitted to Elsevier Signal Processing: Image Communication special
  Issue on Deep Learning
- **Journal**: None
- **Summary**: Pedestrian detection is a popular research topic due to its paramount importance for a number of applications, especially in the fields of automotive, surveillance and robotics. Despite the significant improvements, pedestrian detection is still an open challenge that calls for more and more accurate algorithms. In the last few years, deep learning and in particular convolutional neural networks emerged as the state of the art in terms of accuracy for a number of computer vision tasks such as image classification, object detection and segmentation, often outperforming the previous gold standards by a large margin. In this paper, we propose a pedestrian detection system based on deep learning, adapting a general-purpose convolutional network to the task at hand. By thoroughly analyzing and optimizing each step of the detection pipeline we propose an architecture that outperforms traditional methods, achieving a task accuracy close to that of state-of-the-art approaches, while requiring a low computational time. Finally, we tested the system on an NVIDIA Jetson TK1, a 192-core platform that is envisioned to be a forerunner computational brain of future self-driving cars.



### SemanticPaint: A Framework for the Interactive Segmentation of 3D Scenes
- **Arxiv ID**: http://arxiv.org/abs/1510.03727v1
- **DOI**: 10.1145/2751556
- **Categories**: **cs.CV**, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/1510.03727v1)
- **Published**: 2015-10-13 15:06:03+00:00
- **Updated**: 2015-10-13 15:06:03+00:00
- **Authors**: Stuart Golodetz, Michael Sapienza, Julien P. C. Valentin, Vibhav Vineet, Ming-Ming Cheng, Anurag Arnab, Victor A. Prisacariu, Olaf Kähler, Carl Yuheng Ren, David W. Murray, Shahram Izadi, Philip H. S. Torr
- **Comment**: 33 pages, Project: http://www.semantic-paint.com, Code:
  https://github.com/torrvision/spaint
- **Journal**: None
- **Summary**: We present an open-source, real-time implementation of SemanticPaint, a system for geometric reconstruction, object-class segmentation and learning of 3D scenes. Using our system, a user can walk into a room wearing a depth camera and a virtual reality headset, and both densely reconstruct the 3D scene and interactively segment the environment into object classes such as 'chair', 'floor' and 'table'. The user interacts physically with the real-world scene, touching objects and using voice commands to assign them appropriate labels. These user-generated labels are leveraged by an online random forest-based machine learning algorithm, which is used to predict labels for previously unseen parts of the scene. The entire pipeline runs in real time, and the user stays 'in the loop' throughout the process, receiving immediate feedback about the progress of the labelling and interacting with the scene as necessary to refine the predicted segmentation.



### Fast sequential forensic camera identification
- **Arxiv ID**: http://arxiv.org/abs/1510.03730v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1510.03730v1)
- **Published**: 2015-10-13 15:07:46+00:00
- **Updated**: 2015-10-13 15:07:46+00:00
- **Authors**: Fernando Pérez-González, Iria González-Iglesias, Miguel Masciopinto, Pedro Comesaña
- **Comment**: None
- **Journal**: None
- **Summary**: Two sequential camera source identification methods are proposed. Sequential tests implement a log-likelihood ratio test in an incremental way, thus enabling a reliable decision with a minimal number of observations. One of our methods adapts Goljan et al.'s to sequential operation. The second, which offers better performance in terms of error probabilities and average number of test observations, is based on treating the alternative hypothesis as a doubly stochastic model. We also discuss how the standard sequential test can be corrected to account for the event of weak fingerprints. Finally, we validate the goodness of our methods with experiments.



### Wide-Area Image Geolocalization with Aerial Reference Imagery
- **Arxiv ID**: http://arxiv.org/abs/1510.03743v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.03743v1)
- **Published**: 2015-10-13 15:33:01+00:00
- **Updated**: 2015-10-13 15:33:01+00:00
- **Authors**: Scott Workman, Richard Souvenir, Nathan Jacobs
- **Comment**: International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: We propose to use deep convolutional neural networks to address the problem of cross-view image geolocalization, in which the geolocation of a ground-level query image is estimated by matching to georeferenced aerial images. We use state-of-the-art feature representations for ground-level images and introduce a cross-view training approach for learning a joint semantic feature representation for aerial images. We also propose a network architecture that fuses features extracted from aerial images at multiple spatial scales. To support training these networks, we introduce a massive database that contains pairs of aerial and ground-level images from across the United States. Our methods significantly out-perform the state of the art on two benchmark datasets. We also show, qualitatively, that the proposed feature representations are discriminative at both local and continental spatial scales.



### Variable-state Latent Conditional Random Fields for Facial Expression Recognition and Action Unit Detection
- **Arxiv ID**: http://arxiv.org/abs/1510.03909v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1510.03909v1)
- **Published**: 2015-10-13 21:57:47+00:00
- **Updated**: 2015-10-13 21:57:47+00:00
- **Authors**: Robert Walecki, Ognjen Rudovic, Vladimir Pavlovic, Maja Pantic
- **Comment**: None
- **Journal**: None
- **Summary**: Automated recognition of facial expressions of emotions, and detection of facial action units (AUs), from videos depends critically on modeling of their dynamics. These dynamics are characterized by changes in temporal phases (onset-apex-offset) and intensity of emotion expressions and AUs, the appearance of which may vary considerably among target subjects, making the recognition/detection task very challenging. The state-of-the-art Latent Conditional Random Fields (L-CRF) framework allows one to efficiently encode these dynamics through the latent states accounting for the temporal consistency in emotion expression and ordinal relationships between its intensity levels, these latent states are typically assumed to be either unordered (nominal) or fully ordered (ordinal). Yet, such an approach is often too restrictive. For instance, in the case of AU detection, the goal is to discriminate between the segments of an image sequence in which this AU is active or inactive. While the sequence segments containing activation of the target AU may better be described using ordinal latent states, the inactive segments better be described using unordered (nominal) latent states, as no assumption can be made about their underlying structure (since they can contain either neutral faces or activations of non-target AUs). To address this, we propose the variable-state L-CRF (VSL-CRF) model that automatically selects the optimal latent states for the target image sequence. To reduce the model overfitting either the nominal or ordinal latent states, we propose a novel graph-Laplacian regularization of the latent states. Our experiments on three public expression databases show that the proposed model achieves better generalization performance compared to traditional L-CRFs and other related state-of-the-art models.



