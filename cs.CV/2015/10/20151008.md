# Arxiv Papers in cs.CV on 2015-10-08
### Data-Efficient Learning of Feedback Policies from Image Pixels using Deep Dynamical Models
- **Arxiv ID**: http://arxiv.org/abs/1510.02173v2
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1510.02173v2)
- **Published**: 2015-10-08 00:20:42+00:00
- **Updated**: 2015-10-09 15:21:01+00:00
- **Authors**: John-Alexander M. Assael, Niklas Wahlström, Thomas B. Schön, Marc Peter Deisenroth
- **Comment**: None
- **Journal**: None
- **Summary**: Data-efficient reinforcement learning (RL) in continuous state-action spaces using very high-dimensional observations remains a key challenge in developing fully autonomous systems. We consider a particularly important instance of this challenge, the pixels-to-torques problem, where an RL agent learns a closed-loop control policy ("torques") from pixel information only. We introduce a data-efficient, model-based reinforcement learning algorithm that learns such a closed-loop policy directly from pixel information. The key ingredient is a deep dynamical model for learning a low-dimensional feature embedding of images jointly with a predictive model in this low-dimensional feature space. Joint learning is crucial for long-term predictions, which lie at the core of the adaptive nonlinear model predictive control strategy that we use for closed-loop control. Compared to state-of-the-art RL methods for continuous states and actions, our approach learns quickly, scales to high-dimensional state spaces, is lightweight and an important step toward fully autonomous end-to-end learning from pixels to torques.



### Simultaneous Deep Transfer Across Domains and Tasks
- **Arxiv ID**: http://arxiv.org/abs/1510.02192v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.02192v1)
- **Published**: 2015-10-08 03:42:45+00:00
- **Updated**: 2015-10-08 03:42:45+00:00
- **Authors**: Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko
- **Comment**: None
- **Journal**: None
- **Summary**: Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias. Fine-tuning deep models in a new domain can require a significant amount of labeled data, which for many applications is simply not available. We propose a new CNN architecture to exploit unlabeled and sparsely labeled target domain data. Our approach simultaneously optimizes for domain invariance to facilitate domain transfer and uses a soft label distribution matching loss to transfer information between tasks. Our proposed adaptation method offers empirical performance which exceeds previously published results on two standard benchmark visual domain adaptation tasks, evaluated across supervised and semi-supervised adaptation settings.



### Texture Modelling with Nested High-order Markov-Gibbs Random Fields
- **Arxiv ID**: http://arxiv.org/abs/1510.02364v1
- **DOI**: 10.1016/j.cviu.2015.11.003
- **Categories**: **cs.CV**, cs.LG, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/1510.02364v1)
- **Published**: 2015-10-08 15:22:21+00:00
- **Updated**: 2015-10-08 15:22:21+00:00
- **Authors**: Ralph Versteegen, Georgy Gimel'farb, Patricia Riddle
- **Comment**: Submitted to Computer Vision and Image Understanding
- **Journal**: None
- **Summary**: Currently, Markov-Gibbs random field (MGRF) image models which include high-order interactions are almost always built by modelling responses of a stack of local linear filters. Actual interaction structure is specified implicitly by the filter coefficients. In contrast, we learn an explicit high-order MGRF structure by considering the learning process in terms of general exponential family distributions nested over base models, so that potentials added later can build on previous ones. We relatively rapidly add new features by skipping over the costly optimisation of parameters.   We introduce the use of local binary patterns as features in MGRF texture models, and generalise them by learning offsets to the surrounding pixels. These prove effective as high-order features, and are fast to compute. Several schemes for selecting high-order features by composition or search of a small subclass are compared. Additionally we present a simple modification of the maximum likelihood as a texture modelling-specific objective function which aims to improve generalisation by local windowing of statistics.   The proposed method was experimentally evaluated by learning high-order MGRF models for a broad selection of complex textures and then performing texture synthesis, and succeeded on much of the continuum from stochastic through irregularly structured to near-regular textures. Learning interaction structure is very beneficial for textures with large-scale structure, although those with complex irregular structure still provide difficulties. The texture models were also quantitatively evaluated on two tasks and found to be competitive with other works: grading of synthesised textures by a panel of observers; and comparison against several recent MGRF models by evaluation on a constrained inpainting task.



### Learning Data-driven Reflectance Priors for Intrinsic Image Decomposition
- **Arxiv ID**: http://arxiv.org/abs/1510.02413v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.02413v1)
- **Published**: 2015-10-08 17:28:22+00:00
- **Updated**: 2015-10-08 17:28:22+00:00
- **Authors**: Tinghui Zhou, Philipp Krähenbühl, Alexei A. Efros
- **Comment**: International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: We propose a data-driven approach for intrinsic image decomposition, which is the process of inferring the confounding factors of reflectance and shading in an image. We pose this as a two-stage learning problem. First, we train a model to predict relative reflectance ordering between image patches (`brighter', `darker', `same') from large-scale human annotations, producing a data-driven reflectance prior. Second, we show how to naturally integrate this learned prior into existing energy minimization frameworks for intrinsic image decomposition. We compare our method to the state-of-the-art approach of Bell et al. on both decomposition and image relighting tasks, demonstrating the benefits of the simple relative reflectance prior, especially for scenes under challenging lighting conditions.



