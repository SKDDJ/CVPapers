# Arxiv Papers in cs.CV on 2015-10-16
### Multiresolution hierarchy co-clustering for semantic segmentation in sequences with small variations
- **Arxiv ID**: http://arxiv.org/abs/1510.04842v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.04842v1)
- **Published**: 2015-10-16 11:25:33+00:00
- **Updated**: 2015-10-16 11:25:33+00:00
- **Authors**: David Varas, Mónica Alfaro, Ferran Marques
- **Comment**: International Conference on Computer Vision (ICCV) 2015
- **Journal**: None
- **Summary**: This paper presents a co-clustering technique that, given a collection of images and their hierarchies, clusters nodes from these hierarchies to obtain a coherent multiresolution representation of the image collection. We formalize the co-clustering as a Quadratic Semi-Assignment Problem and solve it with a linear programming relaxation approach that makes effective use of information from hierarchies. Initially, we address the problem of generating an optimal, coherent partition per image and, afterwards, we extend this method to a multiresolution framework. Finally, we particularize this framework to an iterative multiresolution video segmentation algorithm in sequences with small variations. We evaluate the algorithm on the Video Occlusion/Object Boundary Detection Dataset, showing that it produces state-of-the-art results in these scenarios.



### Measurement of Road Traffic Parameters Based on Multi-Vehicle Tracking
- **Arxiv ID**: http://arxiv.org/abs/1510.04860v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.04860v1)
- **Published**: 2015-10-16 12:26:29+00:00
- **Updated**: 2015-10-16 12:26:29+00:00
- **Authors**: Kristian Kovačić, Edouard Ivanjko, Niko Jelušić
- **Comment**: Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2015, Year 3
- **Journal**: None
- **Summary**: Development of computing power and cheap video cameras enabled today's traffic management systems to include more cameras and computer vision applications for transportation system monitoring and control. Combined with image processing algorithms cameras are used as sensors to measure road traffic parameters like flow volume, origin-destination matrices, classify vehicles, etc. In this paper we propose a system for measurement of road traffic parameters (basic motion model parameters and macro-scopic traffic parameters). The system is based on Local Binary Pattern (LBP) image features classification with a cascade of Gentle Adaboost (GAB) classifiers to determine vehicle existence and its location in an image. Additionally, vehicle tracking and counting in a road traffic video is performed by using Extended Kalman Filter (EKF) and virtual markers. The newly proposed system is compared with a system based on background subtraction. Comparison is performed by the means of execution time and accuracy.



### Towards Reversible De-Identification in Video Sequences Using 3D Avatars and Steganography
- **Arxiv ID**: http://arxiv.org/abs/1510.04861v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/1510.04861v1)
- **Published**: 2015-10-16 12:31:29+00:00
- **Updated**: 2015-10-16 12:31:29+00:00
- **Authors**: Martin Blažević, Karla Brkić, Tomislav Hrkać
- **Comment**: Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2015, Year 3
- **Journal**: None
- **Summary**: We propose a de-identification pipeline that protects the privacy of humans in video sequences by replacing them with rendered 3D human models, hence concealing their identity while retaining the naturalness of the scene. The original images of humans are steganographically encoded in the carrier image, i.e. the image containing the original scene and the rendered 3D human models. We qualitatively explore the feasibility of our approach, utilizing the Kinect sensor and its libraries to detect and localize human joints. A 3D avatar is rendered into the scene using the obtained joint positions, and the original human image is steganographically encoded in the new scene. Our qualitative evaluation shows reasonably good results that merit further exploration.



### You-Do, I-Learn: Unsupervised Multi-User egocentric Approach Towards Video-Based Guidance
- **Arxiv ID**: http://arxiv.org/abs/1510.04862v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.04862v2)
- **Published**: 2015-10-16 12:32:26+00:00
- **Updated**: 2016-03-19 17:44:58+00:00
- **Authors**: Dima Damen, Teesid Leelasawassuk, Walterio Mayol-Cuevas
- **Comment**: None
- **Journal**: None
- **Summary**: This paper presents an unsupervised approach towards automatically extracting video-based guidance on object usage, from egocentric video and wearable gaze tracking, collected from multiple users while performing tasks. The approach i) discovers task relevant objects, ii) builds a model for each, iii) distinguishes different ways in which each discovered object has been used and iv) discovers the dependencies between object interactions. The work investigates using appearance, position, motion and attention, and presents results using each and a combination of relevant features. Moreover, an online scalable approach is presented and is compared to offline results. The paper proposes a method for selecting a suitable video guide to be displayed to a novice user indicating how to use an object, purely triggered by the user's gaze. The potential assistive mode can also recommend an object to be used next based on the learnt sequence of object interactions. The approach was tested on a variety of daily tasks such as initialising a printer, preparing a coffee and setting up a gym machine.



### An Extension to Hough Transform Based on Gradient Orientation
- **Arxiv ID**: http://arxiv.org/abs/1510.04863v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.04863v1)
- **Published**: 2015-10-16 12:36:13+00:00
- **Updated**: 2015-10-16 12:36:13+00:00
- **Authors**: Tomislav Petković, Sven Lončarić
- **Comment**: Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2015, Year 3
- **Journal**: None
- **Summary**: The Hough transform is one of the most common methods for line detection. In this paper we propose a novel extension of the regular Hough transform. The proposed extension combines the extension of the accumulator space and the local gradient orientation resulting in clutter reduction and yielding more prominent peaks, thus enabling better line identification. We demonstrate benefits in applications such as visual quality inspection and rectangle detection.



### No Spare Parts: Sharing Part Detectors for Image Categorization
- **Arxiv ID**: http://arxiv.org/abs/1510.04908v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.04908v2)
- **Published**: 2015-10-16 15:05:41+00:00
- **Updated**: 2016-07-12 17:05:27+00:00
- **Authors**: Pascal Mettes, Jan C. van Gemert, Cees G. M. Snoek
- **Comment**: None
- **Journal**: None
- **Summary**: This work aims for image categorization using a representation of distinctive parts. Different from existing part-based work, we argue that parts are naturally shared between image categories and should be modeled as such. We motivate our approach with a quantitative and qualitative analysis by backtracking where selected parts come from. Our analysis shows that in addition to the category parts defining the class, the parts coming from the background context and parts from other image categories improve categorization performance. Part selection should not be done separately for each category, but instead be shared and optimized over all categories. To incorporate part sharing between categories, we present an algorithm based on AdaBoost to jointly optimize part sharing and selection, as well as fusion with the global image representation. We achieve results competitive to the state-of-the-art on object, scene, and action categories, further improving over deep convolutional neural networks.



