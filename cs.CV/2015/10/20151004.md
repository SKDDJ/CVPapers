# Arxiv Papers in cs.CV on 2015-10-04
### Background Image Generation Using Boolean Operations
- **Arxiv ID**: http://arxiv.org/abs/1510.00889v1
- **DOI**: None
- **Categories**: **cs.CV**, I.4.6
- **Links**: [PDF](http://arxiv.org/pdf/1510.00889v1)
- **Published**: 2015-10-04 00:34:56+00:00
- **Updated**: 2015-10-04 00:34:56+00:00
- **Authors**: Kardi Teknomo, Proceso Fernandez
- **Comment**: None
- **Journal**: Philippine Computing Journal Vol 4 No 2, December 2009, pp. 43-49
- **Summary**: Tracking moving objects from a video sequence requires segmentation of these objects from the background image. However, getting the actual background image automatically without object detection and using only the video is difficult. In this paper, we describe a novel algorithm that generates background from real world images without foreground detection. The algorithm assumes that the background image is shown in the majority of the video. Given this simple assumption, the method described in this paper is able to accurately generate, with high probability, the background image from a video using only a small number of binary operations.



### Cross-convolutional-layer Pooling for Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/1510.00921v6
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.00921v6)
- **Published**: 2015-10-04 10:27:36+00:00
- **Updated**: 2016-12-22 04:43:19+00:00
- **Authors**: Lingqiao Liu, Chunhua Shen, Anton van den Hengel
- **Comment**: Fixed typos. Journal extension of arXiv:1411.7466. Accepted to IEEE
  Transactions on Pattern Analysis and Machine Intelligence
- **Journal**: None
- **Summary**: Recent studies have shown that a Deep Convolutional Neural Network (DCNN) pretrained on a large image dataset can be used as a universal image descriptor, and that doing so leads to impressive performance for a variety of image classification tasks. Most of these studies adopt activations from a single DCNN layer, usually the fully-connected layer, as the image representation. In this paper, we proposed a novel way to extract image representations from two consecutive convolutional layers: one layer is utilized for local feature extraction and the other serves as guidance to pool the extracted features. By taking different viewpoints of convolutional layers, we further develop two schemes to realize this idea. The first one directly uses convolutional layers from a DCNN. The second one applies the pretrained CNN on densely sampled image regions and treats the fully-connected activations of each image region as convolutional feature activations. We then train another convolutional layer on top of that as the pooling-guidance convolutional layer. By applying our method to three popular visual classification tasks, we find our first scheme tends to perform better on the applications which need strong discrimination on subtle object patterns within small regions while the latter excels in the cases that require discrimination on category-level patterns. Overall, the proposed method achieves superior performance over existing ways of extracting image representations from a DCNN.



### Efficient Hand Articulations Tracking using Adaptive Hand Model and Depth map
- **Arxiv ID**: http://arxiv.org/abs/1510.00981v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.00981v3)
- **Published**: 2015-10-04 20:34:15+00:00
- **Updated**: 2015-10-18 03:21:48+00:00
- **Authors**: Byeongkeun Kang, Yeejin Lee, Truong Q. Nguyen
- **Comment**: Advances in Visual Computing: 11th International Symposium on Visual
  Computing (ISVC'15)
- **Journal**: None
- **Summary**: Real-time hand articulations tracking is important for many applications such as interacting with virtual / augmented reality devices or tablets. However, most of existing algorithms highly rely on expensive and high power-consuming GPUs to achieve real-time processing. Consequently, these systems are inappropriate for mobile and wearable devices. In this paper, we propose an efficient hand tracking system which does not require high performance GPUs. In our system, we track hand articulations by minimizing discrepancy between depth map from sensor and computer-generated hand model. We also initialize hand pose at each frame using finger detection and classification. Our contributions are: (a) propose adaptive hand model to consider different hand shapes of users without generating personalized hand model; (b) improve the highly efficient frame initialization for robust tracking and automatic initialization; (c) propose hierarchical random sampling of pixels from each depth map to improve tracking accuracy while limiting required computations. To the best of our knowledge, it is the first system that achieves both automatic hand model adjustment and real-time tracking without using GPUs.



