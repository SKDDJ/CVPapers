# Arxiv Papers in cs.CV on 2015-10-22
### Generic decoding of seen and imagined objects using hierarchical visual features
- **Arxiv ID**: http://arxiv.org/abs/1510.06479v3
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/1510.06479v3)
- **Published**: 2015-10-22 02:34:03+00:00
- **Updated**: 2016-09-27 14:27:20+00:00
- **Authors**: Tomoyasu Horikawa, Yukiyasu Kamitani
- **Comment**: None
- **Journal**: None
- **Summary**: Object recognition is a key function in both human and machine vision. While recent studies have achieved fMRI decoding of seen and imagined contents, the prediction is limited to training examples. We present a decoding approach for arbitrary objects, using the machine vision principle that an object category is represented by a set of features rendered invariant through hierarchical processing. We show that visual features including those from a convolutional neural network can be predicted from fMRI patterns and that greater accuracy is achieved for low/high-level features with lower/higher-level visual areas, respectively. Predicted features are used to identify seen/imagined object categories (extending beyond decoder training) from a set of computed features for numerous object images. Furthermore, the decoding of imagined objects reveals progressive recruitment of higher to lower visual representations. Our results demonstrate a homology between human and machine vision and its utility for brain-based information retrieval.



### Personalized Age Progression with Aging Dictionary
- **Arxiv ID**: http://arxiv.org/abs/1510.06503v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.06503v1)
- **Published**: 2015-10-22 07:33:18+00:00
- **Updated**: 2015-10-22 07:33:18+00:00
- **Authors**: Xiangbo Shu, Jinhui Tang, Hanjiang Lai, Luoqi Liu, Shuicheng Yan
- **Comment**: in International Conference on Computer Vision, 2015
- **Journal**: None
- **Summary**: In this paper, we aim to automatically render aging faces in a personalized way. Basically, a set of age-group specific dictionaries are learned, where the dictionary bases corresponding to the same index yet from different dictionaries form a particular aging process pattern cross different age groups, and a linear combination of these patterns expresses a particular personalized aging process. Moreover, two factors are taken into consideration in the dictionary learning process. First, beyond the aging dictionaries, each subject may have extra personalized facial characteristics, e.g. mole, which are invariant in the aging process. Second, it is challenging or even impossible to collect faces of all age groups for a particular subject, yet much easier and more practical to get face pairs from neighboring age groups. Thus a personality-aware coupled reconstruction loss is utilized to learn the dictionaries based on face pairs from neighboring age groups. Extensive experiments well demonstrate the advantages of our proposed solution over other state-of-the-arts in term of personalized aging progression, as well as the performance gain for cross-age face verification by synthesizing aging faces.



### Modelling, Measuring and Compensating Color Weak Vision
- **Arxiv ID**: http://arxiv.org/abs/1510.06507v1
- **DOI**: 10.1109/TIP.2016.2539679
- **Categories**: **cs.CV**, I.2.10; I.4.8; I.5
- **Links**: [PDF](http://arxiv.org/pdf/1510.06507v1)
- **Published**: 2015-10-22 07:44:24+00:00
- **Updated**: 2015-10-22 07:44:24+00:00
- **Authors**: Satoshi Oshima, Rica Mochizuki, Reiner Lenz, Jinhui Chao
- **Comment**: Full resolution color pictures are available from the authors
- **Journal**: None
- **Summary**: We use methods from Riemann geometry to investigate transformations between the color spaces of color-normal and color weak observers. The two main applications are the simulation of the perception of a color weak observer for a color normal observer and the compensation of color images in a way that a color weak observer has approximately the same perception as a color normal observer. The metrics in the color spaces of interest are characterized with the help of ellipsoids defined by the just-noticable-differences between color which are measured with the help of color-matching experiments. The constructed mappings are isometries of Riemann spaces that preserve the perceived color-differences for both observers. Among the two approaches to build such an isometry, we introduce normal coordinates in Riemann spaces as a tool to construct a global color-weak compensation map. Compared to previously used methods this method is free from approximation errors due to local linearizations and it avoids the problem of shifting locations of the origin of the local coordinate system. We analyse the variations of the Riemann metrics for different observers obtained from new color matching experiments and describe three variations of the basic method. The performance of the methods is evaluated with the help of semantic differential (SD) tests.



### Efficient Unsupervised Temporal Segmentation of Motion Data
- **Arxiv ID**: http://arxiv.org/abs/1510.06595v1
- **DOI**: 10.1109/TMM.2016.2635030
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.06595v1)
- **Published**: 2015-10-22 12:20:04+00:00
- **Updated**: 2015-10-22 12:20:04+00:00
- **Authors**: Björn Krüger, Anna Vögele, Tobias Willig, Angela Yao, Reinhard Klein, Andreas Weber
- **Comment**: 15 pages, submitted to TPAMI
- **Journal**: None
- **Summary**: We introduce a method for automated temporal segmentation of human motion data into distinct actions and compositing motion primitives based on self-similar structures in the motion sequence. We use neighbourhood graphs for the partitioning and the similarity information in the graph is further exploited to cluster the motion primitives into larger entities of semantic significance. The method requires no assumptions about the motion sequences at hand and no user interaction is required for the segmentation or clustering. In addition, we introduce a feature bundling preprocessing technique to make the segmentation more robust to noise, as well as a notion of motion symmetry for more refined primitive detection. We test our method on several sensor modalities, including markered and markerless motion capture as well as on electromyograph and accelerometer recordings. The results highlight our system's capabilities for both segmentation and for analysis of the finer structures of motion data, all in a completely unsupervised manner.



### ZNN - A Fast and Scalable Algorithm for Training 3D Convolutional Networks on Multi-Core and Many-Core Shared Memory Machines
- **Arxiv ID**: http://arxiv.org/abs/1510.06706v1
- **DOI**: 10.1109/IPDPS.2016.119
- **Categories**: **cs.NE**, cs.CV, cs.DC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/1510.06706v1)
- **Published**: 2015-10-22 18:14:42+00:00
- **Updated**: 2015-10-22 18:14:42+00:00
- **Authors**: Aleksandar Zlateski, Kisuk Lee, H. Sebastian Seung
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional networks (ConvNets) have become a popular approach to computer vision. It is important to accelerate ConvNet training, which is computationally costly. We propose a novel parallel algorithm based on decomposition into a set of tasks, most of which are convolutions or FFTs. Applying Brent's theorem to the task dependency graph implies that linear speedup with the number of processors is attainable within the PRAM model of parallel computation, for wide network architectures. To attain such performance on real shared-memory machines, our algorithm computes convolutions converging on the same node of the network with temporal locality to reduce cache misses, and sums the convergent convolution outputs via an almost wait-free concurrent method to reduce time spent in critical sections. We implement the algorithm with a publicly available software package called ZNN. Benchmarking with multi-core CPUs shows that ZNN can attain speedup roughly equal to the number of physical cores. We also show that ZNN can attain over 90x speedup on a many-core CPU (Xeon Phi Knights Corner). These speedups are achieved for network architectures with widths that are in common use. The task parallelism of the ZNN algorithm is suited to CPUs, while the SIMD parallelism of previous algorithms is compatible with GPUs. Through examples, we show that ZNN can be either faster or slower than certain GPU implementations depending on specifics of the network architecture, kernel sizes, and density and size of the output patch. ZNN may be less costly to develop and maintain, due to the relative ease of general-purpose CPU programming.



### Order-Fractal transition in abstract paintings
- **Arxiv ID**: http://arxiv.org/abs/1510.06767v3
- **DOI**: 10.1016/j.aop.2016.04.007
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.06767v3)
- **Published**: 2015-10-22 21:03:50+00:00
- **Updated**: 2016-04-12 12:28:31+00:00
- **Authors**: E. M. De la Calleja, F. Cervantes, J. De la Calleja
- **Comment**: None
- **Journal**: None
- **Summary**: We report the degree of order of twenty-two Jackson Pollock's paintings using \emph{Hausdorff-Besicovitch fractal dimension}. Through the maximum value of each multi-fractal spectrum, the artworks are classify by the year in which they were painted. It has been reported that Pollock's paintings are fractal and it increased on his latest works. However our results show that fractal dimension of the paintings are on a range of fractal dimension with values close to two. We identify this behavior as a fractal-order transition. Based on the study of disorder-order transition in physical systems, we interpreted the fractal-order transition through its dark paint strokes in Pollocks' paintings, as structured lines following a power law measured by fractal dimension. We obtain self-similarity in some specific Pollock's paintings, that reveal an important dependence on the scale of observation. We also characterize by its fractal spectrum, the called \emph{Teri's Find}. We obtained similar spectrums between \emph{Teri's Find} and \emph{Number 5} from Pollock, suggesting that fractal dimension cannot be completely rejected as a quantitative parameter to authenticate this kind of artworks.



