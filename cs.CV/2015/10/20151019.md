# Arxiv Papers in cs.CV on 2015-10-19
### Color graph based wavelet transform with perceptual information
- **Arxiv ID**: http://arxiv.org/abs/1510.05436v1
- **DOI**: 10.1117/1.JEI.24.5.053004
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05436v1)
- **Published**: 2015-10-19 11:48:23+00:00
- **Updated**: 2015-10-19 11:48:23+00:00
- **Authors**: Mohamed Malek, David Helbert, Philippe Carre
- **Comment**: None
- **Journal**: Journal of Electronic Imaging (SPIE), 24(5), 2015
- **Summary**: In this paper, we propose a numerical strategy to define a multiscale analysis for color and multicomponent images based on the representation of data on a graph. Our approach consists in computing the graph of an image using the psychovisual information and analysing it by using the spectral graph wavelet transform. We suggest introducing color dimension into the computation of the weights of the graph and using the geodesic distance as a means of distance measurement. We thus have defined a wavelet transform based on a graph with perceptual information by using the CIELab color distance. This new representation is illustrated with denoising and inpainting applications. Overall, by introducing psychovisual information in the graph computation for the graph wavelet transform we obtain very promising results. Therefore results in image restoration highlight the interest of the appropriate use of color information.



### DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection
- **Arxiv ID**: http://arxiv.org/abs/1510.05484v2
- **DOI**: 10.1109/TIP.2016.2579306
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05484v2)
- **Published**: 2015-10-19 14:11:49+00:00
- **Updated**: 2016-06-07 15:20:44+00:00
- **Authors**: Xi Li, Liming Zhao, Lina Wei, Ming-Hsuan Yang, Fei Wu, Yueting Zhuang, Haibin Ling, Jingdong Wang
- **Comment**: To appear in IEEE Transactions on Image Processing (TIP), Project
  Website: http://www.zhaoliming.net/research/deepsaliency
- **Journal**: None
- **Summary**: A key problem in salient object detection is how to effectively model the semantic properties of salient objects in a data-driven manner. In this paper, we propose a multi-task deep saliency model based on a fully convolutional neural network (FCNN) with global input (whole raw images) and global output (whole saliency maps). In principle, the proposed saliency model takes a data-driven strategy for encoding the underlying saliency prior information, and then sets up a multi-task learning scheme for exploring the intrinsic correlations between saliency detection and semantic image segmentation. Through collaborative feature learning from such two correlated tasks, the shared fully convolutional layers produce effective features for object perception. Moreover, it is capable of capturing the semantic information on salient objects across different levels using the fully convolutional layers, which investigate the feature-sharing properties of salient object detection with great feature redundancy reduction. Finally, we present a graph Laplacian regularized nonlinear regression model for saliency refinement. Experimental results demonstrate the effectiveness of our approach in comparison with the state-of-the-art approaches.



### Sparse + Low Rank Decomposition of Annihilating Filter-based Hankel Matrix for Impulse Noise Removal
- **Arxiv ID**: http://arxiv.org/abs/1510.05559v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05559v1)
- **Published**: 2015-10-19 16:11:24+00:00
- **Updated**: 2015-10-19 16:11:24+00:00
- **Authors**: Kyong Hwan Jin, Jong Chul Ye
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, so called annihilating filer-based low rank Hankel matrix (ALOHA) approach was proposed as a powerful image inpainting method. Based on the observation that smoothness or textures within an image patch corresponds to sparse spectral components in the frequency domain, ALOHA exploits the existence of annihilating filters and the associated rank-deficient Hankel matrices in the image domain to estimate the missing pixels. By extending this idea, here we propose a novel impulse noise removal algorithm using sparse + low rank decomposition of an annihilating filter-based Hankel matrix. The new approach, what we call the robust ALOHA, is motivated by the observation that an image corrupted with impulse noises has intact pixels; so the impulse noises can be modeled as sparse components, whereas the underlying image can be still modeled using a low-rank Hankel structured matrix. To solve the sparse + low rank decomposition problem, we propose an alternating direction method of multiplier (ADMM) method with initial factorized matrices coming from low rank matrix fitting (LMaFit) algorithm. To adapt the local image statistics that have distinct spectral distributions, the robust ALOHA is applied patch by patch. Experimental results from two types of impulse noises - random valued impulse noises and salt/pepper noises - for both single channel and multi-channel color images demonstrate that the robust ALOHA outperforms the existing algorithms up to 8dB in terms of the peak signal to noise ratio (PSNR).



### PERCH: Perception via Search for Multi-Object Recognition and Localization
- **Arxiv ID**: http://arxiv.org/abs/1510.05613v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/1510.05613v2)
- **Published**: 2015-10-19 18:39:05+00:00
- **Updated**: 2016-03-16 20:49:52+00:00
- **Authors**: Venkatraman Narayanan, Maxim Likhachev
- **Comment**: 8 pages, International Conference on Robotics and Automation (ICRA),
  2016
- **Journal**: None
- **Summary**: In many robotic domains such as flexible automated manufacturing or personal assistance, a fundamental perception task is that of identifying and localizing objects whose 3D models are known. Canonical approaches to this problem include discriminative methods that find correspondences between feature descriptors computed over the model and observed data. While these methods have been employed successfully, they can be unreliable when the feature descriptors fail to capture variations in observed data; a classic cause being occlusion. As a step towards deliberative reasoning, we present PERCH: PErception via SeaRCH, an algorithm that seeks to find the best explanation of the observed sensor data by hypothesizing possible scenes in a generative fashion. Our contributions are: i) formulating the multi-object recognition and localization task as an optimization problem over the space of hypothesized scenes, ii) exploiting structure in the optimization to cast it as a combinatorial search problem on what we call the Monotone Scene Generation Tree, and iii) leveraging parallelization and recent advances in multi-heuristic search in making combinatorial search tractable. We prove that our system can guaranteedly produce the best explanation of the scene under the chosen cost function, and validate our claims on real world RGB-D test data. Our experimental results show that we can identify and localize objects under heavy occlusion--cases where state-of-the-art methods struggle.



