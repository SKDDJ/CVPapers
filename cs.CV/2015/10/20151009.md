# Arxiv Papers in cs.CV on 2015-10-09
### Free-hand Sketch Synthesis with Deformable Stroke Models
- **Arxiv ID**: http://arxiv.org/abs/1510.02644v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.02644v1)
- **Published**: 2015-10-09 12:08:38+00:00
- **Updated**: 2015-10-09 12:08:38+00:00
- **Authors**: Yi Li, Yi-Zhe Song, Timothy Hospedales, Shaogang Gong
- **Comment**: None
- **Journal**: None
- **Summary**: We present a generative model which can automatically summarize the stroke composition of free-hand sketches of a given category. When our model is fit to a collection of sketches with similar poses, it discovers and learns the structure and appearance of a set of coherent parts, with each part represented by a group of strokes. It represents both consistent (topology) as well as diverse aspects (structure and appearance variations) of each sketch category. Key to the success of our model are important insights learned from a comprehensive study performed on human stroke data. By fitting this model to images, we are able to synthesize visually similar and pleasant free-hand sketches.



### Procams-Based Cybernetics
- **Arxiv ID**: http://arxiv.org/abs/1510.02710v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/1510.02710v1)
- **Published**: 2015-10-09 15:47:00+00:00
- **Updated**: 2015-10-09 15:47:00+00:00
- **Authors**: Kosuke Sato, Daisuke Iwai, Sei Ikeda, Noriko Takemura
- **Comment**: 2 pages, 2 figures, IEEE VR 2015 Lab/Project presentation
- **Journal**: None
- **Summary**: Procams-based cybernetics is a unique, emerging research field, which aims at enhancing and supporting our activities by naturally connecting human and computers/machines as a cooperative integrated system via projector-camera systems (procams). It rests on various research domains such as virtual/augmented reality, computer vision, computer graphics, projection display, human computer interface, human robot interaction and so on. This laboratory presentation provides a brief history including recent achievements of our procams-based cybernetics project.



### Human Head Pose Estimation by Facial Features Location
- **Arxiv ID**: http://arxiv.org/abs/1510.02774v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.02774v1)
- **Published**: 2015-10-09 19:15:52+00:00
- **Updated**: 2015-10-09 19:15:52+00:00
- **Authors**: Eugene Borovikov
- **Comment**: This is a master's thesis completed at UMCP in 1998, being published
  here given enough of the demand on its contents from the Computer Vision R&D
  community
- **Journal**: None
- **Summary**: We describe a method for estimating human head pose in a color image that contains enough of information to locate the head silhouette and detect non-trivial color edges of individual facial features. The method works by spotting the human head on an arbitrary background, extracting the head outline, and locating facial features necessary to describe the head orientation in the 3D space. It is robust enough to work with both color and gray-level images featuring quasi-frontal views of a human head under variable lighting conditions.



### Where Is My Puppy? Retrieving Lost Dogs by Facial Features
- **Arxiv ID**: http://arxiv.org/abs/1510.02781v2
- **DOI**: None
- **Categories**: **cs.CV**, 68T45, I.5.4
- **Links**: [PDF](http://arxiv.org/pdf/1510.02781v2)
- **Published**: 2015-10-09 19:39:15+00:00
- **Updated**: 2016-08-01 20:02:15+00:00
- **Authors**: Thierry Pinheiro Moreira, Mauricio Lisboa Perez, Rafael de Oliveira Werneck, Eduardo Valle
- **Comment**: 17 pages, 8 figures, 1 table, Multimedia Tools and Applications
- **Journal**: None
- **Summary**: A pet that goes missing is among many people's worst fears: a moment of distraction is enough for a dog or a cat wandering off from home. Some measures help matching lost animals to their owners; but automated visual recognition is one that - although convenient, highly available, and low-cost - is surprisingly overlooked. In this paper, we inaugurate that promising avenue by pursuing face recognition for dogs. We contrast four ready-to-use human facial recognizers (EigenFaces, FisherFaces, LBPH, and a Sparse method) to two original solutions based upon convolutional neural networks: BARK (inspired in architecture-optimized networks employed for human facial recognition) and WOOF (based upon off-the-shelf OverFeat features). Human facial recognizers perform poorly for dogs (up to 60.5% accuracy), showing that dog facial recognition is not a trivial extension of human facial recognition. The convolutional network solutions work much better, with BARK attaining up to 81.1% accuracy, and WOOF, 89.4%. The tests were conducted in two datasets: Flickr-dog, with 42 dogs of two breeds (pugs and huskies); and Snoopybook, with 18 mongrel dogs.



### Dreaming More Data: Class-dependent Distributions over Diffeomorphisms for Learned Data Augmentation
- **Arxiv ID**: http://arxiv.org/abs/1510.02795v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.02795v2)
- **Published**: 2015-10-09 20:00:47+00:00
- **Updated**: 2016-06-30 06:12:38+00:00
- **Authors**: SÃ¸ren Hauberg, Oren Freifeld, Anders Boesen Lindbo Larsen, John W. Fisher III, Lars Kai Hansen
- **Comment**: None
- **Journal**: Proceedings of the 19th International Conference on Artificial
  Intelligence and Statistics, pp. 342-350, 2016
- **Summary**: Data augmentation is a key element in training high-dimensional models. In this approach, one synthesizes new observations by applying pre-specified transformations to the original training data; e.g.~new images are formed by rotating old ones. Current augmentation schemes, however, rely on manual specification of the applied transformations, making data augmentation an implicit form of feature engineering. With an eye towards true end-to-end learning, we suggest learning the applied transformations on a per-class basis. Particularly, we align image pairs within each class under the assumption that the spatial transformation between images belongs to a large class of diffeomorphisms. We then learn a class-specific probabilistic generative models of the transformations in a Riemannian submanifold of the Lie group of diffeomorphisms. We demonstrate significant performance improvements in training deep neural nets over manually-specified augmentation schemes. Our code and augmented datasets are available online.



