# Arxiv Papers in cs.CV on 2015-10-17
### Integral Images: Efficient Algorithms for Their Computation and Storage in Resource-Constrained Embedded Vision Systems
- **Arxiv ID**: http://arxiv.org/abs/1510.05138v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05138v1)
- **Published**: 2015-10-17 15:41:26+00:00
- **Updated**: 2015-10-17 15:41:26+00:00
- **Authors**: Shoaib Ehsan, Adrian F. Clark, Naveed ur Rehman, Klaus D. McDonald-Maier
- **Comment**: None
- **Journal**: Sensors 2015, 15, 16804-16830
- **Summary**: The integral image, an intermediate image representation, has found extensive use in multi-scale local feature detection algorithms, such as Speeded-Up Robust Features (SURF), allowing fast computation of rectangular features at constant speed, independent of filter size. For resource-constrained real-time embedded vision systems, computation and storage of integral image presents several design challenges due to strict timing and hardware limitations. Although calculation of the integral image only consists of simple addition operations, the total number of operations is large owing to the generally large size of image data. Recursive equations allow substantial decrease in the number of operations but require calculation in a serial fashion. This paper presents two new hardware algorithms that are based on the decomposition of these recursive equations, allowing calculation of up to four integral image values in a row-parallel way without significantly increasing the number of operations. An efficient design strategy is also proposed for a parallel integral image computation unit to reduce the size of the required internal memory (nearly 35% for common HD video). Addressing the storage problem of integral image in embedded vision systems, the paper presents two algorithms which allow substantial decrease (at least 44.44%) in the memory requirements. Finally, the paper provides a case study that highlights the utility of the proposed architectures in embedded vision systems.



### Memory-Efficient Design Strategy for a Parallel Embedded Integral Image Computation Engine
- **Arxiv ID**: http://arxiv.org/abs/1510.05142v1
- **DOI**: 10.1109/IMVIP.2011.29
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05142v1)
- **Published**: 2015-10-17 16:04:33+00:00
- **Updated**: 2015-10-17 16:04:33+00:00
- **Authors**: Shoaib Ehsan, Adrian F. Clark, Wah M. Cheung, Arjunsingh M. Bais, Bayar I. Menzat, Nadia Kanwal, Klaus D. McDonald-Maier
- **Comment**: Machine Vision and Image Processing Conference (IMVIP), 2011
- **Journal**: None
- **Summary**: In embedded vision systems, parallel computation of the integral image presents several design challenges in terms of hardware resources, speed and power consumption. Although recursive equations significantly reduce the number of operations for computing the integral image, the required internal memory becomes prohibitively large for an embedded integral image computation engine for increasing image sizes. With the objective of achieving high-throughput with minimum hardware resources, this paper proposes a memory-efficient design strategy for a parallel embedded integral image computation engine. Results show that the design achieves nearly 35% reduction in memory for common HD video.



### Rapid Online Analysis of Local Feature Detectors and Their Complementarity
- **Arxiv ID**: http://arxiv.org/abs/1510.05145v1
- **DOI**: 10.3390/s130810876
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05145v1)
- **Published**: 2015-10-17 16:14:11+00:00
- **Updated**: 2015-10-17 16:14:11+00:00
- **Authors**: Shoaib Ehsan, Adrian F. Clark, Klaus D. McDonald-Maier
- **Comment**: None
- **Journal**: Sensors 2013, 13, 10876-10907
- **Summary**: A vision system that can assess its own performance and take appropriate actions online to maximize its effectiveness would be a step towards achieving the long-cherished goal of imitating humans. This paper proposes a method for performing an online performance analysis of local feature detectors, the primary stage of many practical vision systems. It advocates the spatial distribution of local image features as a good performance indicator and presents a metric that can be calculated rapidly, concurs with human visual assessments and is complementary to existing offline measures such as repeatability. The metric is shown to provide a measure of complementarity for combinations of detectors, correctly reflecting the underlying principles of individual detectors. Qualitative results on well-established datasets for several state-of-the-art detectors are presented based on the proposed measure. Using a hypothesis testing approach and a newly-acquired, larger image database, statistically-significant performance differences are identified. Different detector pairs and triplets are examined quantitatively and the results provide a useful guideline for combining detectors in applications that require a reasonable spatial distribution of image features. A principled framework for combining feature detectors in these applications is also presented. Timing results reveal the potential of the metric for online applications.



### Assessing The Performance Bounds Of Local Feature Detectors: Taking Inspiration From Electronics Design Practices
- **Arxiv ID**: http://arxiv.org/abs/1510.05156v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05156v1)
- **Published**: 2015-10-17 19:07:44+00:00
- **Updated**: 2015-10-17 19:07:44+00:00
- **Authors**: Shoaib Ehsan, Adrian F. Clark, Bruno Ferrarini, Naveed Ur Rehman, Klaus D. McDonald-Maier
- **Comment**: IWSSIP 2015
- **Journal**: None
- **Summary**: Since local feature detection has been one of the most active research areas in computer vision, a large number of detectors have been proposed. This has rendered the task of characterizing the performance of various feature detection methods an important issue in vision research. Inspired by the good practices of electronic system design, a generic framework based on the improved repeatability measure is presented in this paper that allows assessment of the upper and lower bounds of detector performance in an effort to design more reliable and effective vision systems. This framework is then employed to establish operating and guarantee regions for several state-of-the art detectors for JPEG compression and uniform light changes. The results are obtained using a newly acquired, large image database (15092 images) with 539 different scenes. These results provide new insights into the behavior of detectors and are also useful from the vision systems design perspective.



### Performance Characterization of Image Feature Detectors in Relation to the Scene Content Utilizing a Large Image Database
- **Arxiv ID**: http://arxiv.org/abs/1510.05157v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/1510.05157v1)
- **Published**: 2015-10-17 19:13:10+00:00
- **Updated**: 2015-10-17 19:13:10+00:00
- **Authors**: Bruno Ferrarini, Shoaib Ehsan, Naveed Ur Rehman, Klaus D. McDonald-Maier
- **Comment**: IWSSIP 2015
- **Journal**: None
- **Summary**: Selecting the most suitable local invariant feature detector for a particular application has rendered the task of evaluating feature detectors a critical issue in vision research. No state-of-the-art image feature detector works satisfactorily under all types of image transformations. Although the literature offers a variety of comparison works focusing on performance evaluation of image feature detectors under several types of image transformation, the influence of the scene content on the performance of local feature detectors has received little attention so far. This paper aims to bridge this gap with a new framework for determining the type of scenes, which maximize and minimize the performance of detectors in terms of repeatability rate. Several state-of-the-art feature detectors have been assessed utilizing a large database of 12936 images generated by applying uniform light and blur changes to 539 scenes captured from the real world. The results obtained provide new insights into the behaviour of feature detectors.



