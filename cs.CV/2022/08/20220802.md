# Arxiv Papers in cs.CV on 2022-08-02
### Curved Geometric Networks for Visual Anomaly Recognition
- **Arxiv ID**: http://arxiv.org/abs/2208.01188v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01188v1)
- **Published**: 2022-08-02 01:15:39+00:00
- **Updated**: 2022-08-02 01:15:39+00:00
- **Authors**: Jie Hong, Pengfei Fang, Weihao Li, Junlin Han, Lars Petersson, Mehrtash Harandi
- **Comment**: None
- **Journal**: None
- **Summary**: Learning a latent embedding to understand the underlying nature of data distribution is often formulated in Euclidean spaces with zero curvature. However, the success of the geometry constraints, posed in the embedding space, indicates that curved spaces might encode more structural information, leading to better discriminative power and hence richer representations. In this work, we investigate benefits of the curved space for analyzing anomalies or out-of-distribution objects in data. This is achieved by considering embeddings via three geometry constraints, namely, spherical geometry (with positive curvature), hyperbolic geometry (with negative curvature) or mixed geometry (with both positive and negative curvatures). Three geometric constraints can be chosen interchangeably in a unified design given the task at hand. Tailored for the embeddings in the curved space, we also formulate functions to compute the anomaly score. Two types of geometric modules (i.e., Geometric-in-One and Geometric-in-Two models) are proposed to plug in the original Euclidean classifier, and anomaly scores are computed from the curved embeddings. We evaluate the resulting designs under a diverse set of visual recognition scenarios, including image detection (multi-class OOD detection and one-class anomaly detection) and segmentation (multi-class anomaly segmentation and one-class anomaly segmentation). The empirical results show the effectiveness of our proposal through the consistent improvement over various scenarios.



### Making the Best of Both Worlds: A Domain-Oriented Transformer for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2208.01195v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01195v1)
- **Published**: 2022-08-02 01:38:37+00:00
- **Updated**: 2022-08-02 01:38:37+00:00
- **Authors**: Wenxuan Ma, Jinming Zhang, Shuang Li, Chi Harold Liu, Yulin Wang, Wei Li
- **Comment**: Accepted at ACMMM 2022
- **Journal**: None
- **Summary**: Extensive studies on Unsupervised Domain Adaptation (UDA) have propelled the deployment of deep learning from limited experimental datasets into real-world unconstrained domains. Most UDA approaches align features within a common embedding space and apply a shared classifier for target prediction. However, since a perfectly aligned feature space may not exist when the domain discrepancy is large, these methods suffer from two limitations. First, the coercive domain alignment deteriorates target domain discriminability due to lacking target label supervision. Second, the source-supervised classifier is inevitably biased to source data, thus it may underperform in target domain. To alleviate these issues, we propose to simultaneously conduct feature alignment in two individual spaces focusing on different domains, and create for each space a domain-oriented classifier tailored specifically for that domain. Specifically, we design a Domain-Oriented Transformer (DOT) that has two individual classification tokens to learn different domain-oriented representations, and two classifiers to preserve domain-wise discriminability. Theoretical guaranteed contrastive-based alignment and the source-guided pseudo-label refinement strategy are utilized to explore both domain-invariant and specific information. Comprehensive experiments validate that our method achieves state-of-the-art on several benchmarks.



### Making a Spiking Net Work: Robust brain-like unsupervised machine learning
- **Arxiv ID**: http://arxiv.org/abs/2208.01204v2
- **DOI**: None
- **Categories**: **cs.NE**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01204v2)
- **Published**: 2022-08-02 02:10:00+00:00
- **Updated**: 2022-09-01 00:32:25+00:00
- **Authors**: Peter G. Stratton, Andrew Wabnitz, Chip Essam, Allen Cheung, Tara J. Hamilton
- **Comment**: 12 pages (manuscript), 5 figures, 10 pages (appendix), 11 pages
  (extended data)
- **Journal**: None
- **Summary**: The surge in interest in Artificial Intelligence (AI) over the past decade has been driven almost exclusively by advances in Artificial Neural Networks (ANNs). While ANNs set state-of-the-art performance for many previously intractable problems, the use of global gradient descent necessitates large datasets and computational resources for training, potentially limiting their scalability for real-world domains. Spiking Neural Networks (SNNs) are an alternative to ANNs that use more brain-like artificial neurons and can use local unsupervised learning to rapidly discover sparse recognizable features in the input data. SNNs, however, struggle with dynamical stability and have failed to match the accuracy of ANNs. Here we show how an SNN can overcome many of the shortcomings that have been identified in the literature, including offering a principled solution to the dynamical "vanishing spike problem", to outperform all existing shallow SNNs and equal the performance of an ANN. It accomplishes this while using unsupervised learning with unlabeled data and only 1/50th of the training epochs (labeled data is used only for a simple linear readout layer). This result makes SNNs a viable new method for fast, accurate, efficient, explainable, and re-deployable machine learning with unlabeled data.



### Streaming-capable High-performance Architecture of Learned Image Compression Codecs
- **Arxiv ID**: http://arxiv.org/abs/2208.01641v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01641v1)
- **Published**: 2022-08-02 03:15:48+00:00
- **Updated**: 2022-08-02 03:15:48+00:00
- **Authors**: Fangzheng Lin, Heming Sun, Jiro Katto
- **Comment**: Accepted to IEEE ICIP 2022
- **Journal**: None
- **Summary**: Learned image compression allows achieving state-of-the-art accuracy and compression ratios, but their relatively slow runtime performance limits their usage. While previous attempts on optimizing learned image codecs focused more on the neural model and entropy coding, we present an alternative method to improving the runtime performance of various learned image compression models. We introduce multi-threaded pipelining and an optimized memory model to enable GPU and CPU workloads asynchronous execution, fully taking advantage of computational resources. Our architecture alone already produces excellent performance without any change to the neural model itself. We also demonstrate that combining our architecture with previous tweaks to the neural models can further improve runtime performance. We show that our implementations excel in throughput and latency compared to the baseline and demonstrate the performance of our implementations by creating a real-time video streaming encoder-decoder sample application, with the encoder running on an embedded device.



### A Novel Transformer Network with Shifted Window Cross-Attention for Spatiotemporal Weather Forecasting
- **Arxiv ID**: http://arxiv.org/abs/2208.01252v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01252v1)
- **Published**: 2022-08-02 05:04:53+00:00
- **Updated**: 2022-08-02 05:04:53+00:00
- **Authors**: Alabi Bojesomo, Hasan Al Marzouqi, Panos Liatsis
- **Comment**: 16 pages, 7 figures, 7 tables
- **Journal**: None
- **Summary**: Earth Observatory is a growing research area that can capitalize on the powers of AI for short time forecasting, a Now-casting scenario. In this work, we tackle the challenge of weather forecasting using a video transformer network. Vision transformer architectures have been explored in various applications, with major constraints being the computational complexity of Attention and the data hungry training. To address these issues, we propose the use of Video Swin-Transformer, coupled with a dedicated augmentation scheme. Moreover, we employ gradual spatial reduction on the encoder side and cross-attention on the decoder. The proposed approach is tested on the Weather4Cast2021 weather forecasting challenge data, which requires the prediction of 8 hours ahead future frames (4 per hour) from an hourly weather product sequence. The dataset was normalized to 0-1 to facilitate using the evaluation metrics across different datasets. The model results in an MSE score of 0.4750 when provided with training data, and 0.4420 during transfer learning without using training data, respectively.



### A Robust Morphological Approach for Semantic Segmentation of Very High Resolution Images
- **Arxiv ID**: http://arxiv.org/abs/2208.01254v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01254v1)
- **Published**: 2022-08-02 05:25:35+00:00
- **Updated**: 2022-08-02 05:25:35+00:00
- **Authors**: Siddharth Saravanan, Aditya Challa, Sravan Danda
- **Comment**: Under review at IEEE Transactions on Image Processing
- **Journal**: None
- **Summary**: State-of-the-art methods for semantic segmentation of images involve computationally intensive neural network architectures. Most of these methods are not adaptable to high-resolution image segmentation due to memory and other computational issues. Typical approaches in literature involve design of neural network architectures that can fuse global information from low-resolution images and local information from the high-resolution counterparts. However, architectures designed for processing high resolution images are unnecessarily complex and involve a lot of hyper parameters that can be difficult to tune. Also, most of these architectures require ground truth annotations of the high resolution images to train, which can be hard to obtain. In this article, we develop a robust pipeline based on mathematical morphological (MM) operators that can seamlessly extend any existing semantic segmentation algorithm to high resolution images. Our method does not require the ground truth annotations of the high resolution images. It is based on efficiently utilizing information from the low-resolution counterparts, and gradient information on the high-resolution images. We obtain high quality seeds from the inferred labels on low-resolution images using traditional morphological operators and propagate seed labels using a random walker to refine the semantic labels at the boundaries. We show that the semantic segmentation results obtained by our method beat the existing state-of-the-art algorithms on high-resolution images. We empirically prove the robustness of our approach to the hyper parameters used in our pipeline. Further, we characterize some necessary conditions under which our pipeline is applicable and provide an in-depth analysis of the proposed approach.



### Explicit Use of Fourier Spectrum in Generative Adversarial Networks
- **Arxiv ID**: http://arxiv.org/abs/2208.01265v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01265v1)
- **Published**: 2022-08-02 06:26:44+00:00
- **Updated**: 2022-08-02 06:26:44+00:00
- **Authors**: Soroush Sheikh Gargar
- **Comment**: Masters thesis
- **Journal**: None
- **Summary**: Generative Adversarial Networks have got the researchers' attention due to their state-of-the-art performance in generating new images with only a dataset of the target distribution. It has been shown that there is a dissimilarity between the spectrum of authentic images and fake ones. Since the Fourier transform is a bijective mapping, saying that the model has a significant problem in learning the original distribution is a fair conclusion. In this work, we investigate the possible reasons for the mentioned drawback in the architecture and mathematical theory of the current GANs. Then we propose a new model to reduce the discrepancies between the spectrum of the actual and fake images. To that end, we design a brand new architecture for the frequency domain using the blueprint of geometric deep learning. Then, we experimentally show promising improvements in the quality of the generated images by considering the Fourier domain representation of the original data as a principal feature in the training process.



### In-Hand Pose Estimation and Pin Inspection for Insertion of Through-Hole Components
- **Arxiv ID**: http://arxiv.org/abs/2208.01284v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01284v1)
- **Published**: 2022-08-02 07:13:24+00:00
- **Updated**: 2022-08-02 07:13:24+00:00
- **Authors**: Frederik Hagelskjaer, Dirk Kraft
- **Comment**: 8 pages, 11 figures, 3 tables
- **Journal**: None
- **Summary**: The insertion of through-hole components is a difficult task. As the tolerances of the holes are very small, minor errors in the insertion will result in failures. These failures can damage components and will require manual intervention for recovery. Errors can occur both from imprecise object grasps and bent pins. Therefore, it is important that a system can accurately determine the object's position and reject components with bent pins. By utilizing the constraints inherent in the object grasp a method using template matching is able to obtain very precise pose estimates. Methods for pin-checking are also implemented, compared, and a successful method is shown. The set-up is performed automatically, with two novel contributions. A deep learning segmentation of the pins is performed and the inspection pose is found by simulation. From the inspection pose and the segmented pins, the templates for pose estimation and pin check are then generated. To train the deep learning method a dataset of segmented through-hole components is created. The network shows a 97.3 % accuracy on the test set. The pin-segmentation network is also tested on the insertion CAD models and successfully segment the pins. The complete system is tested on three different objects, and experiments show that the system is able to insert all objects successfully. Both by correcting in-hand grasp errors and rejecting objects with bent pins.



### Multiview Regenerative Morphing with Dual Flows
- **Arxiv ID**: http://arxiv.org/abs/2208.01287v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01287v1)
- **Published**: 2022-08-02 07:22:48+00:00
- **Updated**: 2022-08-02 07:22:48+00:00
- **Authors**: Chih-Jung Tsai, Cheng Sun, Hwann-Tzong Chen
- **Comment**: None
- **Journal**: None
- **Summary**: This paper aims to address a new task of image morphing under a multiview setting, which takes two sets of multiview images as the input and generates intermediate renderings that not only exhibit smooth transitions between the two input sets but also ensure visual consistency across different views at any transition state. To achieve this goal, we propose a novel approach called Multiview Regenerative Morphing that formulates the morphing process as an optimization to solve for rigid transformation and optimal-transport interpolation. Given the multiview input images of the source and target scenes, we first learn a volumetric representation that models the geometry and appearance for each scene to enable the rendering of novel views. Then, the morphing between the two scenes is obtained by solving optimal transport between the two volumetric representations in Wasserstein metrics. Our approach does not rely on user-specified correspondences or 2D/3D input meshes, and we do not assume any predefined categories of the source and target scenes. The proposed view-consistent interpolation scheme directly works on multiview images to yield a novel and visually plausible effect of multiview free-form morphing.



### Overlooked Poses Actually Make Sense: Distilling Privileged Knowledge for Human Motion Prediction
- **Arxiv ID**: http://arxiv.org/abs/2208.01302v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01302v1)
- **Published**: 2022-08-02 08:13:43+00:00
- **Updated**: 2022-08-02 08:13:43+00:00
- **Authors**: Xiaoning Sun, Qiongjie Cui, Huaijiang Sun, Bin Li, Weiqing Li, Jianfeng Lu
- **Comment**: accepted by ECCV2022
- **Journal**: None
- **Summary**: Previous works on human motion prediction follow the pattern of building a mapping relation between the sequence observed and the one to be predicted. However, due to the inherent complexity of multivariate time series data, it still remains a challenge to find the extrapolation relation between motion sequences. In this paper, we present a new prediction pattern, which introduces previously overlooked human poses, to implement the prediction task from the view of interpolation. These poses exist after the predicted sequence, and form the privileged sequence. To be specific, we first propose an InTerPolation learning Network (ITP-Network) that encodes both the observed sequence and the privileged sequence to interpolate the in-between predicted sequence, wherein the embedded Privileged-sequence-Encoder (Priv-Encoder) learns the privileged knowledge (PK) simultaneously. Then, we propose a Final Prediction Network (FP-Network) for which the privileged sequence is not observable, but is equipped with a novel PK-Simulator that distills PK learned from the previous network. This simulator takes as input the observed sequence, but approximates the behavior of Priv-Encoder, enabling FP-Network to imitate the interpolation process. Extensive experimental results demonstrate that our prediction pattern achieves state-of-the-art performance on benchmarked H3.6M, CMU-Mocap and 3DPW datasets in both short-term and long-term predictions.



### Unified Normalization for Accelerating and Stabilizing Transformers
- **Arxiv ID**: http://arxiv.org/abs/2208.01313v1
- **DOI**: 10.1145/3503161.3547860
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2208.01313v1)
- **Published**: 2022-08-02 08:41:31+00:00
- **Updated**: 2022-08-02 08:41:31+00:00
- **Authors**: Qiming Yang, Kai Zhang, Chaoxiang Lan, Zhi Yang, Zheyang Li, Wenming Tan, Jun Xiao, Shiliang Pu
- **Comment**: ACM MM'22
- **Journal**: None
- **Summary**: Solid results from Transformers have made them prevailing architectures in various natural language and vision tasks. As a default component in Transformers, Layer Normalization (LN) normalizes activations within each token to boost the robustness. However, LN requires on-the-fly statistics calculation in inference as well as division and square root operations, leading to inefficiency on hardware. What is more, replacing LN with other hardware-efficient normalization schemes (e.g., Batch Normalization) results in inferior performance, even collapse in training. We find that this dilemma is caused by abnormal behaviors of activation statistics, including large fluctuations over iterations and extreme outliers across layers. To tackle these issues, we propose Unified Normalization (UN), which can speed up the inference by being fused with other linear operations and achieve comparable performance on par with LN. UN strives to boost performance by calibrating the activation and gradient statistics with a tailored fluctuation smoothing strategy. Meanwhile, an adaptive outlier filtration strategy is applied to avoid collapse in training whose effectiveness is theoretically proved and experimentally verified in this paper. We demonstrate that UN can be an efficient drop-in alternative to LN by conducting extensive experiments on language and vision tasks. Besides, we evaluate the efficiency of our method on GPU. Transformers equipped with UN enjoy about 31% inference speedup and nearly 18% memory reduction. Code will be released at https://github.com/hikvision-research/Unified-Normalization.



### CTooth+: A Large-scale Dental Cone Beam Computed Tomography Dataset and Benchmark for Tooth Volume Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2208.01643v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01643v1)
- **Published**: 2022-08-02 09:13:23+00:00
- **Updated**: 2022-08-02 09:13:23+00:00
- **Authors**: Weiwei Cui, Yaqi Wang, Yilong Li, Dan Song, Xingyong Zuo, Jiaojiao Wang, Yifan Zhang, Huiyu Zhou, Bung san Chong, Liaoyuan Zeng, Qianni Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Accurate tooth volume segmentation is a prerequisite for computer-aided dental analysis. Deep learning-based tooth segmentation methods have achieved satisfying performances but require a large quantity of tooth data with ground truth. The dental data publicly available is limited meaning the existing methods can not be reproduced, evaluated and applied in clinical practice. In this paper, we establish a 3D dental CBCT dataset CTooth+, with 22 fully annotated volumes and 146 unlabeled volumes. We further evaluate several state-of-the-art tooth volume segmentation strategies based on fully-supervised learning, semi-supervised learning and active learning, and define the performance principles. This work provides a new benchmark for the tooth volume segmentation task, and the experiment can serve as the baseline for future AI-based dental imaging research and clinical application development.



### Self-Supervised Traversability Prediction by Learning to Reconstruct Safe Terrain
- **Arxiv ID**: http://arxiv.org/abs/2208.01329v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01329v1)
- **Published**: 2022-08-02 09:24:39+00:00
- **Updated**: 2022-08-02 09:24:39+00:00
- **Authors**: Robin Schmid, Deegan Atha, Frederik Schöller, Sharmita Dey, Seyed Fakoorian, Kyohei Otsu, Barry Ridge, Marko Bjelonic, Lorenz Wellhausen, Marco Hutter, Ali-akbar Agha-mohammadi
- **Comment**: None
- **Journal**: None
- **Summary**: Navigating off-road with a fast autonomous vehicle depends on a robust perception system that differentiates traversable from non-traversable terrain. Typically, this depends on a semantic understanding which is based on supervised learning from images annotated by a human expert. This requires a significant investment in human time, assumes correct expert classification, and small details can lead to misclassification. To address these challenges, we propose a method for predicting high- and low-risk terrains from only past vehicle experience in a self-supervised fashion. First, we develop a tool that projects the vehicle trajectory into the front camera image. Second, occlusions in the 3D representation of the terrain are filtered out. Third, an autoencoder trained on masked vehicle trajectory regions identifies low- and high-risk terrains based on the reconstruction error. We evaluated our approach with two models and different bottleneck sizes with two different training and testing sites with a fourwheeled off-road vehicle. Comparison with two independent test sets of semantic labels from similar terrain as training sites demonstrates the ability to separate the ground as low-risk and the vegetation as high-risk with 81.1% and 85.1% accuracy.



### What can we Learn by Predicting Accuracy?
- **Arxiv ID**: http://arxiv.org/abs/2208.01358v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01358v2)
- **Published**: 2022-08-02 10:58:17+00:00
- **Updated**: 2022-08-23 13:36:31+00:00
- **Authors**: Olivier Risser-Maroix, Benjamin Chamand
- **Comment**: None
- **Journal**: None
- **Summary**: This paper seeks to answer the following question: \textit{"What can we learn by predicting accuracy?"}.   Indeed, classification is one of the most popular tasks in machine learning, and many loss functions have been developed to maximize this non-differentiable objective function.   Unlike past work on loss function design, which was guided mainly by intuition and theory before being validated by experimentation, here we propose to approach this problem in the opposite way: we seek to extract knowledge by experimentation.   This data-driven approach is similar to that used in physics to discover general laws from data.   We used a symbolic regression method to automatically find a mathematical expression highly correlated with a linear classifier's accuracy.   The formula discovered on more than 260 datasets of embeddings has a Pearson's correlation of 0.96 and a $r^2$ of 0.93.   More interestingly, this formula is highly explainable and confirms insights from various previous papers on loss design.   We hope this work will open new perspectives in the search for new heuristics leading to a deeper understanding of machine learning theory.



### The Face of Affective Disorders
- **Arxiv ID**: http://arxiv.org/abs/2208.01369v3
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, q-bio.NC
- **Links**: [PDF](http://arxiv.org/pdf/2208.01369v3)
- **Published**: 2022-08-02 11:28:17+00:00
- **Updated**: 2022-09-05 08:02:52+00:00
- **Authors**: Christian S. Pilz, Benjamin Clemens, Inka C. Hiss, Christoph Weiss, Ulrich Canzler, Jarek Krajewski, Ute Habel, Steffen Leonhardt
- **Comment**: 15 pages. Submitted for Peer Review to the IEEE Transaction on
  Affective Computing
- **Journal**: None
- **Summary**: We study the statistical properties of facial behaviour altered by the regulation of brain arousal in the clinical domain of psychiatry. The underlying mechanism is linked to the empirical interpretation of the vigilance continuum as behavioral surrogate measurement for certain states of mind. Referring to the classical scalp-based obtrusive measurements, we name the presented method Opto-Electronic Encephalography (OEG) which solely relies on modern camera-based real-time signal processing and computer vision. Based upon a stochastic representation as coherence of the face dynamics, reflecting the hemifacial asymmetry in emotion expressions, we demonstrate an almost flawless distinction between patients and healthy controls as well as between the mental disorders depression and schizophrenia and the symptom severity. In contrast to the standard diagnostic process, which is time-consuming, subjective and does not incorporate neurobiological data such as real-time face dynamics, the objective stochastic modeling of the affective responsiveness only requires a few minutes of video-based facial recordings. We also highlight the potential of the methodology as a causal inference model in transdiagnostic analysis to predict the outcome of pharmacological treatment. All results are obtained on a clinical longitudinal data collection with an amount of 99 patients and 43 controls.



### GaitGL: Learning Discriminative Global-Local Feature Representations for Gait Recognition
- **Arxiv ID**: http://arxiv.org/abs/2208.01380v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01380v1)
- **Published**: 2022-08-02 11:50:21+00:00
- **Updated**: 2022-08-02 11:50:21+00:00
- **Authors**: Beibei Lin, Shunli Zhang, Ming Wang, Lincheng Li, Xin Yu
- **Comment**: None
- **Journal**: None
- **Summary**: Existing gait recognition methods either directly establish Global Feature Representation (GFR) from original gait sequences or generate Local Feature Representation (LFR) from several local parts. However, GFR tends to neglect local details of human postures as the receptive fields become larger in the deeper network layers. Although LFR allows the network to focus on the detailed posture information of each local region, it neglects the relations among different local parts and thus only exploits limited local information of several specific regions. To solve these issues, we propose a global-local based gait recognition network, named GaitGL, to generate more discriminative feature representations. To be specific, a novel Global and Local Convolutional Layer (GLCL) is developed to take full advantage of both global visual information and local region details in each layer. GLCL is a dual-branch structure that consists of a GFR extractor and a mask-based LFR extractor. GFR extractor aims to extract contextual information, e.g., the relationship among various body parts, and the mask-based LFR extractor is presented to exploit the detailed posture changes of local regions. In addition, we introduce a novel mask-based strategy to improve the local feature extraction capability. Specifically, we design pairs of complementary masks to randomly occlude feature maps, and then train our mask-based LFR extractor on various occluded feature maps. In this manner, the LFR extractor will learn to fully exploit local information. Extensive experiments demonstrate that GaitGL achieves better performance than state-of-the-art gait recognition methods. The average rank-1 accuracy on CASIA-B, OU-MVLP, GREW and Gait3D is 93.6%, 98.7%, 68.0% and 63.8%, respectively, significantly outperforming the competing methods. The proposed method has won the first prize in two competitions: HID 2020 and HID 2021.



### A New Probabilistic V-Net Model with Hierarchical Spatial Feature Transform for Efficient Abdominal Multi-Organ Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2208.01382v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01382v1)
- **Published**: 2022-08-02 11:51:46+00:00
- **Updated**: 2022-08-02 11:51:46+00:00
- **Authors**: Minfeng Xu, Heng Guo, Jianfeng Zhang, Ke Yan, Le Lu
- **Comment**: 12 pages, 6 figures
- **Journal**: None
- **Summary**: Accurate and robust abdominal multi-organ segmentation from CT imaging of different modalities is a challenging task due to complex inter- and intra-organ shape and appearance variations among abdominal organs. In this paper, we propose a probabilistic multi-organ segmentation network with hierarchical spatial-wise feature modulation to capture flexible organ semantic variants and inject the learnt variants into different scales of feature maps for guiding segmentation. More specifically, we design an input decomposition module via a conditional variational auto-encoder to learn organ-specific distributions on the low dimensional latent space and model richer organ semantic variations that is conditioned on input images.Then by integrating these learned variations into the V-Net decoder hierarchically via spatial feature transformation, which has the ability to convert the variations into conditional Affine transformation parameters for spatial-wise feature maps modulating and guiding the fine-scale segmentation. The proposed method is trained on the publicly available AbdomenCT-1K dataset and evaluated on two other open datasets, i.e., 100 challenging/pathological testing patient cases from AbdomenCT-1K fully-supervised abdominal organ segmentation benchmark and 90 cases from TCIA+&BTCV dataset. Highly competitive or superior quantitative segmentation results have been achieved using these datasets for four abdominal organs of liver, kidney, spleen and pancreas with reported Dice scores improved by 7.3% for kidneys and 9.7% for pancreas, while being ~7 times faster than two strong baseline segmentation methods(nnUNet and CoTr).



### T4DT: Tensorizing Time for Learning Temporal 3D Visual Data
- **Arxiv ID**: http://arxiv.org/abs/2208.01421v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01421v2)
- **Published**: 2022-08-02 12:57:08+00:00
- **Updated**: 2022-10-05 16:33:52+00:00
- **Authors**: Mikhail Usvyatsov, Rafael Ballester-Rippoll, Lina Bashaeva, Konrad Schindler, Gonzalo Ferrer, Ivan Oseledets
- **Comment**: None
- **Journal**: None
- **Summary**: Unlike 2D raster images, there is no single dominant representation for 3D visual data processing. Different formats like point clouds, meshes, or implicit functions each have their strengths and weaknesses. Still, grid representations such as signed distance functions have attractive properties also in 3D. In particular, they offer constant-time random access and are eminently suitable for modern machine learning. Unfortunately, the storage size of a grid grows exponentially with its dimension. Hence they often exceed memory limits even at moderate resolution. This work proposes using low-rank tensor formats, including the Tucker, tensor train, and quantics tensor train decompositions, to compress time-varying 3D data. Our method iteratively computes, voxelizes, and compresses each frame's truncated signed distance function and applies tensor rank truncation to condense all frames into a single, compressed tensor that represents the entire 4D scene. We show that low-rank tensor compression is extremely compact to store and query time-varying signed distance functions. It significantly reduces the memory footprint of 4D scenes while remarkably preserving their geometric quality. Unlike existing, iterative learning-based approaches like DeepSDF and NeRF, our method uses a closed-form algorithm with theoretical guarantees.



### Connection Reduction of DenseNet for Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/2208.01424v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01424v3)
- **Published**: 2022-08-02 13:00:35+00:00
- **Updated**: 2022-11-15 04:36:26+00:00
- **Authors**: Rui-Yang Ju, Jen-Shiun Chiang, Chih-Chia Chen, Yu-Shian Lin
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional Neural Networks (CNN) increase depth by stacking convolutional layers, and deeper network models perform better in image recognition. Empirical research shows that simply stacking convolutional layers does not make the network train better, and skip connection (residual learning) can improve network model performance. For the image classification task, models with global densely connected architectures perform well in large datasets like ImageNet, but are not suitable for small datasets such as CIFAR-10 and SVHN. Different from dense connections, we propose two new algorithms to connect layers. Baseline is a densely connected network, and the networks connected by the two new algorithms are named ShortNet1 and ShortNet2 respectively. The experimental results of image classification on CIFAR-10 and SVHN show that ShortNet1 has a 5% lower test error rate and 25% faster inference time than Baseline. ShortNet2 speeds up inference time by 40% with less loss in test accuracy. Code and pre-trained models are available at https://github.com/RuiyangJu/Connection_Reduction.



### IterMiUnet: A lightweight architecture for automatic blood vessel segmentation
- **Arxiv ID**: http://arxiv.org/abs/2208.01485v1
- **DOI**: 10.1007/s11042-023-15433-7
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01485v1)
- **Published**: 2022-08-02 14:33:14+00:00
- **Updated**: 2022-08-02 14:33:14+00:00
- **Authors**: Ashish Kumar, R. K. Agrawal, Leve Joseph
- **Comment**: None
- **Journal**: None
- **Summary**: The automatic segmentation of blood vessels in fundus images can help analyze the condition of retinal vasculature, which is crucial for identifying various systemic diseases like hypertension, diabetes, etc. Despite the success of Deep Learning-based models in this segmentation task, most of them are heavily parametrized and thus have limited use in practical applications. This paper proposes IterMiUnet, a new lightweight convolution-based segmentation model that requires significantly fewer parameters and yet delivers performance similar to existing models. The model makes use of the excellent segmentation capabilities of Iternet architecture but overcomes its heavily parametrized nature by incorporating the encoder-decoder structure of MiUnet model within it. Thus, the new model reduces parameters without any compromise with the network's depth, which is necessary to learn abstract hierarchical concepts in deep models. This lightweight segmentation model speeds up training and inference time and is potentially helpful in the medical domain where data is scarce and, therefore, heavily parametrized models tend to overfit. The proposed model was evaluated on three publicly available datasets: DRIVE, STARE, and CHASE-DB1. Further cross-training and inter-rater variability evaluations have also been performed. The proposed model has a lot of potential to be utilized as a tool for the early diagnosis of many diseases.



### Deconstructing Self-Supervised Monocular Reconstruction: The Design Decisions that Matter
- **Arxiv ID**: http://arxiv.org/abs/2208.01489v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01489v4)
- **Published**: 2022-08-02 14:38:53+00:00
- **Updated**: 2022-12-21 16:10:02+00:00
- **Authors**: Jaime Spencer, Chris Russell, Simon Hadfield, Richard Bowden
- **Comment**: https://github.com/jspenmar/monodepth_benchmark
- **Journal**: Transactions of Machine Learning Research 2022
- **Summary**: This paper presents an open and comprehensive framework to systematically evaluate state-of-the-art contributions to self-supervised monocular depth estimation. This includes pretraining, backbone, architectural design choices and loss functions. Many papers in this field claim novelty in either architecture design or loss formulation. However, simply updating the backbone of historical systems results in relative improvements of 25%, allowing them to outperform the majority of existing systems. A systematic evaluation of papers in this field was not straightforward. The need to compare like-with-like in previous papers means that longstanding errors in the evaluation protocol are ubiquitous in the field. It is likely that many papers were not only optimized for particular datasets, but also for errors in the data and evaluation criteria. To aid future research in this area, we release a modular codebase (https://github.com/jspenmar/monodepth_benchmark), allowing for easy evaluation of alternate design decisions against corrected data and evaluation criteria. We re-implement, validate and re-evaluate 16 state-of-the-art contributions and introduce a new dataset (SYNS-Patches) containing dense outdoor depth maps in a variety of both natural and urban scenes. This allows for the computation of informative metrics in complex regions such as depth boundaries.



### Maximal Independent Vertex Set applied to Graph Pooling
- **Arxiv ID**: http://arxiv.org/abs/2208.01648v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01648v1)
- **Published**: 2022-08-02 14:42:58+00:00
- **Updated**: 2022-08-02 14:42:58+00:00
- **Authors**: Stevan Stanovic, Benoit Gaüzère, Luc Brun
- **Comment**: None
- **Journal**: Structural and Syntactic Pattern Recognition (SSPR), Aug 2022,
  Montr{\'e}al, Canada
- **Summary**: Convolutional neural networks (CNN) have enabled major advances in image classification through convolution and pooling. In particular, image pooling transforms a connected discrete grid into a reduced grid with the same connectivity and allows reduction functions to take into account all the pixels of an image. However, a pooling satisfying such properties does not exist for graphs. Indeed, some methods are based on a vertex selection step which induces an important loss of information. Other methods learn a fuzzy clustering of vertex sets which induces almost complete reduced graphs. We propose to overcome both problems using a new pooling method, named MIVSPool. This method is based on a selection of vertices called surviving vertices using a Maximal Independent Vertex Set (MIVS) and an assignment of the remaining vertices to the survivors. Consequently, our method does not discard any vertex information nor artificially increase the density of the graph. Experimental results show an increase in accuracy for graph classification on various standard datasets.



### A Multi-body Tracking Framework - From Rigid Objects to Kinematic Structures
- **Arxiv ID**: http://arxiv.org/abs/2208.01502v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01502v2)
- **Published**: 2022-08-02 14:49:34+00:00
- **Updated**: 2023-02-14 08:19:35+00:00
- **Authors**: Manuel Stoiber, Martin Sundermeyer, Wout Boerdijk, Rudolph Triebel
- **Comment**: Submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence
- **Journal**: None
- **Summary**: Kinematic structures are very common in the real world. They range from simple articulated objects to complex mechanical systems. However, despite their relevance, most model-based 3D tracking methods only consider rigid objects. To overcome this limitation, we propose a flexible framework that allows the extension of existing 6DoF algorithms to kinematic structures. Our approach focuses on methods that employ Newton-like optimization techniques, which are widely used in object tracking. The framework considers both tree-like and closed kinematic structures and allows a flexible configuration of joints and constraints. To project equations from individual rigid bodies to a multi-body system, Jacobians are used. For closed kinematic chains, a novel formulation that features Lagrange multipliers is developed. In a detailed mathematical proof, we show that our constraint formulation leads to an exact kinematic solution and converges in a single iteration. Based on the proposed framework, we extend ICG, which is a state-of-the-art rigid object tracking algorithm, to multi-body tracking. For the evaluation, we create a highly-realistic synthetic dataset that features a large number of sequences and various robots. Based on this dataset, we conduct a wide variety of experiments that demonstrate the excellent performance of the developed framework and our multi-body tracker.



### DSR -- A dual subspace re-projection network for surface anomaly detection
- **Arxiv ID**: http://arxiv.org/abs/2208.01521v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01521v2)
- **Published**: 2022-08-02 15:15:29+00:00
- **Updated**: 2022-11-23 23:56:09+00:00
- **Authors**: Vitjan Zavrtanik, Matej Kristan, Danijel Skočaj
- **Comment**: Presented at ECCV2022
- **Journal**: None
- **Summary**: The state-of-the-art in discriminative unsupervised surface anomaly detection relies on external datasets for synthesizing anomaly-augmented training images. Such approaches are prone to failure on near-in-distribution anomalies since these are difficult to be synthesized realistically due to their similarity to anomaly-free regions. We propose an architecture based on quantized feature space representation with dual decoders, DSR, that avoids the image-level anomaly synthesis requirement. Without making any assumptions about the visual properties of anomalies, DSR generates the anomalies at the feature level by sampling the learned quantized feature space, which allows a controlled generation of near-in-distribution anomalies. DSR achieves state-of-the-art results on the KSDD2 and MVTec anomaly detection datasets. The experiments on the challenging real-world KSDD2 dataset show that DSR significantly outperforms other unsupervised surface anomaly detection methods, improving the previous top-performing methods by 10% AP in anomaly detection and 35% AP in anomaly localization.



### Texture features in medical image analysis: a survey
- **Arxiv ID**: http://arxiv.org/abs/2208.02046v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.02046v1)
- **Published**: 2022-08-02 15:31:10+00:00
- **Updated**: 2022-08-02 15:31:10+00:00
- **Authors**: Faeze Kiani
- **Comment**: None
- **Journal**: None
- **Summary**: The texture is defined as spatial structure of the intensities of the pixels in an image that is repeated periodically in the whole image or regions, and makes the concept of the image. Texture, color and shape are three main components which are used by human visual system to recognize image contents. In this paper, first of all, efficient and updated texture analysis operators are survived with details. Next, some state-of-the-art methods are survived that use texture analysis in medical applications and disease diagnosis. Finally, different approaches are compared in terms of accuracy, dataset, application, etc. Results demonstrate that texture features separately or in joint of different feature sets such as deep, color or shape features provide high accuracy in medical image classification.



### ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries
- **Arxiv ID**: http://arxiv.org/abs/2208.01582v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2208.01582v3)
- **Published**: 2022-08-02 16:38:28+00:00
- **Updated**: 2023-06-19 11:50:41+00:00
- **Authors**: Junru Gu, Chenxu Hu, Tianyuan Zhang, Xuanyao Chen, Yilun Wang, Yue Wang, Hang Zhao
- **Comment**: CVPR 2023
- **Journal**: None
- **Summary**: Perception and prediction are two separate modules in the existing autonomous driving systems. They interact with each other via hand-picked features such as agent bounding boxes and trajectories. Due to this separation, prediction, as a downstream module, only receives limited information from the perception module. To make matters worse, errors from the perception modules can propagate and accumulate, adversely affecting the prediction results. In this work, we propose ViP3D, a query-based visual trajectory prediction pipeline that exploits rich information from raw videos to directly predict future trajectories of agents in a scene. ViP3D employs sparse agent queries to detect, track, and predict throughout the pipeline, making it the first fully differentiable vision-based trajectory prediction approach. Instead of using historical feature maps and trajectories, useful information from previous timestamps is encoded in agent queries, which makes ViP3D a concise streaming prediction method. Furthermore, extensive experimental results on the nuScenes dataset show the strong vision-based prediction performance of ViP3D over traditional pipelines and previous end-to-end models.



### Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization
- **Arxiv ID**: http://arxiv.org/abs/2208.01587v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01587v2)
- **Published**: 2022-08-02 16:45:55+00:00
- **Updated**: 2022-10-05 02:28:09+00:00
- **Authors**: Xiang Gao, Yuqi Zhang, Yingjie Tian
- **Comment**: Proceedings of the 39th International Conference on Machine Learning,
  PMLR 162:7183-7207, 2022
- **Journal**: International Conference on Machine Learning. PMLR 162, 2022,
  7183-7207
- **Summary**: Image cartoonization is recently dominated by generative adversarial networks (GANs) from the perspective of unsupervised image-to-image translation, in which an inherent challenge is to precisely capture and sufficiently transfer characteristic cartoon styles (e.g., clear edges, smooth color shading, abstract fine structures, etc.). Existing advanced models try to enhance cartoonization effect by learning to promote edges adversarially, introducing style transfer loss, or learning to align style from multiple representation space. This paper demonstrates that more distinct and vivid cartoonization effect could be easily achieved with only basic adversarial loss. Observing that cartoon style is more evident in cartoon-texture-salient local image regions, we build a region-level adversarial learning branch in parallel with the normal image-level one, which constrains adversarial learning on cartoon-texture-salient local patches for better perceiving and transferring cartoon texture features. To this end, a novel cartoon-texture-saliency-sampler (CTSS) module is proposed to dynamically sample cartoon-texture-salient patches from training data. With extensive experiments, we demonstrate that texture saliency adaptive attention in adversarial learning, as a missing ingredient of related methods in image cartoonization, is of significant importance in facilitating and enhancing image cartoon stylization, especially for high-resolution input pictures.



### Lossy compression of multidimensional medical images using sinusoidal activation networks: an evaluation study
- **Arxiv ID**: http://arxiv.org/abs/2208.01602v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2208.01602v2)
- **Published**: 2022-08-02 17:16:33+00:00
- **Updated**: 2022-08-03 15:24:52+00:00
- **Authors**: Matteo Mancini, Derek K. Jones, Marco Palombo
- **Comment**: None
- **Journal**: None
- **Summary**: In this work, we evaluate how neural networks with periodic activation functions can be leveraged to reliably compress large multidimensional medical image datasets, with proof-of-concept application to 4D diffusion-weighted MRI (dMRI). In the medical imaging landscape, multidimensional MRI is a key area of research for developing biomarkers that are both sensitive and specific to the underlying tissue microstructure. However, the high-dimensional nature of these data poses a challenge in terms of both storage and sharing capabilities and associated costs, requiring appropriate algorithms able to represent the information in a low-dimensional space. Recent theoretical developments in deep learning have shown how periodic activation functions are a powerful tool for implicit neural representation of images and can be used for compression of 2D images. Here we extend this approach to 4D images and show how any given 4D dMRI dataset can be accurately represented through the parameters of a sinusoidal activation network, achieving a data compression rate about 10 times higher than the standard DEFLATE algorithm. Our results show that the proposed approach outperforms benchmark ReLU and Tanh activation perceptron architectures in terms of mean squared error, peak signal-to-noise ratio and structural similarity index. Subsequent analyses using the tensor and spherical harmonics representations demonstrate that the proposed lossy compression reproduces accurately the characteristics of the original data, leading to relative errors about 5 to 10 times lower than the benchmark JPEG2000 lossy compression and similar to standard pre-processing steps such as MP-PCA denosing, suggesting a loss of information within the currently accepted levels for clinical application.



### An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion
- **Arxiv ID**: http://arxiv.org/abs/2208.01618v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01618v1)
- **Published**: 2022-08-02 17:50:36+00:00
- **Updated**: 2022-08-02 17:50:36+00:00
- **Authors**: Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H. Bermano, Gal Chechik, Daniel Cohen-Or
- **Comment**: Project page: https://textual-inversion.github.io
- **Journal**: None
- **Summary**: Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes. In other words, we ask: how can we use language-guided models to turn our cat into a painting, or imagine a new product based on our favorite toy? Here we present a simple approach that allows such creative freedom. Using only 3-5 images of a user-provided concept, like an object or a style, we learn to represent it through new "words" in the embedding space of a frozen text-to-image model. These "words" can be composed into natural language sentences, guiding personalized creation in an intuitive way. Notably, we find evidence that a single word embedding is sufficient for capturing unique and varied concepts. We compare our approach to a wide range of baselines, and demonstrate that it can more faithfully portray the concepts across a range of applications and tasks.   Our code, data and new words will be available at: https://textual-inversion.github.io



### Prompt-to-Prompt Image Editing with Cross Attention Control
- **Arxiv ID**: http://arxiv.org/abs/2208.01626v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL, cs.GR, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2208.01626v1)
- **Published**: 2022-08-02 17:55:41+00:00
- **Updated**: 2022-08-02 17:55:41+00:00
- **Authors**: Amir Hertz, Ron Mokady, Jay Tenenbaum, Kfir Aberman, Yael Pritch, Daniel Cohen-Or
- **Comment**: None
- **Journal**: None
- **Summary**: Recent large-scale text-driven synthesis models have attracted much attention thanks to their remarkable capabilities of generating highly diverse images that follow given text prompts. Such text-based synthesis methods are particularly appealing to humans who are used to verbally describe their intent. Therefore, it is only natural to extend the text-driven image synthesis to text-driven image editing. Editing is challenging for these generative models, since an innate property of an editing technique is to preserve most of the original image, while in the text-based models, even a small modification of the text prompt often leads to a completely different outcome. State-of-the-art methods mitigate this by requiring the users to provide a spatial mask to localize the edit, hence, ignoring the original structure and content within the masked region. In this paper, we pursue an intuitive prompt-to-prompt editing framework, where the edits are controlled by text only. To this end, we analyze a text-conditioned model in depth and observe that the cross-attention layers are the key to controlling the relation between the spatial layout of the image to each word in the prompt. With this observation, we present several applications which monitor the image synthesis by editing the textual prompt only. This includes localized editing by replacing a word, global editing by adding a specification, and even delicately controlling the extent to which a word is reflected in the image. We present our results over diverse images and prompts, demonstrating high-quality synthesis and fidelity to the edited prompts.



### UnrealEgo: A New Dataset for Robust Egocentric 3D Human Motion Capture
- **Arxiv ID**: http://arxiv.org/abs/2208.01633v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01633v1)
- **Published**: 2022-08-02 17:59:54+00:00
- **Updated**: 2022-08-02 17:59:54+00:00
- **Authors**: Hiroyasu Akada, Jian Wang, Soshi Shimada, Masaki Takahashi, Christian Theobalt, Vladislav Golyanik
- **Comment**: 21 pages, 10 figures, 10 tables; project page:
  https://4dqv.mpi-inf.mpg.de/UnrealEgo/
- **Journal**: European Conference on Computer Vision (ECCV) 2022
- **Summary**: We present UnrealEgo, i.e., a new large-scale naturalistic dataset for egocentric 3D human pose estimation. UnrealEgo is based on an advanced concept of eyeglasses equipped with two fisheye cameras that can be used in unconstrained environments. We design their virtual prototype and attach them to 3D human models for stereo view capture. We next generate a large corpus of human motions. As a consequence, UnrealEgo is the first dataset to provide in-the-wild stereo images with the largest variety of motions among existing egocentric datasets. Furthermore, we propose a new benchmark method with a simple but effective idea of devising a 2D keypoint estimation module for stereo inputs to improve 3D human pose estimation. The extensive experiments show that our approach outperforms the previous state-of-the-art methods qualitatively and quantitatively. UnrealEgo and our source codes are available on our project web page.



### Diagnosis of Paratuberculosis in Histopathological Images Based on Explainable Artificial Intelligence and Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2208.01674v1
- **DOI**: 10.18280/ts.390311
- **Categories**: **eess.IV**, cs.CV, cs.LG, 68T07, I.4.0
- **Links**: [PDF](http://arxiv.org/pdf/2208.01674v1)
- **Published**: 2022-08-02 18:05:26+00:00
- **Updated**: 2022-08-02 18:05:26+00:00
- **Authors**: Tuncay Yiğit, Nilgün Şengöz, Özlem Özmen, Jude Hemanth, Ali Hakan Işık
- **Comment**: 7 pages
- **Journal**: Traitement du Signal, Vol. 39, No. 3, pp. 863-869, 2022
- **Summary**: Artificial intelligence holds great promise in medical imaging, especially histopathological imaging. However, artificial intelligence algorithms cannot fully explain the thought processes during decision-making. This situation has brought the problem of explainability, i.e., the black box problem, of artificial intelligence applications to the agenda: an algorithm simply responds without stating the reasons for the given images. To overcome the problem and improve the explainability, explainable artificial intelligence (XAI) has come to the fore, and piqued the interest of many researchers. Against this backdrop, this study examines a new and original dataset using the deep learning algorithm, and visualizes the output with gradient-weighted class activation mapping (Grad-CAM), one of the XAI applications. Afterwards, a detailed questionnaire survey was conducted with the pathologists on these images. Both the decision-making processes and the explanations were verified, and the accuracy of the output was tested. The research results greatly help pathologists in the diagnosis of paratuberculosis.



### Non-Line-of-Sight Tracking and Mapping with an Active Corner Camera
- **Arxiv ID**: http://arxiv.org/abs/2208.01702v1
- **DOI**: 10.1038/s41467-023-39327-2
- **Categories**: **eess.IV**, cs.CV, physics.optics
- **Links**: [PDF](http://arxiv.org/pdf/2208.01702v1)
- **Published**: 2022-08-02 19:27:45+00:00
- **Updated**: 2022-08-02 19:27:45+00:00
- **Authors**: Sheila Seidel, Hoover Rueda-Chacon, Iris Cusini, Federica Villa, Franco Zappa, Christopher Yu, Vivek K Goyal
- **Comment**: None
- **Journal**: None
- **Summary**: The ability to form non-line-of-sight (NLOS) images of changing scenes could be transformative in a variety of fields, including search and rescue, autonomous vehicle navigation, and reconnaissance. Most existing active NLOS methods illuminate the hidden scene using a pulsed laser directed at a relay surface and collect time-resolved measurements of returning light. The prevailing approaches include raster scanning of a rectangular grid on a vertical wall opposite the volume of interest to generate a collection of confocal measurements. These are inherently limited by the need for laser scanning. Methods that avoid laser scanning track the moving parts of the hidden scene as one or two point targets. In this work, based on more complete optical response modeling yet still without multiple illumination positions, we demonstrate accurate reconstructions of objects in motion and a 'map' of the stationary scenery behind them. The ability to count, localize, and characterize the sizes of hidden objects in motion, combined with mapping of the stationary hidden scene, could greatly improve indoor situational awareness in a variety of applications.



### Autonomous Agriculture Robot for Smart Farming
- **Arxiv ID**: http://arxiv.org/abs/2208.01708v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2208.01708v1)
- **Published**: 2022-08-02 19:38:48+00:00
- **Updated**: 2022-08-02 19:38:48+00:00
- **Authors**: Vinay Ummadi, Aravind Gundlapalle, Althaf Shaik, Shaik Mohammad Rafi B
- **Comment**: 12 pages, 8 figures and code available.To be published
- **Journal**: None
- **Summary**: This project aims to develop and demonstrate a ground robot with intelligence capable of conducting semi-autonomous farm operations for different low-heights vegetable crops referred as Agriculture Application Robot(AAR). AAR is a lightweight, solar-electric powered robot that uses intelligent perception for conducting detection and classification of plants and their characteristics. The system also has a robotic arm for the autonomous weed cutting process. The robot can deliver fertilizer spraying, insecticide, herbicide, and other fluids to the targets such as crops, weeds, and other pests. Besides, it provides information for future research into higher-level tasks such as yield estimation, crop, and soil health monitoring. We present the design of robot and the associated experiments which show the promising results in real world environments.



### Two-Stream Transformer Architecture for Long Video Understanding
- **Arxiv ID**: http://arxiv.org/abs/2208.01753v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2208.01753v1)
- **Published**: 2022-08-02 21:03:48+00:00
- **Updated**: 2022-08-02 21:03:48+00:00
- **Authors**: Edward Fish, Jon Weinbren, Andrew Gilbert
- **Comment**: None
- **Journal**: None
- **Summary**: Pure vision transformer architectures are highly effective for short video classification and action recognition tasks. However, due to the quadratic complexity of self attention and lack of inductive bias, transformers are resource intensive and suffer from data inefficiencies. Long form video understanding tasks amplify data and memory efficiency problems in transformers making current approaches unfeasible to implement on data or memory restricted domains. This paper introduces an efficient Spatio-Temporal Attention Network (STAN) which uses a two-stream transformer architecture to model dependencies between static image features and temporal contextual features. Our proposed approach can classify videos up to two minutes in length on a single GPU, is data efficient, and achieves SOTA performance on several long video understanding tasks.



### Robust RGB-D Fusion for Saliency Detection
- **Arxiv ID**: http://arxiv.org/abs/2208.01762v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01762v2)
- **Published**: 2022-08-02 21:23:00+00:00
- **Updated**: 2022-08-30 15:17:06+00:00
- **Authors**: Zongwei Wu, Shriarulmozhivarman Gobichettipalayam, Brahim Tamadazte, Guillaume Allibert, Danda Pani Paudel, Cédric Demonceaux
- **Comment**: Accepted to 3DV 2022
- **Journal**: None
- **Summary**: Efficiently exploiting multi-modal inputs for accurate RGB-D saliency detection is a topic of high interest. Most existing works leverage cross-modal interactions to fuse the two streams of RGB-D for intermediate features' enhancement. In this process, a practical aspect of the low quality of the available depths has not been fully considered yet. In this work, we aim for RGB-D saliency detection that is robust to the low-quality depths which primarily appear in two forms: inaccuracy due to noise and the misalignment to RGB. To this end, we propose a robust RGB-D fusion method that benefits from (1) layer-wise, and (2) trident spatial, attention mechanisms. On the one hand, layer-wise attention (LWA) learns the trade-off between early and late fusion of RGB and depth features, depending upon the depth accuracy. On the other hand, trident spatial attention (TSA) aggregates the features from a wider spatial context to address the depth misalignment problem. The proposed LWA and TSA mechanisms allow us to efficiently exploit the multi-modal inputs for saliency detection while being robust against low-quality depths. Our experiments on five benchmark datasets demonstrate that the proposed fusion method performs consistently better than the state-of-the-art fusion alternatives.



### Mates2Motion: Learning How Mechanical CAD Assemblies Work
- **Arxiv ID**: http://arxiv.org/abs/2208.01779v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2208.01779v2)
- **Published**: 2022-08-02 23:12:37+00:00
- **Updated**: 2023-05-04 22:39:40+00:00
- **Authors**: James Noeckel, Benjamin T. Jones, Karl Willis, Brian Curless, Adriana Schulz
- **Comment**: Contains 5 pages, 2 figures. Presented at the ICML 2022 Workshop on
  Machine Learning in Computational Design
- **Journal**: None
- **Summary**: We describe our work on inferring the degrees of freedom between mated parts in mechanical assemblies using deep learning on CAD representations. We train our model using a large dataset of real-world mechanical assemblies consisting of CAD parts and mates joining them together. We present methods for re-defining these mates to make them better reflect the motion of the assembly, as well as narrowing down the possible axes of motion. We also conduct a user study to create a motion-annotated test set with more reliable labels.



