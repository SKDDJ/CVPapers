# Arxiv Papers in cs.CV on 2022-09-02
### Temporal Contrastive Learning with Curriculum
- **Arxiv ID**: http://arxiv.org/abs/2209.00760v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00760v1)
- **Published**: 2022-09-02 00:12:05+00:00
- **Updated**: 2022-09-02 00:12:05+00:00
- **Authors**: Shuvendu Roy, Ali Etemad
- **Comment**: None
- **Journal**: None
- **Summary**: We present ConCur, a contrastive video representation learning method that uses curriculum learning to impose a dynamic sampling strategy in contrastive training. More specifically, ConCur starts the contrastive training with easy positive samples (temporally close and semantically similar clips), and as the training progresses, it increases the temporal span effectively sampling hard positives (temporally away and semantically dissimilar). To learn better context-aware representations, we also propose an auxiliary task of predicting the temporal distance between a positive pair of clips. We conduct extensive experiments on two popular action recognition datasets, UCF101 and HMDB51, on which our proposed method achieves state-of-the-art performance on two benchmark tasks of video action recognition and video retrieval. We explore the impact of encoder backbones and pre-training strategies by using R(2+1)D and C3D encoders and pre-training on Kinetics-400 and Kinetics-200 datasets. Moreover, a detailed ablation study shows the effectiveness of each of the components of our proposed method.



### Artifact-Tolerant Clustering-Guided Contrastive Embedding Learning for Ophthalmic Images
- **Arxiv ID**: http://arxiv.org/abs/2209.00773v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2209.00773v1)
- **Published**: 2022-09-02 01:25:45+00:00
- **Updated**: 2022-09-02 01:25:45+00:00
- **Authors**: Min Shi, Anagha Lokhande, Mojtaba S. Fazli, Vishal Sharma, Yu Tian, Yan Luo, Louis R. Pasquale, Tobias Elze, Michael V. Boland, Nazlee Zebardast, David S. Friedman, Lucy Q. Shen, Mengyu Wang
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Ophthalmic images and derivatives such as the retinal nerve fiber layer (RNFL) thickness map are crucial for detecting and monitoring ophthalmic diseases (e.g., glaucoma). For computer-aided diagnosis of eye diseases, the key technique is to automatically extract meaningful features from ophthalmic images that can reveal the biomarkers (e.g., RNFL thinning patterns) linked to functional vision loss. However, representation learning from ophthalmic images that links structural retinal damage with human vision loss is non-trivial mostly due to large anatomical variations between patients. The task becomes even more challenging in the presence of image artifacts, which are common due to issues with image acquisition and automated segmentation. In this paper, we propose an artifact-tolerant unsupervised learning framework termed EyeLearn for learning representations of ophthalmic images. EyeLearn has an artifact correction module to learn representations that can best predict artifact-free ophthalmic images. In addition, EyeLearn adopts a clustering-guided contrastive learning strategy to explicitly capture the intra- and inter-image affinities. During training, images are dynamically organized in clusters to form contrastive samples in which images in the same or different clusters are encouraged to learn similar or dissimilar representations, respectively. To evaluate EyeLearn, we use the learned representations for visual field prediction and glaucoma detection using a real-world ophthalmic image dataset of glaucoma patients. Extensive experiments and comparisons with state-of-the-art methods verified the effectiveness of EyeLearn for learning optimal feature representations from ophthalmic images.



### WOC: A Handy Webcam-based 3D Online Chatroom
- **Arxiv ID**: http://arxiv.org/abs/2209.00776v2
- **DOI**: 10.1145/3503161.3547743
- **Categories**: **cs.HC**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2209.00776v2)
- **Published**: 2022-09-02 01:34:14+00:00
- **Updated**: 2023-03-17 14:33:59+00:00
- **Authors**: Chuanhang Yan, Yu Sun, Qian Bao, Jinhui Pang, Wu Liu, Tao Mei
- **Comment**: None
- **Journal**: None
- **Summary**: We develop WOC, a webcam-based 3D virtual online chatroom for multi-person interaction, which captures the 3D motion of users and drives their individual 3D virtual avatars in real-time. Compared to the existing wearable equipment-based solution, WOC offers convenient and low-cost 3D motion capture with a single camera. To promote the immersive chat experience, WOC provides high-fidelity virtual avatar manipulation, which also supports the user-defined characters. With the distributed data flow service, the system delivers highly synchronized motion and voice for all users. Deployed on the website and no installation required, users can freely experience the virtual online chat at https://yanch.cloud.



### BinImg2Vec: Augmenting Malware Binary Image Classification with Data2Vec
- **Arxiv ID**: http://arxiv.org/abs/2209.00782v1
- **DOI**: None
- **Categories**: **cs.CR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.00782v1)
- **Published**: 2022-09-02 01:55:26+00:00
- **Updated**: 2022-09-02 01:55:26+00:00
- **Authors**: Joon Sern Lee, Kai Keng Tay, Zong Fu Chua
- **Comment**: None
- **Journal**: 1st International Conference on AI in Cybersecurity (ICAIC), 2022
- **Summary**: Rapid digitalisation spurred by the Covid-19 pandemic has resulted in more cyber crime. Malware-as-a-service is now a booming business for cyber criminals. With the surge in malware activities, it is vital for cyber defenders to understand more about the malware samples they have at hand as such information can greatly influence their next course of actions during a breach. Recently, researchers have shown how malware family classification can be done by first converting malware binaries into grayscale images and then passing them through neural networks for classification. However, most work focus on studying the impact of different neural network architectures on classification performance. In the last year, researchers have shown that augmenting supervised learning with self-supervised learning can improve performance. Even more recently, Data2Vec was proposed as a modality agnostic self-supervised framework to train neural networks. In this paper, we present BinImg2Vec, a framework of training malware binary image classifiers that incorporates both self-supervised learning and supervised learning to produce a model that consistently outperforms one trained only via supervised learning. We were able to achieve a 4% improvement in classification performance and a 0.5% reduction in performance variance over multiple runs. We also show how our framework produces embeddings that can be well clustered, facilitating model explanability.



### Structure-Preserving Graph Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2209.00793v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.SI
- **Links**: [PDF](http://arxiv.org/pdf/2209.00793v2)
- **Published**: 2022-09-02 02:49:19+00:00
- **Updated**: 2022-12-08 03:09:57+00:00
- **Authors**: Ruiyi Fang, Liangjian Wen, Zhao Kang, Jianzhuang Liu
- **Comment**: Accepted by the IEEE International Conference on Data Mining (ICDM)
  2022. arXiv admin note: text overlap with arXiv:2108.04822
- **Journal**: None
- **Summary**: Though graph representation learning (GRL) has made significant progress, it is still a challenge to extract and embed the rich topological structure and feature information in an adequate way. Most existing methods focus on local structure and fail to fully incorporate the global topological structure. To this end, we propose a novel Structure-Preserving Graph Representation Learning (SPGRL) method, to fully capture the structure information of graphs. Specifically, to reduce the uncertainty and misinformation of the original graph, we construct a feature graph as a complementary view via k-Nearest Neighbor method. The feature graph can be used to contrast at node-level to capture the local relation. Besides, we retain the global topological structure information by maximizing the mutual information (MI) of the whole graph and feature embeddings, which is theoretically reduced to exchanging the feature embeddings of the feature and the original graphs to reconstruct themselves. Extensive experiments show that our method has quite superior performance on semi-supervised node classification task and excellent robustness under noise perturbation on graph structure or node features.



### Diffusion Models: A Comprehensive Survey of Methods and Applications
- **Arxiv ID**: http://arxiv.org/abs/2209.00796v10
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2209.00796v10)
- **Published**: 2022-09-02 02:59:10+00:00
- **Updated**: 2023-03-23 08:25:32+00:00
- **Authors**: Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin Cui, Ming-Hsuan Yang
- **Comment**: 49 pages, 17 figures, citing 337 (up-to-date) papers, project:
  https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy
- **Journal**: None
- **Summary**: Diffusion models have emerged as a powerful new family of deep generative models with record-breaking performance in many applications, including image synthesis, video generation, and molecule design. In this survey, we provide an overview of the rapidly expanding body of work on diffusion models, categorizing the research into three key areas: efficient sampling, improved likelihood estimation, and handling data with special structures. We also discuss the potential for combining diffusion models with other generative models for enhanced results. We further review the wide-ranging applications of diffusion models in fields spanning from computer vision, natural language generation, temporal data modeling, to interdisciplinary applications in other scientific disciplines. This survey aims to provide a contextualized, in-depth look at the state of diffusion models, identifying the key areas of focus and pointing to potential areas for further exploration. Github: https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy.



### PCDNF: Revisiting Learning-based Point Cloud Denoising via Joint Normal Filtering
- **Arxiv ID**: http://arxiv.org/abs/2209.00798v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2209.00798v2)
- **Published**: 2022-09-02 03:10:21+00:00
- **Updated**: 2023-07-03 08:24:21+00:00
- **Authors**: Zheng Liu, Yaowu Zhao, Sijing Zhan, Yuanyuan Liu, Renjie Chen, Ying He
- **Comment**: None
- **Journal**: None
- **Summary**: Recovering high quality surfaces from noisy point clouds, known as point cloud denoising, is a fundamental yet challenging problem in geometry processing. Most of the existing methods either directly denoise the noisy input or filter raw normals followed by updating point positions. Motivated by the essential interplay between point cloud denoising and normal filtering, we revisit point cloud denoising from a multitask perspective, and propose an end-to-end network, named PCDNF, to denoise point clouds via joint normal filtering. In particular, we introduce an auxiliary normal filtering task to help the overall network remove noise more effectively while preserving geometric features more accurately. In addition to the overall architecture, our network has two novel modules. On one hand, to improve noise removal performance, we design a shape-aware selector to construct the latent tangent space representation of the specific point by comprehensively considering the learned point and normal features and geometry priors. On the other hand, point features are more suitable for describing geometric details, and normal features are more conducive for representing geometric structures (e.g., sharp edges and corners). Combining point and normal features allows us to overcome their weaknesses. Thus, we design a feature refinement module to fuse point and normal features for better recovering geometric information. Extensive evaluations, comparisons, and ablation studies demonstrate that the proposed method outperforms state-of-the-arts for both point cloud denoising and normal filtering.



### Self-Score: Self-Supervised Learning on Score-Based Models for MRI Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2209.00835v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2209.00835v1)
- **Published**: 2022-09-02 06:21:42+00:00
- **Updated**: 2022-09-02 06:21:42+00:00
- **Authors**: Zhuo-Xu Cui, Chentao Cao, Shaonan Liu, Qingyong Zhu, Jing Cheng, Haifeng Wang, Yanjie Zhu, Dong Liang
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, score-based diffusion models have shown satisfactory performance in MRI reconstruction. Most of these methods require a large amount of fully sampled MRI data as a training set, which, sometimes, is difficult to acquire in practice. This paper proposes a fully-sampled-data-free score-based diffusion model for MRI reconstruction, which learns the fully sampled MR image prior in a self-supervised manner on undersampled data. Specifically, we first infer the fully sampled MR image distribution from the undersampled data by Bayesian deep learning, then perturb the data distribution and approximate their probability density gradient by training a score function. Leveraging the learned score function as a prior, we can reconstruct the MR image by performing conditioned Langevin Markov chain Monte Carlo (MCMC) sampling. Experiments on the public dataset show that the proposed method outperforms existing self-supervised MRI reconstruction methods and achieves comparable performances with the conventional (fully sampled data trained) score-based diffusion methods.



### Geometric and Learning-based Mesh Denoising: A Comprehensive Survey
- **Arxiv ID**: http://arxiv.org/abs/2209.00841v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00841v1)
- **Published**: 2022-09-02 06:54:32+00:00
- **Updated**: 2022-09-02 06:54:32+00:00
- **Authors**: Honghua Chen, Mingqiang Wei, Jun Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Mesh denoising is a fundamental problem in digital geometry processing. It seeks to remove surface noise, while preserving surface intrinsic signals as accurately as possible. While the traditional wisdom has been built upon specialized priors to smooth surfaces, learning-based approaches are making their debut with great success in generalization and automation. In this work, we provide a comprehensive review of the advances in mesh denoising, containing both traditional geometric approaches and recent learning-based methods. First, to familiarize readers with the denoising tasks, we summarize four common issues in mesh denoising. We then provide two categorizations of the existing denoising methods. Furthermore, three important categories, including optimization-, filter-, and data-driven-based techniques, are introduced and analyzed in detail, respectively. Both qualitative and quantitative comparisons are illustrated, to demonstrate the effectiveness of the state-of-the-art denoising methods. Finally, potential directions of future work are pointed out to solve the common problems of these approaches. A mesh denoising benchmark is also built in this work, and future researchers will easily and conveniently evaluate their methods with the state-of-the-art approaches.



### Geometry Aligned Variational Transformer for Image-conditioned Layout Generation
- **Arxiv ID**: http://arxiv.org/abs/2209.00852v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2209.00852v1)
- **Published**: 2022-09-02 07:19:12+00:00
- **Updated**: 2022-09-02 07:19:12+00:00
- **Authors**: Yunning Cao, Ye Ma, Min Zhou, Chuanbin Liu, Hongtao Xie, Tiezheng Ge, Yuning Jiang
- **Comment**: To be published in ACM MM 2022
- **Journal**: None
- **Summary**: Layout generation is a novel task in computer vision, which combines the challenges in both object localization and aesthetic appraisal, widely used in advertisements, posters, and slides design. An accurate and pleasant layout should consider both the intra-domain relationship within layout elements and the inter-domain relationship between layout elements and the image. However, most previous methods simply focus on image-content-agnostic layout generation, without leveraging the complex visual information from the image. To this end, we explore a novel paradigm entitled image-conditioned layout generation, which aims to add text overlays to an image in a semantically coherent manner. Specifically, we propose an Image-Conditioned Variational Transformer (ICVT) that autoregressively generates various layouts in an image. First, self-attention mechanism is adopted to model the contextual relationship within layout elements, while cross-attention mechanism is used to fuse the visual information of conditional images. Subsequently, we take them as building blocks of conditional variational autoencoder (CVAE), which demonstrates appealing diversity. Second, in order to alleviate the gap between layout elements domain and visual domain, we design a Geometry Alignment module, in which the geometric information of the image is aligned with the layout representation. In addition, we construct a large-scale advertisement poster layout designing dataset with delicate layout and saliency map annotations. Experimental results show that our model can adaptively generate layouts in the non-intrusive area of the image, resulting in a harmonious layout design.



### Vision-Language Adaptive Mutual Decoder for OOV-STR
- **Arxiv ID**: http://arxiv.org/abs/2209.00859v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00859v1)
- **Published**: 2022-09-02 07:32:22+00:00
- **Updated**: 2022-09-02 07:32:22+00:00
- **Authors**: Jinshui Hu, Chenyu Liu, Qiandong Yan, Xuyang Zhu, Fengli yu, Jiajia Wu, Bing Yin
- **Comment**: 1st Place Solution to ECCV 2022 OOV-ST Challenge
- **Journal**: None
- **Summary**: Recent works have shown huge success of deep learning models for common in vocabulary (IV) scene text recognition. However, in real-world scenarios, out-of-vocabulary (OOV) words are of great importance and SOTA recognition models usually perform poorly on OOV settings. Inspired by the intuition that the learned language prior have limited OOV preformence, we design a framework named Vision Language Adaptive Mutual Decoder (VLAMD) to tackle OOV problems partly. VLAMD consists of three main conponents. Firstly, we build an attention based LSTM decoder with two adaptively merged visual-only modules, yields a vision-language balanced main branch. Secondly, we add an auxiliary query based autoregressive transformer decoding head for common visual and language prior representation learning. Finally, we couple these two designs with bidirectional training for more diverse language modeling, and do mutual sequential decoding to get robuster results. Our approach achieved 70.31\% and 59.61\% word accuracy on IV+OOV and OOV settings respectively on Cropped Word Recognition Task of OOV-ST Challenge at ECCV 2022 TiE Workshop, where we got 1st place on both settings.



### Real-time 3D Single Object Tracking with Transformer
- **Arxiv ID**: http://arxiv.org/abs/2209.00860v1
- **DOI**: 10.1109/TMM.2022.3146714
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00860v1)
- **Published**: 2022-09-02 07:36:20+00:00
- **Updated**: 2022-09-02 07:36:20+00:00
- **Authors**: Jiayao Shan, Sifan Zhou, Yubo Cui, Zheng Fang
- **Comment**: IEEE Transactions on Multimedia. arXiv admin note: text overlap with
  arXiv:2108.06455
- **Journal**: None
- **Summary**: LiDAR-based 3D single object tracking is a challenging issue in robotics and autonomous driving. Currently, existing approaches usually suffer from the problem that objects at long distance often have very sparse or partially-occluded point clouds, which makes the features extracted by the model ambiguous. Ambiguous features will make it hard to locate the target object and finally lead to bad tracking results. To solve this problem, we utilize the powerful Transformer architecture and propose a Point-Track-Transformer (PTT) module for point cloud-based 3D single object tracking task. Specifically, PTT module generates fine-tuned attention features by computing attention weights, which guides the tracker focusing on the important features of the target and improves the tracking ability in complex scenarios. To evaluate our PTT module, we embed PTT into the dominant method and construct a novel 3D SOT tracker named PTT-Net. In PTT-Net, we embed PTT into the voting stage and proposal generation stage, respectively. PTT module in the voting stage could model the interactions among point patches, which learns context-dependent features. Meanwhile, PTT module in the proposal generation stage could capture the contextual information between object and background. We evaluate our PTT-Net on KITTI and NuScenes datasets. Experimental results demonstrate the effectiveness of PTT module and the superiority of PTT-Net, which surpasses the baseline by a noticeable margin, ~10% in the Car category. Meanwhile, our method also has a significant performance improvement in sparse scenarios. In general, the combination of transformer and tracking pipeline enables our PTT-Net to achieve state-of-the-art performance on both two datasets. Additionally, PTT-Net could run in real-time at 40FPS on NVIDIA 1080Ti GPU. Our code is open-sourced for the research community at https://github.com/shanjiayao/PTT.



### Impact of Scaled Image on Robustness of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2209.02132v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.02132v2)
- **Published**: 2022-09-02 08:06:58+00:00
- **Updated**: 2023-05-23 15:46:32+00:00
- **Authors**: Chengyin Hu, Weiwen Shi
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have been widely used in computer vision tasks like image classification, object detection and segmentation. Whereas recent studies have shown their vulnerability to manual digital perturbations or distortion in the input images. The accuracy of the networks is remarkably influenced by the data distribution of their training dataset. Scaling the raw images creates out-of-distribution data, which makes it a possible adversarial attack to fool the networks. In this work, we propose a Scaling-distortion dataset ImageNet-CS by Scaling a subset of the ImageNet Challenge dataset by different multiples. The aim of our work is to study the impact of scaled images on the performance of advanced DNNs. We perform experiments on several state-of-the-art deep neural network architectures on the proposed ImageNet-CS, and the results show a significant positive correlation between scaling size and accuracy decline. Moreover, based on ResNet50 architecture, we demonstrate some tests on the performance of recent proposed robust training techniques and strategies like Augmix, Revisiting and Normalizer Free on our proposed ImageNet-CS. Experiment results have shown that these robust training techniques can improve networks' robustness to scaling transformation.



### Impact of Colour Variation on Robustness of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2209.02832v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2209.02832v2)
- **Published**: 2022-09-02 08:16:04+00:00
- **Updated**: 2023-05-23 15:43:28+00:00
- **Authors**: Chengyin Hu, Weiwen Shi
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2209.02132
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have have shown state-of-the-art performance for computer vision applications like image classification, segmentation and object detection. Whereas recent advances have shown their vulnerability to manual digital perturbations in the input data, namely adversarial attacks. The accuracy of the networks is significantly affected by the data distribution of their training dataset. Distortions or perturbations on color space of input images generates out-of-distribution data, which make networks more likely to misclassify them. In this work, we propose a color-variation dataset by distorting their RGB color on a subset of the ImageNet with 27 different combinations. The aim of our work is to study the impact of color variation on the performance of DNNs. We perform experiments on several state-of-the-art DNN architectures on the proposed dataset, and the result shows a significant correlation between color variation and loss of accuracy. Furthermore, based on the ResNet50 architecture, we demonstrate some experiments of the performance of recently proposed robust training techniques and strategies, such as Augmix, revisit, and free normalizer, on our proposed dataset. Experimental results indicate that these robust training techniques can improve the robustness of deep networks to color variation.



### Adversarial Color Film: Effective Physical-World Attack to DNNs
- **Arxiv ID**: http://arxiv.org/abs/2209.02430v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.02430v2)
- **Published**: 2022-09-02 08:22:32+00:00
- **Updated**: 2023-05-23 12:29:21+00:00
- **Authors**: Chengyin Hu, Weiwen Shi
- **Comment**: None
- **Journal**: None
- **Summary**: It is well known that the performance of deep neural networks (DNNs) is susceptible to subtle interference. So far, camera-based physical adversarial attacks haven't gotten much attention, but it is the vacancy of physical attack. In this paper, we propose a simple and efficient camera-based physical attack called Adversarial Color Film (AdvCF), which manipulates the physical parameters of color film to perform attacks. Carefully designed experiments show the effectiveness of the proposed method in both digital and physical environments. In addition, experimental results show that the adversarial samples generated by AdvCF have excellent performance in attack transferability, which enables AdvCF effective black-box attacks. At the same time, we give the guidance of defense against AdvCF by means of adversarial training. Finally, we look into AdvCF's threat to future vision-based systems and propose some promising mentality for camera-based physical attacks.



### Mapping the ocular surface from monocular videos with an application to dry eye disease grading
- **Arxiv ID**: http://arxiv.org/abs/2209.00886v2
- **DOI**: 10.1007/978-3-031-16525-2_7
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2209.00886v2)
- **Published**: 2022-09-02 08:54:02+00:00
- **Updated**: 2022-09-05 09:39:17+00:00
- **Authors**: Ikram Brahim, Mathieu Lamard, Anas-Alexis Benyoussef, Pierre-Henri Conze, Béatrice Cochener, Divi Cornec, Gwenolé Quellec
- **Comment**: Accepted MICCAI-OMIA pre-print
- **Journal**: None
- **Summary**: With a prevalence of 5 to 50%, Dry Eye Disease (DED) is one of the leading reasons for ophthalmologist consultations. The diagnosis and quantification of DED usually rely on ocular surface analysis through slit-lamp examinations. However, evaluations are subjective and non-reproducible. To improve the diagnosis, we propose to 1) track the ocular surface in 3-D using video recordings acquired during examinations, and 2) grade the severity using registered frames. Our registration method uses unsupervised image-to-depth learning. These methods learn depth from lights and shadows and estimate pose based on depth maps. However, DED examinations undergo unresolved challenges including a moving light source, transparent ocular tissues, etc. To overcome these and estimate the ego-motion, we implement joint CNN architectures with multiple losses incorporating prior known information, namely the shape of the eye, through semantic segmentation as well as sphere fitting. The achieved tracking errors outperform the state-of-the-art, with a mean Euclidean distance as low as 0.48% of the image width on our test set. This registration improves the DED severity classification by a 0.20 AUC difference. The proposed approach is the first to address DED diagnosis with supervision from monocular videos



### Instance-Dependent Noisy Label Learning via Graphical Modelling
- **Arxiv ID**: http://arxiv.org/abs/2209.00906v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.00906v1)
- **Published**: 2022-09-02 09:27:37+00:00
- **Updated**: 2022-09-02 09:27:37+00:00
- **Authors**: Arpit Garg, Cuong Nguyen, Rafael Felix, Thanh-Toan Do, Gustavo Carneiro
- **Comment**: Accepted at WACV 2023
- **Journal**: None
- **Summary**: Noisy labels are unavoidable yet troublesome in the ecosystem of deep learning because models can easily overfit them. There are many types of label noise, such as symmetric, asymmetric and instance-dependent noise (IDN), with IDN being the only type that depends on image information. Such dependence on image information makes IDN a critical type of label noise to study, given that labelling mistakes are caused in large part by insufficient or ambiguous information about the visual classes present in images. Aiming to provide an effective technique to address IDN, we present a new graphical modelling approach called InstanceGM, that combines discriminative and generative models. The main contributions of InstanceGM are: i) the use of the continuous Bernoulli distribution to train the generative model, offering significant training advantages, and ii) the exploration of a state-of-the-art noisy-label discriminative classifier to generate clean labels from instance-dependent noisy-label samples. InstanceGM is competitive with current noisy-label learning approaches, particularly in IDN benchmarks using synthetic and real-world datasets, where our method shows better accuracy than the competitors in most experiments.



### Detection of diabetic retinopathy using longitudinal self-supervised learning
- **Arxiv ID**: http://arxiv.org/abs/2209.00915v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.00915v2)
- **Published**: 2022-09-02 09:50:31+00:00
- **Updated**: 2022-09-05 09:46:08+00:00
- **Authors**: Rachid Zeghlache, Pierre-Henri Conze, Mostafa El Habib Daho, Ramin Tadayoni, Pascal Massin, Béatrice Cochener, Gwenolé Quellec, Mathieu Lamard
- **Comment**: Accepted preprint for presentation at MICCAI-OMIA
- **Journal**: None
- **Summary**: Longitudinal imaging is able to capture both static anatomical structures and dynamic changes in disease progression towards earlier and better patient-specific pathology management. However, conventional approaches for detecting diabetic retinopathy (DR) rarely take advantage of longitudinal information to improve DR analysis. In this work, we investigate the benefit of exploiting self-supervised learning with a longitudinal nature for DR diagnosis purposes. We compare different longitudinal self-supervised learning (LSSL) methods to model the disease progression from longitudinal retinal color fundus photographs (CFP) to detect early DR severity changes using a pair of consecutive exams. The experiments were conducted on a longitudinal DR screening dataset with or without those trained encoders (LSSL) acting as a longitudinal pretext task. Results achieve an AUC of 0.875 for the baseline (model trained from scratch) and an AUC of 0.96 (95% CI: 0.9593-0.9655 DeLong test) with a p-value < 2.2e-16 on early fusion using a simple ResNet alike architecture with frozen LSSL weights, suggesting that the LSSL latent space enables to encode the dynamic of DR progression.



### DPIT: Dual-Pipeline Integrated Transformer for Human Pose Estimation
- **Arxiv ID**: http://arxiv.org/abs/2209.02431v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.02431v1)
- **Published**: 2022-09-02 10:18:26+00:00
- **Updated**: 2022-09-02 10:18:26+00:00
- **Authors**: Shuaitao Zhao, Kun Liu, Yuhang Huang, Qian Bao, Dan Zeng, Wu Liu
- **Comment**: None
- **Journal**: None
- **Summary**: Human pose estimation aims to figure out the keypoints of all people in different scenes. Current approaches still face some challenges despite promising results. Existing top-down methods deal with a single person individually, without the interaction between different people and the scene they are situated in. Consequently, the performance of human detection degrades when serious occlusion happens. On the other hand, existing bottom-up methods consider all people at the same time and capture the global knowledge of the entire image. However, they are less accurate than the top-down methods due to the scale variation. To address these problems, we propose a novel Dual-Pipeline Integrated Transformer (DPIT) by integrating top-down and bottom-up pipelines to explore the visual clues of different receptive fields and achieve their complementarity. Specifically, DPIT consists of two branches, the bottom-up branch deals with the whole image to capture the global visual information, while the top-down branch extracts the feature representation of local vision from the single-human bounding box. Then, the extracted feature representations from bottom-up and top-down branches are fed into the transformer encoder to fuse the global and local knowledge interactively. Moreover, we define the keypoint queries to explore both full-scene and single-human posture visual clues to realize the mutual complementarity of the two pipelines. To the best of our knowledge, this is one of the first works to integrate the bottom-up and top-down pipelines with transformers for human pose estimation. Extensive experiments on COCO and MPII datasets demonstrate that our DPIT achieves comparable performance to the state-of-the-art methods.



### Which country is this picture from? New data and methods for DNN-based country recognition
- **Arxiv ID**: http://arxiv.org/abs/2209.02429v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.02429v2)
- **Published**: 2022-09-02 10:56:41+00:00
- **Updated**: 2023-02-17 15:31:32+00:00
- **Authors**: Omran Alamayreh, Giovanna Maria Dimitri, Jun Wang, Benedetta Tondi, Mauro Barni
- **Comment**: None
- **Journal**: None
- **Summary**: Recognizing the country where a picture has been taken has many potential applications, such as identification of fake news and prevention of disinformation campaigns. Previous works focused on the estimation of the geo-coordinates where a picture has been taken. Yet, recognizing in which country an image was taken could be more critical, from a semantic and forensic point of view, than estimating its spatial coordinates. In the above framework, this paper provides two contributions. First, we introduce the VIPPGeo dataset, containing 3.8 million geo-tagged images. Secondly, we used the dataset to train a model casting the country recognition problem as a classification problem. The experiments show that our model provides better results than the current state of the art. Notably, we found that asking the network to identify the country provides better results than estimating the geo-coordinates and then tracing them back to the country where the picture was taken.



### Learning task-specific features for 3D pointcloud graph creation
- **Arxiv ID**: http://arxiv.org/abs/2209.00949v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00949v1)
- **Published**: 2022-09-02 11:13:02+00:00
- **Updated**: 2022-09-02 11:13:02+00:00
- **Authors**: Elías Abad-Rocamora, Javier Ruiz-Hidalgo
- **Comment**: None
- **Journal**: None
- **Summary**: Processing 3D pointclouds with Deep Learning methods is not an easy task. A common choice is to do so with Graph Neural Networks, but this framework involves the creation of edges between points, which are explicitly not related between them. Historically, naive and handcrafted methods like k Nearest Neighbors (k-NN) or query ball point over xyz features have been proposed, focusing more attention on improving the network than improving the graph. In this work, we propose a more principled way of creating a graph from a 3D pointcloud. Our method is based on performing k-NN over a transformation of the input 3D pointcloud. This transformation is done by an Multi-Later Perceptron (MLP) with learnable parameters that is optimized through backpropagation jointly with the rest of the network. We also introduce a regularization method based on stress minimization, which allows to control how distant is the learnt graph from our baseline: k-NN over xyz space. This framework is tested on ModelNet40, where graphs generated by our network outperformed the baseline by 0.3 points in overall accuracy.



### Echocardiographic Image Quality Assessment Using Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2209.00959v1
- **DOI**: 10.1007/978-3-030-80432-9_36
- **Categories**: **eess.IV**, cs.CV, cs.LG, q-bio.TO
- **Links**: [PDF](http://arxiv.org/pdf/2209.00959v1)
- **Published**: 2022-09-02 11:35:20+00:00
- **Updated**: 2022-09-02 11:35:20+00:00
- **Authors**: Robert B. Labs, Massoud Zolgharni, Jonathan P. Loo
- **Comment**: None
- **Journal**: Medical Image Understanding and Analysis. MIUA 2021
- **Summary**: Echocardiography image quality assessment is not a trivial issue in transthoracic examination. As the in vivo examination of heart structures gained prominence in cardiac diagnosis, it has been affirmed that accurate diagnosis of the left ventricle functions is hugely dependent on the quality of echo images. Up till now, visual assessment of echo images is highly subjective and requires specific definition under clinical pathologies. While poor-quality images impair quantifications and diagnosis, the inherent variations in echocardiographic image quality standards indicates the complexity faced among different observers and provides apparent evidence for incoherent assessment under clinical trials, especially with less experienced cardiologists. In this research, our aim was to analyse and define specific quality attributes mostly discussed by experts and present a fully trained convolutional neural network model for assessing such quality features objectively.



### LiteDepth: Digging into Fast and Accurate Depth Estimation on Mobile Devices
- **Arxiv ID**: http://arxiv.org/abs/2209.00961v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00961v1)
- **Published**: 2022-09-02 11:38:28+00:00
- **Updated**: 2022-09-02 11:38:28+00:00
- **Authors**: Zhenyu Li, Zehui Chen, Jialei Xu, Xianming Liu, Junjun Jiang
- **Comment**: Accepted to European Conference on Computer Vision Workshop (ECCVW
  2022)
- **Journal**: None
- **Summary**: Monocular depth estimation is an essential task in the computer vision community. While tremendous successful methods have obtained excellent results, most of them are computationally expensive and not applicable for real-time on-device inference. In this paper, we aim to address more practical applications of monocular depth estimation, where the solution should consider not only the precision but also the inference time on mobile devices. To this end, we first develop an end-to-end learning-based model with a tiny weight size (1.4MB) and a short inference time (27FPS on Raspberry Pi 4). Then, we propose a simple yet effective data augmentation strategy, called R2 crop, to boost the model performance. Moreover, we observe that the simple lightweight model trained with only one single loss term will suffer from performance bottleneck. To alleviate this issue, we adopt multiple loss terms to provide sufficient constraints during the training stage. Furthermore, with a simple dynamic re-weight strategy, we can avoid the time-consuming hyper-parameter choice of loss terms. Finally, we adopt the structure-aware distillation to further improve the model performance. Notably, our solution named LiteDepth ranks 2nd in the MAI&AIM2022 Monocular Depth Estimation Challenge}, with a si-RMSE of 0.311, an RMSE of 3.79, and the inference time is 37$ms$ tested on the Raspberry Pi 4. Notably, we provide the fastest solution to the challenge. Codes and models will be released at \url{https://github.com/zhyever/LiteDepth}.



### Reducing The Amortization Gap of Entropy Bottleneck In End-to-End Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2209.00964v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG, 94A08
- **Links**: [PDF](http://arxiv.org/pdf/2209.00964v1)
- **Published**: 2022-09-02 11:43:45+00:00
- **Updated**: 2022-09-02 11:43:45+00:00
- **Authors**: Muhammet Balcilar, Bharath Damodaran, Pierre Hellier
- **Comment**: 5 pages, 3 figures,
- **Journal**: None
- **Summary**: End-to-end deep trainable models are about to exceed the performance of the traditional handcrafted compression techniques on videos and images. The core idea is to learn a non-linear transformation, modeled as a deep neural network, mapping input image into latent space, jointly with an entropy model of the latent distribution. The decoder is also learned as a deep trainable network, and the reconstructed image measures the distortion. These methods enforce the latent to follow some prior distributions. Since these priors are learned by optimization over the entire training set, the performance is optimal in average. However, it cannot fit exactly on every single new instance, hence damaging the compression performance by enlarging the bit-stream. In this paper, we propose a simple yet efficient instance-based parameterization method to reduce this amortization gap at a minor cost. The proposed method is applicable to any end-to-end compressing methods, improving the compression bitrate by 1% without any impact on the reconstruction quality.



### Automated Assessment of Transthoracic Echocardiogram Image Quality Using Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2209.00976v1
- **DOI**: 10.1016/j.imed.2022.08.001
- **Categories**: **eess.IV**, cs.CV, cs.LG, cs.NE, q-bio.QM, q-bio.TO
- **Links**: [PDF](http://arxiv.org/pdf/2209.00976v1)
- **Published**: 2022-09-02 12:15:14+00:00
- **Updated**: 2022-09-02 12:15:14+00:00
- **Authors**: Robert B. Labs, Apostolos Vrettos, Jonathan Loo, Massoud Zolgharni
- **Comment**: None
- **Journal**: None
- **Summary**: Standard views in two-dimensional echocardiography are well established but the quality of acquired images are highly dependent on operator skills and are assessed subjectively. This study is aimed at providing an objective assessment pipeline for echocardiogram image quality by defining a new set of domain-specific quality indicators. Consequently, image quality assessment can thus be automated to enhance clinical measurements, interpretation, and real-time optimization. We have developed deep neural networks for the automated assessment of echocardiographic frame which were randomly sampled from 11,262 adult patients. The private echocardiography dataset consists of 33,784 frames, previously acquired between 2010 and 2020. Deep learning approaches were used to extract the spatiotemporal features and the image quality indicators were evaluated against the mean absolute error. Our quality indicators encapsulate both anatomical and pathological elements to provide multivariate assessment scores for anatomical visibility, clarity, depth-gain and foreshortedness, respectively.



### Contrastive Semantic-Guided Image Smoothing Network
- **Arxiv ID**: http://arxiv.org/abs/2209.00977v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.00977v1)
- **Published**: 2022-09-02 12:18:49+00:00
- **Updated**: 2022-09-02 12:18:49+00:00
- **Authors**: Jie Wang, Yongzhen Wang, Yidan Feng, Lina Gong, Xuefeng Yan, Haoran Xie, Fu Lee Wang, Mingqiang Wei
- **Comment**: None
- **Journal**: None
- **Summary**: Image smoothing is a fundamental low-level vision task that aims to preserve salient structures of an image while removing insignificant details. Deep learning has been explored in image smoothing to deal with the complex entanglement of semantic structures and trivial details. However, current methods neglect two important facts in smoothing: 1) naive pixel-level regression supervised by the limited number of high-quality smoothing ground-truth could lead to domain shift and cause generalization problems towards real-world images; 2) texture appearance is closely related to object semantics, so that image smoothing requires awareness of semantic difference to apply adaptive smoothing strengths. To address these issues, we propose a novel Contrastive Semantic-Guided Image Smoothing Network (CSGIS-Net) that combines both contrastive prior and semantic prior to facilitate robust image smoothing. The supervision signal is augmented by leveraging undesired smoothing effects as negative teachers, and by incorporating segmentation tasks to encourage semantic distinctiveness. To realize the proposed network, we also enrich the original VOC dataset with texture enhancement and smoothing labels, namely VOC-smooth, which first bridges image smoothing and semantic segmentation. Extensive experiments demonstrate that the proposed CSGIS-Net outperforms state-of-the-art algorithms by a large margin. Code and dataset are available at https://github.com/wangjie6866/CSGIS-Net.



### Multimodal Information Fusion for Glaucoma and DR Classification
- **Arxiv ID**: http://arxiv.org/abs/2209.00979v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.00979v2)
- **Published**: 2022-09-02 12:19:03+00:00
- **Updated**: 2022-09-05 09:48:29+00:00
- **Authors**: Yihao Li, Mostafa El Habib Daho, Pierre-Henri Conze, Hassan Al Hajj, Sophie Bonnin, Hugang Ren, Niranchana Manivannan, Stephanie Magazzeni, Ramin Tadayoni, Béatrice Cochener, Mathieu Lamard, Gwenolé Quellec
- **Comment**: Accepted preprint for presentation at MICCAI-OMIA
- **Journal**: None
- **Summary**: Multimodal information is frequently available in medical tasks. By combining information from multiple sources, clinicians are able to make more accurate judgments. In recent years, multiple imaging techniques have been used in clinical practice for retinal analysis: 2D fundus photographs, 3D optical coherence tomography (OCT) and 3D OCT angiography, etc. Our paper investigates three multimodal information fusion strategies based on deep learning to solve retinal analysis tasks: early fusion, intermediate fusion, and hierarchical fusion. The commonly used early and intermediate fusions are simple but do not fully exploit the complementary information between modalities. We developed a hierarchical fusion approach that focuses on combining features across multiple dimensions of the network, as well as exploring the correlation between modalities. These approaches were applied to glaucoma and diabetic retinopathy classification, using the public GAMMA dataset (fundus photographs and OCT) and a private dataset of PlexElite 9000 (Carl Zeis Meditec Inc.) OCT angiography acquisitions, respectively. Our hierarchical fusion method performed the best in both cases and paved the way for better clinical diagnosis.



### Occlusion-Resistant LiDAR Fiducial Marker Detection
- **Arxiv ID**: http://arxiv.org/abs/2209.01072v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2209.01072v2)
- **Published**: 2022-09-02 14:07:25+00:00
- **Updated**: 2023-08-01 22:44:35+00:00
- **Authors**: Yibo Liu, Jinjun Shan, Hunter Schofield
- **Comment**: 7 pages, 11 figures
- **Journal**: None
- **Summary**: The LiDAR fiducial marker, akin to the well-known AprilTag used in camera applications, serves as a convenient resource to impart artificial features to the LiDAR sensor, facilitating robotics applications. Unfortunately, current LiDAR fiducial marker detection methods are limited to occlusion-free point clouds. In this work, we present a novel approach for occlusion-resistant LiDAR fiducial marker detection. We first extract 3D points potentially corresponding to the markers, leveraging the 3D intensity gradients. Afterward, we analyze the 3D spatial distribution of the extracted points through clustering. Subsequently, we determine the potential marker locations by examining the geometric characteristics of these clusters. We then successively transfer the 3D points that fall within the candidate locations from the raw point cloud onto a designed intermediate plane. Finally, using the intermediate plane, we validate each location for the presence of a fiducial marker and compute the marker's pose if found. We conduct both qualitative and quantitative experiments to demonstrate that our approach is the first LiDAR fiducial marker detection method applicable to point clouds with occlusion while achieving better accuracy.



### Learning an Ensemble of Deep Fingerprint Representations
- **Arxiv ID**: http://arxiv.org/abs/2209.02425v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.02425v1)
- **Published**: 2022-09-02 15:08:33+00:00
- **Updated**: 2022-09-02 15:08:33+00:00
- **Authors**: Akash Godbole, Karthik Nandakumar, Anil K. Jain
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks (DNNs) have shown incredible promise in learning fixed-length representations from fingerprints. Since the representation learning is often focused on capturing specific prior knowledge (e.g., minutiae), there is no universal representation that comprehensively encapsulates all the discriminatory information available in a fingerprint. While learning an ensemble of representations can mitigate this problem, two critical challenges need to be addressed: (i) How to extract multiple diverse representations from the same fingerprint image? and (ii) How to optimally exploit these representations during the matching process? In this work, we train multiple instances of DeepPrint (a state-of-the-art DNN-based fingerprint encoder) on different transformations of the input image to generate an ensemble of fingerprint embeddings. We also propose a feature fusion technique that distills these multiple representations into a single embedding, which faithfully captures the diversity present in the ensemble without increasing the computational complexity. The proposed approach has been comprehensively evaluated on five databases containing rolled, plain, and latent fingerprints (NIST SD4, NIST SD14, NIST SD27, NIST SD302, and FVC2004 DB2A) and statistically significant improvements in accuracy have been consistently demonstrated across a range of verification as well as closed- and open-set identification settings. The proposed approach serves as a wrapper capable of improving the accuracy of any DNN-based recognition system.



### AutoPET Challenge: Combining nn-Unet with Swin UNETR Augmented by Maximum Intensity Projection Classifier
- **Arxiv ID**: http://arxiv.org/abs/2209.01112v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2209.01112v2)
- **Published**: 2022-09-02 15:20:28+00:00
- **Updated**: 2022-10-14 08:51:28+00:00
- **Authors**: Lars Heiliger, Zdravko Marinov, Max Hasin, André Ferreira, Jana Fragemann, Kelsey Pomykala, Jacob Murray, David Kersting, Victor Alves, Rainer Stiefelhagen, Jan Egger, Jens Kleesiek
- **Comment**: 11 pages, 2 figures
- **Journal**: None
- **Summary**: Tumor volume and changes in tumor characteristics over time are important biomarkers for cancer therapy. In this context, FDG-PET/CT scans are routinely used for staging and re-staging of cancer, as the radiolabeled fluorodeoxyglucose is taken up in regions of high metabolism. Unfortunately, these regions with high metabolism are not specific to tumors and can also represent physiological uptake by normal functioning organs, inflammation, or infection, making detailed and reliable tumor segmentation in these scans a demanding task. This gap in research is addressed by the AutoPET challenge, which provides a public data set with FDG-PET/CT scans from 900 patients to encourage further improvement in this field. Our contribution to this challenge is an ensemble of two state-of-the-art segmentation models, the nn-Unet and the Swin UNETR, augmented by a maximum intensity projection classifier that acts like a gating mechanism. If it predicts the existence of lesions, both segmentations are combined by a late fusion approach. Our solution achieves a Dice score of 72.12\% on patients diagnosed with lung cancer, melanoma, and lymphoma in our cross-validation. Code: https://github.com/heiligerl/autopet_submission



### Distilling Facial Knowledge With Teacher-Tasks: Semantic-Segmentation-Features For Pose-Invariant Face-Recognition
- **Arxiv ID**: http://arxiv.org/abs/2209.01115v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01115v1)
- **Published**: 2022-09-02 15:24:22+00:00
- **Updated**: 2022-09-02 15:24:22+00:00
- **Authors**: Ali Hassani, Zaid El Shair, Rafi Ud Duala Refat, Hafiz Malik
- **Comment**: None
- **Journal**: None
- **Summary**: This paper demonstrates a novel approach to improve face-recognition pose-invariance using semantic-segmentation features. The proposed Seg-Distilled-ID network jointly learns identification and semantic-segmentation tasks, where the segmentation task is then "distilled" (MobileNet encoder). Performance is benchmarked against three state-of-the-art encoders on a publicly available data-set emphasizing head-pose variations. Experimental evaluations show the Seg-Distilled-ID network shows notable robustness benefits, achieving 99.9% test-accuracy in comparison to 81.6% on ResNet-101, 96.1% on VGG-19 and 96.3% on InceptionV3. This is achieved using approximately one-tenth of the top encoder's inference parameters. These results demonstrate distilling semantic-segmentation features can efficiently address face-recognition pose-invariance.



### Back-to-Bones: Rediscovering the Role of Backbones in Domain Generalization
- **Arxiv ID**: http://arxiv.org/abs/2209.01121v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.01121v2)
- **Published**: 2022-09-02 15:30:17+00:00
- **Updated**: 2023-05-09 14:31:36+00:00
- **Authors**: Simone Angarano, Mauro Martini, Francesco Salvetti, Vittorio Mazzia, Marcello Chiaberge
- **Comment**: None
- **Journal**: None
- **Summary**: Domain Generalization (DG) studies the capability of a deep learning model to generalize to out-of-training distributions. In the last decade, literature has been massively filled with training methodologies that claim to obtain more abstract and robust data representations to tackle domain shifts. Recent research has provided a reproducible benchmark for DG, pointing out the effectiveness of naive empirical risk minimization (ERM) over existing algorithms. Nevertheless, researchers persist in using the same outdated feature extractors, and no attention has been given to the effects of different backbones yet. In this paper, we start back to the backbones proposing a comprehensive analysis of their intrinsic generalization capabilities, which so far have been ignored by the research community. We evaluate a wide variety of feature extractors, from standard residual solutions to transformer-based architectures, finding an evident linear correlation between large-scale single-domain classification accuracy and DG capability. Our extensive experimentation shows that by adopting competitive backbones in conjunction with effective data augmentation, plain ERM outperforms recent DG solutions and achieves state-of-the-art accuracy. Moreover, our additional qualitative studies reveal that novel backbones give more similar representations to same-class samples, separating different domains in the feature space. This boost in generalization capabilities leaves marginal room for DG algorithms. It suggests a new paradigm for investigating the problem, placing backbones in the spotlight and encouraging the development of consistent algorithms on top of them. The code is available at https://github.com/PIC4SeR/Back-to-Bones.



### nnOOD: A Framework for Benchmarking Self-supervised Anomaly Localisation Methods
- **Arxiv ID**: http://arxiv.org/abs/2209.01124v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01124v1)
- **Published**: 2022-09-02 15:34:02+00:00
- **Updated**: 2022-09-02 15:34:02+00:00
- **Authors**: Matthew Baugh, Jeremy Tan, Athanasios Vlontzos, Johanna P. Müller, Bernhard Kainz
- **Comment**: Accepted as Spotlight to UNSURE 2022, a workshop at MICCAI 2022
- **Journal**: None
- **Summary**: The wide variety of in-distribution and out-of-distribution data in medical imaging makes universal anomaly detection a challenging task. Recently a number of self-supervised methods have been developed that train end-to-end models on healthy data augmented with synthetic anomalies. However, it is difficult to compare these methods as it is not clear whether gains in performance are from the task itself or the training pipeline around it. It is also difficult to assess whether a task generalises well for universal anomaly detection, as they are often only tested on a limited range of anomalies. To assist with this we have developed nnOOD, a framework that adapts nnU-Net to allow for comparison of self-supervised anomaly localisation methods. By isolating the synthetic, self-supervised task from the rest of the training process we perform a more faithful comparison of the tasks, whilst also making the workflow for evaluating over a given dataset quick and easy. Using this we have implemented the current state-of-the-art tasks and evaluated them on a challenging X-ray dataset.



### ARST: Auto-Regressive Surgical Transformer for Phase Recognition from Laparoscopic Videos
- **Arxiv ID**: http://arxiv.org/abs/2209.01148v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2209.01148v1)
- **Published**: 2022-09-02 16:05:39+00:00
- **Updated**: 2022-09-02 16:05:39+00:00
- **Authors**: Xiaoyang Zou, Wenyong Liu, Junchen Wang, Rong Tao, Guoyan Zheng
- **Comment**: 11 Pages, 3 figures
- **Journal**: None
- **Summary**: Phase recognition plays an essential role for surgical workflow analysis in computer assisted intervention. Transformer, originally proposed for sequential data modeling in natural language processing, has been successfully applied to surgical phase recognition. Existing works based on transformer mainly focus on modeling attention dependency, without introducing auto-regression. In this work, an Auto-Regressive Surgical Transformer, referred as ARST, is first proposed for on-line surgical phase recognition from laparoscopic videos, modeling the inter-phase correlation implicitly by conditional probability distribution. To reduce inference bias and to enhance phase consistency, we further develop a consistency constraint inference strategy based on auto-regression. We conduct comprehensive validations on a well-known public dataset Cholec80. Experimental results show that our method outperforms the state-of-the-art methods both quantitatively and qualitatively, and achieves an inference rate of 66 frames per second (fps).



### A Novel Approach for Pill-Prescription Matching with GNN Assistance and Contrastive Learning
- **Arxiv ID**: http://arxiv.org/abs/2209.01152v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01152v1)
- **Published**: 2022-09-02 16:18:36+00:00
- **Updated**: 2022-09-02 16:18:36+00:00
- **Authors**: Trung Thanh Nguyen, Hoang Dang Nguyen, Thanh Hung Nguyen, Huy Hieu Pham, Ichiro Ide, Phi Le Nguyen
- **Comment**: Accepted for publication and presentation at the 19th Pacific Rim
  International Conference on Artificial Intelligence (PRICAI 2022)
- **Journal**: None
- **Summary**: Medication mistaking is one of the risks that can result in unpredictable consequences for patients. To mitigate this risk, we develop an automatic system that correctly identifies pill-prescription from mobile images. Specifically, we define a so-called pill-prescription matching task, which attempts to match the images of the pills taken with the pills' names in the prescription. We then propose PIMA, a novel approach using Graph Neural Network (GNN) and contrastive learning to address the targeted problem. In particular, GNN is used to learn the spatial correlation between the text boxes in the prescription and thereby highlight the text boxes carrying the pill names. In addition, contrastive learning is employed to facilitate the modeling of cross-modal similarity between textual representations of pill names and visual representations of pill images. We conducted extensive experiments and demonstrated that PIMA outperforms baseline models on a real-world dataset of pill and prescription images that we constructed. Specifically, PIMA improves the accuracy from 19.09% to 46.95% compared to other baselines. We believe our work can open up new opportunities to build new clinical applications and improve medication safety and patient care.



### Reconstructing editable prismatic CAD from rounded voxel models
- **Arxiv ID**: http://arxiv.org/abs/2209.01161v1
- **DOI**: 10.1145/3550469.3555424
- **Categories**: **cs.CV**, cs.LG, I.2.10
- **Links**: [PDF](http://arxiv.org/pdf/2209.01161v1)
- **Published**: 2022-09-02 16:44:10+00:00
- **Updated**: 2022-09-02 16:44:10+00:00
- **Authors**: Joseph G. Lambourne, Karl D. D. Willis, Pradeep Kumar Jayaraman, Longfei Zhang, Aditya Sanghi, Kamal Rahimi Malekshan
- **Comment**: SIGGRAPH Asia 2022 Conference Paper
- **Journal**: None
- **Summary**: Reverse Engineering a CAD shape from other representations is an important geometric processing step for many downstream applications. In this work, we introduce a novel neural network architecture to solve this challenging task and approximate a smoothed signed distance function with an editable, constrained, prismatic CAD model. During training, our method reconstructs the input geometry in the voxel space by decomposing the shape into a series of 2D profile images and 1D envelope functions. These can then be recombined in a differentiable way allowing a geometric loss function to be defined. During inference, we obtain the CAD data by first searching a database of 2D constrained sketches to find curves which approximate the profile images, then extrude them and use Boolean operations to build the final CAD model. Our method approximates the target shape more closely than other methods and outputs highly editable constrained parametric sketches which are compatible with existing CAD software.



### SIAN: Style-Guided Instance-Adaptive Normalization for Multi-Organ Histopathology Image Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2209.02412v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.02412v2)
- **Published**: 2022-09-02 16:45:46+00:00
- **Updated**: 2023-01-24 17:27:34+00:00
- **Authors**: Haotian Wang, Min Xian, Aleksandar Vakanski, Bryar Shareef
- **Comment**: None
- **Journal**: None
- **Summary**: Existing deep neural networks for histopathology image synthesis cannot generate image styles that align with different organs, and cannot produce accurate boundaries of clustered nuclei. To address these issues, we propose a style-guided instance-adaptive normalization (SIAN) approach to synthesize realistic color distributions and textures for histopathology images from different organs. SIAN contains four phases, semantization, stylization, instantiation, and modulation. The first two phases synthesize image semantics and styles by using semantic maps and learned image style vectors. The instantiation module integrates geometrical and topological information and generates accurate nuclei boundaries. We validate the proposed approach on a multiple-organ dataset, Extensive experimental results demonstrate that the proposed method generates more realistic histopathology images than four state-of-the-art approaches for five organs. By incorporating synthetic images from the proposed approach to model training, an instance segmentation network can achieve state-of-the-art performance.



### First Hitting Diffusion Models for Generating Manifold, Graph and Categorical Data
- **Arxiv ID**: http://arxiv.org/abs/2209.01170v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2209.01170v2)
- **Published**: 2022-09-02 17:01:32+00:00
- **Updated**: 2022-10-14 18:19:22+00:00
- **Authors**: Mao Ye, Lemeng Wu, Qiang Liu
- **Comment**: None
- **Journal**: None
- **Summary**: We propose a family of First Hitting Diffusion Models (FHDM), deep generative models that generate data with a diffusion process that terminates at a random first hitting time. This yields an extension of the standard fixed-time diffusion models that terminate at a pre-specified deterministic time. Although standard diffusion models are designed for continuous unconstrained data, FHDM is naturally designed to learn distributions on continuous as well as a range of discrete and structure domains. Moreover, FHDM enables instance-dependent terminate time and accelerates the diffusion process to sample higher quality data with fewer diffusion steps. Technically, we train FHDM by maximum likelihood estimation on diffusion trajectories augmented from observed data with conditional first hitting processes (i.e., bridge) derived based on Doob's $h$-transform, deviating from the commonly used time-reversal mechanism. We apply FHDM to generate data in various domains such as point cloud (general continuous distribution), climate and geographical events on earth (continuous distribution on the sphere), unweighted graphs (distribution of binary matrices), and segmentation maps of 2D images (high-dimensional categorical distribution). We observe considerable improvement compared with the state-of-the-art approaches in both quality and speed.



### CLONeR: Camera-Lidar Fusion for Occupancy Grid-aided Neural Representations
- **Arxiv ID**: http://arxiv.org/abs/2209.01194v4
- **DOI**: 10.1109/LRA.2023.3262139
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01194v4)
- **Published**: 2022-09-02 17:44:50+00:00
- **Updated**: 2023-04-04 17:48:17+00:00
- **Authors**: Alexandra Carlson, Manikandasriram Srinivasan Ramanagopal, Nathan Tseng, Matthew Johnson-Roberson, Ram Vasudevan, Katherine A. Skinner
- **Comment**: first two authors equally contributed
- **Journal**: IEEE Robotics and Automation Letters, vol. 8, no. 5, pp.
  2812-2819, May 2023
- **Summary**: Recent advances in neural radiance fields (NeRFs) achieve state-of-the-art novel view synthesis and facilitate dense estimation of scene properties. However, NeRFs often fail for large, unbounded scenes that are captured under very sparse views with the scene content concentrated far away from the camera, as is typical for field robotics applications. In particular, NeRF-style algorithms perform poorly: (1) when there are insufficient views with little pose diversity, (2) when scenes contain saturation and shadows, and (3) when finely sampling large unbounded scenes with fine structures becomes computationally intensive.   This paper proposes CLONeR, which significantly improves upon NeRF by allowing it to model large outdoor driving scenes that are observed from sparse input sensor views. This is achieved by decoupling occupancy and color learning within the NeRF framework into separate Multi-Layer Perceptrons (MLPs) trained using LiDAR and camera data, respectively. In addition, this paper proposes a novel method to build differentiable 3D Occupancy Grid Maps (OGM) alongside the NeRF model, and leverage this occupancy grid for improved sampling of points along a ray for volumetric rendering in metric space.   Through extensive quantitative and qualitative experiments on scenes from the KITTI dataset, this paper demonstrates that the proposed method outperforms state-of-the-art NeRF models on both novel view synthesis and dense depth prediction tasks when trained on sparse input data.



### Hierarchical Relational Learning for Few-Shot Knowledge Graph Completion
- **Arxiv ID**: http://arxiv.org/abs/2209.01205v3
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2209.01205v3)
- **Published**: 2022-09-02 17:57:03+00:00
- **Updated**: 2022-09-16 08:45:15+00:00
- **Authors**: Han Wu, Jie Yin, Bala Rajaratnam, Jianyuan Guo
- **Comment**: 10 pages, 5 figures
- **Journal**: None
- **Summary**: Knowledge graphs (KGs) are known for their large scale and knowledge inference ability, but are also notorious for the incompleteness associated with them. Due to the long-tail distribution of the relations in KGs, few-shot KG completion has been proposed as a solution to alleviate incompleteness and expand the coverage of KGs. It aims to make predictions for triplets involving novel relations when only a few training triplets are provided as reference. Previous methods have mostly focused on designing local neighbor aggregators to learn entity-level information and/or imposing sequential dependency assumption at the triplet level to learn meta relation information. However, valuable pairwise triplet-level interactions and context-level relational information have been largely overlooked for learning meta representations of few-shot relations. In this paper, we propose a hierarchical relational learning method (HiRe) for few-shot KG completion. By jointly capturing three levels of relational information (entity-level, triplet-level and context-level), HiRe can effectively learn and refine the meta representation of few-shot relations, and consequently generalize very well to new unseen relations. Extensive experiments on two benchmark datasets validate the superiority of HiRe against other state-of-the-art methods.



### Transformers in Remote Sensing: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2209.01206v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01206v1)
- **Published**: 2022-09-02 17:57:05+00:00
- **Updated**: 2022-09-02 17:57:05+00:00
- **Authors**: Abdulaziz Amer Aleissaee, Amandeep Kumar, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal, Gui-Song Xia, Fahad Shahbaz khan
- **Comment**: 22 pages, 13 figures
- **Journal**: None
- **Summary**: Deep learning-based algorithms have seen a massive popularity in different areas of remote sensing image analysis over the past decade. Recently, transformers-based architectures, originally introduced in natural language processing, have pervaded computer vision field where the self-attention mechanism has been utilized as a replacement to the popular convolution operator for capturing long-range dependencies. Inspired by recent advances in computer vision, remote sensing community has also witnessed an increased exploration of vision transformers for a diverse set of tasks. Although a number of surveys have focused on transformers in computer vision in general, to the best of our knowledge we are the first to present a systematic review of recent advances based on transformers in remote sensing. Our survey covers more than 60 recent transformers-based methods for different remote sensing problems in sub-areas of remote sensing: very high-resolution (VHR), hyperspectral (HSI) and synthetic aperture radar (SAR) imagery. We conclude the survey by discussing different challenges and open issues of transformers in remote sensing. Additionally, we intend to frequently update and maintain the latest transformers in remote sensing papers with their respective code at: https://github.com/VIROBO-15/Transformer-in-Remote-Sensing



### Person Monitoring by Full Body Tracking in Uniform Crowd Environment
- **Arxiv ID**: http://arxiv.org/abs/2209.01274v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2209.01274v1)
- **Published**: 2022-09-02 21:21:47+00:00
- **Updated**: 2022-09-02 21:21:47+00:00
- **Authors**: Zhibo Zhang, Omar Alremeithi, Maryam Almheiri, Marwa Albeshr, Xiaoxiong Zhang, Sajid Javed, Naoufel Werghi
- **Comment**: Accepted by the conference International Conference on Advances in
  Data-driven Computing and Intelligent Systems (ADCIS 2022), published in
  Scopus indexed Springer Book Series, 'Lecture Notes in Networks and Systems'
- **Journal**: None
- **Summary**: Full body trackers are utilized for surveillance and security purposes, such as person-tracking robots. In the Middle East, uniform crowd environments are the norm which challenges state-of-the-art trackers. Despite tremendous improvements in tracker technology documented in the past literature, these trackers have not been trained using a dataset that captures these environments. In this work, we develop an annotated dataset with one specific target per video in a uniform crowd environment. The dataset was generated in four different scenarios where mainly the target was moving alongside the crowd, sometimes occluding with them, and other times the camera's view of the target is blocked by the crowd for a short period. After the annotations, it was used in evaluating and fine-tuning a state-of-the-art tracker. Our results have shown that the fine-tuned tracker performed better on the evaluation dataset based on two quantitative evaluation metrics, compared to the initial pre-trained tracker.



