# Arxiv Papers in cs.CV on 2022-01-05
### Self-Supervised Approach to Addressing Zero-Shot Learning Problem
- **Arxiv ID**: http://arxiv.org/abs/2201.01391v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01391v2)
- **Published**: 2022-01-05 00:08:36+00:00
- **Updated**: 2022-01-21 14:09:29+00:00
- **Authors**: Ademola Okerinde, Sam Hoggatt, Divya Vani Lakkireddy, Nolan Brubaker, William Hsu, Lior Shamir, Brian Spiesman
- **Comment**: None
- **Journal**: The 4th International Conference on Computing and Data Science
  (CONF-CDS 2022)
- **Summary**: In recent years, self-supervised learning has had significant success in applications involving computer vision and natural language processing. The type of pretext task is important to this boost in performance. One common pretext task is the measure of similarity and dissimilarity between pairs of images. In this scenario, the two images that make up the negative pair are visibly different to humans. However, in entomology, species are nearly indistinguishable and thus hard to differentiate. In this study, we explored the performance of a Siamese neural network using contrastive loss by learning to push apart embeddings of bumblebee species pair that are dissimilar, and pull together similar embeddings. Our experimental results show a 61% F1-score on zero-shot instances, a performance showing 11% improvement on samples of classes that share intersections with the training set.



### Corrupting Data to Remove Deceptive Perturbation: Using Preprocessing Method to Improve System Robustness
- **Arxiv ID**: http://arxiv.org/abs/2201.01399v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01399v1)
- **Published**: 2022-01-05 00:53:41+00:00
- **Updated**: 2022-01-05 00:53:41+00:00
- **Authors**: Hieu Le, Hans Walker, Dung Tran, Peter Chin
- **Comment**: CSCI 2021
- **Journal**: None
- **Summary**: Although deep neural networks have achieved great performance on classification tasks, recent studies showed that well trained networks can be fooled by adding subtle noises. This paper introduces a new approach to improve neural network robustness by applying the recovery process on top of the naturally trained classifier. In this approach, images will be intentionally corrupted by some significant operator and then be recovered before passing through the classifiers. SARGAN -- an extension on Generative Adversarial Networks (GAN) is capable of denoising radar signals. This paper will show that SARGAN can also recover corrupted images by removing the adversarial effects. Our results show that this approach does improve the performance of naturally trained networks.



### Fusing Convolutional Neural Network and Geometric Constraint for Image-based Indoor Localization
- **Arxiv ID**: http://arxiv.org/abs/2201.01408v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2201.01408v1)
- **Published**: 2022-01-05 02:04:41+00:00
- **Updated**: 2022-01-05 02:04:41+00:00
- **Authors**: Jingwei Song, Mitesh Patel, Maani Ghaffari
- **Comment**: Accepted by IEEE robotics and automation letters
- **Journal**: None
- **Summary**: This paper proposes a new image-based localization framework that explicitly localizes the camera/robot by fusing Convolutional Neural Network (CNN) and sequential images' geometric constraints. The camera is localized using a single or few observed images and training images with 6-degree-of-freedom pose labels. A Siamese network structure is adopted to train an image descriptor network, and the visually similar candidate image in the training set is retrieved to localize the testing image geometrically. Meanwhile, a probabilistic motion model predicts the pose based on a constant velocity assumption. The two estimated poses are finally fused using their uncertainties to yield an accurate pose prediction. This method leverages the geometric uncertainty and is applicable in indoor scenarios predominated by diffuse illumination. Experiments on simulation and real data sets demonstrate the efficiency of our proposed method. The results further show that combining the CNN-based framework with geometric constraint achieves better accuracy when compared with CNN-only methods, especially when the training data size is small.



### Synthesizing Tensor Transformations for Visual Self-attention
- **Arxiv ID**: http://arxiv.org/abs/2201.01410v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01410v1)
- **Published**: 2022-01-05 02:07:32+00:00
- **Updated**: 2022-01-05 02:07:32+00:00
- **Authors**: Xian Wei, Xihao Wang, Hai Lan, JiaMing Lei, Yanhui Huang, Hui Yu, Jian Yang
- **Comment**: 13 pages,3 figures
- **Journal**: None
- **Summary**: Self-attention shows outstanding competence in capturing long-range relationships while enhancing performance on vision tasks, such as image classification and image captioning. However, the self-attention module highly relies on the dot product multiplication and dimension alignment among query-key-value features, which cause two problems: (1) The dot product multiplication results in exhaustive and redundant computation. (2) Due to the visual feature map often appearing as a multi-dimensional tensor, reshaping the scale of the tensor feature to adapt to the dimension alignment might destroy the internal structure of the tensor feature map. To address these problems, this paper proposes a self-attention plug-in module with its variants, namely, Synthesizing Tensor Transformations (STT), for directly processing image tensor features. Without computing the dot-product multiplication among query-key-value, the basic STT is composed of the tensor transformation to learn the synthetic attention weight from visual information. The effectiveness of STT series is validated on the image classification and image caption. Experiments show that the proposed STT achieves competitive performance while keeping robustness compared to self-attention based above vision tasks.



### Problem-dependent attention and effort in neural networks with applications to image resolution and model selection
- **Arxiv ID**: http://arxiv.org/abs/2201.01415v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG, eess.IV, I.2.6; I.2.10; I.4.0; H.3.3
- **Links**: [PDF](http://arxiv.org/pdf/2201.01415v4)
- **Published**: 2022-01-05 02:27:35+00:00
- **Updated**: 2023-04-14 00:08:08+00:00
- **Authors**: Chris Rohlfs
- **Comment**: None
- **Journal**: None
- **Summary**: This paper introduces two new ensemble-based methods to reduce the data and computation costs of image classification. They can be used with any set of classifiers and do not require additional training. In the first approach, data usage is reduced by only analyzing a full-sized image if the model has low confidence in classifying a low-resolution pixelated version. When applied on the best performing classifiers considered here, data usage is reduced by 61.2% on MNIST, 69.6% on KMNIST, 56.3% on FashionMNIST, 84.6% on SVHN, 40.6% on ImageNet, and 27.6% on ImageNet-V2, all with a less than 5% reduction in accuracy. However, for CIFAR-10, the pixelated data are not particularly informative, and the ensemble approach increases data usage while reducing accuracy. In the second approach, compute costs are reduced by only using a complex model if a simpler model has low confidence in its classification. Computation cost is reduced by 82.1% on MNIST, 47.6% on KMNIST, 72.3% on FashionMNIST, 86.9% on SVHN, 89.2% on ImageNet, and 81.5% on ImageNet-V2, all with a less than 5% reduction in accuracy; for CIFAR-10 the corresponding improvements are smaller at 13.5%. When cost is not an object, choosing the projection from the most confident model for each observation increases validation accuracy to 81.0% from 79.3% for ImageNet and to 69.4% from 67.5% for ImageNet-V2.



### Latent Vector Expansion using Autoencoder for Anomaly Detection
- **Arxiv ID**: http://arxiv.org/abs/2201.01416v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01416v1)
- **Published**: 2022-01-05 02:28:38+00:00
- **Updated**: 2022-01-05 02:28:38+00:00
- **Authors**: UJu Gim, YeongHyeon Park
- **Comment**: 3 pages, 2 figures, In Proceedings of the 34th Workshop on Image
  Processing and Image Understanding (IPIU 2022)
- **Journal**: None
- **Summary**: Deep learning methods can classify various unstructured data such as images, language, and voice as input data. As the task of classifying anomalies becomes more important in the real world, various methods exist for classifying using deep learning with data collected in the real world. As the task of classifying anomalies becomes more important in the real world, there are various methods for classifying using deep learning with data collected in the real world. Among the various methods, the representative approach is a method of extracting and learning the main features based on a transition model from pre-trained models, and a method of learning an autoencoderbased structure only with normal data and classifying it as abnormal through a threshold value. However, if the dataset is imbalanced, even the state-of-the-arts models do not achieve good performance. This can be addressed by augmenting normal and abnormal features in imbalanced data as features with strong distinction. We use the features of the autoencoder to train latent vectors from low to high dimensionality. We train normal and abnormal data as a feature that has a strong distinction among the features of imbalanced data. We propose a latent vector expansion autoencoder model that improves classification performance at imbalanced data. The proposed method shows performance improvement compared to the basic autoencoder using imbalanced anomaly dataset.



### Eye Know You Too: A DenseNet Architecture for End-to-end Eye Movement Biometrics
- **Arxiv ID**: http://arxiv.org/abs/2201.02110v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.HC
- **Links**: [PDF](http://arxiv.org/pdf/2201.02110v2)
- **Published**: 2022-01-05 02:49:30+00:00
- **Updated**: 2022-03-28 22:54:25+00:00
- **Authors**: Dillon Lohr, Oleg V Komogortsev
- **Comment**: This work has been submitted to the IEEE for possible publication.
  Copyright may be transferred without notice, after which this version may no
  longer be accessible
- **Journal**: None
- **Summary**: Eye movement biometrics (EMB) is a relatively recent behavioral biometric modality that may have the potential to become the primary authentication method in virtual- and augmented-reality devices due to their emerging use of eye-tracking sensors to enable foveated rendering techniques. However, existing EMB models have yet to demonstrate levels of performance that would be acceptable for real-world use. Deep learning approaches to EMB have largely employed plain convolutional neural networks (CNNs), but there have been many milestone improvements to convolutional architectures over the years including residual networks (ResNets) and densely connected convolutional networks (DenseNets). The present study employs a DenseNet architecture for end-to-end EMB and compares the proposed model against the most relevant prior works. The proposed technique not only outperforms the previous state of the art, but is also the first to approach a level of authentication performance that would be acceptable for real-world use.



### Advancing 3D Medical Image Analysis with Variable Dimension Transform based Supervised 3D Pre-training
- **Arxiv ID**: http://arxiv.org/abs/2201.01426v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01426v1)
- **Published**: 2022-01-05 03:11:21+00:00
- **Updated**: 2022-01-05 03:11:21+00:00
- **Authors**: Shu Zhang, Zihao Li, Hong-Yu Zhou, Jiechao Ma, Yizhou Yu
- **Comment**: None
- **Journal**: None
- **Summary**: The difficulties in both data acquisition and annotation substantially restrict the sample sizes of training datasets for 3D medical imaging applications. As a result, constructing high-performance 3D convolutional neural networks from scratch remains a difficult task in the absence of a sufficient pre-training parameter. Previous efforts on 3D pre-training have frequently relied on self-supervised approaches, which use either predictive or contrastive learning on unlabeled data to build invariant 3D representations. However, because of the unavailability of large-scale supervision information, obtaining semantically invariant and discriminative representations from these learning frameworks remains problematic. In this paper, we revisit an innovative yet simple fully-supervised 3D network pre-training framework to take advantage of semantic supervisions from large-scale 2D natural image datasets. With a redesigned 3D network architecture, reformulated natural images are used to address the problem of data scarcity and develop powerful 3D representations. Comprehensive experiments on four benchmark datasets demonstrate that the proposed pre-trained models can effectively accelerate convergence while also improving accuracy for a variety of 3D medical imaging tasks such as classification, segmentation and detection. In addition, as compared to training from scratch, it can save up to 60% of annotation efforts. On the NIH DeepLesion dataset, it likewise achieves state-of-the-art detection performance, outperforming earlier self-supervised and fully-supervised pre-training approaches, as well as methods that do training from scratch. To facilitate further development of 3D medical models, our code and pre-trained model weights are publicly available at https://github.com/urmagicsmine/CSPR.



### Attention-based Dual Supervised Decoder for RGBD Semantic Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2201.01427v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01427v2)
- **Published**: 2022-01-05 03:12:27+00:00
- **Updated**: 2022-03-15 03:29:15+00:00
- **Authors**: Yang Zhang, Yang Yang, Chenyun Xiong, Guodong Sun, Yanwen Guo
- **Comment**: 12 pages, 6 figures
- **Journal**: None
- **Summary**: Encoder-decoder models have been widely used in RGBD semantic segmentation, and most of them are designed via a two-stream network. In general, jointly reasoning the color and geometric information from RGBD is beneficial for semantic segmentation. However, most existing approaches fail to comprehensively utilize multimodal information in both the encoder and decoder. In this paper, we propose a novel attention-based dual supervised decoder for RGBD semantic segmentation. In the encoder, we design a simple yet effective attention-based multimodal fusion module to extract and fuse deeply multi-level paired complementary information. To learn more robust deep representations and rich multi-modal information, we introduce a dual-branch decoder to effectively leverage the correlations and complementary cues of different tasks. Extensive experiments on NYUDv2 and SUN-RGBD datasets demonstrate that our method achieves superior performance against the state-of-the-art methods.



### Neural KEM: A Kernel Method with Deep Coefficient Prior for PET Image Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2201.01443v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, physics.med-ph
- **Links**: [PDF](http://arxiv.org/pdf/2201.01443v2)
- **Published**: 2022-01-05 04:12:38+00:00
- **Updated**: 2022-10-24 05:46:09+00:00
- **Authors**: Siqi Li, Kuang Gong, Ramsey D. Badawi, Edward J. Kim, Jinyi Qi, Guobao Wang
- **Comment**: arXiv admin note: text overlap with arXiv:2110.01174
- **Journal**: None
- **Summary**: Image reconstruction of low-count positron emission tomography (PET) data is challenging. Kernel methods address the challenge by incorporating image prior information in the forward model of iterative PET image reconstruction. The kernelized expectation-maximization (KEM) algorithm has been developed and demonstrated to be effective and easy to implement. A common approach for a further improvement of the kernel method would be adding an explicit regularization, which however leads to a complex optimization problem. In this paper, we propose an implicit regularization for the kernel method by using a deep coefficient prior, which represents the kernel coefficient image in the PET forward model using a convolutional neural-network. To solve the maximum-likelihood neural network-based reconstruction problem, we apply the principle of optimization transfer to derive a neural KEM algorithm. Each iteration of the algorithm consists of two separate steps: a KEM step for image update from the projection data and a deep-learning step in the image domain for updating the kernel coefficient image using the neural network. This optimization algorithm is guaranteed to monotonically increase the data likelihood. The results from computer simulations and real patient data have demonstrated that the neural KEM can outperform existing KEM and deep image prior methods.



### Deep Learning-Based Sparse Whole-Slide Image Analysis for the Diagnosis of Gastric Intestinal Metaplasia
- **Arxiv ID**: http://arxiv.org/abs/2201.01449v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01449v1)
- **Published**: 2022-01-05 04:43:46+00:00
- **Updated**: 2022-01-05 04:43:46+00:00
- **Authors**: Jon Braatz, Pranav Rajpurkar, Stephanie Zhang, Andrew Y. Ng, Jeanne Shen
- **Comment**: None
- **Journal**: None
- **Summary**: In recent years, deep learning has successfully been applied to automate a wide variety of tasks in diagnostic histopathology. However, fast and reliable localization of small-scale regions-of-interest (ROI) has remained a key challenge, as discriminative morphologic features often occupy only a small fraction of a gigapixel-scale whole-slide image (WSI). In this paper, we propose a sparse WSI analysis method for the rapid identification of high-power ROI for WSI-level classification. We develop an evaluation framework inspired by the early classification literature, in order to quantify the tradeoff between diagnostic performance and inference time for sparse analytic approaches. We test our method on a common but time-consuming task in pathology - that of diagnosing gastric intestinal metaplasia (GIM) on hematoxylin and eosin (H&E)-stained slides from endoscopic biopsy specimens. GIM is a well-known precursor lesion along the pathway to development of gastric cancer. We performed a thorough evaluation of the performance and inference time of our approach on a test set of GIM-positive and GIM-negative WSI, finding that our method successfully detects GIM in all positive WSI, with a WSI-level classification area under the receiver operating characteristic curve (AUC) of 0.98 and an average precision (AP) of 0.95. Furthermore, we show that our method can attain these metrics in under one minute on a standard CPU. Our results are applicable toward the goal of developing neural networks that can easily be deployed in clinical settings to support pathologists in quickly localizing and diagnosing small-scale morphologic features in WSI.



### Robust photon-efficient imaging using a pixel-wise residual shrinkage network
- **Arxiv ID**: http://arxiv.org/abs/2201.01453v2
- **DOI**: 10.1364/OE.452597
- **Categories**: **eess.IV**, cs.CV, eess.SP
- **Links**: [PDF](http://arxiv.org/pdf/2201.01453v2)
- **Published**: 2022-01-05 05:08:12+00:00
- **Updated**: 2022-05-18 05:33:09+00:00
- **Authors**: Gongxin Yao, Yiwei Chen, Yong Liu, Xiaomin Hu, Yu Pan
- **Comment**: None
- **Journal**: Optics Express 30(11):18856-18873, 2022
- **Summary**: Single-photon light detection and ranging (LiDAR) has been widely applied to 3D imaging in challenging scenarios. However, limited signal photon counts and high noises in the collected data have posed great challenges for predicting the depth image precisely. In this paper, we propose a pixel-wise residual shrinkage network for photon-efficient imaging from high-noise data, which adaptively generates the optimal thresholds for each pixel and denoises the intermediate features by soft thresholding. Besides, redefining the optimization target as pixel-wise classification provides a sharp advantage in producing confident and accurate depth estimation when compared with existing research. Comprehensive experiments conducted on both simulated and real-world datasets demonstrate that the proposed model outperforms the state-of-the-arts and maintains robust imaging performance under different signal-to-noise ratios including the extreme case of 1:100.



### Cross-SRN: Structure-Preserving Super-Resolution Network with Cross Convolution
- **Arxiv ID**: http://arxiv.org/abs/2201.01458v2
- **DOI**: 10.1109/TCSVT.2021.3138431
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01458v2)
- **Published**: 2022-01-05 05:15:01+00:00
- **Updated**: 2022-01-07 09:40:00+00:00
- **Authors**: Yuqing Liu, Qi Jia, Xin Fan, Shanshe Wang, Siwei Ma, Wen Gao
- **Comment**: None
- **Journal**: None
- **Summary**: It is challenging to restore low-resolution (LR) images to super-resolution (SR) images with correct and clear details. Existing deep learning works almost neglect the inherent structural information of images, which acts as an important role for visual perception of SR results. In this paper, we design a hierarchical feature exploitation network to probe and preserve structural information in a multi-scale feature fusion manner. First, we propose a cross convolution upon traditional edge detectors to localize and represent edge features. Then, cross convolution blocks (CCBs) are designed with feature normalization and channel attention to consider the inherent correlations of features. Finally, we leverage multi-scale feature fusion group (MFFG) to embed the cross convolution blocks and develop the relations of structural features in different scales hierarchically, invoking a lightweight structure-preserving network named as Cross-SRN. Experimental results demonstrate the Cross-SRN achieves competitive or superior restoration performances against the state-of-the-art methods with accurate and clear structural details. Moreover, we set a criterion to select images with rich structural textures. The proposed Cross-SRN outperforms the state-of-the-art methods on the selected benchmark, which demonstrates that our network has a significant advantage in preserving edges.



### Challenges of Artificial Intelligence -- From Machine Learning and Computer Vision to Emotional Intelligence
- **Arxiv ID**: http://arxiv.org/abs/2201.01466v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01466v1)
- **Published**: 2022-01-05 06:00:22+00:00
- **Updated**: 2022-01-05 06:00:22+00:00
- **Authors**: Matti Pietikäinen, Olli Silven
- **Comment**: 234 pages. Published as an electronic publication at the University
  of Oulu, Finland, in December 2021, ISBN: 978-952-62-3199-0 link
  http://jultika.oulu.fi/Record/isbn978-952-62-3199-0
- **Journal**: None
- **Summary**: Artificial intelligence (AI) has become a part of everyday conversation and our lives. It is considered as the new electricity that is revolutionizing the world. AI is heavily invested in both industry and academy. However, there is also a lot of hype in the current AI debate. AI based on so-called deep learning has achieved impressive results in many problems, but its limits are already visible. AI has been under research since the 1940s, and the industry has seen many ups and downs due to over-expectations and related disappointments that have followed.   The purpose of this book is to give a realistic picture of AI, its history, its potential and limitations. We believe that AI is a helper, not a ruler of humans. We begin by describing what AI is and how it has evolved over the decades. After fundamentals, we explain the importance of massive data for the current mainstream of artificial intelligence. The most common representations for AI, methods, and machine learning are covered. In addition, the main application areas are introduced. Computer vision has been central to the development of AI. The book provides a general introduction to computer vision, and includes an exposure to the results and applications of our own research. Emotions are central to human intelligence, but little use has been made in AI. We present the basics of emotional intelligence and our own research on the topic. We discuss super-intelligence that transcends human understanding, explaining why such achievement seems impossible on the basis of present knowledge,and how AI could be improved. Finally, a summary is made of the current state of AI and what to do in the future. In the appendix, we look at the development of AI education, especially from the perspective of contents at our own university.



### Sign Language Recognition System using TensorFlow Object Detection API
- **Arxiv ID**: http://arxiv.org/abs/2201.01486v2
- **DOI**: 10.1007/978-3-030-96040-7_48
- **Categories**: **cs.CV**, cs.AI, cs.LG, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2201.01486v2)
- **Published**: 2022-01-05 07:13:03+00:00
- **Updated**: 2022-03-03 04:51:42+00:00
- **Authors**: Sharvani Srivastava, Amisha Gangwar, Richa Mishra, Sudhakar Singh
- **Comment**: 14 pages, 5 figures, ANTIC 2021
- **Journal**: None
- **Summary**: Communication is defined as the act of sharing or exchanging information, ideas or feelings. To establish communication between two people, both of them are required to have knowledge and understanding of a common language. But in the case of deaf and dumb people, the means of communication are different. Deaf is the inability to hear and dumb is the inability to speak. They communicate using sign language among themselves and with normal people but normal people do not take seriously the importance of sign language. Not everyone possesses the knowledge and understanding of sign language which makes communication difficult between a normal person and a deaf and dumb person. To overcome this barrier, one can build a model based on machine learning. A model can be trained to recognize different gestures of sign language and translate them into English. This will help a lot of people in communicating and conversing with deaf and dumb people. The existing Indian Sing Language Recognition systems are designed using machine learning algorithms with single and double-handed gestures but they are not real-time. In this paper, we propose a method to create an Indian Sign Language dataset using a webcam and then using transfer learning, train a TensorFlow model to create a real-time Sign Language Recognition system. The system achieves a good level of accuracy even with a limited size dataset.



### Exemplar-free Class Incremental Learning via Discriminative and Comparable One-class Classifiers
- **Arxiv ID**: http://arxiv.org/abs/2201.01488v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01488v1)
- **Published**: 2022-01-05 07:16:34+00:00
- **Updated**: 2022-01-05 07:16:34+00:00
- **Authors**: Wenju Sun, Qingyong Li, Jing Zhang, Danyu Wang, Wen Wang, Yangli-ao Geng
- **Comment**: None
- **Journal**: [J]. Pattern Recognition, 2023, 140: 109561
- **Summary**: The exemplar-free class incremental learning requires classification models to learn new class knowledge incrementally without retaining any old samples. Recently, the framework based on parallel one-class classifiers (POC), which trains a one-class classifier (OCC) independently for each category, has attracted extensive attention, since it can naturally avoid catastrophic forgetting. POC, however, suffers from weak discriminability and comparability due to its independent training strategy for different OOCs. To meet this challenge, we propose a new framework, named Discriminative and Comparable One-class classifiers for Incremental Learning (DisCOIL). DisCOIL follows the basic principle of POC, but it adopts variational auto-encoders (VAE) instead of other well-established one-class classifiers (e.g. deep SVDD), because a trained VAE can not only identify the probability of an input sample belonging to a class but also generate pseudo samples of the class to assist in learning new tasks. With this advantage, DisCOIL trains a new-class VAE in contrast with the old-class VAEs, which forces the new-class VAE to reconstruct better for new-class samples but worse for the old-class pseudo samples, thus enhancing the comparability. Furthermore, DisCOIL introduces a hinge reconstruction loss to ensure the discriminability. We evaluate our method extensively on MNIST, CIFAR10, and Tiny-ImageNet. The experimental results show that DisCOIL achieves state-of-the-art performance.



### Debiased Learning from Naturally Imbalanced Pseudo-Labels
- **Arxiv ID**: http://arxiv.org/abs/2201.01490v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01490v2)
- **Published**: 2022-01-05 07:40:24+00:00
- **Updated**: 2022-04-21 09:13:11+00:00
- **Authors**: Xudong Wang, Zhirong Wu, Long Lian, Stella X. Yu
- **Comment**: Accepted by CVPR 2022
- **Journal**: None
- **Summary**: Pseudo-labels are confident predictions made on unlabeled target data by a classifier trained on labeled source data. They are widely used for adapting a model to unlabeled data, e.g., in a semi-supervised learning setting.   Our key insight is that pseudo-labels are naturally imbalanced due to intrinsic data similarity, even when a model is trained on balanced source data and evaluated on balanced target data. If we address this previously unknown imbalanced classification problem arising from pseudo-labels instead of ground-truth training labels, we could remove model biases towards false majorities created by pseudo-labels.   We propose a novel and effective debiased learning method with pseudo-labels, based on counterfactual reasoning and adaptive margins: The former removes the classifier response bias, whereas the latter adjusts the margin of each class according to the imbalance of pseudo-labels. Validated by extensive experimentation, our simple debiased learning delivers significant accuracy gains over the state-of-the-art on ImageNet-1K: 26% for semi-supervised learning with 0.2% annotations and 9% for zero-shot learning. Our code is available at: https://github.com/frank-xwang/debiased-pseudo-labeling.



### FAVER: Blind Quality Prediction of Variable Frame Rate Videos
- **Arxiv ID**: http://arxiv.org/abs/2201.01492v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01492v1)
- **Published**: 2022-01-05 07:54:12+00:00
- **Updated**: 2022-01-05 07:54:12+00:00
- **Authors**: Qi Zheng, Zhengzhong Tu, Pavan C. Madhusudana, Xiaoyang Zeng, Alan C. Bovik, Yibo Fan
- **Comment**: 12 pages, 8 figures
- **Journal**: None
- **Summary**: Video quality assessment (VQA) remains an important and challenging problem that affects many applications at the widest scales. Recent advances in mobile devices and cloud computing techniques have made it possible to capture, process, and share high resolution, high frame rate (HFR) videos across the Internet nearly instantaneously. Being able to monitor and control the quality of these streamed videos can enable the delivery of more enjoyable content and perceptually optimized rate control. Accordingly, there is a pressing need to develop VQA models that can be deployed at enormous scales. While some recent effects have been applied to full-reference (FR) analysis of variable frame rate and HFR video quality, the development of no-reference (NR) VQA algorithms targeting frame rate variations has been little studied. Here, we propose a first-of-a-kind blind VQA model for evaluating HFR videos, which we dub the Framerate-Aware Video Evaluator w/o Reference (FAVER). FAVER uses extended models of spatial natural scene statistics that encompass space-time wavelet-decomposed video signals, to conduct efficient frame rate sensitive quality prediction. Our extensive experiments on several HFR video quality datasets show that FAVER outperforms other blind VQA algorithms at a reasonable computational cost. To facilitate reproducible research and public evaluation, an implementation of FAVER is being made freely available online: \url{https://github.com/uniqzheng/HFR-BVQA}.



### Improving Object Detection, Multi-object Tracking, and Re-Identification for Disaster Response Drones
- **Arxiv ID**: http://arxiv.org/abs/2201.01494v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01494v1)
- **Published**: 2022-01-05 07:56:58+00:00
- **Updated**: 2022-01-05 07:56:58+00:00
- **Authors**: Chongkeun Paik, Hyunwoo J. Kim
- **Comment**: None
- **Journal**: None
- **Summary**: We aim to detect and identify multiple objects using multiple cameras and computer vision for disaster response drones. The major challenges are taming detection errors, resolving ID switching and fragmentation, adapting to multi-scale features and multiple views with global camera motion. Two simple approaches are proposed to solve these issues. One is a fast multi-camera system that added a tracklet association, and the other is incorporating a high-performance detector and tracker to resolve restrictions. (...) The accuracy of our first approach (85.71%) is slightly improved compared to our baseline, FairMOT (85.44%) in the validation dataset. In the final results calculated based on L2-norm error, the baseline was 48.1, while the proposed model combination was 34.9, which is a great reduction of error by a margin of 27.4%. In the second approach, although DeepSORT only processes a quarter of all frames due to hardware and time limitations, our model with DeepSORT (42.9%) outperforms FairMOT (71.4%) in terms of recall. Both of our models ranked second and third place in the `AI Grand Challenge' organized by the Korean Ministry of Science and ICT in 2020 and 2021, respectively. The source codes are publicly available at these URLs (github.com/mlvlab/drone_ai_challenge, github.com/mlvlab/Drone_Task1, github.com/mlvlab/Rony2_task3, github.com/mlvlab/Drone_task4).



### Rethinking Depth Estimation for Multi-View Stereo: A Unified Representation
- **Arxiv ID**: http://arxiv.org/abs/2201.01501v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2201.01501v3)
- **Published**: 2022-01-05 08:49:31+00:00
- **Updated**: 2022-03-11 08:58:57+00:00
- **Authors**: Rui Peng, Rongjie Wang, Zhenyu Wang, Yawen Lai, Ronggang Wang
- **Comment**: CVPR 2022 Accepted
- **Journal**: None
- **Summary**: Depth estimation is solved as a regression or classification problem in existing learning-based multi-view stereo methods. Although these two representations have recently demonstrated their excellent performance, they still have apparent shortcomings, e.g., regression methods tend to overfit due to the indirect learning cost volume, and classification methods cannot directly infer the exact depth due to its discrete prediction. In this paper, we propose a novel representation, termed Unification, to unify the advantages of regression and classification. It can directly constrain the cost volume like classification methods, but also realize the sub-pixel depth prediction like regression methods. To excavate the potential of unification, we design a new loss function named Unified Focal Loss, which is more uniform and reasonable to combat the challenge of sample imbalance. Combining these two unburdened modules, we present a coarse-to-fine framework, that we call UniMVSNet. The results of ranking first on both DTU and Tanks and Temples benchmarks verify that our model not only performs the best but also has the best generalization ability.



### Towards Uniform Point Distribution in Feature-preserving Point Cloud Filtering
- **Arxiv ID**: http://arxiv.org/abs/2201.01503v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01503v2)
- **Published**: 2022-01-05 09:08:44+00:00
- **Updated**: 2022-01-17 03:33:52+00:00
- **Authors**: Shuaijun Chen, Jinxi Wang, Wei Pan, Shang Gao, Meili Wang, Xuequan Lu
- **Comment**: This paper is accepted to CVM
- **Journal**: None
- **Summary**: As a popular representation of 3D data, point cloud may contain noise and need to be filtered before use. Existing point cloud filtering methods either cannot preserve sharp features or result in uneven point distribution in the filtered output. To address this problem, this paper introduces a point cloud filtering method that considers both point distribution and feature preservation during filtering. The key idea is to incorporate a repulsion term with a data term in energy minimization. The repulsion term is responsible for the point distribution, while the data term is to approximate the noisy surfaces while preserving the geometric features. This method is capable of handling models with fine-scale features and sharp features. Extensive experiments show that our method yields better results with a more uniform point distribution ($5.8\times10^{-5}$ Chamfer Distance on average) in seconds.



### Culture-to-Culture Image Translation and User Evaluation
- **Arxiv ID**: http://arxiv.org/abs/2201.01565v6
- **DOI**: None
- **Categories**: **cs.CV**, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2201.01565v6)
- **Published**: 2022-01-05 12:10:42+00:00
- **Updated**: 2023-05-12 14:18:10+00:00
- **Authors**: Giulia Zaino, Carmine Tommaso Recchiuto, Antonio Sgorbissa
- **Comment**: 31 pages (bibliography excluded), 4 figures, 6 Tables
- **Journal**: None
- **Summary**: The article introduces the concept of image "culturization," which we define as the process of altering the ``brushstroke of cultural features" that make objects perceived as belonging to a given culture while preserving their functionalities. First, we defined a pipeline for translating objects' images from a source to a target cultural domain based on state-of-the-art Generative Adversarial Networks. Then, we gathered data through an online questionnaire to test four hypotheses concerning the impact of images belonging to different cultural domains on Italian participants. As expected, results depend on individual tastes and preferences: however, they align with our conjecture that some people, during the interaction with an intelligent system, will prefer to be shown images modified to match their cultural background. The study has two main limitations. First, we focussed on the culturization of individual objects instead of complete scenes. However, objects play a crucial role in conveying cultural meanings and can strongly influence how an image is perceived within a specific cultural context. Understanding and addressing object-level translation is a vital step toward achieving more comprehensive scene-level translation in future research. Second, we performed experiments with Italian participants only. We think that there are unique aspects of Italian culture that make it an interesting and relevant case study for exploring the impact of image culturization. Italy is a very culturally conservative society, and Italians have specific sensitivities and expectations regarding the accurate representation of their cultural identity and traditions, which can shape individuals' preferences and inclinations toward certain visual styles, aesthetics, and design choices. As a consequence, we think they are an ideal candidate for a preliminary investigation of image culturization.



### Learning True Rate-Distortion-Optimization for End-To-End Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2201.01586v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01586v1)
- **Published**: 2022-01-05 13:02:00+00:00
- **Updated**: 2022-01-05 13:02:00+00:00
- **Authors**: Fabian Brand, Kristian Fischer, Alexander Kopte, André Kaup
- **Comment**: Accepted to DCC as Poster
- **Journal**: None
- **Summary**: Even though rate-distortion optimization is a crucial part of traditional image and video compression, not many approaches exist which transfer this concept to end-to-end-trained image compression. Most frameworks contain static compression and decompression models which are fixed after training, so efficient rate-distortion optimization is not possible. In a previous work, we proposed RDONet, which enables an RDO approach comparable to adaptive block partitioning in HEVC. In this paper, we enhance the training by introducing low-complexity estimations of the RDO result into the training. Additionally, we propose fast and very fast RDO inference modes. With our novel training method, we achieve average rate savings of 19.6% in MS-SSIM over the previous RDONet model, which equals rate savings of 27.3% over a comparable conventional deep image coder.



### Biphasic Face Photo-Sketch Synthesis via Semantic-Driven Generative Adversarial Network with Graph Representation Learning
- **Arxiv ID**: http://arxiv.org/abs/2201.01592v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01592v1)
- **Published**: 2022-01-05 13:14:14+00:00
- **Updated**: 2022-01-05 13:14:14+00:00
- **Authors**: Xingqun Qi, Muyi Sun, Qi Li, Caifeng Shan
- **Comment**: Under Review. arXiv admin note: text overlap with arXiv:2106.15121
- **Journal**: None
- **Summary**: In recent years, significant progress has been achieved in biphasic face photo-sketch synthesis with the development of Generative Adversarial Network (GAN). Biphasic face photo-sketch synthesis could be applied in wide-ranging fields such as digital entertainment and law enforcement. However, generating realistic photos and distinct sketches suffers from great challenges due to the low quality of sketches and complex photo variations in the real scenes. To this end, we propose a novel Semantic-Driven Generative Adversarial Network to address the above issues, cooperating with the Graph Representation Learning. Specifically, we inject class-wise semantic layouts into the generator to provide style-based spatial supervision for synthesized face photos and sketches. In addition, to improve the fidelity of the generated results, we leverage the semantic layouts to construct two types of Representational Graphs which indicate the intra-class semantic features and inter-class structural features of the synthesized images. Furthermore, we design two types of constraints based on the proposed Representational Graphs which facilitate the preservation of the details in generated face photos and sketches. Moreover, to further enhance the perceptual quality of synthesized images, we propose a novel biphasic training strategy which is dedicated to refine the generated results through Iterative Cycle Training. Extensive experiments are conducted on CUFS and CUFSF datasets to demonstrate the prominent ability of our proposed method which achieves the state-of-the-art performance.



### GLAN: A Graph-based Linear Assignment Network
- **Arxiv ID**: http://arxiv.org/abs/2201.02057v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.02057v1)
- **Published**: 2022-01-05 13:18:02+00:00
- **Updated**: 2022-01-05 13:18:02+00:00
- **Authors**: He Liu, Tao Wang, Congyan Lang, Songhe Feng, Yi Jin, Yidong Li
- **Comment**: None
- **Journal**: None
- **Summary**: Differentiable solvers for the linear assignment problem (LAP) have attracted much research attention in recent years, which are usually embedded into learning frameworks as components. However, previous algorithms, with or without learning strategies, usually suffer from the degradation of the optimality with the increment of the problem size. In this paper, we propose a learnable linear assignment solver based on deep graph networks. Specifically, we first transform the cost matrix to a bipartite graph and convert the assignment task to the problem of selecting reliable edges from the constructed graph. Subsequently, a deep graph network is developed to aggregate and update the features of nodes and edges. Finally, the network predicts a label for each edge that indicates the assignment relationship. The experimental results on a synthetic dataset reveal that our method outperforms state-of-the-art baselines and achieves consistently high accuracy with the increment of the problem size. Furthermore, we also embed the proposed solver, in comparison with state-of-the-art baseline solvers, into a popular multi-object tracking (MOT) framework to train the tracker in an end-to-end manner. The experimental results on MOT benchmarks illustrate that the proposed LAP solver improves the tracker by the largest margin.



### Deep Probabilistic Graph Matching
- **Arxiv ID**: http://arxiv.org/abs/2201.01603v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01603v1)
- **Published**: 2022-01-05 13:37:27+00:00
- **Updated**: 2022-01-05 13:37:27+00:00
- **Authors**: He Liu, Tao Wang, Yidong Li, Congyan Lang, Songhe Feng, Haibin Ling
- **Comment**: None
- **Journal**: None
- **Summary**: Most previous learning-based graph matching algorithms solve the \textit{quadratic assignment problem} (QAP) by dropping one or more of the matching constraints and adopting a relaxed assignment solver to obtain sub-optimal correspondences. Such relaxation may actually weaken the original graph matching problem, and in turn hurt the matching performance. In this paper we propose a deep learning-based graph matching framework that works for the original QAP without compromising on the matching constraints. In particular, we design an affinity-assignment prediction network to jointly learn the pairwise affinity and estimate the node assignments, and we then develop a differentiable solver inspired by the probabilistic perspective of the pairwise affinities. Aiming to obtain better matching results, the probabilistic solver refines the estimated assignments in an iterative manner to impose both discrete and one-to-one matching constraints. The proposed method is evaluated on three popularly tested benchmarks (Pascal VOC, Willow Object and SPair-71k), and it outperforms all previous state-of-the-arts on all benchmarks.



### All You Need In Sign Language Production
- **Arxiv ID**: http://arxiv.org/abs/2201.01609v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CL
- **Links**: [PDF](http://arxiv.org/pdf/2201.01609v2)
- **Published**: 2022-01-05 13:45:09+00:00
- **Updated**: 2022-01-06 18:10:58+00:00
- **Authors**: Razieh Rastgoo, Kourosh Kiani, Sergio Escalera, Vassilis Athitsos, Mohammad Sabokrou
- **Comment**: arXiv admin note: substantial text overlap with arXiv:2103.15910
- **Journal**: None
- **Summary**: Sign Language is the dominant form of communication language used in the deaf and hearing-impaired community. To make an easy and mutual communication between the hearing-impaired and the hearing communities, building a robust system capable of translating the spoken language into sign language and vice versa is fundamental. To this end, sign language recognition and production are two necessary parts for making such a two-way system. Sign language recognition and production need to cope with some critical challenges. In this survey, we review recent advances in Sign Language Production (SLP) and related areas using deep learning. To have more realistic perspectives to sign language, we present an introduction to the Deaf culture, Deaf centers, psychological perspective of sign language, the main differences between spoken language and sign language. Furthermore, we present the fundamental components of a bi-directional sign language translation system, discussing the main challenges in this area. Also, the backbone architectures and methods in SLP are briefly introduced and the proposed taxonomy on SLP is presented. Finally, a general framework for SLP and performance evaluation, and also a discussion on the recent developments, advantages, and limitations in SLP, commenting on possible lines for future research are presented.



### Lawin Transformer: Improving Semantic Segmentation Transformer with Multi-Scale Representations via Large Window Attention
- **Arxiv ID**: http://arxiv.org/abs/2201.01615v4
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01615v4)
- **Published**: 2022-01-05 13:51:20+00:00
- **Updated**: 2023-08-09 14:15:32+00:00
- **Authors**: Haotian Yan, Chuang Zhang, Ming Wu
- **Comment**: None
- **Journal**: None
- **Summary**: Multi-scale representations are crucial for semantic segmentation. The community has witnessed the flourish of semantic segmentation convolutional neural networks (CNN) exploiting multi-scale contextual information. Motivated by that the vision transformer (ViT) is powerful in image classification, some semantic segmentation ViTs are recently proposed, most of them attaining impressive results but at a cost of computational economy. In this paper, we succeed in introducing multi-scale representations into semantic segmentation ViT via window attention mechanism and further improves the performance and efficiency. To this end, we introduce large window attention which allows the local window to query a larger area of context window at only a little computation overhead. By regulating the ratio of the context area to the query area, we enable the $\textit{large window attention}$ to capture the contextual information at multiple scales. Moreover, the framework of spatial pyramid pooling is adopted to collaborate with $\textit{the large window attention}$, which presents a novel decoder named $\textbf{la}$rge $\textbf{win}$dow attention spatial pyramid pooling (LawinASPP) for semantic segmentation ViT. Our resulting ViT, Lawin Transformer, is composed of an efficient hierachical vision transformer (HVT) as encoder and a LawinASPP as decoder. The empirical results demonstrate that Lawin Transformer offers an improved efficiency compared to the existing method. Lawin Transformer further sets new state-of-the-art performance on Cityscapes (84.4% mIoU), ADE20K (56.2% mIoU) and COCO-Stuff datasets. The code will be released at https://github.com/yan-hao-tian/lawin



### Tackling the Class Imbalance Problem of Deep Learning Based Head and Neck Organ Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2201.01636v2
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV, I.4.6; I.2.10; J.3
- **Links**: [PDF](http://arxiv.org/pdf/2201.01636v2)
- **Published**: 2022-01-05 14:36:45+00:00
- **Updated**: 2022-04-21 14:06:16+00:00
- **Authors**: Elias Tappeiner, Martin Welk, Rainer Schubert
- **Comment**: 10 pages, 3 figures, 1 table, submitted to the International Journal
  of Computer Assisted Radiology and Surgery
- **Journal**: None
- **Summary**: The segmentation of organs at risk (OAR) is a required precondition for the cancer treatment with image guided radiation therapy. The automation of the segmentation task is therefore of high clinical relevance. Deep Learning (DL) based medical image segmentation is currently the most successful approach, but suffers from the over-presence of the background class and the anatomically given organ size difference, which is most severe in the head and neck (HAN) area. To tackle the HAN area specific class imbalance problem we first optimize the patch-size of the currently best performing general purpose segmentation framework, the nnU-Net, based on the introduced class imbalance measurement, and second, introduce the class adaptive Dice loss to further compensate for the highly imbalanced setting. Both the patch-size and the loss function are parameters with direct influence on the class imbalance and their optimization leads to a 3\% increase of the Dice score and 22% reduction of the 95% Hausdorff distance compared to the baseline, finally reaching $0.8\pm0.15$ and $3.17\pm1.7$ mm for the segmentation of seven HAN organs using a single and simple neural network. The patch-size optimization and the class adaptive Dice loss are both simply integrable in current DL based segmentation approaches and allow to increase the performance for class imbalanced segmentation tasks.



### TableParser: Automatic Table Parsing with Weak Supervision from Spreadsheets
- **Arxiv ID**: http://arxiv.org/abs/2201.01654v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01654v1)
- **Published**: 2022-01-05 15:21:06+00:00
- **Updated**: 2022-01-05 15:21:06+00:00
- **Authors**: Susie Xi Rao, Johannes Rausch, Peter Egger, Ce Zhang
- **Comment**: accepted in the AAAI-22 Workshop on Scientific Document Understanding
  at the Thirty-Sixth AAAI Conference on Artificial Intelligence (SDU@AAAI-22)
- **Journal**: None
- **Summary**: Tables have been an ever-existing structure to store data. There exist now different approaches to store tabular data physically. PDFs, images, spreadsheets, and CSVs are leading examples. Being able to parse table structures and extract content bounded by these structures is of high importance in many applications. In this paper, we devise TableParser, a system capable of parsing tables in both native PDFs and scanned images with high precision. We have conducted extensive experiments to show the efficacy of domain adaptation in developing such a tool. Moreover, we create TableAnnotator and ExcelAnnotator, which constitute a spreadsheet-based weak supervision mechanism and a pipeline to enable table parsing. We share these resources with the research community to facilitate further research in this interesting direction.



### Evaluation of Thermal Imaging on Embedded GPU Platforms for Application in Vehicular Assistance Systems
- **Arxiv ID**: http://arxiv.org/abs/2201.01661v1
- **DOI**: 10.1109/TIV.2022.3158094
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01661v1)
- **Published**: 2022-01-05 15:36:25+00:00
- **Updated**: 2022-01-05 15:36:25+00:00
- **Authors**: Muhammad Ali Farooq, Waseem Shariff, Peter Corcoran
- **Comment**: 14 pages, 9 tables, and 27 figures
- **Journal**: Published in IEEE-TIV Journal in 2023
- **Summary**: This study is focused on evaluating the real-time performance of thermal object detection for smart and safe vehicular systems by deploying the trained networks on GPU & single-board EDGE-GPU computing platforms for onboard automotive sensor suite testing. A novel large-scale thermal dataset comprising of > 35,000 distinct frames is acquired, processed, and open-sourced in challenging weather and environmental scenarios. The dataset is a recorded from lost-cost yet effective uncooled LWIR thermal camera, mounted stand-alone and on an electric vehicle to minimize mechanical vibrations. State-of-the-art YOLO-V5 networks variants are trained using four different public datasets as well newly acquired local dataset for optimal generalization of DNN by employing SGD optimizer. The effectiveness of trained networks is validated on extensive test data using various quantitative metrics which include precision, recall curve, mean average precision, and frames per second. The smaller network variant of YOLO is further optimized using TensorRT inference accelerator to explicitly boost the frames per second rate. Optimized network engine increases the frames per second rate by 3.5 times when testing on low power edge devices thus achieving 11 fps on Nvidia Jetson Nano and 60 fps on Nvidia Xavier NX development boards.



### Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis
- **Arxiv ID**: http://arxiv.org/abs/2201.01683v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01683v2)
- **Published**: 2022-01-05 16:25:32+00:00
- **Updated**: 2022-04-03 19:01:00+00:00
- **Authors**: Tianhan Xu, Yasuhiro Fujita, Eiichi Matsumoto
- **Comment**: CVPR 2022. Project page:
  https://pfnet-research.github.io/surface-aligned-nerf/
- **Journal**: None
- **Summary**: We propose a new method for reconstructing controllable implicit 3D human models from sparse multi-view RGB videos. Our method defines the neural scene representation on the mesh surface points and signed distances from the surface of a human body mesh. We identify an indistinguishability issue that arises when a point in 3D space is mapped to its nearest surface point on a mesh for learning surface-aligned neural scene representation. To address this issue, we propose projecting a point onto a mesh surface using a barycentric interpolation with modified vertex normals. Experiments with the ZJU-MoCap and Human3.6M datasets show that our approach achieves a higher quality in a novel-view and novel-pose synthesis than existing methods. We also demonstrate that our method easily supports the control of body shape and clothes. Project page: https://pfnet-research.github.io/surface-aligned-nerf/.



### An Investigation of "Benford's" Law Divergence and Machine Learning Techniques for "Intra-Class" Separability of Fingerprint Images
- **Arxiv ID**: http://arxiv.org/abs/2201.01699v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/2201.01699v2)
- **Published**: 2022-01-05 16:49:34+00:00
- **Updated**: 2022-01-07 13:45:35+00:00
- **Authors**: Aamo Iorliam, Orgem Emmanuel, Yahaya I. Shehu
- **Comment**: None
- **Journal**: None
- **Summary**: Protecting a fingerprint database against attackers is very vital in order to protect against false acceptance rate or false rejection rate. A key property in distinguishing fingerprint images is by exploiting the characteristics of these different types of fingerprint images. The aim of this paper is to perform the classification of fingerprint images using the Ben-ford's law divergence values and machine learning techniques. The usage of these Ben-ford's law divergence values as features fed into the machine learning techniques has proved to be very effective and efficient in the classification of fingerprint images. The effectiveness of our proposed methodology was demonstrated on five datasets, achieving very high classification "accuracies" of 100% for the Decision Tree and CNN. However, the "Naive" Bayes, and Logistic Regression achieved "accuracies" of 95.95%, and 90.54%, respectively. These results showed that Ben-ford's law features and machine learning techniques especially Decision Tree and CNN can be effectively applied for the classification of fingerprint images.



### Probing TryOnGAN
- **Arxiv ID**: http://arxiv.org/abs/2201.01703v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01703v1)
- **Published**: 2022-01-05 16:51:19+00:00
- **Updated**: 2022-01-05 16:51:19+00:00
- **Authors**: Saurabh Kumar, Nishant Sinha
- **Comment**: 5 pages, to appear in the proceedings of the 9th ACM IKDD CODS and
  27th COMAD (CODS-COMAD '22)
- **Journal**: None
- **Summary**: TryOnGAN is a recent virtual try-on approach, which generates highly realistic images and outperforms most previous approaches. In this article, we reproduce the TryOnGAN implementation and probe it along diverse angles: impact of transfer learning, variants of conditioning image generation with poses and properties of latent space interpolation. Some of these facets have never been explored in literature earlier. We find that transfer helps training initially but gains are lost as models train longer and pose conditioning via concatenation performs better. The latent space self-disentangles the pose and the style features and enables style transfer across poses. Our code and models are available in open source.



### The Effect of Model Compression on Fairness in Facial Expression Recognition
- **Arxiv ID**: http://arxiv.org/abs/2201.01709v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01709v1)
- **Published**: 2022-01-05 16:59:15+00:00
- **Updated**: 2022-01-05 16:59:15+00:00
- **Authors**: Samuil Stoychev, Hatice Gunes
- **Comment**: None
- **Journal**: None
- **Summary**: Deep neural networks have proved hugely successful, achieving human-like performance on a variety of tasks. However, they are also computationally expensive, which has motivated the development of model compression techniques which reduce the resource consumption associated with deep learning models. Nevertheless, recent studies have suggested that model compression can have an adverse effect on algorithmic fairness, amplifying existing biases in machine learning models. With this project we aim to extend those studies to the context of facial expression recognition. To do that, we set up a neural network classifier to perform facial expression recognition and implement several model compression techniques on top of it. We then run experiments on two facial expression datasets, namely the Extended Cohn-Kanade Dataset (CK+DB) and the Real-World Affective Faces Database (RAF-DB), to examine the individual and combined effect that compression techniques have on the model size, accuracy and fairness. Our experimental results show that: (i) Compression and quantisation achieve significant reduction in model size with minimal impact on overall accuracy for both CK+DB and RAF-DB; (ii) in terms of model accuracy, the classifier trained and tested on RAF-DB seems more robust to compression compared to the CK+ DB; (iii) for RAF-DB, the different compression strategies do not seem to increase the gap in predictive performance across the sensitive attributes of gender, race and age which is in contrast with the results on the CK+DB, where compression seems to amplify existing biases for gender. We analyse the results and discuss the potential reasons for our findings.



### Learning Audio-Visual Speech Representation by Masked Multimodal Cluster Prediction
- **Arxiv ID**: http://arxiv.org/abs/2201.02184v2
- **DOI**: None
- **Categories**: **eess.AS**, cs.CV, cs.SD
- **Links**: [PDF](http://arxiv.org/pdf/2201.02184v2)
- **Published**: 2022-01-05 17:40:45+00:00
- **Updated**: 2022-03-13 01:52:28+00:00
- **Authors**: Bowen Shi, Wei-Ning Hsu, Kushal Lakhotia, Abdelrahman Mohamed
- **Comment**: ICLR 2022
- **Journal**: None
- **Summary**: Video recordings of speech contain correlated audio and visual information, providing a strong signal for speech representation learning from the speaker's lip movements and the produced sound. We introduce Audio-Visual Hidden Unit BERT (AV-HuBERT), a self-supervised representation learning framework for audio-visual speech, which masks multi-stream video input and predicts automatically discovered and iteratively refined multimodal hidden units. AV-HuBERT learns powerful audio-visual speech representation benefiting both lip-reading and automatic speech recognition. On the largest public lip-reading benchmark LRS3 (433 hours), AV-HuBERT achieves 32.5% WER with only 30 hours of labeled data, outperforming the former state-of-the-art approach (33.6%) trained with a thousand times more transcribed video data (31K hours). The lip-reading WER is further reduced to 26.9% when using all 433 hours of labeled data from LRS3 and combined with self-training. Using our audio-visual representation on the same benchmark for audio-only speech recognition leads to a 40% relative WER reduction over the state-of-the-art performance (1.3% vs 2.3%). Our code and models are available at https://github.com/facebookresearch/av_hubert



### Multi-Robot Collaborative Perception with Graph Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2201.01760v2
- **DOI**: 10.1109/LRA.2022.3141661
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01760v2)
- **Published**: 2022-01-05 18:47:07+00:00
- **Updated**: 2022-01-23 00:19:18+00:00
- **Authors**: Yang Zhou, Jiuhong Xiao, Yue Zhou, Giuseppe Loianno
- **Comment**: 8 pages, 10 figures, 3 tables, Accepted at the IEEE Robotics
  Automation Letter (RAL) and the IEEE International Conference on Robotics and
  Automation (ICRA), 2022
- **Journal**: None
- **Summary**: Multi-robot systems such as swarms of aerial robots are naturally suited to offer additional flexibility, resilience, and robustness in several tasks compared to a single robot by enabling cooperation among the agents. To enhance the autonomous robot decision-making process and situational awareness, multi-robot systems have to coordinate their perception capabilities to collect, share, and fuse environment information among the agents in an efficient and meaningful way such to accurately obtain context-appropriate information or gain resilience to sensor noise or failures. In this paper, we propose a general-purpose Graph Neural Network (GNN) with the main goal to increase, in multi-robot perception tasks, single robots' inference perception accuracy as well as resilience to sensor failures and disturbances. We show that the proposed framework can address multi-view visual perception problems such as monocular depth estimation and semantic segmentation. Several experiments both using photo-realistic and real data gathered from multiple aerial robots' viewpoints show the effectiveness of the proposed approach in challenging inference conditions including images corrupted by heavy noise and camera occlusions or failures.



### Robust Self-Supervised Audio-Visual Speech Recognition
- **Arxiv ID**: http://arxiv.org/abs/2201.01763v3
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, cs.LG, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2201.01763v3)
- **Published**: 2022-01-05 18:50:50+00:00
- **Updated**: 2022-07-14 23:05:52+00:00
- **Authors**: Bowen Shi, Wei-Ning Hsu, Abdelrahman Mohamed
- **Comment**: Interspeech 2022
- **Journal**: None
- **Summary**: Audio-based automatic speech recognition (ASR) degrades significantly in noisy environments and is particularly vulnerable to interfering speech, as the model cannot determine which speaker to transcribe. Audio-visual speech recognition (AVSR) systems improve robustness by complementing the audio stream with the visual information that is invariant to noise and helps the model focus on the desired speaker. However, previous AVSR work focused solely on the supervised learning setup; hence the progress was hindered by the amount of labeled data available. In this work, we present a self-supervised AVSR framework built upon Audio-Visual HuBERT (AV-HuBERT), a state-of-the-art audio-visual speech representation learning model. On the largest available AVSR benchmark dataset LRS3, our approach outperforms prior state-of-the-art by ~50% (28.0% vs. 14.1%) using less than 10% of labeled data (433hr vs. 30hr) in the presence of babble noise, while reducing the WER of an audio-based model by over 75% (25.8% vs. 5.8%) on average.



### Quantum Capsule Networks
- **Arxiv ID**: http://arxiv.org/abs/2201.01778v3
- **DOI**: 10.1088/2058-9565/aca55d
- **Categories**: **quant-ph**, cond-mat.dis-nn, cond-mat.mes-hall, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01778v3)
- **Published**: 2022-01-05 19:00:02+00:00
- **Updated**: 2022-12-05 14:52:21+00:00
- **Authors**: Zidu Liu, Pei-Xin Shen, Weikang Li, L. -M. Duan, Dong-Ling Deng
- **Comment**: 7 pages (main text) + 8 pages (supplementary information), 8 figures
- **Journal**: Quantum Sci. Technol. 8 015016 (2022)
- **Summary**: Capsule networks, which incorporate the paradigms of connectionism and symbolism, have brought fresh insights into artificial intelligence. The capsule, as the building block of capsule networks, is a group of neurons represented by a vector to encode different features of an entity. The information is extracted hierarchically through capsule layers via routing algorithms. Here, we introduce a quantum capsule network (dubbed QCapsNet) together with an efficient quantum dynamic routing algorithm. To benchmark the performance of the QCapsNet, we carry out extensive numerical simulations on the classification of handwritten digits and symmetry-protected topological phases, and show that the QCapsNet can achieve an enhanced accuracy and outperform conventional quantum classifiers evidently. We further unpack the output capsule state and find that a particular subspace may correspond to a human-understandable feature of the input data, which indicates the potential explainability of such networks. Our work reveals an intriguing prospect of quantum capsule networks in quantum machine learning, which may provide a valuable guide towards explainable quantum artificial intelligence.



### Automated Scoring of Graphical Open-Ended Responses Using Artificial Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2201.01783v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG, stat.AP
- **Links**: [PDF](http://arxiv.org/pdf/2201.01783v1)
- **Published**: 2022-01-05 19:00:18+00:00
- **Updated**: 2022-01-05 19:00:18+00:00
- **Authors**: Matthias von Davier, Lillian Tyack, Lale Khorramdel
- **Comment**: 23 pages
- **Journal**: None
- **Summary**: Automated scoring of free drawings or images as responses has yet to be utilized in large-scale assessments of student achievement. In this study, we propose artificial neural networks to classify these types of graphical responses from a computer based international mathematics and science assessment. We are comparing classification accuracy of convolutional and feedforward approaches. Our results show that convolutional neural networks (CNNs) outperform feedforward neural networks in both loss and accuracy. The CNN models classified up to 97.71% of the image responses into the appropriate scoring category, which is comparable to, if not more accurate, than typical human raters. These findings were further strengthened by the observation that the most accurate CNN models correctly classified some image responses that had been incorrectly scored by the human raters. As an additional innovation, we outline a method to select human rated responses for the training sample based on an application of the expected response function derived from item response theory. This paper argues that CNN-based automated scoring of image responses is a highly accurate procedure that could potentially replace the workload and cost of second human raters for large scale assessments, while improving the validity and comparability of scoring complex constructed-response items.



### Revisiting Deep Subspace Alignment for Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2201.01806v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01806v1)
- **Published**: 2022-01-05 20:16:38+00:00
- **Updated**: 2022-01-05 20:16:38+00:00
- **Authors**: Kowshik Thopalli, Jayaraman J Thiagarajan, Rushil Anirudh, Pavan K Turaga
- **Comment**: arXiv admin note: text overlap with arXiv:1906.04338
- **Journal**: None
- **Summary**: Unsupervised domain adaptation (UDA) aims to transfer and adapt knowledge from a labeled source domain to an unlabeled target domain. Traditionally, subspace-based methods form an important class of solutions to this problem. Despite their mathematical elegance and tractability, these methods are often found to be ineffective at producing domain-invariant features with complex, real-world datasets. Motivated by the recent advances in representation learning with deep networks, this paper revisits the use of subspace alignment for UDA and proposes a novel adaptation algorithm that consistently leads to improved generalization. In contrast to existing adversarial training-based DA methods, our approach isolates feature learning and distribution alignment steps, and utilizes a primary-auxiliary optimization strategy to effectively balance the objectives of domain invariance and model fidelity. While providing a significant reduction in target data and computational requirements, our subspace-based DA performs competitively and sometimes even outperforms state-of-the-art approaches on several standard UDA benchmarks. Furthermore, subspace alignment leads to intrinsically well-regularized models that demonstrate strong generalization even in the challenging partial DA setting. Finally, the design of our UDA framework inherently supports progressive adaptation to new target domains at test-time, without requiring retraining of the model from scratch. In summary, powered by powerful feature learners and an effective optimization strategy, we establish subspace-based DA as a highly effective approach for visual recognition.



### Formal Analysis of Art: Proxy Learning of Visual Concepts from Style Through Language Models
- **Arxiv ID**: http://arxiv.org/abs/2201.01819v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CL, cs.CV, I.2.6; I.2.7; I.2.10; J.5
- **Links**: [PDF](http://arxiv.org/pdf/2201.01819v1)
- **Published**: 2022-01-05 21:03:29+00:00
- **Updated**: 2022-01-05 21:03:29+00:00
- **Authors**: Diana Kim, Ahmed Elgammal, Marian Mazzone
- **Comment**: 23 pages, This paper is an extended version of a paper that will be
  published at the 36th AAAI Conference on Artificial Intelligence, to beheld
  in Vancouver, BC, Canada, February 22 - March 1, 2022
- **Journal**: None
- **Summary**: We present a machine learning system that can quantify fine art paintings with a set of visual elements and principles of art. This formal analysis is fundamental for understanding art, but developing such a system is challenging. Paintings have high visual complexities, but it is also difficult to collect enough training data with direct labels. To resolve these practical limitations, we introduce a novel mechanism, called proxy learning, which learns visual concepts in paintings though their general relation to styles. This framework does not require any visual annotation, but only uses style labels and a general relationship between visual concepts and style. In this paper, we propose a novel proxy model and reformulate four pre-existing methods in the context of proxy learning. Through quantitative and qualitative comparison, we evaluate these methods and compare their effectiveness in quantifying the artistic visual concepts, where the general relationship is estimated by language models; GloVe or BERT. The language modeling is a practical and scalable solution requiring no labeling, but it is inevitably imperfect. We demonstrate how the new proxy model is robust to the imperfection, while the other models are sensitively affected by it.



### Learning Semantic Ambiguities for Zero-Shot Learning
- **Arxiv ID**: http://arxiv.org/abs/2201.01823v3
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2201.01823v3)
- **Published**: 2022-01-05 21:08:29+00:00
- **Updated**: 2022-09-28 13:21:41+00:00
- **Authors**: Celina Hanouti, Hervé Le Borgne
- **Comment**: None
- **Journal**: None
- **Summary**: Zero-shot learning (ZSL) aims at recognizing classes for which no visual sample is available at training time. To address this issue, one can rely on a semantic description of each class. A typical ZSL model learns a mapping between the visual samples of seen classes and the corresponding semantic descriptions, in order to do the same on unseen classes at test time. State of the art approaches rely on generative models that synthesize visual features from the prototype of a class, such that a classifier can then be learned in a supervised manner. However, these approaches are usually biased towards seen classes whose visual instances are the only one that can be matched to a given class prototype. We propose a regularization method that can be applied to any conditional generative-based ZSL method, by leveraging only the semantic class prototypes. It learns to synthesize discriminative features for possible semantic description that are not available at training time, that is the unseen ones. The approach is evaluated for ZSL and GZSL on four datasets commonly used in the literature, either in inductive and transductive settings, with results on-par or above state of the art approaches.



### POCO: Point Convolution for Surface Reconstruction
- **Arxiv ID**: http://arxiv.org/abs/2201.01831v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.CG, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01831v2)
- **Published**: 2022-01-05 21:26:18+00:00
- **Updated**: 2022-03-30 09:48:01+00:00
- **Authors**: Alexandre Boulch, Renaud Marlet
- **Comment**: Accepted at Conference on Computer Vision and Pattern Recognition
  (CVPR), 2022
- **Journal**: None
- **Summary**: Implicit neural networks have been successfully used for surface reconstruction from point clouds. However, many of them face scalability issues as they encode the isosurface function of a whole object or scene into a single latent vector. To overcome this limitation, a few approaches infer latent vectors on a coarse regular 3D grid or on 3D patches, and interpolate them to answer occupancy queries. In doing so, they loose the direct connection with the input points sampled on the surface of objects, and they attach information uniformly in space rather than where it matters the most, i.e., near the surface. Besides, relying on fixed patch sizes may require discretization tuning. To address these issues, we propose to use point cloud convolutions and compute latent vectors at each input point. We then perform a learning-based interpolation on nearest neighbors using inferred weights. Experiments on both object and scene datasets show that our approach significantly outperforms other methods on most classical metrics, producing finer details and better reconstructing thinner volumes. The code is available at https://github.com/valeoai/POCO.



### Multiple Sclerosis Lesions Segmentation using Attention-Based CNNs in FLAIR Images
- **Arxiv ID**: http://arxiv.org/abs/2201.01832v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01832v1)
- **Published**: 2022-01-05 21:37:43+00:00
- **Updated**: 2022-01-05 21:37:43+00:00
- **Authors**: Mehdi SadeghiBakhi, Hamidreza Pourreza, Hamidreza Mahyar
- **Comment**: None
- **Journal**: None
- **Summary**: Objective: Multiple Sclerosis (MS) is an autoimmune, and demyelinating disease that leads to lesions in the central nervous system. This disease can be tracked and diagnosed using Magnetic Resonance Imaging (MRI). Up to now a multitude of multimodality automatic biomedical approaches is used to segment lesions which are not beneficial for patients in terms of cost, time, and usability. The authors of the present paper propose a method employing just one modality (FLAIR image) to segment MS lesions accurately. Methods: A patch-based Convolutional Neural Network (CNN) is designed, inspired by 3D-ResNet and spatial-channel attention module, to segment MS lesions. The proposed method consists of three stages: (1) the contrast-limited adaptive histogram equalization (CLAHE) is applied to the original images and concatenated to the extracted edges in order to create 4D images; (2) the patches of size 80 * 80 * 80 * 2 are randomly selected from the 4D images; and (3) the extracted patches are passed into an attention-based CNN which is used to segment the lesions. Finally, the proposed method was compared to previous studies of the same dataset. Results: The current study evaluates the model, with a test set of ISIB challenge data. Experimental results illustrate that the proposed approach significantly surpasses existing methods in terms of Dice similarity and Absolute Volume Difference while the proposed method use just one modality (FLAIR) to segment the lesions. Conclusions: The authors have introduced an automated approach to segment the lesions which is based on, at most, two modalities as an input. The proposed architecture is composed of convolution, deconvolution, and an SCA-VoxRes module as an attention module. The results show, the proposed method outperforms well compare to other methods.



### Lumbar Bone Mineral Density Estimation from Chest X-ray Images: Anatomy-aware Attentive Multi-ROI Modeling
- **Arxiv ID**: http://arxiv.org/abs/2201.01838v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2201.01838v2)
- **Published**: 2022-01-05 22:03:32+00:00
- **Updated**: 2022-06-09 19:27:47+00:00
- **Authors**: Fakai Wang, Kang Zheng, Le Lu, Jing Xiao, Min Wu, Chang-Fu Kuo, Shun Miao
- **Comment**: None
- **Journal**: None
- **Summary**: Osteoporosis is a common chronic metabolic bone disease often under-diagnosed and under-treated due to the limited access to bone mineral density (BMD) examinations, e.g. via Dual-energy X-ray Absorptiometry (DXA). This paper proposes a method to predict BMD from Chest X-ray (CXR), one of the most commonly accessible and low-cost medical imaging examinations. Our method first automatically detects Regions of Interest (ROIs) of local CXR bone structures. Then a multi-ROI deep model with transformer encoder is developed to exploit both local and global information in the chest X-ray image for accurate BMD estimation. Our method is evaluated on 13719 CXR patient cases with ground truth BMD measured by the gold standard DXA. The model predicted BMD has a strong correlation with the ground truth (Pearson correlation coefficient 0.894 on lumbar 1). When applied in osteoporosis screening, it achieves a high classification performance (average AUC of 0.968). As the first effort of using CXR scans to predict the BMD, the proposed algorithm holds strong potential for early osteoporosis screening and public health promotion.



### On the Real-World Adversarial Robustness of Real-Time Semantic Segmentation Models for Autonomous Driving
- **Arxiv ID**: http://arxiv.org/abs/2201.01850v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2201.01850v1)
- **Published**: 2022-01-05 22:33:43+00:00
- **Updated**: 2022-01-05 22:33:43+00:00
- **Authors**: Giulio Rossolini, Federico Nesti, Gianluca D'Amico, Saasha Nair, Alessandro Biondi, Giorgio Buttazzo
- **Comment**: None
- **Journal**: None
- **Summary**: The existence of real-world adversarial examples (commonly in the form of patches) poses a serious threat for the use of deep learning models in safety-critical computer vision tasks such as visual perception in autonomous driving. This paper presents an extensive evaluation of the robustness of semantic segmentation models when attacked with different types of adversarial patches, including digital, simulated, and physical ones. A novel loss function is proposed to improve the capabilities of attackers in inducing a misclassification of pixels. Also, a novel attack strategy is presented to improve the Expectation Over Transformation method for placing a patch in the scene. Finally, a state-of-the-art method for detecting adversarial patch is first extended to cope with semantic segmentation models, then improved to obtain real-time performance, and eventually evaluated in real-world scenarios. Experimental results reveal that, even though the adversarial effect is visible with both digital and real-world attacks, its impact is often spatially confined to areas of the image around the patch. This opens to further questions about the spatial robustness of real-time semantic segmentation models.



### Multi-Grid Redundant Bounding Box Annotation for Accurate Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2201.01857v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01857v1)
- **Published**: 2022-01-05 23:01:55+00:00
- **Updated**: 2022-01-05 23:01:55+00:00
- **Authors**: Solomon Negussie Tesema, El-Bay Bourennane
- **Comment**: Will appear on "The 19th IEEE International Conference on Pervasive
  Intelligence and Computing (PICom 2021)". Conference Held on 25 - 28 October
  2021
- **Journal**: None
- **Summary**: Modern leading object detectors are either two-stage or one-stage networks repurposed from a deep CNN-based backbone classifier network. YOLOv3 is one such very-well known state-of-the-art one-shot detector that takes in an input image and divides it into an equal-sized grid matrix. The grid cell having the center of an object is the one responsible for detecting the particular object. This paper presents a new mathematical approach that assigns multiple grids per object for accurately tight-fit bounding box prediction. We also propose an effective offline copy-paste data augmentation for object detection. Our proposed method significantly outperforms some current state-of-the-art object detectors with a prospect for further better performance.



### Towards realistic symmetry-based completion of previously unseen point clouds
- **Arxiv ID**: http://arxiv.org/abs/2201.01858v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2201.01858v1)
- **Published**: 2022-01-05 23:05:13+00:00
- **Updated**: 2022-01-05 23:05:13+00:00
- **Authors**: Taras Rumezhak, Oles Dobosevych, Rostyslav Hryniv, Vladyslav Selotkin, Volodymyr Karpiv, Mykola Maksymenko
- **Comment**: None
- **Journal**: Proceedings of the IEEE/CVF International Conference on Computer
  Vision (ICCV) Workshops, October, 2021, 2542-2550
- **Summary**: 3D scanning is a complex multistage process that generates a point cloud of an object typically containing damaged parts due to occlusions, reflections, shadows, scanner motion, specific properties of the object surface, imperfect reconstruction algorithms, etc. Point cloud completion is specifically designed to fill in the missing parts of the object and obtain its high-quality 3D representation. The existing completion approaches perform well on the academic datasets with a predefined set of object classes and very specific types of defects; however, their performance drops significantly in the real-world settings and degrades even further on previously unseen object classes.   We propose a novel framework that performs well on symmetric objects, which are ubiquitous in man-made environments. Unlike learning-based approaches, the proposed framework does not require training data and is capable of completing non-critical damages occurring in customer 3D scanning process using e.g. Kinect, time-of-flight, or structured light scanners. With thorough experiments, we demonstrate that the proposed framework achieves state-of-the-art efficiency in point cloud completion of real-world customer scans. We benchmark the framework performance on two types of datasets: properly augmented existing academic dataset and the actual 3D scans of various objects.



### NeuralMLS: Geometry-Aware Control Point Deformation
- **Arxiv ID**: http://arxiv.org/abs/2201.01873v2
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2201.01873v2)
- **Published**: 2022-01-05 23:55:34+00:00
- **Updated**: 2022-06-12 00:41:30+00:00
- **Authors**: Meitar Shechter, Rana Hanocka, Gal Metzer, Raja Giryes, Daniel Cohen-Or
- **Comment**: Eurographics 2022 Short Papers
- **Journal**: None
- **Summary**: We introduce NeuralMLS, a space-based deformation technique, guided by a set of displaced control points. We leverage the power of neural networks to inject the underlying shape geometry into the deformation parameters. The goal of our technique is to enable a realistic and intuitive shape deformation. Our method is built upon moving least-squares (MLS), since it minimizes a weighted sum of the given control point displacements. Traditionally, the influence of each control point on every point in space (i.e., the weighting function) is defined using inverse distance heuristics. In this work, we opt to learn the weighting function, by training a neural network on the control points from a single input shape, and exploit the innate smoothness of neural networks. Our geometry-aware control point deformation is agnostic to the surface representation and quality; it can be applied to point clouds or meshes, including non-manifold and disconnected surface soups. We show that our technique facilitates intuitive piecewise smooth deformations, which are well suited for manufactured objects. We show the advantages of our approach compared to existing surface and space-based deformation techniques, both quantitatively and qualitatively.



