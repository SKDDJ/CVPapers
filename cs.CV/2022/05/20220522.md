# Arxiv Papers in cs.CV on 2022-05-22
### GL-RG: Global-Local Representation Granularity for Video Captioning
- **Arxiv ID**: http://arxiv.org/abs/2205.10706v2
- **DOI**: 10.24963/ijcai.2022/384
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10706v2)
- **Published**: 2022-05-22 02:00:09+00:00
- **Updated**: 2023-02-28 05:17:43+00:00
- **Authors**: Liqi Yan, Qifan Wang, Yiming Cui, Fuli Feng, Xiaojun Quan, Xiangyu Zhang, Dongfang Liu
- **Comment**: Accepted to IJCAI 2022
- **Journal**: None
- **Summary**: Video captioning is a challenging task as it needs to accurately transform visual understanding into natural language description. To date, state-of-the-art methods inadequately model global-local representation across video frames for caption generation, leaving plenty of room for improvement. In this work, we approach the video captioning task from a new perspective and propose a GL-RG framework for video captioning, namely a \textbf{G}lobal-\textbf{L}ocal \textbf{R}epresentation \textbf{G}ranularity. Our GL-RG demonstrates three advantages over the prior efforts: 1) we explicitly exploit extensive visual representations from different video ranges to improve linguistic expression; 2) we devise a novel global-local encoder to produce rich semantic vocabulary to obtain a descriptive granularity of video contents across frames; 3) we develop an incremental training strategy which organizes model learning in an incremental fashion to incur an optimal captioning behavior. Experimental results on the challenging MSR-VTT and MSVD datasets show that our DL-RG outperforms recent state-of-the-art methods by a significant margin. Code is available at \url{https://github.com/ylqi/GL-RG}.



### Housekeep: Tidying Virtual Households using Commonsense Reasoning
- **Arxiv ID**: http://arxiv.org/abs/2205.10712v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10712v1)
- **Published**: 2022-05-22 02:37:09+00:00
- **Updated**: 2022-05-22 02:37:09+00:00
- **Authors**: Yash Kant, Arun Ramachandran, Sriram Yenamandra, Igor Gilitschenski, Dhruv Batra, Andrew Szot, Harsh Agrawal
- **Comment**: None
- **Journal**: None
- **Summary**: We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the home for embodied AI. In Housekeep, an embodied agent must tidy a house by rearranging misplaced objects without explicit instructions specifying which objects need to be rearranged. Instead, the agent must learn from and is evaluated against human preferences of which objects belong where in a tidy house. Specifically, we collect a dataset of where humans typically place objects in tidy and untidy houses constituting 1799 objects, 268 object categories, 585 placements, and 105 rooms. Next, we propose a modular baseline approach for Housekeep that integrates planning, exploration, and navigation. It leverages a fine-tuned large language model (LLM) trained on an internet text corpus for effective planning. We show that our baseline agent generalizes to rearranging unseen objects in unknown environments. See our webpage for more details: https://yashkant.github.io/housekeep/



### Learnable Visual Words for Interpretable Image Recognition
- **Arxiv ID**: http://arxiv.org/abs/2205.10724v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10724v2)
- **Published**: 2022-05-22 03:24:45+00:00
- **Updated**: 2022-05-26 14:43:21+00:00
- **Authors**: Wenxiao Xiao, Zhengming Ding, Hongfu Liu
- **Comment**: None
- **Journal**: None
- **Summary**: To interpret deep models' predictions, attention-based visual cues are widely used in addressing \textit{why} deep models make such predictions. Beyond that, the current research community becomes more interested in reasoning \textit{how} deep models make predictions, where some prototype-based methods employ interpretable representations with their corresponding visual cues to reveal the black-box mechanism of deep model behaviors. However, these pioneering attempts only either learn the category-specific prototypes and deteriorate their generalizing capacities, or demonstrate several illustrative examples without a quantitative evaluation of visual-based interpretability with further limitations on their practical usages. In this paper, we revisit the concept of visual words and propose the Learnable Visual Words (LVW) to interpret the model prediction behaviors with two novel modules: semantic visual words learning and dual fidelity preservation. The semantic visual words learning relaxes the category-specific constraint, enabling the general visual words shared across different categories. Beyond employing the visual words for prediction to align visual words with the base model, our dual fidelity preservation also includes the attention guided semantic alignment that encourages the learned visual words to focus on the same conceptual regions for prediction. Experiments on six visual benchmarks demonstrate the superior effectiveness of our proposed LVW in both accuracy and model interpretation over the state-of-the-art methods. Moreover, we elaborate on various in-depth analyses to further explore the learned visual words and the generalizability of our method for unseen categories.



### OTAdapt: Optimal Transport-based Approach For Unsupervised Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2205.10738v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10738v1)
- **Published**: 2022-05-22 04:25:24+00:00
- **Updated**: 2022-05-22 04:25:24+00:00
- **Authors**: Thanh-Dat Truong, Naga Venkata Sai Raviteja Chappa, Xuan Bac Nguyen, Ngan Le, Ashley Dowling, Khoa Luu
- **Comment**: Accepted to ICPR 2022
- **Journal**: None
- **Summary**: Unsupervised domain adaptation is one of the challenging problems in computer vision. This paper presents a novel approach to unsupervised domain adaptations based on the optimal transport-based distance. Our approach allows aligning target and source domains without the requirement of meaningful metrics across domains. In addition, the proposal can associate the correct mapping between source and target domains and guarantee a constraint of topology between source and target domains. The proposed method is evaluated on different datasets in various problems, i.e. (i) digit recognition on MNIST, MNIST-M, USPS datasets, (ii) Object recognition on Amazon, Webcam, DSLR, and VisDA datasets, (iii) Insect Recognition on the IP102 dataset. The experimental results show that our proposed method consistently improves performance accuracy. Also, our framework could be incorporated with any other CNN frameworks within an end-to-end deep network design for recognition problems to improve their performance.



### Classification of Quasars, Galaxies, and Stars in the Mapping of the Universe Multi-modal Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2205.10745v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2205.10745v1)
- **Published**: 2022-05-22 05:17:31+00:00
- **Updated**: 2022-05-22 05:17:31+00:00
- **Authors**: Sabeesh Ethiraj, Bharath Kumar Bolla
- **Comment**: Presented at Deep Learning Developers Conference, 2021, Bangalore
- **Journal**: None
- **Summary**: In this paper, the fourth version the Sloan Digital Sky Survey (SDSS-4), Data Release 16 dataset was used to classify the SDSS dataset into galaxies, stars, and quasars using machine learning and deep learning architectures. We efficiently utilize both image and metadata in tabular format to build a novel multi-modal architecture and achieve state-of-the-art results. In addition, our experiments on transfer learning using Imagenet weights on five different architectures (Resnet-50, DenseNet-121 VGG-16, Xception, and EfficientNet) reveal that freezing all layers and adding a final trainable layer may not be an optimal solution for transfer learning. It is hypothesized that higher the number of trainable layers, higher will be the training time and accuracy of predictions. It is also hypothesized that any subsequent increase in the number of training layers towards the base layers will not increase in accuracy as the pre trained lower layers only help in low level feature extraction which would be quite similar in all the datasets. Hence the ideal level of trainable layers needs to be identified for each model in respect to the number of parameters. For the tabular data, we compared classical machine learning algorithms (Logistic Regression, Random Forest, Decision Trees, Adaboost, LightGBM etc.,) with artificial neural networks. Our works shed new light on transfer learning and multi-modal deep learning architectures. The multi-modal architecture not only resulted in higher metrics (accuracy, precision, recall, F1 score) than models using only image data or tabular data. Furthermore, multi-modal architecture achieved the best metrics in lesser training epochs and improved the metrics on all classes.



### Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners
- **Arxiv ID**: http://arxiv.org/abs/2205.10747v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2205.10747v4)
- **Published**: 2022-05-22 05:18:27+00:00
- **Updated**: 2022-10-13 06:32:37+00:00
- **Authors**: Zhenhailong Wang, Manling Li, Ruochen Xu, Luowei Zhou, Jie Lei, Xudong Lin, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Derek Hoiem, Shih-Fu Chang, Mohit Bansal, Heng Ji
- **Comment**: None
- **Journal**: None
- **Summary**: The goal of this work is to build flexible video-language models that can generalize to various video-to-text tasks from few examples, such as domain-specific captioning, question answering, and future event prediction. Existing few-shot video-language learners focus exclusively on the encoder, resulting in the absence of a video-to-text decoder to handle generative tasks. Video captioners have been pretrained on large-scale video-language datasets, but they rely heavily on finetuning and lack the ability to generate text for unseen tasks in a few-shot setting. We propose VidIL, a few-shot Video-language Learner via Image and Language models, which demonstrates strong performance on few-shot video-to-text tasks without the necessity of pretraining or finetuning on any video datasets. We use the image-language models to translate the video content into frame captions, object, attribute, and event phrases, and compose them into a temporal structure template. We then instruct a language model, with a prompt containing a few in-context examples, to generate a target output from the composed content. The flexibility of prompting allows the model to capture any form of text input, such as automatic speech recognition (ASR) transcripts. Our experiments demonstrate the power of language models in understanding videos on a wide variety of video-language tasks, including video captioning, video question answering, video caption retrieval, and video future event prediction. Especially, on video future event prediction, our few-shot model significantly outperforms state-of-the-art supervised models trained on large-scale video datasets. Code and resources are publicly available for research purposes at https://github.com/MikeWangWZHL/VidIL .



### Preparing data for pathological artificial intelligence with clinical-grade performance
- **Arxiv ID**: http://arxiv.org/abs/2205.10748v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2205.10748v1)
- **Published**: 2022-05-22 05:20:41+00:00
- **Updated**: 2022-05-22 05:20:41+00:00
- **Authors**: Yuanqing Yang, Kai Sun, Yanhua Gao, Kuangsong Wang, Gang Yu
- **Comment**: None
- **Journal**: None
- **Summary**: [Purpose] The pathology is decisive for disease diagnosis, but relies heavily on the experienced pathologists. Recently, pathological artificial intelligence (PAI) is thought to improve diagnostic accuracy and efficiency. However, the high performance of PAI based on deep learning in the laboratory generally cannot be reproduced in the clinic. [Methods] Because the data preparation is important for PAI, the paper has reviewed PAI-related studies in the PubMed database published from January 2017 to February 2022, and 118 studies were included. The in-depth analysis of methods for preparing data is performed, including obtaining slides of pathological tissue, cleaning, screening, and then digitizing. Expert review, image annotation, dataset division for model training and validation are also discussed. We further discuss the reasons why the high performance of PAI is not reproducible in the clinical practices and show some effective ways to improve clinical performances of PAI. [Results] The robustness of PAI depend on randomized collection of representative disease slides, including rigorous quality control and screening, correction of digital discrepancies, reasonable annotation, and the amount of data. The digital pathology is fundamental of clinical-grade PAI, and the techniques of data standardization and weakly supervised learning methods based on whole slide image (WSI) are effective ways to overcome obstacles of performance reproduction. [Conclusion] The representative data, the amount of labeling and consistency from multi-centers is the key to performance reproduction. The digital pathology for clinical diagnosis, data standardization and technique of WSI-based weakly supervised learning hopefully build clinical-grade PAI. Keywords: pathological artificial intelligence; data preparation; clinical-grade; deep learning



### Real Time Detection Free Tracking of Multiple Objects Via Equilibrium Optimizer
- **Arxiv ID**: http://arxiv.org/abs/2205.10756v2
- **DOI**: None
- **Categories**: **cs.CV**, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2205.10756v2)
- **Published**: 2022-05-22 06:04:34+00:00
- **Updated**: 2022-05-24 05:41:57+00:00
- **Authors**: Djemai Charef-Khodja, Toumi Abida
- **Comment**: None
- **Journal**: None
- **Summary**: Multiple objects tracking (MOT) is a difficult task, as it usually requires special hardware and higher computation complexity. In this work, we present a new framework of MOT by using of equilibrium optimizer (EO) algorithm and reducing the resolution of the bounding boxes of the objects to solve such problems in the detection free framework. First, in the first frame the target objects are initialized and its size is computed, then its resolution is reduced if it is higher than a threshold, and then modeled by their kernel color histogram to establish a feature model. The Bhattacharya distances between the histogram of object models and other candidates are used as the fitness function to be optimized. Multiple agents are generated by EO, according to the number of the target objects to be tracked. EO algorithm is used because of its efficiency and lower computation cost compared to other algorithms in global optimization. Experimental results confirm that EO multi-object tracker achieves satisfying tracking results then other trackers.



### Deep Feature Fusion via Graph Convolutional Network for Intracranial Artery Labeling
- **Arxiv ID**: http://arxiv.org/abs/2205.10757v1
- **DOI**: 10.1109/EMBC48229.2022.9871848
- **Categories**: **eess.IV**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2205.10757v1)
- **Published**: 2022-05-22 06:11:21+00:00
- **Updated**: 2022-05-22 06:11:21+00:00
- **Authors**: Yaxin Zhu, Peisheng Qian, Ziyuan Zhao, Zeng Zeng
- **Comment**: Accepted by the 44th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC 2022)
- **Journal**: 2022 44th Annual International Conference of the IEEE Engineering
  in Medicine & Biology Society (EMBC)
- **Summary**: Intracranial arteries are critical blood vessels that supply the brain with oxygenated blood. Intracranial artery labels provide valuable guidance and navigation to numerous clinical applications and disease diagnoses. Various machine learning algorithms have been carried out for automation in the anatomical labeling of cerebral arteries. However, the task remains challenging because of the high complexity and variations of intracranial arteries. This study investigates a novel graph convolutional neural network with deep feature fusion for cerebral artery labeling. We introduce stacked graph convolutions in an encoder-core-decoder architecture, extracting high-level representations from graph nodes and their neighbors. Furthermore, we efficiently aggregate intermediate features from different hierarchies to enhance the proposed model's representation capability and labeling performance. We perform extensive experiments on public datasets, in which the results prove the superiority of our approach over baselines by a clear margin.



### Residual Channel Attention Network for Brain Glioma Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2205.10758v1
- **DOI**: 10.1109/EMBC48229.2022.9871233
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2205.10758v1)
- **Published**: 2022-05-22 06:12:19+00:00
- **Updated**: 2022-05-22 06:12:19+00:00
- **Authors**: Yiming Yao, Peisheng Qian, Ziyuan Zhao, Zeng Zeng
- **Comment**: Accepted by the 44th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC 2022)
- **Journal**: 2022 44th Annual International Conference of the IEEE Engineering
  in Medicine & Biology Society (EMBC)
- **Summary**: A glioma is a malignant brain tumor that seriously affects cognitive functions and lowers patients' life quality. Segmentation of brain glioma is challenging because of interclass ambiguities in tumor regions. Recently, deep learning approaches have achieved outstanding performance in the automatic segmentation of brain glioma. However, existing algorithms fail to exploit channel-wise feature interdependence to select semantic attributes for glioma segmentation. In this study, we implement a novel deep neural network that integrates residual channel attention modules to calibrate intermediate features for glioma segmentation. The proposed channel attention mechanism adaptively weights feature channel-wise to optimize the latent representation of gliomas. We evaluate our method on the established dataset BraTS2017. Experimental results indicate the superiority of our method.



### CNNs Avoid Curse of Dimensionality by Learning on Patches
- **Arxiv ID**: http://arxiv.org/abs/2205.10760v4
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2205.10760v4)
- **Published**: 2022-05-22 06:22:27+00:00
- **Updated**: 2023-04-12 17:33:41+00:00
- **Authors**: Vamshi C. Madala, Shivkumar Chandrasekaran, Jason Bunk
- **Comment**: Reorganization
- **Journal**: None
- **Summary**: Despite the success of convolutional neural networks (CNNs) in numerous computer vision tasks and their extraordinary generalization performances, several attempts to predict the generalization errors of CNNs have only been limited to a posteriori analyses thus far. A priori theories explaining the generalization performances of deep neural networks have mostly ignored the convolutionality aspect and do not specify why CNNs are able to seemingly overcome curse of dimensionality on computer vision tasks like image classification where the image dimensions are in thousands. Our work attempts to explain the generalization performance of CNNs on image classification under the hypothesis that CNNs operate on the domain of image patches. Ours is the first work we are aware of to derive an a priori error bound for the generalization error of CNNs and we present both quantitative and qualitative evidences in the support of our theory. Our patch-based theory also offers explanation for why data augmentation techniques like Cutout, CutMix and random cropping are effective in improving the generalization error of CNNs.



### Evidence for Hypodescent in Visual Semantic AI
- **Arxiv ID**: http://arxiv.org/abs/2205.10764v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, cs.CL, cs.CY
- **Links**: [PDF](http://arxiv.org/pdf/2205.10764v1)
- **Published**: 2022-05-22 06:46:39+00:00
- **Updated**: 2022-05-22 06:46:39+00:00
- **Authors**: Robert Wolfe, Mahzarin R. Banaji, Aylin Caliskan
- **Comment**: To be published at ACM FAccT 2022
- **Journal**: None
- **Summary**: We examine the state-of-the-art multimodal "visual semantic" model CLIP ("Contrastive Language Image Pretraining") for the rule of hypodescent, or one-drop rule, whereby multiracial people are more likely to be assigned a racial or ethnic label corresponding to a minority or disadvantaged racial or ethnic group than to the equivalent majority or advantaged group. A face morphing experiment grounded in psychological research demonstrating hypodescent indicates that, at the midway point of 1,000 series of morphed images, CLIP associates 69.7% of Black-White female images with a Black text label over a White text label, and similarly prefers Latina (75.8%) and Asian (89.1%) text labels at the midway point for Latina-White female and Asian-White female morphs, reflecting hypodescent. Additionally, assessment of the underlying cosine similarities in the model reveals that association with White is correlated with association with "person," with Pearson's rho as high as 0.82 over a 21,000-image morph series, indicating that a White person corresponds to the default representation of a person in CLIP. Finally, we show that the stereotype-congruent pleasantness association of an image correlates with association with the Black text label in CLIP, with Pearson's rho = 0.48 for 21,000 Black-White multiracial male images, and rho = 0.41 for Black-White multiracial female images. CLIP is trained on English-language text gathered using data collected from an American website (Wikipedia), and our findings demonstrate that CLIP embeds the values of American racial hierarchy, reflecting the implicit and explicit beliefs that are present in human minds. We contextualize these findings within the history and psychology of hypodescent. Overall, the data suggests that AI supervised using natural language will, unless checked, learn biases that reflect racial hierarchies.



### Recent Advances in Embedding Methods for Multi-Object Tracking: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2205.10766v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10766v1)
- **Published**: 2022-05-22 06:54:33+00:00
- **Updated**: 2022-05-22 06:54:33+00:00
- **Authors**: Gaoang Wang, Mingli Song, Jenq-Neng Hwang
- **Comment**: None
- **Journal**: None
- **Summary**: Multi-object tracking (MOT) aims to associate target objects across video frames in order to obtain entire moving trajectories. With the advancement of deep neural networks and the increasing demand for intelligent video analysis, MOT has gained significantly increased interest in the computer vision community. Embedding methods play an essential role in object location estimation and temporal identity association in MOT. Unlike other computer vision tasks, such as image classification, object detection, re-identification, and segmentation, embedding methods in MOT have large variations, and they have never been systematically analyzed and summarized. In this survey, we first conduct a comprehensive overview with in-depth analysis for embedding methods in MOT from seven different perspectives, including patch-level embedding, single-frame embedding, cross-frame joint embedding, correlation embedding, sequential embedding, tracklet embedding, and cross-track relational embedding. We further summarize the existing widely used MOT datasets and analyze the advantages of existing state-of-the-art methods according to their embedding strategies. Finally, some critical yet under-investigated areas and future research directions are discussed.



### Human Instance Matting via Mutual Guidance and Multi-Instance Refinement
- **Arxiv ID**: http://arxiv.org/abs/2205.10767v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10767v1)
- **Published**: 2022-05-22 06:56:52+00:00
- **Updated**: 2022-05-22 06:56:52+00:00
- **Authors**: Yanan Sun, Chi-Keung Tang, Yu-Wing Tai
- **Comment**: 16 pages, 20 figures, CVPR2022 Oral
- **Journal**: None
- **Summary**: This paper introduces a new matting task called human instance matting (HIM), which requires the pertinent model to automatically predict a precise alpha matte for each human instance. Straightforward combination of closely related techniques, namely, instance segmentation, soft segmentation and human/conventional matting, will easily fail in complex cases requiring disentangling mingled colors belonging to multiple instances along hairy and thin boundary structures. To tackle these technical challenges, we propose a human instance matting framework, called InstMatt, where a novel mutual guidance strategy working in tandem with a multi-instance refinement module is used, for delineating multi-instance relationship among humans with complex and overlapping boundaries if present. A new instance matting metric called instance matting quality (IMQ) is proposed, which addresses the absence of a unified and fair means of evaluation emphasizing both instance recognition and matting quality. Finally, we construct a HIM benchmark for evaluation, which comprises of both synthetic and natural benchmark images. In addition to thorough experimental results on complex cases with multiple and overlapping human instances each has intricate boundaries, preliminary results are presented on general instance matting. Code and benchmark are available in https://github.com/nowsyn/InstMatt.



### aSTDP: A More Biologically Plausible Learning
- **Arxiv ID**: http://arxiv.org/abs/2206.14137v1
- **DOI**: None
- **Categories**: **cs.NE**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2206.14137v1)
- **Published**: 2022-05-22 08:12:50+00:00
- **Updated**: 2022-05-22 08:12:50+00:00
- **Authors**: Shiyuan Li
- **Comment**: 17 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1912.00009
- **Journal**: None
- **Summary**: Spike-timing dependent plasticity in biological neural networks has been proven to be important during biological learning process. On the other hand, artificial neural networks use a different way to learn, such as Back-Propagation or Contrastive Hebbian Learning. In this work we introduce approximate STDP, a new neural networks learning framework more similar to the biological learning process. It uses only STDP rules for supervised and unsupervised learning, every neuron distributed learn patterns and don' t need a global loss or other supervised information. We also use a numerical way to approximate the derivatives of each neuron in order to better use SDTP learning and use the derivatives to set a target for neurons to accelerate training and testing process. The framework can make predictions or generate patterns in one model without additional configuration. Finally, we verified our framework on MNIST dataset for classification and generation tasks.



### Learning Muti-expert Distribution Calibration for Long-tailed Video Classification
- **Arxiv ID**: http://arxiv.org/abs/2205.10788v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10788v2)
- **Published**: 2022-05-22 09:52:34+00:00
- **Updated**: 2022-07-05 03:22:51+00:00
- **Authors**: Yufan Hu, Junyu Gao, Changsheng Xu
- **Comment**: None
- **Journal**: None
- **Summary**: Most existing state-of-the-art video classification methods assume that the training data obey a uniform distribution. However, video data in the real world typically exhibit an imbalanced long-tailed class distribution, resulting in a model bias towards head class and relatively low performance on tail class. While the current long-tailed classification methods usually focus on image classification, adapting it to video data is not a trivial extension. We propose an end-to-end multi-expert distribution calibration method to address these challenges based on two-level distribution information. The method jointly considers the distribution of samples in each class (intra-class distribution) and the overall distribution of diverse data (inter-class distribution) to solve the issue of imbalanced data under long-tailed distribution. By modeling the two-level distribution information, the model can jointly consider the head classes and the tail classes and significantly transfer the knowledge from the head classes to improve the performance of the tail classes. Extensive experiments verify that our method achieves state-of-the-art performance on the long-tailed video classification task.



### Knowledge Distillation via the Target-aware Transformer
- **Arxiv ID**: http://arxiv.org/abs/2205.10793v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10793v1)
- **Published**: 2022-05-22 10:26:54+00:00
- **Updated**: 2022-05-22 10:26:54+00:00
- **Authors**: Sihao Lin, Hongwei Xie, Bing Wang, Kaicheng Yu, Xiaojun Chang, Xiaodan Liang, Gang Wang
- **Comment**: CVPR2022(Oral)
- **Journal**: None
- **Summary**: Knowledge distillation becomes a de facto standard to improve the performance of small neural networks. Most of the previous works propose to regress the representational features from the teacher to the student in a one-to-one spatial matching fashion. However, people tend to overlook the fact that, due to the architecture differences, the semantic information on the same spatial location usually vary. This greatly undermines the underlying assumption of the one-to-one distillation approach. To this end, we propose a novel one-to-all spatial matching knowledge distillation approach. Specifically, we allow each pixel of the teacher feature to be distilled to all spatial locations of the student features given its similarity, which is generated from a target-aware transformer. Our approach surpasses the state-of-the-art methods by a significant margin on various computer vision benchmarks, such as ImageNet, Pascal VOC and COCOStuff10k. Code will be released soon.



### ReLU Fields: The Little Non-linearity That Could
- **Arxiv ID**: http://arxiv.org/abs/2205.10824v2
- **DOI**: 10.1145/3528233.3530707
- **Categories**: **cs.CV**, cs.GR
- **Links**: [PDF](http://arxiv.org/pdf/2205.10824v2)
- **Published**: 2022-05-22 13:42:31+00:00
- **Updated**: 2023-07-03 00:27:54+00:00
- **Authors**: Animesh Karnewar, Tobias Ritschel, Oliver Wang, Niloy J. Mitra
- **Comment**: Published at SIGGRAPH 2022
- **Journal**: None
- **Summary**: In many recent works, multi-layer perceptions (MLPs) have been shown to be suitable for modeling complex spatially-varying functions including images and 3D scenes. Although the MLPs are able to represent complex scenes with unprecedented quality and memory footprint, this expressive power of the MLPs, however, comes at the cost of long training and inference times. On the other hand, bilinear/trilinear interpolation on regular grid based representations can give fast training and inference times, but cannot match the quality of MLPs without requiring significant additional memory. Hence, in this work, we investigate what is the smallest change to grid-based representations that allows for retaining the high fidelity result of MLPs while enabling fast reconstruction and rendering times. We introduce a surprisingly simple change that achieves this task -- simply allowing a fixed non-linearity (ReLU) on interpolated grid values. When combined with coarse to-fine optimization, we show that such an approach becomes competitive with the state-of-the-art. We report results on radiance fields, and occupancy fields, and compare against multiple existing alternatives. Code and data for the paper are available at https://geometry.cs.ucl.ac.uk/projects/2022/relu_fields.



### Grad-CAM++ is Equivalent to Grad-CAM With Positive Gradients
- **Arxiv ID**: http://arxiv.org/abs/2205.10838v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, 68T07, I.2.m
- **Links**: [PDF](http://arxiv.org/pdf/2205.10838v1)
- **Published**: 2022-05-22 14:44:12+00:00
- **Updated**: 2022-05-22 14:44:12+00:00
- **Authors**: Miguel Lerma, Mirtha Lucas
- **Comment**: 10 pages, 8 figures
- **Journal**: None
- **Summary**: The Grad-CAM algorithm provides a way to identify what parts of an image contribute most to the output of a classifier deep network. The algorithm is simple and widely used for localization of objects in an image, although some researchers have point out its limitations, and proposed various alternatives. One of them is Grad-CAM++, that according to its authors can provide better visual explanations for network predictions, and does a better job at locating objects even for occurrences of multiple object instances in a single image. Here we show that Grad-CAM++ is practically equivalent to a very simple variation of Grad-CAM in which gradients are replaced with positive gradients.



### Deep Learning for Visual Speech Analysis: A Survey
- **Arxiv ID**: http://arxiv.org/abs/2205.10839v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10839v1)
- **Published**: 2022-05-22 14:44:53+00:00
- **Updated**: 2022-05-22 14:44:53+00:00
- **Authors**: Changchong Sheng, Gangyao Kuang, Liang Bai, Chenping Hou, Yulan Guo, Xin Xu, Matti Pietikäinen, Li Liu
- **Comment**: 20 pages, 8 figures
- **Journal**: None
- **Summary**: Visual speech, referring to the visual domain of speech, has attracted increasing attention due to its wide applications, such as public security, medical treatment, military defense, and film entertainment. As a powerful AI strategy, deep learning techniques have extensively promoted the development of visual speech learning. Over the past five years, numerous deep learning based methods have been proposed to address various problems in this area, especially automatic visual speech recognition and generation. To push forward future research on visual speech, this paper aims to present a comprehensive review of recent progress in deep learning methods on visual speech analysis. We cover different aspects of visual speech, including fundamental problems, challenges, benchmark datasets, a taxonomy of existing methods, and state-of-the-art performance. Besides, we also identify gaps in current research and discuss inspiring future research directions.



### Self-mentoring: a new deep learning pipeline to train a self-supervised U-net for few-shot learning of bio-artificial capsule segmentation
- **Arxiv ID**: http://arxiv.org/abs/2205.10840v3
- **DOI**: 10.1016/j.compbiomed.2022.106454
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2205.10840v3)
- **Published**: 2022-05-22 14:54:25+00:00
- **Updated**: 2023-01-07 11:40:59+00:00
- **Authors**: Arnaud Deleruyelle, Cristian Versari, John Klein
- **Comment**: None
- **Journal**: Computers in Biology and Medicine, 106454 (2022)
- **Summary**: Background: Accurate segmentation of microscopic structures such as bio-artificial capsules in microscopy imaging is a prerequisite to the computer-aided understanding of important biomechanical phenomenons. State-of-the-art segmentation performances are achieved by deep neural networks and related data-driven approaches. Training these networks from only a few annotated examples is challenging while producing manually annotated images that provide supervision is tedious.   Method: Recently, self-supervision, i.e. designing a neural pipeline providing synthetic or indirect supervision, has proved to significantly increase generalization performances of models trained on few shots. The objective of this paper is to introduce one such neural pipeline in the context of micro-capsule image segmentation. Our method leverages the rather simple content of these images so that a trainee network can be mentored by a referee network which has been previously trained on synthetically generated pairs of corrupted/correct region masks.   Results: Challenging experimental setups are investigated. They involve from only 3 to 10 annotated images along with moderately large amounts of unannotated images. In a bio-artificial capsule dataset, our approach consistently and drastically improves accuracy. We also show that the learnt referee network is transferable to another Glioblastoma cell dataset and that it can be efficiently coupled with data augmentation strategies.   Conclusions: Experimental results show that very significant accuracy increments are obtained by the proposed pipeline, leading to the conclusion that the self-supervision mechanism introduced in this paper has the potential to replace human annotations.



### Vision-based Anti-UAV Detection and Tracking
- **Arxiv ID**: http://arxiv.org/abs/2205.10851v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10851v1)
- **Published**: 2022-05-22 15:21:45+00:00
- **Updated**: 2022-05-22 15:21:45+00:00
- **Authors**: Jie Zhao, Jingshu Zhang, Dongdong Li, Dong Wang
- **Comment**: Accepted by IEEE Transactions on Intelligent Transportation Systems
- **Journal**: None
- **Summary**: Unmanned aerial vehicles (UAV) have been widely used in various fields, and their invasion of security and privacy has aroused social concern. Several detection and tracking systems for UAVs have been introduced in recent years, but most of them are based on radio frequency, radar, and other media. We assume that the field of computer vision is mature enough to detect and track invading UAVs. Thus we propose a visible light mode dataset called Dalian University of Technology Anti-UAV dataset, DUT Anti-UAV for short. It contains a detection dataset with a total of 10,000 images and a tracking dataset with 20 videos that include short-term and long-term sequences. All frames and images are manually annotated precisely. We use this dataset to train several existing detection algorithms and evaluate the algorithms' performance. Several tracking methods are also tested on our tracking dataset. Furthermore, we propose a clear and simple tracking algorithm combined with detection that inherits the detector's high precision. Extensive experiments show that the tracking performance is improved considerably after fusing detection, thus providing a new attempt at UAV tracking using our dataset.The datasets and results are publicly available at: https://github.com/wangdongdut/DUT-Anti-UAV



### Dynamic Query Selection for Fast Visual Perceiver
- **Arxiv ID**: http://arxiv.org/abs/2205.10873v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10873v2)
- **Published**: 2022-05-22 17:23:51+00:00
- **Updated**: 2023-03-21 10:53:32+00:00
- **Authors**: Corentin Dancette, Matthieu Cord
- **Comment**: Accepted at the Transformer for Vision workshop, CVPR 2022
- **Journal**: None
- **Summary**: Transformers have been matching deep convolutional networks for vision architectures in recent works. Most work is focused on getting the best results on large-scale benchmarks, and scaling laws seem to be the most successful strategy: bigger models, more data, and longer training result in higher performance. However, the reduction of network complexity and inference time remains under-explored. The Perceiver model offers a solution to this problem: by first performing a Cross-attention with a fixed number Q of latent query tokens, the complexity of the L-layers Transformer network that follows is bounded by O(LQ^2). In this work, we explore how to make Perceivers even more efficient, by reducing the number of queries Q during inference while limiting the accuracy drop.



### Geo-Localization via Ground-to-Satellite Cross-View Image Retrieval
- **Arxiv ID**: http://arxiv.org/abs/2205.10878v1
- **DOI**: 10.1109/TMM.2022.3144066
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10878v1)
- **Published**: 2022-05-22 17:35:13+00:00
- **Updated**: 2022-05-22 17:35:13+00:00
- **Authors**: Zelong Zeng, Zheng Wang, Fan Yang, Shin'ichi Satoh
- **Comment**: 13 pages, 10 figures
- **Journal**: IEEE Transactions on Multimedia (2022)
- **Summary**: The large variation of viewpoint and irrelevant content around the target always hinder accurate image retrieval and its subsequent tasks. In this paper, we investigate an extremely challenging task: given a ground-view image of a landmark, we aim to achieve cross-view geo-localization by searching out its corresponding satellite-view images. Specifically, the challenge comes from the gap between ground-view and satellite-view, which includes not only large viewpoint changes (some parts of the landmark may be invisible from front view to top view) but also highly irrelevant background (the target landmark tend to be hidden in other surrounding buildings), making it difficult to learn a common representation or a suitable mapping.   To address this issue, we take advantage of drone-view information as a bridge between ground-view and satellite-view domains. We propose a Peer Learning and Cross Diffusion (PLCD) framework. PLCD consists of three parts: 1) a peer learning across ground-view and drone-view to find visible parts to benefit ground-drone cross-view representation learning; 2) a patch-based network for satellite-drone cross-view representation learning; 3) a cross diffusion between ground-drone space and satellite-drone space. Extensive experiments conducted on the University-Earth and University-Google datasets show that our method outperforms state-of-the-arts significantly.



### Improving AMD diagnosis by the simultaneous identification of associated retinal lesions
- **Arxiv ID**: http://arxiv.org/abs/2205.10885v1
- **DOI**: 10.1007/978-3-031-06427-2_13
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2205.10885v1)
- **Published**: 2022-05-22 17:52:02+00:00
- **Updated**: 2022-05-22 17:52:02+00:00
- **Authors**: José Morano, Álvaro S. Hervella, José Rouco, Jorge Novo, José I. Fernández-Vigo, Marcos Ortega
- **Comment**: Accepted at 21st International Conference on Image Analysis and
  Processing (ICIAP 2021). The final authenticated publication is available
  online at https://doi.org/10.1007/978-3-031-06427-2_13
- **Journal**: None
- **Summary**: Age-related Macular Degeneration (AMD) is the predominant cause of blindness in developed countries, specially in elderly people. Moreover, its prevalence is increasing due to the global population ageing. In this scenario, early detection is crucial to avert later vision impairment. Nonetheless, implementing large-scale screening programmes is usually not viable, since the population at-risk is large and the analysis must be performed by expert clinicians. Also, the diagnosis of AMD is considered to be particularly difficult, as it is characterized by many different lesions that, in many cases, resemble those of other macular diseases. To overcome these issues, several works have proposed automatic methods for the detection of AMD in retinography images, the most widely used modality for the screening of the disease. Nowadays, most of these works use Convolutional Neural Networks (CNNs) for the binary classification of images into AMD and non-AMD classes. In this work, we propose a novel approach based on CNNs that simultaneously performs AMD diagnosis and the classification of its potential lesions. This latter secondary task has not yet been addressed in this domain, and provides complementary useful information that improves the diagnosis performance and helps understanding the decision. A CNN model is trained using retinography images with image-level labels for both AMD and lesion presence, which are relatively easy to obtain. The experiments conducted in several public datasets show that the proposed approach improves the detection of AMD, while achieving satisfactory results in the identification of most lesions.



### Visual Explanations from Deep Networks via Riemann-Stieltjes Integrated Gradient-based Localization
- **Arxiv ID**: http://arxiv.org/abs/2205.10900v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, 68T45, I.2.m; I.4.m
- **Links**: [PDF](http://arxiv.org/pdf/2205.10900v1)
- **Published**: 2022-05-22 18:30:38+00:00
- **Updated**: 2022-05-22 18:30:38+00:00
- **Authors**: Mirtha Lucas, Miguel Lerma, Jacob Furst, Daniela Raicu
- **Comment**: 16 pages, 33 figures
- **Journal**: None
- **Summary**: Neural networks are becoming increasingly better at tasks that involve classifying and recognizing images. At the same time techniques intended to explain the network output have been proposed. One such technique is the Gradient-based Class Activation Map (Grad-CAM), which is able to locate features of an input image at various levels of a convolutional neural network (CNN), but is sensitive to the vanishing gradients problem. There are techniques such as Integrated Gradients (IG), that are not affected by that problem, but its use is limited to the input layer of a network. Here we introduce a new technique to produce visual explanations for the predictions of a CNN. Like Grad-CAM, our method can be applied to any layer of the network, and like Integrated Gradients it is not affected by the problem of vanishing gradients. For efficiency, gradient integration is performed numerically at the layer level using a Riemann-Stieltjes sum approximation. Compared to Grad-CAM, heatmaps produced by our algorithm are better focused in the areas of interest, and their numerical computation is more stable. Our code is available at https://github.com/mlerma54/RSIGradCAM



### AutoJoin: Efficient Adversarial Training for Robust Maneuvering via Denoising Autoencoder and Joint Learning
- **Arxiv ID**: http://arxiv.org/abs/2205.10933v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2205.10933v2)
- **Published**: 2022-05-22 21:18:40+00:00
- **Updated**: 2022-10-03 20:07:08+00:00
- **Authors**: Michael Villarreal, Bibek Poudel, Ryan Wickman, Yu Shen, Weizi Li
- **Comment**: None
- **Journal**: None
- **Summary**: As a result of increasingly adopted machine learning algorithms and ubiquitous sensors, many 'perception-to-control' systems are developed and deployed. For these systems to be trustworthy, we need to improve their robustness with adversarial training being one approach. We propose a gradient-free adversarial training technique, called AutoJoin, which is a very simple yet effective and efficient approach to produce robust models for imaged-based maneuvering. Compared to other SOTA methods with testing on over 5M perturbed and clean images, AutoJoin achieves significant performance increases up to the 40% range under gradient-free perturbations while improving on clean performance up to 300%. Regarding efficiency, AutoJoin demonstrates strong advantages over other SOTA techniques by saving up to 83% time per training epoch and 90% training data. Although not the focus of AutoJoin, it even demonstrates superb ability in defending gradient-based attacks. The core idea of AutoJoin is to use a decoder attachment to the original regression model creating a denoising autoencoder within the architecture. This architecture allows the tasks 'maneuvering' and 'denoising sensor input' to be jointly learnt and reinforce each other's performance.



### muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems
- **Arxiv ID**: http://arxiv.org/abs/2205.10937v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.NE
- **Links**: [PDF](http://arxiv.org/pdf/2205.10937v2)
- **Published**: 2022-05-22 21:54:33+00:00
- **Updated**: 2022-05-25 12:49:04+00:00
- **Authors**: Andrea Gesmundo, Jeff Dean
- **Comment**: None
- **Journal**: None
- **Summary**: Most uses of machine learning today involve training a model from scratch for a particular task, or sometimes starting with a model pretrained on a related task and then fine-tuning on a downstream task. Both approaches offer limited knowledge transfer between different tasks, time-consuming human-driven customization to individual tasks and high computational costs especially when starting from randomly initialized models. We propose a method that uses the layers of a pretrained deep neural network as building blocks to construct an ML system that can jointly solve an arbitrary number of tasks. The resulting system can leverage cross tasks knowledge transfer, while being immune from common drawbacks of multitask approaches such as catastrophic forgetting, gradients interference and negative transfer. We define an evolutionary approach designed to jointly select the prior knowledge relevant for each task, choose the subset of the model parameters to train and dynamically auto-tune its hyperparameters. Furthermore, a novel scale control method is employed to achieve quality/size trade-offs that outperform common fine-tuning techniques. Compared with standard fine-tuning on a benchmark of 10 diverse image classification tasks, the proposed model improves the average accuracy by 2.39% while using 47% less parameters per task.



### Evaluating deep tracking models for player tracking in broadcast ice hockey video
- **Arxiv ID**: http://arxiv.org/abs/2205.10949v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2205.10949v1)
- **Published**: 2022-05-22 22:56:31+00:00
- **Updated**: 2022-05-22 22:56:31+00:00
- **Authors**: Kanav Vats, Mehrnaz Fani, David A. Clausi, John S. Zelek
- **Comment**: Accepted to Link\"oping Hockey Analytics Conference (LINHAC). arXiv
  admin note: substantial text overlap with arXiv:2110.03090
- **Journal**: None
- **Summary**: Tracking and identifying players is an important problem in computer vision based ice hockey analytics. Player tracking is a challenging problem since the motion of players in hockey is fast-paced and non-linear. There is also significant player-player and player-board occlusion, camera panning and zooming in hockey broadcast video. Prior published research perform player tracking with the help of handcrafted features for player detection and re-identification. Although commercial solutions for hockey player tracking exist, to the best of our knowledge, no network architectures used, training data or performance metrics are publicly reported. There is currently no published work for hockey player tracking making use of the recent advancements in deep learning while also reporting the current accuracy metrics used in literature. Therefore, in this paper, we compare and contrast several state-of-the-art tracking algorithms and analyze their performance and failure modes in ice hockey.



### An Automated System for Detecting Visual Damages of Wind Turbine Blades
- **Arxiv ID**: http://arxiv.org/abs/2205.10954v1
- **DOI**: None
- **Categories**: **cs.AI**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2205.10954v1)
- **Published**: 2022-05-22 23:17:49+00:00
- **Updated**: 2022-05-22 23:17:49+00:00
- **Authors**: Linh Nguyen, Akshay Iyer, Shweta Khushu
- **Comment**: None
- **Journal**: None
- **Summary**: Wind energy's ability to compete with fossil fuels on a market level depends on lowering wind's high operational costs. Since damages on wind turbine blades are the leading cause for these operational problems, identifying blade damages is critical. However, recent works in visual identification of blade damages are still experimental and focus on optimizing the traditional machine learning metrics such as IoU. In this paper, we argue that pushing models to production long before achieving the "optimal" model performance can still generate real value for this use case. We discuss the performance of our damage's suggestion model in production and how this system works in coordination with humans as part of a commercialized product and how it can contribute towards lowering wind energy's operational costs.



