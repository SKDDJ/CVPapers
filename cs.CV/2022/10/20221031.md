# Arxiv Papers in cs.CV on 2022-10-31
### STN: a new tensor network method to identify stimulus category from brain activity pattern
- **Arxiv ID**: http://arxiv.org/abs/2210.16993v3
- **DOI**: None
- **Categories**: **q-bio.NC**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.16993v3)
- **Published**: 2022-10-31 00:42:48+00:00
- **Updated**: 2022-11-23 00:18:32+00:00
- **Authors**: Chunyu Liu, Jiacai Zhang
- **Comment**: 12 pages
- **Journal**: None
- **Summary**: Neural decoding is still a challenge and hot topic in neurocomputing science. Recently, many studies have shown that brain network patterns containing rich spatial and temporal structure information, which represents the activation information of brain under external stimuli. %Therefore, the research of decoding stimuli from brain network received extensive more attention. The traditional method extracts brain network features directly from the common machine learning method, then puts these features into the classifier, and realizes to decode external stimuli. However, this method cannot effectively extract the multi-dimensional structural information, which is hidden in the brain network. The tensor researchers show that the tensor decomposition model can fully mine unique spatio-temporal structure characteristics in multi-dimensional structure data. This research proposed a stimulus constrained tensor brain model(STN)which involves the tensor decomposition idea and stimulus category constraint information. The model was verified on the real neuroimaging data sets (MEG and fMRI). The experimental results show that the STN model achieves more than 11.06% and 18.46% on accuracy matrix compared with others methods on two modal data sets. These results imply the superiority of extracting discriminative characteristics about STN model, especially for decoding object stimuli with semantic information.



### Point-Syn2Real: Semi-Supervised Synthetic-to-Real Cross-Domain Learning for Object Classification in 3D Point Clouds
- **Arxiv ID**: http://arxiv.org/abs/2210.17009v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.MM
- **Links**: [PDF](http://arxiv.org/pdf/2210.17009v1)
- **Published**: 2022-10-31 01:53:51+00:00
- **Updated**: 2022-10-31 01:53:51+00:00
- **Authors**: Ziwei Wang, Reza Arablouei, Jiajun Liu, Paulo Borges, Greg Bishop-Hurley, Nicholas Heaney
- **Comment**: None
- **Journal**: None
- **Summary**: Object classification using LiDAR 3D point cloud data is critical for modern applications such as autonomous driving. However, labeling point cloud data is labor-intensive as it requires human annotators to visualize and inspect the 3D data from different perspectives. In this paper, we propose a semi-supervised cross-domain learning approach that does not rely on manual annotations of point clouds and performs similar to fully-supervised approaches. We utilize available 3D object models to train classifiers that can generalize to real-world point clouds. We simulate the acquisition of point clouds by sampling 3D object models from multiple viewpoints and with arbitrary partial occlusions. We then augment the resulting set of point clouds through random rotations and adding Gaussian noise to better emulate the real-world scenarios. We then train point cloud encoding models, e.g., DGCNN, PointNet++, on the synthesized and augmented datasets and evaluate their cross-domain classification performance on corresponding real-world datasets. We also introduce Point-Syn2Real, a new benchmark dataset for cross-domain learning on point clouds. The results of our extensive experiments with this dataset demonstrate that the proposed cross-domain learning approach for point clouds outperforms the related baseline and state-of-the-art approaches in both indoor and outdoor settings in terms of cross-domain generalizability. The code and data will be available upon publishing.



### Embedding Space Augmentation for Weakly Supervised Learning in Whole-Slide Images
- **Arxiv ID**: http://arxiv.org/abs/2210.17013v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI, I.5.4; I.4.0
- **Links**: [PDF](http://arxiv.org/pdf/2210.17013v1)
- **Published**: 2022-10-31 02:06:39+00:00
- **Updated**: 2022-10-31 02:06:39+00:00
- **Authors**: Imaad Zaffar, Guillaume Jaume, Nasir Rajpoot, Faisal Mahmood
- **Comment**: 5 pages, 3 figures, 1 table, ISBI 2023
- **Journal**: None
- **Summary**: Multiple Instance Learning (MIL) is a widely employed framework for learning on gigapixel whole-slide images (WSIs) from WSI-level annotations. In most MIL based analytical pipelines for WSI-level analysis, the WSIs are often divided into patches and deep features for patches (i.e., patch embeddings) are extracted prior to training to reduce the overall computational cost and cope with the GPUs' limited RAM. To overcome this limitation, we present EmbAugmenter, a data augmentation generative adversarial network (DA-GAN) that can synthesize data augmentations in the embedding space rather than in the pixel space, thereby significantly reducing the computational requirements. Experiments on the SICAPv2 dataset show that our approach outperforms MIL without augmentation and is on par with traditional patch-level augmentation for MIL training while being substantially faster.



### Emotional Brain State Classification on fMRI Data Using Deep Residual and Convolutional Networks
- **Arxiv ID**: http://arxiv.org/abs/2210.17015v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2210.17015v1)
- **Published**: 2022-10-31 02:08:02+00:00
- **Updated**: 2022-10-31 02:08:02+00:00
- **Authors**: Maxime Tchibozo, Donggeun Kim, Zijing Wang, Xiaofu He
- **Comment**: None
- **Journal**: None
- **Summary**: The goal of emotional brain state classification on functional MRI (fMRI) data is to recognize brain activity patterns related to specific emotion tasks performed by subjects during an experiment. Distinguishing emotional brain states from other brain states using fMRI data has proven to be challenging due to two factors: a difficulty to generate fast yet accurate predictions in short time frames, and a difficulty to extract emotion features which generalize to unseen subjects. To address these challenges, we conducted an experiment in which 22 subjects viewed pictures designed to stimulate either negative, neutral or rest emotional responses while their brain activity was measured using fMRI. We then developed two distinct Convolution-based approaches to decode emotional brain states using only spatial information from single, minimally pre-processed (slice timing and realignment) fMRI volumes. In our first approach, we trained a 1D Convolutional Network (84.9% accuracy; chance level 33%) to classify 3 emotion conditions using One-way Analysis of Variance (ANOVA) voxel selection combined with hyperalignment. In our second approach, we trained a 3D ResNet-50 model (78.0% accuracy; chance level 50%) to classify 2 emotion conditions from single 3D fMRI volumes directly. Our Convolutional and Residual classifiers successfully learned group-level emotion features and could decode emotion conditions from fMRI volumes in milliseconds. These approaches could potentially be used in brain computer interfaces and real-time fMRI neurofeedback research.



### A Law of Data Separation in Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2210.17020v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.IT, math.IT, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2210.17020v2)
- **Published**: 2022-10-31 02:25:38+00:00
- **Updated**: 2023-08-11 00:47:30+00:00
- **Authors**: Hangfeng He, Weijie J. Su
- **Comment**: Accepted at PNAS
- **Journal**: None
- **Summary**: While deep learning has enabled significant advances in many areas of science, its black-box nature hinders architecture design for future artificial intelligence applications and interpretation for high-stakes decision makings. We addressed this issue by studying the fundamental question of how deep neural networks process data in the intermediate layers. Our finding is a simple and quantitative law that governs how deep neural networks separate data according to class membership throughout all layers for classification. This law shows that each layer improves data separation at a constant geometric rate, and its emergence is observed in a collection of network architectures and datasets during training. This law offers practical guidelines for designing architectures, improving model robustness and out-of-sample performance, as well as interpreting the predictions.



### Improving Multi-generation Robustness of Learned Image Compression
- **Arxiv ID**: http://arxiv.org/abs/2210.17039v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17039v1)
- **Published**: 2022-10-31 03:26:11+00:00
- **Updated**: 2022-10-31 03:26:11+00:00
- **Authors**: Litian Li, Zheng Yang, Ronggang Wang
- **Comment**: None
- **Journal**: None
- **Summary**: Benefit from flexible network designs and end-to-end joint optimization approach, learned image compression (LIC) has demonstrated excellent coding performance and practical feasibility in recent years. However, existing compression models suffer from serious multi-generation loss, which always occurs during image editing and transcoding. During the process of repeatedly encoding and decoding, the quality of the image will rapidly degrade, resulting in various types of distortion, which significantly limits the practical application of LIC. In this paper, a thorough analysis is carried out to determine the source of generative loss in successive image compression (SIC). We point out and solve the quantization drift problem that affects SIC, reversibility loss function as well as channel relaxation method are proposed to further reduce the generation loss. Experiments show that by using our proposed solutions, LIC can achieve comparable performance to the first compression of BPG even after 50 times reencoding without any change of the network structure.



### Unified Optimal Transport Framework for Universal Domain Adaptation
- **Arxiv ID**: http://arxiv.org/abs/2210.17067v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17067v2)
- **Published**: 2022-10-31 05:07:09+00:00
- **Updated**: 2023-01-11 14:50:34+00:00
- **Authors**: Wanxing Chang, Ye Shi, Hoang Duong Tuan, Jingya Wang
- **Comment**: Accepted by NeurIPS2022
- **Journal**: None
- **Summary**: Universal Domain Adaptation (UniDA) aims to transfer knowledge from a source domain to a target domain without any constraints on label sets. Since both domains may hold private classes, identifying target common samples for domain alignment is an essential issue in UniDA. Most existing methods require manually specified or hand-tuned threshold values to detect common samples thus they are hard to extend to more realistic UniDA because of the diverse ratios of common classes. Moreover, they cannot recognize different categories among target-private samples as these private samples are treated as a whole. In this paper, we propose to use Optimal Transport (OT) to handle these issues under a unified framework, namely UniOT. First, an OT-based partial alignment with adaptive filling is designed to detect common classes without any predefined threshold values for realistic UniDA. It can automatically discover the intrinsic difference between common and private classes based on the statistical information of the assignment matrix obtained from OT. Second, we propose an OT-based target representation learning that encourages both global discrimination and local consistency of samples to avoid the over-reliance on the source. Notably, UniOT is the first method with the capability to automatically discover and recognize private categories in the target domain for UniDA. Accordingly, we introduce a new metric H^3-score to evaluate the performance in terms of both accuracy of common samples and clustering performance of private ones. Extensive experiments clearly demonstrate the advantages of UniOT over a wide range of state-of-the-art methods in UniDA.



### TW-BAG: Tensor-wise Brain-aware Gate Network for Inpainting Disrupted Diffusion Tensor Imaging
- **Arxiv ID**: http://arxiv.org/abs/2210.17076v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17076v1)
- **Published**: 2022-10-31 05:53:02+00:00
- **Updated**: 2022-10-31 05:53:02+00:00
- **Authors**: Zihao Tang, Xinyi Wang, Lihaowen Zhu, Mariano Cabezas, Dongnan Liu, Michael Barnett, Weidong Cai, Chengyu Wang
- **Comment**: Accepted by The 2022 International Conference on Digital Image
  Computing: Techniques and Applications (DICTA 2022)
- **Journal**: None
- **Summary**: Diffusion Weighted Imaging (DWI) is an advanced imaging technique commonly used in neuroscience and neurological clinical research through a Diffusion Tensor Imaging (DTI) model. Volumetric scalar metrics including fractional anisotropy, mean diffusivity, and axial diffusivity can be derived from the DTI model to summarise water diffusivity and other quantitative microstructural information for clinical studies. However, clinical practice constraints can lead to sub-optimal DWI acquisitions with missing slices (either due to a limited field of view or the acquisition of disrupted slices). To avoid discarding valuable subjects for group-wise studies, we propose a novel 3D Tensor-Wise Brain-Aware Gate network (TW-BAG) for inpainting disrupted DTIs. The proposed method is tailored to the problem with a dynamic gate mechanism and independent tensor-wise decoders. We evaluated the proposed method on the publicly available Human Connectome Project (HCP) dataset using common image similarity metrics derived from the predicted tensors and scalar DTI metrics. Our experimental results show that the proposed approach can reconstruct the original brain DTI volume and recover relevant clinical imaging information.



### Intelligent Painter: Picture Composition With Resampling Diffusion Model
- **Arxiv ID**: http://arxiv.org/abs/2210.17106v3
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17106v3)
- **Published**: 2022-10-31 07:27:01+00:00
- **Updated**: 2023-07-04 15:26:36+00:00
- **Authors**: Wing-Fung Ku, Wan-Chi Siu, Xi Cheng, H. Anthony Chan
- **Comment**: ICIP 2023
- **Journal**: None
- **Summary**: Have you ever thought that you can be an intelligent painter? This means that you can paint a picture with a few expected objects in mind, or with a desirable scene. This is different from normal inpainting approaches for which the location of specific objects cannot be determined. In this paper, we present an intelligent painter that generate a person's imaginary scene in one go, given explicit hints. We propose a resampling strategy for Denoising Diffusion Probabilistic Model (DDPM) to intelligently compose unconditional harmonized pictures according to the input subjects at specific locations. By exploiting the diffusion property, we resample efficiently to produce realistic pictures. Experimental results show that our resampling method favors the semantic meaning of the generated output efficiently and generates less blurry output. Quantitative analysis of image quality assessment shows that our method produces higher perceptual quality images compared with the state-of-the-art methods.



### ViT-LSLA: Vision Transformer with Light Self-Limited-Attention
- **Arxiv ID**: http://arxiv.org/abs/2210.17115v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17115v1)
- **Published**: 2022-10-31 07:46:45+00:00
- **Updated**: 2022-10-31 07:46:45+00:00
- **Authors**: Zhenzhe Hechen, Wei Huang, Yixin Zhao
- **Comment**: None
- **Journal**: None
- **Summary**: Transformers have demonstrated a competitive performance across a wide range of vision tasks, while it is very expensive to compute the global self-attention. Many methods limit the range of attention within a local window to reduce computation complexity. However, their approaches cannot save the number of parameters; meanwhile, the self-attention and inner position bias (inside the softmax function) cause each query to focus on similar and close patches. Consequently, this paper presents a light self-limited-attention (LSLA) consisting of a light self-attention mechanism (LSA) to save the computation cost and the number of parameters, and a self-limited-attention mechanism (SLA) to improve the performance. Firstly, the LSA replaces the K (Key) and V (Value) of self-attention with the X(origin input). Applying it in vision Transformers which have encoder architecture and self-attention mechanism, can simplify the computation. Secondly, the SLA has a positional information module and a limited-attention module. The former contains a dynamic scale and an inner position bias to adjust the distribution of the self-attention scores and enhance the positional information. The latter uses an outer position bias after the softmax function to limit some large values of attention weights. Finally, a hierarchical Vision Transformer with Light self-Limited-attention (ViT-LSLA) is presented. The experiments show that ViT-LSLA achieves 71.6% top-1 accuracy on IP102 (2.4% absolute improvement of Swin-T); 87.2% top-1 accuracy on Mini-ImageNet (3.7% absolute improvement of Swin-T). Furthermore, it greatly reduces FLOPs (3.5GFLOPs vs. 4.5GFLOPs of Swin-T) and parameters (18.9M vs. 27.6M of Swin-T).



### BOREx: Bayesian-Optimization--Based Refinement of Saliency Map for Image- and Video-Classification Models
- **Arxiv ID**: http://arxiv.org/abs/2210.17130v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.AI
- **Links**: [PDF](http://arxiv.org/pdf/2210.17130v1)
- **Published**: 2022-10-31 08:25:12+00:00
- **Updated**: 2022-10-31 08:25:12+00:00
- **Authors**: Atsushi Kikuchi, Kotaro Uchida, Masaki Waga, Kohei Suenaga
- **Comment**: 32 pages. To appear in ACCV 2022
- **Journal**: None
- **Summary**: Explaining a classification result produced by an image- and video-classification model is one of the important but challenging issues in computer vision. Many methods have been proposed for producing heat-map--based explanations for this purpose, including ones based on the white-box approach that uses the internal information of a model (e.g., LRP, Grad-CAM, and Grad-CAM++) and ones based on the black-box approach that does not use any internal information (e.g., LIME, SHAP, and RISE). We propose a new black-box method BOREx (Bayesian Optimization for Refinement of visual model Explanation) to refine a heat map produced by any method. Our observation is that a heat-map--based explanation can be seen as a prior for an explanation method based on Bayesian optimization. Based on this observation, BOREx conducts Gaussian process regression (GPR) to estimate the saliency of each pixel in a given image starting from the one produced by another explanation method. Our experiments statistically demonstrate that the refinement by BOREx improves low-quality heat maps for image- and video-classification results.



### Studying inductive biases in image classification task
- **Arxiv ID**: http://arxiv.org/abs/2210.17141v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17141v1)
- **Published**: 2022-10-31 08:43:26+00:00
- **Updated**: 2022-10-31 08:43:26+00:00
- **Authors**: Nana Arizumi
- **Comment**: None
- **Journal**: None
- **Summary**: Recently, self-attention (SA) structures became popular in computer vision fields. They have locally independent filters and can use large kernels, which contradicts the previously popular convolutional neural networks (CNNs). CNNs success was attributed to the hard-coded inductive biases of locality and spatial invariance. However, recent studies have shown that inductive biases in CNNs are too restrictive. On the other hand, the relative position encodings, similar to depthwise (DW) convolution, are necessary for the local SA networks, which indicates that the SA structures are not entirely spatially variant. Hence, we would like to determine which part of inductive biases contributes to the success of the local SA structures. To do so, we introduced context-aware decomposed attention (CADA), which decomposes attention maps into multiple trainable base kernels and accumulates them using context-aware (CA) parameters. This way, we could identify the link between the CNNs and SA networks. We conducted ablation studies using the ResNet50 applied to the ImageNet classification task. DW convolution could have a large locality without increasing computational costs compared to CNNs, but the accuracy saturates with larger kernels. CADA follows this characteristic of locality. We showed that context awareness was the crucial property; however, large local information was not necessary to construct CA parameters. Even though no spatial invariance makes training difficult, more relaxed spatial invariance gave better accuracy than strict spatial invariance. Also, additional strong spatial invariance through relative position encoding was preferable. We extended these experiments to filters for downsampling and showed that locality bias is more critical for downsampling but can remove the strong locality bias using relaxed spatial invariance.



### LAD-RCNN:A Powerful Tool for Livestock Face Detection and Normalization
- **Arxiv ID**: http://arxiv.org/abs/2210.17146v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17146v2)
- **Published**: 2022-10-31 08:54:21+00:00
- **Updated**: 2022-11-05 09:11:13+00:00
- **Authors**: Ling Sun, Guiqiong Liu, Xunping Jiang, Junrui Liu, Xu Wang, Han Yang, Shiping Yang
- **Comment**: 8 figures, 5 tables
- **Journal**: None
- **Summary**: With the demand for standardized large-scale livestock farming and the development of artificial intelligence technology, a lot of research in area of animal face recognition were carried on pigs, cattle, sheep and other livestock. Face recognition consists of three sub-task: face detection, face normalizing and face identification. Most of animal face recognition study focuses on face detection and face identification. Animals are often uncooperative when taking photos, so the collected animal face images are often in arbitrary directions. The use of non-standard images may significantly reduce the performance of face recognition system. However, there is no study on normalizing of the animal face image with arbitrary directions. In this study, we developed a light-weight angle detection and region-based convolutional network (LAD-RCNN) containing a new rotation angle coding method that can detect the rotation angle and the location of animal face in one-stage. LAD-RCNN has a frame rate of 72.74 FPS (including all steps) on a single GeForce RTX 2080 Ti GPU. LAD-RCNN has been evaluated on multiple dataset including goat dataset and gaot infrared image. Evaluation result show that the AP of face detection was more than 95% and the deviation between the detected rotation angle and the ground-truth rotation angle were less than 0.036 (i.e. 6.48{\deg}) on all the test dataset. This shows that LAD-RCNN has excellent performance on livestock face and its direction detection, and therefore it is very suitable for livestock face detection and Normalizing. Code is available at https://github.com/SheepBreedingLab-HZAU/LAD-RCNN/



### Tech Report: One-stage Lightweight Object Detectors
- **Arxiv ID**: http://arxiv.org/abs/2210.17151v1
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17151v1)
- **Published**: 2022-10-31 09:02:37+00:00
- **Updated**: 2022-10-31 09:02:37+00:00
- **Authors**: Deokki Hong
- **Comment**: None
- **Journal**: None
- **Summary**: This work is for designing one-stage lightweight detectors which perform well in terms of mAP and latency. With baseline models each of which targets on GPU and CPU respectively, various operations are applied instead of the main operations in backbone networks of baseline models. In addition to experiments about backbone networks and operations, several feature pyramid network (FPN) architectures are investigated. Benchmarks and proposed detectors are analyzed in terms of the number of parameters, Gflops, GPU latency, CPU latency and mAP, on MS COCO dataset which is a benchmark dataset in object detection. This work propose similar or better network architectures considering the trade-off between accuracy and latency. For example, our proposed GPU-target backbone network outperforms that of YOLOX-tiny which is selected as the benchmark by 1.43x in speed and 0.5 mAP in accuracy on NVIDIA GeForce RTX 2080 Ti GPU.



### Automatic Subspace Evoking for Efficient Neural Architecture Search
- **Arxiv ID**: http://arxiv.org/abs/2210.17180v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17180v1)
- **Published**: 2022-10-31 09:54:28+00:00
- **Updated**: 2022-10-31 09:54:28+00:00
- **Authors**: Yaofo Chen, Yong Guo, Daihai Liao, Fanbing Lv, Hengjie Song, Mingkui Tan
- **Comment**: None
- **Journal**: None
- **Summary**: Neural Architecture Search (NAS) aims to automatically find effective architectures from a predefined search space. However, the search space is often extremely large. As a result, directly searching in such a large search space is non-trivial and also very time-consuming. To address the above issues, in each search step, we seek to limit the search space to a small but effective subspace to boost both the search performance and search efficiency. To this end, we propose a novel Neural Architecture Search method via Automatic Subspace Evoking (ASE-NAS) that finds promising architectures in automatically evoked subspaces. Specifically, we first perform a global search, i.e., automatic subspace evoking, to evoke/find a good subspace from a set of candidates. Then, we perform a local search within the evoked subspace to find an effective architecture. More critically, we further boost search performance by taking well-designed/searched architectures as the initial candidate subspaces. Extensive experiments show that our ASE-NAS not only greatly reduces the search cost but also finds better architectures than state-of-the-art methods in various benchmark search spaces.



### Combining Automatic Speaker Verification and Prosody Analysis for Synthetic Speech Detection
- **Arxiv ID**: http://arxiv.org/abs/2210.17222v1
- **DOI**: None
- **Categories**: **cs.SD**, cs.CV, cs.MM, eess.AS
- **Links**: [PDF](http://arxiv.org/pdf/2210.17222v1)
- **Published**: 2022-10-31 11:03:03+00:00
- **Updated**: 2022-10-31 11:03:03+00:00
- **Authors**: Luigi Attorresi, Davide Salvi, Clara Borrelli, Paolo Bestagini, Stefano Tubaro
- **Comment**: None
- **Journal**: None
- **Summary**: The rapid spread of media content synthesis technology and the potentially damaging impact of audio and video deepfakes on people's lives have raised the need to implement systems able to detect these forgeries automatically. In this work we present a novel approach for synthetic speech detection, exploiting the combination of two high-level semantic properties of the human voice. On one side, we focus on speaker identity cues and represent them as speaker embeddings extracted using a state-of-the-art method for the automatic speaker verification task. On the other side, voice prosody, intended as variations in rhythm, pitch or accent in speech, is extracted through a specialized encoder. We show that the combination of these two embeddings fed to a supervised binary classifier allows the detection of deepfake speech generated with both Text-to-Speech and Voice Conversion techniques. Our results show improvements over the considered baselines, good generalization properties over multiple datasets and robustness to audio compression.



### CorrLoss: Integrating Co-Occurrence Domain Knowledge for Affect Recognition
- **Arxiv ID**: http://arxiv.org/abs/2210.17233v1
- **DOI**: 10.1109/ICPR56361.2022.9956319
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17233v1)
- **Published**: 2022-10-31 11:28:23+00:00
- **Updated**: 2022-10-31 11:28:23+00:00
- **Authors**: Ines Rieger, Jaspar Pahl, Bettina Finzel, Ute Schmid
- **Comment**: This paper is accepted at IEEE 26TH International Conference on
  Pattern Recognition (ICPR) 2022
- **Journal**: 2022 26th International Conference on Pattern Recognition (ICPR)
- **Summary**: Neural networks are widely adopted, yet the integration of domain knowledge is still underutilized. We propose to integrate domain knowledge about co-occurring facial movements as a constraint in the loss function to enhance the training of neural networks for affect recognition. As the co-ccurrence patterns tend to be similar across datasets, applying our method can lead to a higher generalizability of models and a lower risk of overfitting. We demonstrate this by showing performance increases in cross-dataset testing for various datasets. We also show the applicability of our method for calibrating neural networks to different facial expressions.



### Tables to LaTeX: structure and content extraction from scientific tables
- **Arxiv ID**: http://arxiv.org/abs/2210.17246v1
- **DOI**: 10.1007/s10032-022-00420-9
- **Categories**: **cs.IR**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17246v1)
- **Published**: 2022-10-31 12:08:39+00:00
- **Updated**: 2022-10-31 12:08:39+00:00
- **Authors**: Pratik Kayal, Mrinal Anand, Harsh Desai, Mayank Singh
- **Comment**: 10 pages, published in IJDAR'22. arXiv admin note: text overlap with
  arXiv:2105.14426
- **Journal**: None
- **Summary**: Scientific documents contain tables that list important information in a concise fashion. Structure and content extraction from tables embedded within PDF research documents is a very challenging task due to the existence of visual features like spanning cells and content features like mathematical symbols and equations. Most existing table structure identification methods tend to ignore these academic writing features. In this paper, we adapt the transformer-based language modeling paradigm for scientific table structure and content extraction. Specifically, the proposed model converts a tabular image to its corresponding LaTeX source code. Overall, we outperform the current state-of-the-art baselines and achieve an exact match accuracy of 70.35 and 49.69% on table structure and content extraction, respectively. Further analysis demonstrates that the proposed models efficiently identify the number of rows and columns, the alphanumeric characters, the LaTeX tokens, and symbols.



### Multi-Camera Calibration Free BEV Representation for 3D Object Detection
- **Arxiv ID**: http://arxiv.org/abs/2210.17252v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17252v1)
- **Published**: 2022-10-31 12:18:08+00:00
- **Updated**: 2022-10-31 12:18:08+00:00
- **Authors**: Hongxiang Jiang, Wenming Meng, Hongmei Zhu, Qian Zhang, Jihao Yin
- **Comment**: 15 pages, 7 figures
- **Journal**: None
- **Summary**: In advanced paradigms of autonomous driving, learning Bird's Eye View (BEV) representation from surrounding views is crucial for multi-task framework. However, existing methods based on depth estimation or camera-driven attention are not stable to obtain transformation under noisy camera parameters, mainly with two challenges, accurate depth prediction and calibration. In this work, we present a completely Multi-Camera Calibration Free Transformer (CFT) for robust BEV representation, which focuses on exploring implicit mapping, not relied on camera intrinsics and extrinsics. To guide better feature learning from image views to BEV, CFT mines potential 3D information in BEV via our designed position-aware enhancement (PA). Instead of camera-driven point-wise or global transformation, for interaction within more effective region and lower computation cost, we propose a view-aware attention which also reduces redundant computation and promotes converge. CFT achieves 49.7% NDS on the nuScenes detection task leaderboard, which is the first work removing camera parameters, comparable to other geometry-guided methods. Without temporal input and other modal information, CFT achieves second highest performance with a smaller image input 1600 * 640. Thanks to view-attention variant, CFT reduces memory and transformer FLOPs for vanilla attention by about 12% and 60%, respectively, with improved NDS by 1.0%. Moreover, its natural robustness to noisy camera parameters makes CFT more competitive.



### Teacher-Student Network for 3D Point Cloud Anomaly Detection with Few Normal Samples
- **Arxiv ID**: http://arxiv.org/abs/2210.17258v2
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17258v2)
- **Published**: 2022-10-31 12:29:55+00:00
- **Updated**: 2023-05-09 13:49:20+00:00
- **Authors**: Jianjian Qin, Chunzhi Gu, Jun Yu, Chao Zhang
- **Comment**: None
- **Journal**: None
- **Summary**: Anomaly detection, which is a critical and popular topic in computer vision, aims to detect anomalous samples that are different from the normal (i.e., non-anomalous) ones. The current mainstream methods focus on anomaly detection for images, whereas little attention has been paid to 3D point cloud. In this paper, drawing inspiration from the knowledge transfer ability of teacher-student architecture and the impressive feature extraction capability of recent neural networks, we design a teacher-student structured model for 3D anomaly detection. Specifically, we use feature space alignment, dimension zoom, and max pooling to extract the features of the point cloud and then minimize a multi-scale loss between the feature vectors produced by the teacher and the student networks. Moreover, our method only requires very few normal samples to train the student network due to the teacher-student distillation mechanism. Once trained, the teacher-student network pair can be leveraged jointly to fulfill 3D point cloud anomaly detection based on the calculated anomaly score. For evaluation, we compare our method against the reconstruction-based method on the ShapeNet-Part dataset. The experimental results and ablation studies quantitatively and qualitatively confirm that our model can achieve higher performance compared with the state of the arts in 3D anomaly detection with very few training samples.



### Scoliosis Detection using Deep Neural Network
- **Arxiv ID**: http://arxiv.org/abs/2210.17269v1
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2210.17269v1)
- **Published**: 2022-10-31 12:52:04+00:00
- **Updated**: 2022-10-31 12:52:04+00:00
- **Authors**: Yen Hoang Nguyen
- **Comment**: arXiv admin note: text overlap with arXiv:1911.03723 by other authors
- **Journal**: None
- **Summary**: Scoliosis is a sideways curvature of the spine that most often is diagnosed among young teenagers. It dramatically affects the quality of life, which can cause complications from heart and lung injuries in severe cases. The current gold standard to detect and estimate scoliosis is to manually examine the spinal anterior-posterior X-ray images. This process is time-consuming, observer-dependent, and has high inter-rater variability. Consequently, there has been increasing interest in automatic scoliosis estimation from spinal X-ray images, and the development of deep learning has shown amazing achievements in automatic spinal curvature estimation. The main target of this thesis is to review the fundamental concepts of deep learning, analyze how deep learning is applied to detect spinal curvature, explore the practical deep learning-based models that have been employed. It aims to improve the accuracy of scoliosis detection and implement the most successful one for automated Cobb angle prediction. Keywords: Scoliosis Detection, Spinal Curvature Estimation, Deep Learning. i



### Generative Negative Text Replay for Continual Vision-Language Pretraining
- **Arxiv ID**: http://arxiv.org/abs/2210.17322v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17322v1)
- **Published**: 2022-10-31 13:42:21+00:00
- **Updated**: 2022-10-31 13:42:21+00:00
- **Authors**: Shipeng Yan, Lanqing Hong, Hang Xu, Jianhua Han, Tinne Tuytelaars, Zhenguo Li, Xuming He
- **Comment**: ECCV 2022
- **Journal**: None
- **Summary**: Vision-language pre-training (VLP) has attracted increasing attention recently. With a large amount of image-text pairs, VLP models trained with contrastive loss have achieved impressive performance in various tasks, especially the zero-shot generalization on downstream datasets. In practical applications, however, massive data are usually collected in a streaming fashion, requiring VLP models to continuously integrate novel knowledge from incoming data and retain learned knowledge. In this work, we focus on learning a VLP model with sequential chunks of image-text pair data. To tackle the catastrophic forgetting issue in this multi-modal continual learning setting, we first introduce pseudo text replay that generates hard negative texts conditioned on the training images in memory, which not only better preserves learned knowledge but also improves the diversity of negative samples in the contrastive loss. Moreover, we propose multi-modal knowledge distillation between images and texts to align the instance-wise prediction between old and new models. We incrementally pre-train our model on both the instance and class incremental splits of the Conceptual Caption dataset, and evaluate the model on zero-shot image classification and image-text retrieval tasks. Our method consistently outperforms the existing baselines with a large margin, which demonstrates its superiority. Notably, we realize an average performance boost of $4.60\%$ on image-classification downstream datasets for the class incremental split.



### Real-time Mapping of Physical Scene Properties with an Autonomous Robot Experimenter
- **Arxiv ID**: http://arxiv.org/abs/2210.17325v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17325v1)
- **Published**: 2022-10-31 13:46:21+00:00
- **Updated**: 2022-10-31 13:46:21+00:00
- **Authors**: Iain Haughton, Edgar Sucar, Andre Mouton, Edward Johns, Andrew J. Davison
- **Comment**: None
- **Journal**: None
- **Summary**: Neural fields can be trained from scratch to represent the shape and appearance of 3D scenes efficiently. It has also been shown that they can densely map correlated properties such as semantics, via sparse interactions from a human labeller. In this work, we show that a robot can densely annotate a scene with arbitrary discrete or continuous physical properties via its own fully-autonomous experimental interactions, as it simultaneously scans and maps it with an RGB-D camera. A variety of scene interactions are possible, including poking with force sensing to determine rigidity, measuring local material type with single-pixel spectroscopy or predicting force distributions by pushing. Sparse experimental interactions are guided by entropy to enable high efficiency, with tabletop scene properties densely mapped from scratch in a few minutes from a few tens of interactions.



### gCoRF: Generative Compositional Radiance Fields
- **Arxiv ID**: http://arxiv.org/abs/2210.17344v1
- **DOI**: None
- **Categories**: **cs.GR**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17344v1)
- **Published**: 2022-10-31 14:10:44+00:00
- **Updated**: 2022-10-31 14:10:44+00:00
- **Authors**: Mallikarjun BR, Ayush Tewari, Xingang Pan, Mohamed Elgharib, Christian Theobalt
- **Comment**: https://vcai.mpi-inf.mpg.de/projects/gCoRF/
- **Journal**: None
- **Summary**: 3D generative models of objects enable photorealistic image synthesis with 3D control. Existing methods model the scene as a global scene representation, ignoring the compositional aspect of the scene. Compositional reasoning can enable a wide variety of editing applications, in addition to enabling generalizable 3D reasoning. In this paper, we present a compositional generative model, where each semantic part of the object is represented as an independent 3D representation learned from only in-the-wild 2D data. We start with a global generative model (GAN) and learn to decompose it into different semantic parts using supervision from 2D segmentation masks. We then learn to composite independently sampled parts in order to create coherent global scenes. Different parts can be independently sampled while keeping the rest of the object fixed. We evaluate our method on a wide variety of objects and parts and demonstrate editing applications.



### Rethinking Generalization: The Impact of Annotation Style on Medical Image Segmentation
- **Arxiv ID**: http://arxiv.org/abs/2210.17398v3
- **DOI**: None
- **Categories**: **cs.CV**, eess.IV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17398v3)
- **Published**: 2022-10-31 15:28:49+00:00
- **Updated**: 2022-12-13 16:55:45+00:00
- **Authors**: Brennan Nichyporuk, Jillian Cardinell, Justin Szeto, Raghav Mehta, Jean-Pierre R. Falet, Douglas L. Arnold, Sotirios A. Tsaftaris, Tal Arbel
- **Comment**: Accepted for publication at the Journal of Machine Learning for
  Biomedical Imaging (MELBA) https://www.melba-journal.org/papers/2022:029.html
- **Journal**: Machine.Learning.for.Biomedical.Imaging. 1 (2022)
- **Summary**: Generalization is an important attribute of machine learning models, particularly for those that are to be deployed in a medical context, where unreliable predictions can have real world consequences. While the failure of models to generalize across datasets is typically attributed to a mismatch in the data distributions, performance gaps are often a consequence of biases in the 'ground-truth' label annotations. This is particularly important in the context of medical image segmentation of pathological structures (e.g. lesions), where the annotation process is much more subjective, and affected by a number underlying factors, including the annotation protocol, rater education/experience, and clinical aims, among others. In this paper, we show that modeling annotation biases, rather than ignoring them, poses a promising way of accounting for differences in annotation style across datasets. To this end, we propose a generalized conditioning framework to (1) learn and account for different annotation styles across multiple datasets using a single model, (2) identify similar annotation styles across different datasets in order to permit their effective aggregation, and (3) fine-tune a fully trained model to a new annotation style with just a few samples. Next, we present an image-conditioning approach to model annotation styles that correlate with specific image features, potentially enabling detection biases to be more easily identified.



### Max Pooling with Vision Transformers reconciles class and shape in weakly supervised semantic segmentation
- **Arxiv ID**: http://arxiv.org/abs/2210.17400v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17400v1)
- **Published**: 2022-10-31 15:32:23+00:00
- **Updated**: 2022-10-31 15:32:23+00:00
- **Authors**: Simone Rossetti, Damiano Zappia, Marta Sanzari, Marco Schaerf, Fiora Pirri
- **Comment**: 28 pages, 9 images, ECCV 2022 conference
- **Journal**: None
- **Summary**: Weakly Supervised Semantic Segmentation (WSSS) research has explored many directions to improve the typical pipeline CNN plus class activation maps (CAM) plus refinements, given the image-class label as the only supervision. Though the gap with the fully supervised methods is reduced, further abating the spread seems unlikely within this framework. On the other hand, WSSS methods based on Vision Transformers (ViT) have not yet explored valid alternatives to CAM. ViT features have been shown to retain a scene layout, and object boundaries in self-supervised learning. To confirm these findings, we prove that the advantages of transformers in self-supervised methods are further strengthened by Global Max Pooling (GMP), which can leverage patch features to negotiate pixel-label probability with class probability. This work proposes a new WSSS method dubbed ViT-PCM (ViT Patch-Class Mapping), not based on CAM. The end-to-end presented network learns with a single optimization process, refined shape and proper localization for segmentation masks. Our model outperforms the state-of-the-art on baseline pseudo-masks (BPM), where we achieve $69.3\%$ mIoU on PascalVOC 2012 $val$ set. We show that our approach has the least set of parameters, though obtaining higher accuracy than all other approaches. In a sentence, quantitative and qualitative results of our method reveal that ViT-PCM is an excellent alternative to CNN-CAM based architectures.



### Tree Detection and Diameter Estimation Based on Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2210.17424v1
- **DOI**: 10.1093/forestry/cpac043
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2210.17424v1)
- **Published**: 2022-10-31 15:51:32+00:00
- **Updated**: 2022-10-31 15:51:32+00:00
- **Authors**: Vincent Grondin, Jean-Michel Fortin, François Pomerleau, Philippe Giguère
- **Comment**: None
- **Journal**: None
- **Summary**: Tree perception is an essential building block toward autonomous forestry operations. Current developments generally consider input data from lidar sensors to solve forest navigation, tree detection and diameter estimation problems. Whereas cameras paired with deep learning algorithms usually address species classification or forest anomaly detection. In either of these cases, data unavailability and forest diversity restrain deep learning developments for autonomous systems. So, we propose two densely annotated image datasets - 43k synthetic, 100 real - for bounding box, segmentation mask and keypoint detections to assess the potential of vision-based methods. Deep neural network models trained on our datasets achieve a precision of 90.4% for tree detection, 87.2% for tree segmentation, and centimeter accurate keypoint estimations. We measure our models' generalizability when testing it on other forest datasets, and their scalability with different dataset sizes and architectural improvements. Overall, the experimental results offer promising avenues toward autonomous tree felling operations and other applied forestry problems. The datasets and pre-trained models in this article are publicly available on \href{https://github.com/norlab-ulaval/PercepTreeV1}{GitHub} (https://github.com/norlab-ulaval/PercepTreeV1).



### Trade-off Between Efficiency and Consistency for Removal-based Explanations
- **Arxiv ID**: http://arxiv.org/abs/2210.17426v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, stat.ML
- **Links**: [PDF](http://arxiv.org/pdf/2210.17426v2)
- **Published**: 2022-10-31 15:56:39+00:00
- **Updated**: 2023-05-30 15:28:46+00:00
- **Authors**: Yifan Zhang, Haowei He, Zhiquan Tan, Yang Yuan
- **Comment**: None
- **Journal**: None
- **Summary**: In the current landscape of explanation methodologies, most predominant approaches, such as SHAP and LIME, employ removal-based techniques to evaluate the impact of individual features by simulating various scenarios with specific features omitted. Nonetheless, these methods primarily emphasize efficiency in the original context, often resulting in general inconsistencies. In this paper, we demonstrate that such inconsistency is an inherent aspect of these approaches by establishing the Impossible Trinity Theorem, which posits that interpretability, efficiency and consistency cannot hold simultaneously. Recognizing that the attainment of an ideal explanation remains elusive, we propose the utilization of interpretation error as a metric to gauge inconsistencies and inefficiencies. To this end, we present two novel algorithms founded on the standard polynomial basis, aimed at minimizing interpretation error. Our empirical findings indicate that the proposed methods achieve a substantial reduction in interpretation error, up to 31.8 times lower when compared to alternative techniques.



### A Faster Approach to Spiking Deep Convolutional Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2210.17442v1
- **DOI**: None
- **Categories**: **cs.CV**, q-bio.NC, I.2.6
- **Links**: [PDF](http://arxiv.org/pdf/2210.17442v1)
- **Published**: 2022-10-31 16:13:15+00:00
- **Updated**: 2022-10-31 16:13:15+00:00
- **Authors**: Shahriar Rezghi Shirsavar, Mohammad-Reza A. Dehaqani
- **Comment**: 6 pages, 7 figures, to be published in the Asilomar 2022 conference
- **Journal**: None
- **Summary**: Spiking neural networks (SNNs) have closer dynamics to the brain than current deep neural networks. Their low power consumption and sample efficiency make these networks interesting. Recently, several deep convolutional spiking neural networks have been proposed. These networks aim to increase biological plausibility while creating powerful tools to be applied to machine learning tasks. Here, we suggest a network structure based on previous work to improve network runtime and accuracy. Improvements to the network include reducing training iterations to only once, effectively using principal component analysis (PCA) dimension reduction, weight quantization, timed outputs for classification, and better hyperparameter tuning. Furthermore, the preprocessing step is changed to allow the processing of colored images instead of only black and white to improve accuracy. The proposed structure fractionalizes runtime and introduces an efficient approach to deep convolutional SNNs.



### Iterative Teaching by Data Hallucination
- **Arxiv ID**: http://arxiv.org/abs/2210.17467v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2210.17467v2)
- **Published**: 2022-10-31 16:48:47+00:00
- **Updated**: 2023-04-12 20:49:44+00:00
- **Authors**: Zeju Qiu, Weiyang Liu, Tim Z. Xiao, Zhen Liu, Umang Bhatt, Yucen Luo, Adrian Weller, Bernhard Schölkopf
- **Comment**: AISTATS 2023 (v2: 22 pages, 24 figures)
- **Journal**: None
- **Summary**: We consider the problem of iterative machine teaching, where a teacher sequentially provides examples based on the status of a learner under a discrete input space (i.e., a pool of finite samples), which greatly limits the teacher's capability. To address this issue, we study iterative teaching under a continuous input space where the input example (i.e., image) can be either generated by solving an optimization problem or drawn directly from a continuous distribution. Specifically, we propose data hallucination teaching (DHT) where the teacher can generate input data intelligently based on labels, the learner's status and the target concept. We study a number of challenging teaching setups (e.g., linear/neural learners in omniscient and black-box settings). Extensive empirical results verify the effectiveness of DHT.



### Quantum-Inspired Edge Detection Algorithms Implementation using New Dynamic Visual Data Representation and Short-Length Convolution Computation
- **Arxiv ID**: http://arxiv.org/abs/2210.17490v1
- **DOI**: None
- **Categories**: **cs.CV**, math.QA, 68Q12, F.2; I.4.0
- **Links**: [PDF](http://arxiv.org/pdf/2210.17490v1)
- **Published**: 2022-10-31 17:13:27+00:00
- **Updated**: 2022-10-31 17:13:27+00:00
- **Authors**: Artyom M. Grigoryan, Sos S. Agaian, Karen Panetta
- **Comment**: 11 pages, 11 figures
- **Journal**: None
- **Summary**: As the availability of imagery data continues to swell, so do the demands on transmission, storage and processing power. Processing requirements to handle this plethora of data is quickly outpacing the utility of conventional processing techniques. Transitioning to quantum processing and algorithms that offer promising efficiencies over conventional methods can address some of these issues. However, to make this transformation possible, fundamental issues of implementing real time Quantum algorithms must be overcome for crucial processes needed for intelligent analysis applications. For example, consider edge detection tasks which require time-consuming acquisition processes and are further hindered by the complexity of the devices used thus limiting feasibility for implementation in real-time applications. Convolution is another example of an operation that is essential for signal and image processing applications, where the mathematical operations consist of an intelligent mixture of multiplication and addition that require considerable computational resources. This paper studies a new paired transform-based quantum representation and computation of one-dimensional and 2-D signals convolutions and gradients. A new visual data representation is defined to simplify convolution calculations making it feasible to parallelize convolution and gradient operations for more efficient performance. The new data representation is demonstrated on multiple illustrative examples for quantum edge detection, gradients, and convolution. Furthermore, the efficiency of the proposed approach is shown on real-world images.



### Road Damages Detection and Classification with YOLOv7
- **Arxiv ID**: http://arxiv.org/abs/2211.00091v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2211.00091v1)
- **Published**: 2022-10-31 18:55:58+00:00
- **Updated**: 2022-10-31 18:55:58+00:00
- **Authors**: Vung Pham, Du Nguyen, Christopher Donan
- **Comment**: 8 pages, 5 tables, 9 figures, 17 references
- **Journal**: None
- **Summary**: Maintaining the roadway infrastructure is one of the essential factors in enabling a safe, economic, and sustainable transportation system. Manual roadway damage data collection is laborious and unsafe for humans to perform. This area is poised to benefit from the rapid advance and diffusion of artificial intelligence technologies. Specifically, deep learning advancements enable the detection of road damages automatically from the collected road images. This work proposes to collect and label road damage data using Google Street View and use YOLOv7 (You Only Look Once version 7) together with coordinate attention and related accuracy fine-tuning techniques such as label smoothing and ensemble method to train deep learning models for automatic road damage detection and classification. The proposed approaches are applied to the Crowdsensing-based Road Damage Detection Challenge (CRDDC2022), IEEE BigData 2022. The results show that the data collection from Google Street View is efficient, and the proposed deep learning approach results in F1 scores of 81.7% on the road damage data collected from the United States using Google Street View and 74.1% on all test images of this dataset.



### Synthetic ID Card Image Generation for Improving Presentation Attack Detection
- **Arxiv ID**: http://arxiv.org/abs/2211.00098v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CR
- **Links**: [PDF](http://arxiv.org/pdf/2211.00098v1)
- **Published**: 2022-10-31 19:07:30+00:00
- **Updated**: 2022-10-31 19:07:30+00:00
- **Authors**: Daniel Benalcazar, Juan E. Tapia, Sebastian Gonzalez, Christoph Busch
- **Comment**: None
- **Journal**: None
- **Summary**: Currently, it is ever more common to access online services for activities which formerly required physical attendance. From banking operations to visa applications, a significant number of processes have been digitised, especially since the advent of the COVID-19 pandemic, requiring remote biometric authentication of the user. On the downside, some subjects intend to interfere with the normal operation of remote systems for personal profit by using fake identity documents, such as passports and ID cards. Deep learning solutions to detect such frauds have been presented in the literature. However, due to privacy concerns and the sensitive nature of personal identity documents, developing a dataset with the necessary number of examples for training deep neural networks is challenging. This work explores three methods for synthetically generating ID card images to increase the amount of data while training fraud-detection networks. These methods include computer vision algorithms and Generative Adversarial Networks. Our results indicate that databases can be supplemented with synthetic images without any loss in performance for the print/scan Presentation Attack Instrument Species (PAIS) and a loss in performance of 1% for the screen capture PAIS.



### UmeTrack: Unified multi-view end-to-end hand tracking for VR
- **Arxiv ID**: http://arxiv.org/abs/2211.00099v1
- **DOI**: 10.1145/3550469.3555378
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2211.00099v1)
- **Published**: 2022-10-31 19:09:21+00:00
- **Updated**: 2022-10-31 19:09:21+00:00
- **Authors**: Shangchen Han, Po-chen Wu, Yubo Zhang, Beibei Liu, Linguang Zhang, Zheng Wang, Weiguang Si, Peizhao Zhang, Yujun Cai, Tomas Hodan, Randi Cabezas, Luan Tran, Muzaffer Akbay, Tsz-Ho Yu, Cem Keskin, Robert Wang
- **Comment**: SIGGRAPH Asia 2022 Conference Papers, 8 pages
- **Journal**: None
- **Summary**: Real-time tracking of 3D hand pose in world space is a challenging problem and plays an important role in VR interaction. Existing work in this space are limited to either producing root-relative (versus world space) 3D pose or rely on multiple stages such as generating heatmaps and kinematic optimization to obtain 3D pose. Moreover, the typical VR scenario, which involves multi-view tracking from wide \ac{fov} cameras is seldom addressed by these methods. In this paper, we present a unified end-to-end differentiable framework for multi-view, multi-frame hand tracking that directly predicts 3D hand pose in world space. We demonstrate the benefits of end-to-end differentiabilty by extending our framework with downstream tasks such as jitter reduction and pinch prediction. To demonstrate the efficacy of our model, we further present a new large-scale egocentric hand pose dataset that consists of both real and synthetic data. Experiments show that our system trained on this dataset handles various challenging interactive motions, and has been successfully applied to real-time VR applications.



### A new benchmark for group distribution shifts in hand grasp regression for object manipulation. Can meta-learning raise the bar?
- **Arxiv ID**: http://arxiv.org/abs/2211.00110v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2211.00110v1)
- **Published**: 2022-10-31 19:32:14+00:00
- **Updated**: 2022-10-31 19:32:14+00:00
- **Authors**: Théo Morales, Gerard Lacey
- **Comment**: Workshop on Distribution Shifts, 36th Conference on Neural
  Information Processing Systems (NeurIPS 2022)
- **Journal**: None
- **Summary**: Understanding hand-object pose with computer vision opens the door to new applications in mixed reality, assisted living or human-robot interaction. Most methods are trained and evaluated on balanced datasets. This is of limited use in real-world applications; how do these methods perform in the wild on unknown objects? We propose a novel benchmark for object group distribution shifts in hand and object pose regression. We then test the hypothesis that meta-learning a baseline pose regression neural network can adapt to these shifts and generalize better to unknown objects. Our results show measurable improvements over the baseline, depending on the amount of prior knowledge. For the task of joint hand-object pose regression, we observe optimization interference for the meta-learner. To address this issue and improve the method further, we provide a comprehensive analysis which should serve as a basis for future work on this benchmark.



### SAGE: Saliency-Guided Mixup with Optimal Rearrangements
- **Arxiv ID**: http://arxiv.org/abs/2211.00113v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2211.00113v1)
- **Published**: 2022-10-31 19:45:21+00:00
- **Updated**: 2022-10-31 19:45:21+00:00
- **Authors**: Avery Ma, Nikita Dvornik, Ran Zhang, Leila Pishdad, Konstantinos G. Derpanis, Afsaneh Fazly
- **Comment**: Accepted at British Machine Vision Conference (BMVC) 2022. Code:
  https://github.com/SamsungLabs/SAGE
- **Journal**: None
- **Summary**: Data augmentation is a key element for training accurate models by reducing overfitting and improving generalization. For image classification, the most popular data augmentation techniques range from simple photometric and geometrical transformations, to more complex methods that use visual saliency to craft new training examples. As augmentation methods get more complex, their ability to increase the test accuracy improves, yet, such methods become cumbersome, inefficient and lead to poor out-of-domain generalization, as we show in this paper. This motivates a new augmentation technique that allows for high accuracy gains while being simple, efficient (i.e., minimal computation overhead) and generalizable. To this end, we introduce Saliency-Guided Mixup with Optimal Rearrangements (SAGE), which creates new training examples by rearranging and mixing image pairs using visual saliency as guidance. By explicitly leveraging saliency, SAGE promotes discriminative foreground objects and produces informative new images useful for training. We demonstrate on CIFAR-10 and CIFAR-100 that SAGE achieves better or comparable performance to the state of the art while being more efficient. Additionally, evaluations in the out-of-distribution setting, and few-shot learning on mini-ImageNet, show that SAGE achieves improved generalization performance without trading off robustness.



### minoHealth.ai: A Clinical Evaluation Of Deep Learning Systems For the Diagnosis of Pleural Effusion and Cardiomegaly In Ghana, Vietnam and the United States of America
- **Arxiv ID**: http://arxiv.org/abs/2211.00644v2
- **DOI**: None
- **Categories**: **eess.IV**, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2211.00644v2)
- **Published**: 2022-10-31 20:12:41+00:00
- **Updated**: 2022-11-05 22:51:29+00:00
- **Authors**: Darlington Akogo, Benjamin Dabo Sarkodie, Issah Abubakari Samori, Bashiru Babatunde Jimah, Dorothea Akosua Anim, Yaw Boateng Mensah
- **Comment**: None
- **Journal**: None
- **Summary**: A rapid and accurate diagnosis of cardiomegaly and pleural effusion is of the utmost importance to reduce mortality and medical costs. Artificial Intelligence has shown promise in diagnosing medical conditions. With this study, we seek to evaluate how well Artificial Intelligence (AI) systems, developed my minoHealth AI Labs, will perform at diagnosing cardiomegaly and pleural effusion, using chest x-rays from Ghana, Vietnam and the USA, and how well AI systems will perform when compared with radiologists working in Ghana. The evaluation dataset used in this study contained 100 images randomly selected from three datasets. The Deep Learning models were further tested on a larger Ghanaian dataset containing five hundred and sixty one (561) samples. Two AI systems were then evaluated on the evaluation dataset, whilst we also gave the same chest x-ray images within the evaluation dataset to 4 radiologists, with 5 - 20 years experience, to diagnose independently. For cardiomegaly, minoHealth-ai systems scored Area under the Receiver operating characteristic Curve (AUC-ROC) of 0.9 and 0.97 while the AUC-ROC of individual radiologists ranged from 0.77 to 0.87. For pleural effusion, the minoHealth-ai systems scored 0.97 and 0.91 whereas individual radiologists scored between 0.75 and 0.86. On both conditions, the best performing AI model outperforms the best performing radiologist by about 10%. We also evaluate the specificity, sensitivity, negative predictive value (NPV), and positive predictive value (PPV) between the minoHealth-ai systems and radiologists.



### Is Facial Recognition Biased at Near-Infrared Spectrum As Well?
- **Arxiv ID**: http://arxiv.org/abs/2211.00129v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.CY, cs.HC, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2211.00129v1)
- **Published**: 2022-10-31 20:37:41+00:00
- **Updated**: 2022-10-31 20:37:41+00:00
- **Authors**: Anoop Krishnan, Brian Neas, Ajita Rattani
- **Comment**: 7 pages, 2022 Virtual IEEE International Symposium on Technologies
  for Homeland Security
- **Journal**: None
- **Summary**: Published academic research and media articles suggest face recognition is biased across demographics. Specifically, unequal performance is obtained for women, dark-skinned people, and older adults. However, these published studies have examined the bias of facial recognition in the visible spectrum (VIS). Factors such as facial makeup, facial hair, skin color, and illumination variation have been attributed to the bias of this technology at the VIS. The near-infrared (NIR) spectrum offers an advantage over the VIS in terms of robustness to factors such as illumination changes, facial makeup, and skin color. Therefore, it is worthwhile to investigate the bias of facial recognition at the near-infrared spectrum (NIR). This first study investigates the bias of the face recognition systems at the NIR spectrum. To this aim, two popular NIR facial image datasets namely, CASIA-Face-Africa and Notre-Dame-NIVL consisting of African and Caucasian subjects, respectively, are used to investigate the bias of facial recognition technology across gender and race. Interestingly, experimental results suggest equitable face recognition performance across gender and race at the NIR spectrum.



### A Machine Learning Tutorial for Operational Meteorology, Part II: Neural Networks and Deep Learning
- **Arxiv ID**: http://arxiv.org/abs/2211.00147v2
- **DOI**: 10.1175/WAF-D-22-0187.1
- **Categories**: **cs.LG**, cs.CV, physics.ao-ph
- **Links**: [PDF](http://arxiv.org/pdf/2211.00147v2)
- **Published**: 2022-10-31 21:10:48+00:00
- **Updated**: 2023-03-12 15:13:54+00:00
- **Authors**: Randy J. Chase, David R. Harrison, Gary Lackmann, Amy McGovern
- **Comment**: None
- **Journal**: None
- **Summary**: Over the past decade the use of machine learning in meteorology has grown rapidly. Specifically neural networks and deep learning have been used at an unprecedented rate. In order to fill the dearth of resources covering neural networks with a meteorological lens, this paper discusses machine learning methods in a plain language format that is targeted for the operational meteorological community. This is the second paper in a pair that aim to serve as a machine learning resource for meteorologists. While the first paper focused on traditional machine learning methods (e.g., random forest), here a broad spectrum of neural networks and deep learning methods are discussed. Specifically this paper covers perceptrons, artificial neural networks, convolutional neural networks and U-networks. Like the part 1 paper, this manuscript discusses the terms associated with neural networks and their training. Then the manuscript provides some intuition behind every method and concludes by showing each method used in a meteorological example of diagnosing thunderstorms from satellite images (e.g., lightning flashes). This paper is accompanied with an open-source code repository to allow readers to explore neural networks using either the dataset provided (which is used in the paper) or as a template for alternate datasets.



### Improving Motion Forecasting for Autonomous Driving with the Cycle Consistency Loss
- **Arxiv ID**: http://arxiv.org/abs/2211.00149v1
- **DOI**: None
- **Categories**: **cs.CV**
- **Links**: [PDF](http://arxiv.org/pdf/2211.00149v1)
- **Published**: 2022-10-31 21:25:15+00:00
- **Updated**: 2022-10-31 21:25:15+00:00
- **Authors**: Titas Chakraborty, Akshay Bhagat, Henggang Cui
- **Comment**: Accepted at NeurIPS 2022 Machine Learning for Autonomous Driving
  Workshop
- **Journal**: None
- **Summary**: Robust motion forecasting of the dynamic scene is a critical component of an autonomous vehicle. It is a challenging problem due to the heterogeneity in the scene and the inherent uncertainties in the problem. To improve the accuracy of motion forecasting, in this work, we identify a new consistency constraint in this task, that is an agent's future trajectory should be coherent with its history observations and visa versa. To leverage this property, we propose a novel cycle consistency training scheme and define a novel cycle loss to encourage this consistency. In particular, we reverse the predicted future trajectory backward in time and feed it back into the prediction model to predict the history and compute the loss as an additional cycle loss term. Through our experiments on the Argoverse dataset, we demonstrate that cycle loss can improve the performance of competitive motion forecasting models.



### Agent-Controller Representations: Principled Offline RL with Rich Exogenous Information
- **Arxiv ID**: http://arxiv.org/abs/2211.00164v2
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV, cs.RO
- **Links**: [PDF](http://arxiv.org/pdf/2211.00164v2)
- **Published**: 2022-10-31 22:12:48+00:00
- **Updated**: 2023-08-14 00:16:23+00:00
- **Authors**: Riashat Islam, Manan Tomar, Alex Lamb, Yonathan Efroni, Hongyu Zang, Aniket Didolkar, Dipendra Misra, Xin Li, Harm van Seijen, Remi Tachet des Combes, John Langford
- **Comment**: ICML 2023
- **Journal**: None
- **Summary**: Learning to control an agent from data collected offline in a rich pixel-based visual observation space is vital for real-world applications of reinforcement learning (RL). A major challenge in this setting is the presence of input information that is hard to model and irrelevant to controlling the agent. This problem has been approached by the theoretical RL community through the lens of exogenous information, i.e, any control-irrelevant information contained in observations. For example, a robot navigating in busy streets needs to ignore irrelevant information, such as other people walking in the background, textures of objects, or birds in the sky. In this paper, we focus on the setting with visually detailed exogenous information, and introduce new offline RL benchmarks offering the ability to study this problem. We find that contemporary representation learning techniques can fail on datasets where the noise is a complex and time dependent process, which is prevalent in practical applications. To address these, we propose to use multi-step inverse models, which have seen a great deal of interest in the RL theory community, to learn Agent-Controller Representations for Offline-RL (ACRO). Despite being simple and requiring no reward, we show theoretically and empirically that the representation created by this objective greatly outperforms baselines.



### Improving Fairness in Image Classification via Sketching
- **Arxiv ID**: http://arxiv.org/abs/2211.00168v1
- **DOI**: None
- **Categories**: **cs.CV**, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2211.00168v1)
- **Published**: 2022-10-31 22:26:32+00:00
- **Updated**: 2022-10-31 22:26:32+00:00
- **Authors**: Ruichen Yao, Ziteng Cui, Xiaoxiao Li, Lin Gu
- **Comment**: 8 pages, 2 figures. To appear in 2022 Trustworthy and Socially
  Responsible Machine Learning (TSRML 2022) co-located with NeurIPS 2022
- **Journal**: None
- **Summary**: Fairness is a fundamental requirement for trustworthy and human-centered Artificial Intelligence (AI) system. However, deep neural networks (DNNs) tend to make unfair predictions when the training data are collected from different sub-populations with different attributes (i.e. color, sex, age), leading to biased DNN predictions. We notice that such a troubling phenomenon is often caused by data itself, which means that bias information is encoded to the DNN along with the useful information (i.e. class information, semantic information). Therefore, we propose to use sketching to handle this phenomenon. Without losing the utility of data, we explore the image-to-sketching methods that can maintain useful semantic information for the target classification while filtering out the useless bias information. In addition, we design a fair loss to further improve the model fairness. We evaluate our method through extensive experiments on both general scene dataset and medical scene dataset. Our results show that the desired image-to-sketching method improves model fairness and achieves satisfactory results among state-of-the-art.



### Class Interference of Deep Neural Networks
- **Arxiv ID**: http://arxiv.org/abs/2211.01370v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2211.01370v1)
- **Published**: 2022-10-31 22:29:30+00:00
- **Updated**: 2022-10-31 22:29:30+00:00
- **Authors**: Dongcui Diao, Hengshuai Yao, Bei Jiang
- **Comment**: None
- **Journal**: None
- **Summary**: Recognizing and telling similar objects apart is even hard for human beings. In this paper, we show that there is a phenomenon of class interference with all deep neural networks. Class interference represents the learning difficulty in data, and it constitutes the largest percentage of generalization errors by deep networks. To understand class interference, we propose cross-class tests, class ego directions and interference models. We show how to use these definitions to study minima flatness and class interference of a trained model. We also show how to detect class interference during training through label dancing pattern and class dancing notes.



### Xtreme Margin: A Tunable Loss Function for Binary Classification Problems
- **Arxiv ID**: http://arxiv.org/abs/2211.00176v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2211.00176v1)
- **Published**: 2022-10-31 22:39:32+00:00
- **Updated**: 2022-10-31 22:39:32+00:00
- **Authors**: Rayan Wali
- **Comment**: 10 pages
- **Journal**: None
- **Summary**: Loss functions drive the optimization of machine learning algorithms. The choice of a loss function can have a significant impact on the training of a model, and how the model learns the data. Binary classification is one of the major pillars of machine learning problems, used in medical imaging to failure detection applications. The most commonly used surrogate loss functions for binary classification include the binary cross-entropy and the hinge loss functions, which form the focus of our study.   In this paper, we provide an overview of a novel loss function, the Xtreme Margin loss function. Unlike the binary cross-entropy and the hinge loss functions, this loss function provides researchers and practitioners flexibility with their training process, from maximizing precision and AUC score to maximizing conditional accuracy for a particular class, through tunable hyperparameters $\lambda_1$ and $\lambda_2$, i.e., changing their values will alter the training of a model.



### Hybrid CNN -Interpreter: Interpret local and global contexts for CNN-based Models
- **Arxiv ID**: http://arxiv.org/abs/2211.00185v1
- **DOI**: None
- **Categories**: **cs.LG**, cs.AI, cs.CV
- **Links**: [PDF](http://arxiv.org/pdf/2211.00185v1)
- **Published**: 2022-10-31 22:59:33+00:00
- **Updated**: 2022-10-31 22:59:33+00:00
- **Authors**: Wenli Yang, Guan Huang, Renjie Li, Jiahao Yu, Yanyu Chen, Quan Bai, Beyong Kang
- **Comment**: None
- **Journal**: None
- **Summary**: Convolutional neural network (CNN) models have seen advanced improvements in performance in various domains, but lack of interpretability is a major barrier to assurance and regulation during operation for acceptance and deployment of AI-assisted applications. There have been many works on input interpretability focusing on analyzing the input-output relations, but the internal logic of models has not been clarified in the current mainstream interpretability methods. In this study, we propose a novel hybrid CNN-interpreter through: (1) An original forward propagation mechanism to examine the layer-specific prediction results for local interpretability. (2) A new global interpretability that indicates the feature correlation and filter importance effects. By combining the local and global interpretabilities, hybrid CNN-interpreter enables us to have a solid understanding and monitoring of model context during the whole learning process with detailed and consistent representations. Finally, the proposed interpretabilities have been demonstrated to adapt to various CNN-based model structures.



### Edge Grasp Network: A Graph-Based SE(3)-invariant Approach to Grasp Detection
- **Arxiv ID**: http://arxiv.org/abs/2211.00191v1
- **DOI**: None
- **Categories**: **cs.RO**, cs.AI, cs.CV, cs.LG
- **Links**: [PDF](http://arxiv.org/pdf/2211.00191v1)
- **Published**: 2022-10-31 23:17:59+00:00
- **Updated**: 2022-10-31 23:17:59+00:00
- **Authors**: Haojie Huang, Dian Wang, Xupeng Zhu, Robin Walters, Robert Platt
- **Comment**: https://haojhuang.github.io/edge_grasp_page/
- **Journal**: None
- **Summary**: Given point cloud input, the problem of 6-DoF grasp pose detection is to identify a set of hand poses in SE(3) from which an object can be successfully grasped. This important problem has many practical applications. Here we propose a novel method and neural network model that enables better grasp success rates relative to what is available in the literature. The method takes standard point cloud data as input and works well with single-view point clouds observed from arbitrary viewing directions.



